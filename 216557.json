{"path":"lucene/src/java/org/apache/lucene/codecs/lucene40/values/VarStraightBytesImpl.Writer#merge(DocValues,int,int,Bits).mjava","commits":[{"id":"fa0f44f887719e97183771e977cfc4bfb485b766","date":1326668713,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/codecs/lucene40/values/VarStraightBytesImpl.Writer#merge(DocValues,int,int,Bits).mjava","pathOld":"lucene/src/java/org/apache/lucene/codecs/lucene40/values/VarStraightBytesImpl.Writer#merge(SingleSubMergeState).mjava","sourceNew":"    @Override\n    protected void merge(DocValues readerIn, int docBase, int docCount, Bits liveDocs) throws IOException {\n      merge = true;\n      datOut = getOrCreateDataOut();\n      boolean success = false;\n      try {\n        if (liveDocs == null && readerIn instanceof VarStraightReader) {\n          // bulk merge since we don't have any deletes\n          VarStraightReader reader = (VarStraightReader) readerIn;\n          final int maxDocs = reader.maxDoc;\n          if (maxDocs == 0) {\n            return;\n          }\n          if (lastDocID+1 < docBase) {\n            fill(docBase, address);\n            lastDocID = docBase-1;\n          }\n          final long numDataBytes;\n          final IndexInput cloneIdx = reader.cloneIndex();\n          try {\n            numDataBytes = cloneIdx.readVLong();\n            final ReaderIterator iter = PackedInts.getReaderIterator(cloneIdx);\n            for (int i = 0; i < maxDocs; i++) {\n              long offset = iter.next();\n              ++lastDocID;\n              if (lastDocID >= docToAddress.length) {\n                int oldSize = docToAddress.length;\n                docToAddress = ArrayUtil.grow(docToAddress, 1 + lastDocID);\n                bytesUsed.addAndGet((docToAddress.length - oldSize)\n                    * RamUsageEstimator.NUM_BYTES_INT);\n              }\n              docToAddress[lastDocID] = address + offset;\n            }\n            address += numDataBytes; // this is the address after all addr pointers are updated\n            iter.close();\n          } finally {\n            IOUtils.close(cloneIdx);\n          }\n          final IndexInput cloneData = reader.cloneData();\n          try {\n            datOut.copyBytes(cloneData, numDataBytes);\n          } finally {\n            IOUtils.close(cloneData);  \n          }\n        } else {\n          super.merge(readerIn, docBase, docCount, liveDocs);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          IOUtils.closeWhileHandlingException(datOut);\n        }\n      }\n    }\n\n","sourceOld":"    @Override\n    protected void merge(SingleSubMergeState state) throws IOException {\n      merge = true;\n      datOut = getOrCreateDataOut();\n      boolean success = false;\n      try {\n        if (state.liveDocs == null && state.reader instanceof VarStraightReader) {\n          // bulk merge since we don't have any deletes\n          VarStraightReader reader = (VarStraightReader) state.reader;\n          final int maxDocs = reader.maxDoc;\n          if (maxDocs == 0) {\n            return;\n          }\n          if (lastDocID+1 < state.docBase) {\n            fill(state.docBase, address);\n            lastDocID = state.docBase-1;\n          }\n          final long numDataBytes;\n          final IndexInput cloneIdx = reader.cloneIndex();\n          try {\n            numDataBytes = cloneIdx.readVLong();\n            final ReaderIterator iter = PackedInts.getReaderIterator(cloneIdx);\n            for (int i = 0; i < maxDocs; i++) {\n              long offset = iter.next();\n              ++lastDocID;\n              if (lastDocID >= docToAddress.length) {\n                int oldSize = docToAddress.length;\n                docToAddress = ArrayUtil.grow(docToAddress, 1 + lastDocID);\n                bytesUsed.addAndGet((docToAddress.length - oldSize)\n                    * RamUsageEstimator.NUM_BYTES_INT);\n              }\n              docToAddress[lastDocID] = address + offset;\n            }\n            address += numDataBytes; // this is the address after all addr pointers are updated\n            iter.close();\n          } finally {\n            IOUtils.close(cloneIdx);\n          }\n          final IndexInput cloneData = reader.cloneData();\n          try {\n            datOut.copyBytes(cloneData, numDataBytes);\n          } finally {\n            IOUtils.close(cloneData);  \n          }\n        } else {\n          super.merge(state);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          IOUtils.closeWhileHandlingException(datOut);\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/VarStraightBytesImpl.Writer#merge(DocValues,int,int,Bits).mjava","pathOld":"lucene/src/java/org/apache/lucene/codecs/lucene40/values/VarStraightBytesImpl.Writer#merge(DocValues,int,int,Bits).mjava","sourceNew":"    @Override\n    protected void merge(DocValues readerIn, int docBase, int docCount, Bits liveDocs) throws IOException {\n      merge = true;\n      datOut = getOrCreateDataOut();\n      boolean success = false;\n      try {\n        if (liveDocs == null && readerIn instanceof VarStraightReader) {\n          // bulk merge since we don't have any deletes\n          VarStraightReader reader = (VarStraightReader) readerIn;\n          final int maxDocs = reader.maxDoc;\n          if (maxDocs == 0) {\n            return;\n          }\n          if (lastDocID+1 < docBase) {\n            fill(docBase, address);\n            lastDocID = docBase-1;\n          }\n          final long numDataBytes;\n          final IndexInput cloneIdx = reader.cloneIndex();\n          try {\n            numDataBytes = cloneIdx.readVLong();\n            final ReaderIterator iter = PackedInts.getReaderIterator(cloneIdx);\n            for (int i = 0; i < maxDocs; i++) {\n              long offset = iter.next();\n              ++lastDocID;\n              if (lastDocID >= docToAddress.length) {\n                int oldSize = docToAddress.length;\n                docToAddress = ArrayUtil.grow(docToAddress, 1 + lastDocID);\n                bytesUsed.addAndGet((docToAddress.length - oldSize)\n                    * RamUsageEstimator.NUM_BYTES_INT);\n              }\n              docToAddress[lastDocID] = address + offset;\n            }\n            address += numDataBytes; // this is the address after all addr pointers are updated\n            iter.close();\n          } finally {\n            IOUtils.close(cloneIdx);\n          }\n          final IndexInput cloneData = reader.cloneData();\n          try {\n            datOut.copyBytes(cloneData, numDataBytes);\n          } finally {\n            IOUtils.close(cloneData);  \n          }\n        } else {\n          super.merge(readerIn, docBase, docCount, liveDocs);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          IOUtils.closeWhileHandlingException(datOut);\n        }\n      }\n    }\n\n","sourceOld":"    @Override\n    protected void merge(DocValues readerIn, int docBase, int docCount, Bits liveDocs) throws IOException {\n      merge = true;\n      datOut = getOrCreateDataOut();\n      boolean success = false;\n      try {\n        if (liveDocs == null && readerIn instanceof VarStraightReader) {\n          // bulk merge since we don't have any deletes\n          VarStraightReader reader = (VarStraightReader) readerIn;\n          final int maxDocs = reader.maxDoc;\n          if (maxDocs == 0) {\n            return;\n          }\n          if (lastDocID+1 < docBase) {\n            fill(docBase, address);\n            lastDocID = docBase-1;\n          }\n          final long numDataBytes;\n          final IndexInput cloneIdx = reader.cloneIndex();\n          try {\n            numDataBytes = cloneIdx.readVLong();\n            final ReaderIterator iter = PackedInts.getReaderIterator(cloneIdx);\n            for (int i = 0; i < maxDocs; i++) {\n              long offset = iter.next();\n              ++lastDocID;\n              if (lastDocID >= docToAddress.length) {\n                int oldSize = docToAddress.length;\n                docToAddress = ArrayUtil.grow(docToAddress, 1 + lastDocID);\n                bytesUsed.addAndGet((docToAddress.length - oldSize)\n                    * RamUsageEstimator.NUM_BYTES_INT);\n              }\n              docToAddress[lastDocID] = address + offset;\n            }\n            address += numDataBytes; // this is the address after all addr pointers are updated\n            iter.close();\n          } finally {\n            IOUtils.close(cloneIdx);\n          }\n          final IndexInput cloneData = reader.cloneData();\n          try {\n            datOut.copyBytes(cloneData, numDataBytes);\n          } finally {\n            IOUtils.close(cloneData);  \n          }\n        } else {\n          super.merge(readerIn, docBase, docCount, liveDocs);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          IOUtils.closeWhileHandlingException(datOut);\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["fa0f44f887719e97183771e977cfc4bfb485b766"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"fa0f44f887719e97183771e977cfc4bfb485b766":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["fa0f44f887719e97183771e977cfc4bfb485b766"],"fa0f44f887719e97183771e977cfc4bfb485b766":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}