{"path":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","commits":[{"id":"eb55f624eb53f26cfb7f9614b862fb7657633358","date":1414519951,"type":0,"author":"Anshum Gupta","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","pathOld":"/dev/null","sourceNew":"  public Query parse() {\n    String id = localParams.get(\"id\");\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    \n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n    // TODO: Are the mintf and mindf defaults ok at 1/0 ?\n    \n    mlt.setMinTermFreq(localParams.getInt(\"mintf\", 1));\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n    if(localParams.get(\"minwl\") != null)\n      mlt.setMinWordLen(localParams.getInt(\"minwl\"));\n    \n    if(localParams.get(\"maxwl\") != null)\n      mlt.setMaxWordLen(localParams.getInt(\"maxwl\"));\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    String[] qf = localParams.getParams(\"qf\");\n    Map<String, ArrayList<String>> filteredDocument = new HashMap();\n\n    if (qf != null) {\n      mlt.setFieldNames(qf);\n      for (String field : qf) {\n        filteredDocument.put(field, (ArrayList<String>) doc.get(field));\n      }\n    } else {\n      for (String field : doc.getFieldNames()) {\n        filteredDocument.put(field, (ArrayList<String>) doc.get(field));\n      }\n    }\n\n    try {\n      return mlt.like(filteredDocument);\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["2100a5b744ecaec4d2b191a7da9083feb50a6f7f","655260340014c640e7d0f9a7a7ea1f00f36f65e5"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d32e559c96d0c16fe041e1608a4bbbf8a6c9a4e1","date":1414624217,"type":3,"author":"Anshum Gupta","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","sourceNew":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    \n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n    // TODO: Are the mintf and mindf defaults ok at 1/0 ?\n    \n    mlt.setMinTermFreq(localParams.getInt(\"mintf\", 1));\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n    if(localParams.get(\"minwl\") != null)\n      mlt.setMinWordLen(localParams.getInt(\"minwl\"));\n    \n    if(localParams.get(\"maxwl\") != null)\n      mlt.setMaxWordLen(localParams.getInt(\"maxwl\"));\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    String[] qf = localParams.getParams(\"qf\");\n    Map<String, ArrayList<String>> filteredDocument = new HashMap();\n\n    if (qf != null) {\n      mlt.setFieldNames(qf);\n      for (String field : qf) {\n        filteredDocument.put(field, (ArrayList<String>) doc.get(field));\n      }\n    } else {\n      for (String field : doc.getFieldNames()) {\n        filteredDocument.put(field, (ArrayList<String>) doc.get(field));\n      }\n    }\n\n    try {\n      return mlt.like(filteredDocument);\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","sourceOld":"  public Query parse() {\n    String id = localParams.get(\"id\");\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    \n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n    // TODO: Are the mintf and mindf defaults ok at 1/0 ?\n    \n    mlt.setMinTermFreq(localParams.getInt(\"mintf\", 1));\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n    if(localParams.get(\"minwl\") != null)\n      mlt.setMinWordLen(localParams.getInt(\"minwl\"));\n    \n    if(localParams.get(\"maxwl\") != null)\n      mlt.setMaxWordLen(localParams.getInt(\"maxwl\"));\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    String[] qf = localParams.getParams(\"qf\");\n    Map<String, ArrayList<String>> filteredDocument = new HashMap();\n\n    if (qf != null) {\n      mlt.setFieldNames(qf);\n      for (String field : qf) {\n        filteredDocument.put(field, (ArrayList<String>) doc.get(field));\n      }\n    } else {\n      for (String field : doc.getFieldNames()) {\n        filteredDocument.put(field, (ArrayList<String>) doc.get(field));\n      }\n    }\n\n    try {\n      return mlt.like(filteredDocument);\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"07d695a14a1938b01a5d4ab68b3c815eb061da94","date":1415146902,"type":3,"author":"Anshum Gupta","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","sourceNew":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    \n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n    // TODO: Are the mintf and mindf defaults ok at 1/0 ?\n    \n    mlt.setMinTermFreq(localParams.getInt(\"mintf\", 1));\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n    if(localParams.get(\"minwl\") != null)\n      mlt.setMinWordLen(localParams.getInt(\"minwl\"));\n    \n    if(localParams.get(\"maxwl\") != null)\n      mlt.setMaxWordLen(localParams.getInt(\"maxwl\"));\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    String[] qf = localParams.getParams(\"qf\");\n    Map<String, Collection<Object>> filteredDocument = new HashMap();\n\n    if (qf != null) {\n      mlt.setFieldNames(qf);\n      for (String field : qf) {\n        filteredDocument.put(field, doc.getFieldValues(field));\n      }\n    } else {\n      Map<String, SchemaField> fields = req.getSchema().getFields();\n      ArrayList<String> fieldNames = new ArrayList();\n      for (String field : doc.getFieldNames()) {\n        // Only use fields that are stored and have an explicit analyzer.\n        // This makes sense as the query uses tf/idf/.. for query construction.\n        // We might want to relook and change this in the future though.\n        if(fields.get(field).stored() \n            && fields.get(field).getType().isExplicitAnalyzer()) {\n          fieldNames.add(field);\n          filteredDocument.put(field, doc.getFieldValues(field));\n        }\n      }\n      mlt.setFieldNames(fieldNames.toArray(new String[fieldNames.size()]));\n    }\n\n    try {\n      return mlt.like(filteredDocument);\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","sourceOld":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    \n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n    // TODO: Are the mintf and mindf defaults ok at 1/0 ?\n    \n    mlt.setMinTermFreq(localParams.getInt(\"mintf\", 1));\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n    if(localParams.get(\"minwl\") != null)\n      mlt.setMinWordLen(localParams.getInt(\"minwl\"));\n    \n    if(localParams.get(\"maxwl\") != null)\n      mlt.setMaxWordLen(localParams.getInt(\"maxwl\"));\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    String[] qf = localParams.getParams(\"qf\");\n    Map<String, ArrayList<String>> filteredDocument = new HashMap();\n\n    if (qf != null) {\n      mlt.setFieldNames(qf);\n      for (String field : qf) {\n        filteredDocument.put(field, (ArrayList<String>) doc.get(field));\n      }\n    } else {\n      for (String field : doc.getFieldNames()) {\n        filteredDocument.put(field, (ArrayList<String>) doc.get(field));\n      }\n    }\n\n    try {\n      return mlt.like(filteredDocument);\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","bugFix":null,"bugIntro":["2100a5b744ecaec4d2b191a7da9083feb50a6f7f","655260340014c640e7d0f9a7a7ea1f00f36f65e5"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"19d28b1683d6453ee94a9205e2d32206d2dde868","date":1429661373,"type":3,"author":"Anshum Gupta","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","sourceNew":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    if(doc == null) {\n      new SolrException(\n          SolrException.ErrorCode.BAD_REQUEST, \"Error completing MLT request. Could not fetch \" +\n          \"document with id [\" + id + \"]\");\n    }\n    \n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n    // TODO: Are the mintf and mindf defaults ok at 1/0 ?\n    \n    mlt.setMinTermFreq(localParams.getInt(\"mintf\", 1));\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n    if(localParams.get(\"minwl\") != null)\n      mlt.setMinWordLen(localParams.getInt(\"minwl\"));\n    \n    if(localParams.get(\"maxwl\") != null)\n      mlt.setMaxWordLen(localParams.getInt(\"maxwl\"));\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    String[] qf = localParams.getParams(\"qf\");\n    Map<String, Collection<Object>> filteredDocument = new HashMap();\n\n    if (qf != null) {\n      mlt.setFieldNames(qf);\n      for (String field : qf) {\n        filteredDocument.put(field, doc.getFieldValues(field));\n      }\n    } else {\n      Map<String, SchemaField> fields = req.getSchema().getFields();\n      ArrayList<String> fieldNames = new ArrayList();\n      for (String field : doc.getFieldNames()) {\n        // Only use fields that are stored and have an explicit analyzer.\n        // This makes sense as the query uses tf/idf/.. for query construction.\n        // We might want to relook and change this in the future though.\n        if(fields.get(field).stored() \n            && fields.get(field).getType().isExplicitAnalyzer()) {\n          fieldNames.add(field);\n          filteredDocument.put(field, doc.getFieldValues(field));\n        }\n      }\n      mlt.setFieldNames(fieldNames.toArray(new String[fieldNames.size()]));\n    }\n\n    try {\n      return mlt.like(filteredDocument);\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","sourceOld":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    \n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n    // TODO: Are the mintf and mindf defaults ok at 1/0 ?\n    \n    mlt.setMinTermFreq(localParams.getInt(\"mintf\", 1));\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n    if(localParams.get(\"minwl\") != null)\n      mlt.setMinWordLen(localParams.getInt(\"minwl\"));\n    \n    if(localParams.get(\"maxwl\") != null)\n      mlt.setMaxWordLen(localParams.getInt(\"maxwl\"));\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    String[] qf = localParams.getParams(\"qf\");\n    Map<String, Collection<Object>> filteredDocument = new HashMap();\n\n    if (qf != null) {\n      mlt.setFieldNames(qf);\n      for (String field : qf) {\n        filteredDocument.put(field, doc.getFieldValues(field));\n      }\n    } else {\n      Map<String, SchemaField> fields = req.getSchema().getFields();\n      ArrayList<String> fieldNames = new ArrayList();\n      for (String field : doc.getFieldNames()) {\n        // Only use fields that are stored and have an explicit analyzer.\n        // This makes sense as the query uses tf/idf/.. for query construction.\n        // We might want to relook and change this in the future though.\n        if(fields.get(field).stored() \n            && fields.get(field).getType().isExplicitAnalyzer()) {\n          fieldNames.add(field);\n          filteredDocument.put(field, doc.getFieldValues(field));\n        }\n      }\n      mlt.setFieldNames(fieldNames.toArray(new String[fieldNames.size()]));\n    }\n\n    try {\n      return mlt.like(filteredDocument);\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"776417a20af3930a363a226c989867f65e93ee91","date":1434582735,"type":3,"author":"Anshum Gupta","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","sourceNew":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    if(doc == null) {\n      throw new SolrException(\n          SolrException.ErrorCode.BAD_REQUEST, \"Error completing MLT request. Could not fetch \" +\n          \"document with id [\" + id + \"]\");\n    }\n    \n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n    \n    if(localParams.getInt(\"mintf\") != null)\n      mlt.setMinTermFreq(localParams.getInt(\"mintf\"));\n\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n\n    if(localParams.get(\"minwl\") != null)\n      mlt.setMinWordLen(localParams.getInt(\"minwl\"));\n\n    if(localParams.get(\"maxwl\") != null)\n      mlt.setMaxWordLen(localParams.getInt(\"maxwl\"));\n\n    if(localParams.get(\"maxqt\") != null)\n      mlt.setMaxWordLen(localParams.getInt(\"maxqt\"));\n\n    if(localParams.get(\"maxntp\") != null)\n      mlt.setMaxWordLen(localParams.getInt(\"maxntp\"));\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    String[] qf = localParams.getParams(\"qf\");\n    Map<String, Collection<Object>> filteredDocument = new HashMap();\n\n    if (qf != null) {\n      mlt.setFieldNames(qf);\n      for (String field : qf) {\n        filteredDocument.put(field, doc.getFieldValues(field));\n      }\n    } else {\n      Map<String, SchemaField> fields = req.getSchema().getFields();\n      ArrayList<String> fieldNames = new ArrayList();\n      for (String field : doc.getFieldNames()) {\n        // Only use fields that are stored and have an explicit analyzer.\n        // This makes sense as the query uses tf/idf/.. for query construction.\n        // We might want to relook and change this in the future though.\n        if(fields.get(field).stored() \n            && fields.get(field).getType().isExplicitAnalyzer()) {\n          fieldNames.add(field);\n          filteredDocument.put(field, doc.getFieldValues(field));\n        }\n      }\n      mlt.setFieldNames(fieldNames.toArray(new String[fieldNames.size()]));\n    }\n\n    try {\n      return mlt.like(filteredDocument);\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","sourceOld":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    if(doc == null) {\n      new SolrException(\n          SolrException.ErrorCode.BAD_REQUEST, \"Error completing MLT request. Could not fetch \" +\n          \"document with id [\" + id + \"]\");\n    }\n    \n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n    // TODO: Are the mintf and mindf defaults ok at 1/0 ?\n    \n    mlt.setMinTermFreq(localParams.getInt(\"mintf\", 1));\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n    if(localParams.get(\"minwl\") != null)\n      mlt.setMinWordLen(localParams.getInt(\"minwl\"));\n    \n    if(localParams.get(\"maxwl\") != null)\n      mlt.setMaxWordLen(localParams.getInt(\"maxwl\"));\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    String[] qf = localParams.getParams(\"qf\");\n    Map<String, Collection<Object>> filteredDocument = new HashMap();\n\n    if (qf != null) {\n      mlt.setFieldNames(qf);\n      for (String field : qf) {\n        filteredDocument.put(field, doc.getFieldValues(field));\n      }\n    } else {\n      Map<String, SchemaField> fields = req.getSchema().getFields();\n      ArrayList<String> fieldNames = new ArrayList();\n      for (String field : doc.getFieldNames()) {\n        // Only use fields that are stored and have an explicit analyzer.\n        // This makes sense as the query uses tf/idf/.. for query construction.\n        // We might want to relook and change this in the future though.\n        if(fields.get(field).stored() \n            && fields.get(field).getType().isExplicitAnalyzer()) {\n          fieldNames.add(field);\n          filteredDocument.put(field, doc.getFieldValues(field));\n        }\n      }\n      mlt.setFieldNames(fieldNames.toArray(new String[fieldNames.size()]));\n    }\n\n    try {\n      return mlt.like(filteredDocument);\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"caeebbaa964f57dceaab0b9cb5800882e88d57ff","date":1435075428,"type":3,"author":"Anshum Gupta","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","sourceNew":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    if(doc == null) {\n      throw new SolrException(\n          SolrException.ErrorCode.BAD_REQUEST, \"Error completing MLT request. Could not fetch \" +\n          \"document with id [\" + id + \"]\");\n    }\n    \n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n    \n    if(localParams.getInt(\"mintf\") != null)\n      mlt.setMinTermFreq(localParams.getInt(\"mintf\"));\n\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n\n    if(localParams.get(\"minwl\") != null)\n      mlt.setMinWordLen(localParams.getInt(\"minwl\"));\n\n    if(localParams.get(\"maxwl\") != null)\n      mlt.setMaxWordLen(localParams.getInt(\"maxwl\"));\n\n    if(localParams.get(\"maxqt\") != null)\n      mlt.setMaxQueryTerms(localParams.getInt(\"maxqt\"));\n\n    if(localParams.get(\"maxntp\") != null)\n      mlt.setMaxNumTokensParsed(localParams.getInt(\"maxntp\"));\n    \n    if(localParams.get(\"maxdf\") != null) {\n      mlt.setMaxDocFreq(localParams.getInt(\"maxdf\"));\n    }\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    String[] qf = localParams.getParams(\"qf\");\n    Map<String, Collection<Object>> filteredDocument = new HashMap();\n\n    if (qf != null) {\n      mlt.setFieldNames(qf);\n      for (String field : qf) {\n        filteredDocument.put(field, doc.getFieldValues(field));\n      }\n    } else {\n      Map<String, SchemaField> fields = req.getSchema().getFields();\n      ArrayList<String> fieldNames = new ArrayList();\n      for (String field : doc.getFieldNames()) {\n        // Only use fields that are stored and have an explicit analyzer.\n        // This makes sense as the query uses tf/idf/.. for query construction.\n        // We might want to relook and change this in the future though.\n        if(fields.get(field).stored() \n            && fields.get(field).getType().isExplicitAnalyzer()) {\n          fieldNames.add(field);\n          filteredDocument.put(field, doc.getFieldValues(field));\n        }\n      }\n      mlt.setFieldNames(fieldNames.toArray(new String[fieldNames.size()]));\n    }\n\n    try {\n      return mlt.like(filteredDocument);\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","sourceOld":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    if(doc == null) {\n      throw new SolrException(\n          SolrException.ErrorCode.BAD_REQUEST, \"Error completing MLT request. Could not fetch \" +\n          \"document with id [\" + id + \"]\");\n    }\n    \n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n    \n    if(localParams.getInt(\"mintf\") != null)\n      mlt.setMinTermFreq(localParams.getInt(\"mintf\"));\n\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n\n    if(localParams.get(\"minwl\") != null)\n      mlt.setMinWordLen(localParams.getInt(\"minwl\"));\n\n    if(localParams.get(\"maxwl\") != null)\n      mlt.setMaxWordLen(localParams.getInt(\"maxwl\"));\n\n    if(localParams.get(\"maxqt\") != null)\n      mlt.setMaxWordLen(localParams.getInt(\"maxqt\"));\n\n    if(localParams.get(\"maxntp\") != null)\n      mlt.setMaxWordLen(localParams.getInt(\"maxntp\"));\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    String[] qf = localParams.getParams(\"qf\");\n    Map<String, Collection<Object>> filteredDocument = new HashMap();\n\n    if (qf != null) {\n      mlt.setFieldNames(qf);\n      for (String field : qf) {\n        filteredDocument.put(field, doc.getFieldValues(field));\n      }\n    } else {\n      Map<String, SchemaField> fields = req.getSchema().getFields();\n      ArrayList<String> fieldNames = new ArrayList();\n      for (String field : doc.getFieldNames()) {\n        // Only use fields that are stored and have an explicit analyzer.\n        // This makes sense as the query uses tf/idf/.. for query construction.\n        // We might want to relook and change this in the future though.\n        if(fields.get(field).stored() \n            && fields.get(field).getType().isExplicitAnalyzer()) {\n          fieldNames.add(field);\n          filteredDocument.put(field, doc.getFieldValues(field));\n        }\n      }\n      mlt.setFieldNames(fieldNames.toArray(new String[fieldNames.size()]));\n    }\n\n    try {\n      return mlt.like(filteredDocument);\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"655260340014c640e7d0f9a7a7ea1f00f36f65e5","date":1436227523,"type":3,"author":"Anshum Gupta","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","sourceNew":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    if(doc == null) {\n      throw new SolrException(\n          SolrException.ErrorCode.BAD_REQUEST, \"Error completing MLT request. Could not fetch \" +\n          \"document with id [\" + id + \"]\");\n    }\n    \n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n    \n    if(localParams.getInt(\"mintf\") != null)\n      mlt.setMinTermFreq(localParams.getInt(\"mintf\"));\n\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n\n    if(localParams.get(\"minwl\") != null)\n      mlt.setMinWordLen(localParams.getInt(\"minwl\"));\n\n    if(localParams.get(\"maxwl\") != null)\n      mlt.setMaxWordLen(localParams.getInt(\"maxwl\"));\n\n    if(localParams.get(\"maxqt\") != null)\n      mlt.setMaxQueryTerms(localParams.getInt(\"maxqt\"));\n\n    if(localParams.get(\"maxntp\") != null)\n      mlt.setMaxNumTokensParsed(localParams.getInt(\"maxntp\"));\n    \n    if(localParams.get(\"maxdf\") != null) {\n      mlt.setMaxDocFreq(localParams.getInt(\"maxdf\"));\n    }\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    String[] qf = localParams.getParams(\"qf\");\n    Map<String, Collection<Object>> filteredDocument = new HashMap();\n\n    ArrayList<String> fieldNames = new ArrayList();\n\n    if (qf != null) {\n      for (String fieldName : qf) {\n        if (!StringUtils.isEmpty(fieldName))  {\n          String[] strings = splitList.split(fieldName);\n          for (String string : strings) {\n            if (!StringUtils.isEmpty(string)) {\n              fieldNames.add(string);\n            }\n          }\n        }\n      }\n    } else {\n      Map<String, SchemaField> fields = req.getSchema().getFields();\n      for (String field : doc.getFieldNames()) {\n        // Only use fields that are stored and have an explicit analyzer.\n        // This makes sense as the query uses tf/idf/.. for query construction.\n        // We might want to relook and change this in the future though.\n        if(fields.get(field).stored() \n            && fields.get(field).getType().isExplicitAnalyzer()) {\n          fieldNames.add(field);\n        }\n      }\n    }\n\n    if( fieldNames.size() < 1 ) {\n      throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\n          \"MoreLikeThis requires at least one similarity field: qf\" );\n    }\n\n    mlt.setFieldNames(fieldNames.toArray(new String[fieldNames.size()]));\n    for (String field : fieldNames) {\n      filteredDocument.put(field, doc.getFieldValues(field));\n    }\n\n    try {\n      return mlt.like(filteredDocument);\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","sourceOld":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    if(doc == null) {\n      throw new SolrException(\n          SolrException.ErrorCode.BAD_REQUEST, \"Error completing MLT request. Could not fetch \" +\n          \"document with id [\" + id + \"]\");\n    }\n    \n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n    \n    if(localParams.getInt(\"mintf\") != null)\n      mlt.setMinTermFreq(localParams.getInt(\"mintf\"));\n\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n\n    if(localParams.get(\"minwl\") != null)\n      mlt.setMinWordLen(localParams.getInt(\"minwl\"));\n\n    if(localParams.get(\"maxwl\") != null)\n      mlt.setMaxWordLen(localParams.getInt(\"maxwl\"));\n\n    if(localParams.get(\"maxqt\") != null)\n      mlt.setMaxQueryTerms(localParams.getInt(\"maxqt\"));\n\n    if(localParams.get(\"maxntp\") != null)\n      mlt.setMaxNumTokensParsed(localParams.getInt(\"maxntp\"));\n    \n    if(localParams.get(\"maxdf\") != null) {\n      mlt.setMaxDocFreq(localParams.getInt(\"maxdf\"));\n    }\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    String[] qf = localParams.getParams(\"qf\");\n    Map<String, Collection<Object>> filteredDocument = new HashMap();\n\n    if (qf != null) {\n      mlt.setFieldNames(qf);\n      for (String field : qf) {\n        filteredDocument.put(field, doc.getFieldValues(field));\n      }\n    } else {\n      Map<String, SchemaField> fields = req.getSchema().getFields();\n      ArrayList<String> fieldNames = new ArrayList();\n      for (String field : doc.getFieldNames()) {\n        // Only use fields that are stored and have an explicit analyzer.\n        // This makes sense as the query uses tf/idf/.. for query construction.\n        // We might want to relook and change this in the future though.\n        if(fields.get(field).stored() \n            && fields.get(field).getType().isExplicitAnalyzer()) {\n          fieldNames.add(field);\n          filteredDocument.put(field, doc.getFieldValues(field));\n        }\n      }\n      mlt.setFieldNames(fieldNames.toArray(new String[fieldNames.size()]));\n    }\n\n    try {\n      return mlt.like(filteredDocument);\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","bugFix":["07d695a14a1938b01a5d4ab68b3c815eb061da94","eb55f624eb53f26cfb7f9614b862fb7657633358"],"bugIntro":["2100a5b744ecaec4d2b191a7da9083feb50a6f7f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ed95a777f3860385e015fb8a082e4b66a5aa6bb8","date":1448307668,"type":3,"author":"Anshum Gupta","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","sourceNew":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    if(doc == null) {\n      throw new SolrException(\n          SolrException.ErrorCode.BAD_REQUEST, \"Error completing MLT request. Could not fetch \" +\n          \"document with id [\" + id + \"]\");\n    }\n    \n    String[] qf = localParams.getParams(\"qf\");\n    Map<String,Float> boostFields = new HashMap<>();\n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n    \n    if(localParams.getInt(\"mintf\") != null)\n      mlt.setMinTermFreq(localParams.getInt(\"mintf\"));\n\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n\n    if(localParams.get(\"minwl\") != null)\n      mlt.setMinWordLen(localParams.getInt(\"minwl\"));\n\n    if(localParams.get(\"maxwl\") != null)\n      mlt.setMaxWordLen(localParams.getInt(\"maxwl\"));\n\n    if(localParams.get(\"maxqt\") != null)\n      mlt.setMaxQueryTerms(localParams.getInt(\"maxqt\"));\n\n    if(localParams.get(\"maxntp\") != null)\n      mlt.setMaxNumTokensParsed(localParams.getInt(\"maxntp\"));\n    \n    if(localParams.get(\"maxdf\") != null) {\n      mlt.setMaxDocFreq(localParams.getInt(\"maxdf\"));\n    }\n\n    if(localParams.get(\"boost\") != null) {\n      mlt.setBoost(localParams.getBool(\"boost\"));\n      boostFields = SolrPluginUtils.parseFieldBoosts(qf);\n    }\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    Map<String, Collection<Object>> filteredDocument = new HashMap();\n    ArrayList<String> fieldNames = new ArrayList();\n\n    if (qf != null) {\n      for (String fieldName : qf) {\n        if (!StringUtils.isEmpty(fieldName))  {\n          String[] strings = splitList.split(fieldName);\n          for (String string : strings) {\n            if (!StringUtils.isEmpty(string)) {\n              fieldNames.add(string);\n            }\n          }\n        }\n      }\n    } else {\n      Map<String, SchemaField> fields = req.getSchema().getFields();\n      for (String field : doc.getFieldNames()) {\n        // Only use fields that are stored and have an explicit analyzer.\n        // This makes sense as the query uses tf/idf/.. for query construction.\n        // We might want to relook and change this in the future though.\n        if(fields.get(field).stored() \n            && fields.get(field).getType().isExplicitAnalyzer()) {\n          fieldNames.add(field);\n        }\n      }\n    }\n\n    if( fieldNames.size() < 1 ) {\n      throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\n          \"MoreLikeThis requires at least one similarity field: qf\" );\n    }\n\n    mlt.setFieldNames(fieldNames.toArray(new String[fieldNames.size()]));\n    for (String field : fieldNames) {\n      filteredDocument.put(field, doc.getFieldValues(field));\n    }\n\n    try {\n      Query rawMLTQuery = mlt.like(filteredDocument);\n      BooleanQuery boostedMLTQuery = (BooleanQuery) rawMLTQuery;\n\n      if (boostFields.size() > 0) {\n        BooleanQuery.Builder newQ = new BooleanQuery.Builder();\n        newQ.setDisableCoord(boostedMLTQuery.isCoordDisabled());\n        newQ.setMinimumNumberShouldMatch(boostedMLTQuery.getMinimumNumberShouldMatch());\n\n        for (BooleanClause clause : boostedMLTQuery) {\n          Query q = clause.getQuery();\n          Float b = boostFields.get(((TermQuery) q).getTerm().field());\n\n          if (b != null) {\n            q = new BoostQuery(q, b);\n          }\n\n          newQ.add(q, clause.getOccur());\n        }\n\n        boostedMLTQuery = newQ.build();\n      }\n\n      // exclude current document from results\n      BooleanQuery.Builder realMLTQuery = new BooleanQuery.Builder();\n      realMLTQuery.setDisableCoord(true);\n      realMLTQuery.add(boostedMLTQuery, BooleanClause.Occur.MUST);\n      realMLTQuery.add(createIdQuery(\"id\", id), BooleanClause.Occur.MUST_NOT);\n\n      return realMLTQuery.build();\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","sourceOld":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    if(doc == null) {\n      throw new SolrException(\n          SolrException.ErrorCode.BAD_REQUEST, \"Error completing MLT request. Could not fetch \" +\n          \"document with id [\" + id + \"]\");\n    }\n    \n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n    \n    if(localParams.getInt(\"mintf\") != null)\n      mlt.setMinTermFreq(localParams.getInt(\"mintf\"));\n\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n\n    if(localParams.get(\"minwl\") != null)\n      mlt.setMinWordLen(localParams.getInt(\"minwl\"));\n\n    if(localParams.get(\"maxwl\") != null)\n      mlt.setMaxWordLen(localParams.getInt(\"maxwl\"));\n\n    if(localParams.get(\"maxqt\") != null)\n      mlt.setMaxQueryTerms(localParams.getInt(\"maxqt\"));\n\n    if(localParams.get(\"maxntp\") != null)\n      mlt.setMaxNumTokensParsed(localParams.getInt(\"maxntp\"));\n    \n    if(localParams.get(\"maxdf\") != null) {\n      mlt.setMaxDocFreq(localParams.getInt(\"maxdf\"));\n    }\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    String[] qf = localParams.getParams(\"qf\");\n    Map<String, Collection<Object>> filteredDocument = new HashMap();\n\n    ArrayList<String> fieldNames = new ArrayList();\n\n    if (qf != null) {\n      for (String fieldName : qf) {\n        if (!StringUtils.isEmpty(fieldName))  {\n          String[] strings = splitList.split(fieldName);\n          for (String string : strings) {\n            if (!StringUtils.isEmpty(string)) {\n              fieldNames.add(string);\n            }\n          }\n        }\n      }\n    } else {\n      Map<String, SchemaField> fields = req.getSchema().getFields();\n      for (String field : doc.getFieldNames()) {\n        // Only use fields that are stored and have an explicit analyzer.\n        // This makes sense as the query uses tf/idf/.. for query construction.\n        // We might want to relook and change this in the future though.\n        if(fields.get(field).stored() \n            && fields.get(field).getType().isExplicitAnalyzer()) {\n          fieldNames.add(field);\n        }\n      }\n    }\n\n    if( fieldNames.size() < 1 ) {\n      throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\n          \"MoreLikeThis requires at least one similarity field: qf\" );\n    }\n\n    mlt.setFieldNames(fieldNames.toArray(new String[fieldNames.size()]));\n    for (String field : fieldNames) {\n      filteredDocument.put(field, doc.getFieldValues(field));\n    }\n\n    try {\n      return mlt.like(filteredDocument);\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","bugFix":null,"bugIntro":["2100a5b744ecaec4d2b191a7da9083feb50a6f7f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"19cb756f0ad73c8d898cb8bfdd9f04bcc6e3b7c1","date":1451604685,"type":3,"author":"Ramkumar Aiyengar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","sourceNew":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    if(doc == null) {\n      throw new SolrException(\n          SolrException.ErrorCode.BAD_REQUEST, \"Error completing MLT request. Could not fetch \" +\n          \"document with id [\" + id + \"]\");\n    }\n    \n    String[] qf = localParams.getParams(\"qf\");\n    Map<String,Float> boostFields = new HashMap<>();\n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n    \n    if(localParams.getInt(\"mintf\") != null)\n      mlt.setMinTermFreq(localParams.getInt(\"mintf\"));\n\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n\n    if(localParams.get(\"minwl\") != null)\n      mlt.setMinWordLen(localParams.getInt(\"minwl\"));\n\n    if(localParams.get(\"maxwl\") != null)\n      mlt.setMaxWordLen(localParams.getInt(\"maxwl\"));\n\n    if(localParams.get(\"maxqt\") != null)\n      mlt.setMaxQueryTerms(localParams.getInt(\"maxqt\"));\n\n    if(localParams.get(\"maxntp\") != null)\n      mlt.setMaxNumTokensParsed(localParams.getInt(\"maxntp\"));\n    \n    if(localParams.get(\"maxdf\") != null) {\n      mlt.setMaxDocFreq(localParams.getInt(\"maxdf\"));\n    }\n\n    if(localParams.get(\"boost\") != null) {\n      mlt.setBoost(localParams.getBool(\"boost\"));\n      boostFields = SolrPluginUtils.parseFieldBoosts(qf);\n    }\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    Map<String, Collection<Object>> filteredDocument = new HashMap<>();\n    ArrayList<String> fieldNames = new ArrayList<>();\n\n    if (qf != null) {\n      for (String fieldName : qf) {\n        if (!StringUtils.isEmpty(fieldName))  {\n          String[] strings = splitList.split(fieldName);\n          for (String string : strings) {\n            if (!StringUtils.isEmpty(string)) {\n              fieldNames.add(string);\n            }\n          }\n        }\n      }\n    } else {\n      Map<String, SchemaField> fields = req.getSchema().getFields();\n      for (String field : doc.getFieldNames()) {\n        // Only use fields that are stored and have an explicit analyzer.\n        // This makes sense as the query uses tf/idf/.. for query construction.\n        // We might want to relook and change this in the future though.\n        if(fields.get(field).stored() \n            && fields.get(field).getType().isExplicitAnalyzer()) {\n          fieldNames.add(field);\n        }\n      }\n    }\n\n    if( fieldNames.size() < 1 ) {\n      throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\n          \"MoreLikeThis requires at least one similarity field: qf\" );\n    }\n\n    mlt.setFieldNames(fieldNames.toArray(new String[fieldNames.size()]));\n    for (String field : fieldNames) {\n      filteredDocument.put(field, doc.getFieldValues(field));\n    }\n\n    try {\n      Query rawMLTQuery = mlt.like(filteredDocument);\n      BooleanQuery boostedMLTQuery = (BooleanQuery) rawMLTQuery;\n\n      if (boostFields.size() > 0) {\n        BooleanQuery.Builder newQ = new BooleanQuery.Builder();\n        newQ.setDisableCoord(boostedMLTQuery.isCoordDisabled());\n        newQ.setMinimumNumberShouldMatch(boostedMLTQuery.getMinimumNumberShouldMatch());\n\n        for (BooleanClause clause : boostedMLTQuery) {\n          Query q = clause.getQuery();\n          float originalBoost = 1f;\n          if (q instanceof BoostQuery) {\n            BoostQuery bq = (BoostQuery) q;\n            q = bq.getQuery();\n            originalBoost = bq.getBoost();\n          }\n          Float fieldBoost = boostFields.get(((TermQuery) q).getTerm().field());\n          q = ((fieldBoost != null) ? new BoostQuery(q, fieldBoost * originalBoost) : clause.getQuery());\n          newQ.add(q, clause.getOccur());\n        }\n\n        boostedMLTQuery = newQ.build();\n      }\n\n      // exclude current document from results\n      BooleanQuery.Builder realMLTQuery = new BooleanQuery.Builder();\n      realMLTQuery.setDisableCoord(true);\n      realMLTQuery.add(boostedMLTQuery, BooleanClause.Occur.MUST);\n      realMLTQuery.add(createIdQuery(\"id\", id), BooleanClause.Occur.MUST_NOT);\n\n      return realMLTQuery.build();\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","sourceOld":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    if(doc == null) {\n      throw new SolrException(\n          SolrException.ErrorCode.BAD_REQUEST, \"Error completing MLT request. Could not fetch \" +\n          \"document with id [\" + id + \"]\");\n    }\n    \n    String[] qf = localParams.getParams(\"qf\");\n    Map<String,Float> boostFields = new HashMap<>();\n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n    \n    if(localParams.getInt(\"mintf\") != null)\n      mlt.setMinTermFreq(localParams.getInt(\"mintf\"));\n\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n\n    if(localParams.get(\"minwl\") != null)\n      mlt.setMinWordLen(localParams.getInt(\"minwl\"));\n\n    if(localParams.get(\"maxwl\") != null)\n      mlt.setMaxWordLen(localParams.getInt(\"maxwl\"));\n\n    if(localParams.get(\"maxqt\") != null)\n      mlt.setMaxQueryTerms(localParams.getInt(\"maxqt\"));\n\n    if(localParams.get(\"maxntp\") != null)\n      mlt.setMaxNumTokensParsed(localParams.getInt(\"maxntp\"));\n    \n    if(localParams.get(\"maxdf\") != null) {\n      mlt.setMaxDocFreq(localParams.getInt(\"maxdf\"));\n    }\n\n    if(localParams.get(\"boost\") != null) {\n      mlt.setBoost(localParams.getBool(\"boost\"));\n      boostFields = SolrPluginUtils.parseFieldBoosts(qf);\n    }\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    Map<String, Collection<Object>> filteredDocument = new HashMap();\n    ArrayList<String> fieldNames = new ArrayList();\n\n    if (qf != null) {\n      for (String fieldName : qf) {\n        if (!StringUtils.isEmpty(fieldName))  {\n          String[] strings = splitList.split(fieldName);\n          for (String string : strings) {\n            if (!StringUtils.isEmpty(string)) {\n              fieldNames.add(string);\n            }\n          }\n        }\n      }\n    } else {\n      Map<String, SchemaField> fields = req.getSchema().getFields();\n      for (String field : doc.getFieldNames()) {\n        // Only use fields that are stored and have an explicit analyzer.\n        // This makes sense as the query uses tf/idf/.. for query construction.\n        // We might want to relook and change this in the future though.\n        if(fields.get(field).stored() \n            && fields.get(field).getType().isExplicitAnalyzer()) {\n          fieldNames.add(field);\n        }\n      }\n    }\n\n    if( fieldNames.size() < 1 ) {\n      throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\n          \"MoreLikeThis requires at least one similarity field: qf\" );\n    }\n\n    mlt.setFieldNames(fieldNames.toArray(new String[fieldNames.size()]));\n    for (String field : fieldNames) {\n      filteredDocument.put(field, doc.getFieldValues(field));\n    }\n\n    try {\n      Query rawMLTQuery = mlt.like(filteredDocument);\n      BooleanQuery boostedMLTQuery = (BooleanQuery) rawMLTQuery;\n\n      if (boostFields.size() > 0) {\n        BooleanQuery.Builder newQ = new BooleanQuery.Builder();\n        newQ.setDisableCoord(boostedMLTQuery.isCoordDisabled());\n        newQ.setMinimumNumberShouldMatch(boostedMLTQuery.getMinimumNumberShouldMatch());\n\n        for (BooleanClause clause : boostedMLTQuery) {\n          Query q = clause.getQuery();\n          Float b = boostFields.get(((TermQuery) q).getTerm().field());\n\n          if (b != null) {\n            q = new BoostQuery(q, b);\n          }\n\n          newQ.add(q, clause.getOccur());\n        }\n\n        boostedMLTQuery = newQ.build();\n      }\n\n      // exclude current document from results\n      BooleanQuery.Builder realMLTQuery = new BooleanQuery.Builder();\n      realMLTQuery.setDisableCoord(true);\n      realMLTQuery.add(boostedMLTQuery, BooleanClause.Occur.MUST);\n      realMLTQuery.add(createIdQuery(\"id\", id), BooleanClause.Occur.MUST_NOT);\n\n      return realMLTQuery.build();\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","bugFix":null,"bugIntro":["2100a5b744ecaec4d2b191a7da9083feb50a6f7f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7eaf6db9e40efc42a6f8bb385825483657f923f6","date":1457047624,"type":3,"author":"anshum","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","sourceNew":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    if(doc == null) {\n      throw new SolrException(\n          SolrException.ErrorCode.BAD_REQUEST, \"Error completing MLT request. Could not fetch \" +\n          \"document with id [\" + id + \"]\");\n    }\n    \n    String[] qf = localParams.getParams(\"qf\");\n    Map<String,Float> boostFields = new HashMap<>();\n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n    \n    if(localParams.getInt(\"mintf\") != null)\n      mlt.setMinTermFreq(localParams.getInt(\"mintf\"));\n\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n\n    if(localParams.get(\"minwl\") != null)\n      mlt.setMinWordLen(localParams.getInt(\"minwl\"));\n\n    if(localParams.get(\"maxwl\") != null)\n      mlt.setMaxWordLen(localParams.getInt(\"maxwl\"));\n\n    if(localParams.get(\"maxqt\") != null)\n      mlt.setMaxQueryTerms(localParams.getInt(\"maxqt\"));\n\n    if(localParams.get(\"maxntp\") != null)\n      mlt.setMaxNumTokensParsed(localParams.getInt(\"maxntp\"));\n    \n    if(localParams.get(\"maxdf\") != null) {\n      mlt.setMaxDocFreq(localParams.getInt(\"maxdf\"));\n    }\n\n    if(localParams.get(\"boost\") != null) {\n      mlt.setBoost(localParams.getBool(\"boost\"));\n      boostFields = SolrPluginUtils.parseFieldBoosts(qf);\n    }\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    Map<String, Collection<Object>> filteredDocument = new HashMap<>();\n    ArrayList<String> fieldNames = new ArrayList<>();\n\n    if (qf != null) {\n      for (String fieldName : qf) {\n        if (!StringUtils.isEmpty(fieldName))  {\n          String[] strings = splitList.split(fieldName);\n          for (String string : strings) {\n            if (!StringUtils.isEmpty(string)) {\n              fieldNames.add(string);\n            }\n          }\n        }\n      }\n    } else {\n      Map<String, SchemaField> fields = req.getSchema().getFields();\n      for (String field : doc.getFieldNames()) {\n        // Only use fields that are stored and have an explicit analyzer.\n        // This makes sense as the query uses tf/idf/.. for query construction.\n        // We might want to relook and change this in the future though.\n        if(fields.get(field).stored() \n            && fields.get(field).getType().isExplicitAnalyzer()) {\n          fieldNames.add(field);\n        }\n      }\n    }\n\n    if( fieldNames.size() < 1 ) {\n      throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\n          \"MoreLikeThis requires at least one similarity field: qf\" );\n    }\n\n    mlt.setFieldNames(fieldNames.toArray(new String[fieldNames.size()]));\n    for (String field : fieldNames) {\n      filteredDocument.put(field, doc.getFieldValues(field));\n    }\n\n    try {\n      Query rawMLTQuery = mlt.like(filteredDocument);\n      BooleanQuery boostedMLTQuery = (BooleanQuery) rawMLTQuery;\n\n      if (boostFields.size() > 0) {\n        BooleanQuery.Builder newQ = new BooleanQuery.Builder();\n        newQ.setDisableCoord(boostedMLTQuery.isCoordDisabled());\n        newQ.setMinimumNumberShouldMatch(boostedMLTQuery.getMinimumNumberShouldMatch());\n\n        for (BooleanClause clause : boostedMLTQuery) {\n          Query q = clause.getQuery();\n          float originalBoost = 1f;\n          if (q instanceof BoostQuery) {\n            BoostQuery bq = (BoostQuery) q;\n            q = bq.getQuery();\n            originalBoost = bq.getBoost();\n          }\n          Float fieldBoost = boostFields.get(((TermQuery) q).getTerm().field());\n          q = ((fieldBoost != null) ? new BoostQuery(q, fieldBoost * originalBoost) : clause.getQuery());\n          newQ.add(q, clause.getOccur());\n        }\n\n        boostedMLTQuery = newQ.build();\n      }\n\n      // exclude current document from results\n      BooleanQuery.Builder realMLTQuery = new BooleanQuery.Builder();\n      realMLTQuery.setDisableCoord(true);\n      realMLTQuery.add(boostedMLTQuery, BooleanClause.Occur.MUST);\n      realMLTQuery.add(createIdQuery(req.getSchema().getUniqueKeyField().getName(), id), BooleanClause.Occur.MUST_NOT);\n\n      return realMLTQuery.build();\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","sourceOld":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    if(doc == null) {\n      throw new SolrException(\n          SolrException.ErrorCode.BAD_REQUEST, \"Error completing MLT request. Could not fetch \" +\n          \"document with id [\" + id + \"]\");\n    }\n    \n    String[] qf = localParams.getParams(\"qf\");\n    Map<String,Float> boostFields = new HashMap<>();\n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n    \n    if(localParams.getInt(\"mintf\") != null)\n      mlt.setMinTermFreq(localParams.getInt(\"mintf\"));\n\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n\n    if(localParams.get(\"minwl\") != null)\n      mlt.setMinWordLen(localParams.getInt(\"minwl\"));\n\n    if(localParams.get(\"maxwl\") != null)\n      mlt.setMaxWordLen(localParams.getInt(\"maxwl\"));\n\n    if(localParams.get(\"maxqt\") != null)\n      mlt.setMaxQueryTerms(localParams.getInt(\"maxqt\"));\n\n    if(localParams.get(\"maxntp\") != null)\n      mlt.setMaxNumTokensParsed(localParams.getInt(\"maxntp\"));\n    \n    if(localParams.get(\"maxdf\") != null) {\n      mlt.setMaxDocFreq(localParams.getInt(\"maxdf\"));\n    }\n\n    if(localParams.get(\"boost\") != null) {\n      mlt.setBoost(localParams.getBool(\"boost\"));\n      boostFields = SolrPluginUtils.parseFieldBoosts(qf);\n    }\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    Map<String, Collection<Object>> filteredDocument = new HashMap<>();\n    ArrayList<String> fieldNames = new ArrayList<>();\n\n    if (qf != null) {\n      for (String fieldName : qf) {\n        if (!StringUtils.isEmpty(fieldName))  {\n          String[] strings = splitList.split(fieldName);\n          for (String string : strings) {\n            if (!StringUtils.isEmpty(string)) {\n              fieldNames.add(string);\n            }\n          }\n        }\n      }\n    } else {\n      Map<String, SchemaField> fields = req.getSchema().getFields();\n      for (String field : doc.getFieldNames()) {\n        // Only use fields that are stored and have an explicit analyzer.\n        // This makes sense as the query uses tf/idf/.. for query construction.\n        // We might want to relook and change this in the future though.\n        if(fields.get(field).stored() \n            && fields.get(field).getType().isExplicitAnalyzer()) {\n          fieldNames.add(field);\n        }\n      }\n    }\n\n    if( fieldNames.size() < 1 ) {\n      throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\n          \"MoreLikeThis requires at least one similarity field: qf\" );\n    }\n\n    mlt.setFieldNames(fieldNames.toArray(new String[fieldNames.size()]));\n    for (String field : fieldNames) {\n      filteredDocument.put(field, doc.getFieldValues(field));\n    }\n\n    try {\n      Query rawMLTQuery = mlt.like(filteredDocument);\n      BooleanQuery boostedMLTQuery = (BooleanQuery) rawMLTQuery;\n\n      if (boostFields.size() > 0) {\n        BooleanQuery.Builder newQ = new BooleanQuery.Builder();\n        newQ.setDisableCoord(boostedMLTQuery.isCoordDisabled());\n        newQ.setMinimumNumberShouldMatch(boostedMLTQuery.getMinimumNumberShouldMatch());\n\n        for (BooleanClause clause : boostedMLTQuery) {\n          Query q = clause.getQuery();\n          float originalBoost = 1f;\n          if (q instanceof BoostQuery) {\n            BoostQuery bq = (BoostQuery) q;\n            q = bq.getQuery();\n            originalBoost = bq.getBoost();\n          }\n          Float fieldBoost = boostFields.get(((TermQuery) q).getTerm().field());\n          q = ((fieldBoost != null) ? new BoostQuery(q, fieldBoost * originalBoost) : clause.getQuery());\n          newQ.add(q, clause.getOccur());\n        }\n\n        boostedMLTQuery = newQ.build();\n      }\n\n      // exclude current document from results\n      BooleanQuery.Builder realMLTQuery = new BooleanQuery.Builder();\n      realMLTQuery.setDisableCoord(true);\n      realMLTQuery.add(boostedMLTQuery, BooleanClause.Occur.MUST);\n      realMLTQuery.add(createIdQuery(\"id\", id), BooleanClause.Occur.MUST_NOT);\n\n      return realMLTQuery.build();\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"cf1a614098b46c9c22afebd7b898ae4d1d2fc273","date":1457088850,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","sourceNew":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    if(doc == null) {\n      throw new SolrException(\n          SolrException.ErrorCode.BAD_REQUEST, \"Error completing MLT request. Could not fetch \" +\n          \"document with id [\" + id + \"]\");\n    }\n    \n    String[] qf = localParams.getParams(\"qf\");\n    Map<String,Float> boostFields = new HashMap<>();\n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n    \n    if(localParams.getInt(\"mintf\") != null)\n      mlt.setMinTermFreq(localParams.getInt(\"mintf\"));\n\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n\n    if(localParams.get(\"minwl\") != null)\n      mlt.setMinWordLen(localParams.getInt(\"minwl\"));\n\n    if(localParams.get(\"maxwl\") != null)\n      mlt.setMaxWordLen(localParams.getInt(\"maxwl\"));\n\n    if(localParams.get(\"maxqt\") != null)\n      mlt.setMaxQueryTerms(localParams.getInt(\"maxqt\"));\n\n    if(localParams.get(\"maxntp\") != null)\n      mlt.setMaxNumTokensParsed(localParams.getInt(\"maxntp\"));\n    \n    if(localParams.get(\"maxdf\") != null) {\n      mlt.setMaxDocFreq(localParams.getInt(\"maxdf\"));\n    }\n\n    if(localParams.get(\"boost\") != null) {\n      mlt.setBoost(localParams.getBool(\"boost\"));\n      boostFields = SolrPluginUtils.parseFieldBoosts(qf);\n    }\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    Map<String, Collection<Object>> filteredDocument = new HashMap<>();\n    ArrayList<String> fieldNames = new ArrayList<>();\n\n    if (qf != null) {\n      for (String fieldName : qf) {\n        if (!StringUtils.isEmpty(fieldName))  {\n          String[] strings = splitList.split(fieldName);\n          for (String string : strings) {\n            if (!StringUtils.isEmpty(string)) {\n              fieldNames.add(string);\n            }\n          }\n        }\n      }\n    } else {\n      Map<String, SchemaField> fields = req.getSchema().getFields();\n      for (String field : doc.getFieldNames()) {\n        // Only use fields that are stored and have an explicit analyzer.\n        // This makes sense as the query uses tf/idf/.. for query construction.\n        // We might want to relook and change this in the future though.\n        if(fields.get(field).stored() \n            && fields.get(field).getType().isExplicitAnalyzer()) {\n          fieldNames.add(field);\n        }\n      }\n    }\n\n    if( fieldNames.size() < 1 ) {\n      throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\n          \"MoreLikeThis requires at least one similarity field: qf\" );\n    }\n\n    mlt.setFieldNames(fieldNames.toArray(new String[fieldNames.size()]));\n    for (String field : fieldNames) {\n      filteredDocument.put(field, doc.getFieldValues(field));\n    }\n\n    try {\n      Query rawMLTQuery = mlt.like(filteredDocument);\n      BooleanQuery boostedMLTQuery = (BooleanQuery) rawMLTQuery;\n\n      if (boostFields.size() > 0) {\n        BooleanQuery.Builder newQ = new BooleanQuery.Builder();\n        newQ.setDisableCoord(boostedMLTQuery.isCoordDisabled());\n        newQ.setMinimumNumberShouldMatch(boostedMLTQuery.getMinimumNumberShouldMatch());\n\n        for (BooleanClause clause : boostedMLTQuery) {\n          Query q = clause.getQuery();\n          float originalBoost = 1f;\n          if (q instanceof BoostQuery) {\n            BoostQuery bq = (BoostQuery) q;\n            q = bq.getQuery();\n            originalBoost = bq.getBoost();\n          }\n          Float fieldBoost = boostFields.get(((TermQuery) q).getTerm().field());\n          q = ((fieldBoost != null) ? new BoostQuery(q, fieldBoost * originalBoost) : clause.getQuery());\n          newQ.add(q, clause.getOccur());\n        }\n\n        boostedMLTQuery = newQ.build();\n      }\n\n      // exclude current document from results\n      BooleanQuery.Builder realMLTQuery = new BooleanQuery.Builder();\n      realMLTQuery.setDisableCoord(true);\n      realMLTQuery.add(boostedMLTQuery, BooleanClause.Occur.MUST);\n      realMLTQuery.add(createIdQuery(req.getSchema().getUniqueKeyField().getName(), id), BooleanClause.Occur.MUST_NOT);\n\n      return realMLTQuery.build();\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","sourceOld":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    if(doc == null) {\n      throw new SolrException(\n          SolrException.ErrorCode.BAD_REQUEST, \"Error completing MLT request. Could not fetch \" +\n          \"document with id [\" + id + \"]\");\n    }\n    \n    String[] qf = localParams.getParams(\"qf\");\n    Map<String,Float> boostFields = new HashMap<>();\n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n    \n    if(localParams.getInt(\"mintf\") != null)\n      mlt.setMinTermFreq(localParams.getInt(\"mintf\"));\n\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n\n    if(localParams.get(\"minwl\") != null)\n      mlt.setMinWordLen(localParams.getInt(\"minwl\"));\n\n    if(localParams.get(\"maxwl\") != null)\n      mlt.setMaxWordLen(localParams.getInt(\"maxwl\"));\n\n    if(localParams.get(\"maxqt\") != null)\n      mlt.setMaxQueryTerms(localParams.getInt(\"maxqt\"));\n\n    if(localParams.get(\"maxntp\") != null)\n      mlt.setMaxNumTokensParsed(localParams.getInt(\"maxntp\"));\n    \n    if(localParams.get(\"maxdf\") != null) {\n      mlt.setMaxDocFreq(localParams.getInt(\"maxdf\"));\n    }\n\n    if(localParams.get(\"boost\") != null) {\n      mlt.setBoost(localParams.getBool(\"boost\"));\n      boostFields = SolrPluginUtils.parseFieldBoosts(qf);\n    }\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    Map<String, Collection<Object>> filteredDocument = new HashMap<>();\n    ArrayList<String> fieldNames = new ArrayList<>();\n\n    if (qf != null) {\n      for (String fieldName : qf) {\n        if (!StringUtils.isEmpty(fieldName))  {\n          String[] strings = splitList.split(fieldName);\n          for (String string : strings) {\n            if (!StringUtils.isEmpty(string)) {\n              fieldNames.add(string);\n            }\n          }\n        }\n      }\n    } else {\n      Map<String, SchemaField> fields = req.getSchema().getFields();\n      for (String field : doc.getFieldNames()) {\n        // Only use fields that are stored and have an explicit analyzer.\n        // This makes sense as the query uses tf/idf/.. for query construction.\n        // We might want to relook and change this in the future though.\n        if(fields.get(field).stored() \n            && fields.get(field).getType().isExplicitAnalyzer()) {\n          fieldNames.add(field);\n        }\n      }\n    }\n\n    if( fieldNames.size() < 1 ) {\n      throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\n          \"MoreLikeThis requires at least one similarity field: qf\" );\n    }\n\n    mlt.setFieldNames(fieldNames.toArray(new String[fieldNames.size()]));\n    for (String field : fieldNames) {\n      filteredDocument.put(field, doc.getFieldValues(field));\n    }\n\n    try {\n      Query rawMLTQuery = mlt.like(filteredDocument);\n      BooleanQuery boostedMLTQuery = (BooleanQuery) rawMLTQuery;\n\n      if (boostFields.size() > 0) {\n        BooleanQuery.Builder newQ = new BooleanQuery.Builder();\n        newQ.setDisableCoord(boostedMLTQuery.isCoordDisabled());\n        newQ.setMinimumNumberShouldMatch(boostedMLTQuery.getMinimumNumberShouldMatch());\n\n        for (BooleanClause clause : boostedMLTQuery) {\n          Query q = clause.getQuery();\n          float originalBoost = 1f;\n          if (q instanceof BoostQuery) {\n            BoostQuery bq = (BoostQuery) q;\n            q = bq.getQuery();\n            originalBoost = bq.getBoost();\n          }\n          Float fieldBoost = boostFields.get(((TermQuery) q).getTerm().field());\n          q = ((fieldBoost != null) ? new BoostQuery(q, fieldBoost * originalBoost) : clause.getQuery());\n          newQ.add(q, clause.getOccur());\n        }\n\n        boostedMLTQuery = newQ.build();\n      }\n\n      // exclude current document from results\n      BooleanQuery.Builder realMLTQuery = new BooleanQuery.Builder();\n      realMLTQuery.setDisableCoord(true);\n      realMLTQuery.add(boostedMLTQuery, BooleanClause.Occur.MUST);\n      realMLTQuery.add(createIdQuery(\"id\", id), BooleanClause.Occur.MUST_NOT);\n\n      return realMLTQuery.build();\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5ebf70dabe6279454c5ff460bdea3f0dc2814a86","date":1463672611,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","sourceNew":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    if(doc == null) {\n      throw new SolrException(\n          SolrException.ErrorCode.BAD_REQUEST, \"Error completing MLT request. Could not fetch \" +\n          \"document with id [\" + id + \"]\");\n    }\n    \n    String[] qf = localParams.getParams(\"qf\");\n    Map<String,Float> boostFields = new HashMap<>();\n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n    \n    if(localParams.getInt(\"mintf\") != null)\n      mlt.setMinTermFreq(localParams.getInt(\"mintf\"));\n\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n\n    if(localParams.get(\"minwl\") != null)\n      mlt.setMinWordLen(localParams.getInt(\"minwl\"));\n\n    if(localParams.get(\"maxwl\") != null)\n      mlt.setMaxWordLen(localParams.getInt(\"maxwl\"));\n\n    if(localParams.get(\"maxqt\") != null)\n      mlt.setMaxQueryTerms(localParams.getInt(\"maxqt\"));\n\n    if(localParams.get(\"maxntp\") != null)\n      mlt.setMaxNumTokensParsed(localParams.getInt(\"maxntp\"));\n    \n    if(localParams.get(\"maxdf\") != null) {\n      mlt.setMaxDocFreq(localParams.getInt(\"maxdf\"));\n    }\n\n    if(localParams.get(\"boost\") != null) {\n      mlt.setBoost(localParams.getBool(\"boost\"));\n      boostFields = SolrPluginUtils.parseFieldBoosts(qf);\n    }\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    Map<String, Collection<Object>> filteredDocument = new HashMap<>();\n    ArrayList<String> fieldNames = new ArrayList<>();\n\n    if (qf != null) {\n      for (String fieldName : qf) {\n        if (!StringUtils.isEmpty(fieldName))  {\n          String[] strings = splitList.split(fieldName);\n          for (String string : strings) {\n            if (!StringUtils.isEmpty(string)) {\n              fieldNames.add(string);\n            }\n          }\n        }\n      }\n    } else {\n      for (String field : doc.getFieldNames()) {\n        // Only use fields that are stored and have an explicit analyzer.\n        // This makes sense as the query uses tf/idf/.. for query construction.\n        // We might want to relook and change this in the future though.\n        SchemaField f = req.getSchema().getFieldOrNull(field);\n        if (f != null && f.stored() && f.getType().isExplicitAnalyzer()) {\n          fieldNames.add(field);\n        }\n      }\n    }\n\n    if( fieldNames.size() < 1 ) {\n      throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\n          \"MoreLikeThis requires at least one similarity field: qf\" );\n    }\n\n    mlt.setFieldNames(fieldNames.toArray(new String[fieldNames.size()]));\n    for (String field : fieldNames) {\n      filteredDocument.put(field, doc.getFieldValues(field));\n    }\n\n    try {\n      Query rawMLTQuery = mlt.like(filteredDocument);\n      BooleanQuery boostedMLTQuery = (BooleanQuery) rawMLTQuery;\n\n      if (boostFields.size() > 0) {\n        BooleanQuery.Builder newQ = new BooleanQuery.Builder();\n        newQ.setDisableCoord(boostedMLTQuery.isCoordDisabled());\n        newQ.setMinimumNumberShouldMatch(boostedMLTQuery.getMinimumNumberShouldMatch());\n\n        for (BooleanClause clause : boostedMLTQuery) {\n          Query q = clause.getQuery();\n          float originalBoost = 1f;\n          if (q instanceof BoostQuery) {\n            BoostQuery bq = (BoostQuery) q;\n            q = bq.getQuery();\n            originalBoost = bq.getBoost();\n          }\n          Float fieldBoost = boostFields.get(((TermQuery) q).getTerm().field());\n          q = ((fieldBoost != null) ? new BoostQuery(q, fieldBoost * originalBoost) : clause.getQuery());\n          newQ.add(q, clause.getOccur());\n        }\n\n        boostedMLTQuery = newQ.build();\n      }\n\n      // exclude current document from results\n      BooleanQuery.Builder realMLTQuery = new BooleanQuery.Builder();\n      realMLTQuery.setDisableCoord(true);\n      realMLTQuery.add(boostedMLTQuery, BooleanClause.Occur.MUST);\n      realMLTQuery.add(createIdQuery(req.getSchema().getUniqueKeyField().getName(), id), BooleanClause.Occur.MUST_NOT);\n\n      return realMLTQuery.build();\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","sourceOld":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    if(doc == null) {\n      throw new SolrException(\n          SolrException.ErrorCode.BAD_REQUEST, \"Error completing MLT request. Could not fetch \" +\n          \"document with id [\" + id + \"]\");\n    }\n    \n    String[] qf = localParams.getParams(\"qf\");\n    Map<String,Float> boostFields = new HashMap<>();\n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n    \n    if(localParams.getInt(\"mintf\") != null)\n      mlt.setMinTermFreq(localParams.getInt(\"mintf\"));\n\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n\n    if(localParams.get(\"minwl\") != null)\n      mlt.setMinWordLen(localParams.getInt(\"minwl\"));\n\n    if(localParams.get(\"maxwl\") != null)\n      mlt.setMaxWordLen(localParams.getInt(\"maxwl\"));\n\n    if(localParams.get(\"maxqt\") != null)\n      mlt.setMaxQueryTerms(localParams.getInt(\"maxqt\"));\n\n    if(localParams.get(\"maxntp\") != null)\n      mlt.setMaxNumTokensParsed(localParams.getInt(\"maxntp\"));\n    \n    if(localParams.get(\"maxdf\") != null) {\n      mlt.setMaxDocFreq(localParams.getInt(\"maxdf\"));\n    }\n\n    if(localParams.get(\"boost\") != null) {\n      mlt.setBoost(localParams.getBool(\"boost\"));\n      boostFields = SolrPluginUtils.parseFieldBoosts(qf);\n    }\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    Map<String, Collection<Object>> filteredDocument = new HashMap<>();\n    ArrayList<String> fieldNames = new ArrayList<>();\n\n    if (qf != null) {\n      for (String fieldName : qf) {\n        if (!StringUtils.isEmpty(fieldName))  {\n          String[] strings = splitList.split(fieldName);\n          for (String string : strings) {\n            if (!StringUtils.isEmpty(string)) {\n              fieldNames.add(string);\n            }\n          }\n        }\n      }\n    } else {\n      Map<String, SchemaField> fields = req.getSchema().getFields();\n      for (String field : doc.getFieldNames()) {\n        // Only use fields that are stored and have an explicit analyzer.\n        // This makes sense as the query uses tf/idf/.. for query construction.\n        // We might want to relook and change this in the future though.\n        if(fields.get(field).stored() \n            && fields.get(field).getType().isExplicitAnalyzer()) {\n          fieldNames.add(field);\n        }\n      }\n    }\n\n    if( fieldNames.size() < 1 ) {\n      throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\n          \"MoreLikeThis requires at least one similarity field: qf\" );\n    }\n\n    mlt.setFieldNames(fieldNames.toArray(new String[fieldNames.size()]));\n    for (String field : fieldNames) {\n      filteredDocument.put(field, doc.getFieldValues(field));\n    }\n\n    try {\n      Query rawMLTQuery = mlt.like(filteredDocument);\n      BooleanQuery boostedMLTQuery = (BooleanQuery) rawMLTQuery;\n\n      if (boostFields.size() > 0) {\n        BooleanQuery.Builder newQ = new BooleanQuery.Builder();\n        newQ.setDisableCoord(boostedMLTQuery.isCoordDisabled());\n        newQ.setMinimumNumberShouldMatch(boostedMLTQuery.getMinimumNumberShouldMatch());\n\n        for (BooleanClause clause : boostedMLTQuery) {\n          Query q = clause.getQuery();\n          float originalBoost = 1f;\n          if (q instanceof BoostQuery) {\n            BoostQuery bq = (BoostQuery) q;\n            q = bq.getQuery();\n            originalBoost = bq.getBoost();\n          }\n          Float fieldBoost = boostFields.get(((TermQuery) q).getTerm().field());\n          q = ((fieldBoost != null) ? new BoostQuery(q, fieldBoost * originalBoost) : clause.getQuery());\n          newQ.add(q, clause.getOccur());\n        }\n\n        boostedMLTQuery = newQ.build();\n      }\n\n      // exclude current document from results\n      BooleanQuery.Builder realMLTQuery = new BooleanQuery.Builder();\n      realMLTQuery.setDisableCoord(true);\n      realMLTQuery.add(boostedMLTQuery, BooleanClause.Occur.MUST);\n      realMLTQuery.add(createIdQuery(req.getSchema().getUniqueKeyField().getName(), id), BooleanClause.Occur.MUST_NOT);\n\n      return realMLTQuery.build();\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d470c8182e92b264680e34081b75e70a9f2b3c89","date":1463985353,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","sourceNew":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    if(doc == null) {\n      throw new SolrException(\n          SolrException.ErrorCode.BAD_REQUEST, \"Error completing MLT request. Could not fetch \" +\n          \"document with id [\" + id + \"]\");\n    }\n    \n    String[] qf = localParams.getParams(\"qf\");\n    Map<String,Float> boostFields = new HashMap<>();\n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n    \n    if(localParams.getInt(\"mintf\") != null)\n      mlt.setMinTermFreq(localParams.getInt(\"mintf\"));\n\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n\n    if(localParams.get(\"minwl\") != null)\n      mlt.setMinWordLen(localParams.getInt(\"minwl\"));\n\n    if(localParams.get(\"maxwl\") != null)\n      mlt.setMaxWordLen(localParams.getInt(\"maxwl\"));\n\n    if(localParams.get(\"maxqt\") != null)\n      mlt.setMaxQueryTerms(localParams.getInt(\"maxqt\"));\n\n    if(localParams.get(\"maxntp\") != null)\n      mlt.setMaxNumTokensParsed(localParams.getInt(\"maxntp\"));\n    \n    if(localParams.get(\"maxdf\") != null) {\n      mlt.setMaxDocFreq(localParams.getInt(\"maxdf\"));\n    }\n\n    if(localParams.get(\"boost\") != null) {\n      mlt.setBoost(localParams.getBool(\"boost\"));\n      boostFields = SolrPluginUtils.parseFieldBoosts(qf);\n    }\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    Map<String, Collection<Object>> filteredDocument = new HashMap<>();\n    ArrayList<String> fieldNames = new ArrayList<>();\n\n    if (qf != null) {\n      for (String fieldName : qf) {\n        if (!StringUtils.isEmpty(fieldName))  {\n          String[] strings = splitList.split(fieldName);\n          for (String string : strings) {\n            if (!StringUtils.isEmpty(string)) {\n              fieldNames.add(string);\n            }\n          }\n        }\n      }\n    } else {\n      for (String field : doc.getFieldNames()) {\n        // Only use fields that are stored and have an explicit analyzer.\n        // This makes sense as the query uses tf/idf/.. for query construction.\n        // We might want to relook and change this in the future though.\n        SchemaField f = req.getSchema().getFieldOrNull(field);\n        if (f != null && f.stored() && f.getType().isExplicitAnalyzer()) {\n          fieldNames.add(field);\n        }\n      }\n    }\n\n    if( fieldNames.size() < 1 ) {\n      throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\n          \"MoreLikeThis requires at least one similarity field: qf\" );\n    }\n\n    mlt.setFieldNames(fieldNames.toArray(new String[fieldNames.size()]));\n    for (String field : fieldNames) {\n      filteredDocument.put(field, doc.getFieldValues(field));\n    }\n\n    try {\n      Query rawMLTQuery = mlt.like(filteredDocument);\n      BooleanQuery boostedMLTQuery = (BooleanQuery) rawMLTQuery;\n\n      if (boostFields.size() > 0) {\n        BooleanQuery.Builder newQ = new BooleanQuery.Builder();\n        newQ.setDisableCoord(boostedMLTQuery.isCoordDisabled());\n        newQ.setMinimumNumberShouldMatch(boostedMLTQuery.getMinimumNumberShouldMatch());\n\n        for (BooleanClause clause : boostedMLTQuery) {\n          Query q = clause.getQuery();\n          float originalBoost = 1f;\n          if (q instanceof BoostQuery) {\n            BoostQuery bq = (BoostQuery) q;\n            q = bq.getQuery();\n            originalBoost = bq.getBoost();\n          }\n          Float fieldBoost = boostFields.get(((TermQuery) q).getTerm().field());\n          q = ((fieldBoost != null) ? new BoostQuery(q, fieldBoost * originalBoost) : clause.getQuery());\n          newQ.add(q, clause.getOccur());\n        }\n\n        boostedMLTQuery = newQ.build();\n      }\n\n      // exclude current document from results\n      BooleanQuery.Builder realMLTQuery = new BooleanQuery.Builder();\n      realMLTQuery.setDisableCoord(true);\n      realMLTQuery.add(boostedMLTQuery, BooleanClause.Occur.MUST);\n      realMLTQuery.add(createIdQuery(req.getSchema().getUniqueKeyField().getName(), id), BooleanClause.Occur.MUST_NOT);\n\n      return realMLTQuery.build();\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","sourceOld":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    if(doc == null) {\n      throw new SolrException(\n          SolrException.ErrorCode.BAD_REQUEST, \"Error completing MLT request. Could not fetch \" +\n          \"document with id [\" + id + \"]\");\n    }\n    \n    String[] qf = localParams.getParams(\"qf\");\n    Map<String,Float> boostFields = new HashMap<>();\n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n    \n    if(localParams.getInt(\"mintf\") != null)\n      mlt.setMinTermFreq(localParams.getInt(\"mintf\"));\n\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n\n    if(localParams.get(\"minwl\") != null)\n      mlt.setMinWordLen(localParams.getInt(\"minwl\"));\n\n    if(localParams.get(\"maxwl\") != null)\n      mlt.setMaxWordLen(localParams.getInt(\"maxwl\"));\n\n    if(localParams.get(\"maxqt\") != null)\n      mlt.setMaxQueryTerms(localParams.getInt(\"maxqt\"));\n\n    if(localParams.get(\"maxntp\") != null)\n      mlt.setMaxNumTokensParsed(localParams.getInt(\"maxntp\"));\n    \n    if(localParams.get(\"maxdf\") != null) {\n      mlt.setMaxDocFreq(localParams.getInt(\"maxdf\"));\n    }\n\n    if(localParams.get(\"boost\") != null) {\n      mlt.setBoost(localParams.getBool(\"boost\"));\n      boostFields = SolrPluginUtils.parseFieldBoosts(qf);\n    }\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    Map<String, Collection<Object>> filteredDocument = new HashMap<>();\n    ArrayList<String> fieldNames = new ArrayList<>();\n\n    if (qf != null) {\n      for (String fieldName : qf) {\n        if (!StringUtils.isEmpty(fieldName))  {\n          String[] strings = splitList.split(fieldName);\n          for (String string : strings) {\n            if (!StringUtils.isEmpty(string)) {\n              fieldNames.add(string);\n            }\n          }\n        }\n      }\n    } else {\n      Map<String, SchemaField> fields = req.getSchema().getFields();\n      for (String field : doc.getFieldNames()) {\n        // Only use fields that are stored and have an explicit analyzer.\n        // This makes sense as the query uses tf/idf/.. for query construction.\n        // We might want to relook and change this in the future though.\n        if(fields.get(field).stored() \n            && fields.get(field).getType().isExplicitAnalyzer()) {\n          fieldNames.add(field);\n        }\n      }\n    }\n\n    if( fieldNames.size() < 1 ) {\n      throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\n          \"MoreLikeThis requires at least one similarity field: qf\" );\n    }\n\n    mlt.setFieldNames(fieldNames.toArray(new String[fieldNames.size()]));\n    for (String field : fieldNames) {\n      filteredDocument.put(field, doc.getFieldValues(field));\n    }\n\n    try {\n      Query rawMLTQuery = mlt.like(filteredDocument);\n      BooleanQuery boostedMLTQuery = (BooleanQuery) rawMLTQuery;\n\n      if (boostFields.size() > 0) {\n        BooleanQuery.Builder newQ = new BooleanQuery.Builder();\n        newQ.setDisableCoord(boostedMLTQuery.isCoordDisabled());\n        newQ.setMinimumNumberShouldMatch(boostedMLTQuery.getMinimumNumberShouldMatch());\n\n        for (BooleanClause clause : boostedMLTQuery) {\n          Query q = clause.getQuery();\n          float originalBoost = 1f;\n          if (q instanceof BoostQuery) {\n            BoostQuery bq = (BoostQuery) q;\n            q = bq.getQuery();\n            originalBoost = bq.getBoost();\n          }\n          Float fieldBoost = boostFields.get(((TermQuery) q).getTerm().field());\n          q = ((fieldBoost != null) ? new BoostQuery(q, fieldBoost * originalBoost) : clause.getQuery());\n          newQ.add(q, clause.getOccur());\n        }\n\n        boostedMLTQuery = newQ.build();\n      }\n\n      // exclude current document from results\n      BooleanQuery.Builder realMLTQuery = new BooleanQuery.Builder();\n      realMLTQuery.setDisableCoord(true);\n      realMLTQuery.add(boostedMLTQuery, BooleanClause.Occur.MUST);\n      realMLTQuery.add(createIdQuery(req.getSchema().getUniqueKeyField().getName(), id), BooleanClause.Occur.MUST_NOT);\n\n      return realMLTQuery.build();\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c8a0e442f7b61f811680273b25da95994a724466","date":1467878549,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","sourceNew":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    if(doc == null) {\n      throw new SolrException(\n          SolrException.ErrorCode.BAD_REQUEST, \"Error completing MLT request. Could not fetch \" +\n          \"document with id [\" + id + \"]\");\n    }\n    \n    String[] qf = localParams.getParams(\"qf\");\n    Map<String,Float> boostFields = new HashMap<>();\n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n    \n    if(localParams.getInt(\"mintf\") != null)\n      mlt.setMinTermFreq(localParams.getInt(\"mintf\"));\n\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n\n    if(localParams.get(\"minwl\") != null)\n      mlt.setMinWordLen(localParams.getInt(\"minwl\"));\n\n    if(localParams.get(\"maxwl\") != null)\n      mlt.setMaxWordLen(localParams.getInt(\"maxwl\"));\n\n    if(localParams.get(\"maxqt\") != null)\n      mlt.setMaxQueryTerms(localParams.getInt(\"maxqt\"));\n\n    if(localParams.get(\"maxntp\") != null)\n      mlt.setMaxNumTokensParsed(localParams.getInt(\"maxntp\"));\n    \n    if(localParams.get(\"maxdf\") != null) {\n      mlt.setMaxDocFreq(localParams.getInt(\"maxdf\"));\n    }\n\n    if(localParams.get(\"boost\") != null) {\n      mlt.setBoost(localParams.getBool(\"boost\"));\n      boostFields = SolrPluginUtils.parseFieldBoosts(qf);\n    }\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    Map<String, Collection<Object>> filteredDocument = new HashMap<>();\n    ArrayList<String> fieldNames = new ArrayList<>();\n\n    if (qf != null) {\n      for (String fieldName : qf) {\n        if (!StringUtils.isEmpty(fieldName))  {\n          String[] strings = splitList.split(fieldName);\n          for (String string : strings) {\n            if (!StringUtils.isEmpty(string)) {\n              fieldNames.add(string);\n            }\n          }\n        }\n      }\n    } else {\n      for (String field : doc.getFieldNames()) {\n        // Only use fields that are stored and have an explicit analyzer.\n        // This makes sense as the query uses tf/idf/.. for query construction.\n        // We might want to relook and change this in the future though.\n        SchemaField f = req.getSchema().getFieldOrNull(field);\n        if (f != null && f.stored() && f.getType().isExplicitAnalyzer()) {\n          fieldNames.add(field);\n        }\n      }\n    }\n\n    if( fieldNames.size() < 1 ) {\n      throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\n          \"MoreLikeThis requires at least one similarity field: qf\" );\n    }\n\n    mlt.setFieldNames(fieldNames.toArray(new String[fieldNames.size()]));\n    for (String field : fieldNames) {\n      filteredDocument.put(field, doc.getFieldValues(field));\n    }\n\n    try {\n      Query rawMLTQuery = mlt.like(filteredDocument);\n      BooleanQuery boostedMLTQuery = (BooleanQuery) rawMLTQuery;\n\n      if (boostFields.size() > 0) {\n        BooleanQuery.Builder newQ = new BooleanQuery.Builder();\n        newQ.setMinimumNumberShouldMatch(boostedMLTQuery.getMinimumNumberShouldMatch());\n\n        for (BooleanClause clause : boostedMLTQuery) {\n          Query q = clause.getQuery();\n          float originalBoost = 1f;\n          if (q instanceof BoostQuery) {\n            BoostQuery bq = (BoostQuery) q;\n            q = bq.getQuery();\n            originalBoost = bq.getBoost();\n          }\n          Float fieldBoost = boostFields.get(((TermQuery) q).getTerm().field());\n          q = ((fieldBoost != null) ? new BoostQuery(q, fieldBoost * originalBoost) : clause.getQuery());\n          newQ.add(q, clause.getOccur());\n        }\n\n        boostedMLTQuery = newQ.build();\n      }\n\n      // exclude current document from results\n      BooleanQuery.Builder realMLTQuery = new BooleanQuery.Builder();\n      realMLTQuery.add(boostedMLTQuery, BooleanClause.Occur.MUST);\n      realMLTQuery.add(createIdQuery(req.getSchema().getUniqueKeyField().getName(), id), BooleanClause.Occur.MUST_NOT);\n\n      return realMLTQuery.build();\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","sourceOld":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    if(doc == null) {\n      throw new SolrException(\n          SolrException.ErrorCode.BAD_REQUEST, \"Error completing MLT request. Could not fetch \" +\n          \"document with id [\" + id + \"]\");\n    }\n    \n    String[] qf = localParams.getParams(\"qf\");\n    Map<String,Float> boostFields = new HashMap<>();\n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n    \n    if(localParams.getInt(\"mintf\") != null)\n      mlt.setMinTermFreq(localParams.getInt(\"mintf\"));\n\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n\n    if(localParams.get(\"minwl\") != null)\n      mlt.setMinWordLen(localParams.getInt(\"minwl\"));\n\n    if(localParams.get(\"maxwl\") != null)\n      mlt.setMaxWordLen(localParams.getInt(\"maxwl\"));\n\n    if(localParams.get(\"maxqt\") != null)\n      mlt.setMaxQueryTerms(localParams.getInt(\"maxqt\"));\n\n    if(localParams.get(\"maxntp\") != null)\n      mlt.setMaxNumTokensParsed(localParams.getInt(\"maxntp\"));\n    \n    if(localParams.get(\"maxdf\") != null) {\n      mlt.setMaxDocFreq(localParams.getInt(\"maxdf\"));\n    }\n\n    if(localParams.get(\"boost\") != null) {\n      mlt.setBoost(localParams.getBool(\"boost\"));\n      boostFields = SolrPluginUtils.parseFieldBoosts(qf);\n    }\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    Map<String, Collection<Object>> filteredDocument = new HashMap<>();\n    ArrayList<String> fieldNames = new ArrayList<>();\n\n    if (qf != null) {\n      for (String fieldName : qf) {\n        if (!StringUtils.isEmpty(fieldName))  {\n          String[] strings = splitList.split(fieldName);\n          for (String string : strings) {\n            if (!StringUtils.isEmpty(string)) {\n              fieldNames.add(string);\n            }\n          }\n        }\n      }\n    } else {\n      for (String field : doc.getFieldNames()) {\n        // Only use fields that are stored and have an explicit analyzer.\n        // This makes sense as the query uses tf/idf/.. for query construction.\n        // We might want to relook and change this in the future though.\n        SchemaField f = req.getSchema().getFieldOrNull(field);\n        if (f != null && f.stored() && f.getType().isExplicitAnalyzer()) {\n          fieldNames.add(field);\n        }\n      }\n    }\n\n    if( fieldNames.size() < 1 ) {\n      throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\n          \"MoreLikeThis requires at least one similarity field: qf\" );\n    }\n\n    mlt.setFieldNames(fieldNames.toArray(new String[fieldNames.size()]));\n    for (String field : fieldNames) {\n      filteredDocument.put(field, doc.getFieldValues(field));\n    }\n\n    try {\n      Query rawMLTQuery = mlt.like(filteredDocument);\n      BooleanQuery boostedMLTQuery = (BooleanQuery) rawMLTQuery;\n\n      if (boostFields.size() > 0) {\n        BooleanQuery.Builder newQ = new BooleanQuery.Builder();\n        newQ.setDisableCoord(boostedMLTQuery.isCoordDisabled());\n        newQ.setMinimumNumberShouldMatch(boostedMLTQuery.getMinimumNumberShouldMatch());\n\n        for (BooleanClause clause : boostedMLTQuery) {\n          Query q = clause.getQuery();\n          float originalBoost = 1f;\n          if (q instanceof BoostQuery) {\n            BoostQuery bq = (BoostQuery) q;\n            q = bq.getQuery();\n            originalBoost = bq.getBoost();\n          }\n          Float fieldBoost = boostFields.get(((TermQuery) q).getTerm().field());\n          q = ((fieldBoost != null) ? new BoostQuery(q, fieldBoost * originalBoost) : clause.getQuery());\n          newQ.add(q, clause.getOccur());\n        }\n\n        boostedMLTQuery = newQ.build();\n      }\n\n      // exclude current document from results\n      BooleanQuery.Builder realMLTQuery = new BooleanQuery.Builder();\n      realMLTQuery.setDisableCoord(true);\n      realMLTQuery.add(boostedMLTQuery, BooleanClause.Occur.MUST);\n      realMLTQuery.add(createIdQuery(req.getSchema().getUniqueKeyField().getName(), id), BooleanClause.Occur.MUST_NOT);\n\n      return realMLTQuery.build();\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","sourceNew":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    if(doc == null) {\n      throw new SolrException(\n          SolrException.ErrorCode.BAD_REQUEST, \"Error completing MLT request. Could not fetch \" +\n          \"document with id [\" + id + \"]\");\n    }\n    \n    String[] qf = localParams.getParams(\"qf\");\n    Map<String,Float> boostFields = new HashMap<>();\n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n    \n    if(localParams.getInt(\"mintf\") != null)\n      mlt.setMinTermFreq(localParams.getInt(\"mintf\"));\n\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n\n    if(localParams.get(\"minwl\") != null)\n      mlt.setMinWordLen(localParams.getInt(\"minwl\"));\n\n    if(localParams.get(\"maxwl\") != null)\n      mlt.setMaxWordLen(localParams.getInt(\"maxwl\"));\n\n    if(localParams.get(\"maxqt\") != null)\n      mlt.setMaxQueryTerms(localParams.getInt(\"maxqt\"));\n\n    if(localParams.get(\"maxntp\") != null)\n      mlt.setMaxNumTokensParsed(localParams.getInt(\"maxntp\"));\n    \n    if(localParams.get(\"maxdf\") != null) {\n      mlt.setMaxDocFreq(localParams.getInt(\"maxdf\"));\n    }\n\n    if(localParams.get(\"boost\") != null) {\n      mlt.setBoost(localParams.getBool(\"boost\"));\n      boostFields = SolrPluginUtils.parseFieldBoosts(qf);\n    }\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    Map<String, Collection<Object>> filteredDocument = new HashMap<>();\n    ArrayList<String> fieldNames = new ArrayList<>();\n\n    if (qf != null) {\n      for (String fieldName : qf) {\n        if (!StringUtils.isEmpty(fieldName))  {\n          String[] strings = splitList.split(fieldName);\n          for (String string : strings) {\n            if (!StringUtils.isEmpty(string)) {\n              fieldNames.add(string);\n            }\n          }\n        }\n      }\n    } else {\n      for (String field : doc.getFieldNames()) {\n        // Only use fields that are stored and have an explicit analyzer.\n        // This makes sense as the query uses tf/idf/.. for query construction.\n        // We might want to relook and change this in the future though.\n        SchemaField f = req.getSchema().getFieldOrNull(field);\n        if (f != null && f.stored() && f.getType().isExplicitAnalyzer()) {\n          fieldNames.add(field);\n        }\n      }\n    }\n\n    if( fieldNames.size() < 1 ) {\n      throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\n          \"MoreLikeThis requires at least one similarity field: qf\" );\n    }\n\n    mlt.setFieldNames(fieldNames.toArray(new String[fieldNames.size()]));\n    for (String field : fieldNames) {\n      filteredDocument.put(field, doc.getFieldValues(field));\n    }\n\n    try {\n      Query rawMLTQuery = mlt.like(filteredDocument);\n      BooleanQuery boostedMLTQuery = (BooleanQuery) rawMLTQuery;\n\n      if (boostFields.size() > 0) {\n        BooleanQuery.Builder newQ = new BooleanQuery.Builder();\n        newQ.setMinimumNumberShouldMatch(boostedMLTQuery.getMinimumNumberShouldMatch());\n\n        for (BooleanClause clause : boostedMLTQuery) {\n          Query q = clause.getQuery();\n          float originalBoost = 1f;\n          if (q instanceof BoostQuery) {\n            BoostQuery bq = (BoostQuery) q;\n            q = bq.getQuery();\n            originalBoost = bq.getBoost();\n          }\n          Float fieldBoost = boostFields.get(((TermQuery) q).getTerm().field());\n          q = ((fieldBoost != null) ? new BoostQuery(q, fieldBoost * originalBoost) : clause.getQuery());\n          newQ.add(q, clause.getOccur());\n        }\n\n        boostedMLTQuery = newQ.build();\n      }\n\n      // exclude current document from results\n      BooleanQuery.Builder realMLTQuery = new BooleanQuery.Builder();\n      realMLTQuery.add(boostedMLTQuery, BooleanClause.Occur.MUST);\n      realMLTQuery.add(createIdQuery(req.getSchema().getUniqueKeyField().getName(), id), BooleanClause.Occur.MUST_NOT);\n\n      return realMLTQuery.build();\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","sourceOld":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    if(doc == null) {\n      throw new SolrException(\n          SolrException.ErrorCode.BAD_REQUEST, \"Error completing MLT request. Could not fetch \" +\n          \"document with id [\" + id + \"]\");\n    }\n    \n    String[] qf = localParams.getParams(\"qf\");\n    Map<String,Float> boostFields = new HashMap<>();\n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n    \n    if(localParams.getInt(\"mintf\") != null)\n      mlt.setMinTermFreq(localParams.getInt(\"mintf\"));\n\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n\n    if(localParams.get(\"minwl\") != null)\n      mlt.setMinWordLen(localParams.getInt(\"minwl\"));\n\n    if(localParams.get(\"maxwl\") != null)\n      mlt.setMaxWordLen(localParams.getInt(\"maxwl\"));\n\n    if(localParams.get(\"maxqt\") != null)\n      mlt.setMaxQueryTerms(localParams.getInt(\"maxqt\"));\n\n    if(localParams.get(\"maxntp\") != null)\n      mlt.setMaxNumTokensParsed(localParams.getInt(\"maxntp\"));\n    \n    if(localParams.get(\"maxdf\") != null) {\n      mlt.setMaxDocFreq(localParams.getInt(\"maxdf\"));\n    }\n\n    if(localParams.get(\"boost\") != null) {\n      mlt.setBoost(localParams.getBool(\"boost\"));\n      boostFields = SolrPluginUtils.parseFieldBoosts(qf);\n    }\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    Map<String, Collection<Object>> filteredDocument = new HashMap<>();\n    ArrayList<String> fieldNames = new ArrayList<>();\n\n    if (qf != null) {\n      for (String fieldName : qf) {\n        if (!StringUtils.isEmpty(fieldName))  {\n          String[] strings = splitList.split(fieldName);\n          for (String string : strings) {\n            if (!StringUtils.isEmpty(string)) {\n              fieldNames.add(string);\n            }\n          }\n        }\n      }\n    } else {\n      Map<String, SchemaField> fields = req.getSchema().getFields();\n      for (String field : doc.getFieldNames()) {\n        // Only use fields that are stored and have an explicit analyzer.\n        // This makes sense as the query uses tf/idf/.. for query construction.\n        // We might want to relook and change this in the future though.\n        if(fields.get(field).stored() \n            && fields.get(field).getType().isExplicitAnalyzer()) {\n          fieldNames.add(field);\n        }\n      }\n    }\n\n    if( fieldNames.size() < 1 ) {\n      throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\n          \"MoreLikeThis requires at least one similarity field: qf\" );\n    }\n\n    mlt.setFieldNames(fieldNames.toArray(new String[fieldNames.size()]));\n    for (String field : fieldNames) {\n      filteredDocument.put(field, doc.getFieldValues(field));\n    }\n\n    try {\n      Query rawMLTQuery = mlt.like(filteredDocument);\n      BooleanQuery boostedMLTQuery = (BooleanQuery) rawMLTQuery;\n\n      if (boostFields.size() > 0) {\n        BooleanQuery.Builder newQ = new BooleanQuery.Builder();\n        newQ.setDisableCoord(boostedMLTQuery.isCoordDisabled());\n        newQ.setMinimumNumberShouldMatch(boostedMLTQuery.getMinimumNumberShouldMatch());\n\n        for (BooleanClause clause : boostedMLTQuery) {\n          Query q = clause.getQuery();\n          float originalBoost = 1f;\n          if (q instanceof BoostQuery) {\n            BoostQuery bq = (BoostQuery) q;\n            q = bq.getQuery();\n            originalBoost = bq.getBoost();\n          }\n          Float fieldBoost = boostFields.get(((TermQuery) q).getTerm().field());\n          q = ((fieldBoost != null) ? new BoostQuery(q, fieldBoost * originalBoost) : clause.getQuery());\n          newQ.add(q, clause.getOccur());\n        }\n\n        boostedMLTQuery = newQ.build();\n      }\n\n      // exclude current document from results\n      BooleanQuery.Builder realMLTQuery = new BooleanQuery.Builder();\n      realMLTQuery.setDisableCoord(true);\n      realMLTQuery.add(boostedMLTQuery, BooleanClause.Occur.MUST);\n      realMLTQuery.add(createIdQuery(req.getSchema().getUniqueKeyField().getName(), id), BooleanClause.Occur.MUST_NOT);\n\n      return realMLTQuery.build();\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8ed124d21605b0e41f648c25f80f60ba1828e78a","date":1477056513,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","sourceNew":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    if(doc == null) {\n      throw new SolrException(\n          SolrException.ErrorCode.BAD_REQUEST, \"Error completing MLT request. Could not fetch \" +\n          \"document with id [\" + id + \"]\");\n    }\n    \n    String[] qf = localParams.getParams(\"qf\");\n    Map<String,Float> boostFields = new HashMap<>();\n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n    \n    mlt.setMinTermFreq(localParams.getInt(\"mintf\", MoreLikeThis.DEFAULT_MIN_TERM_FREQ));\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", MoreLikeThis.DEFAULT_MIN_DOC_FREQ));\n    mlt.setMinWordLen(localParams.getInt(\"minwl\", MoreLikeThis.DEFAULT_MIN_WORD_LENGTH));\n    mlt.setMaxWordLen(localParams.getInt(\"maxwl\", MoreLikeThis.DEFAULT_MIN_WORD_LENGTH));\n    mlt.setMaxQueryTerms(localParams.getInt(\"maxqt\",MoreLikeThis.DEFAULT_MAX_QUERY_TERMS));\n    mlt.setMaxNumTokensParsed(localParams.getInt(\"maxntp\",MoreLikeThis.DEFAULT_MAX_NUM_TOKENS_PARSED));\n    mlt.setMaxDocFreq(localParams.getInt(\"maxdf\", MoreLikeThis.DEFAULT_MAX_DOC_FREQ));\n\n    if(localParams.get(\"boost\") != null) {\n      mlt.setBoost(localParams.getBool(\"boost\", false));\n      boostFields = SolrPluginUtils.parseFieldBoosts(qf);\n    }\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    Map<String, Collection<Object>> filteredDocument = new HashMap<>();\n    ArrayList<String> fieldNames = new ArrayList<>();\n\n    if (qf != null) {\n      for (String fieldName : qf) {\n        if (!StringUtils.isEmpty(fieldName))  {\n          String[] strings = splitList.split(fieldName);\n          for (String string : strings) {\n            if (!StringUtils.isEmpty(string)) {\n              fieldNames.add(string);\n            }\n          }\n        }\n      }\n    } else {\n      for (String field : doc.getFieldNames()) {\n        // Only use fields that are stored and have an explicit analyzer.\n        // This makes sense as the query uses tf/idf/.. for query construction.\n        // We might want to relook and change this in the future though.\n        SchemaField f = req.getSchema().getFieldOrNull(field);\n        if (f != null && f.stored() && f.getType().isExplicitAnalyzer()) {\n          fieldNames.add(field);\n        }\n      }\n    }\n\n    if( fieldNames.size() < 1 ) {\n      throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\n          \"MoreLikeThis requires at least one similarity field: qf\" );\n    }\n\n    mlt.setFieldNames(fieldNames.toArray(new String[fieldNames.size()]));\n    for (String field : fieldNames) {\n      filteredDocument.put(field, doc.getFieldValues(field));\n    }\n\n    try {\n      Query rawMLTQuery = mlt.like(filteredDocument);\n      BooleanQuery boostedMLTQuery = (BooleanQuery) rawMLTQuery;\n\n      if (boostFields.size() > 0) {\n        BooleanQuery.Builder newQ = new BooleanQuery.Builder();\n        newQ.setMinimumNumberShouldMatch(boostedMLTQuery.getMinimumNumberShouldMatch());\n\n        for (BooleanClause clause : boostedMLTQuery) {\n          Query q = clause.getQuery();\n          float originalBoost = 1f;\n          if (q instanceof BoostQuery) {\n            BoostQuery bq = (BoostQuery) q;\n            q = bq.getQuery();\n            originalBoost = bq.getBoost();\n          }\n          Float fieldBoost = boostFields.get(((TermQuery) q).getTerm().field());\n          q = ((fieldBoost != null) ? new BoostQuery(q, fieldBoost * originalBoost) : clause.getQuery());\n          newQ.add(q, clause.getOccur());\n        }\n\n        boostedMLTQuery = newQ.build();\n      }\n\n      // exclude current document from results\n      BooleanQuery.Builder realMLTQuery = new BooleanQuery.Builder();\n      realMLTQuery.add(boostedMLTQuery, BooleanClause.Occur.MUST);\n      realMLTQuery.add(createIdQuery(req.getSchema().getUniqueKeyField().getName(), id), BooleanClause.Occur.MUST_NOT);\n\n      return realMLTQuery.build();\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","sourceOld":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    if(doc == null) {\n      throw new SolrException(\n          SolrException.ErrorCode.BAD_REQUEST, \"Error completing MLT request. Could not fetch \" +\n          \"document with id [\" + id + \"]\");\n    }\n    \n    String[] qf = localParams.getParams(\"qf\");\n    Map<String,Float> boostFields = new HashMap<>();\n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n    \n    if(localParams.getInt(\"mintf\") != null)\n      mlt.setMinTermFreq(localParams.getInt(\"mintf\"));\n\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n\n    if(localParams.get(\"minwl\") != null)\n      mlt.setMinWordLen(localParams.getInt(\"minwl\"));\n\n    if(localParams.get(\"maxwl\") != null)\n      mlt.setMaxWordLen(localParams.getInt(\"maxwl\"));\n\n    if(localParams.get(\"maxqt\") != null)\n      mlt.setMaxQueryTerms(localParams.getInt(\"maxqt\"));\n\n    if(localParams.get(\"maxntp\") != null)\n      mlt.setMaxNumTokensParsed(localParams.getInt(\"maxntp\"));\n    \n    if(localParams.get(\"maxdf\") != null) {\n      mlt.setMaxDocFreq(localParams.getInt(\"maxdf\"));\n    }\n\n    if(localParams.get(\"boost\") != null) {\n      mlt.setBoost(localParams.getBool(\"boost\"));\n      boostFields = SolrPluginUtils.parseFieldBoosts(qf);\n    }\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    Map<String, Collection<Object>> filteredDocument = new HashMap<>();\n    ArrayList<String> fieldNames = new ArrayList<>();\n\n    if (qf != null) {\n      for (String fieldName : qf) {\n        if (!StringUtils.isEmpty(fieldName))  {\n          String[] strings = splitList.split(fieldName);\n          for (String string : strings) {\n            if (!StringUtils.isEmpty(string)) {\n              fieldNames.add(string);\n            }\n          }\n        }\n      }\n    } else {\n      for (String field : doc.getFieldNames()) {\n        // Only use fields that are stored and have an explicit analyzer.\n        // This makes sense as the query uses tf/idf/.. for query construction.\n        // We might want to relook and change this in the future though.\n        SchemaField f = req.getSchema().getFieldOrNull(field);\n        if (f != null && f.stored() && f.getType().isExplicitAnalyzer()) {\n          fieldNames.add(field);\n        }\n      }\n    }\n\n    if( fieldNames.size() < 1 ) {\n      throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\n          \"MoreLikeThis requires at least one similarity field: qf\" );\n    }\n\n    mlt.setFieldNames(fieldNames.toArray(new String[fieldNames.size()]));\n    for (String field : fieldNames) {\n      filteredDocument.put(field, doc.getFieldValues(field));\n    }\n\n    try {\n      Query rawMLTQuery = mlt.like(filteredDocument);\n      BooleanQuery boostedMLTQuery = (BooleanQuery) rawMLTQuery;\n\n      if (boostFields.size() > 0) {\n        BooleanQuery.Builder newQ = new BooleanQuery.Builder();\n        newQ.setMinimumNumberShouldMatch(boostedMLTQuery.getMinimumNumberShouldMatch());\n\n        for (BooleanClause clause : boostedMLTQuery) {\n          Query q = clause.getQuery();\n          float originalBoost = 1f;\n          if (q instanceof BoostQuery) {\n            BoostQuery bq = (BoostQuery) q;\n            q = bq.getQuery();\n            originalBoost = bq.getBoost();\n          }\n          Float fieldBoost = boostFields.get(((TermQuery) q).getTerm().field());\n          q = ((fieldBoost != null) ? new BoostQuery(q, fieldBoost * originalBoost) : clause.getQuery());\n          newQ.add(q, clause.getOccur());\n        }\n\n        boostedMLTQuery = newQ.build();\n      }\n\n      // exclude current document from results\n      BooleanQuery.Builder realMLTQuery = new BooleanQuery.Builder();\n      realMLTQuery.add(boostedMLTQuery, BooleanClause.Occur.MUST);\n      realMLTQuery.add(createIdQuery(req.getSchema().getUniqueKeyField().getName(), id), BooleanClause.Occur.MUST_NOT);\n\n      return realMLTQuery.build();\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"04bdaa444003ce31c8e9cb6cd43f6a32ccfe8969","date":1477057575,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","sourceNew":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    if(doc == null) {\n      throw new SolrException(\n          SolrException.ErrorCode.BAD_REQUEST, \"Error completing MLT request. Could not fetch \" +\n          \"document with id [\" + id + \"]\");\n    }\n    \n    String[] qf = localParams.getParams(\"qf\");\n    Map<String,Float> boostFields = new HashMap<>();\n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n    \n    if(localParams.getInt(\"mintf\") != null)\n      mlt.setMinTermFreq(localParams.getInt(\"mintf\"));\n\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n\n    if(localParams.get(\"minwl\") != null)\n      mlt.setMinWordLen(localParams.getInt(\"minwl\"));\n\n    if(localParams.get(\"maxwl\") != null)\n      mlt.setMaxWordLen(localParams.getInt(\"maxwl\"));\n\n    if(localParams.get(\"maxqt\") != null)\n      mlt.setMaxQueryTerms(localParams.getInt(\"maxqt\"));\n\n    if(localParams.get(\"maxntp\") != null)\n      mlt.setMaxNumTokensParsed(localParams.getInt(\"maxntp\"));\n    \n    if(localParams.get(\"maxdf\") != null) {\n      mlt.setMaxDocFreq(localParams.getInt(\"maxdf\"));\n    }\n\n    if(localParams.get(\"boost\") != null) {\n      mlt.setBoost(localParams.getBool(\"boost\"));\n      boostFields = SolrPluginUtils.parseFieldBoosts(qf);\n    }\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    Map<String, Collection<Object>> filteredDocument = new HashMap<>();\n    ArrayList<String> fieldNames = new ArrayList<>();\n\n    if (qf != null) {\n      for (String fieldName : qf) {\n        if (!StringUtils.isEmpty(fieldName))  {\n          String[] strings = splitList.split(fieldName);\n          for (String string : strings) {\n            if (!StringUtils.isEmpty(string)) {\n              fieldNames.add(string);\n            }\n          }\n        }\n      }\n    } else {\n      for (String field : doc.getFieldNames()) {\n        // Only use fields that are stored and have an explicit analyzer.\n        // This makes sense as the query uses tf/idf/.. for query construction.\n        // We might want to relook and change this in the future though.\n        SchemaField f = req.getSchema().getFieldOrNull(field);\n        if (f != null && f.stored() && f.getType().isExplicitAnalyzer()) {\n          fieldNames.add(field);\n        }\n      }\n    }\n\n    if( fieldNames.size() < 1 ) {\n      throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\n          \"MoreLikeThis requires at least one similarity field: qf\" );\n    }\n\n    mlt.setFieldNames(fieldNames.toArray(new String[fieldNames.size()]));\n    for (String field : fieldNames) {\n      filteredDocument.put(field, doc.getFieldValues(field));\n    }\n\n    try {\n      Query rawMLTQuery = mlt.like(filteredDocument);\n      BooleanQuery boostedMLTQuery = (BooleanQuery) rawMLTQuery;\n\n      if (boostFields.size() > 0) {\n        BooleanQuery.Builder newQ = new BooleanQuery.Builder();\n        newQ.setMinimumNumberShouldMatch(boostedMLTQuery.getMinimumNumberShouldMatch());\n\n        for (BooleanClause clause : boostedMLTQuery) {\n          Query q = clause.getQuery();\n          float originalBoost = 1f;\n          if (q instanceof BoostQuery) {\n            BoostQuery bq = (BoostQuery) q;\n            q = bq.getQuery();\n            originalBoost = bq.getBoost();\n          }\n          Float fieldBoost = boostFields.get(((TermQuery) q).getTerm().field());\n          q = ((fieldBoost != null) ? new BoostQuery(q, fieldBoost * originalBoost) : clause.getQuery());\n          newQ.add(q, clause.getOccur());\n        }\n\n        boostedMLTQuery = newQ.build();\n      }\n\n      // exclude current document from results\n      BooleanQuery.Builder realMLTQuery = new BooleanQuery.Builder();\n      realMLTQuery.add(boostedMLTQuery, BooleanClause.Occur.MUST);\n      realMLTQuery.add(createIdQuery(req.getSchema().getUniqueKeyField().getName(), id), BooleanClause.Occur.MUST_NOT);\n\n      return realMLTQuery.build();\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","sourceOld":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    if(doc == null) {\n      throw new SolrException(\n          SolrException.ErrorCode.BAD_REQUEST, \"Error completing MLT request. Could not fetch \" +\n          \"document with id [\" + id + \"]\");\n    }\n    \n    String[] qf = localParams.getParams(\"qf\");\n    Map<String,Float> boostFields = new HashMap<>();\n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n    \n    mlt.setMinTermFreq(localParams.getInt(\"mintf\", MoreLikeThis.DEFAULT_MIN_TERM_FREQ));\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", MoreLikeThis.DEFAULT_MIN_DOC_FREQ));\n    mlt.setMinWordLen(localParams.getInt(\"minwl\", MoreLikeThis.DEFAULT_MIN_WORD_LENGTH));\n    mlt.setMaxWordLen(localParams.getInt(\"maxwl\", MoreLikeThis.DEFAULT_MIN_WORD_LENGTH));\n    mlt.setMaxQueryTerms(localParams.getInt(\"maxqt\",MoreLikeThis.DEFAULT_MAX_QUERY_TERMS));\n    mlt.setMaxNumTokensParsed(localParams.getInt(\"maxntp\",MoreLikeThis.DEFAULT_MAX_NUM_TOKENS_PARSED));\n    mlt.setMaxDocFreq(localParams.getInt(\"maxdf\", MoreLikeThis.DEFAULT_MAX_DOC_FREQ));\n\n    if(localParams.get(\"boost\") != null) {\n      mlt.setBoost(localParams.getBool(\"boost\", false));\n      boostFields = SolrPluginUtils.parseFieldBoosts(qf);\n    }\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    Map<String, Collection<Object>> filteredDocument = new HashMap<>();\n    ArrayList<String> fieldNames = new ArrayList<>();\n\n    if (qf != null) {\n      for (String fieldName : qf) {\n        if (!StringUtils.isEmpty(fieldName))  {\n          String[] strings = splitList.split(fieldName);\n          for (String string : strings) {\n            if (!StringUtils.isEmpty(string)) {\n              fieldNames.add(string);\n            }\n          }\n        }\n      }\n    } else {\n      for (String field : doc.getFieldNames()) {\n        // Only use fields that are stored and have an explicit analyzer.\n        // This makes sense as the query uses tf/idf/.. for query construction.\n        // We might want to relook and change this in the future though.\n        SchemaField f = req.getSchema().getFieldOrNull(field);\n        if (f != null && f.stored() && f.getType().isExplicitAnalyzer()) {\n          fieldNames.add(field);\n        }\n      }\n    }\n\n    if( fieldNames.size() < 1 ) {\n      throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\n          \"MoreLikeThis requires at least one similarity field: qf\" );\n    }\n\n    mlt.setFieldNames(fieldNames.toArray(new String[fieldNames.size()]));\n    for (String field : fieldNames) {\n      filteredDocument.put(field, doc.getFieldValues(field));\n    }\n\n    try {\n      Query rawMLTQuery = mlt.like(filteredDocument);\n      BooleanQuery boostedMLTQuery = (BooleanQuery) rawMLTQuery;\n\n      if (boostFields.size() > 0) {\n        BooleanQuery.Builder newQ = new BooleanQuery.Builder();\n        newQ.setMinimumNumberShouldMatch(boostedMLTQuery.getMinimumNumberShouldMatch());\n\n        for (BooleanClause clause : boostedMLTQuery) {\n          Query q = clause.getQuery();\n          float originalBoost = 1f;\n          if (q instanceof BoostQuery) {\n            BoostQuery bq = (BoostQuery) q;\n            q = bq.getQuery();\n            originalBoost = bq.getBoost();\n          }\n          Float fieldBoost = boostFields.get(((TermQuery) q).getTerm().field());\n          q = ((fieldBoost != null) ? new BoostQuery(q, fieldBoost * originalBoost) : clause.getQuery());\n          newQ.add(q, clause.getOccur());\n        }\n\n        boostedMLTQuery = newQ.build();\n      }\n\n      // exclude current document from results\n      BooleanQuery.Builder realMLTQuery = new BooleanQuery.Builder();\n      realMLTQuery.add(boostedMLTQuery, BooleanClause.Occur.MUST);\n      realMLTQuery.add(createIdQuery(req.getSchema().getUniqueKeyField().getName(), id), BooleanClause.Occur.MUST_NOT);\n\n      return realMLTQuery.build();\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","bugFix":null,"bugIntro":["2100a5b744ecaec4d2b191a7da9083feb50a6f7f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9d8dad4099bd3cb610a9a9229685f246ef6b9f16","date":1480422779,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","sourceNew":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    if(doc == null) {\n      throw new SolrException(\n          SolrException.ErrorCode.BAD_REQUEST, \"Error completing MLT request. Could not fetch \" +\n          \"document with id [\" + id + \"]\");\n    }\n    \n    String[] qf = localParams.getParams(\"qf\");\n    Map<String,Float> boostFields = new HashMap<>();\n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n    \n    mlt.setMinTermFreq(localParams.getInt(\"mintf\", MoreLikeThis.DEFAULT_MIN_TERM_FREQ));\n\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n\n    mlt.setMinWordLen(localParams.getInt(\"minwl\", MoreLikeThis.DEFAULT_MIN_WORD_LENGTH));\n\n    mlt.setMaxWordLen(localParams.getInt(\"maxwl\", MoreLikeThis.DEFAULT_MAX_WORD_LENGTH));\n\n    mlt.setMaxQueryTerms(localParams.getInt(\"maxqt\", MoreLikeThis.DEFAULT_MAX_QUERY_TERMS));\n\n    mlt.setMaxNumTokensParsed(localParams.getInt(\"maxntp\", MoreLikeThis.DEFAULT_MAX_NUM_TOKENS_PARSED));\n    \n    mlt.setMaxDocFreq(localParams.getInt(\"maxdf\", MoreLikeThis.DEFAULT_MAX_DOC_FREQ));\n\n    if(localParams.get(\"boost\") != null) {\n      mlt.setBoost(localParams.getBool(\"boost\"));\n      boostFields = SolrPluginUtils.parseFieldBoosts(qf);\n    }\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    Map<String, Collection<Object>> filteredDocument = new HashMap<>();\n    ArrayList<String> fieldNames = new ArrayList<>();\n\n    if (qf != null) {\n      for (String fieldName : qf) {\n        if (!StringUtils.isEmpty(fieldName))  {\n          String[] strings = splitList.split(fieldName);\n          for (String string : strings) {\n            if (!StringUtils.isEmpty(string)) {\n              fieldNames.add(string);\n            }\n          }\n        }\n      }\n    } else {\n      for (String field : doc.getFieldNames()) {\n        // Only use fields that are stored and have an explicit analyzer.\n        // This makes sense as the query uses tf/idf/.. for query construction.\n        // We might want to relook and change this in the future though.\n        SchemaField f = req.getSchema().getFieldOrNull(field);\n        if (f != null && f.stored() && f.getType().isExplicitAnalyzer()) {\n          fieldNames.add(field);\n        }\n      }\n    }\n\n    if( fieldNames.size() < 1 ) {\n      throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\n          \"MoreLikeThis requires at least one similarity field: qf\" );\n    }\n\n    mlt.setFieldNames(fieldNames.toArray(new String[fieldNames.size()]));\n    for (String field : fieldNames) {\n      filteredDocument.put(field, doc.getFieldValues(field));\n    }\n\n    try {\n      Query rawMLTQuery = mlt.like(filteredDocument);\n      BooleanQuery boostedMLTQuery = (BooleanQuery) rawMLTQuery;\n\n      if (boostFields.size() > 0) {\n        BooleanQuery.Builder newQ = new BooleanQuery.Builder();\n        newQ.setMinimumNumberShouldMatch(boostedMLTQuery.getMinimumNumberShouldMatch());\n\n        for (BooleanClause clause : boostedMLTQuery) {\n          Query q = clause.getQuery();\n          float originalBoost = 1f;\n          if (q instanceof BoostQuery) {\n            BoostQuery bq = (BoostQuery) q;\n            q = bq.getQuery();\n            originalBoost = bq.getBoost();\n          }\n          Float fieldBoost = boostFields.get(((TermQuery) q).getTerm().field());\n          q = ((fieldBoost != null) ? new BoostQuery(q, fieldBoost * originalBoost) : clause.getQuery());\n          newQ.add(q, clause.getOccur());\n        }\n\n        boostedMLTQuery = newQ.build();\n      }\n\n      // exclude current document from results\n      BooleanQuery.Builder realMLTQuery = new BooleanQuery.Builder();\n      realMLTQuery.add(boostedMLTQuery, BooleanClause.Occur.MUST);\n      realMLTQuery.add(createIdQuery(req.getSchema().getUniqueKeyField().getName(), id), BooleanClause.Occur.MUST_NOT);\n\n      return realMLTQuery.build();\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","sourceOld":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    if(doc == null) {\n      throw new SolrException(\n          SolrException.ErrorCode.BAD_REQUEST, \"Error completing MLT request. Could not fetch \" +\n          \"document with id [\" + id + \"]\");\n    }\n    \n    String[] qf = localParams.getParams(\"qf\");\n    Map<String,Float> boostFields = new HashMap<>();\n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n    \n    if(localParams.getInt(\"mintf\") != null)\n      mlt.setMinTermFreq(localParams.getInt(\"mintf\"));\n\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n\n    if(localParams.get(\"minwl\") != null)\n      mlt.setMinWordLen(localParams.getInt(\"minwl\"));\n\n    if(localParams.get(\"maxwl\") != null)\n      mlt.setMaxWordLen(localParams.getInt(\"maxwl\"));\n\n    if(localParams.get(\"maxqt\") != null)\n      mlt.setMaxQueryTerms(localParams.getInt(\"maxqt\"));\n\n    if(localParams.get(\"maxntp\") != null)\n      mlt.setMaxNumTokensParsed(localParams.getInt(\"maxntp\"));\n    \n    if(localParams.get(\"maxdf\") != null) {\n      mlt.setMaxDocFreq(localParams.getInt(\"maxdf\"));\n    }\n\n    if(localParams.get(\"boost\") != null) {\n      mlt.setBoost(localParams.getBool(\"boost\"));\n      boostFields = SolrPluginUtils.parseFieldBoosts(qf);\n    }\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    Map<String, Collection<Object>> filteredDocument = new HashMap<>();\n    ArrayList<String> fieldNames = new ArrayList<>();\n\n    if (qf != null) {\n      for (String fieldName : qf) {\n        if (!StringUtils.isEmpty(fieldName))  {\n          String[] strings = splitList.split(fieldName);\n          for (String string : strings) {\n            if (!StringUtils.isEmpty(string)) {\n              fieldNames.add(string);\n            }\n          }\n        }\n      }\n    } else {\n      for (String field : doc.getFieldNames()) {\n        // Only use fields that are stored and have an explicit analyzer.\n        // This makes sense as the query uses tf/idf/.. for query construction.\n        // We might want to relook and change this in the future though.\n        SchemaField f = req.getSchema().getFieldOrNull(field);\n        if (f != null && f.stored() && f.getType().isExplicitAnalyzer()) {\n          fieldNames.add(field);\n        }\n      }\n    }\n\n    if( fieldNames.size() < 1 ) {\n      throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\n          \"MoreLikeThis requires at least one similarity field: qf\" );\n    }\n\n    mlt.setFieldNames(fieldNames.toArray(new String[fieldNames.size()]));\n    for (String field : fieldNames) {\n      filteredDocument.put(field, doc.getFieldValues(field));\n    }\n\n    try {\n      Query rawMLTQuery = mlt.like(filteredDocument);\n      BooleanQuery boostedMLTQuery = (BooleanQuery) rawMLTQuery;\n\n      if (boostFields.size() > 0) {\n        BooleanQuery.Builder newQ = new BooleanQuery.Builder();\n        newQ.setMinimumNumberShouldMatch(boostedMLTQuery.getMinimumNumberShouldMatch());\n\n        for (BooleanClause clause : boostedMLTQuery) {\n          Query q = clause.getQuery();\n          float originalBoost = 1f;\n          if (q instanceof BoostQuery) {\n            BoostQuery bq = (BoostQuery) q;\n            q = bq.getQuery();\n            originalBoost = bq.getBoost();\n          }\n          Float fieldBoost = boostFields.get(((TermQuery) q).getTerm().field());\n          q = ((fieldBoost != null) ? new BoostQuery(q, fieldBoost * originalBoost) : clause.getQuery());\n          newQ.add(q, clause.getOccur());\n        }\n\n        boostedMLTQuery = newQ.build();\n      }\n\n      // exclude current document from results\n      BooleanQuery.Builder realMLTQuery = new BooleanQuery.Builder();\n      realMLTQuery.add(boostedMLTQuery, BooleanClause.Occur.MUST);\n      realMLTQuery.add(createIdQuery(req.getSchema().getUniqueKeyField().getName(), id), BooleanClause.Occur.MUST_NOT);\n\n      return realMLTQuery.build();\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9856095f7afb5a607bf5e65077615ed91273508c","date":1481837697,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","sourceNew":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    if(doc == null) {\n      throw new SolrException(\n          SolrException.ErrorCode.BAD_REQUEST, \"Error completing MLT request. Could not fetch \" +\n          \"document with id [\" + id + \"]\");\n    }\n    \n    String[] qf = localParams.getParams(\"qf\");\n    Map<String,Float> boostFields = new HashMap<>();\n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n    \n    mlt.setMinTermFreq(localParams.getInt(\"mintf\", MoreLikeThis.DEFAULT_MIN_TERM_FREQ));\n\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n\n    mlt.setMinWordLen(localParams.getInt(\"minwl\", MoreLikeThis.DEFAULT_MIN_WORD_LENGTH));\n\n    mlt.setMaxWordLen(localParams.getInt(\"maxwl\", MoreLikeThis.DEFAULT_MAX_WORD_LENGTH));\n\n    mlt.setMaxQueryTerms(localParams.getInt(\"maxqt\", MoreLikeThis.DEFAULT_MAX_QUERY_TERMS));\n\n    mlt.setMaxNumTokensParsed(localParams.getInt(\"maxntp\", MoreLikeThis.DEFAULT_MAX_NUM_TOKENS_PARSED));\n    \n    mlt.setMaxDocFreq(localParams.getInt(\"maxdf\", MoreLikeThis.DEFAULT_MAX_DOC_FREQ));\n\n    if(localParams.get(\"boost\") != null) {\n      mlt.setBoost(localParams.getBool(\"boost\"));\n      boostFields = SolrPluginUtils.parseFieldBoosts(qf);\n    }\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    Map<String, Collection<Object>> filteredDocument = new HashMap<>();\n    ArrayList<String> fieldNames = new ArrayList<>();\n\n    if (qf != null) {\n      for (String fieldName : qf) {\n        if (!StringUtils.isEmpty(fieldName))  {\n          String[] strings = splitList.split(fieldName);\n          for (String string : strings) {\n            if (!StringUtils.isEmpty(string)) {\n              fieldNames.add(string);\n            }\n          }\n        }\n      }\n    } else {\n      for (String field : doc.getFieldNames()) {\n        // Only use fields that are stored and have an explicit analyzer.\n        // This makes sense as the query uses tf/idf/.. for query construction.\n        // We might want to relook and change this in the future though.\n        SchemaField f = req.getSchema().getFieldOrNull(field);\n        if (f != null && f.stored() && f.getType().isExplicitAnalyzer()) {\n          fieldNames.add(field);\n        }\n      }\n    }\n\n    if( fieldNames.size() < 1 ) {\n      throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\n          \"MoreLikeThis requires at least one similarity field: qf\" );\n    }\n\n    mlt.setFieldNames(fieldNames.toArray(new String[fieldNames.size()]));\n    for (String field : fieldNames) {\n      filteredDocument.put(field, doc.getFieldValues(field));\n    }\n\n    try {\n      Query rawMLTQuery = mlt.like(filteredDocument);\n      BooleanQuery boostedMLTQuery = (BooleanQuery) rawMLTQuery;\n\n      if (boostFields.size() > 0) {\n        BooleanQuery.Builder newQ = new BooleanQuery.Builder();\n        newQ.setMinimumNumberShouldMatch(boostedMLTQuery.getMinimumNumberShouldMatch());\n\n        for (BooleanClause clause : boostedMLTQuery) {\n          Query q = clause.getQuery();\n          float originalBoost = 1f;\n          if (q instanceof BoostQuery) {\n            BoostQuery bq = (BoostQuery) q;\n            q = bq.getQuery();\n            originalBoost = bq.getBoost();\n          }\n          Float fieldBoost = boostFields.get(((TermQuery) q).getTerm().field());\n          q = ((fieldBoost != null) ? new BoostQuery(q, fieldBoost * originalBoost) : clause.getQuery());\n          newQ.add(q, clause.getOccur());\n        }\n\n        boostedMLTQuery = newQ.build();\n      }\n\n      // exclude current document from results\n      BooleanQuery.Builder realMLTQuery = new BooleanQuery.Builder();\n      realMLTQuery.add(boostedMLTQuery, BooleanClause.Occur.MUST);\n      realMLTQuery.add(createIdQuery(req.getSchema().getUniqueKeyField().getName(), id), BooleanClause.Occur.MUST_NOT);\n\n      return realMLTQuery.build();\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","sourceOld":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    if(doc == null) {\n      throw new SolrException(\n          SolrException.ErrorCode.BAD_REQUEST, \"Error completing MLT request. Could not fetch \" +\n          \"document with id [\" + id + \"]\");\n    }\n    \n    String[] qf = localParams.getParams(\"qf\");\n    Map<String,Float> boostFields = new HashMap<>();\n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n    \n    if(localParams.getInt(\"mintf\") != null)\n      mlt.setMinTermFreq(localParams.getInt(\"mintf\"));\n\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n\n    if(localParams.get(\"minwl\") != null)\n      mlt.setMinWordLen(localParams.getInt(\"minwl\"));\n\n    if(localParams.get(\"maxwl\") != null)\n      mlt.setMaxWordLen(localParams.getInt(\"maxwl\"));\n\n    if(localParams.get(\"maxqt\") != null)\n      mlt.setMaxQueryTerms(localParams.getInt(\"maxqt\"));\n\n    if(localParams.get(\"maxntp\") != null)\n      mlt.setMaxNumTokensParsed(localParams.getInt(\"maxntp\"));\n    \n    if(localParams.get(\"maxdf\") != null) {\n      mlt.setMaxDocFreq(localParams.getInt(\"maxdf\"));\n    }\n\n    if(localParams.get(\"boost\") != null) {\n      mlt.setBoost(localParams.getBool(\"boost\"));\n      boostFields = SolrPluginUtils.parseFieldBoosts(qf);\n    }\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    Map<String, Collection<Object>> filteredDocument = new HashMap<>();\n    ArrayList<String> fieldNames = new ArrayList<>();\n\n    if (qf != null) {\n      for (String fieldName : qf) {\n        if (!StringUtils.isEmpty(fieldName))  {\n          String[] strings = splitList.split(fieldName);\n          for (String string : strings) {\n            if (!StringUtils.isEmpty(string)) {\n              fieldNames.add(string);\n            }\n          }\n        }\n      }\n    } else {\n      for (String field : doc.getFieldNames()) {\n        // Only use fields that are stored and have an explicit analyzer.\n        // This makes sense as the query uses tf/idf/.. for query construction.\n        // We might want to relook and change this in the future though.\n        SchemaField f = req.getSchema().getFieldOrNull(field);\n        if (f != null && f.stored() && f.getType().isExplicitAnalyzer()) {\n          fieldNames.add(field);\n        }\n      }\n    }\n\n    if( fieldNames.size() < 1 ) {\n      throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\n          \"MoreLikeThis requires at least one similarity field: qf\" );\n    }\n\n    mlt.setFieldNames(fieldNames.toArray(new String[fieldNames.size()]));\n    for (String field : fieldNames) {\n      filteredDocument.put(field, doc.getFieldValues(field));\n    }\n\n    try {\n      Query rawMLTQuery = mlt.like(filteredDocument);\n      BooleanQuery boostedMLTQuery = (BooleanQuery) rawMLTQuery;\n\n      if (boostFields.size() > 0) {\n        BooleanQuery.Builder newQ = new BooleanQuery.Builder();\n        newQ.setMinimumNumberShouldMatch(boostedMLTQuery.getMinimumNumberShouldMatch());\n\n        for (BooleanClause clause : boostedMLTQuery) {\n          Query q = clause.getQuery();\n          float originalBoost = 1f;\n          if (q instanceof BoostQuery) {\n            BoostQuery bq = (BoostQuery) q;\n            q = bq.getQuery();\n            originalBoost = bq.getBoost();\n          }\n          Float fieldBoost = boostFields.get(((TermQuery) q).getTerm().field());\n          q = ((fieldBoost != null) ? new BoostQuery(q, fieldBoost * originalBoost) : clause.getQuery());\n          newQ.add(q, clause.getOccur());\n        }\n\n        boostedMLTQuery = newQ.build();\n      }\n\n      // exclude current document from results\n      BooleanQuery.Builder realMLTQuery = new BooleanQuery.Builder();\n      realMLTQuery.add(boostedMLTQuery, BooleanClause.Occur.MUST);\n      realMLTQuery.add(createIdQuery(req.getSchema().getUniqueKeyField().getName(), id), BooleanClause.Occur.MUST_NOT);\n\n      return realMLTQuery.build();\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2100a5b744ecaec4d2b191a7da9083feb50a6f7f","date":1483995984,"type":3,"author":"anshum","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","sourceNew":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    if(doc == null) {\n      throw new SolrException(\n          SolrException.ErrorCode.BAD_REQUEST, \"Error completing MLT request. Could not fetch \" +\n          \"document with id [\" + id + \"]\");\n    }\n\n    String[] qf = localParams.getParams(\"qf\");\n    Map<String,Float> boostFields = new HashMap<>();\n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n\n    mlt.setMinTermFreq(localParams.getInt(\"mintf\", MoreLikeThis.DEFAULT_MIN_TERM_FREQ));\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n    mlt.setMinWordLen(localParams.getInt(\"minwl\", MoreLikeThis.DEFAULT_MIN_WORD_LENGTH));\n    mlt.setMaxWordLen(localParams.getInt(\"maxwl\", MoreLikeThis.DEFAULT_MAX_WORD_LENGTH));\n    mlt.setMaxQueryTerms(localParams.getInt(\"maxqt\", MoreLikeThis.DEFAULT_MAX_QUERY_TERMS));\n    mlt.setMaxNumTokensParsed(localParams.getInt(\"maxntp\", MoreLikeThis.DEFAULT_MAX_NUM_TOKENS_PARSED));\n    mlt.setMaxDocFreq(localParams.getInt(\"maxdf\", MoreLikeThis.DEFAULT_MAX_DOC_FREQ));\n\n    Boolean boost = localParams.getBool(\"boost\", MoreLikeThis.DEFAULT_BOOST);\n    mlt.setBoost(boost);\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    Map<String, Collection<Object>> filteredDocument = new HashMap<>();\n    String[] fieldNames;\n\n    if (qf != null) {\n      ArrayList<String> fields = new ArrayList();\n      for (String fieldName : qf) {\n        if (!StringUtils.isEmpty(fieldName))  {\n          String[] strings = splitList.split(fieldName);\n          for (String string : strings) {\n            if (!StringUtils.isEmpty(string)) {\n              fields.add(string);\n            }\n          }\n        }\n      }\n      // Parse field names and boosts from the fields\n      boostFields = SolrPluginUtils.parseFieldBoosts(fields.toArray(new String[0]));\n      fieldNames = boostFields.keySet().toArray(new String[0]);\n    } else {\n      ArrayList<String> fields = new ArrayList();\n      for (String field : doc.getFieldNames()) {\n        // Only use fields that are stored and have an explicit analyzer.\n        // This makes sense as the query uses tf/idf/.. for query construction.\n        // We might want to relook and change this in the future though.\n        SchemaField f = req.getSchema().getFieldOrNull(field);\n        if (f != null && f.stored() && f.getType().isExplicitAnalyzer()) {\n          fields.add(field);\n        }\n      }\n      fieldNames = fields.toArray(new String[0]);\n    }\n\n    if (fieldNames.length < 1) {\n      throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\n          \"MoreLikeThis requires at least one similarity field: qf\" );\n    }\n\n    mlt.setFieldNames(fieldNames);\n    for (String field : fieldNames) {\n      Collection<Object> fieldValues = doc.getFieldValues(field);\n      if (fieldValues != null) {\n        Collection<Object> values = new ArrayList();\n        for (Object val : fieldValues) {\n          if (val instanceof IndexableField) {\n            values.add(((IndexableField)val).stringValue());\n          }\n          else {\n            values.add(val);\n          }\n        }\n        filteredDocument.put(field, values);\n      }\n    }\n\n    try {\n      Query rawMLTQuery = mlt.like(filteredDocument);\n      BooleanQuery boostedMLTQuery = (BooleanQuery) rawMLTQuery;\n\n      if (boost && boostFields.size() > 0) {\n        BooleanQuery.Builder newQ = new BooleanQuery.Builder();\n        newQ.setMinimumNumberShouldMatch(boostedMLTQuery.getMinimumNumberShouldMatch());\n\n        for (BooleanClause clause : boostedMLTQuery) {\n          Query q = clause.getQuery();\n          float originalBoost = 1f;\n          if (q instanceof BoostQuery) {\n            BoostQuery bq = (BoostQuery) q;\n            q = bq.getQuery();\n            originalBoost = bq.getBoost();\n          }\n          Float fieldBoost = boostFields.get(((TermQuery) q).getTerm().field());\n          q = ((fieldBoost != null) ? new BoostQuery(q, fieldBoost * originalBoost) : clause.getQuery());\n          newQ.add(q, clause.getOccur());\n        }\n\n        boostedMLTQuery = newQ.build();\n      }\n\n      // exclude current document from results\n      BooleanQuery.Builder realMLTQuery = new BooleanQuery.Builder();\n      realMLTQuery.add(boostedMLTQuery, BooleanClause.Occur.MUST);\n      realMLTQuery.add(createIdQuery(req.getSchema().getUniqueKeyField().getName(), id), BooleanClause.Occur.MUST_NOT);\n\n      return realMLTQuery.build();\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","sourceOld":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    if(doc == null) {\n      throw new SolrException(\n          SolrException.ErrorCode.BAD_REQUEST, \"Error completing MLT request. Could not fetch \" +\n          \"document with id [\" + id + \"]\");\n    }\n    \n    String[] qf = localParams.getParams(\"qf\");\n    Map<String,Float> boostFields = new HashMap<>();\n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n    \n    mlt.setMinTermFreq(localParams.getInt(\"mintf\", MoreLikeThis.DEFAULT_MIN_TERM_FREQ));\n\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n\n    mlt.setMinWordLen(localParams.getInt(\"minwl\", MoreLikeThis.DEFAULT_MIN_WORD_LENGTH));\n\n    mlt.setMaxWordLen(localParams.getInt(\"maxwl\", MoreLikeThis.DEFAULT_MAX_WORD_LENGTH));\n\n    mlt.setMaxQueryTerms(localParams.getInt(\"maxqt\", MoreLikeThis.DEFAULT_MAX_QUERY_TERMS));\n\n    mlt.setMaxNumTokensParsed(localParams.getInt(\"maxntp\", MoreLikeThis.DEFAULT_MAX_NUM_TOKENS_PARSED));\n    \n    mlt.setMaxDocFreq(localParams.getInt(\"maxdf\", MoreLikeThis.DEFAULT_MAX_DOC_FREQ));\n\n    if(localParams.get(\"boost\") != null) {\n      mlt.setBoost(localParams.getBool(\"boost\"));\n      boostFields = SolrPluginUtils.parseFieldBoosts(qf);\n    }\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    Map<String, Collection<Object>> filteredDocument = new HashMap<>();\n    ArrayList<String> fieldNames = new ArrayList<>();\n\n    if (qf != null) {\n      for (String fieldName : qf) {\n        if (!StringUtils.isEmpty(fieldName))  {\n          String[] strings = splitList.split(fieldName);\n          for (String string : strings) {\n            if (!StringUtils.isEmpty(string)) {\n              fieldNames.add(string);\n            }\n          }\n        }\n      }\n    } else {\n      for (String field : doc.getFieldNames()) {\n        // Only use fields that are stored and have an explicit analyzer.\n        // This makes sense as the query uses tf/idf/.. for query construction.\n        // We might want to relook and change this in the future though.\n        SchemaField f = req.getSchema().getFieldOrNull(field);\n        if (f != null && f.stored() && f.getType().isExplicitAnalyzer()) {\n          fieldNames.add(field);\n        }\n      }\n    }\n\n    if( fieldNames.size() < 1 ) {\n      throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\n          \"MoreLikeThis requires at least one similarity field: qf\" );\n    }\n\n    mlt.setFieldNames(fieldNames.toArray(new String[fieldNames.size()]));\n    for (String field : fieldNames) {\n      filteredDocument.put(field, doc.getFieldValues(field));\n    }\n\n    try {\n      Query rawMLTQuery = mlt.like(filteredDocument);\n      BooleanQuery boostedMLTQuery = (BooleanQuery) rawMLTQuery;\n\n      if (boostFields.size() > 0) {\n        BooleanQuery.Builder newQ = new BooleanQuery.Builder();\n        newQ.setMinimumNumberShouldMatch(boostedMLTQuery.getMinimumNumberShouldMatch());\n\n        for (BooleanClause clause : boostedMLTQuery) {\n          Query q = clause.getQuery();\n          float originalBoost = 1f;\n          if (q instanceof BoostQuery) {\n            BoostQuery bq = (BoostQuery) q;\n            q = bq.getQuery();\n            originalBoost = bq.getBoost();\n          }\n          Float fieldBoost = boostFields.get(((TermQuery) q).getTerm().field());\n          q = ((fieldBoost != null) ? new BoostQuery(q, fieldBoost * originalBoost) : clause.getQuery());\n          newQ.add(q, clause.getOccur());\n        }\n\n        boostedMLTQuery = newQ.build();\n      }\n\n      // exclude current document from results\n      BooleanQuery.Builder realMLTQuery = new BooleanQuery.Builder();\n      realMLTQuery.add(boostedMLTQuery, BooleanClause.Occur.MUST);\n      realMLTQuery.add(createIdQuery(req.getSchema().getUniqueKeyField().getName(), id), BooleanClause.Occur.MUST_NOT);\n\n      return realMLTQuery.build();\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","bugFix":["04bdaa444003ce31c8e9cb6cd43f6a32ccfe8969","ed95a777f3860385e015fb8a082e4b66a5aa6bb8","655260340014c640e7d0f9a7a7ea1f00f36f65e5","07d695a14a1938b01a5d4ab68b3c815eb061da94","19cb756f0ad73c8d898cb8bfdd9f04bcc6e3b7c1","eb55f624eb53f26cfb7f9614b862fb7657633358"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"09ab8ee44ca898536770d0106a7c0ee4be4f0eb7","date":1484239864,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","sourceNew":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    if(doc == null) {\n      throw new SolrException(\n          SolrException.ErrorCode.BAD_REQUEST, \"Error completing MLT request. Could not fetch \" +\n          \"document with id [\" + id + \"]\");\n    }\n\n    String[] qf = localParams.getParams(\"qf\");\n    Map<String,Float> boostFields = new HashMap<>();\n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n\n    mlt.setMinTermFreq(localParams.getInt(\"mintf\", MoreLikeThis.DEFAULT_MIN_TERM_FREQ));\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n    mlt.setMinWordLen(localParams.getInt(\"minwl\", MoreLikeThis.DEFAULT_MIN_WORD_LENGTH));\n    mlt.setMaxWordLen(localParams.getInt(\"maxwl\", MoreLikeThis.DEFAULT_MAX_WORD_LENGTH));\n    mlt.setMaxQueryTerms(localParams.getInt(\"maxqt\", MoreLikeThis.DEFAULT_MAX_QUERY_TERMS));\n    mlt.setMaxNumTokensParsed(localParams.getInt(\"maxntp\", MoreLikeThis.DEFAULT_MAX_NUM_TOKENS_PARSED));\n    mlt.setMaxDocFreq(localParams.getInt(\"maxdf\", MoreLikeThis.DEFAULT_MAX_DOC_FREQ));\n\n    Boolean boost = localParams.getBool(\"boost\", MoreLikeThis.DEFAULT_BOOST);\n    mlt.setBoost(boost);\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    Map<String, Collection<Object>> filteredDocument = new HashMap<>();\n    String[] fieldNames;\n\n    if (qf != null) {\n      ArrayList<String> fields = new ArrayList();\n      for (String fieldName : qf) {\n        if (!StringUtils.isEmpty(fieldName))  {\n          String[] strings = splitList.split(fieldName);\n          for (String string : strings) {\n            if (!StringUtils.isEmpty(string)) {\n              fields.add(string);\n            }\n          }\n        }\n      }\n      // Parse field names and boosts from the fields\n      boostFields = SolrPluginUtils.parseFieldBoosts(fields.toArray(new String[0]));\n      fieldNames = boostFields.keySet().toArray(new String[0]);\n    } else {\n      ArrayList<String> fields = new ArrayList();\n      for (String field : doc.getFieldNames()) {\n        // Only use fields that are stored and have an explicit analyzer.\n        // This makes sense as the query uses tf/idf/.. for query construction.\n        // We might want to relook and change this in the future though.\n        SchemaField f = req.getSchema().getFieldOrNull(field);\n        if (f != null && f.stored() && f.getType().isExplicitAnalyzer()) {\n          fields.add(field);\n        }\n      }\n      fieldNames = fields.toArray(new String[0]);\n    }\n\n    if (fieldNames.length < 1) {\n      throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\n          \"MoreLikeThis requires at least one similarity field: qf\" );\n    }\n\n    mlt.setFieldNames(fieldNames);\n    for (String field : fieldNames) {\n      Collection<Object> fieldValues = doc.getFieldValues(field);\n      if (fieldValues != null) {\n        Collection<Object> values = new ArrayList();\n        for (Object val : fieldValues) {\n          if (val instanceof IndexableField) {\n            values.add(((IndexableField)val).stringValue());\n          }\n          else {\n            values.add(val);\n          }\n        }\n        filteredDocument.put(field, values);\n      }\n    }\n\n    try {\n      Query rawMLTQuery = mlt.like(filteredDocument);\n      BooleanQuery boostedMLTQuery = (BooleanQuery) rawMLTQuery;\n\n      if (boost && boostFields.size() > 0) {\n        BooleanQuery.Builder newQ = new BooleanQuery.Builder();\n        newQ.setMinimumNumberShouldMatch(boostedMLTQuery.getMinimumNumberShouldMatch());\n\n        for (BooleanClause clause : boostedMLTQuery) {\n          Query q = clause.getQuery();\n          float originalBoost = 1f;\n          if (q instanceof BoostQuery) {\n            BoostQuery bq = (BoostQuery) q;\n            q = bq.getQuery();\n            originalBoost = bq.getBoost();\n          }\n          Float fieldBoost = boostFields.get(((TermQuery) q).getTerm().field());\n          q = ((fieldBoost != null) ? new BoostQuery(q, fieldBoost * originalBoost) : clause.getQuery());\n          newQ.add(q, clause.getOccur());\n        }\n\n        boostedMLTQuery = newQ.build();\n      }\n\n      // exclude current document from results\n      BooleanQuery.Builder realMLTQuery = new BooleanQuery.Builder();\n      realMLTQuery.add(boostedMLTQuery, BooleanClause.Occur.MUST);\n      realMLTQuery.add(createIdQuery(req.getSchema().getUniqueKeyField().getName(), id), BooleanClause.Occur.MUST_NOT);\n\n      return realMLTQuery.build();\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","sourceOld":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    if(doc == null) {\n      throw new SolrException(\n          SolrException.ErrorCode.BAD_REQUEST, \"Error completing MLT request. Could not fetch \" +\n          \"document with id [\" + id + \"]\");\n    }\n    \n    String[] qf = localParams.getParams(\"qf\");\n    Map<String,Float> boostFields = new HashMap<>();\n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n    \n    mlt.setMinTermFreq(localParams.getInt(\"mintf\", MoreLikeThis.DEFAULT_MIN_TERM_FREQ));\n\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n\n    mlt.setMinWordLen(localParams.getInt(\"minwl\", MoreLikeThis.DEFAULT_MIN_WORD_LENGTH));\n\n    mlt.setMaxWordLen(localParams.getInt(\"maxwl\", MoreLikeThis.DEFAULT_MAX_WORD_LENGTH));\n\n    mlt.setMaxQueryTerms(localParams.getInt(\"maxqt\", MoreLikeThis.DEFAULT_MAX_QUERY_TERMS));\n\n    mlt.setMaxNumTokensParsed(localParams.getInt(\"maxntp\", MoreLikeThis.DEFAULT_MAX_NUM_TOKENS_PARSED));\n    \n    mlt.setMaxDocFreq(localParams.getInt(\"maxdf\", MoreLikeThis.DEFAULT_MAX_DOC_FREQ));\n\n    if(localParams.get(\"boost\") != null) {\n      mlt.setBoost(localParams.getBool(\"boost\"));\n      boostFields = SolrPluginUtils.parseFieldBoosts(qf);\n    }\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    Map<String, Collection<Object>> filteredDocument = new HashMap<>();\n    ArrayList<String> fieldNames = new ArrayList<>();\n\n    if (qf != null) {\n      for (String fieldName : qf) {\n        if (!StringUtils.isEmpty(fieldName))  {\n          String[] strings = splitList.split(fieldName);\n          for (String string : strings) {\n            if (!StringUtils.isEmpty(string)) {\n              fieldNames.add(string);\n            }\n          }\n        }\n      }\n    } else {\n      for (String field : doc.getFieldNames()) {\n        // Only use fields that are stored and have an explicit analyzer.\n        // This makes sense as the query uses tf/idf/.. for query construction.\n        // We might want to relook and change this in the future though.\n        SchemaField f = req.getSchema().getFieldOrNull(field);\n        if (f != null && f.stored() && f.getType().isExplicitAnalyzer()) {\n          fieldNames.add(field);\n        }\n      }\n    }\n\n    if( fieldNames.size() < 1 ) {\n      throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\n          \"MoreLikeThis requires at least one similarity field: qf\" );\n    }\n\n    mlt.setFieldNames(fieldNames.toArray(new String[fieldNames.size()]));\n    for (String field : fieldNames) {\n      filteredDocument.put(field, doc.getFieldValues(field));\n    }\n\n    try {\n      Query rawMLTQuery = mlt.like(filteredDocument);\n      BooleanQuery boostedMLTQuery = (BooleanQuery) rawMLTQuery;\n\n      if (boostFields.size() > 0) {\n        BooleanQuery.Builder newQ = new BooleanQuery.Builder();\n        newQ.setMinimumNumberShouldMatch(boostedMLTQuery.getMinimumNumberShouldMatch());\n\n        for (BooleanClause clause : boostedMLTQuery) {\n          Query q = clause.getQuery();\n          float originalBoost = 1f;\n          if (q instanceof BoostQuery) {\n            BoostQuery bq = (BoostQuery) q;\n            q = bq.getQuery();\n            originalBoost = bq.getBoost();\n          }\n          Float fieldBoost = boostFields.get(((TermQuery) q).getTerm().field());\n          q = ((fieldBoost != null) ? new BoostQuery(q, fieldBoost * originalBoost) : clause.getQuery());\n          newQ.add(q, clause.getOccur());\n        }\n\n        boostedMLTQuery = newQ.build();\n      }\n\n      // exclude current document from results\n      BooleanQuery.Builder realMLTQuery = new BooleanQuery.Builder();\n      realMLTQuery.add(boostedMLTQuery, BooleanClause.Occur.MUST);\n      realMLTQuery.add(createIdQuery(req.getSchema().getUniqueKeyField().getName(), id), BooleanClause.Occur.MUST_NOT);\n\n      return realMLTQuery.build();\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"39fdbc59d893f5a211736e861fe145798a40b9ff","date":1498161919,"type":3,"author":"yonik","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","sourceNew":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    if(doc == null) {\n      throw new SolrException(\n          SolrException.ErrorCode.BAD_REQUEST, \"Error completing MLT request. Could not fetch \" +\n          \"document with id [\" + id + \"]\");\n    }\n\n    String[] qf = localParams.getParams(\"qf\");\n    Map<String,Float> boostFields = new HashMap<>();\n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n\n    mlt.setMinTermFreq(localParams.getInt(\"mintf\", MoreLikeThis.DEFAULT_MIN_TERM_FREQ));\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n    mlt.setMinWordLen(localParams.getInt(\"minwl\", MoreLikeThis.DEFAULT_MIN_WORD_LENGTH));\n    mlt.setMaxWordLen(localParams.getInt(\"maxwl\", MoreLikeThis.DEFAULT_MAX_WORD_LENGTH));\n    mlt.setMaxQueryTerms(localParams.getInt(\"maxqt\", MoreLikeThis.DEFAULT_MAX_QUERY_TERMS));\n    mlt.setMaxNumTokensParsed(localParams.getInt(\"maxntp\", MoreLikeThis.DEFAULT_MAX_NUM_TOKENS_PARSED));\n    mlt.setMaxDocFreq(localParams.getInt(\"maxdf\", MoreLikeThis.DEFAULT_MAX_DOC_FREQ));\n\n    Boolean boost = localParams.getBool(\"boost\", MoreLikeThis.DEFAULT_BOOST);\n    mlt.setBoost(boost);\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    Map<String, Collection<Object>> filteredDocument = new HashMap<>();\n    String[] fieldNames;\n\n    if (qf != null) {\n      ArrayList<String> fields = new ArrayList();\n      for (String fieldName : qf) {\n        if (!StringUtils.isEmpty(fieldName))  {\n          String[] strings = splitList.split(fieldName);\n          for (String string : strings) {\n            if (!StringUtils.isEmpty(string)) {\n              fields.add(string);\n            }\n          }\n        }\n      }\n      // Parse field names and boosts from the fields\n      boostFields = SolrPluginUtils.parseFieldBoosts(fields.toArray(new String[0]));\n      fieldNames = boostFields.keySet().toArray(new String[0]);\n    } else {\n      ArrayList<String> fields = new ArrayList();\n      for (String field : doc.getFieldNames()) {\n        // Only use fields that are stored and have an explicit analyzer.\n        // This makes sense as the query uses tf/idf/.. for query construction.\n        // We might want to relook and change this in the future though.\n        SchemaField f = req.getSchema().getFieldOrNull(field);\n        if (f != null && f.stored() && f.getType().isExplicitAnalyzer()) {\n          fields.add(field);\n        }\n      }\n      fieldNames = fields.toArray(new String[0]);\n    }\n\n    if (fieldNames.length < 1) {\n      throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\n          \"MoreLikeThis requires at least one similarity field: qf\" );\n    }\n\n    mlt.setFieldNames(fieldNames);\n    for (String field : fieldNames) {\n      Collection<Object> fieldValues = doc.getFieldValues(field);\n      if (fieldValues != null) {\n        Collection<Object> values = new ArrayList();\n        for (Object val : fieldValues) {\n          if (val instanceof IndexableField) {\n            values.add(((IndexableField)val).stringValue());\n          }\n          else {\n            values.add(val);\n          }\n        }\n        filteredDocument.put(field, values);\n      }\n    }\n\n    try {\n      Query rawMLTQuery = mlt.like(filteredDocument);\n      BooleanQuery boostedMLTQuery = (BooleanQuery) rawMLTQuery;\n\n      if (boost && boostFields.size() > 0) {\n        BooleanQuery.Builder newQ = new BooleanQuery.Builder();\n        newQ.setMinimumNumberShouldMatch(boostedMLTQuery.getMinimumNumberShouldMatch());\n\n        for (BooleanClause clause : boostedMLTQuery) {\n          Query q = clause.getQuery();\n          float originalBoost = 1f;\n          if (q instanceof BoostQuery) {\n            BoostQuery bq = (BoostQuery) q;\n            q = bq.getQuery();\n            originalBoost = bq.getBoost();\n          }\n          Float fieldBoost = boostFields.get(((TermQuery) q).getTerm().field());\n          q = ((fieldBoost != null) ? new BoostQuery(q, fieldBoost * originalBoost) : clause.getQuery());\n          newQ.add(q, clause.getOccur());\n        }\n\n        boostedMLTQuery = QueryUtils.build(newQ, this);\n      }\n\n      // exclude current document from results\n      BooleanQuery.Builder realMLTQuery = new BooleanQuery.Builder();\n      realMLTQuery.add(boostedMLTQuery, BooleanClause.Occur.MUST);\n      realMLTQuery.add(createIdQuery(req.getSchema().getUniqueKeyField().getName(), id), BooleanClause.Occur.MUST_NOT);\n\n      return realMLTQuery.build();\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","sourceOld":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    if(doc == null) {\n      throw new SolrException(\n          SolrException.ErrorCode.BAD_REQUEST, \"Error completing MLT request. Could not fetch \" +\n          \"document with id [\" + id + \"]\");\n    }\n\n    String[] qf = localParams.getParams(\"qf\");\n    Map<String,Float> boostFields = new HashMap<>();\n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n\n    mlt.setMinTermFreq(localParams.getInt(\"mintf\", MoreLikeThis.DEFAULT_MIN_TERM_FREQ));\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n    mlt.setMinWordLen(localParams.getInt(\"minwl\", MoreLikeThis.DEFAULT_MIN_WORD_LENGTH));\n    mlt.setMaxWordLen(localParams.getInt(\"maxwl\", MoreLikeThis.DEFAULT_MAX_WORD_LENGTH));\n    mlt.setMaxQueryTerms(localParams.getInt(\"maxqt\", MoreLikeThis.DEFAULT_MAX_QUERY_TERMS));\n    mlt.setMaxNumTokensParsed(localParams.getInt(\"maxntp\", MoreLikeThis.DEFAULT_MAX_NUM_TOKENS_PARSED));\n    mlt.setMaxDocFreq(localParams.getInt(\"maxdf\", MoreLikeThis.DEFAULT_MAX_DOC_FREQ));\n\n    Boolean boost = localParams.getBool(\"boost\", MoreLikeThis.DEFAULT_BOOST);\n    mlt.setBoost(boost);\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    Map<String, Collection<Object>> filteredDocument = new HashMap<>();\n    String[] fieldNames;\n\n    if (qf != null) {\n      ArrayList<String> fields = new ArrayList();\n      for (String fieldName : qf) {\n        if (!StringUtils.isEmpty(fieldName))  {\n          String[] strings = splitList.split(fieldName);\n          for (String string : strings) {\n            if (!StringUtils.isEmpty(string)) {\n              fields.add(string);\n            }\n          }\n        }\n      }\n      // Parse field names and boosts from the fields\n      boostFields = SolrPluginUtils.parseFieldBoosts(fields.toArray(new String[0]));\n      fieldNames = boostFields.keySet().toArray(new String[0]);\n    } else {\n      ArrayList<String> fields = new ArrayList();\n      for (String field : doc.getFieldNames()) {\n        // Only use fields that are stored and have an explicit analyzer.\n        // This makes sense as the query uses tf/idf/.. for query construction.\n        // We might want to relook and change this in the future though.\n        SchemaField f = req.getSchema().getFieldOrNull(field);\n        if (f != null && f.stored() && f.getType().isExplicitAnalyzer()) {\n          fields.add(field);\n        }\n      }\n      fieldNames = fields.toArray(new String[0]);\n    }\n\n    if (fieldNames.length < 1) {\n      throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\n          \"MoreLikeThis requires at least one similarity field: qf\" );\n    }\n\n    mlt.setFieldNames(fieldNames);\n    for (String field : fieldNames) {\n      Collection<Object> fieldValues = doc.getFieldValues(field);\n      if (fieldValues != null) {\n        Collection<Object> values = new ArrayList();\n        for (Object val : fieldValues) {\n          if (val instanceof IndexableField) {\n            values.add(((IndexableField)val).stringValue());\n          }\n          else {\n            values.add(val);\n          }\n        }\n        filteredDocument.put(field, values);\n      }\n    }\n\n    try {\n      Query rawMLTQuery = mlt.like(filteredDocument);\n      BooleanQuery boostedMLTQuery = (BooleanQuery) rawMLTQuery;\n\n      if (boost && boostFields.size() > 0) {\n        BooleanQuery.Builder newQ = new BooleanQuery.Builder();\n        newQ.setMinimumNumberShouldMatch(boostedMLTQuery.getMinimumNumberShouldMatch());\n\n        for (BooleanClause clause : boostedMLTQuery) {\n          Query q = clause.getQuery();\n          float originalBoost = 1f;\n          if (q instanceof BoostQuery) {\n            BoostQuery bq = (BoostQuery) q;\n            q = bq.getQuery();\n            originalBoost = bq.getBoost();\n          }\n          Float fieldBoost = boostFields.get(((TermQuery) q).getTerm().field());\n          q = ((fieldBoost != null) ? new BoostQuery(q, fieldBoost * originalBoost) : clause.getQuery());\n          newQ.add(q, clause.getOccur());\n        }\n\n        boostedMLTQuery = newQ.build();\n      }\n\n      // exclude current document from results\n      BooleanQuery.Builder realMLTQuery = new BooleanQuery.Builder();\n      realMLTQuery.add(boostedMLTQuery, BooleanClause.Occur.MUST);\n      realMLTQuery.add(createIdQuery(req.getSchema().getUniqueKeyField().getName(), id), BooleanClause.Occur.MUST_NOT);\n\n      return realMLTQuery.build();\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7dfa64bc2074fb87d0ca70095a644c1ead107e1","date":1498356339,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","sourceNew":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    if(doc == null) {\n      throw new SolrException(\n          SolrException.ErrorCode.BAD_REQUEST, \"Error completing MLT request. Could not fetch \" +\n          \"document with id [\" + id + \"]\");\n    }\n\n    String[] qf = localParams.getParams(\"qf\");\n    Map<String,Float> boostFields = new HashMap<>();\n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n\n    mlt.setMinTermFreq(localParams.getInt(\"mintf\", MoreLikeThis.DEFAULT_MIN_TERM_FREQ));\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n    mlt.setMinWordLen(localParams.getInt(\"minwl\", MoreLikeThis.DEFAULT_MIN_WORD_LENGTH));\n    mlt.setMaxWordLen(localParams.getInt(\"maxwl\", MoreLikeThis.DEFAULT_MAX_WORD_LENGTH));\n    mlt.setMaxQueryTerms(localParams.getInt(\"maxqt\", MoreLikeThis.DEFAULT_MAX_QUERY_TERMS));\n    mlt.setMaxNumTokensParsed(localParams.getInt(\"maxntp\", MoreLikeThis.DEFAULT_MAX_NUM_TOKENS_PARSED));\n    mlt.setMaxDocFreq(localParams.getInt(\"maxdf\", MoreLikeThis.DEFAULT_MAX_DOC_FREQ));\n\n    Boolean boost = localParams.getBool(\"boost\", MoreLikeThis.DEFAULT_BOOST);\n    mlt.setBoost(boost);\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    Map<String, Collection<Object>> filteredDocument = new HashMap<>();\n    String[] fieldNames;\n\n    if (qf != null) {\n      ArrayList<String> fields = new ArrayList();\n      for (String fieldName : qf) {\n        if (!StringUtils.isEmpty(fieldName))  {\n          String[] strings = splitList.split(fieldName);\n          for (String string : strings) {\n            if (!StringUtils.isEmpty(string)) {\n              fields.add(string);\n            }\n          }\n        }\n      }\n      // Parse field names and boosts from the fields\n      boostFields = SolrPluginUtils.parseFieldBoosts(fields.toArray(new String[0]));\n      fieldNames = boostFields.keySet().toArray(new String[0]);\n    } else {\n      ArrayList<String> fields = new ArrayList();\n      for (String field : doc.getFieldNames()) {\n        // Only use fields that are stored and have an explicit analyzer.\n        // This makes sense as the query uses tf/idf/.. for query construction.\n        // We might want to relook and change this in the future though.\n        SchemaField f = req.getSchema().getFieldOrNull(field);\n        if (f != null && f.stored() && f.getType().isExplicitAnalyzer()) {\n          fields.add(field);\n        }\n      }\n      fieldNames = fields.toArray(new String[0]);\n    }\n\n    if (fieldNames.length < 1) {\n      throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\n          \"MoreLikeThis requires at least one similarity field: qf\" );\n    }\n\n    mlt.setFieldNames(fieldNames);\n    for (String field : fieldNames) {\n      Collection<Object> fieldValues = doc.getFieldValues(field);\n      if (fieldValues != null) {\n        Collection<Object> values = new ArrayList();\n        for (Object val : fieldValues) {\n          if (val instanceof IndexableField) {\n            values.add(((IndexableField)val).stringValue());\n          }\n          else {\n            values.add(val);\n          }\n        }\n        filteredDocument.put(field, values);\n      }\n    }\n\n    try {\n      Query rawMLTQuery = mlt.like(filteredDocument);\n      BooleanQuery boostedMLTQuery = (BooleanQuery) rawMLTQuery;\n\n      if (boost && boostFields.size() > 0) {\n        BooleanQuery.Builder newQ = new BooleanQuery.Builder();\n        newQ.setMinimumNumberShouldMatch(boostedMLTQuery.getMinimumNumberShouldMatch());\n\n        for (BooleanClause clause : boostedMLTQuery) {\n          Query q = clause.getQuery();\n          float originalBoost = 1f;\n          if (q instanceof BoostQuery) {\n            BoostQuery bq = (BoostQuery) q;\n            q = bq.getQuery();\n            originalBoost = bq.getBoost();\n          }\n          Float fieldBoost = boostFields.get(((TermQuery) q).getTerm().field());\n          q = ((fieldBoost != null) ? new BoostQuery(q, fieldBoost * originalBoost) : clause.getQuery());\n          newQ.add(q, clause.getOccur());\n        }\n\n        boostedMLTQuery = QueryUtils.build(newQ, this);\n      }\n\n      // exclude current document from results\n      BooleanQuery.Builder realMLTQuery = new BooleanQuery.Builder();\n      realMLTQuery.add(boostedMLTQuery, BooleanClause.Occur.MUST);\n      realMLTQuery.add(createIdQuery(req.getSchema().getUniqueKeyField().getName(), id), BooleanClause.Occur.MUST_NOT);\n\n      return realMLTQuery.build();\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","sourceOld":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    if(doc == null) {\n      throw new SolrException(\n          SolrException.ErrorCode.BAD_REQUEST, \"Error completing MLT request. Could not fetch \" +\n          \"document with id [\" + id + \"]\");\n    }\n\n    String[] qf = localParams.getParams(\"qf\");\n    Map<String,Float> boostFields = new HashMap<>();\n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n\n    mlt.setMinTermFreq(localParams.getInt(\"mintf\", MoreLikeThis.DEFAULT_MIN_TERM_FREQ));\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n    mlt.setMinWordLen(localParams.getInt(\"minwl\", MoreLikeThis.DEFAULT_MIN_WORD_LENGTH));\n    mlt.setMaxWordLen(localParams.getInt(\"maxwl\", MoreLikeThis.DEFAULT_MAX_WORD_LENGTH));\n    mlt.setMaxQueryTerms(localParams.getInt(\"maxqt\", MoreLikeThis.DEFAULT_MAX_QUERY_TERMS));\n    mlt.setMaxNumTokensParsed(localParams.getInt(\"maxntp\", MoreLikeThis.DEFAULT_MAX_NUM_TOKENS_PARSED));\n    mlt.setMaxDocFreq(localParams.getInt(\"maxdf\", MoreLikeThis.DEFAULT_MAX_DOC_FREQ));\n\n    Boolean boost = localParams.getBool(\"boost\", MoreLikeThis.DEFAULT_BOOST);\n    mlt.setBoost(boost);\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    Map<String, Collection<Object>> filteredDocument = new HashMap<>();\n    String[] fieldNames;\n\n    if (qf != null) {\n      ArrayList<String> fields = new ArrayList();\n      for (String fieldName : qf) {\n        if (!StringUtils.isEmpty(fieldName))  {\n          String[] strings = splitList.split(fieldName);\n          for (String string : strings) {\n            if (!StringUtils.isEmpty(string)) {\n              fields.add(string);\n            }\n          }\n        }\n      }\n      // Parse field names and boosts from the fields\n      boostFields = SolrPluginUtils.parseFieldBoosts(fields.toArray(new String[0]));\n      fieldNames = boostFields.keySet().toArray(new String[0]);\n    } else {\n      ArrayList<String> fields = new ArrayList();\n      for (String field : doc.getFieldNames()) {\n        // Only use fields that are stored and have an explicit analyzer.\n        // This makes sense as the query uses tf/idf/.. for query construction.\n        // We might want to relook and change this in the future though.\n        SchemaField f = req.getSchema().getFieldOrNull(field);\n        if (f != null && f.stored() && f.getType().isExplicitAnalyzer()) {\n          fields.add(field);\n        }\n      }\n      fieldNames = fields.toArray(new String[0]);\n    }\n\n    if (fieldNames.length < 1) {\n      throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\n          \"MoreLikeThis requires at least one similarity field: qf\" );\n    }\n\n    mlt.setFieldNames(fieldNames);\n    for (String field : fieldNames) {\n      Collection<Object> fieldValues = doc.getFieldValues(field);\n      if (fieldValues != null) {\n        Collection<Object> values = new ArrayList();\n        for (Object val : fieldValues) {\n          if (val instanceof IndexableField) {\n            values.add(((IndexableField)val).stringValue());\n          }\n          else {\n            values.add(val);\n          }\n        }\n        filteredDocument.put(field, values);\n      }\n    }\n\n    try {\n      Query rawMLTQuery = mlt.like(filteredDocument);\n      BooleanQuery boostedMLTQuery = (BooleanQuery) rawMLTQuery;\n\n      if (boost && boostFields.size() > 0) {\n        BooleanQuery.Builder newQ = new BooleanQuery.Builder();\n        newQ.setMinimumNumberShouldMatch(boostedMLTQuery.getMinimumNumberShouldMatch());\n\n        for (BooleanClause clause : boostedMLTQuery) {\n          Query q = clause.getQuery();\n          float originalBoost = 1f;\n          if (q instanceof BoostQuery) {\n            BoostQuery bq = (BoostQuery) q;\n            q = bq.getQuery();\n            originalBoost = bq.getBoost();\n          }\n          Float fieldBoost = boostFields.get(((TermQuery) q).getTerm().field());\n          q = ((fieldBoost != null) ? new BoostQuery(q, fieldBoost * originalBoost) : clause.getQuery());\n          newQ.add(q, clause.getOccur());\n        }\n\n        boostedMLTQuery = newQ.build();\n      }\n\n      // exclude current document from results\n      BooleanQuery.Builder realMLTQuery = new BooleanQuery.Builder();\n      realMLTQuery.add(boostedMLTQuery, BooleanClause.Occur.MUST);\n      realMLTQuery.add(createIdQuery(req.getSchema().getUniqueKeyField().getName(), id), BooleanClause.Occur.MUST_NOT);\n\n      return realMLTQuery.build();\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"28288370235ed02234a64753cdbf0c6ec096304a","date":1498726817,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","sourceNew":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    if(doc == null) {\n      throw new SolrException(\n          SolrException.ErrorCode.BAD_REQUEST, \"Error completing MLT request. Could not fetch \" +\n          \"document with id [\" + id + \"]\");\n    }\n\n    String[] qf = localParams.getParams(\"qf\");\n    Map<String,Float> boostFields = new HashMap<>();\n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n\n    mlt.setMinTermFreq(localParams.getInt(\"mintf\", MoreLikeThis.DEFAULT_MIN_TERM_FREQ));\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n    mlt.setMinWordLen(localParams.getInt(\"minwl\", MoreLikeThis.DEFAULT_MIN_WORD_LENGTH));\n    mlt.setMaxWordLen(localParams.getInt(\"maxwl\", MoreLikeThis.DEFAULT_MAX_WORD_LENGTH));\n    mlt.setMaxQueryTerms(localParams.getInt(\"maxqt\", MoreLikeThis.DEFAULT_MAX_QUERY_TERMS));\n    mlt.setMaxNumTokensParsed(localParams.getInt(\"maxntp\", MoreLikeThis.DEFAULT_MAX_NUM_TOKENS_PARSED));\n    mlt.setMaxDocFreq(localParams.getInt(\"maxdf\", MoreLikeThis.DEFAULT_MAX_DOC_FREQ));\n\n    Boolean boost = localParams.getBool(\"boost\", MoreLikeThis.DEFAULT_BOOST);\n    mlt.setBoost(boost);\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    Map<String, Collection<Object>> filteredDocument = new HashMap<>();\n    String[] fieldNames;\n\n    if (qf != null) {\n      ArrayList<String> fields = new ArrayList();\n      for (String fieldName : qf) {\n        if (!StringUtils.isEmpty(fieldName))  {\n          String[] strings = splitList.split(fieldName);\n          for (String string : strings) {\n            if (!StringUtils.isEmpty(string)) {\n              fields.add(string);\n            }\n          }\n        }\n      }\n      // Parse field names and boosts from the fields\n      boostFields = SolrPluginUtils.parseFieldBoosts(fields.toArray(new String[0]));\n      fieldNames = boostFields.keySet().toArray(new String[0]);\n    } else {\n      ArrayList<String> fields = new ArrayList();\n      for (String field : doc.getFieldNames()) {\n        // Only use fields that are stored and have an explicit analyzer.\n        // This makes sense as the query uses tf/idf/.. for query construction.\n        // We might want to relook and change this in the future though.\n        SchemaField f = req.getSchema().getFieldOrNull(field);\n        if (f != null && f.stored() && f.getType().isExplicitAnalyzer()) {\n          fields.add(field);\n        }\n      }\n      fieldNames = fields.toArray(new String[0]);\n    }\n\n    if (fieldNames.length < 1) {\n      throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\n          \"MoreLikeThis requires at least one similarity field: qf\" );\n    }\n\n    mlt.setFieldNames(fieldNames);\n    for (String field : fieldNames) {\n      Collection<Object> fieldValues = doc.getFieldValues(field);\n      if (fieldValues != null) {\n        Collection<Object> values = new ArrayList();\n        for (Object val : fieldValues) {\n          if (val instanceof IndexableField) {\n            values.add(((IndexableField)val).stringValue());\n          }\n          else {\n            values.add(val);\n          }\n        }\n        filteredDocument.put(field, values);\n      }\n    }\n\n    try {\n      Query rawMLTQuery = mlt.like(filteredDocument);\n      BooleanQuery boostedMLTQuery = (BooleanQuery) rawMLTQuery;\n\n      if (boost && boostFields.size() > 0) {\n        BooleanQuery.Builder newQ = new BooleanQuery.Builder();\n        newQ.setMinimumNumberShouldMatch(boostedMLTQuery.getMinimumNumberShouldMatch());\n\n        for (BooleanClause clause : boostedMLTQuery) {\n          Query q = clause.getQuery();\n          float originalBoost = 1f;\n          if (q instanceof BoostQuery) {\n            BoostQuery bq = (BoostQuery) q;\n            q = bq.getQuery();\n            originalBoost = bq.getBoost();\n          }\n          Float fieldBoost = boostFields.get(((TermQuery) q).getTerm().field());\n          q = ((fieldBoost != null) ? new BoostQuery(q, fieldBoost * originalBoost) : clause.getQuery());\n          newQ.add(q, clause.getOccur());\n        }\n\n        boostedMLTQuery = QueryUtils.build(newQ, this);\n      }\n\n      // exclude current document from results\n      BooleanQuery.Builder realMLTQuery = new BooleanQuery.Builder();\n      realMLTQuery.add(boostedMLTQuery, BooleanClause.Occur.MUST);\n      realMLTQuery.add(createIdQuery(req.getSchema().getUniqueKeyField().getName(), id), BooleanClause.Occur.MUST_NOT);\n\n      return realMLTQuery.build();\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","sourceOld":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    if(doc == null) {\n      throw new SolrException(\n          SolrException.ErrorCode.BAD_REQUEST, \"Error completing MLT request. Could not fetch \" +\n          \"document with id [\" + id + \"]\");\n    }\n\n    String[] qf = localParams.getParams(\"qf\");\n    Map<String,Float> boostFields = new HashMap<>();\n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n\n    mlt.setMinTermFreq(localParams.getInt(\"mintf\", MoreLikeThis.DEFAULT_MIN_TERM_FREQ));\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n    mlt.setMinWordLen(localParams.getInt(\"minwl\", MoreLikeThis.DEFAULT_MIN_WORD_LENGTH));\n    mlt.setMaxWordLen(localParams.getInt(\"maxwl\", MoreLikeThis.DEFAULT_MAX_WORD_LENGTH));\n    mlt.setMaxQueryTerms(localParams.getInt(\"maxqt\", MoreLikeThis.DEFAULT_MAX_QUERY_TERMS));\n    mlt.setMaxNumTokensParsed(localParams.getInt(\"maxntp\", MoreLikeThis.DEFAULT_MAX_NUM_TOKENS_PARSED));\n    mlt.setMaxDocFreq(localParams.getInt(\"maxdf\", MoreLikeThis.DEFAULT_MAX_DOC_FREQ));\n\n    Boolean boost = localParams.getBool(\"boost\", MoreLikeThis.DEFAULT_BOOST);\n    mlt.setBoost(boost);\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    Map<String, Collection<Object>> filteredDocument = new HashMap<>();\n    String[] fieldNames;\n\n    if (qf != null) {\n      ArrayList<String> fields = new ArrayList();\n      for (String fieldName : qf) {\n        if (!StringUtils.isEmpty(fieldName))  {\n          String[] strings = splitList.split(fieldName);\n          for (String string : strings) {\n            if (!StringUtils.isEmpty(string)) {\n              fields.add(string);\n            }\n          }\n        }\n      }\n      // Parse field names and boosts from the fields\n      boostFields = SolrPluginUtils.parseFieldBoosts(fields.toArray(new String[0]));\n      fieldNames = boostFields.keySet().toArray(new String[0]);\n    } else {\n      ArrayList<String> fields = new ArrayList();\n      for (String field : doc.getFieldNames()) {\n        // Only use fields that are stored and have an explicit analyzer.\n        // This makes sense as the query uses tf/idf/.. for query construction.\n        // We might want to relook and change this in the future though.\n        SchemaField f = req.getSchema().getFieldOrNull(field);\n        if (f != null && f.stored() && f.getType().isExplicitAnalyzer()) {\n          fields.add(field);\n        }\n      }\n      fieldNames = fields.toArray(new String[0]);\n    }\n\n    if (fieldNames.length < 1) {\n      throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\n          \"MoreLikeThis requires at least one similarity field: qf\" );\n    }\n\n    mlt.setFieldNames(fieldNames);\n    for (String field : fieldNames) {\n      Collection<Object> fieldValues = doc.getFieldValues(field);\n      if (fieldValues != null) {\n        Collection<Object> values = new ArrayList();\n        for (Object val : fieldValues) {\n          if (val instanceof IndexableField) {\n            values.add(((IndexableField)val).stringValue());\n          }\n          else {\n            values.add(val);\n          }\n        }\n        filteredDocument.put(field, values);\n      }\n    }\n\n    try {\n      Query rawMLTQuery = mlt.like(filteredDocument);\n      BooleanQuery boostedMLTQuery = (BooleanQuery) rawMLTQuery;\n\n      if (boost && boostFields.size() > 0) {\n        BooleanQuery.Builder newQ = new BooleanQuery.Builder();\n        newQ.setMinimumNumberShouldMatch(boostedMLTQuery.getMinimumNumberShouldMatch());\n\n        for (BooleanClause clause : boostedMLTQuery) {\n          Query q = clause.getQuery();\n          float originalBoost = 1f;\n          if (q instanceof BoostQuery) {\n            BoostQuery bq = (BoostQuery) q;\n            q = bq.getQuery();\n            originalBoost = bq.getBoost();\n          }\n          Float fieldBoost = boostFields.get(((TermQuery) q).getTerm().field());\n          q = ((fieldBoost != null) ? new BoostQuery(q, fieldBoost * originalBoost) : clause.getQuery());\n          newQ.add(q, clause.getOccur());\n        }\n\n        boostedMLTQuery = newQ.build();\n      }\n\n      // exclude current document from results\n      BooleanQuery.Builder realMLTQuery = new BooleanQuery.Builder();\n      realMLTQuery.add(boostedMLTQuery, BooleanClause.Occur.MUST);\n      realMLTQuery.add(createIdQuery(req.getSchema().getUniqueKeyField().getName(), id), BooleanClause.Occur.MUST_NOT);\n\n      return realMLTQuery.build();\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0db83f1bb855a4ac824c9a2a8e1ee9b29a039c15","date":1554259533,"type":3,"author":"Gus Heck","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","sourceNew":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    if(doc == null) {\n      throw new SolrException(\n          SolrException.ErrorCode.BAD_REQUEST, \"Error completing MLT request. Could not fetch \" +\n          \"document with id [\" + id + \"]\");\n    }\n\n    String[] qf = localParams.getParams(\"qf\");\n    Map<String,Float> boostFields = new HashMap<>();\n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n\n    mlt.setMinTermFreq(localParams.getInt(\"mintf\", MoreLikeThis.DEFAULT_MIN_TERM_FREQ));\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n    mlt.setMinWordLen(localParams.getInt(\"minwl\", MoreLikeThis.DEFAULT_MIN_WORD_LENGTH));\n    mlt.setMaxWordLen(localParams.getInt(\"maxwl\", MoreLikeThis.DEFAULT_MAX_WORD_LENGTH));\n    mlt.setMaxQueryTerms(localParams.getInt(\"maxqt\", MoreLikeThis.DEFAULT_MAX_QUERY_TERMS));\n    mlt.setMaxNumTokensParsed(localParams.getInt(\"maxntp\", MoreLikeThis.DEFAULT_MAX_NUM_TOKENS_PARSED));\n    mlt.setMaxDocFreq(localParams.getInt(\"maxdf\", MoreLikeThis.DEFAULT_MAX_DOC_FREQ));\n\n    Boolean boost = localParams.getBool(\"boost\", MoreLikeThis.DEFAULT_BOOST);\n    mlt.setBoost(boost);\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    Map<String, Collection<Object>> filteredDocument = new HashMap<>();\n    String[] fieldNames;\n\n    if (qf != null) {\n      ArrayList<String> fields = new ArrayList();\n      for (String fieldName : qf) {\n        if (!StringUtils.isEmpty(fieldName))  {\n          String[] strings = splitList.split(fieldName);\n          for (String string : strings) {\n            if (!StringUtils.isEmpty(string)) {\n              fields.add(string);\n            }\n          }\n        }\n      }\n      // Parse field names and boosts from the fields\n      boostFields = SolrPluginUtils.parseFieldBoosts(fields.toArray(new String[0]));\n      fieldNames = boostFields.keySet().toArray(new String[0]);\n    } else {\n      ArrayList<String> fields = new ArrayList();\n      for (String field : doc.getFieldNames()) {\n        // Only use fields that are stored and have an explicit analyzer.\n        // This makes sense as the query uses tf/idf/.. for query construction.\n        // We might want to relook and change this in the future though.\n        SchemaField f = req.getSchema().getFieldOrNull(field);\n        if (f != null && f.stored() && f.getType().isExplicitAnalyzer()) {\n          fields.add(field);\n        }\n      }\n      fieldNames = fields.toArray(new String[0]);\n    }\n\n    if (fieldNames.length < 1) {\n      throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\n          \"MoreLikeThis requires at least one similarity field: qf\" );\n    }\n\n    mlt.setFieldNames(fieldNames);\n    for (String field : fieldNames) {\n      Collection<Object> fieldValues = doc.getFieldValues(field);\n      if (fieldValues != null) {\n        Collection<Object> values = new ArrayList();\n        for (Object val : fieldValues) {\n          if (val instanceof IndexableField) {\n            values.add(((IndexableField)val).stringValue());\n          }\n          else {\n            values.add(val);\n          }\n        }\n        filteredDocument.put(field, values);\n      }\n    }\n\n    try {\n      Query rawMLTQuery = mlt.like(filteredDocument);\n      BooleanQuery boostedMLTQuery = (BooleanQuery) rawMLTQuery;\n\n      if (boost && boostFields.size() > 0) {\n        BooleanQuery.Builder newQ = new BooleanQuery.Builder();\n        newQ.setMinimumNumberShouldMatch(boostedMLTQuery.getMinimumNumberShouldMatch());\n\n        for (BooleanClause clause : boostedMLTQuery) {\n          Query q = clause.getQuery();\n          float originalBoost = 1f;\n          if (q instanceof BoostQuery) {\n            BoostQuery bq = (BoostQuery) q;\n            q = bq.getQuery();\n            originalBoost = bq.getBoost();\n          }\n          Float fieldBoost = boostFields.get(((TermQuery) q).getTerm().field());\n          q = ((fieldBoost != null) ? new BoostQuery(q, fieldBoost * originalBoost) : clause.getQuery());\n          newQ.add(q, clause.getOccur());\n        }\n\n        boostedMLTQuery = QueryUtils.build(newQ, this);\n      }\n\n      // exclude current document from results\n      BooleanQuery.Builder realMLTQuery = new BooleanQuery.Builder();\n      realMLTQuery.add(boostedMLTQuery, BooleanClause.Occur.MUST);\n      realMLTQuery.add(createIdQuery(req.getSchema().getUniqueKeyField().getName(), id), BooleanClause.Occur.MUST_NOT);\n\n      return realMLTQuery.build();\n    } catch (IOException e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\", e);\n    }\n\n  }\n\n","sourceOld":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    if(doc == null) {\n      throw new SolrException(\n          SolrException.ErrorCode.BAD_REQUEST, \"Error completing MLT request. Could not fetch \" +\n          \"document with id [\" + id + \"]\");\n    }\n\n    String[] qf = localParams.getParams(\"qf\");\n    Map<String,Float> boostFields = new HashMap<>();\n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n\n    mlt.setMinTermFreq(localParams.getInt(\"mintf\", MoreLikeThis.DEFAULT_MIN_TERM_FREQ));\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n    mlt.setMinWordLen(localParams.getInt(\"minwl\", MoreLikeThis.DEFAULT_MIN_WORD_LENGTH));\n    mlt.setMaxWordLen(localParams.getInt(\"maxwl\", MoreLikeThis.DEFAULT_MAX_WORD_LENGTH));\n    mlt.setMaxQueryTerms(localParams.getInt(\"maxqt\", MoreLikeThis.DEFAULT_MAX_QUERY_TERMS));\n    mlt.setMaxNumTokensParsed(localParams.getInt(\"maxntp\", MoreLikeThis.DEFAULT_MAX_NUM_TOKENS_PARSED));\n    mlt.setMaxDocFreq(localParams.getInt(\"maxdf\", MoreLikeThis.DEFAULT_MAX_DOC_FREQ));\n\n    Boolean boost = localParams.getBool(\"boost\", MoreLikeThis.DEFAULT_BOOST);\n    mlt.setBoost(boost);\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    Map<String, Collection<Object>> filteredDocument = new HashMap<>();\n    String[] fieldNames;\n\n    if (qf != null) {\n      ArrayList<String> fields = new ArrayList();\n      for (String fieldName : qf) {\n        if (!StringUtils.isEmpty(fieldName))  {\n          String[] strings = splitList.split(fieldName);\n          for (String string : strings) {\n            if (!StringUtils.isEmpty(string)) {\n              fields.add(string);\n            }\n          }\n        }\n      }\n      // Parse field names and boosts from the fields\n      boostFields = SolrPluginUtils.parseFieldBoosts(fields.toArray(new String[0]));\n      fieldNames = boostFields.keySet().toArray(new String[0]);\n    } else {\n      ArrayList<String> fields = new ArrayList();\n      for (String field : doc.getFieldNames()) {\n        // Only use fields that are stored and have an explicit analyzer.\n        // This makes sense as the query uses tf/idf/.. for query construction.\n        // We might want to relook and change this in the future though.\n        SchemaField f = req.getSchema().getFieldOrNull(field);\n        if (f != null && f.stored() && f.getType().isExplicitAnalyzer()) {\n          fields.add(field);\n        }\n      }\n      fieldNames = fields.toArray(new String[0]);\n    }\n\n    if (fieldNames.length < 1) {\n      throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\n          \"MoreLikeThis requires at least one similarity field: qf\" );\n    }\n\n    mlt.setFieldNames(fieldNames);\n    for (String field : fieldNames) {\n      Collection<Object> fieldValues = doc.getFieldValues(field);\n      if (fieldValues != null) {\n        Collection<Object> values = new ArrayList();\n        for (Object val : fieldValues) {\n          if (val instanceof IndexableField) {\n            values.add(((IndexableField)val).stringValue());\n          }\n          else {\n            values.add(val);\n          }\n        }\n        filteredDocument.put(field, values);\n      }\n    }\n\n    try {\n      Query rawMLTQuery = mlt.like(filteredDocument);\n      BooleanQuery boostedMLTQuery = (BooleanQuery) rawMLTQuery;\n\n      if (boost && boostFields.size() > 0) {\n        BooleanQuery.Builder newQ = new BooleanQuery.Builder();\n        newQ.setMinimumNumberShouldMatch(boostedMLTQuery.getMinimumNumberShouldMatch());\n\n        for (BooleanClause clause : boostedMLTQuery) {\n          Query q = clause.getQuery();\n          float originalBoost = 1f;\n          if (q instanceof BoostQuery) {\n            BoostQuery bq = (BoostQuery) q;\n            q = bq.getQuery();\n            originalBoost = bq.getBoost();\n          }\n          Float fieldBoost = boostFields.get(((TermQuery) q).getTerm().field());\n          q = ((fieldBoost != null) ? new BoostQuery(q, fieldBoost * originalBoost) : clause.getQuery());\n          newQ.add(q, clause.getOccur());\n        }\n\n        boostedMLTQuery = QueryUtils.build(newQ, this);\n      }\n\n      // exclude current document from results\n      BooleanQuery.Builder realMLTQuery = new BooleanQuery.Builder();\n      realMLTQuery.add(boostedMLTQuery, BooleanClause.Occur.MUST);\n      realMLTQuery.add(createIdQuery(req.getSchema().getUniqueKeyField().getName(), id), BooleanClause.Occur.MUST_NOT);\n\n      return realMLTQuery.build();\n    } catch (IOException e) {\n      e.printStackTrace();\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\");\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"50dfd19525c8d73e856dca6edb64b7aea074037f","date":1591579225,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser#parse().mjava","sourceNew":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    if(doc == null) {\n      throw new SolrException(\n          SolrException.ErrorCode.BAD_REQUEST, \"Error completing MLT request. Could not fetch \" +\n          \"document with id [\" + id + \"]\");\n    }\n\n    String[] qf = localParams.getParams(\"qf\");\n    Map<String,Float> boostFields = new HashMap<>();\n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n\n    mlt.setMinTermFreq(localParams.getInt(\"mintf\", MoreLikeThis.DEFAULT_MIN_TERM_FREQ));\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n    mlt.setMinWordLen(localParams.getInt(\"minwl\", MoreLikeThis.DEFAULT_MIN_WORD_LENGTH));\n    mlt.setMaxWordLen(localParams.getInt(\"maxwl\", MoreLikeThis.DEFAULT_MAX_WORD_LENGTH));\n    mlt.setMaxQueryTerms(localParams.getInt(\"maxqt\", MoreLikeThis.DEFAULT_MAX_QUERY_TERMS));\n    mlt.setMaxNumTokensParsed(localParams.getInt(\"maxntp\", MoreLikeThis.DEFAULT_MAX_NUM_TOKENS_PARSED));\n    mlt.setMaxDocFreq(localParams.getInt(\"maxdf\", MoreLikeThis.DEFAULT_MAX_DOC_FREQ));\n\n    Boolean boost = localParams.getBool(\"boost\", MoreLikeThis.DEFAULT_BOOST);\n    mlt.setBoost(boost);\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    Map<String, Collection<Object>> filteredDocument = new HashMap<>();\n    String[] fieldNames;\n\n    if (qf != null) {\n      @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n      ArrayList<String> fields = new ArrayList();\n      for (String fieldName : qf) {\n        if (!StringUtils.isEmpty(fieldName))  {\n          String[] strings = splitList.split(fieldName);\n          for (String string : strings) {\n            if (!StringUtils.isEmpty(string)) {\n              fields.add(string);\n            }\n          }\n        }\n      }\n      // Parse field names and boosts from the fields\n      boostFields = SolrPluginUtils.parseFieldBoosts(fields.toArray(new String[0]));\n      fieldNames = boostFields.keySet().toArray(new String[0]);\n    } else {\n      @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n      ArrayList<String> fields = new ArrayList();\n      for (String field : doc.getFieldNames()) {\n        // Only use fields that are stored and have an explicit analyzer.\n        // This makes sense as the query uses tf/idf/.. for query construction.\n        // We might want to relook and change this in the future though.\n        SchemaField f = req.getSchema().getFieldOrNull(field);\n        if (f != null && f.stored() && f.getType().isExplicitAnalyzer()) {\n          fields.add(field);\n        }\n      }\n      fieldNames = fields.toArray(new String[0]);\n    }\n\n    if (fieldNames.length < 1) {\n      throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\n          \"MoreLikeThis requires at least one similarity field: qf\" );\n    }\n\n    mlt.setFieldNames(fieldNames);\n    for (String field : fieldNames) {\n      Collection<Object> fieldValues = doc.getFieldValues(field);\n      if (fieldValues != null) {\n        @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n        Collection<Object> values = new ArrayList();\n        for (Object val : fieldValues) {\n          if (val instanceof IndexableField) {\n            values.add(((IndexableField)val).stringValue());\n          }\n          else {\n            values.add(val);\n          }\n        }\n        filteredDocument.put(field, values);\n      }\n    }\n\n    try {\n      Query rawMLTQuery = mlt.like(filteredDocument);\n      BooleanQuery boostedMLTQuery = (BooleanQuery) rawMLTQuery;\n\n      if (boost && boostFields.size() > 0) {\n        BooleanQuery.Builder newQ = new BooleanQuery.Builder();\n        newQ.setMinimumNumberShouldMatch(boostedMLTQuery.getMinimumNumberShouldMatch());\n\n        for (BooleanClause clause : boostedMLTQuery) {\n          Query q = clause.getQuery();\n          float originalBoost = 1f;\n          if (q instanceof BoostQuery) {\n            BoostQuery bq = (BoostQuery) q;\n            q = bq.getQuery();\n            originalBoost = bq.getBoost();\n          }\n          Float fieldBoost = boostFields.get(((TermQuery) q).getTerm().field());\n          q = ((fieldBoost != null) ? new BoostQuery(q, fieldBoost * originalBoost) : clause.getQuery());\n          newQ.add(q, clause.getOccur());\n        }\n\n        boostedMLTQuery = QueryUtils.build(newQ, this);\n      }\n\n      // exclude current document from results\n      BooleanQuery.Builder realMLTQuery = new BooleanQuery.Builder();\n      realMLTQuery.add(boostedMLTQuery, BooleanClause.Occur.MUST);\n      realMLTQuery.add(createIdQuery(req.getSchema().getUniqueKeyField().getName(), id), BooleanClause.Occur.MUST_NOT);\n\n      return realMLTQuery.build();\n    } catch (IOException e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\", e);\n    }\n\n  }\n\n","sourceOld":"  public Query parse() {\n    String id = localParams.get(QueryParsing.V);\n    // Do a Real Time Get for the document\n    SolrDocument doc = getDocument(id);\n    if(doc == null) {\n      throw new SolrException(\n          SolrException.ErrorCode.BAD_REQUEST, \"Error completing MLT request. Could not fetch \" +\n          \"document with id [\" + id + \"]\");\n    }\n\n    String[] qf = localParams.getParams(\"qf\");\n    Map<String,Float> boostFields = new HashMap<>();\n    MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n\n    mlt.setMinTermFreq(localParams.getInt(\"mintf\", MoreLikeThis.DEFAULT_MIN_TERM_FREQ));\n    mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n    mlt.setMinWordLen(localParams.getInt(\"minwl\", MoreLikeThis.DEFAULT_MIN_WORD_LENGTH));\n    mlt.setMaxWordLen(localParams.getInt(\"maxwl\", MoreLikeThis.DEFAULT_MAX_WORD_LENGTH));\n    mlt.setMaxQueryTerms(localParams.getInt(\"maxqt\", MoreLikeThis.DEFAULT_MAX_QUERY_TERMS));\n    mlt.setMaxNumTokensParsed(localParams.getInt(\"maxntp\", MoreLikeThis.DEFAULT_MAX_NUM_TOKENS_PARSED));\n    mlt.setMaxDocFreq(localParams.getInt(\"maxdf\", MoreLikeThis.DEFAULT_MAX_DOC_FREQ));\n\n    Boolean boost = localParams.getBool(\"boost\", MoreLikeThis.DEFAULT_BOOST);\n    mlt.setBoost(boost);\n\n    mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n\n    Map<String, Collection<Object>> filteredDocument = new HashMap<>();\n    String[] fieldNames;\n\n    if (qf != null) {\n      ArrayList<String> fields = new ArrayList();\n      for (String fieldName : qf) {\n        if (!StringUtils.isEmpty(fieldName))  {\n          String[] strings = splitList.split(fieldName);\n          for (String string : strings) {\n            if (!StringUtils.isEmpty(string)) {\n              fields.add(string);\n            }\n          }\n        }\n      }\n      // Parse field names and boosts from the fields\n      boostFields = SolrPluginUtils.parseFieldBoosts(fields.toArray(new String[0]));\n      fieldNames = boostFields.keySet().toArray(new String[0]);\n    } else {\n      ArrayList<String> fields = new ArrayList();\n      for (String field : doc.getFieldNames()) {\n        // Only use fields that are stored and have an explicit analyzer.\n        // This makes sense as the query uses tf/idf/.. for query construction.\n        // We might want to relook and change this in the future though.\n        SchemaField f = req.getSchema().getFieldOrNull(field);\n        if (f != null && f.stored() && f.getType().isExplicitAnalyzer()) {\n          fields.add(field);\n        }\n      }\n      fieldNames = fields.toArray(new String[0]);\n    }\n\n    if (fieldNames.length < 1) {\n      throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\n          \"MoreLikeThis requires at least one similarity field: qf\" );\n    }\n\n    mlt.setFieldNames(fieldNames);\n    for (String field : fieldNames) {\n      Collection<Object> fieldValues = doc.getFieldValues(field);\n      if (fieldValues != null) {\n        Collection<Object> values = new ArrayList();\n        for (Object val : fieldValues) {\n          if (val instanceof IndexableField) {\n            values.add(((IndexableField)val).stringValue());\n          }\n          else {\n            values.add(val);\n          }\n        }\n        filteredDocument.put(field, values);\n      }\n    }\n\n    try {\n      Query rawMLTQuery = mlt.like(filteredDocument);\n      BooleanQuery boostedMLTQuery = (BooleanQuery) rawMLTQuery;\n\n      if (boost && boostFields.size() > 0) {\n        BooleanQuery.Builder newQ = new BooleanQuery.Builder();\n        newQ.setMinimumNumberShouldMatch(boostedMLTQuery.getMinimumNumberShouldMatch());\n\n        for (BooleanClause clause : boostedMLTQuery) {\n          Query q = clause.getQuery();\n          float originalBoost = 1f;\n          if (q instanceof BoostQuery) {\n            BoostQuery bq = (BoostQuery) q;\n            q = bq.getQuery();\n            originalBoost = bq.getBoost();\n          }\n          Float fieldBoost = boostFields.get(((TermQuery) q).getTerm().field());\n          q = ((fieldBoost != null) ? new BoostQuery(q, fieldBoost * originalBoost) : clause.getQuery());\n          newQ.add(q, clause.getOccur());\n        }\n\n        boostedMLTQuery = QueryUtils.build(newQ, this);\n      }\n\n      // exclude current document from results\n      BooleanQuery.Builder realMLTQuery = new BooleanQuery.Builder();\n      realMLTQuery.add(boostedMLTQuery, BooleanClause.Occur.MUST);\n      realMLTQuery.add(createIdQuery(req.getSchema().getUniqueKeyField().getName(), id), BooleanClause.Occur.MUST_NOT);\n\n      return realMLTQuery.build();\n    } catch (IOException e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Bad Request\", e);\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"caeebbaa964f57dceaab0b9cb5800882e88d57ff":["776417a20af3930a363a226c989867f65e93ee91"],"39fdbc59d893f5a211736e861fe145798a40b9ff":["2100a5b744ecaec4d2b191a7da9083feb50a6f7f"],"04bdaa444003ce31c8e9cb6cd43f6a32ccfe8969":["8ed124d21605b0e41f648c25f80f60ba1828e78a"],"d470c8182e92b264680e34081b75e70a9f2b3c89":["cf1a614098b46c9c22afebd7b898ae4d1d2fc273","5ebf70dabe6279454c5ff460bdea3f0dc2814a86"],"8ed124d21605b0e41f648c25f80f60ba1828e78a":["c8a0e442f7b61f811680273b25da95994a724466"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"9856095f7afb5a607bf5e65077615ed91273508c":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","9d8dad4099bd3cb610a9a9229685f246ef6b9f16"],"5ebf70dabe6279454c5ff460bdea3f0dc2814a86":["cf1a614098b46c9c22afebd7b898ae4d1d2fc273"],"655260340014c640e7d0f9a7a7ea1f00f36f65e5":["caeebbaa964f57dceaab0b9cb5800882e88d57ff"],"eb55f624eb53f26cfb7f9614b862fb7657633358":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"19d28b1683d6453ee94a9205e2d32206d2dde868":["07d695a14a1938b01a5d4ab68b3c815eb061da94"],"ed95a777f3860385e015fb8a082e4b66a5aa6bb8":["655260340014c640e7d0f9a7a7ea1f00f36f65e5"],"2100a5b744ecaec4d2b191a7da9083feb50a6f7f":["9d8dad4099bd3cb610a9a9229685f246ef6b9f16"],"09ab8ee44ca898536770d0106a7c0ee4be4f0eb7":["9856095f7afb5a607bf5e65077615ed91273508c","2100a5b744ecaec4d2b191a7da9083feb50a6f7f"],"7eaf6db9e40efc42a6f8bb385825483657f923f6":["19cb756f0ad73c8d898cb8bfdd9f04bcc6e3b7c1"],"b7dfa64bc2074fb87d0ca70095a644c1ead107e1":["2100a5b744ecaec4d2b191a7da9083feb50a6f7f","39fdbc59d893f5a211736e861fe145798a40b9ff"],"28288370235ed02234a64753cdbf0c6ec096304a":["2100a5b744ecaec4d2b191a7da9083feb50a6f7f","39fdbc59d893f5a211736e861fe145798a40b9ff"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["cf1a614098b46c9c22afebd7b898ae4d1d2fc273","c8a0e442f7b61f811680273b25da95994a724466"],"07d695a14a1938b01a5d4ab68b3c815eb061da94":["d32e559c96d0c16fe041e1608a4bbbf8a6c9a4e1"],"9d8dad4099bd3cb610a9a9229685f246ef6b9f16":["04bdaa444003ce31c8e9cb6cd43f6a32ccfe8969"],"d32e559c96d0c16fe041e1608a4bbbf8a6c9a4e1":["eb55f624eb53f26cfb7f9614b862fb7657633358"],"50dfd19525c8d73e856dca6edb64b7aea074037f":["0db83f1bb855a4ac824c9a2a8e1ee9b29a039c15"],"19cb756f0ad73c8d898cb8bfdd9f04bcc6e3b7c1":["ed95a777f3860385e015fb8a082e4b66a5aa6bb8"],"776417a20af3930a363a226c989867f65e93ee91":["19d28b1683d6453ee94a9205e2d32206d2dde868"],"c8a0e442f7b61f811680273b25da95994a724466":["d470c8182e92b264680e34081b75e70a9f2b3c89"],"cf1a614098b46c9c22afebd7b898ae4d1d2fc273":["19cb756f0ad73c8d898cb8bfdd9f04bcc6e3b7c1","7eaf6db9e40efc42a6f8bb385825483657f923f6"],"0db83f1bb855a4ac824c9a2a8e1ee9b29a039c15":["28288370235ed02234a64753cdbf0c6ec096304a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["50dfd19525c8d73e856dca6edb64b7aea074037f"]},"commit2Childs":{"caeebbaa964f57dceaab0b9cb5800882e88d57ff":["655260340014c640e7d0f9a7a7ea1f00f36f65e5"],"39fdbc59d893f5a211736e861fe145798a40b9ff":["b7dfa64bc2074fb87d0ca70095a644c1ead107e1","28288370235ed02234a64753cdbf0c6ec096304a"],"04bdaa444003ce31c8e9cb6cd43f6a32ccfe8969":["9d8dad4099bd3cb610a9a9229685f246ef6b9f16"],"d470c8182e92b264680e34081b75e70a9f2b3c89":["c8a0e442f7b61f811680273b25da95994a724466"],"8ed124d21605b0e41f648c25f80f60ba1828e78a":["04bdaa444003ce31c8e9cb6cd43f6a32ccfe8969"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["eb55f624eb53f26cfb7f9614b862fb7657633358"],"9856095f7afb5a607bf5e65077615ed91273508c":["09ab8ee44ca898536770d0106a7c0ee4be4f0eb7"],"5ebf70dabe6279454c5ff460bdea3f0dc2814a86":["d470c8182e92b264680e34081b75e70a9f2b3c89"],"655260340014c640e7d0f9a7a7ea1f00f36f65e5":["ed95a777f3860385e015fb8a082e4b66a5aa6bb8"],"eb55f624eb53f26cfb7f9614b862fb7657633358":["d32e559c96d0c16fe041e1608a4bbbf8a6c9a4e1"],"19d28b1683d6453ee94a9205e2d32206d2dde868":["776417a20af3930a363a226c989867f65e93ee91"],"ed95a777f3860385e015fb8a082e4b66a5aa6bb8":["19cb756f0ad73c8d898cb8bfdd9f04bcc6e3b7c1"],"2100a5b744ecaec4d2b191a7da9083feb50a6f7f":["39fdbc59d893f5a211736e861fe145798a40b9ff","09ab8ee44ca898536770d0106a7c0ee4be4f0eb7","b7dfa64bc2074fb87d0ca70095a644c1ead107e1","28288370235ed02234a64753cdbf0c6ec096304a"],"09ab8ee44ca898536770d0106a7c0ee4be4f0eb7":[],"7eaf6db9e40efc42a6f8bb385825483657f923f6":["cf1a614098b46c9c22afebd7b898ae4d1d2fc273"],"b7dfa64bc2074fb87d0ca70095a644c1ead107e1":[],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["9856095f7afb5a607bf5e65077615ed91273508c"],"28288370235ed02234a64753cdbf0c6ec096304a":["0db83f1bb855a4ac824c9a2a8e1ee9b29a039c15"],"07d695a14a1938b01a5d4ab68b3c815eb061da94":["19d28b1683d6453ee94a9205e2d32206d2dde868"],"9d8dad4099bd3cb610a9a9229685f246ef6b9f16":["9856095f7afb5a607bf5e65077615ed91273508c","2100a5b744ecaec4d2b191a7da9083feb50a6f7f"],"d32e559c96d0c16fe041e1608a4bbbf8a6c9a4e1":["07d695a14a1938b01a5d4ab68b3c815eb061da94"],"50dfd19525c8d73e856dca6edb64b7aea074037f":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"19cb756f0ad73c8d898cb8bfdd9f04bcc6e3b7c1":["7eaf6db9e40efc42a6f8bb385825483657f923f6","cf1a614098b46c9c22afebd7b898ae4d1d2fc273"],"776417a20af3930a363a226c989867f65e93ee91":["caeebbaa964f57dceaab0b9cb5800882e88d57ff"],"c8a0e442f7b61f811680273b25da95994a724466":["8ed124d21605b0e41f648c25f80f60ba1828e78a","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"cf1a614098b46c9c22afebd7b898ae4d1d2fc273":["d470c8182e92b264680e34081b75e70a9f2b3c89","5ebf70dabe6279454c5ff460bdea3f0dc2814a86","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"0db83f1bb855a4ac824c9a2a8e1ee9b29a039c15":["50dfd19525c8d73e856dca6edb64b7aea074037f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["09ab8ee44ca898536770d0106a7c0ee4be4f0eb7","b7dfa64bc2074fb87d0ca70095a644c1ead107e1","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}