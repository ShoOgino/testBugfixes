{"path":"lucene/core/src/java/org/apache/lucene/index/MergeState#maybeSortReaders(List[CodecReader],SegmentInfo).mjava","commits":[{"id":"ceaef6cfc68c8ab22a684192e469a8280f9e6e70","date":1462354657,"type":0,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/MergeState#maybeSortReaders(List[CodecReader],SegmentInfo).mjava","pathOld":"/dev/null","sourceNew":"  private List<CodecReader> maybeSortReaders(List<CodecReader> originalReaders, SegmentInfo segmentInfo) throws IOException {\n\n    // Default to identity:\n    for(int i=0;i<originalReaders.size();i++) {\n      leafDocMaps[i] = new DocMap() {\n          @Override\n          public int get(int docID) {\n            return docID;\n          }\n        };\n    }\n\n    Sort indexSort = segmentInfo.getIndexSort();\n    if (indexSort == null) {\n      return originalReaders;\n    }\n\n    // If an incoming reader is not sorted, because it was flushed by IW, we sort it here:\n    final Sorter sorter = new Sorter(indexSort);\n    List<CodecReader> readers = new ArrayList<>(originalReaders.size());\n\n    //System.out.println(\"MergeState.maybeSortReaders indexSort=\" + indexSort);\n\n    for (CodecReader leaf : originalReaders) {\n      if (leaf instanceof SegmentReader) {\n        SegmentReader segmentReader = (SegmentReader) leaf;\n        Sort segmentSort = segmentReader.getSegmentInfo().info.getIndexSort();\n        //System.out.println(\"  leaf=\" + leaf + \" sort=\" + segmentSort);\n\n        if (segmentSort == null) {\n          // TODO: fix IW to also sort when flushing?  It's somewhat tricky because of stored fields and term vectors, which write \"live\"\n          // to the files on each indexed document:\n\n          // This segment was written by flush, so documents are not yet sorted, so we sort them now:\n          Sorter.DocMap sortDocMap = sorter.sort(leaf);\n          if (sortDocMap != null) {\n            //System.out.println(\"    sort!\");\n            // nocommit what about MergedReaderWrapper in here?\n            leaf = SlowCodecReaderWrapper.wrap(SortingLeafReader.wrap(leaf, sortDocMap));\n            leafDocMaps[readers.size()] = new DocMap() {\n                @Override\n                public int get(int docID) {\n                  return sortDocMap.oldToNew(docID);\n                }\n              };\n          }\n\n        } else if (segmentSort.equals(indexSort) == false) {\n          throw new IllegalArgumentException(\"index sort mismatch: merged segment has sort=\" + indexSort + \" but to-be-merged segment has sort=\" + segmentSort);\n        }\n      } else {\n        throw new IllegalArgumentException(\"cannot sort index with foreign readers; leaf=\" + leaf);\n      }\n\n      readers.add(leaf);\n    }\n\n    return readers;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["86a0a50d2d14aaee1e635bbec914468551f7f9a2"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5e401f4940308a68c615c8893021c88c57010df5","date":1462635977,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/MergeState#maybeSortReaders(List[CodecReader],SegmentInfo).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/MergeState#maybeSortReaders(List[CodecReader],SegmentInfo).mjava","sourceNew":"  private List<CodecReader> maybeSortReaders(List<CodecReader> originalReaders, SegmentInfo segmentInfo) throws IOException {\n\n    // Default to identity:\n    for(int i=0;i<originalReaders.size();i++) {\n      leafDocMaps[i] = new DocMap() {\n          @Override\n          public int get(int docID) {\n            return docID;\n          }\n        };\n    }\n\n    Sort indexSort = segmentInfo.getIndexSort();\n    if (indexSort == null) {\n      return originalReaders;\n    }\n\n    // If an incoming reader is not sorted, because it was flushed by IW, we sort it here:\n    final Sorter sorter = new Sorter(indexSort);\n    List<CodecReader> readers = new ArrayList<>(originalReaders.size());\n\n    //System.out.println(\"MergeState.maybeSortReaders indexSort=\" + indexSort);\n\n    for (CodecReader leaf : originalReaders) {\n      Sort segmentSort = leaf.getIndexSort();\n      //System.out.println(\"  leaf=\" + leaf + \" sort=\" + segmentSort);\n\n      if (segmentSort == null) {\n        // TODO: fix IW to also sort when flushing?  It's somewhat tricky because of stored fields and term vectors, which write \"live\"\n        // to the files on each indexed document:\n\n        // This segment was written by flush, so documents are not yet sorted, so we sort them now:\n        Sorter.DocMap sortDocMap = sorter.sort(leaf);\n        if (sortDocMap != null) {\n          //System.out.println(\"    sort!\");\n          // nocommit what about MergedReaderWrapper in here?\n          leaf = SlowCodecReaderWrapper.wrap(SortingLeafReader.wrap(leaf, sortDocMap));\n          leafDocMaps[readers.size()] = new DocMap() {\n              @Override\n              public int get(int docID) {\n                return sortDocMap.oldToNew(docID);\n              }\n            };\n        }\n\n      } else if (segmentSort.equals(indexSort) == false) {\n        throw new IllegalArgumentException(\"index sort mismatch: merged segment has sort=\" + indexSort + \" but to-be-merged segment has sort=\" + segmentSort);\n      }\n\n      readers.add(leaf);\n    }\n\n    return readers;\n  }\n\n","sourceOld":"  private List<CodecReader> maybeSortReaders(List<CodecReader> originalReaders, SegmentInfo segmentInfo) throws IOException {\n\n    // Default to identity:\n    for(int i=0;i<originalReaders.size();i++) {\n      leafDocMaps[i] = new DocMap() {\n          @Override\n          public int get(int docID) {\n            return docID;\n          }\n        };\n    }\n\n    Sort indexSort = segmentInfo.getIndexSort();\n    if (indexSort == null) {\n      return originalReaders;\n    }\n\n    // If an incoming reader is not sorted, because it was flushed by IW, we sort it here:\n    final Sorter sorter = new Sorter(indexSort);\n    List<CodecReader> readers = new ArrayList<>(originalReaders.size());\n\n    //System.out.println(\"MergeState.maybeSortReaders indexSort=\" + indexSort);\n\n    for (CodecReader leaf : originalReaders) {\n      if (leaf instanceof SegmentReader) {\n        SegmentReader segmentReader = (SegmentReader) leaf;\n        Sort segmentSort = segmentReader.getSegmentInfo().info.getIndexSort();\n        //System.out.println(\"  leaf=\" + leaf + \" sort=\" + segmentSort);\n\n        if (segmentSort == null) {\n          // TODO: fix IW to also sort when flushing?  It's somewhat tricky because of stored fields and term vectors, which write \"live\"\n          // to the files on each indexed document:\n\n          // This segment was written by flush, so documents are not yet sorted, so we sort them now:\n          Sorter.DocMap sortDocMap = sorter.sort(leaf);\n          if (sortDocMap != null) {\n            //System.out.println(\"    sort!\");\n            // nocommit what about MergedReaderWrapper in here?\n            leaf = SlowCodecReaderWrapper.wrap(SortingLeafReader.wrap(leaf, sortDocMap));\n            leafDocMaps[readers.size()] = new DocMap() {\n                @Override\n                public int get(int docID) {\n                  return sortDocMap.oldToNew(docID);\n                }\n              };\n          }\n\n        } else if (segmentSort.equals(indexSort) == false) {\n          throw new IllegalArgumentException(\"index sort mismatch: merged segment has sort=\" + indexSort + \" but to-be-merged segment has sort=\" + segmentSort);\n        }\n      } else {\n        throw new IllegalArgumentException(\"cannot sort index with foreign readers; leaf=\" + leaf);\n      }\n\n      readers.add(leaf);\n    }\n\n    return readers;\n  }\n\n","bugFix":null,"bugIntro":["86a0a50d2d14aaee1e635bbec914468551f7f9a2"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6d8200beeffd3fa5155855f4cb8a8a5e38aeff14","date":1462698019,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/MergeState#maybeSortReaders(List[CodecReader],SegmentInfo).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/MergeState#maybeSortReaders(List[CodecReader],SegmentInfo).mjava","sourceNew":"  private List<CodecReader> maybeSortReaders(List<CodecReader> originalReaders, SegmentInfo segmentInfo) throws IOException {\n\n    // Default to identity:\n    for(int i=0;i<originalReaders.size();i++) {\n      leafDocMaps[i] = new DocMap() {\n          @Override\n          public int get(int docID) {\n            return docID;\n          }\n        };\n    }\n\n    Sort indexSort = segmentInfo.getIndexSort();\n    if (indexSort == null) {\n      return originalReaders;\n    }\n\n    // If an incoming reader is not sorted, because it was flushed by IW, we sort it here:\n    final Sorter sorter = new Sorter(indexSort);\n    List<CodecReader> readers = new ArrayList<>(originalReaders.size());\n\n    //System.out.println(\"MergeState.maybeSortReaders indexSort=\" + indexSort);\n\n    for (CodecReader leaf : originalReaders) {\n      Sort segmentSort = leaf.getIndexSort();\n      //System.out.println(\"  leaf=\" + leaf + \" sort=\" + segmentSort);\n\n      if (segmentSort == null) {\n        // TODO: fix IW to also sort when flushing?  It's somewhat tricky because of stored fields and term vectors, which write \"live\"\n        // to the files on each indexed document:\n\n        // This segment was written by flush, so documents are not yet sorted, so we sort them now:\n        Sorter.DocMap sortDocMap = sorter.sort(leaf);\n        if (sortDocMap != null) {\n          //System.out.println(\"    sort!\");\n          leaf = SlowCodecReaderWrapper.wrap(SortingLeafReader.wrap(new MergeReaderWrapper(leaf), sortDocMap));\n          leafDocMaps[readers.size()] = new DocMap() {\n              @Override\n              public int get(int docID) {\n                return sortDocMap.oldToNew(docID);\n              }\n            };\n        }\n\n      } else if (segmentSort.equals(indexSort) == false) {\n        throw new IllegalArgumentException(\"index sort mismatch: merged segment has sort=\" + indexSort + \" but to-be-merged segment has sort=\" + segmentSort);\n      }\n\n      readers.add(leaf);\n    }\n\n    return readers;\n  }\n\n","sourceOld":"  private List<CodecReader> maybeSortReaders(List<CodecReader> originalReaders, SegmentInfo segmentInfo) throws IOException {\n\n    // Default to identity:\n    for(int i=0;i<originalReaders.size();i++) {\n      leafDocMaps[i] = new DocMap() {\n          @Override\n          public int get(int docID) {\n            return docID;\n          }\n        };\n    }\n\n    Sort indexSort = segmentInfo.getIndexSort();\n    if (indexSort == null) {\n      return originalReaders;\n    }\n\n    // If an incoming reader is not sorted, because it was flushed by IW, we sort it here:\n    final Sorter sorter = new Sorter(indexSort);\n    List<CodecReader> readers = new ArrayList<>(originalReaders.size());\n\n    //System.out.println(\"MergeState.maybeSortReaders indexSort=\" + indexSort);\n\n    for (CodecReader leaf : originalReaders) {\n      Sort segmentSort = leaf.getIndexSort();\n      //System.out.println(\"  leaf=\" + leaf + \" sort=\" + segmentSort);\n\n      if (segmentSort == null) {\n        // TODO: fix IW to also sort when flushing?  It's somewhat tricky because of stored fields and term vectors, which write \"live\"\n        // to the files on each indexed document:\n\n        // This segment was written by flush, so documents are not yet sorted, so we sort them now:\n        Sorter.DocMap sortDocMap = sorter.sort(leaf);\n        if (sortDocMap != null) {\n          //System.out.println(\"    sort!\");\n          // nocommit what about MergedReaderWrapper in here?\n          leaf = SlowCodecReaderWrapper.wrap(SortingLeafReader.wrap(leaf, sortDocMap));\n          leafDocMaps[readers.size()] = new DocMap() {\n              @Override\n              public int get(int docID) {\n                return sortDocMap.oldToNew(docID);\n              }\n            };\n        }\n\n      } else if (segmentSort.equals(indexSort) == false) {\n        throw new IllegalArgumentException(\"index sort mismatch: merged segment has sort=\" + indexSort + \" but to-be-merged segment has sort=\" + segmentSort);\n      }\n\n      readers.add(leaf);\n    }\n\n    return readers;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fb0345a2d45479f891041f8b3ce351bc975e64ac","date":1462708700,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/MergeState#maybeSortReaders(List[CodecReader],SegmentInfo).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/MergeState#maybeSortReaders(List[CodecReader],SegmentInfo).mjava","sourceNew":"  private List<CodecReader> maybeSortReaders(List<CodecReader> originalReaders, SegmentInfo segmentInfo) throws IOException {\n\n    // Default to identity:\n    for(int i=0;i<originalReaders.size();i++) {\n      leafDocMaps[i] = new DocMap() {\n          @Override\n          public int get(int docID) {\n            return docID;\n          }\n        };\n    }\n\n    Sort indexSort = segmentInfo.getIndexSort();\n    if (indexSort == null) {\n      return originalReaders;\n    }\n\n    // If an incoming reader is not sorted, because it was flushed by IW, we sort it here:\n    final Sorter sorter = new Sorter(indexSort);\n    List<CodecReader> readers = new ArrayList<>(originalReaders.size());\n\n    for (CodecReader leaf : originalReaders) {\n      Sort segmentSort = leaf.getIndexSort();\n\n      if (segmentSort == null) {\n        // TODO: fix IW to also sort when flushing?  It's somewhat tricky because of stored fields and term vectors, which write \"live\"\n        // to their index files on each indexed document:\n\n        // This segment was written by flush, so documents are not yet sorted, so we sort them now:\n        Sorter.DocMap sortDocMap = sorter.sort(leaf);\n        if (sortDocMap != null) {\n          leaf = SlowCodecReaderWrapper.wrap(SortingLeafReader.wrap(new MergeReaderWrapper(leaf), sortDocMap));\n          leafDocMaps[readers.size()] = new DocMap() {\n              @Override\n              public int get(int docID) {\n                return sortDocMap.oldToNew(docID);\n              }\n            };\n        }\n\n      } else if (segmentSort.equals(indexSort) == false) {\n        throw new IllegalArgumentException(\"index sort mismatch: merged segment has sort=\" + indexSort + \" but to-be-merged segment has sort=\" + segmentSort);\n      }\n\n      readers.add(leaf);\n    }\n\n    return readers;\n  }\n\n","sourceOld":"  private List<CodecReader> maybeSortReaders(List<CodecReader> originalReaders, SegmentInfo segmentInfo) throws IOException {\n\n    // Default to identity:\n    for(int i=0;i<originalReaders.size();i++) {\n      leafDocMaps[i] = new DocMap() {\n          @Override\n          public int get(int docID) {\n            return docID;\n          }\n        };\n    }\n\n    Sort indexSort = segmentInfo.getIndexSort();\n    if (indexSort == null) {\n      return originalReaders;\n    }\n\n    // If an incoming reader is not sorted, because it was flushed by IW, we sort it here:\n    final Sorter sorter = new Sorter(indexSort);\n    List<CodecReader> readers = new ArrayList<>(originalReaders.size());\n\n    //System.out.println(\"MergeState.maybeSortReaders indexSort=\" + indexSort);\n\n    for (CodecReader leaf : originalReaders) {\n      Sort segmentSort = leaf.getIndexSort();\n      //System.out.println(\"  leaf=\" + leaf + \" sort=\" + segmentSort);\n\n      if (segmentSort == null) {\n        // TODO: fix IW to also sort when flushing?  It's somewhat tricky because of stored fields and term vectors, which write \"live\"\n        // to the files on each indexed document:\n\n        // This segment was written by flush, so documents are not yet sorted, so we sort them now:\n        Sorter.DocMap sortDocMap = sorter.sort(leaf);\n        if (sortDocMap != null) {\n          //System.out.println(\"    sort!\");\n          leaf = SlowCodecReaderWrapper.wrap(SortingLeafReader.wrap(new MergeReaderWrapper(leaf), sortDocMap));\n          leafDocMaps[readers.size()] = new DocMap() {\n              @Override\n              public int get(int docID) {\n                return sortDocMap.oldToNew(docID);\n              }\n            };\n        }\n\n      } else if (segmentSort.equals(indexSort) == false) {\n        throw new IllegalArgumentException(\"index sort mismatch: merged segment has sort=\" + indexSort + \" but to-be-merged segment has sort=\" + segmentSort);\n      }\n\n      readers.add(leaf);\n    }\n\n    return readers;\n  }\n\n","bugFix":null,"bugIntro":["86a0a50d2d14aaee1e635bbec914468551f7f9a2"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5e03940e6e9044943de4b7ac08f8581da37a9534","date":1462870173,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/MergeState#maybeSortReaders(List[CodecReader],SegmentInfo).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/MergeState#maybeSortReaders(List[CodecReader],SegmentInfo).mjava","sourceNew":"  private List<CodecReader> maybeSortReaders(List<CodecReader> originalReaders, SegmentInfo segmentInfo) throws IOException {\n\n    // Default to identity:\n    for(int i=0;i<originalReaders.size();i++) {\n      leafDocMaps[i] = new DocMap() {\n          @Override\n          public int get(int docID) {\n            return docID;\n          }\n        };\n    }\n\n    Sort indexSort = segmentInfo.getIndexSort();\n    if (indexSort == null) {\n      return originalReaders;\n    }\n\n    // If an incoming reader is not sorted, because it was flushed by IW, we sort it here:\n    final Sorter sorter = new Sorter(indexSort);\n    List<CodecReader> readers = new ArrayList<>(originalReaders.size());\n\n    for (CodecReader leaf : originalReaders) {\n      Sort segmentSort = leaf.getIndexSort();\n\n      if (segmentSort == null) {\n        // TODO: fix IW to also sort when flushing?  It's somewhat tricky because of stored fields and term vectors, which write \"live\"\n        // to their index files on each indexed document:\n\n        // This segment was written by flush, so documents are not yet sorted, so we sort them now:\n        Sorter.DocMap sortDocMap = sorter.sort(leaf);\n        if (sortDocMap != null) {\n          if (infoStream.isEnabled(\"SM\")) {\n            infoStream.message(\"SM\", \"segment \" + leaf + \" is not sorted; wrapping for sort \" + indexSort + \" now\");\n          }\n          leaf = SlowCodecReaderWrapper.wrap(SortingLeafReader.wrap(new MergeReaderWrapper(leaf), sortDocMap));\n          leafDocMaps[readers.size()] = new DocMap() {\n              @Override\n              public int get(int docID) {\n                return sortDocMap.oldToNew(docID);\n              }\n            };\n        } else {\n          if (infoStream.isEnabled(\"SM\")) {\n            infoStream.message(\"SM\", \"segment \" + leaf + \" is not sorted, but is already accidentally in sort \" + indexSort + \" order\");\n          }\n        }\n\n      } else {\n        if (segmentSort.equals(indexSort) == false) {\n          throw new IllegalArgumentException(\"index sort mismatch: merged segment has sort=\" + indexSort + \" but to-be-merged segment has sort=\" + segmentSort);\n        }\n        if (infoStream.isEnabled(\"SM\")) {\n          infoStream.message(\"SM\", \"segment \" + leaf + \" already sorted\");\n        }\n      }\n\n      readers.add(leaf);\n    }\n\n    return readers;\n  }\n\n","sourceOld":"  private List<CodecReader> maybeSortReaders(List<CodecReader> originalReaders, SegmentInfo segmentInfo) throws IOException {\n\n    // Default to identity:\n    for(int i=0;i<originalReaders.size();i++) {\n      leafDocMaps[i] = new DocMap() {\n          @Override\n          public int get(int docID) {\n            return docID;\n          }\n        };\n    }\n\n    Sort indexSort = segmentInfo.getIndexSort();\n    if (indexSort == null) {\n      return originalReaders;\n    }\n\n    // If an incoming reader is not sorted, because it was flushed by IW, we sort it here:\n    final Sorter sorter = new Sorter(indexSort);\n    List<CodecReader> readers = new ArrayList<>(originalReaders.size());\n\n    for (CodecReader leaf : originalReaders) {\n      Sort segmentSort = leaf.getIndexSort();\n\n      if (segmentSort == null) {\n        // TODO: fix IW to also sort when flushing?  It's somewhat tricky because of stored fields and term vectors, which write \"live\"\n        // to their index files on each indexed document:\n\n        // This segment was written by flush, so documents are not yet sorted, so we sort them now:\n        Sorter.DocMap sortDocMap = sorter.sort(leaf);\n        if (sortDocMap != null) {\n          leaf = SlowCodecReaderWrapper.wrap(SortingLeafReader.wrap(new MergeReaderWrapper(leaf), sortDocMap));\n          leafDocMaps[readers.size()] = new DocMap() {\n              @Override\n              public int get(int docID) {\n                return sortDocMap.oldToNew(docID);\n              }\n            };\n        }\n\n      } else if (segmentSort.equals(indexSort) == false) {\n        throw new IllegalArgumentException(\"index sort mismatch: merged segment has sort=\" + indexSort + \" but to-be-merged segment has sort=\" + segmentSort);\n      }\n\n      readers.add(leaf);\n    }\n\n    return readers;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0a6d0e4c7ab9c0e1fc073fddd21f4784555be9cd","date":1463081111,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/MergeState#maybeSortReaders(List[CodecReader],SegmentInfo).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/MergeState#maybeSortReaders(List[CodecReader],SegmentInfo).mjava","sourceNew":"  private List<CodecReader> maybeSortReaders(List<CodecReader> originalReaders, SegmentInfo segmentInfo) throws IOException {\n\n    // Default to identity:\n    for(int i=0;i<originalReaders.size();i++) {\n      leafDocMaps[i] = new DocMap() {\n          @Override\n          public int get(int docID) {\n            return docID;\n          }\n        };\n    }\n\n    Sort indexSort = segmentInfo.getIndexSort();\n    if (indexSort == null) {\n      return originalReaders;\n    }\n\n    // If an incoming reader is not sorted, because it was flushed by IW, we sort it here:\n    final Sorter sorter = new Sorter(indexSort);\n    List<CodecReader> readers = new ArrayList<>(originalReaders.size());\n\n    for (CodecReader leaf : originalReaders) {\n      Sort segmentSort = leaf.getIndexSort();\n\n      if (segmentSort == null) {\n        // TODO: fix IW to also sort when flushing?  It's somewhat tricky because of stored fields and term vectors, which write \"live\"\n        // to their index files on each indexed document:\n\n        // This segment was written by flush, so documents are not yet sorted, so we sort them now:\n        long t0 = System.nanoTime();\n        Sorter.DocMap sortDocMap = sorter.sort(leaf);\n        long t1 = System.nanoTime();\n        double msec = (t1-t0)/1000000.0;\n        \n        if (sortDocMap != null) {\n          if (infoStream.isEnabled(\"SM\")) {\n            infoStream.message(\"SM\", String.format(Locale.ROOT, \"segment %s is not sorted; wrapping for sort %s now (%.2f msec to sort)\", leaf, indexSort, msec));\n          }\n          leaf = SlowCodecReaderWrapper.wrap(SortingLeafReader.wrap(new MergeReaderWrapper(leaf), sortDocMap));\n          leafDocMaps[readers.size()] = new DocMap() {\n              @Override\n              public int get(int docID) {\n                return sortDocMap.oldToNew(docID);\n              }\n            };\n        } else {\n          if (infoStream.isEnabled(\"SM\")) {\n            infoStream.message(\"SM\", String.format(Locale.ROOT, \"segment %s is not sorted, but is already accidentally in sort %s order (%.2f msec to sort)\", leaf, indexSort, msec));\n          }\n        }\n\n      } else {\n        if (segmentSort.equals(indexSort) == false) {\n          throw new IllegalArgumentException(\"index sort mismatch: merged segment has sort=\" + indexSort + \" but to-be-merged segment has sort=\" + segmentSort);\n        }\n        if (infoStream.isEnabled(\"SM\")) {\n          infoStream.message(\"SM\", \"segment \" + leaf + \" already sorted\");\n        }\n      }\n\n      readers.add(leaf);\n    }\n\n    return readers;\n  }\n\n","sourceOld":"  private List<CodecReader> maybeSortReaders(List<CodecReader> originalReaders, SegmentInfo segmentInfo) throws IOException {\n\n    // Default to identity:\n    for(int i=0;i<originalReaders.size();i++) {\n      leafDocMaps[i] = new DocMap() {\n          @Override\n          public int get(int docID) {\n            return docID;\n          }\n        };\n    }\n\n    Sort indexSort = segmentInfo.getIndexSort();\n    if (indexSort == null) {\n      return originalReaders;\n    }\n\n    // If an incoming reader is not sorted, because it was flushed by IW, we sort it here:\n    final Sorter sorter = new Sorter(indexSort);\n    List<CodecReader> readers = new ArrayList<>(originalReaders.size());\n\n    for (CodecReader leaf : originalReaders) {\n      Sort segmentSort = leaf.getIndexSort();\n\n      if (segmentSort == null) {\n        // TODO: fix IW to also sort when flushing?  It's somewhat tricky because of stored fields and term vectors, which write \"live\"\n        // to their index files on each indexed document:\n\n        // This segment was written by flush, so documents are not yet sorted, so we sort them now:\n        Sorter.DocMap sortDocMap = sorter.sort(leaf);\n        if (sortDocMap != null) {\n          if (infoStream.isEnabled(\"SM\")) {\n            infoStream.message(\"SM\", \"segment \" + leaf + \" is not sorted; wrapping for sort \" + indexSort + \" now\");\n          }\n          leaf = SlowCodecReaderWrapper.wrap(SortingLeafReader.wrap(new MergeReaderWrapper(leaf), sortDocMap));\n          leafDocMaps[readers.size()] = new DocMap() {\n              @Override\n              public int get(int docID) {\n                return sortDocMap.oldToNew(docID);\n              }\n            };\n        } else {\n          if (infoStream.isEnabled(\"SM\")) {\n            infoStream.message(\"SM\", \"segment \" + leaf + \" is not sorted, but is already accidentally in sort \" + indexSort + \" order\");\n          }\n        }\n\n      } else {\n        if (segmentSort.equals(indexSort) == false) {\n          throw new IllegalArgumentException(\"index sort mismatch: merged segment has sort=\" + indexSort + \" but to-be-merged segment has sort=\" + segmentSort);\n        }\n        if (infoStream.isEnabled(\"SM\")) {\n          infoStream.message(\"SM\", \"segment \" + leaf + \" already sorted\");\n        }\n      }\n\n      readers.add(leaf);\n    }\n\n    return readers;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3d33e731a93d4b57e662ff094f64f94a745422d4","date":1463128289,"type":0,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/MergeState#maybeSortReaders(List[CodecReader],SegmentInfo).mjava","pathOld":"/dev/null","sourceNew":"  private List<CodecReader> maybeSortReaders(List<CodecReader> originalReaders, SegmentInfo segmentInfo) throws IOException {\n\n    // Default to identity:\n    for(int i=0;i<originalReaders.size();i++) {\n      leafDocMaps[i] = new DocMap() {\n          @Override\n          public int get(int docID) {\n            return docID;\n          }\n        };\n    }\n\n    Sort indexSort = segmentInfo.getIndexSort();\n    if (indexSort == null) {\n      return originalReaders;\n    }\n\n    // If an incoming reader is not sorted, because it was flushed by IW, we sort it here:\n    final Sorter sorter = new Sorter(indexSort);\n    List<CodecReader> readers = new ArrayList<>(originalReaders.size());\n\n    for (CodecReader leaf : originalReaders) {\n      Sort segmentSort = leaf.getIndexSort();\n\n      if (segmentSort == null) {\n        // TODO: fix IW to also sort when flushing?  It's somewhat tricky because of stored fields and term vectors, which write \"live\"\n        // to their index files on each indexed document:\n\n        // This segment was written by flush, so documents are not yet sorted, so we sort them now:\n        long t0 = System.nanoTime();\n        Sorter.DocMap sortDocMap = sorter.sort(leaf);\n        long t1 = System.nanoTime();\n        double msec = (t1-t0)/1000000.0;\n        \n        if (sortDocMap != null) {\n          if (infoStream.isEnabled(\"SM\")) {\n            infoStream.message(\"SM\", String.format(Locale.ROOT, \"segment %s is not sorted; wrapping for sort %s now (%.2f msec to sort)\", leaf, indexSort, msec));\n          }\n          leaf = SlowCodecReaderWrapper.wrap(SortingLeafReader.wrap(new MergeReaderWrapper(leaf), sortDocMap));\n          leafDocMaps[readers.size()] = new DocMap() {\n              @Override\n              public int get(int docID) {\n                return sortDocMap.oldToNew(docID);\n              }\n            };\n        } else {\n          if (infoStream.isEnabled(\"SM\")) {\n            infoStream.message(\"SM\", String.format(Locale.ROOT, \"segment %s is not sorted, but is already accidentally in sort %s order (%.2f msec to sort)\", leaf, indexSort, msec));\n          }\n        }\n\n      } else {\n        if (segmentSort.equals(indexSort) == false) {\n          throw new IllegalArgumentException(\"index sort mismatch: merged segment has sort=\" + indexSort + \" but to-be-merged segment has sort=\" + segmentSort);\n        }\n        if (infoStream.isEnabled(\"SM\")) {\n          infoStream.message(\"SM\", \"segment \" + leaf + \" already sorted\");\n        }\n      }\n\n      readers.add(leaf);\n    }\n\n    return readers;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0ad30c6a479e764150a3316e57263319775f1df2","date":1463395403,"type":0,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/MergeState#maybeSortReaders(List[CodecReader],SegmentInfo).mjava","pathOld":"/dev/null","sourceNew":"  private List<CodecReader> maybeSortReaders(List<CodecReader> originalReaders, SegmentInfo segmentInfo) throws IOException {\n\n    // Default to identity:\n    for(int i=0;i<originalReaders.size();i++) {\n      leafDocMaps[i] = new DocMap() {\n          @Override\n          public int get(int docID) {\n            return docID;\n          }\n        };\n    }\n\n    Sort indexSort = segmentInfo.getIndexSort();\n    if (indexSort == null) {\n      return originalReaders;\n    }\n\n    // If an incoming reader is not sorted, because it was flushed by IW, we sort it here:\n    final Sorter sorter = new Sorter(indexSort);\n    List<CodecReader> readers = new ArrayList<>(originalReaders.size());\n\n    for (CodecReader leaf : originalReaders) {\n      Sort segmentSort = leaf.getIndexSort();\n\n      if (segmentSort == null) {\n        // TODO: fix IW to also sort when flushing?  It's somewhat tricky because of stored fields and term vectors, which write \"live\"\n        // to their index files on each indexed document:\n\n        // This segment was written by flush, so documents are not yet sorted, so we sort them now:\n        long t0 = System.nanoTime();\n        Sorter.DocMap sortDocMap = sorter.sort(leaf);\n        long t1 = System.nanoTime();\n        double msec = (t1-t0)/1000000.0;\n        \n        if (sortDocMap != null) {\n          if (infoStream.isEnabled(\"SM\")) {\n            infoStream.message(\"SM\", String.format(Locale.ROOT, \"segment %s is not sorted; wrapping for sort %s now (%.2f msec to sort)\", leaf, indexSort, msec));\n          }\n          leaf = SlowCodecReaderWrapper.wrap(SortingLeafReader.wrap(new MergeReaderWrapper(leaf), sortDocMap));\n          leafDocMaps[readers.size()] = new DocMap() {\n              @Override\n              public int get(int docID) {\n                return sortDocMap.oldToNew(docID);\n              }\n            };\n        } else {\n          if (infoStream.isEnabled(\"SM\")) {\n            infoStream.message(\"SM\", String.format(Locale.ROOT, \"segment %s is not sorted, but is already accidentally in sort %s order (%.2f msec to sort)\", leaf, indexSort, msec));\n          }\n        }\n\n      } else {\n        if (segmentSort.equals(indexSort) == false) {\n          throw new IllegalArgumentException(\"index sort mismatch: merged segment has sort=\" + indexSort + \" but to-be-merged segment has sort=\" + segmentSort);\n        }\n        if (infoStream.isEnabled(\"SM\")) {\n          infoStream.message(\"SM\", \"segment \" + leaf + \" already sorted\");\n        }\n      }\n\n      readers.add(leaf);\n    }\n\n    return readers;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d470c8182e92b264680e34081b75e70a9f2b3c89","date":1463985353,"type":0,"author":"Noble Paul","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/MergeState#maybeSortReaders(List[CodecReader],SegmentInfo).mjava","pathOld":"/dev/null","sourceNew":"  private List<CodecReader> maybeSortReaders(List<CodecReader> originalReaders, SegmentInfo segmentInfo) throws IOException {\n\n    // Default to identity:\n    for(int i=0;i<originalReaders.size();i++) {\n      leafDocMaps[i] = new DocMap() {\n          @Override\n          public int get(int docID) {\n            return docID;\n          }\n        };\n    }\n\n    Sort indexSort = segmentInfo.getIndexSort();\n    if (indexSort == null) {\n      return originalReaders;\n    }\n\n    // If an incoming reader is not sorted, because it was flushed by IW, we sort it here:\n    final Sorter sorter = new Sorter(indexSort);\n    List<CodecReader> readers = new ArrayList<>(originalReaders.size());\n\n    for (CodecReader leaf : originalReaders) {\n      Sort segmentSort = leaf.getIndexSort();\n\n      if (segmentSort == null) {\n        // TODO: fix IW to also sort when flushing?  It's somewhat tricky because of stored fields and term vectors, which write \"live\"\n        // to their index files on each indexed document:\n\n        // This segment was written by flush, so documents are not yet sorted, so we sort them now:\n        long t0 = System.nanoTime();\n        Sorter.DocMap sortDocMap = sorter.sort(leaf);\n        long t1 = System.nanoTime();\n        double msec = (t1-t0)/1000000.0;\n        \n        if (sortDocMap != null) {\n          if (infoStream.isEnabled(\"SM\")) {\n            infoStream.message(\"SM\", String.format(Locale.ROOT, \"segment %s is not sorted; wrapping for sort %s now (%.2f msec to sort)\", leaf, indexSort, msec));\n          }\n          leaf = SlowCodecReaderWrapper.wrap(SortingLeafReader.wrap(new MergeReaderWrapper(leaf), sortDocMap));\n          leafDocMaps[readers.size()] = new DocMap() {\n              @Override\n              public int get(int docID) {\n                return sortDocMap.oldToNew(docID);\n              }\n            };\n        } else {\n          if (infoStream.isEnabled(\"SM\")) {\n            infoStream.message(\"SM\", String.format(Locale.ROOT, \"segment %s is not sorted, but is already accidentally in sort %s order (%.2f msec to sort)\", leaf, indexSort, msec));\n          }\n        }\n\n      } else {\n        if (segmentSort.equals(indexSort) == false) {\n          throw new IllegalArgumentException(\"index sort mismatch: merged segment has sort=\" + indexSort + \" but to-be-merged segment has sort=\" + segmentSort);\n        }\n        if (infoStream.isEnabled(\"SM\")) {\n          infoStream.message(\"SM\", \"segment \" + leaf + \" already sorted\");\n        }\n      }\n\n      readers.add(leaf);\n    }\n\n    return readers;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/MergeState#maybeSortReaders(List[CodecReader],SegmentInfo).mjava","pathOld":"/dev/null","sourceNew":"  private List<CodecReader> maybeSortReaders(List<CodecReader> originalReaders, SegmentInfo segmentInfo) throws IOException {\n\n    // Default to identity:\n    for(int i=0;i<originalReaders.size();i++) {\n      leafDocMaps[i] = new DocMap() {\n          @Override\n          public int get(int docID) {\n            return docID;\n          }\n        };\n    }\n\n    Sort indexSort = segmentInfo.getIndexSort();\n    if (indexSort == null) {\n      return originalReaders;\n    }\n\n    // If an incoming reader is not sorted, because it was flushed by IW, we sort it here:\n    final Sorter sorter = new Sorter(indexSort);\n    List<CodecReader> readers = new ArrayList<>(originalReaders.size());\n\n    for (CodecReader leaf : originalReaders) {\n      Sort segmentSort = leaf.getIndexSort();\n\n      if (segmentSort == null) {\n        // TODO: fix IW to also sort when flushing?  It's somewhat tricky because of stored fields and term vectors, which write \"live\"\n        // to their index files on each indexed document:\n\n        // This segment was written by flush, so documents are not yet sorted, so we sort them now:\n        long t0 = System.nanoTime();\n        Sorter.DocMap sortDocMap = sorter.sort(leaf);\n        long t1 = System.nanoTime();\n        double msec = (t1-t0)/1000000.0;\n        \n        if (sortDocMap != null) {\n          if (infoStream.isEnabled(\"SM\")) {\n            infoStream.message(\"SM\", String.format(Locale.ROOT, \"segment %s is not sorted; wrapping for sort %s now (%.2f msec to sort)\", leaf, indexSort, msec));\n          }\n          leaf = SlowCodecReaderWrapper.wrap(SortingLeafReader.wrap(new MergeReaderWrapper(leaf), sortDocMap));\n          leafDocMaps[readers.size()] = new DocMap() {\n              @Override\n              public int get(int docID) {\n                return sortDocMap.oldToNew(docID);\n              }\n            };\n        } else {\n          if (infoStream.isEnabled(\"SM\")) {\n            infoStream.message(\"SM\", String.format(Locale.ROOT, \"segment %s is not sorted, but is already accidentally in sort %s order (%.2f msec to sort)\", leaf, indexSort, msec));\n          }\n        }\n\n      } else {\n        if (segmentSort.equals(indexSort) == false) {\n          throw new IllegalArgumentException(\"index sort mismatch: merged segment has sort=\" + indexSort + \" but to-be-merged segment has sort=\" + segmentSort);\n        }\n        if (infoStream.isEnabled(\"SM\")) {\n          infoStream.message(\"SM\", \"segment \" + leaf + \" already sorted\");\n        }\n      }\n\n      readers.add(leaf);\n    }\n\n    return readers;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"653128722fb3b4713ac331c621491a93f34a4a22","date":1479841816,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/MergeState#maybeSortReaders(List[CodecReader],SegmentInfo).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/MergeState#maybeSortReaders(List[CodecReader],SegmentInfo).mjava","sourceNew":"  private List<CodecReader> maybeSortReaders(List<CodecReader> originalReaders, SegmentInfo segmentInfo) throws IOException {\n\n    // Default to identity:\n    for(int i=0;i<originalReaders.size();i++) {\n      leafDocMaps[i] = new DocMap() {\n          @Override\n          public int get(int docID) {\n            return docID;\n          }\n        };\n    }\n\n    Sort indexSort = segmentInfo.getIndexSort();\n    if (indexSort == null) {\n      return originalReaders;\n    }\n\n    // If an incoming reader is not sorted, because it was flushed by IW, we sort it here:\n    final Sorter sorter = new Sorter(indexSort);\n    List<CodecReader> readers = new ArrayList<>(originalReaders.size());\n\n    for (CodecReader leaf : originalReaders) {\n      Sort segmentSort = leaf.getIndexSort();\n\n      if (segmentSort == null) {\n        // TODO: fix IW to also sort when flushing?  It's somewhat tricky because of stored fields and term vectors, which write \"live\"\n        // to their index files on each indexed document:\n\n        // This segment was written by flush, so documents are not yet sorted, so we sort them now:\n        long t0 = System.nanoTime();\n        Sorter.DocMap sortDocMap = sorter.sort(leaf);\n        long t1 = System.nanoTime();\n        double msec = (t1-t0)/1000000.0;\n        \n        if (sortDocMap != null) {\n          if (infoStream.isEnabled(\"SM\")) {\n            infoStream.message(\"SM\", String.format(Locale.ROOT, \"segment %s is not sorted; wrapping for sort %s now (%.2f msec to sort)\", leaf, indexSort, msec));\n          }\n          needsIndexSort = true;\n          leaf = SlowCodecReaderWrapper.wrap(SortingLeafReader.wrap(new MergeReaderWrapper(leaf), sortDocMap));\n          leafDocMaps[readers.size()] = new DocMap() {\n              @Override\n              public int get(int docID) {\n                return sortDocMap.oldToNew(docID);\n              }\n            };\n        } else {\n          if (infoStream.isEnabled(\"SM\")) {\n            infoStream.message(\"SM\", String.format(Locale.ROOT, \"segment %s is not sorted, but is already accidentally in sort %s order (%.2f msec to sort)\", leaf, indexSort, msec));\n          }\n        }\n\n      } else {\n        if (segmentSort.equals(indexSort) == false) {\n          throw new IllegalArgumentException(\"index sort mismatch: merged segment has sort=\" + indexSort + \" but to-be-merged segment has sort=\" + segmentSort);\n        }\n        if (infoStream.isEnabled(\"SM\")) {\n          infoStream.message(\"SM\", \"segment \" + leaf + \" already sorted\");\n        }\n      }\n\n      readers.add(leaf);\n    }\n\n    return readers;\n  }\n\n","sourceOld":"  private List<CodecReader> maybeSortReaders(List<CodecReader> originalReaders, SegmentInfo segmentInfo) throws IOException {\n\n    // Default to identity:\n    for(int i=0;i<originalReaders.size();i++) {\n      leafDocMaps[i] = new DocMap() {\n          @Override\n          public int get(int docID) {\n            return docID;\n          }\n        };\n    }\n\n    Sort indexSort = segmentInfo.getIndexSort();\n    if (indexSort == null) {\n      return originalReaders;\n    }\n\n    // If an incoming reader is not sorted, because it was flushed by IW, we sort it here:\n    final Sorter sorter = new Sorter(indexSort);\n    List<CodecReader> readers = new ArrayList<>(originalReaders.size());\n\n    for (CodecReader leaf : originalReaders) {\n      Sort segmentSort = leaf.getIndexSort();\n\n      if (segmentSort == null) {\n        // TODO: fix IW to also sort when flushing?  It's somewhat tricky because of stored fields and term vectors, which write \"live\"\n        // to their index files on each indexed document:\n\n        // This segment was written by flush, so documents are not yet sorted, so we sort them now:\n        long t0 = System.nanoTime();\n        Sorter.DocMap sortDocMap = sorter.sort(leaf);\n        long t1 = System.nanoTime();\n        double msec = (t1-t0)/1000000.0;\n        \n        if (sortDocMap != null) {\n          if (infoStream.isEnabled(\"SM\")) {\n            infoStream.message(\"SM\", String.format(Locale.ROOT, \"segment %s is not sorted; wrapping for sort %s now (%.2f msec to sort)\", leaf, indexSort, msec));\n          }\n          leaf = SlowCodecReaderWrapper.wrap(SortingLeafReader.wrap(new MergeReaderWrapper(leaf), sortDocMap));\n          leafDocMaps[readers.size()] = new DocMap() {\n              @Override\n              public int get(int docID) {\n                return sortDocMap.oldToNew(docID);\n              }\n            };\n        } else {\n          if (infoStream.isEnabled(\"SM\")) {\n            infoStream.message(\"SM\", String.format(Locale.ROOT, \"segment %s is not sorted, but is already accidentally in sort %s order (%.2f msec to sort)\", leaf, indexSort, msec));\n          }\n        }\n\n      } else {\n        if (segmentSort.equals(indexSort) == false) {\n          throw new IllegalArgumentException(\"index sort mismatch: merged segment has sort=\" + indexSort + \" but to-be-merged segment has sort=\" + segmentSort);\n        }\n        if (infoStream.isEnabled(\"SM\")) {\n          infoStream.message(\"SM\", \"segment \" + leaf + \" already sorted\");\n        }\n      }\n\n      readers.add(leaf);\n    }\n\n    return readers;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"727bb765ff2542275f6d31f67be18d7104bae148","date":1480353976,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/MergeState#maybeSortReaders(List[CodecReader],SegmentInfo).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/MergeState#maybeSortReaders(List[CodecReader],SegmentInfo).mjava","sourceNew":"  private List<CodecReader> maybeSortReaders(List<CodecReader> originalReaders, SegmentInfo segmentInfo) throws IOException {\n\n    // Default to identity:\n    for(int i=0;i<originalReaders.size();i++) {\n      leafDocMaps[i] = new DocMap() {\n          @Override\n          public int get(int docID) {\n            return docID;\n          }\n        };\n    }\n\n    Sort indexSort = segmentInfo.getIndexSort();\n    if (indexSort == null) {\n      return originalReaders;\n    }\n\n    // If an incoming reader is not sorted, because it was flushed by IW, we sort it here:\n    final Sorter sorter = new Sorter(indexSort);\n    List<CodecReader> readers = new ArrayList<>(originalReaders.size());\n\n    for (CodecReader leaf : originalReaders) {\n      Sort segmentSort = leaf.getIndexSort();\n\n      if (segmentSort == null) {\n        // TODO: fix IW to also sort when flushing?  It's somewhat tricky because of stored fields and term vectors, which write \"live\"\n        // to their index files on each indexed document:\n\n        // This segment was written by flush, so documents are not yet sorted, so we sort them now:\n        long t0 = System.nanoTime();\n        Sorter.DocMap sortDocMap = sorter.sort(leaf);\n        long t1 = System.nanoTime();\n        double msec = (t1-t0)/1000000.0;\n        \n        if (sortDocMap != null) {\n          if (infoStream.isEnabled(\"SM\")) {\n            infoStream.message(\"SM\", String.format(Locale.ROOT, \"segment %s is not sorted; wrapping for sort %s now (%.2f msec to sort)\", leaf, indexSort, msec));\n          }\n          needsIndexSort = true;\n          leaf = SlowCodecReaderWrapper.wrap(SortingLeafReader.wrap(new MergeReaderWrapper(leaf), sortDocMap));\n          leafDocMaps[readers.size()] = new DocMap() {\n              @Override\n              public int get(int docID) {\n                return sortDocMap.oldToNew(docID);\n              }\n            };\n        } else {\n          if (infoStream.isEnabled(\"SM\")) {\n            infoStream.message(\"SM\", String.format(Locale.ROOT, \"segment %s is not sorted, but is already accidentally in sort %s order (%.2f msec to sort)\", leaf, indexSort, msec));\n          }\n        }\n\n      } else {\n        if (segmentSort.equals(indexSort) == false) {\n          throw new IllegalArgumentException(\"index sort mismatch: merged segment has sort=\" + indexSort + \" but to-be-merged segment has sort=\" + segmentSort);\n        }\n        if (infoStream.isEnabled(\"SM\")) {\n          infoStream.message(\"SM\", \"segment \" + leaf + \" already sorted\");\n        }\n      }\n\n      readers.add(leaf);\n    }\n\n    return readers;\n  }\n\n","sourceOld":"  private List<CodecReader> maybeSortReaders(List<CodecReader> originalReaders, SegmentInfo segmentInfo) throws IOException {\n\n    // Default to identity:\n    for(int i=0;i<originalReaders.size();i++) {\n      leafDocMaps[i] = new DocMap() {\n          @Override\n          public int get(int docID) {\n            return docID;\n          }\n        };\n    }\n\n    Sort indexSort = segmentInfo.getIndexSort();\n    if (indexSort == null) {\n      return originalReaders;\n    }\n\n    // If an incoming reader is not sorted, because it was flushed by IW, we sort it here:\n    final Sorter sorter = new Sorter(indexSort);\n    List<CodecReader> readers = new ArrayList<>(originalReaders.size());\n\n    for (CodecReader leaf : originalReaders) {\n      Sort segmentSort = leaf.getIndexSort();\n\n      if (segmentSort == null) {\n        // TODO: fix IW to also sort when flushing?  It's somewhat tricky because of stored fields and term vectors, which write \"live\"\n        // to their index files on each indexed document:\n\n        // This segment was written by flush, so documents are not yet sorted, so we sort them now:\n        long t0 = System.nanoTime();\n        Sorter.DocMap sortDocMap = sorter.sort(leaf);\n        long t1 = System.nanoTime();\n        double msec = (t1-t0)/1000000.0;\n        \n        if (sortDocMap != null) {\n          if (infoStream.isEnabled(\"SM\")) {\n            infoStream.message(\"SM\", String.format(Locale.ROOT, \"segment %s is not sorted; wrapping for sort %s now (%.2f msec to sort)\", leaf, indexSort, msec));\n          }\n          leaf = SlowCodecReaderWrapper.wrap(SortingLeafReader.wrap(new MergeReaderWrapper(leaf), sortDocMap));\n          leafDocMaps[readers.size()] = new DocMap() {\n              @Override\n              public int get(int docID) {\n                return sortDocMap.oldToNew(docID);\n              }\n            };\n        } else {\n          if (infoStream.isEnabled(\"SM\")) {\n            infoStream.message(\"SM\", String.format(Locale.ROOT, \"segment %s is not sorted, but is already accidentally in sort %s order (%.2f msec to sort)\", leaf, indexSort, msec));\n          }\n        }\n\n      } else {\n        if (segmentSort.equals(indexSort) == false) {\n          throw new IllegalArgumentException(\"index sort mismatch: merged segment has sort=\" + indexSort + \" but to-be-merged segment has sort=\" + segmentSort);\n        }\n        if (infoStream.isEnabled(\"SM\")) {\n          infoStream.message(\"SM\", \"segment \" + leaf + \" already sorted\");\n        }\n      }\n\n      readers.add(leaf);\n    }\n\n    return readers;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"86a0a50d2d14aaee1e635bbec914468551f7f9a2","date":1482234306,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/MergeState#maybeSortReaders(List[CodecReader],SegmentInfo).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/MergeState#maybeSortReaders(List[CodecReader],SegmentInfo).mjava","sourceNew":"  private List<CodecReader> maybeSortReaders(List<CodecReader> originalReaders, SegmentInfo segmentInfo) throws IOException {\n\n    // Default to identity:\n    for(int i=0;i<originalReaders.size();i++) {\n      leafDocMaps[i] = new DocMap() {\n          @Override\n          public int get(int docID) {\n            return docID;\n          }\n        };\n    }\n\n    Sort indexSort = segmentInfo.getIndexSort();\n    if (indexSort == null) {\n      return originalReaders;\n    }\n\n    /** If an incoming reader is not sorted, because it was flushed by IW older than {@link Version.LUCENE_7_0_0}\n     * or because we add unsorted segments from another index {@link IndexWriter#addIndexes(CodecReader...)} ,\n     * we sort it here:\n     */\n    final Sorter sorter = new Sorter(indexSort);\n    List<CodecReader> readers = new ArrayList<>(originalReaders.size());\n\n    for (CodecReader leaf : originalReaders) {\n      Sort segmentSort = leaf.getIndexSort();\n\n      if (segmentSort == null) {\n        // This segment was written by flush, so documents are not yet sorted, so we sort them now:\n        long t0 = System.nanoTime();\n        Sorter.DocMap sortDocMap = sorter.sort(leaf);\n        long t1 = System.nanoTime();\n        double msec = (t1-t0)/1000000.0;\n        \n        if (sortDocMap != null) {\n          if (infoStream.isEnabled(\"SM\")) {\n            infoStream.message(\"SM\", String.format(Locale.ROOT, \"segment %s is not sorted; wrapping for sort %s now (%.2f msec to sort)\", leaf, indexSort, msec));\n          }\n          needsIndexSort = true;\n          leaf = SlowCodecReaderWrapper.wrap(SortingLeafReader.wrap(new MergeReaderWrapper(leaf), sortDocMap));\n          leafDocMaps[readers.size()] = new DocMap() {\n              @Override\n              public int get(int docID) {\n                return sortDocMap.oldToNew(docID);\n              }\n            };\n        } else {\n          if (infoStream.isEnabled(\"SM\")) {\n            infoStream.message(\"SM\", String.format(Locale.ROOT, \"segment %s is not sorted, but is already accidentally in sort %s order (%.2f msec to sort)\", leaf, indexSort, msec));\n          }\n        }\n\n      } else {\n        if (segmentSort.equals(indexSort) == false) {\n          throw new IllegalArgumentException(\"index sort mismatch: merged segment has sort=\" + indexSort + \" but to-be-merged segment has sort=\" + segmentSort);\n        }\n        if (infoStream.isEnabled(\"SM\")) {\n          infoStream.message(\"SM\", \"segment \" + leaf + \" already sorted\");\n        }\n      }\n\n      readers.add(leaf);\n    }\n\n    return readers;\n  }\n\n","sourceOld":"  private List<CodecReader> maybeSortReaders(List<CodecReader> originalReaders, SegmentInfo segmentInfo) throws IOException {\n\n    // Default to identity:\n    for(int i=0;i<originalReaders.size();i++) {\n      leafDocMaps[i] = new DocMap() {\n          @Override\n          public int get(int docID) {\n            return docID;\n          }\n        };\n    }\n\n    Sort indexSort = segmentInfo.getIndexSort();\n    if (indexSort == null) {\n      return originalReaders;\n    }\n\n    // If an incoming reader is not sorted, because it was flushed by IW, we sort it here:\n    final Sorter sorter = new Sorter(indexSort);\n    List<CodecReader> readers = new ArrayList<>(originalReaders.size());\n\n    for (CodecReader leaf : originalReaders) {\n      Sort segmentSort = leaf.getIndexSort();\n\n      if (segmentSort == null) {\n        // TODO: fix IW to also sort when flushing?  It's somewhat tricky because of stored fields and term vectors, which write \"live\"\n        // to their index files on each indexed document:\n\n        // This segment was written by flush, so documents are not yet sorted, so we sort them now:\n        long t0 = System.nanoTime();\n        Sorter.DocMap sortDocMap = sorter.sort(leaf);\n        long t1 = System.nanoTime();\n        double msec = (t1-t0)/1000000.0;\n        \n        if (sortDocMap != null) {\n          if (infoStream.isEnabled(\"SM\")) {\n            infoStream.message(\"SM\", String.format(Locale.ROOT, \"segment %s is not sorted; wrapping for sort %s now (%.2f msec to sort)\", leaf, indexSort, msec));\n          }\n          needsIndexSort = true;\n          leaf = SlowCodecReaderWrapper.wrap(SortingLeafReader.wrap(new MergeReaderWrapper(leaf), sortDocMap));\n          leafDocMaps[readers.size()] = new DocMap() {\n              @Override\n              public int get(int docID) {\n                return sortDocMap.oldToNew(docID);\n              }\n            };\n        } else {\n          if (infoStream.isEnabled(\"SM\")) {\n            infoStream.message(\"SM\", String.format(Locale.ROOT, \"segment %s is not sorted, but is already accidentally in sort %s order (%.2f msec to sort)\", leaf, indexSort, msec));\n          }\n        }\n\n      } else {\n        if (segmentSort.equals(indexSort) == false) {\n          throw new IllegalArgumentException(\"index sort mismatch: merged segment has sort=\" + indexSort + \" but to-be-merged segment has sort=\" + segmentSort);\n        }\n        if (infoStream.isEnabled(\"SM\")) {\n          infoStream.message(\"SM\", \"segment \" + leaf + \" already sorted\");\n        }\n      }\n\n      readers.add(leaf);\n    }\n\n    return readers;\n  }\n\n","bugFix":["5e401f4940308a68c615c8893021c88c57010df5","fb0345a2d45479f891041f8b3ce351bc975e64ac","ceaef6cfc68c8ab22a684192e469a8280f9e6e70"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf","date":1482251961,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/MergeState#maybeSortReaders(List[CodecReader],SegmentInfo).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/MergeState#maybeSortReaders(List[CodecReader],SegmentInfo).mjava","sourceNew":"  private List<CodecReader> maybeSortReaders(List<CodecReader> originalReaders, SegmentInfo segmentInfo) throws IOException {\n\n    // Default to identity:\n    for(int i=0;i<originalReaders.size();i++) {\n      leafDocMaps[i] = new DocMap() {\n          @Override\n          public int get(int docID) {\n            return docID;\n          }\n        };\n    }\n\n    Sort indexSort = segmentInfo.getIndexSort();\n    if (indexSort == null) {\n      return originalReaders;\n    }\n\n    /** If an incoming reader is not sorted, because it was flushed by IW older than {@link Version.LUCENE_7_0_0}\n     * or because we add unsorted segments from another index {@link IndexWriter#addIndexes(CodecReader...)} ,\n     * we sort it here:\n     */\n    final Sorter sorter = new Sorter(indexSort);\n    List<CodecReader> readers = new ArrayList<>(originalReaders.size());\n\n    for (CodecReader leaf : originalReaders) {\n      Sort segmentSort = leaf.getIndexSort();\n\n      if (segmentSort == null) {\n        // This segment was written by flush, so documents are not yet sorted, so we sort them now:\n        long t0 = System.nanoTime();\n        Sorter.DocMap sortDocMap = sorter.sort(leaf);\n        long t1 = System.nanoTime();\n        double msec = (t1-t0)/1000000.0;\n        \n        if (sortDocMap != null) {\n          if (infoStream.isEnabled(\"SM\")) {\n            infoStream.message(\"SM\", String.format(Locale.ROOT, \"segment %s is not sorted; wrapping for sort %s now (%.2f msec to sort)\", leaf, indexSort, msec));\n          }\n          needsIndexSort = true;\n          leaf = SlowCodecReaderWrapper.wrap(SortingLeafReader.wrap(new MergeReaderWrapper(leaf), sortDocMap));\n          leafDocMaps[readers.size()] = new DocMap() {\n              @Override\n              public int get(int docID) {\n                return sortDocMap.oldToNew(docID);\n              }\n            };\n        } else {\n          if (infoStream.isEnabled(\"SM\")) {\n            infoStream.message(\"SM\", String.format(Locale.ROOT, \"segment %s is not sorted, but is already accidentally in sort %s order (%.2f msec to sort)\", leaf, indexSort, msec));\n          }\n        }\n\n      } else {\n        if (segmentSort.equals(indexSort) == false) {\n          throw new IllegalArgumentException(\"index sort mismatch: merged segment has sort=\" + indexSort + \" but to-be-merged segment has sort=\" + segmentSort);\n        }\n        if (infoStream.isEnabled(\"SM\")) {\n          infoStream.message(\"SM\", \"segment \" + leaf + \" already sorted\");\n        }\n      }\n\n      readers.add(leaf);\n    }\n\n    return readers;\n  }\n\n","sourceOld":"  private List<CodecReader> maybeSortReaders(List<CodecReader> originalReaders, SegmentInfo segmentInfo) throws IOException {\n\n    // Default to identity:\n    for(int i=0;i<originalReaders.size();i++) {\n      leafDocMaps[i] = new DocMap() {\n          @Override\n          public int get(int docID) {\n            return docID;\n          }\n        };\n    }\n\n    Sort indexSort = segmentInfo.getIndexSort();\n    if (indexSort == null) {\n      return originalReaders;\n    }\n\n    // If an incoming reader is not sorted, because it was flushed by IW, we sort it here:\n    final Sorter sorter = new Sorter(indexSort);\n    List<CodecReader> readers = new ArrayList<>(originalReaders.size());\n\n    for (CodecReader leaf : originalReaders) {\n      Sort segmentSort = leaf.getIndexSort();\n\n      if (segmentSort == null) {\n        // TODO: fix IW to also sort when flushing?  It's somewhat tricky because of stored fields and term vectors, which write \"live\"\n        // to their index files on each indexed document:\n\n        // This segment was written by flush, so documents are not yet sorted, so we sort them now:\n        long t0 = System.nanoTime();\n        Sorter.DocMap sortDocMap = sorter.sort(leaf);\n        long t1 = System.nanoTime();\n        double msec = (t1-t0)/1000000.0;\n        \n        if (sortDocMap != null) {\n          if (infoStream.isEnabled(\"SM\")) {\n            infoStream.message(\"SM\", String.format(Locale.ROOT, \"segment %s is not sorted; wrapping for sort %s now (%.2f msec to sort)\", leaf, indexSort, msec));\n          }\n          needsIndexSort = true;\n          leaf = SlowCodecReaderWrapper.wrap(SortingLeafReader.wrap(new MergeReaderWrapper(leaf), sortDocMap));\n          leafDocMaps[readers.size()] = new DocMap() {\n              @Override\n              public int get(int docID) {\n                return sortDocMap.oldToNew(docID);\n              }\n            };\n        } else {\n          if (infoStream.isEnabled(\"SM\")) {\n            infoStream.message(\"SM\", String.format(Locale.ROOT, \"segment %s is not sorted, but is already accidentally in sort %s order (%.2f msec to sort)\", leaf, indexSort, msec));\n          }\n        }\n\n      } else {\n        if (segmentSort.equals(indexSort) == false) {\n          throw new IllegalArgumentException(\"index sort mismatch: merged segment has sort=\" + indexSort + \" but to-be-merged segment has sort=\" + segmentSort);\n        }\n        if (infoStream.isEnabled(\"SM\")) {\n          infoStream.message(\"SM\", \"segment \" + leaf + \" already sorted\");\n        }\n      }\n\n      readers.add(leaf);\n    }\n\n    return readers;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"31741cf1390044e38a2ec3127cf302ba841bfd75","date":1491292636,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/MergeState#maybeSortReaders(List[CodecReader],SegmentInfo).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/MergeState#maybeSortReaders(List[CodecReader],SegmentInfo).mjava","sourceNew":"  private List<CodecReader> maybeSortReaders(List<CodecReader> originalReaders, SegmentInfo segmentInfo) throws IOException {\n\n    // Default to identity:\n    for(int i=0;i<originalReaders.size();i++) {\n      leafDocMaps[i] = new DocMap() {\n          @Override\n          public int get(int docID) {\n            return docID;\n          }\n        };\n    }\n\n    Sort indexSort = segmentInfo.getIndexSort();\n    if (indexSort == null) {\n      return originalReaders;\n    }\n\n    /** If an incoming reader is not sorted, because it was flushed by IW older than {@link Version.LUCENE_7_0_0}\n     * or because we add unsorted segments from another index {@link IndexWriter#addIndexes(CodecReader...)} ,\n     * we sort it here:\n     */\n    final Sorter sorter = new Sorter(indexSort);\n    List<CodecReader> readers = new ArrayList<>(originalReaders.size());\n\n    for (CodecReader leaf : originalReaders) {\n      Sort segmentSort = leaf.getMetaData().getSort();\n\n      if (segmentSort == null) {\n        // This segment was written by flush, so documents are not yet sorted, so we sort them now:\n        long t0 = System.nanoTime();\n        Sorter.DocMap sortDocMap = sorter.sort(leaf);\n        long t1 = System.nanoTime();\n        double msec = (t1-t0)/1000000.0;\n        \n        if (sortDocMap != null) {\n          if (infoStream.isEnabled(\"SM\")) {\n            infoStream.message(\"SM\", String.format(Locale.ROOT, \"segment %s is not sorted; wrapping for sort %s now (%.2f msec to sort)\", leaf, indexSort, msec));\n          }\n          needsIndexSort = true;\n          leaf = SlowCodecReaderWrapper.wrap(SortingLeafReader.wrap(new MergeReaderWrapper(leaf), sortDocMap));\n          leafDocMaps[readers.size()] = new DocMap() {\n              @Override\n              public int get(int docID) {\n                return sortDocMap.oldToNew(docID);\n              }\n            };\n        } else {\n          if (infoStream.isEnabled(\"SM\")) {\n            infoStream.message(\"SM\", String.format(Locale.ROOT, \"segment %s is not sorted, but is already accidentally in sort %s order (%.2f msec to sort)\", leaf, indexSort, msec));\n          }\n        }\n\n      } else {\n        if (segmentSort.equals(indexSort) == false) {\n          throw new IllegalArgumentException(\"index sort mismatch: merged segment has sort=\" + indexSort + \" but to-be-merged segment has sort=\" + segmentSort);\n        }\n        if (infoStream.isEnabled(\"SM\")) {\n          infoStream.message(\"SM\", \"segment \" + leaf + \" already sorted\");\n        }\n      }\n\n      readers.add(leaf);\n    }\n\n    return readers;\n  }\n\n","sourceOld":"  private List<CodecReader> maybeSortReaders(List<CodecReader> originalReaders, SegmentInfo segmentInfo) throws IOException {\n\n    // Default to identity:\n    for(int i=0;i<originalReaders.size();i++) {\n      leafDocMaps[i] = new DocMap() {\n          @Override\n          public int get(int docID) {\n            return docID;\n          }\n        };\n    }\n\n    Sort indexSort = segmentInfo.getIndexSort();\n    if (indexSort == null) {\n      return originalReaders;\n    }\n\n    /** If an incoming reader is not sorted, because it was flushed by IW older than {@link Version.LUCENE_7_0_0}\n     * or because we add unsorted segments from another index {@link IndexWriter#addIndexes(CodecReader...)} ,\n     * we sort it here:\n     */\n    final Sorter sorter = new Sorter(indexSort);\n    List<CodecReader> readers = new ArrayList<>(originalReaders.size());\n\n    for (CodecReader leaf : originalReaders) {\n      Sort segmentSort = leaf.getIndexSort();\n\n      if (segmentSort == null) {\n        // This segment was written by flush, so documents are not yet sorted, so we sort them now:\n        long t0 = System.nanoTime();\n        Sorter.DocMap sortDocMap = sorter.sort(leaf);\n        long t1 = System.nanoTime();\n        double msec = (t1-t0)/1000000.0;\n        \n        if (sortDocMap != null) {\n          if (infoStream.isEnabled(\"SM\")) {\n            infoStream.message(\"SM\", String.format(Locale.ROOT, \"segment %s is not sorted; wrapping for sort %s now (%.2f msec to sort)\", leaf, indexSort, msec));\n          }\n          needsIndexSort = true;\n          leaf = SlowCodecReaderWrapper.wrap(SortingLeafReader.wrap(new MergeReaderWrapper(leaf), sortDocMap));\n          leafDocMaps[readers.size()] = new DocMap() {\n              @Override\n              public int get(int docID) {\n                return sortDocMap.oldToNew(docID);\n              }\n            };\n        } else {\n          if (infoStream.isEnabled(\"SM\")) {\n            infoStream.message(\"SM\", String.format(Locale.ROOT, \"segment %s is not sorted, but is already accidentally in sort %s order (%.2f msec to sort)\", leaf, indexSort, msec));\n          }\n        }\n\n      } else {\n        if (segmentSort.equals(indexSort) == false) {\n          throw new IllegalArgumentException(\"index sort mismatch: merged segment has sort=\" + indexSort + \" but to-be-merged segment has sort=\" + segmentSort);\n        }\n        if (infoStream.isEnabled(\"SM\")) {\n          infoStream.message(\"SM\", \"segment \" + leaf + \" already sorted\");\n        }\n      }\n\n      readers.add(leaf);\n    }\n\n    return readers;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"92212fd254551a0b1156aafc3a1a6ed1a43932ad","date":1491296431,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/MergeState#maybeSortReaders(List[CodecReader],SegmentInfo).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/MergeState#maybeSortReaders(List[CodecReader],SegmentInfo).mjava","sourceNew":"  private List<CodecReader> maybeSortReaders(List<CodecReader> originalReaders, SegmentInfo segmentInfo) throws IOException {\n\n    // Default to identity:\n    for(int i=0;i<originalReaders.size();i++) {\n      leafDocMaps[i] = new DocMap() {\n          @Override\n          public int get(int docID) {\n            return docID;\n          }\n        };\n    }\n\n    Sort indexSort = segmentInfo.getIndexSort();\n    if (indexSort == null) {\n      return originalReaders;\n    }\n\n    /** If an incoming reader is not sorted, because it was flushed by IW older than {@link Version.LUCENE_7_0_0}\n     * or because we add unsorted segments from another index {@link IndexWriter#addIndexes(CodecReader...)} ,\n     * we sort it here:\n     */\n    final Sorter sorter = new Sorter(indexSort);\n    List<CodecReader> readers = new ArrayList<>(originalReaders.size());\n\n    for (CodecReader leaf : originalReaders) {\n      Sort segmentSort = leaf.getMetaData().getSort();\n\n      if (segmentSort == null) {\n        // This segment was written by flush, so documents are not yet sorted, so we sort them now:\n        long t0 = System.nanoTime();\n        Sorter.DocMap sortDocMap = sorter.sort(leaf);\n        long t1 = System.nanoTime();\n        double msec = (t1-t0)/1000000.0;\n        \n        if (sortDocMap != null) {\n          if (infoStream.isEnabled(\"SM\")) {\n            infoStream.message(\"SM\", String.format(Locale.ROOT, \"segment %s is not sorted; wrapping for sort %s now (%.2f msec to sort)\", leaf, indexSort, msec));\n          }\n          needsIndexSort = true;\n          leaf = SlowCodecReaderWrapper.wrap(SortingLeafReader.wrap(new MergeReaderWrapper(leaf), sortDocMap));\n          leafDocMaps[readers.size()] = new DocMap() {\n              @Override\n              public int get(int docID) {\n                return sortDocMap.oldToNew(docID);\n              }\n            };\n        } else {\n          if (infoStream.isEnabled(\"SM\")) {\n            infoStream.message(\"SM\", String.format(Locale.ROOT, \"segment %s is not sorted, but is already accidentally in sort %s order (%.2f msec to sort)\", leaf, indexSort, msec));\n          }\n        }\n\n      } else {\n        if (segmentSort.equals(indexSort) == false) {\n          throw new IllegalArgumentException(\"index sort mismatch: merged segment has sort=\" + indexSort + \" but to-be-merged segment has sort=\" + segmentSort);\n        }\n        if (infoStream.isEnabled(\"SM\")) {\n          infoStream.message(\"SM\", \"segment \" + leaf + \" already sorted\");\n        }\n      }\n\n      readers.add(leaf);\n    }\n\n    return readers;\n  }\n\n","sourceOld":"  private List<CodecReader> maybeSortReaders(List<CodecReader> originalReaders, SegmentInfo segmentInfo) throws IOException {\n\n    // Default to identity:\n    for(int i=0;i<originalReaders.size();i++) {\n      leafDocMaps[i] = new DocMap() {\n          @Override\n          public int get(int docID) {\n            return docID;\n          }\n        };\n    }\n\n    Sort indexSort = segmentInfo.getIndexSort();\n    if (indexSort == null) {\n      return originalReaders;\n    }\n\n    /** If an incoming reader is not sorted, because it was flushed by IW older than {@link Version.LUCENE_7_0_0}\n     * or because we add unsorted segments from another index {@link IndexWriter#addIndexes(CodecReader...)} ,\n     * we sort it here:\n     */\n    final Sorter sorter = new Sorter(indexSort);\n    List<CodecReader> readers = new ArrayList<>(originalReaders.size());\n\n    for (CodecReader leaf : originalReaders) {\n      Sort segmentSort = leaf.getIndexSort();\n\n      if (segmentSort == null) {\n        // This segment was written by flush, so documents are not yet sorted, so we sort them now:\n        long t0 = System.nanoTime();\n        Sorter.DocMap sortDocMap = sorter.sort(leaf);\n        long t1 = System.nanoTime();\n        double msec = (t1-t0)/1000000.0;\n        \n        if (sortDocMap != null) {\n          if (infoStream.isEnabled(\"SM\")) {\n            infoStream.message(\"SM\", String.format(Locale.ROOT, \"segment %s is not sorted; wrapping for sort %s now (%.2f msec to sort)\", leaf, indexSort, msec));\n          }\n          needsIndexSort = true;\n          leaf = SlowCodecReaderWrapper.wrap(SortingLeafReader.wrap(new MergeReaderWrapper(leaf), sortDocMap));\n          leafDocMaps[readers.size()] = new DocMap() {\n              @Override\n              public int get(int docID) {\n                return sortDocMap.oldToNew(docID);\n              }\n            };\n        } else {\n          if (infoStream.isEnabled(\"SM\")) {\n            infoStream.message(\"SM\", String.format(Locale.ROOT, \"segment %s is not sorted, but is already accidentally in sort %s order (%.2f msec to sort)\", leaf, indexSort, msec));\n          }\n        }\n\n      } else {\n        if (segmentSort.equals(indexSort) == false) {\n          throw new IllegalArgumentException(\"index sort mismatch: merged segment has sort=\" + indexSort + \" but to-be-merged segment has sort=\" + segmentSort);\n        }\n        if (infoStream.isEnabled(\"SM\")) {\n          infoStream.message(\"SM\", \"segment \" + leaf + \" already sorted\");\n        }\n      }\n\n      readers.add(leaf);\n    }\n\n    return readers;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6e22133c22c69a013e8c3c14bb986e7848c7296e","date":1537859647,"type":3,"author":"Jim Ferenczi","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/MergeState#maybeSortReaders(List[CodecReader],SegmentInfo).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/MergeState#maybeSortReaders(List[CodecReader],SegmentInfo).mjava","sourceNew":"  private List<CodecReader> maybeSortReaders(List<CodecReader> originalReaders, SegmentInfo segmentInfo) throws IOException {\n\n    // Default to identity:\n    for(int i=0;i<originalReaders.size();i++) {\n      leafDocMaps[i] = new DocMap() {\n          @Override\n          public int get(int docID) {\n            return docID;\n          }\n        };\n    }\n\n    Sort indexSort = segmentInfo.getIndexSort();\n    if (indexSort == null) {\n      return originalReaders;\n    }\n\n    List<CodecReader> readers = new ArrayList<>(originalReaders.size());\n\n    for (CodecReader leaf : originalReaders) {\n      Sort segmentSort = leaf.getMetaData().getSort();\n      if (segmentSort == null || isCongruentSort(indexSort, segmentSort) == false) {\n        throw new IllegalArgumentException(\"index sort mismatch: merged segment has sort=\" + indexSort +\n            \" but to-be-merged segment has sort=\" + (segmentSort == null ? \"null\" : segmentSort));\n      }\n      readers.add(leaf);\n    }\n\n    return readers;\n  }\n\n","sourceOld":"  private List<CodecReader> maybeSortReaders(List<CodecReader> originalReaders, SegmentInfo segmentInfo) throws IOException {\n\n    // Default to identity:\n    for(int i=0;i<originalReaders.size();i++) {\n      leafDocMaps[i] = new DocMap() {\n          @Override\n          public int get(int docID) {\n            return docID;\n          }\n        };\n    }\n\n    Sort indexSort = segmentInfo.getIndexSort();\n    if (indexSort == null) {\n      return originalReaders;\n    }\n\n    /** If an incoming reader is not sorted, because it was flushed by IW older than {@link Version.LUCENE_7_0_0}\n     * or because we add unsorted segments from another index {@link IndexWriter#addIndexes(CodecReader...)} ,\n     * we sort it here:\n     */\n    final Sorter sorter = new Sorter(indexSort);\n    List<CodecReader> readers = new ArrayList<>(originalReaders.size());\n\n    for (CodecReader leaf : originalReaders) {\n      Sort segmentSort = leaf.getMetaData().getSort();\n\n      if (segmentSort == null) {\n        // This segment was written by flush, so documents are not yet sorted, so we sort them now:\n        long t0 = System.nanoTime();\n        Sorter.DocMap sortDocMap = sorter.sort(leaf);\n        long t1 = System.nanoTime();\n        double msec = (t1-t0)/1000000.0;\n        \n        if (sortDocMap != null) {\n          if (infoStream.isEnabled(\"SM\")) {\n            infoStream.message(\"SM\", String.format(Locale.ROOT, \"segment %s is not sorted; wrapping for sort %s now (%.2f msec to sort)\", leaf, indexSort, msec));\n          }\n          needsIndexSort = true;\n          leaf = SlowCodecReaderWrapper.wrap(SortingLeafReader.wrap(new MergeReaderWrapper(leaf), sortDocMap));\n          leafDocMaps[readers.size()] = new DocMap() {\n              @Override\n              public int get(int docID) {\n                return sortDocMap.oldToNew(docID);\n              }\n            };\n        } else {\n          if (infoStream.isEnabled(\"SM\")) {\n            infoStream.message(\"SM\", String.format(Locale.ROOT, \"segment %s is not sorted, but is already accidentally in sort %s order (%.2f msec to sort)\", leaf, indexSort, msec));\n          }\n        }\n\n      } else {\n        if (segmentSort.equals(indexSort) == false) {\n          throw new IllegalArgumentException(\"index sort mismatch: merged segment has sort=\" + indexSort + \" but to-be-merged segment has sort=\" + segmentSort);\n        }\n        if (infoStream.isEnabled(\"SM\")) {\n          infoStream.message(\"SM\", \"segment \" + leaf + \" already sorted\");\n        }\n      }\n\n      readers.add(leaf);\n    }\n\n    return readers;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"0a6d0e4c7ab9c0e1fc073fddd21f4784555be9cd":["5e03940e6e9044943de4b7ac08f8581da37a9534"],"0ad30c6a479e764150a3316e57263319775f1df2":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","3d33e731a93d4b57e662ff094f64f94a745422d4"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","d470c8182e92b264680e34081b75e70a9f2b3c89"],"31741cf1390044e38a2ec3127cf302ba841bfd75":["86a0a50d2d14aaee1e635bbec914468551f7f9a2"],"d470c8182e92b264680e34081b75e70a9f2b3c89":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","0ad30c6a479e764150a3316e57263319775f1df2"],"fb0345a2d45479f891041f8b3ce351bc975e64ac":["6d8200beeffd3fa5155855f4cb8a8a5e38aeff14"],"727bb765ff2542275f6d31f67be18d7104bae148":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","653128722fb3b4713ac331c621491a93f34a4a22"],"6e22133c22c69a013e8c3c14bb986e7848c7296e":["31741cf1390044e38a2ec3127cf302ba841bfd75"],"ceaef6cfc68c8ab22a684192e469a8280f9e6e70":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf":["727bb765ff2542275f6d31f67be18d7104bae148","86a0a50d2d14aaee1e635bbec914468551f7f9a2"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"6d8200beeffd3fa5155855f4cb8a8a5e38aeff14":["5e401f4940308a68c615c8893021c88c57010df5"],"5e401f4940308a68c615c8893021c88c57010df5":["ceaef6cfc68c8ab22a684192e469a8280f9e6e70"],"5e03940e6e9044943de4b7ac08f8581da37a9534":["fb0345a2d45479f891041f8b3ce351bc975e64ac"],"92212fd254551a0b1156aafc3a1a6ed1a43932ad":["86a0a50d2d14aaee1e635bbec914468551f7f9a2"],"3d33e731a93d4b57e662ff094f64f94a745422d4":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","0a6d0e4c7ab9c0e1fc073fddd21f4784555be9cd"],"86a0a50d2d14aaee1e635bbec914468551f7f9a2":["653128722fb3b4713ac331c621491a93f34a4a22"],"653128722fb3b4713ac331c621491a93f34a4a22":["d470c8182e92b264680e34081b75e70a9f2b3c89"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["6e22133c22c69a013e8c3c14bb986e7848c7296e"]},"commit2Childs":{"0a6d0e4c7ab9c0e1fc073fddd21f4784555be9cd":["3d33e731a93d4b57e662ff094f64f94a745422d4"],"0ad30c6a479e764150a3316e57263319775f1df2":["d470c8182e92b264680e34081b75e70a9f2b3c89"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["727bb765ff2542275f6d31f67be18d7104bae148"],"d470c8182e92b264680e34081b75e70a9f2b3c89":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","653128722fb3b4713ac331c621491a93f34a4a22"],"31741cf1390044e38a2ec3127cf302ba841bfd75":["6e22133c22c69a013e8c3c14bb986e7848c7296e"],"fb0345a2d45479f891041f8b3ce351bc975e64ac":["5e03940e6e9044943de4b7ac08f8581da37a9534"],"727bb765ff2542275f6d31f67be18d7104bae148":["5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf"],"6e22133c22c69a013e8c3c14bb986e7848c7296e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"ceaef6cfc68c8ab22a684192e469a8280f9e6e70":["5e401f4940308a68c615c8893021c88c57010df5"],"5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["0ad30c6a479e764150a3316e57263319775f1df2","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","d470c8182e92b264680e34081b75e70a9f2b3c89","ceaef6cfc68c8ab22a684192e469a8280f9e6e70","3d33e731a93d4b57e662ff094f64f94a745422d4"],"6d8200beeffd3fa5155855f4cb8a8a5e38aeff14":["fb0345a2d45479f891041f8b3ce351bc975e64ac"],"5e401f4940308a68c615c8893021c88c57010df5":["6d8200beeffd3fa5155855f4cb8a8a5e38aeff14"],"5e03940e6e9044943de4b7ac08f8581da37a9534":["0a6d0e4c7ab9c0e1fc073fddd21f4784555be9cd"],"92212fd254551a0b1156aafc3a1a6ed1a43932ad":[],"3d33e731a93d4b57e662ff094f64f94a745422d4":["0ad30c6a479e764150a3316e57263319775f1df2"],"86a0a50d2d14aaee1e635bbec914468551f7f9a2":["31741cf1390044e38a2ec3127cf302ba841bfd75","5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf","92212fd254551a0b1156aafc3a1a6ed1a43932ad"],"653128722fb3b4713ac331c621491a93f34a4a22":["727bb765ff2542275f6d31f67be18d7104bae148","86a0a50d2d14aaee1e635bbec914468551f7f9a2"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf","92212fd254551a0b1156aafc3a1a6ed1a43932ad","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}