{"path":"src/test/org/apache/lucene/analysis/TestTokenStreamBWComp#consumeStreamOldAPI(TokenStream).mjava","commits":[{"id":"ec8b5a20a12931b8d7e616c79c5248ae06cc5568","date":1248471948,"type":0,"author":"Michael Busch","isMerge":false,"pathNew":"src/test/org/apache/lucene/analysis/TestTokenStreamBWComp#consumeStreamOldAPI(TokenStream).mjava","pathOld":"/dev/null","sourceNew":"  private static void consumeStreamOldAPI(TokenStream stream) throws IOException {\n    stream.reset();\n    Token reusableToken = new Token();\n    \n    while ((reusableToken = stream.next(reusableToken)) != null) {\n      String term = reusableToken.term();\n      Payload p = reusableToken.getPayload();\n      if (p != null && p.getData().length == 1 && p.getData()[0] == PartOfSpeechAnnotatingFilter.PROPER_NOUN_ANNOTATION) {\n        assertTrue(\"only TokenStream is a proper noun\", \"tokenstream\".equals(term));\n      } else {\n        assertFalse(\"all other tokens (if this test fails, the special POSToken subclass is not correctly passed through the chain)\", \"tokenstream\".equals(term));\n      }\n    }   \n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["93995eb4992a09cc5a4b13b04225eca0bca45d57"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"93995eb4992a09cc5a4b13b04225eca0bca45d57","date":1253288184,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/test/org/apache/lucene/analysis/TestTokenStreamBWComp#consumeStreamOldAPI(TokenStream).mjava","pathOld":"src/test/org/apache/lucene/analysis/TestTokenStreamBWComp#consumeStreamOldAPI(TokenStream).mjava","sourceNew":"  private static void consumeStreamOldAPI(TokenStream stream) throws IOException {\n    stream.reset();\n    Token reusableToken = new Token();\n    \n    int i=0;\n    while ((reusableToken = stream.next(reusableToken)) != null) {\n      String term = reusableToken.term();\n      Payload p = reusableToken.getPayload();\n      if (p != null && p.getData().length == 1 && p.getData()[0] == PartOfSpeechAnnotatingFilter.PROPER_NOUN_ANNOTATION) {\n        assertEquals(\"only TokenStream is a proper noun\", \"tokenstream\", term);\n      } else {\n        assertFalse(\"all other tokens (if this test fails, the special POSToken subclass is not correctly passed through the chain)\", \"tokenstream\".equals(term));\n      }\n      assertEquals(results[i], term);\n      i++;\n    }   \n  }\n\n","sourceOld":"  private static void consumeStreamOldAPI(TokenStream stream) throws IOException {\n    stream.reset();\n    Token reusableToken = new Token();\n    \n    while ((reusableToken = stream.next(reusableToken)) != null) {\n      String term = reusableToken.term();\n      Payload p = reusableToken.getPayload();\n      if (p != null && p.getData().length == 1 && p.getData()[0] == PartOfSpeechAnnotatingFilter.PROPER_NOUN_ANNOTATION) {\n        assertTrue(\"only TokenStream is a proper noun\", \"tokenstream\".equals(term));\n      } else {\n        assertFalse(\"all other tokens (if this test fails, the special POSToken subclass is not correctly passed through the chain)\", \"tokenstream\".equals(term));\n      }\n    }   \n  }\n\n","bugFix":["ec8b5a20a12931b8d7e616c79c5248ae06cc5568"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e8d1458a2543cbd30cbfe7929be4dcb5c5251659","date":1254582241,"type":4,"author":"Uwe Schindler","isMerge":false,"pathNew":"/dev/null","pathOld":"src/test/org/apache/lucene/analysis/TestTokenStreamBWComp#consumeStreamOldAPI(TokenStream).mjava","sourceNew":null,"sourceOld":"  private static void consumeStreamOldAPI(TokenStream stream) throws IOException {\n    stream.reset();\n    Token reusableToken = new Token();\n    \n    int i=0;\n    while ((reusableToken = stream.next(reusableToken)) != null) {\n      String term = reusableToken.term();\n      Payload p = reusableToken.getPayload();\n      if (p != null && p.getData().length == 1 && p.getData()[0] == PartOfSpeechAnnotatingFilter.PROPER_NOUN_ANNOTATION) {\n        assertEquals(\"only TokenStream is a proper noun\", \"tokenstream\", term);\n      } else {\n        assertFalse(\"all other tokens (if this test fails, the special POSToken subclass is not correctly passed through the chain)\", \"tokenstream\".equals(term));\n      }\n      assertEquals(results[i], term);\n      i++;\n    }   \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0a046c0c310bc77931fc8441bd920053b607dd14","date":1254584734,"type":4,"author":"Uwe Schindler","isMerge":true,"pathNew":"/dev/null","pathOld":"src/test/org/apache/lucene/analysis/TestTokenStreamBWComp#consumeStreamOldAPI(TokenStream).mjava","sourceNew":null,"sourceOld":"  private static void consumeStreamOldAPI(TokenStream stream) throws IOException {\n    stream.reset();\n    Token reusableToken = new Token();\n    \n    int i=0;\n    while ((reusableToken = stream.next(reusableToken)) != null) {\n      String term = reusableToken.term();\n      Payload p = reusableToken.getPayload();\n      if (p != null && p.getData().length == 1 && p.getData()[0] == PartOfSpeechAnnotatingFilter.PROPER_NOUN_ANNOTATION) {\n        assertEquals(\"only TokenStream is a proper noun\", \"tokenstream\", term);\n      } else {\n        assertFalse(\"all other tokens (if this test fails, the special POSToken subclass is not correctly passed through the chain)\", \"tokenstream\".equals(term));\n      }\n      assertEquals(results[i], term);\n      i++;\n    }   \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"e8d1458a2543cbd30cbfe7929be4dcb5c5251659":["93995eb4992a09cc5a4b13b04225eca0bca45d57"],"93995eb4992a09cc5a4b13b04225eca0bca45d57":["ec8b5a20a12931b8d7e616c79c5248ae06cc5568"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"0a046c0c310bc77931fc8441bd920053b607dd14":["93995eb4992a09cc5a4b13b04225eca0bca45d57","e8d1458a2543cbd30cbfe7929be4dcb5c5251659"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["0a046c0c310bc77931fc8441bd920053b607dd14"],"ec8b5a20a12931b8d7e616c79c5248ae06cc5568":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"e8d1458a2543cbd30cbfe7929be4dcb5c5251659":["0a046c0c310bc77931fc8441bd920053b607dd14"],"93995eb4992a09cc5a4b13b04225eca0bca45d57":["e8d1458a2543cbd30cbfe7929be4dcb5c5251659","0a046c0c310bc77931fc8441bd920053b607dd14"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["ec8b5a20a12931b8d7e616c79c5248ae06cc5568"],"0a046c0c310bc77931fc8441bd920053b607dd14":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"ec8b5a20a12931b8d7e616c79c5248ae06cc5568":["93995eb4992a09cc5a4b13b04225eca0bca45d57"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}