{"path":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTOrdTermsReader#FSTOrdTermsReader(SegmentReadState,PostingsReaderBase).mjava","commits":[{"id":"56df73d43b6fc340f5332322862382c7e30f4368","date":1378304988,"type":1,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTOrdTermsReader#FSTOrdTermsReader(SegmentReadState,PostingsReaderBase).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/temp/TempFSTOrdTermsReader#TempFSTOrdTermsReader(SegmentReadState,PostingsReaderBase).mjava","sourceNew":"  public FSTOrdTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsIndexFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_INDEX_EXTENSION);\n    final String termsBlockFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_BLOCK_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    try {\n      this.indexIn = state.directory.openInput(termsIndexFileName, state.context);\n      this.blockIn = state.directory.openInput(termsBlockFileName, state.context);\n      readHeader(indexIn);\n      readHeader(blockIn);\n      this.postingsReader.init(blockIn);\n      seekDir(blockIn);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = blockIn.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(blockIn.readVInt());\n        boolean hasFreq = fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY;\n        long numTerms = blockIn.readVLong();\n        long sumTotalTermFreq = hasFreq ? blockIn.readVLong() : -1;\n        long sumDocFreq = blockIn.readVLong();\n        int docCount = blockIn.readVInt();\n        int longsSize = blockIn.readVInt();\n        FST<Long> index = new FST<Long>(indexIn, PositiveIntOutputs.getSingleton());\n\n        TermsReader current = new TermsReader(fieldInfo, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize, index);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, current, previous);\n      }\n    } finally {\n      IOUtils.closeWhileHandlingException(indexIn, blockIn);\n    }\n  }\n\n","sourceOld":"  public TempFSTOrdTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsIndexFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, TempFSTOrdTermsWriter.TERMS_INDEX_EXTENSION);\n    final String termsBlockFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, TempFSTOrdTermsWriter.TERMS_BLOCK_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    try {\n      this.indexIn = state.directory.openInput(termsIndexFileName, state.context);\n      this.blockIn = state.directory.openInput(termsBlockFileName, state.context);\n      readHeader(indexIn);\n      readHeader(blockIn);\n      this.postingsReader.init(blockIn);\n      seekDir(blockIn);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = blockIn.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(blockIn.readVInt());\n        boolean hasFreq = fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY;\n        long numTerms = blockIn.readVLong();\n        long sumTotalTermFreq = hasFreq ? blockIn.readVLong() : -1;\n        long sumDocFreq = blockIn.readVLong();\n        int docCount = blockIn.readVInt();\n        int longsSize = blockIn.readVInt();\n        FST<Long> index = new FST<Long>(indexIn, PositiveIntOutputs.getSingleton());\n\n        TermsReader current = new TermsReader(fieldInfo, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize, index);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, current, previous);\n      }\n    } finally {\n      IOUtils.closeWhileHandlingException(indexIn, blockIn);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2f948dd442d23baa6cbb28daf77c8db78b351329","date":1378742876,"type":0,"author":"Han Jiang","isMerge":true,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTOrdTermsReader#FSTOrdTermsReader(SegmentReadState,PostingsReaderBase).mjava","pathOld":"/dev/null","sourceNew":"  public FSTOrdTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsIndexFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_INDEX_EXTENSION);\n    final String termsBlockFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_BLOCK_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    try {\n      this.indexIn = state.directory.openInput(termsIndexFileName, state.context);\n      this.blockIn = state.directory.openInput(termsBlockFileName, state.context);\n      readHeader(indexIn);\n      readHeader(blockIn);\n      this.postingsReader.init(blockIn);\n      seekDir(blockIn);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = blockIn.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(blockIn.readVInt());\n        boolean hasFreq = fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY;\n        long numTerms = blockIn.readVLong();\n        long sumTotalTermFreq = hasFreq ? blockIn.readVLong() : -1;\n        long sumDocFreq = blockIn.readVLong();\n        int docCount = blockIn.readVInt();\n        int longsSize = blockIn.readVInt();\n        FST<Long> index = new FST<Long>(indexIn, PositiveIntOutputs.getSingleton());\n\n        TermsReader current = new TermsReader(fieldInfo, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize, index);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, current, previous);\n      }\n    } finally {\n      IOUtils.closeWhileHandlingException(indexIn, blockIn);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTOrdTermsReader#FSTOrdTermsReader(SegmentReadState,PostingsReaderBase).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTOrdTermsReader#FSTOrdTermsReader(SegmentReadState,PostingsReaderBase).mjava","sourceNew":"  public FSTOrdTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsIndexFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_INDEX_EXTENSION);\n    final String termsBlockFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_BLOCK_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    try {\n      this.indexIn = state.directory.openInput(termsIndexFileName, state.context);\n      this.blockIn = state.directory.openInput(termsBlockFileName, state.context);\n      readHeader(indexIn);\n      readHeader(blockIn);\n      this.postingsReader.init(blockIn);\n      seekDir(blockIn);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = blockIn.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(blockIn.readVInt());\n        boolean hasFreq = fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY;\n        long numTerms = blockIn.readVLong();\n        long sumTotalTermFreq = hasFreq ? blockIn.readVLong() : -1;\n        long sumDocFreq = blockIn.readVLong();\n        int docCount = blockIn.readVInt();\n        int longsSize = blockIn.readVInt();\n        FST<Long> index = new FST<>(indexIn, PositiveIntOutputs.getSingleton());\n\n        TermsReader current = new TermsReader(fieldInfo, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize, index);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, current, previous);\n      }\n    } finally {\n      IOUtils.closeWhileHandlingException(indexIn, blockIn);\n    }\n  }\n\n","sourceOld":"  public FSTOrdTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsIndexFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_INDEX_EXTENSION);\n    final String termsBlockFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_BLOCK_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    try {\n      this.indexIn = state.directory.openInput(termsIndexFileName, state.context);\n      this.blockIn = state.directory.openInput(termsBlockFileName, state.context);\n      readHeader(indexIn);\n      readHeader(blockIn);\n      this.postingsReader.init(blockIn);\n      seekDir(blockIn);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = blockIn.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(blockIn.readVInt());\n        boolean hasFreq = fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY;\n        long numTerms = blockIn.readVLong();\n        long sumTotalTermFreq = hasFreq ? blockIn.readVLong() : -1;\n        long sumDocFreq = blockIn.readVLong();\n        int docCount = blockIn.readVInt();\n        int longsSize = blockIn.readVInt();\n        FST<Long> index = new FST<Long>(indexIn, PositiveIntOutputs.getSingleton());\n\n        TermsReader current = new TermsReader(fieldInfo, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize, index);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, current, previous);\n      }\n    } finally {\n      IOUtils.closeWhileHandlingException(indexIn, blockIn);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1f3b037cd083286b2af89f96e768f85dcd8072d6","date":1396337805,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTOrdTermsReader#FSTOrdTermsReader(SegmentReadState,PostingsReaderBase).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTOrdTermsReader#FSTOrdTermsReader(SegmentReadState,PostingsReaderBase).mjava","sourceNew":"  public FSTOrdTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsIndexFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_INDEX_EXTENSION);\n    final String termsBlockFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_BLOCK_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    ChecksumIndexInput indexIn = null;\n    IndexInput blockIn = null;\n    boolean success = false;\n    try {\n      indexIn = state.directory.openChecksumInput(termsIndexFileName, state.context);\n      blockIn = state.directory.openInput(termsBlockFileName, state.context);\n      version = readHeader(indexIn);\n      readHeader(blockIn);\n      if (version >= FSTOrdTermsWriter.TERMS_VERSION_CHECKSUM) {\n        CodecUtil.checksumEntireFile(blockIn);\n      }\n      \n      this.postingsReader.init(blockIn);\n      seekDir(blockIn);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = blockIn.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(blockIn.readVInt());\n        boolean hasFreq = fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY;\n        long numTerms = blockIn.readVLong();\n        long sumTotalTermFreq = hasFreq ? blockIn.readVLong() : -1;\n        long sumDocFreq = blockIn.readVLong();\n        int docCount = blockIn.readVInt();\n        int longsSize = blockIn.readVInt();\n        FST<Long> index = new FST<>(indexIn, PositiveIntOutputs.getSingleton());\n\n        TermsReader current = new TermsReader(fieldInfo, blockIn, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize, index);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, indexIn, blockIn, current, previous);\n      }\n      if (version >= FSTOrdTermsWriter.TERMS_VERSION_CHECKSUM) {\n        CodecUtil.checkFooter(indexIn);\n      } else {\n        CodecUtil.checkEOF(indexIn);\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(indexIn, blockIn);\n      } else {\n        IOUtils.closeWhileHandlingException(indexIn, blockIn);\n      }\n    }\n  }\n\n","sourceOld":"  public FSTOrdTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsIndexFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_INDEX_EXTENSION);\n    final String termsBlockFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_BLOCK_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    try {\n      this.indexIn = state.directory.openInput(termsIndexFileName, state.context);\n      this.blockIn = state.directory.openInput(termsBlockFileName, state.context);\n      readHeader(indexIn);\n      readHeader(blockIn);\n      this.postingsReader.init(blockIn);\n      seekDir(blockIn);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = blockIn.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(blockIn.readVInt());\n        boolean hasFreq = fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY;\n        long numTerms = blockIn.readVLong();\n        long sumTotalTermFreq = hasFreq ? blockIn.readVLong() : -1;\n        long sumDocFreq = blockIn.readVLong();\n        int docCount = blockIn.readVInt();\n        int longsSize = blockIn.readVInt();\n        FST<Long> index = new FST<>(indexIn, PositiveIntOutputs.getSingleton());\n\n        TermsReader current = new TermsReader(fieldInfo, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize, index);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, current, previous);\n      }\n    } finally {\n      IOUtils.closeWhileHandlingException(indexIn, blockIn);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5eb2511ababf862ea11e10761c70ee560cd84510","date":1396607225,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTOrdTermsReader#FSTOrdTermsReader(SegmentReadState,PostingsReaderBase).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTOrdTermsReader#FSTOrdTermsReader(SegmentReadState,PostingsReaderBase).mjava","sourceNew":"  public FSTOrdTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsIndexFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_INDEX_EXTENSION);\n    final String termsBlockFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_BLOCK_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    ChecksumIndexInput indexIn = null;\n    IndexInput blockIn = null;\n    boolean success = false;\n    try {\n      indexIn = state.directory.openChecksumInput(termsIndexFileName, state.context);\n      blockIn = state.directory.openInput(termsBlockFileName, state.context);\n      version = readHeader(indexIn);\n      readHeader(blockIn);\n      if (version >= FSTOrdTermsWriter.TERMS_VERSION_CHECKSUM) {\n        CodecUtil.checksumEntireFile(blockIn);\n      }\n      \n      this.postingsReader.init(blockIn);\n      seekDir(blockIn);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = blockIn.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(blockIn.readVInt());\n        boolean hasFreq = fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY;\n        long numTerms = blockIn.readVLong();\n        long sumTotalTermFreq = hasFreq ? blockIn.readVLong() : -1;\n        long sumDocFreq = blockIn.readVLong();\n        int docCount = blockIn.readVInt();\n        int longsSize = blockIn.readVInt();\n        FST<Long> index = new FST<>(indexIn, PositiveIntOutputs.getSingleton());\n\n        TermsReader current = new TermsReader(fieldInfo, blockIn, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize, index);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, indexIn, blockIn, current, previous);\n      }\n      if (version >= FSTOrdTermsWriter.TERMS_VERSION_CHECKSUM) {\n        CodecUtil.checkFooter(indexIn);\n      } else {\n        CodecUtil.checkEOF(indexIn);\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(indexIn, blockIn);\n      } else {\n        IOUtils.closeWhileHandlingException(indexIn, blockIn);\n      }\n    }\n  }\n\n","sourceOld":"  public FSTOrdTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsIndexFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_INDEX_EXTENSION);\n    final String termsBlockFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_BLOCK_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    try {\n      this.indexIn = state.directory.openInput(termsIndexFileName, state.context);\n      this.blockIn = state.directory.openInput(termsBlockFileName, state.context);\n      readHeader(indexIn);\n      readHeader(blockIn);\n      this.postingsReader.init(blockIn);\n      seekDir(blockIn);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = blockIn.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(blockIn.readVInt());\n        boolean hasFreq = fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY;\n        long numTerms = blockIn.readVLong();\n        long sumTotalTermFreq = hasFreq ? blockIn.readVLong() : -1;\n        long sumDocFreq = blockIn.readVLong();\n        int docCount = blockIn.readVInt();\n        int longsSize = blockIn.readVInt();\n        FST<Long> index = new FST<>(indexIn, PositiveIntOutputs.getSingleton());\n\n        TermsReader current = new TermsReader(fieldInfo, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize, index);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, current, previous);\n      }\n    } finally {\n      IOUtils.closeWhileHandlingException(indexIn, blockIn);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d640273789c74bf4f1412b99c67294c14293d154","date":1412169281,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTOrdTermsReader#FSTOrdTermsReader(SegmentReadState,PostingsReaderBase).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTOrdTermsReader#FSTOrdTermsReader(SegmentReadState,PostingsReaderBase).mjava","sourceNew":"  public FSTOrdTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsIndexFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_INDEX_EXTENSION);\n    final String termsBlockFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_BLOCK_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    ChecksumIndexInput indexIn = null;\n    IndexInput blockIn = null;\n    boolean success = false;\n    try {\n      indexIn = state.directory.openChecksumInput(termsIndexFileName, state.context);\n      blockIn = state.directory.openInput(termsBlockFileName, state.context);\n      int version = CodecUtil.checkSegmentHeader(indexIn, FSTOrdTermsWriter.TERMS_INDEX_CODEC_NAME, \n                                                          FSTOrdTermsWriter.VERSION_START, \n                                                          FSTOrdTermsWriter.VERSION_CURRENT, \n                                                          state.segmentInfo.getId(), state.segmentSuffix);\n      int version2 = CodecUtil.checkSegmentHeader(blockIn, FSTOrdTermsWriter.TERMS_CODEC_NAME, \n                                                           FSTOrdTermsWriter.VERSION_START, \n                                                           FSTOrdTermsWriter.VERSION_CURRENT, \n                                                           state.segmentInfo.getId(), state.segmentSuffix);\n      \n      if (version != version2) {\n        throw new CorruptIndexException(\"Format versions mismatch: index=\" + version + \", terms=\" + version2, blockIn);\n      }\n\n      CodecUtil.checksumEntireFile(blockIn);\n      \n      this.postingsReader.init(blockIn);\n      seekDir(blockIn);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = blockIn.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(blockIn.readVInt());\n        boolean hasFreq = fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY;\n        long numTerms = blockIn.readVLong();\n        long sumTotalTermFreq = hasFreq ? blockIn.readVLong() : -1;\n        long sumDocFreq = blockIn.readVLong();\n        int docCount = blockIn.readVInt();\n        int longsSize = blockIn.readVInt();\n        FST<Long> index = new FST<>(indexIn, PositiveIntOutputs.getSingleton());\n\n        TermsReader current = new TermsReader(fieldInfo, blockIn, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize, index);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, indexIn, blockIn, current, previous);\n      }\n      CodecUtil.checkFooter(indexIn);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(indexIn, blockIn);\n      } else {\n        IOUtils.closeWhileHandlingException(indexIn, blockIn);\n      }\n    }\n  }\n\n","sourceOld":"  public FSTOrdTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsIndexFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_INDEX_EXTENSION);\n    final String termsBlockFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_BLOCK_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    ChecksumIndexInput indexIn = null;\n    IndexInput blockIn = null;\n    boolean success = false;\n    try {\n      indexIn = state.directory.openChecksumInput(termsIndexFileName, state.context);\n      blockIn = state.directory.openInput(termsBlockFileName, state.context);\n      version = readHeader(indexIn);\n      readHeader(blockIn);\n      if (version >= FSTOrdTermsWriter.TERMS_VERSION_CHECKSUM) {\n        CodecUtil.checksumEntireFile(blockIn);\n      }\n      \n      this.postingsReader.init(blockIn);\n      seekDir(blockIn);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = blockIn.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(blockIn.readVInt());\n        boolean hasFreq = fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY;\n        long numTerms = blockIn.readVLong();\n        long sumTotalTermFreq = hasFreq ? blockIn.readVLong() : -1;\n        long sumDocFreq = blockIn.readVLong();\n        int docCount = blockIn.readVInt();\n        int longsSize = blockIn.readVInt();\n        FST<Long> index = new FST<>(indexIn, PositiveIntOutputs.getSingleton());\n\n        TermsReader current = new TermsReader(fieldInfo, blockIn, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize, index);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, indexIn, blockIn, current, previous);\n      }\n      if (version >= FSTOrdTermsWriter.TERMS_VERSION_CHECKSUM) {\n        CodecUtil.checkFooter(indexIn);\n      } else {\n        CodecUtil.checkEOF(indexIn);\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(indexIn, blockIn);\n      } else {\n        IOUtils.closeWhileHandlingException(indexIn, blockIn);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9bb9a29a5e71a90295f175df8919802993142c9a","date":1412517673,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTOrdTermsReader#FSTOrdTermsReader(SegmentReadState,PostingsReaderBase).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTOrdTermsReader#FSTOrdTermsReader(SegmentReadState,PostingsReaderBase).mjava","sourceNew":"  public FSTOrdTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsIndexFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_INDEX_EXTENSION);\n    final String termsBlockFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_BLOCK_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    ChecksumIndexInput indexIn = null;\n    IndexInput blockIn = null;\n    boolean success = false;\n    try {\n      indexIn = state.directory.openChecksumInput(termsIndexFileName, state.context);\n      blockIn = state.directory.openInput(termsBlockFileName, state.context);\n      int version = CodecUtil.checkSegmentHeader(indexIn, FSTOrdTermsWriter.TERMS_INDEX_CODEC_NAME, \n                                                          FSTOrdTermsWriter.VERSION_START, \n                                                          FSTOrdTermsWriter.VERSION_CURRENT, \n                                                          state.segmentInfo.getId(), state.segmentSuffix);\n      int version2 = CodecUtil.checkSegmentHeader(blockIn, FSTOrdTermsWriter.TERMS_CODEC_NAME, \n                                                           FSTOrdTermsWriter.VERSION_START, \n                                                           FSTOrdTermsWriter.VERSION_CURRENT, \n                                                           state.segmentInfo.getId(), state.segmentSuffix);\n      \n      if (version != version2) {\n        throw new CorruptIndexException(\"Format versions mismatch: index=\" + version + \", terms=\" + version2, blockIn);\n      }\n\n      CodecUtil.checksumEntireFile(blockIn);\n      \n      this.postingsReader.init(blockIn);\n      seekDir(blockIn);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = blockIn.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(blockIn.readVInt());\n        boolean hasFreq = fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY;\n        long numTerms = blockIn.readVLong();\n        long sumTotalTermFreq = hasFreq ? blockIn.readVLong() : -1;\n        long sumDocFreq = blockIn.readVLong();\n        int docCount = blockIn.readVInt();\n        int longsSize = blockIn.readVInt();\n        FST<Long> index = new FST<>(indexIn, PositiveIntOutputs.getSingleton());\n\n        TermsReader current = new TermsReader(fieldInfo, blockIn, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize, index);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, indexIn, blockIn, current, previous);\n      }\n      CodecUtil.checkFooter(indexIn);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(indexIn, blockIn);\n      } else {\n        IOUtils.closeWhileHandlingException(indexIn, blockIn);\n      }\n    }\n  }\n\n","sourceOld":"  public FSTOrdTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsIndexFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_INDEX_EXTENSION);\n    final String termsBlockFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_BLOCK_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    ChecksumIndexInput indexIn = null;\n    IndexInput blockIn = null;\n    boolean success = false;\n    try {\n      indexIn = state.directory.openChecksumInput(termsIndexFileName, state.context);\n      blockIn = state.directory.openInput(termsBlockFileName, state.context);\n      version = readHeader(indexIn);\n      readHeader(blockIn);\n      if (version >= FSTOrdTermsWriter.TERMS_VERSION_CHECKSUM) {\n        CodecUtil.checksumEntireFile(blockIn);\n      }\n      \n      this.postingsReader.init(blockIn);\n      seekDir(blockIn);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = blockIn.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(blockIn.readVInt());\n        boolean hasFreq = fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY;\n        long numTerms = blockIn.readVLong();\n        long sumTotalTermFreq = hasFreq ? blockIn.readVLong() : -1;\n        long sumDocFreq = blockIn.readVLong();\n        int docCount = blockIn.readVInt();\n        int longsSize = blockIn.readVInt();\n        FST<Long> index = new FST<>(indexIn, PositiveIntOutputs.getSingleton());\n\n        TermsReader current = new TermsReader(fieldInfo, blockIn, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize, index);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, indexIn, blockIn, current, previous);\n      }\n      if (version >= FSTOrdTermsWriter.TERMS_VERSION_CHECKSUM) {\n        CodecUtil.checkFooter(indexIn);\n      } else {\n        CodecUtil.checkEOF(indexIn);\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(indexIn, blockIn);\n      } else {\n        IOUtils.closeWhileHandlingException(indexIn, blockIn);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"99eb4a732d1a908f4636ace52928876136bf1896","date":1413829552,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTOrdTermsReader#FSTOrdTermsReader(SegmentReadState,PostingsReaderBase).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTOrdTermsReader#FSTOrdTermsReader(SegmentReadState,PostingsReaderBase).mjava","sourceNew":"  public FSTOrdTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsIndexFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_INDEX_EXTENSION);\n    final String termsBlockFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_BLOCK_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    ChecksumIndexInput indexIn = null;\n    IndexInput blockIn = null;\n    boolean success = false;\n    try {\n      indexIn = state.directory.openChecksumInput(termsIndexFileName, state.context);\n      blockIn = state.directory.openInput(termsBlockFileName, state.context);\n      int version = CodecUtil.checkSegmentHeader(indexIn, FSTOrdTermsWriter.TERMS_INDEX_CODEC_NAME, \n                                                          FSTOrdTermsWriter.VERSION_START, \n                                                          FSTOrdTermsWriter.VERSION_CURRENT, \n                                                          state.segmentInfo.getId(), state.segmentSuffix);\n      int version2 = CodecUtil.checkSegmentHeader(blockIn, FSTOrdTermsWriter.TERMS_CODEC_NAME, \n                                                           FSTOrdTermsWriter.VERSION_START, \n                                                           FSTOrdTermsWriter.VERSION_CURRENT, \n                                                           state.segmentInfo.getId(), state.segmentSuffix);\n      \n      if (version != version2) {\n        throw new CorruptIndexException(\"Format versions mismatch: index=\" + version + \", terms=\" + version2, blockIn);\n      }\n\n      CodecUtil.checksumEntireFile(blockIn);\n      \n      this.postingsReader.init(blockIn, state);\n      seekDir(blockIn);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = blockIn.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(blockIn.readVInt());\n        boolean hasFreq = fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY;\n        long numTerms = blockIn.readVLong();\n        long sumTotalTermFreq = hasFreq ? blockIn.readVLong() : -1;\n        long sumDocFreq = blockIn.readVLong();\n        int docCount = blockIn.readVInt();\n        int longsSize = blockIn.readVInt();\n        FST<Long> index = new FST<>(indexIn, PositiveIntOutputs.getSingleton());\n\n        TermsReader current = new TermsReader(fieldInfo, blockIn, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize, index);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, indexIn, blockIn, current, previous);\n      }\n      CodecUtil.checkFooter(indexIn);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(indexIn, blockIn);\n      } else {\n        IOUtils.closeWhileHandlingException(indexIn, blockIn);\n      }\n    }\n  }\n\n","sourceOld":"  public FSTOrdTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsIndexFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_INDEX_EXTENSION);\n    final String termsBlockFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_BLOCK_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    ChecksumIndexInput indexIn = null;\n    IndexInput blockIn = null;\n    boolean success = false;\n    try {\n      indexIn = state.directory.openChecksumInput(termsIndexFileName, state.context);\n      blockIn = state.directory.openInput(termsBlockFileName, state.context);\n      int version = CodecUtil.checkSegmentHeader(indexIn, FSTOrdTermsWriter.TERMS_INDEX_CODEC_NAME, \n                                                          FSTOrdTermsWriter.VERSION_START, \n                                                          FSTOrdTermsWriter.VERSION_CURRENT, \n                                                          state.segmentInfo.getId(), state.segmentSuffix);\n      int version2 = CodecUtil.checkSegmentHeader(blockIn, FSTOrdTermsWriter.TERMS_CODEC_NAME, \n                                                           FSTOrdTermsWriter.VERSION_START, \n                                                           FSTOrdTermsWriter.VERSION_CURRENT, \n                                                           state.segmentInfo.getId(), state.segmentSuffix);\n      \n      if (version != version2) {\n        throw new CorruptIndexException(\"Format versions mismatch: index=\" + version + \", terms=\" + version2, blockIn);\n      }\n\n      CodecUtil.checksumEntireFile(blockIn);\n      \n      this.postingsReader.init(blockIn);\n      seekDir(blockIn);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = blockIn.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(blockIn.readVInt());\n        boolean hasFreq = fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY;\n        long numTerms = blockIn.readVLong();\n        long sumTotalTermFreq = hasFreq ? blockIn.readVLong() : -1;\n        long sumDocFreq = blockIn.readVLong();\n        int docCount = blockIn.readVInt();\n        int longsSize = blockIn.readVInt();\n        FST<Long> index = new FST<>(indexIn, PositiveIntOutputs.getSingleton());\n\n        TermsReader current = new TermsReader(fieldInfo, blockIn, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize, index);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, indexIn, blockIn, current, previous);\n      }\n      CodecUtil.checkFooter(indexIn);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(indexIn, blockIn);\n      } else {\n        IOUtils.closeWhileHandlingException(indexIn, blockIn);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3384e6013a93e4d11b7d75388693f8d0388602bf","date":1413951663,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTOrdTermsReader#FSTOrdTermsReader(SegmentReadState,PostingsReaderBase).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTOrdTermsReader#FSTOrdTermsReader(SegmentReadState,PostingsReaderBase).mjava","sourceNew":"  public FSTOrdTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsIndexFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_INDEX_EXTENSION);\n    final String termsBlockFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_BLOCK_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    ChecksumIndexInput indexIn = null;\n    IndexInput blockIn = null;\n    boolean success = false;\n    try {\n      indexIn = state.directory.openChecksumInput(termsIndexFileName, state.context);\n      blockIn = state.directory.openInput(termsBlockFileName, state.context);\n      int version = CodecUtil.checkIndexHeader(indexIn, FSTOrdTermsWriter.TERMS_INDEX_CODEC_NAME, \n                                                          FSTOrdTermsWriter.VERSION_START, \n                                                          FSTOrdTermsWriter.VERSION_CURRENT, \n                                                          state.segmentInfo.getId(), state.segmentSuffix);\n      int version2 = CodecUtil.checkIndexHeader(blockIn, FSTOrdTermsWriter.TERMS_CODEC_NAME, \n                                                           FSTOrdTermsWriter.VERSION_START, \n                                                           FSTOrdTermsWriter.VERSION_CURRENT, \n                                                           state.segmentInfo.getId(), state.segmentSuffix);\n      \n      if (version != version2) {\n        throw new CorruptIndexException(\"Format versions mismatch: index=\" + version + \", terms=\" + version2, blockIn);\n      }\n\n      CodecUtil.checksumEntireFile(blockIn);\n      \n      this.postingsReader.init(blockIn, state);\n      seekDir(blockIn);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = blockIn.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(blockIn.readVInt());\n        boolean hasFreq = fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY;\n        long numTerms = blockIn.readVLong();\n        long sumTotalTermFreq = hasFreq ? blockIn.readVLong() : -1;\n        long sumDocFreq = blockIn.readVLong();\n        int docCount = blockIn.readVInt();\n        int longsSize = blockIn.readVInt();\n        FST<Long> index = new FST<>(indexIn, PositiveIntOutputs.getSingleton());\n\n        TermsReader current = new TermsReader(fieldInfo, blockIn, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize, index);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, indexIn, blockIn, current, previous);\n      }\n      CodecUtil.checkFooter(indexIn);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(indexIn, blockIn);\n      } else {\n        IOUtils.closeWhileHandlingException(indexIn, blockIn);\n      }\n    }\n  }\n\n","sourceOld":"  public FSTOrdTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsIndexFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_INDEX_EXTENSION);\n    final String termsBlockFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_BLOCK_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    ChecksumIndexInput indexIn = null;\n    IndexInput blockIn = null;\n    boolean success = false;\n    try {\n      indexIn = state.directory.openChecksumInput(termsIndexFileName, state.context);\n      blockIn = state.directory.openInput(termsBlockFileName, state.context);\n      int version = CodecUtil.checkSegmentHeader(indexIn, FSTOrdTermsWriter.TERMS_INDEX_CODEC_NAME, \n                                                          FSTOrdTermsWriter.VERSION_START, \n                                                          FSTOrdTermsWriter.VERSION_CURRENT, \n                                                          state.segmentInfo.getId(), state.segmentSuffix);\n      int version2 = CodecUtil.checkSegmentHeader(blockIn, FSTOrdTermsWriter.TERMS_CODEC_NAME, \n                                                           FSTOrdTermsWriter.VERSION_START, \n                                                           FSTOrdTermsWriter.VERSION_CURRENT, \n                                                           state.segmentInfo.getId(), state.segmentSuffix);\n      \n      if (version != version2) {\n        throw new CorruptIndexException(\"Format versions mismatch: index=\" + version + \", terms=\" + version2, blockIn);\n      }\n\n      CodecUtil.checksumEntireFile(blockIn);\n      \n      this.postingsReader.init(blockIn, state);\n      seekDir(blockIn);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = blockIn.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(blockIn.readVInt());\n        boolean hasFreq = fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY;\n        long numTerms = blockIn.readVLong();\n        long sumTotalTermFreq = hasFreq ? blockIn.readVLong() : -1;\n        long sumDocFreq = blockIn.readVLong();\n        int docCount = blockIn.readVInt();\n        int longsSize = blockIn.readVInt();\n        FST<Long> index = new FST<>(indexIn, PositiveIntOutputs.getSingleton());\n\n        TermsReader current = new TermsReader(fieldInfo, blockIn, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize, index);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, indexIn, blockIn, current, previous);\n      }\n      CodecUtil.checkFooter(indexIn);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(indexIn, blockIn);\n      } else {\n        IOUtils.closeWhileHandlingException(indexIn, blockIn);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"db68c63cbfaa8698b9c4475f75ed2b9c9696d238","date":1414118621,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTOrdTermsReader#FSTOrdTermsReader(SegmentReadState,PostingsReaderBase).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTOrdTermsReader#FSTOrdTermsReader(SegmentReadState,PostingsReaderBase).mjava","sourceNew":"  public FSTOrdTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsIndexFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_INDEX_EXTENSION);\n    final String termsBlockFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_BLOCK_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    ChecksumIndexInput indexIn = null;\n    IndexInput blockIn = null;\n    boolean success = false;\n    try {\n      indexIn = state.directory.openChecksumInput(termsIndexFileName, state.context);\n      blockIn = state.directory.openInput(termsBlockFileName, state.context);\n      int version = CodecUtil.checkIndexHeader(indexIn, FSTOrdTermsWriter.TERMS_INDEX_CODEC_NAME, \n                                                          FSTOrdTermsWriter.VERSION_START, \n                                                          FSTOrdTermsWriter.VERSION_CURRENT, \n                                                          state.segmentInfo.getId(), state.segmentSuffix);\n      int version2 = CodecUtil.checkIndexHeader(blockIn, FSTOrdTermsWriter.TERMS_CODEC_NAME, \n                                                           FSTOrdTermsWriter.VERSION_START, \n                                                           FSTOrdTermsWriter.VERSION_CURRENT, \n                                                           state.segmentInfo.getId(), state.segmentSuffix);\n      \n      if (version != version2) {\n        throw new CorruptIndexException(\"Format versions mismatch: index=\" + version + \", terms=\" + version2, blockIn);\n      }\n\n      CodecUtil.checksumEntireFile(blockIn);\n      \n      this.postingsReader.init(blockIn, state);\n      seekDir(blockIn);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = blockIn.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(blockIn.readVInt());\n        boolean hasFreq = fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY;\n        long numTerms = blockIn.readVLong();\n        long sumTotalTermFreq = hasFreq ? blockIn.readVLong() : -1;\n        long sumDocFreq = blockIn.readVLong();\n        int docCount = blockIn.readVInt();\n        int longsSize = blockIn.readVInt();\n        FST<Long> index = new FST<>(indexIn, PositiveIntOutputs.getSingleton());\n\n        TermsReader current = new TermsReader(fieldInfo, blockIn, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize, index);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, indexIn, blockIn, current, previous);\n      }\n      CodecUtil.checkFooter(indexIn);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(indexIn, blockIn);\n      } else {\n        IOUtils.closeWhileHandlingException(indexIn, blockIn);\n      }\n    }\n  }\n\n","sourceOld":"  public FSTOrdTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsIndexFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_INDEX_EXTENSION);\n    final String termsBlockFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_BLOCK_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    ChecksumIndexInput indexIn = null;\n    IndexInput blockIn = null;\n    boolean success = false;\n    try {\n      indexIn = state.directory.openChecksumInput(termsIndexFileName, state.context);\n      blockIn = state.directory.openInput(termsBlockFileName, state.context);\n      int version = CodecUtil.checkSegmentHeader(indexIn, FSTOrdTermsWriter.TERMS_INDEX_CODEC_NAME, \n                                                          FSTOrdTermsWriter.VERSION_START, \n                                                          FSTOrdTermsWriter.VERSION_CURRENT, \n                                                          state.segmentInfo.getId(), state.segmentSuffix);\n      int version2 = CodecUtil.checkSegmentHeader(blockIn, FSTOrdTermsWriter.TERMS_CODEC_NAME, \n                                                           FSTOrdTermsWriter.VERSION_START, \n                                                           FSTOrdTermsWriter.VERSION_CURRENT, \n                                                           state.segmentInfo.getId(), state.segmentSuffix);\n      \n      if (version != version2) {\n        throw new CorruptIndexException(\"Format versions mismatch: index=\" + version + \", terms=\" + version2, blockIn);\n      }\n\n      CodecUtil.checksumEntireFile(blockIn);\n      \n      this.postingsReader.init(blockIn);\n      seekDir(blockIn);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = blockIn.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(blockIn.readVInt());\n        boolean hasFreq = fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY;\n        long numTerms = blockIn.readVLong();\n        long sumTotalTermFreq = hasFreq ? blockIn.readVLong() : -1;\n        long sumDocFreq = blockIn.readVLong();\n        int docCount = blockIn.readVInt();\n        int longsSize = blockIn.readVInt();\n        FST<Long> index = new FST<>(indexIn, PositiveIntOutputs.getSingleton());\n\n        TermsReader current = new TermsReader(fieldInfo, blockIn, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize, index);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, indexIn, blockIn, current, previous);\n      }\n      CodecUtil.checkFooter(indexIn);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(indexIn, blockIn);\n      } else {\n        IOUtils.closeWhileHandlingException(indexIn, blockIn);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2bb2842e561df4e8e9ad89010605fc86ac265465","date":1414768208,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTOrdTermsReader#FSTOrdTermsReader(SegmentReadState,PostingsReaderBase).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTOrdTermsReader#FSTOrdTermsReader(SegmentReadState,PostingsReaderBase).mjava","sourceNew":"  public FSTOrdTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsIndexFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_INDEX_EXTENSION);\n    final String termsBlockFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_BLOCK_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    ChecksumIndexInput indexIn = null;\n    IndexInput blockIn = null;\n    boolean success = false;\n    try {\n      indexIn = state.directory.openChecksumInput(termsIndexFileName, state.context);\n      blockIn = state.directory.openInput(termsBlockFileName, state.context);\n      int version = CodecUtil.checkIndexHeader(indexIn, FSTOrdTermsWriter.TERMS_INDEX_CODEC_NAME, \n                                                          FSTOrdTermsWriter.VERSION_START, \n                                                          FSTOrdTermsWriter.VERSION_CURRENT, \n                                                          state.segmentInfo.getId(), state.segmentSuffix);\n      int version2 = CodecUtil.checkIndexHeader(blockIn, FSTOrdTermsWriter.TERMS_CODEC_NAME, \n                                                           FSTOrdTermsWriter.VERSION_START, \n                                                           FSTOrdTermsWriter.VERSION_CURRENT, \n                                                           state.segmentInfo.getId(), state.segmentSuffix);\n      \n      if (version != version2) {\n        throw new CorruptIndexException(\"Format versions mismatch: index=\" + version + \", terms=\" + version2, blockIn);\n      }\n\n      CodecUtil.checksumEntireFile(blockIn);\n      \n      this.postingsReader.init(blockIn, state);\n      seekDir(blockIn);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = blockIn.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(blockIn.readVInt());\n        boolean hasFreq = fieldInfo.getIndexOptions() != IndexOptions.DOCS;\n        long numTerms = blockIn.readVLong();\n        long sumTotalTermFreq = hasFreq ? blockIn.readVLong() : -1;\n        long sumDocFreq = blockIn.readVLong();\n        int docCount = blockIn.readVInt();\n        int longsSize = blockIn.readVInt();\n        FST<Long> index = new FST<>(indexIn, PositiveIntOutputs.getSingleton());\n\n        TermsReader current = new TermsReader(fieldInfo, blockIn, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize, index);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, indexIn, blockIn, current, previous);\n      }\n      CodecUtil.checkFooter(indexIn);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(indexIn, blockIn);\n      } else {\n        IOUtils.closeWhileHandlingException(indexIn, blockIn);\n      }\n    }\n  }\n\n","sourceOld":"  public FSTOrdTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsIndexFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_INDEX_EXTENSION);\n    final String termsBlockFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_BLOCK_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    ChecksumIndexInput indexIn = null;\n    IndexInput blockIn = null;\n    boolean success = false;\n    try {\n      indexIn = state.directory.openChecksumInput(termsIndexFileName, state.context);\n      blockIn = state.directory.openInput(termsBlockFileName, state.context);\n      int version = CodecUtil.checkIndexHeader(indexIn, FSTOrdTermsWriter.TERMS_INDEX_CODEC_NAME, \n                                                          FSTOrdTermsWriter.VERSION_START, \n                                                          FSTOrdTermsWriter.VERSION_CURRENT, \n                                                          state.segmentInfo.getId(), state.segmentSuffix);\n      int version2 = CodecUtil.checkIndexHeader(blockIn, FSTOrdTermsWriter.TERMS_CODEC_NAME, \n                                                           FSTOrdTermsWriter.VERSION_START, \n                                                           FSTOrdTermsWriter.VERSION_CURRENT, \n                                                           state.segmentInfo.getId(), state.segmentSuffix);\n      \n      if (version != version2) {\n        throw new CorruptIndexException(\"Format versions mismatch: index=\" + version + \", terms=\" + version2, blockIn);\n      }\n\n      CodecUtil.checksumEntireFile(blockIn);\n      \n      this.postingsReader.init(blockIn, state);\n      seekDir(blockIn);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = blockIn.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(blockIn.readVInt());\n        boolean hasFreq = fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY;\n        long numTerms = blockIn.readVLong();\n        long sumTotalTermFreq = hasFreq ? blockIn.readVLong() : -1;\n        long sumDocFreq = blockIn.readVLong();\n        int docCount = blockIn.readVInt();\n        int longsSize = blockIn.readVInt();\n        FST<Long> index = new FST<>(indexIn, PositiveIntOutputs.getSingleton());\n\n        TermsReader current = new TermsReader(fieldInfo, blockIn, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize, index);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, indexIn, blockIn, current, previous);\n      }\n      CodecUtil.checkFooter(indexIn);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(indexIn, blockIn);\n      } else {\n        IOUtils.closeWhileHandlingException(indexIn, blockIn);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"086ffe31d8fba0110227db122974163709ecc1b4","date":1509678141,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTOrdTermsReader#FSTOrdTermsReader(SegmentReadState,PostingsReaderBase).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTOrdTermsReader#FSTOrdTermsReader(SegmentReadState,PostingsReaderBase).mjava","sourceNew":"  public FSTOrdTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsIndexFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_INDEX_EXTENSION);\n    final String termsBlockFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_BLOCK_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    ChecksumIndexInput indexIn = null;\n    IndexInput blockIn = null;\n    boolean success = false;\n    try {\n      indexIn = state.directory.openChecksumInput(termsIndexFileName, state.context);\n      blockIn = state.directory.openInput(termsBlockFileName, state.context);\n      int version = CodecUtil.checkIndexHeader(indexIn, FSTOrdTermsWriter.TERMS_INDEX_CODEC_NAME, \n                                                          FSTOrdTermsWriter.VERSION_START, \n                                                          FSTOrdTermsWriter.VERSION_CURRENT, \n                                                          state.segmentInfo.getId(), state.segmentSuffix);\n      int version2 = CodecUtil.checkIndexHeader(blockIn, FSTOrdTermsWriter.TERMS_CODEC_NAME, \n                                                           FSTOrdTermsWriter.VERSION_START, \n                                                           FSTOrdTermsWriter.VERSION_CURRENT, \n                                                           state.segmentInfo.getId(), state.segmentSuffix);\n      \n      if (version != version2) {\n        throw new CorruptIndexException(\"Format versions mismatch: index=\" + version + \", terms=\" + version2, blockIn);\n      }\n\n      CodecUtil.checksumEntireFile(blockIn);\n      \n      this.postingsReader.init(blockIn, state);\n      seekDir(blockIn);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = blockIn.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(blockIn.readVInt());\n        boolean hasFreq = fieldInfo.getIndexOptions() != IndexOptions.DOCS;\n        long numTerms = blockIn.readVLong();\n        long sumTotalTermFreq = blockIn.readVLong();\n        // if freqs are omitted, sumDocFreq=sumTotalTermFreq and we only write one value\n        long sumDocFreq = hasFreq ? blockIn.readVLong() : sumTotalTermFreq;\n        int docCount = blockIn.readVInt();\n        int longsSize = blockIn.readVInt();\n        FST<Long> index = new FST<>(indexIn, PositiveIntOutputs.getSingleton());\n\n        TermsReader current = new TermsReader(fieldInfo, blockIn, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize, index);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, indexIn, blockIn, current, previous);\n      }\n      CodecUtil.checkFooter(indexIn);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(indexIn, blockIn);\n      } else {\n        IOUtils.closeWhileHandlingException(indexIn, blockIn);\n      }\n    }\n  }\n\n","sourceOld":"  public FSTOrdTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsIndexFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_INDEX_EXTENSION);\n    final String termsBlockFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_BLOCK_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    ChecksumIndexInput indexIn = null;\n    IndexInput blockIn = null;\n    boolean success = false;\n    try {\n      indexIn = state.directory.openChecksumInput(termsIndexFileName, state.context);\n      blockIn = state.directory.openInput(termsBlockFileName, state.context);\n      int version = CodecUtil.checkIndexHeader(indexIn, FSTOrdTermsWriter.TERMS_INDEX_CODEC_NAME, \n                                                          FSTOrdTermsWriter.VERSION_START, \n                                                          FSTOrdTermsWriter.VERSION_CURRENT, \n                                                          state.segmentInfo.getId(), state.segmentSuffix);\n      int version2 = CodecUtil.checkIndexHeader(blockIn, FSTOrdTermsWriter.TERMS_CODEC_NAME, \n                                                           FSTOrdTermsWriter.VERSION_START, \n                                                           FSTOrdTermsWriter.VERSION_CURRENT, \n                                                           state.segmentInfo.getId(), state.segmentSuffix);\n      \n      if (version != version2) {\n        throw new CorruptIndexException(\"Format versions mismatch: index=\" + version + \", terms=\" + version2, blockIn);\n      }\n\n      CodecUtil.checksumEntireFile(blockIn);\n      \n      this.postingsReader.init(blockIn, state);\n      seekDir(blockIn);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = blockIn.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(blockIn.readVInt());\n        boolean hasFreq = fieldInfo.getIndexOptions() != IndexOptions.DOCS;\n        long numTerms = blockIn.readVLong();\n        long sumTotalTermFreq = hasFreq ? blockIn.readVLong() : -1;\n        long sumDocFreq = blockIn.readVLong();\n        int docCount = blockIn.readVInt();\n        int longsSize = blockIn.readVInt();\n        FST<Long> index = new FST<>(indexIn, PositiveIntOutputs.getSingleton());\n\n        TermsReader current = new TermsReader(fieldInfo, blockIn, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize, index);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, indexIn, blockIn, current, previous);\n      }\n      CodecUtil.checkFooter(indexIn);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(indexIn, blockIn);\n      } else {\n        IOUtils.closeWhileHandlingException(indexIn, blockIn);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d523b8189b211dd1630166aa77b8c88bb48b3fcc","date":1510144168,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTOrdTermsReader#FSTOrdTermsReader(SegmentReadState,PostingsReaderBase).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTOrdTermsReader#FSTOrdTermsReader(SegmentReadState,PostingsReaderBase).mjava","sourceNew":"  public FSTOrdTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsIndexFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_INDEX_EXTENSION);\n    final String termsBlockFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_BLOCK_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    ChecksumIndexInput indexIn = null;\n    IndexInput blockIn = null;\n    boolean success = false;\n    try {\n      indexIn = state.directory.openChecksumInput(termsIndexFileName, state.context);\n      blockIn = state.directory.openInput(termsBlockFileName, state.context);\n      int version = CodecUtil.checkIndexHeader(indexIn, FSTOrdTermsWriter.TERMS_INDEX_CODEC_NAME, \n                                                          FSTOrdTermsWriter.VERSION_START, \n                                                          FSTOrdTermsWriter.VERSION_CURRENT, \n                                                          state.segmentInfo.getId(), state.segmentSuffix);\n      int version2 = CodecUtil.checkIndexHeader(blockIn, FSTOrdTermsWriter.TERMS_CODEC_NAME, \n                                                           FSTOrdTermsWriter.VERSION_START, \n                                                           FSTOrdTermsWriter.VERSION_CURRENT, \n                                                           state.segmentInfo.getId(), state.segmentSuffix);\n      \n      if (version != version2) {\n        throw new CorruptIndexException(\"Format versions mismatch: index=\" + version + \", terms=\" + version2, blockIn);\n      }\n\n      CodecUtil.checksumEntireFile(blockIn);\n      \n      this.postingsReader.init(blockIn, state);\n      seekDir(blockIn);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = blockIn.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(blockIn.readVInt());\n        boolean hasFreq = fieldInfo.getIndexOptions() != IndexOptions.DOCS;\n        long numTerms = blockIn.readVLong();\n        long sumTotalTermFreq = blockIn.readVLong();\n        // if freqs are omitted, sumDocFreq=sumTotalTermFreq and we only write one value\n        long sumDocFreq = hasFreq ? blockIn.readVLong() : sumTotalTermFreq;\n        int docCount = blockIn.readVInt();\n        int longsSize = blockIn.readVInt();\n        FST<Long> index = new FST<>(indexIn, PositiveIntOutputs.getSingleton());\n\n        TermsReader current = new TermsReader(fieldInfo, blockIn, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize, index);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, indexIn, blockIn, current, previous);\n      }\n      CodecUtil.checkFooter(indexIn);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(indexIn, blockIn);\n      } else {\n        IOUtils.closeWhileHandlingException(indexIn, blockIn);\n      }\n    }\n  }\n\n","sourceOld":"  public FSTOrdTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsIndexFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_INDEX_EXTENSION);\n    final String termsBlockFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_BLOCK_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    ChecksumIndexInput indexIn = null;\n    IndexInput blockIn = null;\n    boolean success = false;\n    try {\n      indexIn = state.directory.openChecksumInput(termsIndexFileName, state.context);\n      blockIn = state.directory.openInput(termsBlockFileName, state.context);\n      int version = CodecUtil.checkIndexHeader(indexIn, FSTOrdTermsWriter.TERMS_INDEX_CODEC_NAME, \n                                                          FSTOrdTermsWriter.VERSION_START, \n                                                          FSTOrdTermsWriter.VERSION_CURRENT, \n                                                          state.segmentInfo.getId(), state.segmentSuffix);\n      int version2 = CodecUtil.checkIndexHeader(blockIn, FSTOrdTermsWriter.TERMS_CODEC_NAME, \n                                                           FSTOrdTermsWriter.VERSION_START, \n                                                           FSTOrdTermsWriter.VERSION_CURRENT, \n                                                           state.segmentInfo.getId(), state.segmentSuffix);\n      \n      if (version != version2) {\n        throw new CorruptIndexException(\"Format versions mismatch: index=\" + version + \", terms=\" + version2, blockIn);\n      }\n\n      CodecUtil.checksumEntireFile(blockIn);\n      \n      this.postingsReader.init(blockIn, state);\n      seekDir(blockIn);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = blockIn.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(blockIn.readVInt());\n        boolean hasFreq = fieldInfo.getIndexOptions() != IndexOptions.DOCS;\n        long numTerms = blockIn.readVLong();\n        long sumTotalTermFreq = hasFreq ? blockIn.readVLong() : -1;\n        long sumDocFreq = blockIn.readVLong();\n        int docCount = blockIn.readVInt();\n        int longsSize = blockIn.readVInt();\n        FST<Long> index = new FST<>(indexIn, PositiveIntOutputs.getSingleton());\n\n        TermsReader current = new TermsReader(fieldInfo, blockIn, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize, index);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, indexIn, blockIn, current, previous);\n      }\n      CodecUtil.checkFooter(indexIn);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(indexIn, blockIn);\n      } else {\n        IOUtils.closeWhileHandlingException(indexIn, blockIn);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cb77022ef17ff655c519a3f6ecd393747ac88bcf","date":1578579386,"type":4,"author":"Adrien Grand","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTOrdTermsReader#FSTOrdTermsReader(SegmentReadState,PostingsReaderBase).mjava","sourceNew":null,"sourceOld":"  public FSTOrdTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsIndexFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_INDEX_EXTENSION);\n    final String termsBlockFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_BLOCK_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    ChecksumIndexInput indexIn = null;\n    IndexInput blockIn = null;\n    boolean success = false;\n    try {\n      indexIn = state.directory.openChecksumInput(termsIndexFileName, state.context);\n      blockIn = state.directory.openInput(termsBlockFileName, state.context);\n      int version = CodecUtil.checkIndexHeader(indexIn, FSTOrdTermsWriter.TERMS_INDEX_CODEC_NAME, \n                                                          FSTOrdTermsWriter.VERSION_START, \n                                                          FSTOrdTermsWriter.VERSION_CURRENT, \n                                                          state.segmentInfo.getId(), state.segmentSuffix);\n      int version2 = CodecUtil.checkIndexHeader(blockIn, FSTOrdTermsWriter.TERMS_CODEC_NAME, \n                                                           FSTOrdTermsWriter.VERSION_START, \n                                                           FSTOrdTermsWriter.VERSION_CURRENT, \n                                                           state.segmentInfo.getId(), state.segmentSuffix);\n      \n      if (version != version2) {\n        throw new CorruptIndexException(\"Format versions mismatch: index=\" + version + \", terms=\" + version2, blockIn);\n      }\n\n      CodecUtil.checksumEntireFile(blockIn);\n      \n      this.postingsReader.init(blockIn, state);\n      seekDir(blockIn);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = blockIn.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(blockIn.readVInt());\n        boolean hasFreq = fieldInfo.getIndexOptions() != IndexOptions.DOCS;\n        long numTerms = blockIn.readVLong();\n        long sumTotalTermFreq = blockIn.readVLong();\n        // if freqs are omitted, sumDocFreq=sumTotalTermFreq and we only write one value\n        long sumDocFreq = hasFreq ? blockIn.readVLong() : sumTotalTermFreq;\n        int docCount = blockIn.readVInt();\n        int longsSize = blockIn.readVInt();\n        FST<Long> index = new FST<>(indexIn, PositiveIntOutputs.getSingleton());\n\n        TermsReader current = new TermsReader(fieldInfo, blockIn, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize, index);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, indexIn, blockIn, current, previous);\n      }\n      CodecUtil.checkFooter(indexIn);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(indexIn, blockIn);\n      } else {\n        IOUtils.closeWhileHandlingException(indexIn, blockIn);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"06ab276a5660cb79daae8c5ede063531c700a03a","date":1578587874,"type":0,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTOrdTermsReader#FSTOrdTermsReader(SegmentReadState,PostingsReaderBase).mjava","pathOld":"/dev/null","sourceNew":"  public FSTOrdTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsIndexFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_INDEX_EXTENSION);\n    final String termsBlockFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_BLOCK_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    ChecksumIndexInput indexIn = null;\n    IndexInput blockIn = null;\n    boolean success = false;\n    try {\n      indexIn = state.directory.openChecksumInput(termsIndexFileName, state.context);\n      blockIn = state.directory.openInput(termsBlockFileName, state.context);\n      int version = CodecUtil.checkIndexHeader(indexIn, FSTOrdTermsWriter.TERMS_INDEX_CODEC_NAME, \n                                                          FSTOrdTermsWriter.VERSION_START, \n                                                          FSTOrdTermsWriter.VERSION_CURRENT, \n                                                          state.segmentInfo.getId(), state.segmentSuffix);\n      int version2 = CodecUtil.checkIndexHeader(blockIn, FSTOrdTermsWriter.TERMS_CODEC_NAME, \n                                                           FSTOrdTermsWriter.VERSION_START, \n                                                           FSTOrdTermsWriter.VERSION_CURRENT, \n                                                           state.segmentInfo.getId(), state.segmentSuffix);\n      \n      if (version != version2) {\n        throw new CorruptIndexException(\"Format versions mismatch: index=\" + version + \", terms=\" + version2, blockIn);\n      }\n\n      CodecUtil.checksumEntireFile(blockIn);\n      \n      this.postingsReader.init(blockIn, state);\n      seekDir(blockIn);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = blockIn.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(blockIn.readVInt());\n        boolean hasFreq = fieldInfo.getIndexOptions() != IndexOptions.DOCS;\n        long numTerms = blockIn.readVLong();\n        long sumTotalTermFreq = blockIn.readVLong();\n        // if freqs are omitted, sumDocFreq=sumTotalTermFreq and we only write one value\n        long sumDocFreq = hasFreq ? blockIn.readVLong() : sumTotalTermFreq;\n        int docCount = blockIn.readVInt();\n        int longsSize = blockIn.readVInt();\n        FST<Long> index = new FST<>(indexIn, PositiveIntOutputs.getSingleton());\n\n        TermsReader current = new TermsReader(fieldInfo, blockIn, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize, index);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, indexIn, blockIn, current, previous);\n      }\n      CodecUtil.checkFooter(indexIn);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(indexIn, blockIn);\n      } else {\n        IOUtils.closeWhileHandlingException(indexIn, blockIn);\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"08a5168e06e037794c0aba7f94f76ff3c09704d2","date":1579264785,"type":4,"author":"Adrien Grand","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTOrdTermsReader#FSTOrdTermsReader(SegmentReadState,PostingsReaderBase).mjava","sourceNew":null,"sourceOld":"  public FSTOrdTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsIndexFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_INDEX_EXTENSION);\n    final String termsBlockFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTOrdTermsWriter.TERMS_BLOCK_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    ChecksumIndexInput indexIn = null;\n    IndexInput blockIn = null;\n    boolean success = false;\n    try {\n      indexIn = state.directory.openChecksumInput(termsIndexFileName, state.context);\n      blockIn = state.directory.openInput(termsBlockFileName, state.context);\n      int version = CodecUtil.checkIndexHeader(indexIn, FSTOrdTermsWriter.TERMS_INDEX_CODEC_NAME, \n                                                          FSTOrdTermsWriter.VERSION_START, \n                                                          FSTOrdTermsWriter.VERSION_CURRENT, \n                                                          state.segmentInfo.getId(), state.segmentSuffix);\n      int version2 = CodecUtil.checkIndexHeader(blockIn, FSTOrdTermsWriter.TERMS_CODEC_NAME, \n                                                           FSTOrdTermsWriter.VERSION_START, \n                                                           FSTOrdTermsWriter.VERSION_CURRENT, \n                                                           state.segmentInfo.getId(), state.segmentSuffix);\n      \n      if (version != version2) {\n        throw new CorruptIndexException(\"Format versions mismatch: index=\" + version + \", terms=\" + version2, blockIn);\n      }\n\n      CodecUtil.checksumEntireFile(blockIn);\n      \n      this.postingsReader.init(blockIn, state);\n      seekDir(blockIn);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = blockIn.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(blockIn.readVInt());\n        boolean hasFreq = fieldInfo.getIndexOptions() != IndexOptions.DOCS;\n        long numTerms = blockIn.readVLong();\n        long sumTotalTermFreq = blockIn.readVLong();\n        // if freqs are omitted, sumDocFreq=sumTotalTermFreq and we only write one value\n        long sumDocFreq = hasFreq ? blockIn.readVLong() : sumTotalTermFreq;\n        int docCount = blockIn.readVInt();\n        int longsSize = blockIn.readVInt();\n        FST<Long> index = new FST<>(indexIn, PositiveIntOutputs.getSingleton());\n\n        TermsReader current = new TermsReader(fieldInfo, blockIn, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize, index);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, indexIn, blockIn, current, previous);\n      }\n      CodecUtil.checkFooter(indexIn);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(indexIn, blockIn);\n      } else {\n        IOUtils.closeWhileHandlingException(indexIn, blockIn);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"5eb2511ababf862ea11e10761c70ee560cd84510":["634f330c54fd3f9f491d52036dc3f40b4f4d8934","1f3b037cd083286b2af89f96e768f85dcd8072d6"],"1f3b037cd083286b2af89f96e768f85dcd8072d6":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["2f948dd442d23baa6cbb28daf77c8db78b351329"],"56df73d43b6fc340f5332322862382c7e30f4368":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"99eb4a732d1a908f4636ace52928876136bf1896":["d640273789c74bf4f1412b99c67294c14293d154"],"d523b8189b211dd1630166aa77b8c88bb48b3fcc":["2bb2842e561df4e8e9ad89010605fc86ac265465","086ffe31d8fba0110227db122974163709ecc1b4"],"cb77022ef17ff655c519a3f6ecd393747ac88bcf":["d523b8189b211dd1630166aa77b8c88bb48b3fcc"],"3384e6013a93e4d11b7d75388693f8d0388602bf":["99eb4a732d1a908f4636ace52928876136bf1896"],"2bb2842e561df4e8e9ad89010605fc86ac265465":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"086ffe31d8fba0110227db122974163709ecc1b4":["2bb2842e561df4e8e9ad89010605fc86ac265465"],"9bb9a29a5e71a90295f175df8919802993142c9a":["1f3b037cd083286b2af89f96e768f85dcd8072d6","d640273789c74bf4f1412b99c67294c14293d154"],"d640273789c74bf4f1412b99c67294c14293d154":["1f3b037cd083286b2af89f96e768f85dcd8072d6"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"08a5168e06e037794c0aba7f94f76ff3c09704d2":["06ab276a5660cb79daae8c5ede063531c700a03a"],"db68c63cbfaa8698b9c4475f75ed2b9c9696d238":["9bb9a29a5e71a90295f175df8919802993142c9a","3384e6013a93e4d11b7d75388693f8d0388602bf"],"2f948dd442d23baa6cbb28daf77c8db78b351329":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","56df73d43b6fc340f5332322862382c7e30f4368"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["08a5168e06e037794c0aba7f94f76ff3c09704d2"],"06ab276a5660cb79daae8c5ede063531c700a03a":["cb77022ef17ff655c519a3f6ecd393747ac88bcf"]},"commit2Childs":{"5eb2511ababf862ea11e10761c70ee560cd84510":[],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["5eb2511ababf862ea11e10761c70ee560cd84510","1f3b037cd083286b2af89f96e768f85dcd8072d6"],"1f3b037cd083286b2af89f96e768f85dcd8072d6":["5eb2511ababf862ea11e10761c70ee560cd84510","9bb9a29a5e71a90295f175df8919802993142c9a","d640273789c74bf4f1412b99c67294c14293d154"],"56df73d43b6fc340f5332322862382c7e30f4368":["2f948dd442d23baa6cbb28daf77c8db78b351329"],"99eb4a732d1a908f4636ace52928876136bf1896":["3384e6013a93e4d11b7d75388693f8d0388602bf"],"d523b8189b211dd1630166aa77b8c88bb48b3fcc":["cb77022ef17ff655c519a3f6ecd393747ac88bcf"],"cb77022ef17ff655c519a3f6ecd393747ac88bcf":["06ab276a5660cb79daae8c5ede063531c700a03a"],"3384e6013a93e4d11b7d75388693f8d0388602bf":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"2bb2842e561df4e8e9ad89010605fc86ac265465":["d523b8189b211dd1630166aa77b8c88bb48b3fcc","086ffe31d8fba0110227db122974163709ecc1b4"],"086ffe31d8fba0110227db122974163709ecc1b4":["d523b8189b211dd1630166aa77b8c88bb48b3fcc"],"d640273789c74bf4f1412b99c67294c14293d154":["99eb4a732d1a908f4636ace52928876136bf1896","9bb9a29a5e71a90295f175df8919802993142c9a"],"9bb9a29a5e71a90295f175df8919802993142c9a":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["56df73d43b6fc340f5332322862382c7e30f4368","2f948dd442d23baa6cbb28daf77c8db78b351329"],"db68c63cbfaa8698b9c4475f75ed2b9c9696d238":["2bb2842e561df4e8e9ad89010605fc86ac265465"],"08a5168e06e037794c0aba7f94f76ff3c09704d2":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"2f948dd442d23baa6cbb28daf77c8db78b351329":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"06ab276a5660cb79daae8c5ede063531c700a03a":["08a5168e06e037794c0aba7f94f76ff3c09704d2"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["5eb2511ababf862ea11e10761c70ee560cd84510","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}