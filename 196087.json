{"path":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,int,int).mjava","commits":[{"id":"fe19cbe25754c715a0232f453039383119fc122c","date":1306110991,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,int,int).mjava","pathOld":"/dev/null","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, int readBufferSize, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final SegmentCodecs segmentCodecs = si.getSegmentCodecs();\n    this.readBufferSize = readBufferSize;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = new CompoundFileReader(dir, IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), readBufferSize);\n        dir0 = cfsReader;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      \n      // Ask codec for its Fields\n      fields = segmentCodecs.codec().fieldsProducer(new SegmentReadState(cfsDir, si, fieldInfos, readBufferSize, termsIndexDivisor));\n      assert fields != null;\n      \n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae132b768aece5bf21cda14e2f17fba66eb6f7d6","date":1306128032,"type":0,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,int,int).mjava","pathOld":"/dev/null","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, int readBufferSize, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final SegmentCodecs segmentCodecs = si.getSegmentCodecs();\n    this.readBufferSize = readBufferSize;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = new CompoundFileReader(dir, IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), readBufferSize);\n        dir0 = cfsReader;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      \n      // Ask codec for its Fields\n      fields = segmentCodecs.codec().fieldsProducer(new SegmentReadState(cfsDir, si, fieldInfos, readBufferSize, termsIndexDivisor));\n      assert fields != null;\n      \n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5c698c0cb88bac4bcd36a1b1001a0c6a2163ea2a","date":1306150983,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,int,int).mjava","pathOld":"/dev/null","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, int readBufferSize, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final SegmentCodecs segmentCodecs = si.getSegmentCodecs();\n    this.readBufferSize = readBufferSize;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = new CompoundFileReader(dir, IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), readBufferSize);\n        dir0 = cfsReader;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final Codec codec = segmentCodecs.codec();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, readBufferSize, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = codec.fieldsProducer(segmentReadState);\n      assert fields != null;\n      perDocProducer = codec.docsProducer(segmentReadState);\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2e8d7ba2175f47e280231533f7d3016249cea88b","date":1307711934,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,int,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,int,int).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, int readBufferSize, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final SegmentCodecs segmentCodecs = si.getSegmentCodecs();\n    this.readBufferSize = readBufferSize;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = new CompoundFileReader(dir, IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), readBufferSize);\n        dir0 = cfsReader;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final Codec codec = segmentCodecs.codec();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, readBufferSize, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = codec.fieldsProducer(segmentReadState);\n      assert fields != null;\n      perDocProducer = codec.docsProducer(segmentReadState);\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, int readBufferSize, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final SegmentCodecs segmentCodecs = si.getSegmentCodecs();\n    this.readBufferSize = readBufferSize;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = new CompoundFileReader(dir, IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), readBufferSize);\n        dir0 = cfsReader;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      \n      // Ask codec for its Fields\n      fields = segmentCodecs.codec().fieldsProducer(new SegmentReadState(cfsDir, si, fieldInfos, readBufferSize, termsIndexDivisor));\n      assert fields != null;\n      \n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","date":1307729864,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,int,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,int,int).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, int readBufferSize, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final SegmentCodecs segmentCodecs = si.getSegmentCodecs();\n    this.readBufferSize = readBufferSize;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = new CompoundFileReader(dir, IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), readBufferSize);\n        dir0 = cfsReader;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final Codec codec = segmentCodecs.codec();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, readBufferSize, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = codec.fieldsProducer(segmentReadState);\n      assert fields != null;\n      perDocProducer = codec.docsProducer(segmentReadState);\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, int readBufferSize, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final SegmentCodecs segmentCodecs = si.getSegmentCodecs();\n    this.readBufferSize = readBufferSize;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = new CompoundFileReader(dir, IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), readBufferSize);\n        dir0 = cfsReader;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      \n      // Ask codec for its Fields\n      fields = segmentCodecs.codec().fieldsProducer(new SegmentReadState(cfsDir, si, fieldInfos, readBufferSize, termsIndexDivisor));\n      assert fields != null;\n      \n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"639c36565ce03aed5b0fce7c9e4448e53a1f7efd","date":1308580104,"type":5,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,int,int).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final SegmentCodecs segmentCodecs = si.getSegmentCodecs();\n    this.context = context;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = new CompoundFileReader(dir, IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context);\n        dir0 = cfsReader;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final Codec codec = segmentCodecs.codec();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = codec.fieldsProducer(segmentReadState);\n      assert fields != null;\n      perDocProducer = codec.docsProducer(segmentReadState);\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, int readBufferSize, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final SegmentCodecs segmentCodecs = si.getSegmentCodecs();\n    this.readBufferSize = readBufferSize;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = new CompoundFileReader(dir, IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), readBufferSize);\n        dir0 = cfsReader;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final Codec codec = segmentCodecs.codec();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, readBufferSize, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = codec.fieldsProducer(segmentReadState);\n      assert fields != null;\n      perDocProducer = codec.docsProducer(segmentReadState);\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0aab6e810b4b0d3743d6a048be0602801f4b3920","date":1308671625,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,int,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,int,int).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, int readBufferSize, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final SegmentCodecs segmentCodecs = si.getSegmentCodecs();\n    this.readBufferSize = readBufferSize;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = dir.openCompoundInput(IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), readBufferSize);\n        dir0 = cfsReader;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final Codec codec = segmentCodecs.codec();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, readBufferSize, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = codec.fieldsProducer(segmentReadState);\n      assert fields != null;\n      perDocProducer = codec.docsProducer(segmentReadState);\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, int readBufferSize, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final SegmentCodecs segmentCodecs = si.getSegmentCodecs();\n    this.readBufferSize = readBufferSize;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = new CompoundFileReader(dir, IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), readBufferSize);\n        dir0 = cfsReader;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final Codec codec = segmentCodecs.codec();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, readBufferSize, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = codec.fieldsProducer(segmentReadState);\n      assert fields != null;\n      perDocProducer = codec.docsProducer(segmentReadState);\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2553b00f699380c64959ccb27991289aae87be2e","date":1309290151,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,int,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,int,int).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, int readBufferSize, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final SegmentCodecs segmentCodecs = si.getSegmentCodecs();\n    this.readBufferSize = readBufferSize;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = dir.openCompoundInput(IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), readBufferSize);\n        dir0 = cfsReader;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final Codec codec = segmentCodecs.codec();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, readBufferSize, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = codec.fieldsProducer(segmentReadState);\n      assert fields != null;\n      perDocProducer = codec.docsProducer(segmentReadState);\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, int readBufferSize, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final SegmentCodecs segmentCodecs = si.getSegmentCodecs();\n    this.readBufferSize = readBufferSize;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = new CompoundFileReader(dir, IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), readBufferSize);\n        dir0 = cfsReader;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final Codec codec = segmentCodecs.codec();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, readBufferSize, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = codec.fieldsProducer(segmentReadState);\n      assert fields != null;\n      perDocProducer = codec.docsProducer(segmentReadState);\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ddc4c914be86e34b54f70023f45a60fa7f04e929","date":1310115160,"type":5,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,int,int).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final SegmentCodecs segmentCodecs = si.getSegmentCodecs();\n    this.context = context;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = dir.openCompoundInput(IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context);\n        dir0 = cfsReader;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final Codec codec = segmentCodecs.codec();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = codec.fieldsProducer(segmentReadState);\n      assert fields != null;\n      perDocProducer = codec.docsProducer(segmentReadState);\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, int readBufferSize, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final SegmentCodecs segmentCodecs = si.getSegmentCodecs();\n    this.readBufferSize = readBufferSize;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = dir.openCompoundInput(IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), readBufferSize);\n        dir0 = cfsReader;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final Codec codec = segmentCodecs.codec();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, readBufferSize, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = codec.fieldsProducer(segmentReadState);\n      assert fields != null;\n      perDocProducer = codec.docsProducer(segmentReadState);\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5d004d0e0b3f65bb40da76d476d659d7888270e8","date":1310158940,"type":5,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,int,int).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final SegmentCodecs segmentCodecs = si.getSegmentCodecs();\n    this.context = context;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = dir.openCompoundInput(IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context);\n        dir0 = cfsReader;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final Codec codec = segmentCodecs.codec();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = codec.fieldsProducer(segmentReadState);\n      assert fields != null;\n      perDocProducer = codec.docsProducer(segmentReadState);\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, int readBufferSize, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final SegmentCodecs segmentCodecs = si.getSegmentCodecs();\n    this.readBufferSize = readBufferSize;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = dir.openCompoundInput(IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), readBufferSize);\n        dir0 = cfsReader;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final Codec codec = segmentCodecs.codec();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, readBufferSize, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = codec.fieldsProducer(segmentReadState);\n      assert fields != null;\n      perDocProducer = codec.docsProducer(segmentReadState);\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655":["ae132b768aece5bf21cda14e2f17fba66eb6f7d6","2e8d7ba2175f47e280231533f7d3016249cea88b"],"ae132b768aece5bf21cda14e2f17fba66eb6f7d6":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","fe19cbe25754c715a0232f453039383119fc122c"],"2e8d7ba2175f47e280231533f7d3016249cea88b":["fe19cbe25754c715a0232f453039383119fc122c","5c698c0cb88bac4bcd36a1b1001a0c6a2163ea2a"],"5c698c0cb88bac4bcd36a1b1001a0c6a2163ea2a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","fe19cbe25754c715a0232f453039383119fc122c"],"fe19cbe25754c715a0232f453039383119fc122c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"0aab6e810b4b0d3743d6a048be0602801f4b3920":["2e8d7ba2175f47e280231533f7d3016249cea88b"],"639c36565ce03aed5b0fce7c9e4448e53a1f7efd":["2e8d7ba2175f47e280231533f7d3016249cea88b"],"5d004d0e0b3f65bb40da76d476d659d7888270e8":["2553b00f699380c64959ccb27991289aae87be2e","ddc4c914be86e34b54f70023f45a60fa7f04e929"],"ddc4c914be86e34b54f70023f45a60fa7f04e929":["0aab6e810b4b0d3743d6a048be0602801f4b3920","639c36565ce03aed5b0fce7c9e4448e53a1f7efd"],"2553b00f699380c64959ccb27991289aae87be2e":["a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","0aab6e810b4b0d3743d6a048be0602801f4b3920"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["ddc4c914be86e34b54f70023f45a60fa7f04e929"]},"commit2Childs":{"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655":["2553b00f699380c64959ccb27991289aae87be2e"],"ae132b768aece5bf21cda14e2f17fba66eb6f7d6":["a02058e0eaba4bbd5d05e6b06b9522c0acfd1655"],"2e8d7ba2175f47e280231533f7d3016249cea88b":["a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","0aab6e810b4b0d3743d6a048be0602801f4b3920","639c36565ce03aed5b0fce7c9e4448e53a1f7efd"],"5c698c0cb88bac4bcd36a1b1001a0c6a2163ea2a":["2e8d7ba2175f47e280231533f7d3016249cea88b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["ae132b768aece5bf21cda14e2f17fba66eb6f7d6","5c698c0cb88bac4bcd36a1b1001a0c6a2163ea2a","fe19cbe25754c715a0232f453039383119fc122c"],"fe19cbe25754c715a0232f453039383119fc122c":["ae132b768aece5bf21cda14e2f17fba66eb6f7d6","2e8d7ba2175f47e280231533f7d3016249cea88b","5c698c0cb88bac4bcd36a1b1001a0c6a2163ea2a"],"0aab6e810b4b0d3743d6a048be0602801f4b3920":["ddc4c914be86e34b54f70023f45a60fa7f04e929","2553b00f699380c64959ccb27991289aae87be2e"],"639c36565ce03aed5b0fce7c9e4448e53a1f7efd":["ddc4c914be86e34b54f70023f45a60fa7f04e929"],"5d004d0e0b3f65bb40da76d476d659d7888270e8":[],"ddc4c914be86e34b54f70023f45a60fa7f04e929":["5d004d0e0b3f65bb40da76d476d659d7888270e8","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"2553b00f699380c64959ccb27991289aae87be2e":["5d004d0e0b3f65bb40da76d476d659d7888270e8"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["5d004d0e0b3f65bb40da76d476d659d7888270e8","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}