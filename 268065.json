{"path":"contrib/analyzers/src/java/org/apache/lucene/analysis/shingle/ShingleFilter#fillOutputBuf().mjava","commits":[{"id":"c3e328a6f2b163170d23e06008798fb82c27af8b","date":1206825093,"type":0,"author":"Grant Ingersoll","isMerge":false,"pathNew":"contrib/analyzers/src/java/org/apache/lucene/analysis/shingle/ShingleFilter#fillOutputBuf().mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Fill the output buffer with new shingles.\n   *\n   * @throws IOException if there's a problem getting the next token\n   */\n  private void fillOutputBuf() throws IOException {\n    boolean addedToken = false;\n    /*\n     * Try to fill the shingle buffer.\n     */\n    do {\n      Token token = getNextToken();\n      if (token != null) {\n        shingleBuf.add(token);\n        if (shingleBuf.size() > maxShingleSize)\n        {\n          shingleBuf.remove(0);\n        }\n        addedToken = true;\n      } else {\n        break;\n      }\n    } while (shingleBuf.size() < maxShingleSize);\n\n    /*\n     * If no new token could be added to the shingle buffer, we have reached\n     * the end of the input stream and have to discard the least recent token.\n     */\n    if (! addedToken) {\n      if (shingleBuf.isEmpty()) {\n        return;\n      } else {\n        shingleBuf.remove(0);\n      }\n    }\n\n    clearShingles();\n\n    int[] endOffsets = new int[shingleBuf.size()];\n    for (int i = 0; i < endOffsets.length; i++) {\n      endOffsets[i] = 0;\n    }\n\n    int i = 0;\n    Token token = null;\n    for (Iterator it = shingleBuf.iterator(); it.hasNext(); ) {\n      token = (Token) it.next();\n      for (int j = i; j < shingles.length; j++) {\n        if (shingles[j].length() != 0) {\n          shingles[j].append(TOKEN_SEPARATOR);\n        }\n        shingles[j].append(token.termBuffer(), 0, token.termLength());\n      }\n\n      endOffsets[i] = token.endOffset();\n      i++;\n    }\n\n    if ((! shingleBuf.isEmpty()) && outputUnigrams) {\n      Token unigram = (Token) shingleBuf.getFirst();\n      unigram.setPositionIncrement(1);\n      outputBuf.add(unigram);\n    }\n\n    /*\n     * Push new tokens to the output buffer.\n     */\n    for (int j = 1; j < shingleBuf.size(); j++) {\n      Token shingle = new Token(shingles[j].toString(),\n                                ((Token) shingleBuf.get(0)).startOffset(),\n                                endOffsets[j],\n                                tokenType);\n      if ((! outputUnigrams) && j == 1) {\n        shingle.setPositionIncrement(1);\n      } else {\n        shingle.setPositionIncrement(0);\n      }\n      outputBuf.add(shingle);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7e2cb543b41c145f33390f460ee743d6693c9c6c","date":1219243087,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"contrib/analyzers/src/java/org/apache/lucene/analysis/shingle/ShingleFilter#fillOutputBuf(Token).mjava","pathOld":"contrib/analyzers/src/java/org/apache/lucene/analysis/shingle/ShingleFilter#fillOutputBuf().mjava","sourceNew":"  /**\n   * Fill the output buffer with new shingles.\n   *\n   * @throws IOException if there's a problem getting the next token\n   */\n  private void fillOutputBuf(Token token) throws IOException {\n    boolean addedToken = false;\n    /*\n     * Try to fill the shingle buffer.\n     */\n    do {\n      token = getNextToken(token);\n      if (token != null) {\n        shingleBuf.add(token.clone());\n        if (shingleBuf.size() > maxShingleSize)\n        {\n          shingleBuf.remove(0);\n        }\n        addedToken = true;\n      } else {\n        break;\n      }\n    } while (shingleBuf.size() < maxShingleSize);\n\n    /*\n     * If no new token could be added to the shingle buffer, we have reached\n     * the end of the input stream and have to discard the least recent token.\n     */\n    if (! addedToken) {\n      if (shingleBuf.isEmpty()) {\n        return;\n      } else {\n        shingleBuf.remove(0);\n      }\n    }\n\n    clearShingles();\n\n    int[] endOffsets = new int[shingleBuf.size()];\n    for (int i = 0; i < endOffsets.length; i++) {\n      endOffsets[i] = 0;\n    }\n\n    int i = 0;\n    Token shingle = null;\n    for (Iterator it = shingleBuf.iterator(); it.hasNext(); ) {\n      shingle = (Token) it.next();\n      for (int j = i; j < shingles.length; j++) {\n        if (shingles[j].length() != 0) {\n          shingles[j].append(TOKEN_SEPARATOR);\n        }\n        shingles[j].append(shingle.termBuffer(), 0, shingle.termLength());\n      }\n\n      endOffsets[i] = shingle.endOffset();\n      i++;\n    }\n\n    if ((! shingleBuf.isEmpty()) && outputUnigrams) {\n      Token unigram = (Token) shingleBuf.getFirst();\n      unigram.setPositionIncrement(1);\n      outputBuf.add(unigram);\n    }\n\n    /*\n     * Push new tokens to the output buffer.\n     */\n    if (!shingleBuf.isEmpty()) {\n      Token firstShingle = (Token) shingleBuf.get(0);\n      shingle = (Token) firstShingle.clone();\n      shingle.setType(tokenType);\n    }\n    for (int j = 1; j < shingleBuf.size(); j++) {\n      shingle.setEndOffset(endOffsets[j]);\n      StringBuffer buf = shingles[j];\n      int termLength = buf.length();\n      char[] termBuffer = shingle.termBuffer();\n      if (termBuffer.length < termLength)\n        termBuffer = shingle.resizeTermBuffer(termLength);\n      buf.getChars(0, termLength, termBuffer, 0);\n      shingle.setTermLength(termLength);\n      if ((! outputUnigrams) && j == 1) {\n        shingle.setPositionIncrement(1);\n      } else {\n        shingle.setPositionIncrement(0);\n      }\n      outputBuf.add(shingle.clone());\n    }\n  }\n\n","sourceOld":"  /**\n   * Fill the output buffer with new shingles.\n   *\n   * @throws IOException if there's a problem getting the next token\n   */\n  private void fillOutputBuf() throws IOException {\n    boolean addedToken = false;\n    /*\n     * Try to fill the shingle buffer.\n     */\n    do {\n      Token token = getNextToken();\n      if (token != null) {\n        shingleBuf.add(token);\n        if (shingleBuf.size() > maxShingleSize)\n        {\n          shingleBuf.remove(0);\n        }\n        addedToken = true;\n      } else {\n        break;\n      }\n    } while (shingleBuf.size() < maxShingleSize);\n\n    /*\n     * If no new token could be added to the shingle buffer, we have reached\n     * the end of the input stream and have to discard the least recent token.\n     */\n    if (! addedToken) {\n      if (shingleBuf.isEmpty()) {\n        return;\n      } else {\n        shingleBuf.remove(0);\n      }\n    }\n\n    clearShingles();\n\n    int[] endOffsets = new int[shingleBuf.size()];\n    for (int i = 0; i < endOffsets.length; i++) {\n      endOffsets[i] = 0;\n    }\n\n    int i = 0;\n    Token token = null;\n    for (Iterator it = shingleBuf.iterator(); it.hasNext(); ) {\n      token = (Token) it.next();\n      for (int j = i; j < shingles.length; j++) {\n        if (shingles[j].length() != 0) {\n          shingles[j].append(TOKEN_SEPARATOR);\n        }\n        shingles[j].append(token.termBuffer(), 0, token.termLength());\n      }\n\n      endOffsets[i] = token.endOffset();\n      i++;\n    }\n\n    if ((! shingleBuf.isEmpty()) && outputUnigrams) {\n      Token unigram = (Token) shingleBuf.getFirst();\n      unigram.setPositionIncrement(1);\n      outputBuf.add(unigram);\n    }\n\n    /*\n     * Push new tokens to the output buffer.\n     */\n    for (int j = 1; j < shingleBuf.size(); j++) {\n      Token shingle = new Token(shingles[j].toString(),\n                                ((Token) shingleBuf.get(0)).startOffset(),\n                                endOffsets[j],\n                                tokenType);\n      if ((! outputUnigrams) && j == 1) {\n        shingle.setPositionIncrement(1);\n      } else {\n        shingle.setPositionIncrement(0);\n      }\n      outputBuf.add(shingle);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"7e2cb543b41c145f33390f460ee743d6693c9c6c":["c3e328a6f2b163170d23e06008798fb82c27af8b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["7e2cb543b41c145f33390f460ee743d6693c9c6c"],"c3e328a6f2b163170d23e06008798fb82c27af8b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"7e2cb543b41c145f33390f460ee743d6693c9c6c":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c3e328a6f2b163170d23e06008798fb82c27af8b"],"c3e328a6f2b163170d23e06008798fb82c27af8b":["7e2cb543b41c145f33390f460ee743d6693c9c6c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}