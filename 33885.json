{"path":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testDocsOnlyFreq().mjava","commits":[{"id":"df4e0a0e1d198eaaf06bb504b9f0710c8bd6c2b8","date":1355921476,"type":0,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testDocsOnlyFreq().mjava","pathOld":"/dev/null","sourceNew":"  public void testDocsOnlyFreq() throws Exception {\n    // tests that when fields are indexed with DOCS_ONLY, the Codec\n    // returns 1 in docsEnum.freq()\n    Directory dir = newDirectory();\n    Random random = random();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    // we don't need many documents to assert this, but don't use one document either\n    int numDocs = atLeast(random, 50);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      doc.add(new StringField(\"f\", \"doc\", Store.NO));\n      writer.addDocument(doc);\n    }\n    writer.close();\n    \n    Term term = new Term(\"f\", new BytesRef(\"doc\"));\n    DirectoryReader reader = DirectoryReader.open(dir);\n    for (AtomicReaderContext ctx : reader.leaves()) {\n      DocsEnum de = ctx.reader().termDocsEnum(term);\n      while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n        assertEquals(\"wrong freq for doc \" + de.docID(), 1, de.freq());\n      }\n    }\n    reader.close();\n    \n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d3fcb70cf561547c7bb1506e0cf32ca7b1287064","date":1357616416,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testDocsOnlyFreq().mjava","pathOld":"/dev/null","sourceNew":"  public void testDocsOnlyFreq() throws Exception {\n    // tests that when fields are indexed with DOCS_ONLY, the Codec\n    // returns 1 in docsEnum.freq()\n    Directory dir = newDirectory();\n    Random random = random();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    // we don't need many documents to assert this, but don't use one document either\n    int numDocs = atLeast(random, 50);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      doc.add(new StringField(\"f\", \"doc\", Store.NO));\n      writer.addDocument(doc);\n    }\n    writer.close();\n    \n    Term term = new Term(\"f\", new BytesRef(\"doc\"));\n    DirectoryReader reader = DirectoryReader.open(dir);\n    for (AtomicReaderContext ctx : reader.leaves()) {\n      DocsEnum de = ctx.reader().termDocsEnum(term);\n      while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n        assertEquals(\"wrong freq for doc \" + de.docID(), 1, de.freq());\n      }\n    }\n    reader.close();\n    \n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testDocsOnlyFreq().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testDocsOnlyFreq().mjava","sourceNew":"  public void testDocsOnlyFreq() throws Exception {\n    // tests that when fields are indexed with DOCS_ONLY, the Codec\n    // returns 1 in docsEnum.freq()\n    Directory dir = newDirectory();\n    Random random = random();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    // we don't need many documents to assert this, but don't use one document either\n    int numDocs = atLeast(random, 50);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      doc.add(new StringField(\"f\", \"doc\", Store.NO));\n      writer.addDocument(doc);\n    }\n    writer.shutdown();\n    \n    Term term = new Term(\"f\", new BytesRef(\"doc\"));\n    DirectoryReader reader = DirectoryReader.open(dir);\n    for (AtomicReaderContext ctx : reader.leaves()) {\n      DocsEnum de = ctx.reader().termDocsEnum(term);\n      while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n        assertEquals(\"wrong freq for doc \" + de.docID(), 1, de.freq());\n      }\n    }\n    reader.close();\n    \n    dir.close();\n  }\n\n","sourceOld":"  public void testDocsOnlyFreq() throws Exception {\n    // tests that when fields are indexed with DOCS_ONLY, the Codec\n    // returns 1 in docsEnum.freq()\n    Directory dir = newDirectory();\n    Random random = random();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    // we don't need many documents to assert this, but don't use one document either\n    int numDocs = atLeast(random, 50);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      doc.add(new StringField(\"f\", \"doc\", Store.NO));\n      writer.addDocument(doc);\n    }\n    writer.close();\n    \n    Term term = new Term(\"f\", new BytesRef(\"doc\"));\n    DirectoryReader reader = DirectoryReader.open(dir);\n    for (AtomicReaderContext ctx : reader.leaves()) {\n      DocsEnum de = ctx.reader().termDocsEnum(term);\n      while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n        assertEquals(\"wrong freq for doc \" + de.docID(), 1, de.freq());\n      }\n    }\n    reader.close();\n    \n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testDocsOnlyFreq().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testDocsOnlyFreq().mjava","sourceNew":"  public void testDocsOnlyFreq() throws Exception {\n    // tests that when fields are indexed with DOCS_ONLY, the Codec\n    // returns 1 in docsEnum.freq()\n    Directory dir = newDirectory();\n    Random random = random();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random)));\n    // we don't need many documents to assert this, but don't use one document either\n    int numDocs = atLeast(random, 50);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      doc.add(new StringField(\"f\", \"doc\", Store.NO));\n      writer.addDocument(doc);\n    }\n    writer.shutdown();\n    \n    Term term = new Term(\"f\", new BytesRef(\"doc\"));\n    DirectoryReader reader = DirectoryReader.open(dir);\n    for (AtomicReaderContext ctx : reader.leaves()) {\n      DocsEnum de = ctx.reader().termDocsEnum(term);\n      while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n        assertEquals(\"wrong freq for doc \" + de.docID(), 1, de.freq());\n      }\n    }\n    reader.close();\n    \n    dir.close();\n  }\n\n","sourceOld":"  public void testDocsOnlyFreq() throws Exception {\n    // tests that when fields are indexed with DOCS_ONLY, the Codec\n    // returns 1 in docsEnum.freq()\n    Directory dir = newDirectory();\n    Random random = random();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    // we don't need many documents to assert this, but don't use one document either\n    int numDocs = atLeast(random, 50);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      doc.add(new StringField(\"f\", \"doc\", Store.NO));\n      writer.addDocument(doc);\n    }\n    writer.shutdown();\n    \n    Term term = new Term(\"f\", new BytesRef(\"doc\"));\n    DirectoryReader reader = DirectoryReader.open(dir);\n    for (AtomicReaderContext ctx : reader.leaves()) {\n      DocsEnum de = ctx.reader().termDocsEnum(term);\n      while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n        assertEquals(\"wrong freq for doc \" + de.docID(), 1, de.freq());\n      }\n    }\n    reader.close();\n    \n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testDocsOnlyFreq().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testDocsOnlyFreq().mjava","sourceNew":"  public void testDocsOnlyFreq() throws Exception {\n    // tests that when fields are indexed with DOCS_ONLY, the Codec\n    // returns 1 in docsEnum.freq()\n    Directory dir = newDirectory();\n    Random random = random();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random)));\n    // we don't need many documents to assert this, but don't use one document either\n    int numDocs = atLeast(random, 50);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      doc.add(new StringField(\"f\", \"doc\", Store.NO));\n      writer.addDocument(doc);\n    }\n    writer.close();\n    \n    Term term = new Term(\"f\", new BytesRef(\"doc\"));\n    DirectoryReader reader = DirectoryReader.open(dir);\n    for (AtomicReaderContext ctx : reader.leaves()) {\n      DocsEnum de = ctx.reader().termDocsEnum(term);\n      while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n        assertEquals(\"wrong freq for doc \" + de.docID(), 1, de.freq());\n      }\n    }\n    reader.close();\n    \n    dir.close();\n  }\n\n","sourceOld":"  public void testDocsOnlyFreq() throws Exception {\n    // tests that when fields are indexed with DOCS_ONLY, the Codec\n    // returns 1 in docsEnum.freq()\n    Directory dir = newDirectory();\n    Random random = random();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random)));\n    // we don't need many documents to assert this, but don't use one document either\n    int numDocs = atLeast(random, 50);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      doc.add(new StringField(\"f\", \"doc\", Store.NO));\n      writer.addDocument(doc);\n    }\n    writer.shutdown();\n    \n    Term term = new Term(\"f\", new BytesRef(\"doc\"));\n    DirectoryReader reader = DirectoryReader.open(dir);\n    for (AtomicReaderContext ctx : reader.leaves()) {\n      DocsEnum de = ctx.reader().termDocsEnum(term);\n      while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n        assertEquals(\"wrong freq for doc \" + de.docID(), 1, de.freq());\n      }\n    }\n    reader.close();\n    \n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c9fb5f46e264daf5ba3860defe623a89d202dd87","date":1411516315,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testDocsOnlyFreq().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testDocsOnlyFreq().mjava","sourceNew":"  public void testDocsOnlyFreq() throws Exception {\n    // tests that when fields are indexed with DOCS_ONLY, the Codec\n    // returns 1 in docsEnum.freq()\n    Directory dir = newDirectory();\n    Random random = random();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random)));\n    // we don't need many documents to assert this, but don't use one document either\n    int numDocs = atLeast(random, 50);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      doc.add(new StringField(\"f\", \"doc\", Store.NO));\n      writer.addDocument(doc);\n    }\n    writer.close();\n    \n    Term term = new Term(\"f\", new BytesRef(\"doc\"));\n    DirectoryReader reader = DirectoryReader.open(dir);\n    for (LeafReaderContext ctx : reader.leaves()) {\n      DocsEnum de = ctx.reader().termDocsEnum(term);\n      while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n        assertEquals(\"wrong freq for doc \" + de.docID(), 1, de.freq());\n      }\n    }\n    reader.close();\n    \n    dir.close();\n  }\n\n","sourceOld":"  public void testDocsOnlyFreq() throws Exception {\n    // tests that when fields are indexed with DOCS_ONLY, the Codec\n    // returns 1 in docsEnum.freq()\n    Directory dir = newDirectory();\n    Random random = random();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random)));\n    // we don't need many documents to assert this, but don't use one document either\n    int numDocs = atLeast(random, 50);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      doc.add(new StringField(\"f\", \"doc\", Store.NO));\n      writer.addDocument(doc);\n    }\n    writer.close();\n    \n    Term term = new Term(\"f\", new BytesRef(\"doc\"));\n    DirectoryReader reader = DirectoryReader.open(dir);\n    for (AtomicReaderContext ctx : reader.leaves()) {\n      DocsEnum de = ctx.reader().termDocsEnum(term);\n      while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n        assertEquals(\"wrong freq for doc \" + de.docID(), 1, de.freq());\n      }\n    }\n    reader.close();\n    \n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"51f5280f31484820499077f41fcdfe92d527d9dc","date":1423229122,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testDocsOnlyFreq().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testDocsOnlyFreq().mjava","sourceNew":"  public void testDocsOnlyFreq() throws Exception {\n    // tests that when fields are indexed with DOCS_ONLY, the Codec\n    // returns 1 in docsEnum.freq()\n    Directory dir = newDirectory();\n    Random random = random();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random)));\n    // we don't need many documents to assert this, but don't use one document either\n    int numDocs = atLeast(random, 50);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      doc.add(new StringField(\"f\", \"doc\", Store.NO));\n      writer.addDocument(doc);\n    }\n    writer.close();\n    \n    Term term = new Term(\"f\", new BytesRef(\"doc\"));\n    DirectoryReader reader = DirectoryReader.open(dir);\n    for (LeafReaderContext ctx : reader.leaves()) {\n      PostingsEnum de = ctx.reader().termDocsEnum(term);\n      while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n        assertEquals(\"wrong freq for doc \" + de.docID(), 1, de.freq());\n      }\n    }\n    reader.close();\n    \n    dir.close();\n  }\n\n","sourceOld":"  public void testDocsOnlyFreq() throws Exception {\n    // tests that when fields are indexed with DOCS_ONLY, the Codec\n    // returns 1 in docsEnum.freq()\n    Directory dir = newDirectory();\n    Random random = random();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random)));\n    // we don't need many documents to assert this, but don't use one document either\n    int numDocs = atLeast(random, 50);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      doc.add(new StringField(\"f\", \"doc\", Store.NO));\n      writer.addDocument(doc);\n    }\n    writer.close();\n    \n    Term term = new Term(\"f\", new BytesRef(\"doc\"));\n    DirectoryReader reader = DirectoryReader.open(dir);\n    for (LeafReaderContext ctx : reader.leaves()) {\n      DocsEnum de = ctx.reader().termDocsEnum(term);\n      while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n        assertEquals(\"wrong freq for doc \" + de.docID(), 1, de.freq());\n      }\n    }\n    reader.close();\n    \n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e73063b92d958076ef4ae8beb5f493e8ccdcecb4","date":1424177215,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testDocsOnlyFreq().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testDocsOnlyFreq().mjava","sourceNew":"  public void testDocsOnlyFreq() throws Exception {\n    // tests that when fields are indexed with DOCS_ONLY, the Codec\n    // returns 1 in docsEnum.freq()\n    Directory dir = newDirectory();\n    Random random = random();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random)));\n    // we don't need many documents to assert this, but don't use one document either\n    int numDocs = atLeast(random, 50);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      doc.add(new StringField(\"f\", \"doc\", Store.NO));\n      writer.addDocument(doc);\n    }\n    writer.close();\n    \n    Term term = new Term(\"f\", new BytesRef(\"doc\"));\n    DirectoryReader reader = DirectoryReader.open(dir);\n    for (LeafReaderContext ctx : reader.leaves()) {\n      PostingsEnum de = ctx.reader().postings(term);\n      while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n        assertEquals(\"wrong freq for doc \" + de.docID(), 1, de.freq());\n      }\n    }\n    reader.close();\n    \n    dir.close();\n  }\n\n","sourceOld":"  public void testDocsOnlyFreq() throws Exception {\n    // tests that when fields are indexed with DOCS_ONLY, the Codec\n    // returns 1 in docsEnum.freq()\n    Directory dir = newDirectory();\n    Random random = random();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random)));\n    // we don't need many documents to assert this, but don't use one document either\n    int numDocs = atLeast(random, 50);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      doc.add(new StringField(\"f\", \"doc\", Store.NO));\n      writer.addDocument(doc);\n    }\n    writer.close();\n    \n    Term term = new Term(\"f\", new BytesRef(\"doc\"));\n    DirectoryReader reader = DirectoryReader.open(dir);\n    for (LeafReaderContext ctx : reader.leaves()) {\n      PostingsEnum de = ctx.reader().termDocsEnum(term);\n      while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n        assertEquals(\"wrong freq for doc \" + de.docID(), 1, de.freq());\n      }\n    }\n    reader.close();\n    \n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","df4e0a0e1d198eaaf06bb504b9f0710c8bd6c2b8"],"e73063b92d958076ef4ae8beb5f493e8ccdcecb4":["51f5280f31484820499077f41fcdfe92d527d9dc"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"df4e0a0e1d198eaaf06bb504b9f0710c8bd6c2b8":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["df4e0a0e1d198eaaf06bb504b9f0710c8bd6c2b8"],"51f5280f31484820499077f41fcdfe92d527d9dc":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["e73063b92d958076ef4ae8beb5f493e8ccdcecb4"]},"commit2Childs":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":[],"e73063b92d958076ef4ae8beb5f493e8ccdcecb4":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"df4e0a0e1d198eaaf06bb504b9f0710c8bd6c2b8":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","df4e0a0e1d198eaaf06bb504b9f0710c8bd6c2b8"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"51f5280f31484820499077f41fcdfe92d527d9dc":["e73063b92d958076ef4ae8beb5f493e8ccdcecb4"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["51f5280f31484820499077f41fcdfe92d527d9dc"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}