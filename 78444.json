{"path":"lucene/facet/src/test/org/apache/lucene/facet/TestTaxonomyFacetCounts#testManyFacetsInOneDocument().mjava","commits":[{"id":"21d36d0db865f7b84026b447bec653469a6e66df","date":1385495602,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/TestTaxonomyFacetCounts#testManyFacetsInOneDocument().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/simple/TestTaxonomyFacetCounts#testManyFacetsInOneDocument().mjava","sourceNew":"  // LUCENE-4583: make sure if we require > 32 KB for one\n  // document, we don't hit exc when using Facet42DocValuesFormat\n  public void testManyFacetsInOneDocument() throws Exception {\n    assumeTrue(\"default Codec doesn't support huge BinaryDocValues\", _TestUtil.fieldSupportsHugeBinaryDocValues(FacetsConfig.DEFAULT_INDEX_FIELD_NAME));\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    FacetsConfig config = new FacetsConfig(taxoWriter);\n    config.setMultiValued(\"dim\", true);\n    \n    int numLabels = _TestUtil.nextInt(random(), 40000, 100000);\n    \n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"text\", Field.Store.NO));\n    for (int i = 0; i < numLabels; i++) {\n      doc.add(new FacetField(\"dim\", \"\" + i));\n    }\n    writer.addDocument(config.build(doc));\n    \n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    \n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    \n    // Aggregate the facet counts:\n    FacetsCollector c = new FacetsCollector();\n    \n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n    Facets facets = getTaxonomyFacetCounts(taxoReader, config, c);\n\n    FacetResult result = facets.getTopChildren(Integer.MAX_VALUE, \"dim\");\n    assertEquals(numLabels, result.labelValues.length);\n    Set<String> allLabels = new HashSet<String>();\n    for (LabelAndValue labelValue : result.labelValues) {\n      allLabels.add(labelValue.label);\n      assertEquals(1, labelValue.value.intValue());\n    }\n    assertEquals(numLabels, allLabels.size());\n    \n    IOUtils.close(searcher.getIndexReader(), taxoWriter, writer, taxoReader, dir, taxoDir);\n  }\n\n","sourceOld":"  // LUCENE-4583: make sure if we require > 32 KB for one\n  // document, we don't hit exc when using Facet42DocValuesFormat\n  public void testManyFacetsInOneDocument() throws Exception {\n    assumeTrue(\"default Codec doesn't support huge BinaryDocValues\", _TestUtil.fieldSupportsHugeBinaryDocValues(FacetsConfig.DEFAULT_INDEX_FIELD_NAME));\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    FacetsConfig config = new FacetsConfig(taxoWriter);\n    config.setMultiValued(\"dim\", true);\n    \n    int numLabels = _TestUtil.nextInt(random(), 40000, 100000);\n    \n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"text\", Field.Store.NO));\n    for (int i = 0; i < numLabels; i++) {\n      doc.add(new FacetField(\"dim\", \"\" + i));\n    }\n    writer.addDocument(config.build(doc));\n    \n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    \n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    \n    // Aggregate the facet counts:\n    SimpleFacetsCollector c = new SimpleFacetsCollector();\n    \n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n    Facets facets = getTaxonomyFacetCounts(taxoReader, config, c);\n\n    SimpleFacetResult result = facets.getTopChildren(Integer.MAX_VALUE, \"dim\");\n    assertEquals(numLabels, result.labelValues.length);\n    Set<String> allLabels = new HashSet<String>();\n    for (LabelAndValue labelValue : result.labelValues) {\n      allLabels.add(labelValue.label);\n      assertEquals(1, labelValue.value.intValue());\n    }\n    assertEquals(numLabels, allLabels.size());\n    \n    IOUtils.close(searcher.getIndexReader(), taxoWriter, writer, taxoReader, dir, taxoDir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fd83550e4b0bdd36e7d9dca9273264100782440b","date":1385761753,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/TestTaxonomyFacetCounts#testManyFacetsInOneDocument().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/TestTaxonomyFacetCounts#testManyFacetsInOneDocument().mjava","sourceNew":"  // LUCENE-4583: make sure if we require > 32 KB for one\n  // document, we don't hit exc when using Facet42DocValuesFormat\n  public void testManyFacetsInOneDocument() throws Exception {\n    assumeTrue(\"default Codec doesn't support huge BinaryDocValues\", _TestUtil.fieldSupportsHugeBinaryDocValues(FacetsConfig.DEFAULT_INDEX_FIELD_NAME));\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    FacetsConfig config = new FacetsConfig();\n    config.setMultiValued(\"dim\", true);\n    \n    int numLabels = _TestUtil.nextInt(random(), 40000, 100000);\n    \n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"text\", Field.Store.NO));\n    for (int i = 0; i < numLabels; i++) {\n      doc.add(new FacetField(\"dim\", \"\" + i));\n    }\n    writer.addDocument(config.build(taxoWriter, doc));\n    \n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    \n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    \n    // Aggregate the facet counts:\n    FacetsCollector c = new FacetsCollector();\n    \n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n    Facets facets = getTaxonomyFacetCounts(taxoReader, config, c);\n\n    FacetResult result = facets.getTopChildren(Integer.MAX_VALUE, \"dim\");\n    assertEquals(numLabels, result.labelValues.length);\n    Set<String> allLabels = new HashSet<String>();\n    for (LabelAndValue labelValue : result.labelValues) {\n      allLabels.add(labelValue.label);\n      assertEquals(1, labelValue.value.intValue());\n    }\n    assertEquals(numLabels, allLabels.size());\n    \n    IOUtils.close(searcher.getIndexReader(), taxoWriter, writer, taxoReader, dir, taxoDir);\n  }\n\n","sourceOld":"  // LUCENE-4583: make sure if we require > 32 KB for one\n  // document, we don't hit exc when using Facet42DocValuesFormat\n  public void testManyFacetsInOneDocument() throws Exception {\n    assumeTrue(\"default Codec doesn't support huge BinaryDocValues\", _TestUtil.fieldSupportsHugeBinaryDocValues(FacetsConfig.DEFAULT_INDEX_FIELD_NAME));\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    FacetsConfig config = new FacetsConfig(taxoWriter);\n    config.setMultiValued(\"dim\", true);\n    \n    int numLabels = _TestUtil.nextInt(random(), 40000, 100000);\n    \n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"text\", Field.Store.NO));\n    for (int i = 0; i < numLabels; i++) {\n      doc.add(new FacetField(\"dim\", \"\" + i));\n    }\n    writer.addDocument(config.build(doc));\n    \n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    \n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    \n    // Aggregate the facet counts:\n    FacetsCollector c = new FacetsCollector();\n    \n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n    Facets facets = getTaxonomyFacetCounts(taxoReader, config, c);\n\n    FacetResult result = facets.getTopChildren(Integer.MAX_VALUE, \"dim\");\n    assertEquals(numLabels, result.labelValues.length);\n    Set<String> allLabels = new HashSet<String>();\n    for (LabelAndValue labelValue : result.labelValues) {\n      allLabels.add(labelValue.label);\n      assertEquals(1, labelValue.value.intValue());\n    }\n    assertEquals(numLabels, allLabels.size());\n    \n    IOUtils.close(searcher.getIndexReader(), taxoWriter, writer, taxoReader, dir, taxoDir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4edc984f0f4ac77c37e48ace2932f780f888453c","date":1388475218,"type":5,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyFacetCounts#testManyFacetsInOneDocument().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/TestTaxonomyFacetCounts#testManyFacetsInOneDocument().mjava","sourceNew":"  // LUCENE-4583: make sure if we require > 32 KB for one\n  // document, we don't hit exc when using Facet42DocValuesFormat\n  public void testManyFacetsInOneDocument() throws Exception {\n    assumeTrue(\"default Codec doesn't support huge BinaryDocValues\", _TestUtil.fieldSupportsHugeBinaryDocValues(FacetsConfig.DEFAULT_INDEX_FIELD_NAME));\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    FacetsConfig config = new FacetsConfig();\n    config.setMultiValued(\"dim\", true);\n    \n    int numLabels = _TestUtil.nextInt(random(), 40000, 100000);\n    \n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"text\", Field.Store.NO));\n    for (int i = 0; i < numLabels; i++) {\n      doc.add(new FacetField(\"dim\", \"\" + i));\n    }\n    writer.addDocument(config.build(taxoWriter, doc));\n    \n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    \n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    \n    // Aggregate the facet counts:\n    FacetsCollector c = new FacetsCollector();\n    \n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n    Facets facets = getTaxonomyFacetCounts(taxoReader, config, c);\n\n    FacetResult result = facets.getTopChildren(Integer.MAX_VALUE, \"dim\");\n    assertEquals(numLabels, result.labelValues.length);\n    Set<String> allLabels = new HashSet<String>();\n    for (LabelAndValue labelValue : result.labelValues) {\n      allLabels.add(labelValue.label);\n      assertEquals(1, labelValue.value.intValue());\n    }\n    assertEquals(numLabels, allLabels.size());\n    \n    IOUtils.close(searcher.getIndexReader(), taxoWriter, writer, taxoReader, dir, taxoDir);\n  }\n\n","sourceOld":"  // LUCENE-4583: make sure if we require > 32 KB for one\n  // document, we don't hit exc when using Facet42DocValuesFormat\n  public void testManyFacetsInOneDocument() throws Exception {\n    assumeTrue(\"default Codec doesn't support huge BinaryDocValues\", _TestUtil.fieldSupportsHugeBinaryDocValues(FacetsConfig.DEFAULT_INDEX_FIELD_NAME));\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    FacetsConfig config = new FacetsConfig();\n    config.setMultiValued(\"dim\", true);\n    \n    int numLabels = _TestUtil.nextInt(random(), 40000, 100000);\n    \n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"text\", Field.Store.NO));\n    for (int i = 0; i < numLabels; i++) {\n      doc.add(new FacetField(\"dim\", \"\" + i));\n    }\n    writer.addDocument(config.build(taxoWriter, doc));\n    \n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    \n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    \n    // Aggregate the facet counts:\n    FacetsCollector c = new FacetsCollector();\n    \n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n    Facets facets = getTaxonomyFacetCounts(taxoReader, config, c);\n\n    FacetResult result = facets.getTopChildren(Integer.MAX_VALUE, \"dim\");\n    assertEquals(numLabels, result.labelValues.length);\n    Set<String> allLabels = new HashSet<String>();\n    for (LabelAndValue labelValue : result.labelValues) {\n      allLabels.add(labelValue.label);\n      assertEquals(1, labelValue.value.intValue());\n    }\n    assertEquals(numLabels, allLabels.size());\n    \n    IOUtils.close(searcher.getIndexReader(), taxoWriter, writer, taxoReader, dir, taxoDir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4edc984f0f4ac77c37e48ace2932f780f888453c":["fd83550e4b0bdd36e7d9dca9273264100782440b"],"21d36d0db865f7b84026b447bec653469a6e66df":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"fd83550e4b0bdd36e7d9dca9273264100782440b":["21d36d0db865f7b84026b447bec653469a6e66df"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["21d36d0db865f7b84026b447bec653469a6e66df","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"4edc984f0f4ac77c37e48ace2932f780f888453c":[],"21d36d0db865f7b84026b447bec653469a6e66df":["fd83550e4b0bdd36e7d9dca9273264100782440b"],"fd83550e4b0bdd36e7d9dca9273264100782440b":["4edc984f0f4ac77c37e48ace2932f780f888453c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4edc984f0f4ac77c37e48ace2932f780f888453c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}