{"path":"lucene/contrib/queries/src/java/org/apache/lucene/search/similar/MoreLikeThis#createQueue(Map[String,Int]).mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/queries/src/java/org/apache/lucene/search/similar/MoreLikeThis#createQueue(Map[String,Int]).mjava","pathOld":"contrib/queries/src/java/org/apache/lucene/search/similar/MoreLikeThis#createQueue(Map[String,Int]).mjava","sourceNew":"    /**\n     * Create a PriorityQueue from a word->tf map.\n     *\n     * @param words a map of words keyed on the word(String) with Int objects as the values.\n     */\n    private PriorityQueue<Object[]> createQueue(Map<String,Int> words) throws IOException {\n        // have collected all words in doc and their freqs\n        int numDocs = ir.numDocs();\n        FreqQ res = new FreqQ(words.size()); // will order words by score\n\n        Iterator<String> it = words.keySet().iterator();\n        while (it.hasNext()) { // for every word\n            String word = it.next();\n\n            int tf = words.get(word).x; // term freq in the source doc\n            if (minTermFreq > 0 && tf < minTermFreq) {\n                continue; // filter out words that don't occur enough times in the source\n            }\n\n            // go through all the fields and find the largest document frequency\n            String topField = fieldNames[0];\n            int docFreq = 0;\n            for (int i = 0; i < fieldNames.length; i++) {\n                int freq = ir.docFreq(new Term(fieldNames[i], word));\n                topField = (freq > docFreq) ? fieldNames[i] : topField;\n                docFreq = (freq > docFreq) ? freq : docFreq;\n            }\n\n            if (minDocFreq > 0 && docFreq < minDocFreq) {\n                continue; // filter out words that don't occur in enough docs\n            }\n\n            if (docFreq > maxDocFreq) {\n                continue; // filter out words that occur in too many docs            \t\n            }\n\n            if (docFreq == 0) {\n                continue; // index update problem?\n            }\n\n            float idf = similarity.idf(docFreq, numDocs);\n            float score = tf * idf;\n\n            // only really need 1st 3 entries, other ones are for troubleshooting\n            res.insertWithOverflow(new Object[]{word,                   // the word\n                                    topField,               // the top field\n                                    Float.valueOf(score),       // overall score\n                                    Float.valueOf(idf),         // idf\n                                    Integer.valueOf(docFreq),   // freq in all docs\n                                    Integer.valueOf(tf)\n            });\n        }\n        return res;\n    }\n\n","sourceOld":"    /**\n     * Create a PriorityQueue from a word->tf map.\n     *\n     * @param words a map of words keyed on the word(String) with Int objects as the values.\n     */\n    private PriorityQueue<Object[]> createQueue(Map<String,Int> words) throws IOException {\n        // have collected all words in doc and their freqs\n        int numDocs = ir.numDocs();\n        FreqQ res = new FreqQ(words.size()); // will order words by score\n\n        Iterator<String> it = words.keySet().iterator();\n        while (it.hasNext()) { // for every word\n            String word = it.next();\n\n            int tf = words.get(word).x; // term freq in the source doc\n            if (minTermFreq > 0 && tf < minTermFreq) {\n                continue; // filter out words that don't occur enough times in the source\n            }\n\n            // go through all the fields and find the largest document frequency\n            String topField = fieldNames[0];\n            int docFreq = 0;\n            for (int i = 0; i < fieldNames.length; i++) {\n                int freq = ir.docFreq(new Term(fieldNames[i], word));\n                topField = (freq > docFreq) ? fieldNames[i] : topField;\n                docFreq = (freq > docFreq) ? freq : docFreq;\n            }\n\n            if (minDocFreq > 0 && docFreq < minDocFreq) {\n                continue; // filter out words that don't occur in enough docs\n            }\n\n            if (docFreq > maxDocFreq) {\n                continue; // filter out words that occur in too many docs            \t\n            }\n\n            if (docFreq == 0) {\n                continue; // index update problem?\n            }\n\n            float idf = similarity.idf(docFreq, numDocs);\n            float score = tf * idf;\n\n            // only really need 1st 3 entries, other ones are for troubleshooting\n            res.insertWithOverflow(new Object[]{word,                   // the word\n                                    topField,               // the top field\n                                    Float.valueOf(score),       // overall score\n                                    Float.valueOf(idf),         // idf\n                                    Integer.valueOf(docFreq),   // freq in all docs\n                                    Integer.valueOf(tf)\n            });\n        }\n        return res;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e141595402370bee958745de8b1c9de1fa182581","date":1310547892,"type":3,"author":"Christopher John Male","isMerge":false,"pathNew":"lucene/contrib/queries/src/java/org/apache/lucene/search/similar/MoreLikeThis#createQueue(Map[String,Int]).mjava","pathOld":"lucene/contrib/queries/src/java/org/apache/lucene/search/similar/MoreLikeThis#createQueue(Map[String,Int]).mjava","sourceNew":"  /**\n   * Create a PriorityQueue from a word->tf map.\n   *\n   * @param words a map of words keyed on the word(String) with Int objects as the values.\n   */\n  private PriorityQueue<Object[]> createQueue(Map<String, Int> words) throws IOException {\n    // have collected all words in doc and their freqs\n    int numDocs = ir.numDocs();\n    FreqQ res = new FreqQ(words.size()); // will order words by score\n\n    for (String word : words.keySet()) { // for every word\n      int tf = words.get(word).x; // term freq in the source doc\n      if (minTermFreq > 0 && tf < minTermFreq) {\n        continue; // filter out words that don't occur enough times in the source\n      }\n\n      // go through all the fields and find the largest document frequency\n      String topField = fieldNames[0];\n      int docFreq = 0;\n      for (String fieldName : fieldNames) {\n        int freq = ir.docFreq(new Term(fieldName, word));\n        topField = (freq > docFreq) ? fieldName : topField;\n        docFreq = (freq > docFreq) ? freq : docFreq;\n      }\n\n      if (minDocFreq > 0 && docFreq < minDocFreq) {\n        continue; // filter out words that don't occur in enough docs\n      }\n\n      if (docFreq > maxDocFreq) {\n        continue; // filter out words that occur in too many docs\n      }\n\n      if (docFreq == 0) {\n        continue; // index update problem?\n      }\n\n      float idf = similarity.idf(docFreq, numDocs);\n      float score = tf * idf;\n\n      // only really need 1st 3 entries, other ones are for troubleshooting\n      res.insertWithOverflow(new Object[]{word,                   // the word\n          topField,               // the top field\n          score,       // overall score\n          idf,         // idf\n          docFreq,   // freq in all docs\n          tf\n      });\n    }\n    return res;\n  }\n\n","sourceOld":"    /**\n     * Create a PriorityQueue from a word->tf map.\n     *\n     * @param words a map of words keyed on the word(String) with Int objects as the values.\n     */\n    private PriorityQueue<Object[]> createQueue(Map<String,Int> words) throws IOException {\n        // have collected all words in doc and their freqs\n        int numDocs = ir.numDocs();\n        FreqQ res = new FreqQ(words.size()); // will order words by score\n\n        Iterator<String> it = words.keySet().iterator();\n        while (it.hasNext()) { // for every word\n            String word = it.next();\n\n            int tf = words.get(word).x; // term freq in the source doc\n            if (minTermFreq > 0 && tf < minTermFreq) {\n                continue; // filter out words that don't occur enough times in the source\n            }\n\n            // go through all the fields and find the largest document frequency\n            String topField = fieldNames[0];\n            int docFreq = 0;\n            for (int i = 0; i < fieldNames.length; i++) {\n                int freq = ir.docFreq(new Term(fieldNames[i], word));\n                topField = (freq > docFreq) ? fieldNames[i] : topField;\n                docFreq = (freq > docFreq) ? freq : docFreq;\n            }\n\n            if (minDocFreq > 0 && docFreq < minDocFreq) {\n                continue; // filter out words that don't occur in enough docs\n            }\n\n            if (docFreq > maxDocFreq) {\n                continue; // filter out words that occur in too many docs            \t\n            }\n\n            if (docFreq == 0) {\n                continue; // index update problem?\n            }\n\n            float idf = similarity.idf(docFreq, numDocs);\n            float score = tf * idf;\n\n            // only really need 1st 3 entries, other ones are for troubleshooting\n            res.insertWithOverflow(new Object[]{word,                   // the word\n                                    topField,               // the top field\n                                    Float.valueOf(score),       // overall score\n                                    Float.valueOf(idf),         // idf\n                                    Integer.valueOf(docFreq),   // freq in all docs\n                                    Integer.valueOf(tf)\n            });\n        }\n        return res;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7bae1b88906b69dec0d80b1a7afc3c98ec50fa1","date":1310609231,"type":5,"author":"Christopher John Male","isMerge":false,"pathNew":"modules/queries/src/java/org/apache/lucene/queries/mlt/MoreLikeThis#createQueue(Map[String,Int]).mjava","pathOld":"lucene/contrib/queries/src/java/org/apache/lucene/search/similar/MoreLikeThis#createQueue(Map[String,Int]).mjava","sourceNew":"  /**\n   * Create a PriorityQueue from a word->tf map.\n   *\n   * @param words a map of words keyed on the word(String) with Int objects as the values.\n   */\n  private PriorityQueue<Object[]> createQueue(Map<String, Int> words) throws IOException {\n    // have collected all words in doc and their freqs\n    int numDocs = ir.numDocs();\n    FreqQ res = new FreqQ(words.size()); // will order words by score\n\n    for (String word : words.keySet()) { // for every word\n      int tf = words.get(word).x; // term freq in the source doc\n      if (minTermFreq > 0 && tf < minTermFreq) {\n        continue; // filter out words that don't occur enough times in the source\n      }\n\n      // go through all the fields and find the largest document frequency\n      String topField = fieldNames[0];\n      int docFreq = 0;\n      for (String fieldName : fieldNames) {\n        int freq = ir.docFreq(new Term(fieldName, word));\n        topField = (freq > docFreq) ? fieldName : topField;\n        docFreq = (freq > docFreq) ? freq : docFreq;\n      }\n\n      if (minDocFreq > 0 && docFreq < minDocFreq) {\n        continue; // filter out words that don't occur in enough docs\n      }\n\n      if (docFreq > maxDocFreq) {\n        continue; // filter out words that occur in too many docs\n      }\n\n      if (docFreq == 0) {\n        continue; // index update problem?\n      }\n\n      float idf = similarity.idf(docFreq, numDocs);\n      float score = tf * idf;\n\n      // only really need 1st 3 entries, other ones are for troubleshooting\n      res.insertWithOverflow(new Object[]{word,                   // the word\n          topField,               // the top field\n          score,       // overall score\n          idf,         // idf\n          docFreq,   // freq in all docs\n          tf\n      });\n    }\n    return res;\n  }\n\n","sourceOld":"  /**\n   * Create a PriorityQueue from a word->tf map.\n   *\n   * @param words a map of words keyed on the word(String) with Int objects as the values.\n   */\n  private PriorityQueue<Object[]> createQueue(Map<String, Int> words) throws IOException {\n    // have collected all words in doc and their freqs\n    int numDocs = ir.numDocs();\n    FreqQ res = new FreqQ(words.size()); // will order words by score\n\n    for (String word : words.keySet()) { // for every word\n      int tf = words.get(word).x; // term freq in the source doc\n      if (minTermFreq > 0 && tf < minTermFreq) {\n        continue; // filter out words that don't occur enough times in the source\n      }\n\n      // go through all the fields and find the largest document frequency\n      String topField = fieldNames[0];\n      int docFreq = 0;\n      for (String fieldName : fieldNames) {\n        int freq = ir.docFreq(new Term(fieldName, word));\n        topField = (freq > docFreq) ? fieldName : topField;\n        docFreq = (freq > docFreq) ? freq : docFreq;\n      }\n\n      if (minDocFreq > 0 && docFreq < minDocFreq) {\n        continue; // filter out words that don't occur in enough docs\n      }\n\n      if (docFreq > maxDocFreq) {\n        continue; // filter out words that occur in too many docs\n      }\n\n      if (docFreq == 0) {\n        continue; // index update problem?\n      }\n\n      float idf = similarity.idf(docFreq, numDocs);\n      float score = tf * idf;\n\n      // only really need 1st 3 entries, other ones are for troubleshooting\n      res.insertWithOverflow(new Object[]{word,                   // the word\n          topField,               // the top field\n          score,       // overall score\n          idf,         // idf\n          docFreq,   // freq in all docs\n          tf\n      });\n    }\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b7bae1b88906b69dec0d80b1a7afc3c98ec50fa1":["e141595402370bee958745de8b1c9de1fa182581"],"e141595402370bee958745de8b1c9de1fa182581":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b7bae1b88906b69dec0d80b1a7afc3c98ec50fa1"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"b7bae1b88906b69dec0d80b1a7afc3c98ec50fa1":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"e141595402370bee958745de8b1c9de1fa182581":["b7bae1b88906b69dec0d80b1a7afc3c98ec50fa1"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["e141595402370bee958745de8b1c9de1fa182581"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}