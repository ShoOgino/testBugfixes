{"path":"contrib/analyzers/common/src/java/org/apache/lucene/analysis/compound/HyphenationCompoundWordTokenFilter#HyphenationCompoundWordTokenFilter(Version,TokenStream,HyphenationTree,Set,int,int,int,boolean).mjava","commits":[{"id":"7f6c85ffa816c86be877aa7a5029a5daa1336e7f","date":1259617761,"type":0,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/analyzers/common/src/java/org/apache/lucene/analysis/compound/HyphenationCompoundWordTokenFilter#HyphenationCompoundWordTokenFilter(Version,TokenStream,HyphenationTree,Set,int,int,int,boolean).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Creates a new {@link HyphenationCompoundWordTokenFilter} instance.\n   * \n   * @param matchVersion\n   *          Lucene version to enable correct Unicode 4.0 behavior in the\n   *          dictionaries if Version > 3.0. See <a\n   *          href=\"CompoundWordTokenFilterBase#version\"\n   *          >CompoundWordTokenFilterBase</a> for details.\n   * @param input\n   *          the {@link TokenStream} to process\n   * @param hyphenator\n   *          the hyphenation pattern tree to use for hyphenation\n   * @param dictionary\n   *          the word dictionary to match against. If this is a\n   *          {@link org.apache.lucene.analysis.CharArraySet CharArraySet} it\n   *          must have set ignoreCase=false and only contain lower case\n   *          strings.\n   * @param minWordSize\n   *          only words longer than this get processed\n   * @param minSubwordSize\n   *          only subwords longer than this get to the output stream\n   * @param maxSubwordSize\n   *          only subwords shorter than this get to the output stream\n   * @param onlyLongestMatch\n   *          Add only the longest matching subword to the stream\n   */\n  public HyphenationCompoundWordTokenFilter(Version matchVersion, TokenStream input,\n      HyphenationTree hyphenator, Set dictionary, int minWordSize,\n      int minSubwordSize, int maxSubwordSize, boolean onlyLongestMatch) {\n    super(matchVersion, input, dictionary, minWordSize, minSubwordSize, maxSubwordSize,\n        onlyLongestMatch);\n\n    this.hyphenator = hyphenator;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["1e15bea9339982eec538668b67ae252b28e0003e"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a9ac13b5f0ce5ef1b2ce168367d993a79594b23a","date":1267298041,"type":5,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/analyzers/common/src/java/org/apache/lucene/analysis/compound/HyphenationCompoundWordTokenFilter#HyphenationCompoundWordTokenFilter(Version,TokenStream,HyphenationTree,Set[#],int,int,int,boolean).mjava","pathOld":"contrib/analyzers/common/src/java/org/apache/lucene/analysis/compound/HyphenationCompoundWordTokenFilter#HyphenationCompoundWordTokenFilter(Version,TokenStream,HyphenationTree,Set,int,int,int,boolean).mjava","sourceNew":"  /**\n   * Creates a new {@link HyphenationCompoundWordTokenFilter} instance.\n   * \n   * @param matchVersion\n   *          Lucene version to enable correct Unicode 4.0 behavior in the\n   *          dictionaries if Version > 3.0. See <a\n   *          href=\"CompoundWordTokenFilterBase#version\"\n   *          >CompoundWordTokenFilterBase</a> for details.\n   * @param input\n   *          the {@link TokenStream} to process\n   * @param hyphenator\n   *          the hyphenation pattern tree to use for hyphenation\n   * @param dictionary\n   *          the word dictionary to match against. If this is a\n   *          {@link org.apache.lucene.analysis.CharArraySet CharArraySet} it\n   *          must have set ignoreCase=false and only contain lower case\n   *          strings.\n   * @param minWordSize\n   *          only words longer than this get processed\n   * @param minSubwordSize\n   *          only subwords longer than this get to the output stream\n   * @param maxSubwordSize\n   *          only subwords shorter than this get to the output stream\n   * @param onlyLongestMatch\n   *          Add only the longest matching subword to the stream\n   */\n  public HyphenationCompoundWordTokenFilter(Version matchVersion, TokenStream input,\n      HyphenationTree hyphenator, Set<?> dictionary, int minWordSize,\n      int minSubwordSize, int maxSubwordSize, boolean onlyLongestMatch) {\n    super(matchVersion, input, dictionary, minWordSize, minSubwordSize, maxSubwordSize,\n        onlyLongestMatch);\n\n    this.hyphenator = hyphenator;\n  }\n\n","sourceOld":"  /**\n   * Creates a new {@link HyphenationCompoundWordTokenFilter} instance.\n   * \n   * @param matchVersion\n   *          Lucene version to enable correct Unicode 4.0 behavior in the\n   *          dictionaries if Version > 3.0. See <a\n   *          href=\"CompoundWordTokenFilterBase#version\"\n   *          >CompoundWordTokenFilterBase</a> for details.\n   * @param input\n   *          the {@link TokenStream} to process\n   * @param hyphenator\n   *          the hyphenation pattern tree to use for hyphenation\n   * @param dictionary\n   *          the word dictionary to match against. If this is a\n   *          {@link org.apache.lucene.analysis.CharArraySet CharArraySet} it\n   *          must have set ignoreCase=false and only contain lower case\n   *          strings.\n   * @param minWordSize\n   *          only words longer than this get processed\n   * @param minSubwordSize\n   *          only subwords longer than this get to the output stream\n   * @param maxSubwordSize\n   *          only subwords shorter than this get to the output stream\n   * @param onlyLongestMatch\n   *          Add only the longest matching subword to the stream\n   */\n  public HyphenationCompoundWordTokenFilter(Version matchVersion, TokenStream input,\n      HyphenationTree hyphenator, Set dictionary, int minWordSize,\n      int minSubwordSize, int maxSubwordSize, boolean onlyLongestMatch) {\n    super(matchVersion, input, dictionary, minWordSize, minSubwordSize, maxSubwordSize,\n        onlyLongestMatch);\n\n    this.hyphenator = hyphenator;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a9ac13b5f0ce5ef1b2ce168367d993a79594b23a":["7f6c85ffa816c86be877aa7a5029a5daa1336e7f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a9ac13b5f0ce5ef1b2ce168367d993a79594b23a"],"7f6c85ffa816c86be877aa7a5029a5daa1336e7f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["7f6c85ffa816c86be877aa7a5029a5daa1336e7f"],"a9ac13b5f0ce5ef1b2ce168367d993a79594b23a":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"7f6c85ffa816c86be877aa7a5029a5daa1336e7f":["a9ac13b5f0ce5ef1b2ce168367d993a79594b23a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}