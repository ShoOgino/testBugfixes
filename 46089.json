{"path":"lucene/core/src/test/org/apache/lucene/index/TestPayloadsOnVectors.RandomTokenStream#RandomTokenStream(int,String[],boolean).mjava","commits":[{"id":"eda61b1e90b490cc5837200e04c02639a0d272c7","date":1358795519,"type":0,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPayloadsOnVectors.RandomTokenStream#RandomTokenStream(int,String[],boolean).mjava","pathOld":"/dev/null","sourceNew":"    RandomTokenStream(int len, String[] sampleTerms, boolean weird) {\n      terms = new String[len];\n      positionsIncrements = new int[len];\n      positions = new int[len];\n      startOffsets = new int[len];\n      endOffsets = new int[len];\n      payloads = new BytesRef[len];\n      for (int i = 0; i < len; ++i) {\n        terms[i] = RandomPicks.randomFrom(random(), sampleTerms);\n        if (weird) {\n          positionsIncrements[i] = random().nextInt(1 << 18);\n          startOffsets[i] = random().nextInt();\n          endOffsets[i] = random().nextInt();\n        } else if (i == 0) {\n          positionsIncrements[i] = _TestUtil.nextInt(random(), 1, 1 << 5);\n          startOffsets[i] = _TestUtil.nextInt(random(), 0, 1 << 16);\n          endOffsets[i] = startOffsets[i] + _TestUtil.nextInt(random(), 0, rarely() ? 1 << 10 : 20);\n        } else {\n          positionsIncrements[i] = _TestUtil.nextInt(random(), 0, 1 << 5);\n          startOffsets[i] = startOffsets[i-1] + _TestUtil.nextInt(random(), 0, 1 << 16);\n          endOffsets[i] = startOffsets[i] + _TestUtil.nextInt(random(), 0, rarely() ? 1 << 10 : 20);\n        }\n      }\n      for (int i = 0; i < len; ++i) {\n        if (i == 0) {\n          positions[i] = positionsIncrements[i] - 1;\n        } else {\n          positions[i] = positions[i - 1] + positionsIncrements[i];\n        }\n      }\n      if (rarely()) {\n        Arrays.fill(payloads, randomPayload());\n      } else {\n        for (int i = 0; i < len; ++i) {\n          payloads[i] = randomPayload();\n        }\n      }\n\n      positionToTerms = new HashMap<Integer, Set<Integer>>();\n      startOffsetToTerms = new HashMap<Integer, Set<Integer>>();\n      for (int i = 0; i < len; ++i) {\n        if (!positionToTerms.containsKey(positions[i])) {\n          positionToTerms.put(positions[i], new HashSet<Integer>(1));\n        }\n        positionToTerms.get(positions[i]).add(i);\n        if (!startOffsetToTerms.containsKey(startOffsets[i])) {\n          startOffsetToTerms.put(startOffsets[i], new HashSet<Integer>(1));\n        }\n        startOffsetToTerms.get(startOffsets[i]).add(i);\n      }\n\n      addAttributeImpl(new PermissiveOffsetAttributeImpl());\n\n      termAtt = addAttribute(CharTermAttribute.class);\n      piAtt = addAttribute(PositionIncrementAttribute.class);\n      oAtt = addAttribute(OffsetAttribute.class);\n      pAtt = addAttribute(PayloadAttribute.class);\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"07155cdd910937cdf6877e48884d5782845c8b8b","date":1358796205,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPayloadsOnVectors.RandomTokenStream#RandomTokenStream(int,String[],boolean).mjava","pathOld":"/dev/null","sourceNew":"    RandomTokenStream(int len, String[] sampleTerms, boolean weird) {\n      terms = new String[len];\n      positionsIncrements = new int[len];\n      positions = new int[len];\n      startOffsets = new int[len];\n      endOffsets = new int[len];\n      payloads = new BytesRef[len];\n      for (int i = 0; i < len; ++i) {\n        terms[i] = RandomPicks.randomFrom(random(), sampleTerms);\n        if (weird) {\n          positionsIncrements[i] = random().nextInt(1 << 18);\n          startOffsets[i] = random().nextInt();\n          endOffsets[i] = random().nextInt();\n        } else if (i == 0) {\n          positionsIncrements[i] = _TestUtil.nextInt(random(), 1, 1 << 5);\n          startOffsets[i] = _TestUtil.nextInt(random(), 0, 1 << 16);\n          endOffsets[i] = startOffsets[i] + _TestUtil.nextInt(random(), 0, rarely() ? 1 << 10 : 20);\n        } else {\n          positionsIncrements[i] = _TestUtil.nextInt(random(), 0, 1 << 5);\n          startOffsets[i] = startOffsets[i-1] + _TestUtil.nextInt(random(), 0, 1 << 16);\n          endOffsets[i] = startOffsets[i] + _TestUtil.nextInt(random(), 0, rarely() ? 1 << 10 : 20);\n        }\n      }\n      for (int i = 0; i < len; ++i) {\n        if (i == 0) {\n          positions[i] = positionsIncrements[i] - 1;\n        } else {\n          positions[i] = positions[i - 1] + positionsIncrements[i];\n        }\n      }\n      if (rarely()) {\n        Arrays.fill(payloads, randomPayload());\n      } else {\n        for (int i = 0; i < len; ++i) {\n          payloads[i] = randomPayload();\n        }\n      }\n\n      positionToTerms = new HashMap<Integer, Set<Integer>>();\n      startOffsetToTerms = new HashMap<Integer, Set<Integer>>();\n      for (int i = 0; i < len; ++i) {\n        if (!positionToTerms.containsKey(positions[i])) {\n          positionToTerms.put(positions[i], new HashSet<Integer>(1));\n        }\n        positionToTerms.get(positions[i]).add(i);\n        if (!startOffsetToTerms.containsKey(startOffsets[i])) {\n          startOffsetToTerms.put(startOffsets[i], new HashSet<Integer>(1));\n        }\n        startOffsetToTerms.get(startOffsets[i]).add(i);\n      }\n\n      addAttributeImpl(new PermissiveOffsetAttributeImpl());\n\n      termAtt = addAttribute(CharTermAttribute.class);\n      piAtt = addAttribute(PositionIncrementAttribute.class);\n      oAtt = addAttribute(OffsetAttribute.class);\n      pAtt = addAttribute(PayloadAttribute.class);\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"673e721ff6403fb8d7084feb6a36b9da726fd8a9","date":1359537248,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPayloadsOnVectors.RandomTokenStream#RandomTokenStream(int,String[],boolean).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPayloadsOnVectors.RandomTokenStream#RandomTokenStream(int,String[],boolean).mjava","sourceNew":"    RandomTokenStream(int len, String[] sampleTerms, boolean weird) {\n      terms = new String[len];\n      positionsIncrements = new int[len];\n      positions = new int[len];\n      startOffsets = new int[len];\n      endOffsets = new int[len];\n      payloads = new BytesRef[len];\n      for (int i = 0; i < len; ++i) {\n        terms[i] = RandomPicks.randomFrom(random(), sampleTerms);\n        if (weird) {\n          positionsIncrements[i] = _TestUtil.nextInt(random(), 1, 1 << 18);\n          startOffsets[i] = random().nextInt();\n          endOffsets[i] = random().nextInt();\n        } else if (i == 0) {\n          positionsIncrements[i] = _TestUtil.nextInt(random(), 1, 1 << 5);\n          startOffsets[i] = _TestUtil.nextInt(random(), 0, 1 << 16);\n          endOffsets[i] = startOffsets[i] + _TestUtil.nextInt(random(), 0, rarely() ? 1 << 10 : 20);\n        } else {\n          positionsIncrements[i] = _TestUtil.nextInt(random(), 0, 1 << 5);\n          startOffsets[i] = startOffsets[i-1] + _TestUtil.nextInt(random(), 0, 1 << 16);\n          endOffsets[i] = startOffsets[i] + _TestUtil.nextInt(random(), 0, rarely() ? 1 << 10 : 20);\n        }\n      }\n      for (int i = 0; i < len; ++i) {\n        if (i == 0) {\n          positions[i] = positionsIncrements[i] - 1;\n        } else {\n          positions[i] = positions[i - 1] + positionsIncrements[i];\n        }\n      }\n      if (rarely()) {\n        Arrays.fill(payloads, randomPayload());\n      } else {\n        for (int i = 0; i < len; ++i) {\n          payloads[i] = randomPayload();\n        }\n      }\n\n      positionToTerms = new HashMap<Integer, Set<Integer>>();\n      startOffsetToTerms = new HashMap<Integer, Set<Integer>>();\n      for (int i = 0; i < len; ++i) {\n        if (!positionToTerms.containsKey(positions[i])) {\n          positionToTerms.put(positions[i], new HashSet<Integer>(1));\n        }\n        positionToTerms.get(positions[i]).add(i);\n        if (!startOffsetToTerms.containsKey(startOffsets[i])) {\n          startOffsetToTerms.put(startOffsets[i], new HashSet<Integer>(1));\n        }\n        startOffsetToTerms.get(startOffsets[i]).add(i);\n      }\n\n      addAttributeImpl(new PermissiveOffsetAttributeImpl());\n\n      termAtt = addAttribute(CharTermAttribute.class);\n      piAtt = addAttribute(PositionIncrementAttribute.class);\n      oAtt = addAttribute(OffsetAttribute.class);\n      pAtt = addAttribute(PayloadAttribute.class);\n    }\n\n","sourceOld":"    RandomTokenStream(int len, String[] sampleTerms, boolean weird) {\n      terms = new String[len];\n      positionsIncrements = new int[len];\n      positions = new int[len];\n      startOffsets = new int[len];\n      endOffsets = new int[len];\n      payloads = new BytesRef[len];\n      for (int i = 0; i < len; ++i) {\n        terms[i] = RandomPicks.randomFrom(random(), sampleTerms);\n        if (weird) {\n          positionsIncrements[i] = random().nextInt(1 << 18);\n          startOffsets[i] = random().nextInt();\n          endOffsets[i] = random().nextInt();\n        } else if (i == 0) {\n          positionsIncrements[i] = _TestUtil.nextInt(random(), 1, 1 << 5);\n          startOffsets[i] = _TestUtil.nextInt(random(), 0, 1 << 16);\n          endOffsets[i] = startOffsets[i] + _TestUtil.nextInt(random(), 0, rarely() ? 1 << 10 : 20);\n        } else {\n          positionsIncrements[i] = _TestUtil.nextInt(random(), 0, 1 << 5);\n          startOffsets[i] = startOffsets[i-1] + _TestUtil.nextInt(random(), 0, 1 << 16);\n          endOffsets[i] = startOffsets[i] + _TestUtil.nextInt(random(), 0, rarely() ? 1 << 10 : 20);\n        }\n      }\n      for (int i = 0; i < len; ++i) {\n        if (i == 0) {\n          positions[i] = positionsIncrements[i] - 1;\n        } else {\n          positions[i] = positions[i - 1] + positionsIncrements[i];\n        }\n      }\n      if (rarely()) {\n        Arrays.fill(payloads, randomPayload());\n      } else {\n        for (int i = 0; i < len; ++i) {\n          payloads[i] = randomPayload();\n        }\n      }\n\n      positionToTerms = new HashMap<Integer, Set<Integer>>();\n      startOffsetToTerms = new HashMap<Integer, Set<Integer>>();\n      for (int i = 0; i < len; ++i) {\n        if (!positionToTerms.containsKey(positions[i])) {\n          positionToTerms.put(positions[i], new HashSet<Integer>(1));\n        }\n        positionToTerms.get(positions[i]).add(i);\n        if (!startOffsetToTerms.containsKey(startOffsets[i])) {\n          startOffsetToTerms.put(startOffsets[i], new HashSet<Integer>(1));\n        }\n        startOffsetToTerms.get(startOffsets[i]).add(i);\n      }\n\n      addAttributeImpl(new PermissiveOffsetAttributeImpl());\n\n      termAtt = addAttribute(CharTermAttribute.class);\n      piAtt = addAttribute(PositionIncrementAttribute.class);\n      oAtt = addAttribute(OffsetAttribute.class);\n      pAtt = addAttribute(PayloadAttribute.class);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"61d5f95d14e5b9b046998c51e16709a398c15226","date":1359603451,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPayloadsOnVectors.RandomTokenStream#RandomTokenStream(int,String[],boolean).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPayloadsOnVectors.RandomTokenStream#RandomTokenStream(int,String[],boolean).mjava","sourceNew":"    RandomTokenStream(int len, String[] sampleTerms, boolean weird) {\n      terms = new String[len];\n      positionsIncrements = new int[len];\n      positions = new int[len];\n      startOffsets = new int[len];\n      endOffsets = new int[len];\n      payloads = new BytesRef[len];\n      for (int i = 0; i < len; ++i) {\n        terms[i] = RandomPicks.randomFrom(random(), sampleTerms);\n        if (weird) {\n          positionsIncrements[i] = _TestUtil.nextInt(random(), 1, 1 << 18);\n          startOffsets[i] = random().nextInt();\n          endOffsets[i] = random().nextInt();\n        } else if (i == 0) {\n          positionsIncrements[i] = _TestUtil.nextInt(random(), 1, 1 << 5);\n          startOffsets[i] = _TestUtil.nextInt(random(), 0, 1 << 16);\n          endOffsets[i] = startOffsets[i] + _TestUtil.nextInt(random(), 0, rarely() ? 1 << 10 : 20);\n        } else {\n          positionsIncrements[i] = _TestUtil.nextInt(random(), 0, 1 << 5);\n          startOffsets[i] = startOffsets[i-1] + _TestUtil.nextInt(random(), 0, 1 << 16);\n          endOffsets[i] = startOffsets[i] + _TestUtil.nextInt(random(), 0, rarely() ? 1 << 10 : 20);\n        }\n      }\n      for (int i = 0; i < len; ++i) {\n        if (i == 0) {\n          positions[i] = positionsIncrements[i] - 1;\n        } else {\n          positions[i] = positions[i - 1] + positionsIncrements[i];\n        }\n      }\n      if (rarely()) {\n        Arrays.fill(payloads, randomPayload());\n      } else {\n        for (int i = 0; i < len; ++i) {\n          payloads[i] = randomPayload();\n        }\n      }\n\n      positionToTerms = new HashMap<Integer, Set<Integer>>();\n      startOffsetToTerms = new HashMap<Integer, Set<Integer>>();\n      for (int i = 0; i < len; ++i) {\n        if (!positionToTerms.containsKey(positions[i])) {\n          positionToTerms.put(positions[i], new HashSet<Integer>(1));\n        }\n        positionToTerms.get(positions[i]).add(i);\n        if (!startOffsetToTerms.containsKey(startOffsets[i])) {\n          startOffsetToTerms.put(startOffsets[i], new HashSet<Integer>(1));\n        }\n        startOffsetToTerms.get(startOffsets[i]).add(i);\n      }\n\n      addAttributeImpl(new PermissiveOffsetAttributeImpl());\n\n      termAtt = addAttribute(CharTermAttribute.class);\n      piAtt = addAttribute(PositionIncrementAttribute.class);\n      oAtt = addAttribute(OffsetAttribute.class);\n      pAtt = addAttribute(PayloadAttribute.class);\n    }\n\n","sourceOld":"    RandomTokenStream(int len, String[] sampleTerms, boolean weird) {\n      terms = new String[len];\n      positionsIncrements = new int[len];\n      positions = new int[len];\n      startOffsets = new int[len];\n      endOffsets = new int[len];\n      payloads = new BytesRef[len];\n      for (int i = 0; i < len; ++i) {\n        terms[i] = RandomPicks.randomFrom(random(), sampleTerms);\n        if (weird) {\n          positionsIncrements[i] = random().nextInt(1 << 18);\n          startOffsets[i] = random().nextInt();\n          endOffsets[i] = random().nextInt();\n        } else if (i == 0) {\n          positionsIncrements[i] = _TestUtil.nextInt(random(), 1, 1 << 5);\n          startOffsets[i] = _TestUtil.nextInt(random(), 0, 1 << 16);\n          endOffsets[i] = startOffsets[i] + _TestUtil.nextInt(random(), 0, rarely() ? 1 << 10 : 20);\n        } else {\n          positionsIncrements[i] = _TestUtil.nextInt(random(), 0, 1 << 5);\n          startOffsets[i] = startOffsets[i-1] + _TestUtil.nextInt(random(), 0, 1 << 16);\n          endOffsets[i] = startOffsets[i] + _TestUtil.nextInt(random(), 0, rarely() ? 1 << 10 : 20);\n        }\n      }\n      for (int i = 0; i < len; ++i) {\n        if (i == 0) {\n          positions[i] = positionsIncrements[i] - 1;\n        } else {\n          positions[i] = positions[i - 1] + positionsIncrements[i];\n        }\n      }\n      if (rarely()) {\n        Arrays.fill(payloads, randomPayload());\n      } else {\n        for (int i = 0; i < len; ++i) {\n          payloads[i] = randomPayload();\n        }\n      }\n\n      positionToTerms = new HashMap<Integer, Set<Integer>>();\n      startOffsetToTerms = new HashMap<Integer, Set<Integer>>();\n      for (int i = 0; i < len; ++i) {\n        if (!positionToTerms.containsKey(positions[i])) {\n          positionToTerms.put(positions[i], new HashSet<Integer>(1));\n        }\n        positionToTerms.get(positions[i]).add(i);\n        if (!startOffsetToTerms.containsKey(startOffsets[i])) {\n          startOffsetToTerms.put(startOffsets[i], new HashSet<Integer>(1));\n        }\n        startOffsetToTerms.get(startOffsets[i]).add(i);\n      }\n\n      addAttributeImpl(new PermissiveOffsetAttributeImpl());\n\n      termAtt = addAttribute(CharTermAttribute.class);\n      piAtt = addAttribute(PositionIncrementAttribute.class);\n      oAtt = addAttribute(OffsetAttribute.class);\n      pAtt = addAttribute(PayloadAttribute.class);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f21ce13f410ee015e1ba14687ab4b8518ac52a11","date":1359713213,"type":5,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseTermVectorsFormatTestCase.RandomTokenStream#RandomTokenStream(int,String[],BytesRef[],boolean).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPayloadsOnVectors.RandomTokenStream#RandomTokenStream(int,String[],boolean).mjava","sourceNew":"    protected RandomTokenStream(int len, String[] sampleTerms, BytesRef[] sampleTermBytes, boolean offsetsGoBackwards) {\n      terms = new String[len];\n      termBytes = new BytesRef[len];\n      positionsIncrements = new int[len];\n      positions = new int[len];\n      startOffsets = new int[len];\n      endOffsets = new int[len];\n      payloads = new BytesRef[len];\n      for (int i = 0; i < len; ++i) {\n        final int o = random().nextInt(sampleTerms.length);\n        terms[i] = sampleTerms[o];\n        termBytes[i] = sampleTermBytes[o];\n        positionsIncrements[i] = _TestUtil.nextInt(random(), i == 0 ? 1 : 0, 10);\n        if (offsetsGoBackwards) {\n          startOffsets[i] = random().nextInt();\n          endOffsets[i] = random().nextInt();\n        } else {\n          if (i == 0) {\n            startOffsets[i] = _TestUtil.nextInt(random(), 0, 1 << 16);\n          } else {\n            startOffsets[i] = startOffsets[i-1] + _TestUtil.nextInt(random(), 0, rarely() ? 1 << 16 : 20);\n          }\n          endOffsets[i] = startOffsets[i] + _TestUtil.nextInt(random(), 0, rarely() ? 1 << 10 : 20);\n        }\n      }\n\n      for (int i = 0; i < len; ++i) {\n        if (i == 0) {\n          positions[i] = positionsIncrements[i] - 1;\n        } else {\n          positions[i] = positions[i - 1] + positionsIncrements[i];\n        }\n      }\n      if (rarely()) {\n        Arrays.fill(payloads, randomPayload());\n      } else {\n        for (int i = 0; i < len; ++i) {\n          payloads[i] = randomPayload();\n        }\n      }\n\n      positionToTerms = new HashMap<Integer, Set<Integer>>(len);\n      startOffsetToTerms = new HashMap<Integer, Set<Integer>>(len);\n      for (int i = 0; i < len; ++i) {\n        if (!positionToTerms.containsKey(positions[i])) {\n          positionToTerms.put(positions[i], new HashSet<Integer>(1));\n        }\n        positionToTerms.get(positions[i]).add(i);\n        if (!startOffsetToTerms.containsKey(startOffsets[i])) {\n          startOffsetToTerms.put(startOffsets[i], new HashSet<Integer>(1));\n        }\n        startOffsetToTerms.get(startOffsets[i]).add(i);\n      }\n\n      freqs = new HashMap<String, Integer>();\n      for (String term : terms) {\n        if (freqs.containsKey(term)) {\n          freqs.put(term, freqs.get(term) + 1);\n        } else {\n          freqs.put(term, 1);\n        }\n      }\n\n      addAttributeImpl(new PermissiveOffsetAttributeImpl());\n\n      termAtt = addAttribute(CharTermAttribute.class);\n      piAtt = addAttribute(PositionIncrementAttribute.class);\n      oAtt = addAttribute(OffsetAttribute.class);\n      pAtt = addAttribute(PayloadAttribute.class);\n    }\n\n","sourceOld":"    RandomTokenStream(int len, String[] sampleTerms, boolean weird) {\n      terms = new String[len];\n      positionsIncrements = new int[len];\n      positions = new int[len];\n      startOffsets = new int[len];\n      endOffsets = new int[len];\n      payloads = new BytesRef[len];\n      for (int i = 0; i < len; ++i) {\n        terms[i] = RandomPicks.randomFrom(random(), sampleTerms);\n        if (weird) {\n          positionsIncrements[i] = _TestUtil.nextInt(random(), 1, 1 << 18);\n          startOffsets[i] = random().nextInt();\n          endOffsets[i] = random().nextInt();\n        } else if (i == 0) {\n          positionsIncrements[i] = _TestUtil.nextInt(random(), 1, 1 << 5);\n          startOffsets[i] = _TestUtil.nextInt(random(), 0, 1 << 16);\n          endOffsets[i] = startOffsets[i] + _TestUtil.nextInt(random(), 0, rarely() ? 1 << 10 : 20);\n        } else {\n          positionsIncrements[i] = _TestUtil.nextInt(random(), 0, 1 << 5);\n          startOffsets[i] = startOffsets[i-1] + _TestUtil.nextInt(random(), 0, 1 << 16);\n          endOffsets[i] = startOffsets[i] + _TestUtil.nextInt(random(), 0, rarely() ? 1 << 10 : 20);\n        }\n      }\n      for (int i = 0; i < len; ++i) {\n        if (i == 0) {\n          positions[i] = positionsIncrements[i] - 1;\n        } else {\n          positions[i] = positions[i - 1] + positionsIncrements[i];\n        }\n      }\n      if (rarely()) {\n        Arrays.fill(payloads, randomPayload());\n      } else {\n        for (int i = 0; i < len; ++i) {\n          payloads[i] = randomPayload();\n        }\n      }\n\n      positionToTerms = new HashMap<Integer, Set<Integer>>();\n      startOffsetToTerms = new HashMap<Integer, Set<Integer>>();\n      for (int i = 0; i < len; ++i) {\n        if (!positionToTerms.containsKey(positions[i])) {\n          positionToTerms.put(positions[i], new HashSet<Integer>(1));\n        }\n        positionToTerms.get(positions[i]).add(i);\n        if (!startOffsetToTerms.containsKey(startOffsets[i])) {\n          startOffsetToTerms.put(startOffsets[i], new HashSet<Integer>(1));\n        }\n        startOffsetToTerms.get(startOffsets[i]).add(i);\n      }\n\n      addAttributeImpl(new PermissiveOffsetAttributeImpl());\n\n      termAtt = addAttribute(CharTermAttribute.class);\n      piAtt = addAttribute(PositionIncrementAttribute.class);\n      oAtt = addAttribute(OffsetAttribute.class);\n      pAtt = addAttribute(PayloadAttribute.class);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0fa6955ed1b1007ded1349ab72cea4555640432f","date":1359721908,"type":5,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseTermVectorsFormatTestCase.RandomTokenStream#RandomTokenStream(int,String[],BytesRef[],boolean).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPayloadsOnVectors.RandomTokenStream#RandomTokenStream(int,String[],boolean).mjava","sourceNew":"    protected RandomTokenStream(int len, String[] sampleTerms, BytesRef[] sampleTermBytes, boolean offsetsGoBackwards) {\n      terms = new String[len];\n      termBytes = new BytesRef[len];\n      positionsIncrements = new int[len];\n      positions = new int[len];\n      startOffsets = new int[len];\n      endOffsets = new int[len];\n      payloads = new BytesRef[len];\n      for (int i = 0; i < len; ++i) {\n        final int o = random().nextInt(sampleTerms.length);\n        terms[i] = sampleTerms[o];\n        termBytes[i] = sampleTermBytes[o];\n        positionsIncrements[i] = _TestUtil.nextInt(random(), i == 0 ? 1 : 0, 10);\n        if (offsetsGoBackwards) {\n          startOffsets[i] = random().nextInt();\n          endOffsets[i] = random().nextInt();\n        } else {\n          if (i == 0) {\n            startOffsets[i] = _TestUtil.nextInt(random(), 0, 1 << 16);\n          } else {\n            startOffsets[i] = startOffsets[i-1] + _TestUtil.nextInt(random(), 0, rarely() ? 1 << 16 : 20);\n          }\n          endOffsets[i] = startOffsets[i] + _TestUtil.nextInt(random(), 0, rarely() ? 1 << 10 : 20);\n        }\n      }\n\n      for (int i = 0; i < len; ++i) {\n        if (i == 0) {\n          positions[i] = positionsIncrements[i] - 1;\n        } else {\n          positions[i] = positions[i - 1] + positionsIncrements[i];\n        }\n      }\n      if (rarely()) {\n        Arrays.fill(payloads, randomPayload());\n      } else {\n        for (int i = 0; i < len; ++i) {\n          payloads[i] = randomPayload();\n        }\n      }\n\n      positionToTerms = new HashMap<Integer, Set<Integer>>(len);\n      startOffsetToTerms = new HashMap<Integer, Set<Integer>>(len);\n      for (int i = 0; i < len; ++i) {\n        if (!positionToTerms.containsKey(positions[i])) {\n          positionToTerms.put(positions[i], new HashSet<Integer>(1));\n        }\n        positionToTerms.get(positions[i]).add(i);\n        if (!startOffsetToTerms.containsKey(startOffsets[i])) {\n          startOffsetToTerms.put(startOffsets[i], new HashSet<Integer>(1));\n        }\n        startOffsetToTerms.get(startOffsets[i]).add(i);\n      }\n\n      freqs = new HashMap<String, Integer>();\n      for (String term : terms) {\n        if (freqs.containsKey(term)) {\n          freqs.put(term, freqs.get(term) + 1);\n        } else {\n          freqs.put(term, 1);\n        }\n      }\n\n      addAttributeImpl(new PermissiveOffsetAttributeImpl());\n\n      termAtt = addAttribute(CharTermAttribute.class);\n      piAtt = addAttribute(PositionIncrementAttribute.class);\n      oAtt = addAttribute(OffsetAttribute.class);\n      pAtt = addAttribute(PayloadAttribute.class);\n    }\n\n","sourceOld":"    RandomTokenStream(int len, String[] sampleTerms, boolean weird) {\n      terms = new String[len];\n      positionsIncrements = new int[len];\n      positions = new int[len];\n      startOffsets = new int[len];\n      endOffsets = new int[len];\n      payloads = new BytesRef[len];\n      for (int i = 0; i < len; ++i) {\n        terms[i] = RandomPicks.randomFrom(random(), sampleTerms);\n        if (weird) {\n          positionsIncrements[i] = _TestUtil.nextInt(random(), 1, 1 << 18);\n          startOffsets[i] = random().nextInt();\n          endOffsets[i] = random().nextInt();\n        } else if (i == 0) {\n          positionsIncrements[i] = _TestUtil.nextInt(random(), 1, 1 << 5);\n          startOffsets[i] = _TestUtil.nextInt(random(), 0, 1 << 16);\n          endOffsets[i] = startOffsets[i] + _TestUtil.nextInt(random(), 0, rarely() ? 1 << 10 : 20);\n        } else {\n          positionsIncrements[i] = _TestUtil.nextInt(random(), 0, 1 << 5);\n          startOffsets[i] = startOffsets[i-1] + _TestUtil.nextInt(random(), 0, 1 << 16);\n          endOffsets[i] = startOffsets[i] + _TestUtil.nextInt(random(), 0, rarely() ? 1 << 10 : 20);\n        }\n      }\n      for (int i = 0; i < len; ++i) {\n        if (i == 0) {\n          positions[i] = positionsIncrements[i] - 1;\n        } else {\n          positions[i] = positions[i - 1] + positionsIncrements[i];\n        }\n      }\n      if (rarely()) {\n        Arrays.fill(payloads, randomPayload());\n      } else {\n        for (int i = 0; i < len; ++i) {\n          payloads[i] = randomPayload();\n        }\n      }\n\n      positionToTerms = new HashMap<Integer, Set<Integer>>();\n      startOffsetToTerms = new HashMap<Integer, Set<Integer>>();\n      for (int i = 0; i < len; ++i) {\n        if (!positionToTerms.containsKey(positions[i])) {\n          positionToTerms.put(positions[i], new HashSet<Integer>(1));\n        }\n        positionToTerms.get(positions[i]).add(i);\n        if (!startOffsetToTerms.containsKey(startOffsets[i])) {\n          startOffsetToTerms.put(startOffsets[i], new HashSet<Integer>(1));\n        }\n        startOffsetToTerms.get(startOffsets[i]).add(i);\n      }\n\n      addAttributeImpl(new PermissiveOffsetAttributeImpl());\n\n      termAtt = addAttribute(CharTermAttribute.class);\n      piAtt = addAttribute(PositionIncrementAttribute.class);\n      oAtt = addAttribute(OffsetAttribute.class);\n      pAtt = addAttribute(PayloadAttribute.class);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"0fa6955ed1b1007ded1349ab72cea4555640432f":["61d5f95d14e5b9b046998c51e16709a398c15226","f21ce13f410ee015e1ba14687ab4b8518ac52a11"],"61d5f95d14e5b9b046998c51e16709a398c15226":["07155cdd910937cdf6877e48884d5782845c8b8b","673e721ff6403fb8d7084feb6a36b9da726fd8a9"],"eda61b1e90b490cc5837200e04c02639a0d272c7":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"673e721ff6403fb8d7084feb6a36b9da726fd8a9":["eda61b1e90b490cc5837200e04c02639a0d272c7"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"f21ce13f410ee015e1ba14687ab4b8518ac52a11":["673e721ff6403fb8d7084feb6a36b9da726fd8a9"],"07155cdd910937cdf6877e48884d5782845c8b8b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","eda61b1e90b490cc5837200e04c02639a0d272c7"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["f21ce13f410ee015e1ba14687ab4b8518ac52a11"]},"commit2Childs":{"0fa6955ed1b1007ded1349ab72cea4555640432f":[],"61d5f95d14e5b9b046998c51e16709a398c15226":["0fa6955ed1b1007ded1349ab72cea4555640432f"],"eda61b1e90b490cc5837200e04c02639a0d272c7":["673e721ff6403fb8d7084feb6a36b9da726fd8a9","07155cdd910937cdf6877e48884d5782845c8b8b"],"673e721ff6403fb8d7084feb6a36b9da726fd8a9":["61d5f95d14e5b9b046998c51e16709a398c15226","f21ce13f410ee015e1ba14687ab4b8518ac52a11"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["eda61b1e90b490cc5837200e04c02639a0d272c7","07155cdd910937cdf6877e48884d5782845c8b8b"],"f21ce13f410ee015e1ba14687ab4b8518ac52a11":["0fa6955ed1b1007ded1349ab72cea4555640432f","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"07155cdd910937cdf6877e48884d5782845c8b8b":["61d5f95d14e5b9b046998c51e16709a398c15226"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["0fa6955ed1b1007ded1349ab72cea4555640432f","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}