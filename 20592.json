{"path":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50CompoundFormat#write(Directory,SegmentInfo,IOContext).mjava","commits":[{"id":"75d243fa001c0783996918dbbe60b55cbaeeff46","date":1422502815,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50CompoundFormat#write(Directory,SegmentInfo,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50CompoundFormat#write(Directory,SegmentInfo,Collection[String],IOContext).mjava","sourceNew":"  @Override\n  public void write(Directory dir, SegmentInfo si, IOContext context) throws IOException {\n    String dataFile = IndexFileNames.segmentFileName(si.name, \"\", DATA_EXTENSION);\n    String entriesFile = IndexFileNames.segmentFileName(si.name, \"\", ENTRIES_EXTENSION);\n    \n    try (IndexOutput data =    dir.createOutput(dataFile, context);\n         IndexOutput entries = dir.createOutput(entriesFile, context)) {\n      CodecUtil.writeIndexHeader(data,    DATA_CODEC, VERSION_CURRENT, si.getId(), \"\");\n      CodecUtil.writeIndexHeader(entries, ENTRY_CODEC, VERSION_CURRENT, si.getId(), \"\");\n      \n      // write number of files\n      entries.writeVInt(si.files().size());\n      for (String file : si.files()) {\n        \n        // write bytes for file\n        long startOffset = data.getFilePointer();\n        try (IndexInput in = dir.openInput(file, IOContext.READONCE)) {\n          data.copyBytes(in, in.length());\n        }\n        long endOffset = data.getFilePointer();\n        \n        long length = endOffset - startOffset;\n        \n        // write entry for file\n        entries.writeString(IndexFileNames.stripSegmentName(file));\n        entries.writeLong(startOffset);\n        entries.writeLong(length);\n      }\n      \n      CodecUtil.writeFooter(data);\n      CodecUtil.writeFooter(entries);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void write(Directory dir, SegmentInfo si, Collection<String> files, IOContext context) throws IOException {\n    String dataFile = IndexFileNames.segmentFileName(si.name, \"\", DATA_EXTENSION);\n    String entriesFile = IndexFileNames.segmentFileName(si.name, \"\", ENTRIES_EXTENSION);\n    \n    try (IndexOutput data =    dir.createOutput(dataFile, context);\n         IndexOutput entries = dir.createOutput(entriesFile, context)) {\n      CodecUtil.writeIndexHeader(data,    DATA_CODEC, VERSION_CURRENT, si.getId(), \"\");\n      CodecUtil.writeIndexHeader(entries, ENTRY_CODEC, VERSION_CURRENT, si.getId(), \"\");\n      \n      // write number of files\n      entries.writeVInt(files.size());\n      for (String file : files) {\n        \n        // write bytes for file\n        long startOffset = data.getFilePointer();\n        try (IndexInput in = dir.openInput(file, IOContext.READONCE)) {\n          data.copyBytes(in, in.length());\n        }\n        long endOffset = data.getFilePointer();\n        \n        long length = endOffset - startOffset;\n        \n        // write entry for file\n        entries.writeString(IndexFileNames.stripSegmentName(file));\n        entries.writeLong(startOffset);\n        entries.writeLong(length);\n      }\n      \n      CodecUtil.writeFooter(data);\n      CodecUtil.writeFooter(entries);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"71488d7f5786ae87541276121ecb69705a11a295","date":1465498138,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50CompoundFormat#write(Directory,SegmentInfo,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50CompoundFormat#write(Directory,SegmentInfo,IOContext).mjava","sourceNew":"  @Override\n  public void write(Directory dir, SegmentInfo si, IOContext context) throws IOException {\n    String dataFile = IndexFileNames.segmentFileName(si.name, \"\", DATA_EXTENSION);\n    String entriesFile = IndexFileNames.segmentFileName(si.name, \"\", ENTRIES_EXTENSION);\n    \n    byte[] expectedID = si.getId();\n    byte[] id = new byte[StringHelper.ID_LENGTH];\n\n    try (IndexOutput data =    dir.createOutput(dataFile, context);\n         IndexOutput entries = dir.createOutput(entriesFile, context)) {\n      CodecUtil.writeIndexHeader(data,    DATA_CODEC, VERSION_CURRENT, si.getId(), \"\");\n      CodecUtil.writeIndexHeader(entries, ENTRY_CODEC, VERSION_CURRENT, si.getId(), \"\");\n      \n      // write number of files\n      entries.writeVInt(si.files().size());\n      for (String file : si.files()) {\n        \n        // write bytes for file\n        long startOffset = data.getFilePointer();\n        try (ChecksumIndexInput in = dir.openChecksumInput(file, IOContext.READONCE)) {\n\n          // just copies the index header, verifying that its id matches what we expect\n          CodecUtil.verifyAndCopyIndexHeader(in, data, si.getId());\n          \n          // copy all bytes except the footer\n          long numBytesToCopy = in.length() - CodecUtil.footerLength() - in.getFilePointer();\n          data.copyBytes(in, numBytesToCopy);\n\n          // verify footer (checksum) matches for the incoming file we are copying\n          long checksum = CodecUtil.checkFooter(in);\n\n          // this is poached from CodecUtil.writeFooter, but we need to use our own checksum, not data.getChecksum(), but I think\n          // adding a public method to CodecUtil to do that is somewhat dangerous:\n          data.writeInt(CodecUtil.FOOTER_MAGIC);\n          data.writeInt(0);\n          data.writeLong(checksum);\n        }\n        long endOffset = data.getFilePointer();\n        \n        long length = endOffset - startOffset;\n        \n        // write entry for file\n        entries.writeString(IndexFileNames.stripSegmentName(file));\n        entries.writeLong(startOffset);\n        entries.writeLong(length);\n      }\n      \n      CodecUtil.writeFooter(data);\n      CodecUtil.writeFooter(entries);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void write(Directory dir, SegmentInfo si, IOContext context) throws IOException {\n    String dataFile = IndexFileNames.segmentFileName(si.name, \"\", DATA_EXTENSION);\n    String entriesFile = IndexFileNames.segmentFileName(si.name, \"\", ENTRIES_EXTENSION);\n    \n    try (IndexOutput data =    dir.createOutput(dataFile, context);\n         IndexOutput entries = dir.createOutput(entriesFile, context)) {\n      CodecUtil.writeIndexHeader(data,    DATA_CODEC, VERSION_CURRENT, si.getId(), \"\");\n      CodecUtil.writeIndexHeader(entries, ENTRY_CODEC, VERSION_CURRENT, si.getId(), \"\");\n      \n      // write number of files\n      entries.writeVInt(si.files().size());\n      for (String file : si.files()) {\n        \n        // write bytes for file\n        long startOffset = data.getFilePointer();\n        try (IndexInput in = dir.openInput(file, IOContext.READONCE)) {\n          data.copyBytes(in, in.length());\n        }\n        long endOffset = data.getFilePointer();\n        \n        long length = endOffset - startOffset;\n        \n        // write entry for file\n        entries.writeString(IndexFileNames.stripSegmentName(file));\n        entries.writeLong(startOffset);\n        entries.writeLong(length);\n      }\n      \n      CodecUtil.writeFooter(data);\n      CodecUtil.writeFooter(entries);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50CompoundFormat#write(Directory,SegmentInfo,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50CompoundFormat#write(Directory,SegmentInfo,IOContext).mjava","sourceNew":"  @Override\n  public void write(Directory dir, SegmentInfo si, IOContext context) throws IOException {\n    String dataFile = IndexFileNames.segmentFileName(si.name, \"\", DATA_EXTENSION);\n    String entriesFile = IndexFileNames.segmentFileName(si.name, \"\", ENTRIES_EXTENSION);\n    \n    byte[] expectedID = si.getId();\n    byte[] id = new byte[StringHelper.ID_LENGTH];\n\n    try (IndexOutput data =    dir.createOutput(dataFile, context);\n         IndexOutput entries = dir.createOutput(entriesFile, context)) {\n      CodecUtil.writeIndexHeader(data,    DATA_CODEC, VERSION_CURRENT, si.getId(), \"\");\n      CodecUtil.writeIndexHeader(entries, ENTRY_CODEC, VERSION_CURRENT, si.getId(), \"\");\n      \n      // write number of files\n      entries.writeVInt(si.files().size());\n      for (String file : si.files()) {\n        \n        // write bytes for file\n        long startOffset = data.getFilePointer();\n        try (ChecksumIndexInput in = dir.openChecksumInput(file, IOContext.READONCE)) {\n\n          // just copies the index header, verifying that its id matches what we expect\n          CodecUtil.verifyAndCopyIndexHeader(in, data, si.getId());\n          \n          // copy all bytes except the footer\n          long numBytesToCopy = in.length() - CodecUtil.footerLength() - in.getFilePointer();\n          data.copyBytes(in, numBytesToCopy);\n\n          // verify footer (checksum) matches for the incoming file we are copying\n          long checksum = CodecUtil.checkFooter(in);\n\n          // this is poached from CodecUtil.writeFooter, but we need to use our own checksum, not data.getChecksum(), but I think\n          // adding a public method to CodecUtil to do that is somewhat dangerous:\n          data.writeInt(CodecUtil.FOOTER_MAGIC);\n          data.writeInt(0);\n          data.writeLong(checksum);\n        }\n        long endOffset = data.getFilePointer();\n        \n        long length = endOffset - startOffset;\n        \n        // write entry for file\n        entries.writeString(IndexFileNames.stripSegmentName(file));\n        entries.writeLong(startOffset);\n        entries.writeLong(length);\n      }\n      \n      CodecUtil.writeFooter(data);\n      CodecUtil.writeFooter(entries);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void write(Directory dir, SegmentInfo si, IOContext context) throws IOException {\n    String dataFile = IndexFileNames.segmentFileName(si.name, \"\", DATA_EXTENSION);\n    String entriesFile = IndexFileNames.segmentFileName(si.name, \"\", ENTRIES_EXTENSION);\n    \n    try (IndexOutput data =    dir.createOutput(dataFile, context);\n         IndexOutput entries = dir.createOutput(entriesFile, context)) {\n      CodecUtil.writeIndexHeader(data,    DATA_CODEC, VERSION_CURRENT, si.getId(), \"\");\n      CodecUtil.writeIndexHeader(entries, ENTRY_CODEC, VERSION_CURRENT, si.getId(), \"\");\n      \n      // write number of files\n      entries.writeVInt(si.files().size());\n      for (String file : si.files()) {\n        \n        // write bytes for file\n        long startOffset = data.getFilePointer();\n        try (IndexInput in = dir.openInput(file, IOContext.READONCE)) {\n          data.copyBytes(in, in.length());\n        }\n        long endOffset = data.getFilePointer();\n        \n        long length = endOffset - startOffset;\n        \n        // write entry for file\n        entries.writeString(IndexFileNames.stripSegmentName(file));\n        entries.writeLong(startOffset);\n        entries.writeLong(length);\n      }\n      \n      CodecUtil.writeFooter(data);\n      CodecUtil.writeFooter(entries);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9855fd6c49ab7c547385413b41952c980baa5f19","date":1523892439,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50CompoundFormat#write(Directory,SegmentInfo,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50CompoundFormat#write(Directory,SegmentInfo,IOContext).mjava","sourceNew":"  @Override\n  public void write(Directory dir, SegmentInfo si, IOContext context) throws IOException {\n    String dataFile = IndexFileNames.segmentFileName(si.name, \"\", DATA_EXTENSION);\n    String entriesFile = IndexFileNames.segmentFileName(si.name, \"\", ENTRIES_EXTENSION);\n\n    try (IndexOutput data =    dir.createOutput(dataFile, context);\n         IndexOutput entries = dir.createOutput(entriesFile, context)) {\n      CodecUtil.writeIndexHeader(data,    DATA_CODEC, VERSION_CURRENT, si.getId(), \"\");\n      CodecUtil.writeIndexHeader(entries, ENTRY_CODEC, VERSION_CURRENT, si.getId(), \"\");\n      \n      // write number of files\n      entries.writeVInt(si.files().size());\n      for (String file : si.files()) {\n        \n        // write bytes for file\n        long startOffset = data.getFilePointer();\n        try (ChecksumIndexInput in = dir.openChecksumInput(file, IOContext.READONCE)) {\n\n          // just copies the index header, verifying that its id matches what we expect\n          CodecUtil.verifyAndCopyIndexHeader(in, data, si.getId());\n          \n          // copy all bytes except the footer\n          long numBytesToCopy = in.length() - CodecUtil.footerLength() - in.getFilePointer();\n          data.copyBytes(in, numBytesToCopy);\n\n          // verify footer (checksum) matches for the incoming file we are copying\n          long checksum = CodecUtil.checkFooter(in);\n\n          // this is poached from CodecUtil.writeFooter, but we need to use our own checksum, not data.getChecksum(), but I think\n          // adding a public method to CodecUtil to do that is somewhat dangerous:\n          data.writeInt(CodecUtil.FOOTER_MAGIC);\n          data.writeInt(0);\n          data.writeLong(checksum);\n        }\n        long endOffset = data.getFilePointer();\n        \n        long length = endOffset - startOffset;\n        \n        // write entry for file\n        entries.writeString(IndexFileNames.stripSegmentName(file));\n        entries.writeLong(startOffset);\n        entries.writeLong(length);\n      }\n      \n      CodecUtil.writeFooter(data);\n      CodecUtil.writeFooter(entries);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void write(Directory dir, SegmentInfo si, IOContext context) throws IOException {\n    String dataFile = IndexFileNames.segmentFileName(si.name, \"\", DATA_EXTENSION);\n    String entriesFile = IndexFileNames.segmentFileName(si.name, \"\", ENTRIES_EXTENSION);\n    \n    byte[] expectedID = si.getId();\n    byte[] id = new byte[StringHelper.ID_LENGTH];\n\n    try (IndexOutput data =    dir.createOutput(dataFile, context);\n         IndexOutput entries = dir.createOutput(entriesFile, context)) {\n      CodecUtil.writeIndexHeader(data,    DATA_CODEC, VERSION_CURRENT, si.getId(), \"\");\n      CodecUtil.writeIndexHeader(entries, ENTRY_CODEC, VERSION_CURRENT, si.getId(), \"\");\n      \n      // write number of files\n      entries.writeVInt(si.files().size());\n      for (String file : si.files()) {\n        \n        // write bytes for file\n        long startOffset = data.getFilePointer();\n        try (ChecksumIndexInput in = dir.openChecksumInput(file, IOContext.READONCE)) {\n\n          // just copies the index header, verifying that its id matches what we expect\n          CodecUtil.verifyAndCopyIndexHeader(in, data, si.getId());\n          \n          // copy all bytes except the footer\n          long numBytesToCopy = in.length() - CodecUtil.footerLength() - in.getFilePointer();\n          data.copyBytes(in, numBytesToCopy);\n\n          // verify footer (checksum) matches for the incoming file we are copying\n          long checksum = CodecUtil.checkFooter(in);\n\n          // this is poached from CodecUtil.writeFooter, but we need to use our own checksum, not data.getChecksum(), but I think\n          // adding a public method to CodecUtil to do that is somewhat dangerous:\n          data.writeInt(CodecUtil.FOOTER_MAGIC);\n          data.writeInt(0);\n          data.writeLong(checksum);\n        }\n        long endOffset = data.getFilePointer();\n        \n        long length = endOffset - startOffset;\n        \n        // write entry for file\n        entries.writeString(IndexFileNames.stripSegmentName(file));\n        entries.writeLong(startOffset);\n        entries.writeLong(length);\n      }\n      \n      CodecUtil.writeFooter(data);\n      CodecUtil.writeFooter(entries);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"71488d7f5786ae87541276121ecb69705a11a295":["75d243fa001c0783996918dbbe60b55cbaeeff46"],"75d243fa001c0783996918dbbe60b55cbaeeff46":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"9855fd6c49ab7c547385413b41952c980baa5f19":["71488d7f5786ae87541276121ecb69705a11a295"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["75d243fa001c0783996918dbbe60b55cbaeeff46","71488d7f5786ae87541276121ecb69705a11a295"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9855fd6c49ab7c547385413b41952c980baa5f19"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["75d243fa001c0783996918dbbe60b55cbaeeff46"],"71488d7f5786ae87541276121ecb69705a11a295":["9855fd6c49ab7c547385413b41952c980baa5f19","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"75d243fa001c0783996918dbbe60b55cbaeeff46":["71488d7f5786ae87541276121ecb69705a11a295","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"9855fd6c49ab7c547385413b41952c980baa5f19":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}