{"path":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentMerger,SegmentReader).mjava","commits":[{"id":"44fcbde6fb2ac44ee3b45e013e54a42911e689ff","date":1292065621,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentMerger,SegmentReader).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentMerger,int,SegmentReader).mjava","sourceNew":"  /* FIXME if we want to support non-contiguous segment merges */\n  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentMerger merger, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    final int start = ensureContiguousMerge(merge);\n\n    commitMergedDeletes(merge, mergedReader);\n      \n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n    setMergeDocStoreIsCompoundFile(merge);\n\n    merge.info.setHasProx(merger.hasProx());\n\n    segmentInfos.subList(start, start + merge.segments.size()).clear();\n    assert !segmentInfos.contains(merge.info);\n    segmentInfos.add(start, merge.info);\n    \n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n    \n    // remove pending deletes of the segments \n    // that were merged, moving them onto the segment just\n    // before the merged segment\n    // Lock order: IW -> BD\n    bufferedDeletes.commitMerge(merge);\n\n    if (merge.optimize) {\n      // cascade the optimize:\n      segmentsToOptimize.add(merge.info);\n    }\n    return true;\n  }\n\n","sourceOld":"  /* FIXME if we want to support non-contiguous segment merges */\n  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentMerger merger, int mergedDocCount, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    final int start = ensureContiguousMerge(merge);\n\n    commitMergedDeletes(merge, mergedReader);\n    docWriter.remapDeletes(segmentInfos, merger.getDocMaps(), merger.getDelCounts(), merge, mergedDocCount);\n      \n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n    setMergeDocStoreIsCompoundFile(merge);\n\n    merge.info.setHasProx(merger.hasProx());\n\n    segmentInfos.subList(start, start + merge.segments.size()).clear();\n    assert !segmentInfos.contains(merge.info);\n    segmentInfos.add(start, merge.info);\n\n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n\n    if (merge.optimize) {\n      // cascade the optimize:\n      segmentsToOptimize.add(merge.info);\n    }\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e06c9d5fba0a2f937941d199d64ccb32aac502d1","date":1292411167,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentMerger,SegmentReader).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentMerger,SegmentReader).mjava","sourceNew":"  /* FIXME if we want to support non-contiguous segment merges */\n  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentMerger merger, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    final int start = ensureContiguousMerge(merge);\n\n    commitMergedDeletes(merge, mergedReader);\n      \n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n    setMergeDocStoreIsCompoundFile(merge);\n\n    merge.info.setHasProx(merger.fieldInfos().hasProx());\n\n    segmentInfos.subList(start, start + merge.segments.size()).clear();\n    assert !segmentInfos.contains(merge.info);\n    segmentInfos.add(start, merge.info);\n    \n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n    \n    // remove pending deletes of the segments \n    // that were merged, moving them onto the segment just\n    // before the merged segment\n    // Lock order: IW -> BD\n    bufferedDeletes.commitMerge(merge);\n\n    if (merge.optimize) {\n      // cascade the optimize:\n      segmentsToOptimize.add(merge.info);\n    }\n    return true;\n  }\n\n","sourceOld":"  /* FIXME if we want to support non-contiguous segment merges */\n  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentMerger merger, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    final int start = ensureContiguousMerge(merge);\n\n    commitMergedDeletes(merge, mergedReader);\n      \n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n    setMergeDocStoreIsCompoundFile(merge);\n\n    merge.info.setHasProx(merger.hasProx());\n\n    segmentInfos.subList(start, start + merge.segments.size()).clear();\n    assert !segmentInfos.contains(merge.info);\n    segmentInfos.add(start, merge.info);\n    \n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n    \n    // remove pending deletes of the segments \n    // that were merged, moving them onto the segment just\n    // before the merged segment\n    // Lock order: IW -> BD\n    bufferedDeletes.commitMerge(merge);\n\n    if (merge.optimize) {\n      // cascade the optimize:\n      segmentsToOptimize.add(merge.info);\n    }\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"30ca900054c38836c7c167379e300af4dabb34c3","date":1292602599,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentMerger,SegmentReader).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentMerger,SegmentReader).mjava","sourceNew":"  /* FIXME if we want to support non-contiguous segment merges */\n  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentMerger merger, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    final int start = ensureContiguousMerge(merge);\n\n    commitMergedDeletes(merge, mergedReader);\n      \n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n    setMergeDocStoreIsCompoundFile(merge);\n\n    segmentInfos.subList(start, start + merge.segments.size()).clear();\n    assert !segmentInfos.contains(merge.info);\n    segmentInfos.add(start, merge.info);\n    \n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n    \n    // remove pending deletes of the segments \n    // that were merged, moving them onto the segment just\n    // before the merged segment\n    // Lock order: IW -> BD\n    bufferedDeletes.commitMerge(merge);\n\n    if (merge.optimize) {\n      // cascade the optimize:\n      segmentsToOptimize.add(merge.info);\n    }\n    return true;\n  }\n\n","sourceOld":"  /* FIXME if we want to support non-contiguous segment merges */\n  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentMerger merger, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    final int start = ensureContiguousMerge(merge);\n\n    commitMergedDeletes(merge, mergedReader);\n      \n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n    setMergeDocStoreIsCompoundFile(merge);\n\n    merge.info.setHasProx(merger.fieldInfos().hasProx());\n\n    segmentInfos.subList(start, start + merge.segments.size()).clear();\n    assert !segmentInfos.contains(merge.info);\n    segmentInfos.add(start, merge.info);\n    \n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n    \n    // remove pending deletes of the segments \n    // that were merged, moving them onto the segment just\n    // before the merged segment\n    // Lock order: IW -> BD\n    bufferedDeletes.commitMerge(merge);\n\n    if (merge.optimize) {\n      // cascade the optimize:\n      segmentsToOptimize.add(merge.info);\n    }\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4948bc5d29211f0c9b5ccc31b2632cdd27066ea5","date":1292695408,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentMerger,SegmentReader).mjava","sourceNew":"  /* FIXME if we want to support non-contiguous segment merges */\n  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    final int start = ensureContiguousMerge(merge);\n\n    commitMergedDeletes(merge, mergedReader);\n      \n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n    setMergeDocStoreIsCompoundFile(merge);\n\n    segmentInfos.subList(start, start + merge.segments.size()).clear();\n    assert !segmentInfos.contains(merge.info);\n    segmentInfos.add(start, merge.info);\n    \n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n    \n    // remove pending deletes of the segments \n    // that were merged, moving them onto the segment just\n    // before the merged segment\n    // Lock order: IW -> BD\n    bufferedDeletes.commitMerge(merge);\n\n    if (merge.optimize) {\n      // cascade the optimize:\n      segmentsToOptimize.add(merge.info);\n    }\n    return true;\n  }\n\n","sourceOld":"  /* FIXME if we want to support non-contiguous segment merges */\n  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentMerger merger, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    final int start = ensureContiguousMerge(merge);\n\n    commitMergedDeletes(merge, mergedReader);\n      \n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n    setMergeDocStoreIsCompoundFile(merge);\n\n    segmentInfos.subList(start, start + merge.segments.size()).clear();\n    assert !segmentInfos.contains(merge.info);\n    segmentInfos.add(start, merge.info);\n    \n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n    \n    // remove pending deletes of the segments \n    // that were merged, moving them onto the segment just\n    // before the merged segment\n    // Lock order: IW -> BD\n    bufferedDeletes.commitMerge(merge);\n\n    if (merge.optimize) {\n      // cascade the optimize:\n      segmentsToOptimize.add(merge.info);\n    }\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"e06c9d5fba0a2f937941d199d64ccb32aac502d1":["44fcbde6fb2ac44ee3b45e013e54a42911e689ff"],"44fcbde6fb2ac44ee3b45e013e54a42911e689ff":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"30ca900054c38836c7c167379e300af4dabb34c3":["e06c9d5fba0a2f937941d199d64ccb32aac502d1"],"4948bc5d29211f0c9b5ccc31b2632cdd27066ea5":["30ca900054c38836c7c167379e300af4dabb34c3"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["4948bc5d29211f0c9b5ccc31b2632cdd27066ea5"]},"commit2Childs":{"e06c9d5fba0a2f937941d199d64ccb32aac502d1":["30ca900054c38836c7c167379e300af4dabb34c3"],"44fcbde6fb2ac44ee3b45e013e54a42911e689ff":["e06c9d5fba0a2f937941d199d64ccb32aac502d1"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["44fcbde6fb2ac44ee3b45e013e54a42911e689ff"],"30ca900054c38836c7c167379e300af4dabb34c3":["4948bc5d29211f0c9b5ccc31b2632cdd27066ea5"],"4948bc5d29211f0c9b5ccc31b2632cdd27066ea5":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}