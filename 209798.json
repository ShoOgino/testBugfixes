{"path":"solr/core/src/java/org/apache/solr/cloud/RecoveryStrategy#replicate(String,SolrCore,String,ZkNodeProps,String).mjava","commits":[{"id":"2c007e7c4cf8c55bc2a5884e315123afaaeec87f","date":1327520966,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/RecoveryStrategy#replicate(String,SolrCore,String,ZkNodeProps,String).mjava","pathOld":"/dev/null","sourceNew":"  private void replicate(String nodeName, SolrCore core, String shardZkNodeName, ZkNodeProps leaderprops, String baseUrl)\n      throws SolrServerException, IOException {\n    // start buffer updates to tran log\n    // and do recovery - either replay via realtime get (eventually)\n    // or full index replication\n   \n    String leaderBaseUrl = leaderprops.get(ZkStateReader.BASE_URL_PROP);\n    ZkCoreNodeProps leaderCNodeProps = new ZkCoreNodeProps(leaderprops);\n    String leaderUrl = leaderCNodeProps.getCoreUrl();\n    String leaderCoreName = leaderCNodeProps.getCoreName();\n    \n    log.info(\"Attempt to replicate from \" + leaderUrl);\n    \n    // if we are the leader, either we are trying to recover faster\n    // then our ephemeral timed out or we are the only node\n    if (!leaderBaseUrl.equals(baseUrl)) {\n      \n      CommonsHttpSolrServer server = new CommonsHttpSolrServer(leaderBaseUrl);\n      server.setSoTimeout(15000);\n      PrepRecovery prepCmd = new PrepRecovery();\n      prepCmd.setCoreName(leaderCoreName);\n      prepCmd.setNodeName(nodeName);\n      prepCmd.setCoreNodeName(shardZkNodeName);\n      \n      server.request(prepCmd);\n      server.shutdown();\n      \n      // use rep handler directly, so we can do this sync rather than async\n      SolrRequestHandler handler = core.getRequestHandler(REPLICATION_HANDLER);\n      if (handler instanceof LazyRequestHandlerWrapper) {\n        handler = ((LazyRequestHandlerWrapper)handler).getWrappedHandler();\n      }\n      ReplicationHandler replicationHandler = (ReplicationHandler) handler;\n      \n      if (replicationHandler == null) {\n        throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE,\n            \"Skipping recovery, no \" + REPLICATION_HANDLER + \" handler found\");\n      }\n      \n      ModifiableSolrParams solrParams = new ModifiableSolrParams();\n      solrParams.set(ReplicationHandler.MASTER_URL, leaderUrl + \"replication\");\n      \n      if (close) retries = INTERRUPTED; \n      boolean success = replicationHandler.doFetch(solrParams, true); // TODO: look into making sure fore=true does not download files we already have\n\n      if (!success) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Replication for recovery failed.\");\n      }\n      \n      // solrcloud_debug\n//      try {\n//        RefCounted<SolrIndexSearcher> searchHolder = core.getNewestSearcher(false);\n//        SolrIndexSearcher searcher = searchHolder.get();\n//        try {\n//          System.out.println(core.getCoreDescriptor().getCoreContainer().getZkController().getNodeName() + \" replicated \"\n//              + searcher.search(new MatchAllDocsQuery(), 1).totalHits + \" from \" + leaderUrl + \" gen:\" + core.getDeletionPolicy().getLatestCommit().getGeneration() + \" data:\" + core.getDataDir());\n//        } finally {\n//          searchHolder.decref();\n//        }\n//      } catch (Exception e) {\n//        \n//      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d","date":1327523564,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/RecoveryStrategy#replicate(String,SolrCore,String,ZkNodeProps,String).mjava","pathOld":"/dev/null","sourceNew":"  private void replicate(String nodeName, SolrCore core, String shardZkNodeName, ZkNodeProps leaderprops, String baseUrl)\n      throws SolrServerException, IOException {\n    // start buffer updates to tran log\n    // and do recovery - either replay via realtime get (eventually)\n    // or full index replication\n   \n    String leaderBaseUrl = leaderprops.get(ZkStateReader.BASE_URL_PROP);\n    ZkCoreNodeProps leaderCNodeProps = new ZkCoreNodeProps(leaderprops);\n    String leaderUrl = leaderCNodeProps.getCoreUrl();\n    String leaderCoreName = leaderCNodeProps.getCoreName();\n    \n    log.info(\"Attempt to replicate from \" + leaderUrl);\n    \n    // if we are the leader, either we are trying to recover faster\n    // then our ephemeral timed out or we are the only node\n    if (!leaderBaseUrl.equals(baseUrl)) {\n      \n      CommonsHttpSolrServer server = new CommonsHttpSolrServer(leaderBaseUrl);\n      server.setSoTimeout(15000);\n      PrepRecovery prepCmd = new PrepRecovery();\n      prepCmd.setCoreName(leaderCoreName);\n      prepCmd.setNodeName(nodeName);\n      prepCmd.setCoreNodeName(shardZkNodeName);\n      \n      server.request(prepCmd);\n      server.shutdown();\n      \n      // use rep handler directly, so we can do this sync rather than async\n      SolrRequestHandler handler = core.getRequestHandler(REPLICATION_HANDLER);\n      if (handler instanceof LazyRequestHandlerWrapper) {\n        handler = ((LazyRequestHandlerWrapper)handler).getWrappedHandler();\n      }\n      ReplicationHandler replicationHandler = (ReplicationHandler) handler;\n      \n      if (replicationHandler == null) {\n        throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE,\n            \"Skipping recovery, no \" + REPLICATION_HANDLER + \" handler found\");\n      }\n      \n      ModifiableSolrParams solrParams = new ModifiableSolrParams();\n      solrParams.set(ReplicationHandler.MASTER_URL, leaderUrl + \"replication\");\n      \n      if (close) retries = INTERRUPTED; \n      boolean success = replicationHandler.doFetch(solrParams, true); // TODO: look into making sure fore=true does not download files we already have\n\n      if (!success) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Replication for recovery failed.\");\n      }\n      \n      // solrcloud_debug\n//      try {\n//        RefCounted<SolrIndexSearcher> searchHolder = core.getNewestSearcher(false);\n//        SolrIndexSearcher searcher = searchHolder.get();\n//        try {\n//          System.out.println(core.getCoreDescriptor().getCoreContainer().getZkController().getNodeName() + \" replicated \"\n//              + searcher.search(new MatchAllDocsQuery(), 1).totalHits + \" from \" + leaderUrl + \" gen:\" + core.getDeletionPolicy().getLatestCommit().getGeneration() + \" data:\" + core.getDataDir());\n//        } finally {\n//          searchHolder.decref();\n//        }\n//      } catch (Exception e) {\n//        \n//      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0d22ac6a4146774c1bc8400160fc0b6150294e92","date":1327528604,"type":0,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/RecoveryStrategy#replicate(String,SolrCore,String,ZkNodeProps,String).mjava","pathOld":"/dev/null","sourceNew":"  private void replicate(String nodeName, SolrCore core, String shardZkNodeName, ZkNodeProps leaderprops, String baseUrl)\n      throws SolrServerException, IOException {\n    // start buffer updates to tran log\n    // and do recovery - either replay via realtime get (eventually)\n    // or full index replication\n   \n    String leaderBaseUrl = leaderprops.get(ZkStateReader.BASE_URL_PROP);\n    ZkCoreNodeProps leaderCNodeProps = new ZkCoreNodeProps(leaderprops);\n    String leaderUrl = leaderCNodeProps.getCoreUrl();\n    String leaderCoreName = leaderCNodeProps.getCoreName();\n    \n    log.info(\"Attempt to replicate from \" + leaderUrl);\n    \n    // if we are the leader, either we are trying to recover faster\n    // then our ephemeral timed out or we are the only node\n    if (!leaderBaseUrl.equals(baseUrl)) {\n      \n      CommonsHttpSolrServer server = new CommonsHttpSolrServer(leaderBaseUrl);\n      server.setSoTimeout(15000);\n      PrepRecovery prepCmd = new PrepRecovery();\n      prepCmd.setCoreName(leaderCoreName);\n      prepCmd.setNodeName(nodeName);\n      prepCmd.setCoreNodeName(shardZkNodeName);\n      \n      server.request(prepCmd);\n      server.shutdown();\n      \n      // use rep handler directly, so we can do this sync rather than async\n      SolrRequestHandler handler = core.getRequestHandler(REPLICATION_HANDLER);\n      if (handler instanceof LazyRequestHandlerWrapper) {\n        handler = ((LazyRequestHandlerWrapper)handler).getWrappedHandler();\n      }\n      ReplicationHandler replicationHandler = (ReplicationHandler) handler;\n      \n      if (replicationHandler == null) {\n        throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE,\n            \"Skipping recovery, no \" + REPLICATION_HANDLER + \" handler found\");\n      }\n      \n      ModifiableSolrParams solrParams = new ModifiableSolrParams();\n      solrParams.set(ReplicationHandler.MASTER_URL, leaderUrl + \"replication\");\n      \n      if (close) retries = INTERRUPTED; \n      boolean success = replicationHandler.doFetch(solrParams, true); // TODO: look into making sure fore=true does not download files we already have\n\n      if (!success) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Replication for recovery failed.\");\n      }\n      \n      // solrcloud_debug\n//      try {\n//        RefCounted<SolrIndexSearcher> searchHolder = core.getNewestSearcher(false);\n//        SolrIndexSearcher searcher = searchHolder.get();\n//        try {\n//          System.out.println(core.getCoreDescriptor().getCoreContainer().getZkController().getNodeName() + \" replicated \"\n//              + searcher.search(new MatchAllDocsQuery(), 1).totalHits + \" from \" + leaderUrl + \" gen:\" + core.getDeletionPolicy().getLatestCommit().getGeneration() + \" data:\" + core.getDataDir());\n//        } finally {\n//          searchHolder.decref();\n//        }\n//      } catch (Exception e) {\n//        \n//      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7888206046bf93a2bfd1aac95d214e7aa3d21eac","date":1329009245,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/RecoveryStrategy#replicate(String,SolrCore,String,ZkNodeProps,String).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/RecoveryStrategy#replicate(String,SolrCore,String,ZkNodeProps,String).mjava","sourceNew":"  private void replicate(String nodeName, SolrCore core, String shardZkNodeName, ZkNodeProps leaderprops, String baseUrl)\n      throws SolrServerException, IOException {\n    // start buffer updates to tran log\n    // and do recovery - either replay via realtime get (eventually)\n    // or full index replication\n   \n    String leaderBaseUrl = leaderprops.get(ZkStateReader.BASE_URL_PROP);\n    ZkCoreNodeProps leaderCNodeProps = new ZkCoreNodeProps(leaderprops);\n    String leaderUrl = leaderCNodeProps.getCoreUrl();\n    String leaderCoreName = leaderCNodeProps.getCoreName();\n    \n    log.info(\"Attempt to replicate from \" + leaderUrl);\n    \n    // if we are the leader, either we are trying to recover faster\n    // then our ephemeral timed out or we are the only node\n    if (!leaderBaseUrl.equals(baseUrl)) {\n      \n      CommonsHttpSolrServer server = new CommonsHttpSolrServer(leaderBaseUrl);\n      server.setConnectionTimeout(30000);\n      server.setSoTimeout(30000);\n      PrepRecovery prepCmd = new PrepRecovery();\n      prepCmd.setCoreName(leaderCoreName);\n      prepCmd.setNodeName(nodeName);\n      prepCmd.setCoreNodeName(shardZkNodeName);\n      \n      server.request(prepCmd);\n      server.shutdown();\n      \n      // use rep handler directly, so we can do this sync rather than async\n      SolrRequestHandler handler = core.getRequestHandler(REPLICATION_HANDLER);\n      if (handler instanceof LazyRequestHandlerWrapper) {\n        handler = ((LazyRequestHandlerWrapper)handler).getWrappedHandler();\n      }\n      ReplicationHandler replicationHandler = (ReplicationHandler) handler;\n      \n      if (replicationHandler == null) {\n        throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE,\n            \"Skipping recovery, no \" + REPLICATION_HANDLER + \" handler found\");\n      }\n      \n      ModifiableSolrParams solrParams = new ModifiableSolrParams();\n      solrParams.set(ReplicationHandler.MASTER_URL, leaderUrl + \"replication\");\n      \n      if (close) retries = INTERRUPTED; \n      boolean success = replicationHandler.doFetch(solrParams, true); // TODO: look into making sure fore=true does not download files we already have\n\n      if (!success) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Replication for recovery failed.\");\n      }\n      \n      // solrcloud_debug\n//      try {\n//        RefCounted<SolrIndexSearcher> searchHolder = core.getNewestSearcher(false);\n//        SolrIndexSearcher searcher = searchHolder.get();\n//        try {\n//          System.out.println(core.getCoreDescriptor().getCoreContainer().getZkController().getNodeName() + \" replicated \"\n//              + searcher.search(new MatchAllDocsQuery(), 1).totalHits + \" from \" + leaderUrl + \" gen:\" + core.getDeletionPolicy().getLatestCommit().getGeneration() + \" data:\" + core.getDataDir());\n//        } finally {\n//          searchHolder.decref();\n//        }\n//      } catch (Exception e) {\n//        \n//      }\n    }\n  }\n\n","sourceOld":"  private void replicate(String nodeName, SolrCore core, String shardZkNodeName, ZkNodeProps leaderprops, String baseUrl)\n      throws SolrServerException, IOException {\n    // start buffer updates to tran log\n    // and do recovery - either replay via realtime get (eventually)\n    // or full index replication\n   \n    String leaderBaseUrl = leaderprops.get(ZkStateReader.BASE_URL_PROP);\n    ZkCoreNodeProps leaderCNodeProps = new ZkCoreNodeProps(leaderprops);\n    String leaderUrl = leaderCNodeProps.getCoreUrl();\n    String leaderCoreName = leaderCNodeProps.getCoreName();\n    \n    log.info(\"Attempt to replicate from \" + leaderUrl);\n    \n    // if we are the leader, either we are trying to recover faster\n    // then our ephemeral timed out or we are the only node\n    if (!leaderBaseUrl.equals(baseUrl)) {\n      \n      CommonsHttpSolrServer server = new CommonsHttpSolrServer(leaderBaseUrl);\n      server.setSoTimeout(15000);\n      PrepRecovery prepCmd = new PrepRecovery();\n      prepCmd.setCoreName(leaderCoreName);\n      prepCmd.setNodeName(nodeName);\n      prepCmd.setCoreNodeName(shardZkNodeName);\n      \n      server.request(prepCmd);\n      server.shutdown();\n      \n      // use rep handler directly, so we can do this sync rather than async\n      SolrRequestHandler handler = core.getRequestHandler(REPLICATION_HANDLER);\n      if (handler instanceof LazyRequestHandlerWrapper) {\n        handler = ((LazyRequestHandlerWrapper)handler).getWrappedHandler();\n      }\n      ReplicationHandler replicationHandler = (ReplicationHandler) handler;\n      \n      if (replicationHandler == null) {\n        throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE,\n            \"Skipping recovery, no \" + REPLICATION_HANDLER + \" handler found\");\n      }\n      \n      ModifiableSolrParams solrParams = new ModifiableSolrParams();\n      solrParams.set(ReplicationHandler.MASTER_URL, leaderUrl + \"replication\");\n      \n      if (close) retries = INTERRUPTED; \n      boolean success = replicationHandler.doFetch(solrParams, true); // TODO: look into making sure fore=true does not download files we already have\n\n      if (!success) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Replication for recovery failed.\");\n      }\n      \n      // solrcloud_debug\n//      try {\n//        RefCounted<SolrIndexSearcher> searchHolder = core.getNewestSearcher(false);\n//        SolrIndexSearcher searcher = searchHolder.get();\n//        try {\n//          System.out.println(core.getCoreDescriptor().getCoreContainer().getZkController().getNodeName() + \" replicated \"\n//              + searcher.search(new MatchAllDocsQuery(), 1).totalHits + \" from \" + leaderUrl + \" gen:\" + core.getDeletionPolicy().getLatestCommit().getGeneration() + \" data:\" + core.getDataDir());\n//        } finally {\n//          searchHolder.decref();\n//        }\n//      } catch (Exception e) {\n//        \n//      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a752b89ed4b8bfa40e21a23601fbc376340bb3f4","date":1329246954,"type":5,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/RecoveryStrategy#replicate(String,SolrCore,ZkNodeProps,String).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/RecoveryStrategy#replicate(String,SolrCore,String,ZkNodeProps,String).mjava","sourceNew":"  private void replicate(String nodeName, SolrCore core, ZkNodeProps leaderprops, String baseUrl)\n      throws SolrServerException, IOException {\n    // start buffer updates to tran log\n    // and do recovery - either replay via realtime get (eventually)\n    // or full index replication\n   \n    String leaderBaseUrl = leaderprops.get(ZkStateReader.BASE_URL_PROP);\n    ZkCoreNodeProps leaderCNodeProps = new ZkCoreNodeProps(leaderprops);\n    String leaderUrl = leaderCNodeProps.getCoreUrl();\n    String leaderCoreName = leaderCNodeProps.getCoreName();\n    \n    log.info(\"Attempting to replicate from \" + leaderUrl);\n    \n    // if we are the leader, either we are trying to recover faster\n    // then our ephemeral timed out or we are the only node\n    if (!leaderBaseUrl.equals(baseUrl)) {\n      \n      CommonsHttpSolrServer server = new CommonsHttpSolrServer(leaderBaseUrl);\n      server.setConnectionTimeout(30000);\n      server.setSoTimeout(30000);\n      PrepRecovery prepCmd = new PrepRecovery();\n      prepCmd.setCoreName(leaderCoreName);\n      prepCmd.setNodeName(nodeName);\n      prepCmd.setCoreNodeName(coreZkNodeName);\n      \n      server.request(prepCmd);\n      server.shutdown();\n      \n      // use rep handler directly, so we can do this sync rather than async\n      SolrRequestHandler handler = core.getRequestHandler(REPLICATION_HANDLER);\n      if (handler instanceof LazyRequestHandlerWrapper) {\n        handler = ((LazyRequestHandlerWrapper)handler).getWrappedHandler();\n      }\n      ReplicationHandler replicationHandler = (ReplicationHandler) handler;\n      \n      if (replicationHandler == null) {\n        throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE,\n            \"Skipping recovery, no \" + REPLICATION_HANDLER + \" handler found\");\n      }\n      \n      ModifiableSolrParams solrParams = new ModifiableSolrParams();\n      solrParams.set(ReplicationHandler.MASTER_URL, leaderUrl + \"replication\");\n      \n      if (close) retries = INTERRUPTED; \n      boolean success = replicationHandler.doFetch(solrParams, true); // TODO: look into making sure fore=true does not download files we already have\n\n      if (!success) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Replication for recovery failed.\");\n      }\n      \n      // solrcloud_debug\n//      try {\n//        RefCounted<SolrIndexSearcher> searchHolder = core.getNewestSearcher(false);\n//        SolrIndexSearcher searcher = searchHolder.get();\n//        try {\n//          System.out.println(core.getCoreDescriptor().getCoreContainer().getZkController().getNodeName() + \" replicated \"\n//              + searcher.search(new MatchAllDocsQuery(), 1).totalHits + \" from \" + leaderUrl + \" gen:\" + core.getDeletionPolicy().getLatestCommit().getGeneration() + \" data:\" + core.getDataDir());\n//        } finally {\n//          searchHolder.decref();\n//        }\n//      } catch (Exception e) {\n//        \n//      }\n    }\n  }\n\n","sourceOld":"  private void replicate(String nodeName, SolrCore core, String shardZkNodeName, ZkNodeProps leaderprops, String baseUrl)\n      throws SolrServerException, IOException {\n    // start buffer updates to tran log\n    // and do recovery - either replay via realtime get (eventually)\n    // or full index replication\n   \n    String leaderBaseUrl = leaderprops.get(ZkStateReader.BASE_URL_PROP);\n    ZkCoreNodeProps leaderCNodeProps = new ZkCoreNodeProps(leaderprops);\n    String leaderUrl = leaderCNodeProps.getCoreUrl();\n    String leaderCoreName = leaderCNodeProps.getCoreName();\n    \n    log.info(\"Attempt to replicate from \" + leaderUrl);\n    \n    // if we are the leader, either we are trying to recover faster\n    // then our ephemeral timed out or we are the only node\n    if (!leaderBaseUrl.equals(baseUrl)) {\n      \n      CommonsHttpSolrServer server = new CommonsHttpSolrServer(leaderBaseUrl);\n      server.setConnectionTimeout(30000);\n      server.setSoTimeout(30000);\n      PrepRecovery prepCmd = new PrepRecovery();\n      prepCmd.setCoreName(leaderCoreName);\n      prepCmd.setNodeName(nodeName);\n      prepCmd.setCoreNodeName(shardZkNodeName);\n      \n      server.request(prepCmd);\n      server.shutdown();\n      \n      // use rep handler directly, so we can do this sync rather than async\n      SolrRequestHandler handler = core.getRequestHandler(REPLICATION_HANDLER);\n      if (handler instanceof LazyRequestHandlerWrapper) {\n        handler = ((LazyRequestHandlerWrapper)handler).getWrappedHandler();\n      }\n      ReplicationHandler replicationHandler = (ReplicationHandler) handler;\n      \n      if (replicationHandler == null) {\n        throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE,\n            \"Skipping recovery, no \" + REPLICATION_HANDLER + \" handler found\");\n      }\n      \n      ModifiableSolrParams solrParams = new ModifiableSolrParams();\n      solrParams.set(ReplicationHandler.MASTER_URL, leaderUrl + \"replication\");\n      \n      if (close) retries = INTERRUPTED; \n      boolean success = replicationHandler.doFetch(solrParams, true); // TODO: look into making sure fore=true does not download files we already have\n\n      if (!success) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Replication for recovery failed.\");\n      }\n      \n      // solrcloud_debug\n//      try {\n//        RefCounted<SolrIndexSearcher> searchHolder = core.getNewestSearcher(false);\n//        SolrIndexSearcher searcher = searchHolder.get();\n//        try {\n//          System.out.println(core.getCoreDescriptor().getCoreContainer().getZkController().getNodeName() + \" replicated \"\n//              + searcher.search(new MatchAllDocsQuery(), 1).totalHits + \" from \" + leaderUrl + \" gen:\" + core.getDeletionPolicy().getLatestCommit().getGeneration() + \" data:\" + core.getDataDir());\n//        } finally {\n//          searchHolder.decref();\n//        }\n//      } catch (Exception e) {\n//        \n//      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"0d22ac6a4146774c1bc8400160fc0b6150294e92":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"a752b89ed4b8bfa40e21a23601fbc376340bb3f4":["7888206046bf93a2bfd1aac95d214e7aa3d21eac"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"2c007e7c4cf8c55bc2a5884e315123afaaeec87f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"7888206046bf93a2bfd1aac95d214e7aa3d21eac":["2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a752b89ed4b8bfa40e21a23601fbc376340bb3f4"]},"commit2Childs":{"0d22ac6a4146774c1bc8400160fc0b6150294e92":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["0d22ac6a4146774c1bc8400160fc0b6150294e92","a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d","2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"a752b89ed4b8bfa40e21a23601fbc376340bb3f4":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d":[],"2c007e7c4cf8c55bc2a5884e315123afaaeec87f":["0d22ac6a4146774c1bc8400160fc0b6150294e92","a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d","7888206046bf93a2bfd1aac95d214e7aa3d21eac"],"7888206046bf93a2bfd1aac95d214e7aa3d21eac":["a752b89ed4b8bfa40e21a23601fbc376340bb3f4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["0d22ac6a4146774c1bc8400160fc0b6150294e92","a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}