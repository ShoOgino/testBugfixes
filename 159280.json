{"path":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterWithThreads#stressUpdateSingleDocWithThreads(boolean,boolean).mjava","commits":[{"id":"10dae974eb4de913f4a2075cd10fb6dfcba04a99","date":1528877401,"type":0,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterWithThreads#stressUpdateSingleDocWithThreads(boolean,boolean).mjava","pathOld":"/dev/null","sourceNew":"  public void stressUpdateSingleDocWithThreads(boolean useSoftDeletes, boolean forceMerge) throws Exception{\n    try (Directory dir = newDirectory();\n         RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n             newIndexWriterConfig().setMaxBufferedDocs(-1).setRAMBufferSizeMB(0.00001), useSoftDeletes)) {\n      Thread[] threads = new Thread[3 + random().nextInt(3)];\n      AtomicInteger done = new AtomicInteger(0);\n      CyclicBarrier barrier = new CyclicBarrier(threads.length + 1);\n      Document doc = new Document();\n      doc.add(new StringField(\"id\", \"1\", Field.Store.NO));\n      writer.updateDocument(new Term(\"id\", \"1\"), doc);\n      int itersPerThread = 100 + random().nextInt(2000);\n      for (int i = 0; i < threads.length; i++) {\n        threads[i] = new Thread(() -> {\n          try {\n            barrier.await();\n            for (int iters = 0; iters < itersPerThread; iters++) {\n              Document d = new Document();\n              d.add(new StringField(\"id\", \"1\", Field.Store.NO));\n              writer.updateDocument(new Term(\"id\", \"1\"), d);\n            }\n          } catch (Exception e) {\n            throw new AssertionError(e);\n          } finally {\n            done.incrementAndGet();\n          }\n        });\n        threads[i].start();\n      }\n      DirectoryReader open = DirectoryReader.open(writer.w);\n      assertEquals(open.numDocs(), 1);\n      barrier.await();\n      try {\n        do {\n          if (forceMerge && random().nextBoolean()) {\n            writer.forceMerge(1);\n          }\n          DirectoryReader newReader = DirectoryReader.openIfChanged(open);\n          if (newReader != null) {\n            open.close();\n            open = newReader;\n          }\n          assertEquals(open.numDocs(), 1);\n        } while (done.get() < threads.length);\n      } finally {\n        open.close();\n        for (int i = 0; i < threads.length; i++) {\n          threads[i].join();\n        }\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26","date":1531589977,"type":0,"author":"Michael Braun","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterWithThreads#stressUpdateSingleDocWithThreads(boolean,boolean).mjava","pathOld":"/dev/null","sourceNew":"  public void stressUpdateSingleDocWithThreads(boolean useSoftDeletes, boolean forceMerge) throws Exception{\n    try (Directory dir = newDirectory();\n         RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n             newIndexWriterConfig().setMaxBufferedDocs(-1).setRAMBufferSizeMB(0.00001), useSoftDeletes)) {\n      Thread[] threads = new Thread[3 + random().nextInt(3)];\n      AtomicInteger done = new AtomicInteger(0);\n      CyclicBarrier barrier = new CyclicBarrier(threads.length + 1);\n      Document doc = new Document();\n      doc.add(new StringField(\"id\", \"1\", Field.Store.NO));\n      writer.updateDocument(new Term(\"id\", \"1\"), doc);\n      int itersPerThread = 100 + random().nextInt(2000);\n      for (int i = 0; i < threads.length; i++) {\n        threads[i] = new Thread(() -> {\n          try {\n            barrier.await();\n            for (int iters = 0; iters < itersPerThread; iters++) {\n              Document d = new Document();\n              d.add(new StringField(\"id\", \"1\", Field.Store.NO));\n              writer.updateDocument(new Term(\"id\", \"1\"), d);\n            }\n          } catch (Exception e) {\n            throw new AssertionError(e);\n          } finally {\n            done.incrementAndGet();\n          }\n        });\n        threads[i].start();\n      }\n      DirectoryReader open = DirectoryReader.open(writer.w);\n      assertEquals(open.numDocs(), 1);\n      barrier.await();\n      try {\n        do {\n          if (forceMerge && random().nextBoolean()) {\n            writer.forceMerge(1);\n          }\n          DirectoryReader newReader = DirectoryReader.openIfChanged(open);\n          if (newReader != null) {\n            open.close();\n            open = newReader;\n          }\n          assertEquals(open.numDocs(), 1);\n        } while (done.get() < threads.length);\n      } finally {\n        open.close();\n        for (int i = 0; i < threads.length; i++) {\n          threads[i].join();\n        }\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","date":1531905561,"type":0,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterWithThreads#stressUpdateSingleDocWithThreads(boolean,boolean).mjava","pathOld":"/dev/null","sourceNew":"  public void stressUpdateSingleDocWithThreads(boolean useSoftDeletes, boolean forceMerge) throws Exception{\n    try (Directory dir = newDirectory();\n         RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n             newIndexWriterConfig().setMaxBufferedDocs(-1).setRAMBufferSizeMB(0.00001), useSoftDeletes)) {\n      Thread[] threads = new Thread[3 + random().nextInt(3)];\n      AtomicInteger done = new AtomicInteger(0);\n      CyclicBarrier barrier = new CyclicBarrier(threads.length + 1);\n      Document doc = new Document();\n      doc.add(new StringField(\"id\", \"1\", Field.Store.NO));\n      writer.updateDocument(new Term(\"id\", \"1\"), doc);\n      int itersPerThread = 100 + random().nextInt(2000);\n      for (int i = 0; i < threads.length; i++) {\n        threads[i] = new Thread(() -> {\n          try {\n            barrier.await();\n            for (int iters = 0; iters < itersPerThread; iters++) {\n              Document d = new Document();\n              d.add(new StringField(\"id\", \"1\", Field.Store.NO));\n              writer.updateDocument(new Term(\"id\", \"1\"), d);\n            }\n          } catch (Exception e) {\n            throw new AssertionError(e);\n          } finally {\n            done.incrementAndGet();\n          }\n        });\n        threads[i].start();\n      }\n      DirectoryReader open = DirectoryReader.open(writer.w);\n      assertEquals(open.numDocs(), 1);\n      barrier.await();\n      try {\n        do {\n          if (forceMerge && random().nextBoolean()) {\n            writer.forceMerge(1);\n          }\n          DirectoryReader newReader = DirectoryReader.openIfChanged(open);\n          if (newReader != null) {\n            open.close();\n            open = newReader;\n          }\n          assertEquals(open.numDocs(), 1);\n        } while (done.get() < threads.length);\n      } finally {\n        open.close();\n        for (int i = 0; i < threads.length; i++) {\n          threads[i].join();\n        }\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4208ed8e426ae5f75a41d8b4ae53f4587e413061","date":1580475454,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterWithThreads#stressUpdateSingleDocWithThreads(boolean,boolean).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterWithThreads#stressUpdateSingleDocWithThreads(boolean,boolean).mjava","sourceNew":"  public void stressUpdateSingleDocWithThreads(boolean useSoftDeletes, boolean forceMerge) throws Exception{\n    try (Directory dir = newDirectory();\n         RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n             newIndexWriterConfig().setMaxBufferedDocs(-1).setRAMBufferSizeMB(0.00001), useSoftDeletes)) {\n      int numThreads = TEST_NIGHTLY ? 3 + random().nextInt(3) : 3;\n      Thread[] threads = new Thread[numThreads];\n      AtomicInteger done = new AtomicInteger(0);\n      CyclicBarrier barrier = new CyclicBarrier(threads.length + 1);\n      Document doc = new Document();\n      doc.add(new StringField(\"id\", \"1\", Field.Store.NO));\n      writer.updateDocument(new Term(\"id\", \"1\"), doc);\n      int itersPerThread = 100 + random().nextInt(2000);\n      for (int i = 0; i < threads.length; i++) {\n        threads[i] = new Thread(() -> {\n          try {\n            barrier.await();\n            for (int iters = 0; iters < itersPerThread; iters++) {\n              Document d = new Document();\n              d.add(new StringField(\"id\", \"1\", Field.Store.NO));\n              writer.updateDocument(new Term(\"id\", \"1\"), d);\n            }\n          } catch (Exception e) {\n            throw new AssertionError(e);\n          } finally {\n            done.incrementAndGet();\n          }\n        });\n        threads[i].start();\n      }\n      DirectoryReader open = DirectoryReader.open(writer.w);\n      assertEquals(open.numDocs(), 1);\n      barrier.await();\n      try {\n        do {\n          if (forceMerge && random().nextBoolean()) {\n            writer.forceMerge(1);\n          }\n          DirectoryReader newReader = DirectoryReader.openIfChanged(open);\n          if (newReader != null) {\n            open.close();\n            open = newReader;\n          }\n          assertEquals(open.numDocs(), 1);\n        } while (done.get() < threads.length);\n      } finally {\n        open.close();\n        for (int i = 0; i < threads.length; i++) {\n          threads[i].join();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  public void stressUpdateSingleDocWithThreads(boolean useSoftDeletes, boolean forceMerge) throws Exception{\n    try (Directory dir = newDirectory();\n         RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n             newIndexWriterConfig().setMaxBufferedDocs(-1).setRAMBufferSizeMB(0.00001), useSoftDeletes)) {\n      Thread[] threads = new Thread[3 + random().nextInt(3)];\n      AtomicInteger done = new AtomicInteger(0);\n      CyclicBarrier barrier = new CyclicBarrier(threads.length + 1);\n      Document doc = new Document();\n      doc.add(new StringField(\"id\", \"1\", Field.Store.NO));\n      writer.updateDocument(new Term(\"id\", \"1\"), doc);\n      int itersPerThread = 100 + random().nextInt(2000);\n      for (int i = 0; i < threads.length; i++) {\n        threads[i] = new Thread(() -> {\n          try {\n            barrier.await();\n            for (int iters = 0; iters < itersPerThread; iters++) {\n              Document d = new Document();\n              d.add(new StringField(\"id\", \"1\", Field.Store.NO));\n              writer.updateDocument(new Term(\"id\", \"1\"), d);\n            }\n          } catch (Exception e) {\n            throw new AssertionError(e);\n          } finally {\n            done.incrementAndGet();\n          }\n        });\n        threads[i].start();\n      }\n      DirectoryReader open = DirectoryReader.open(writer.w);\n      assertEquals(open.numDocs(), 1);\n      barrier.await();\n      try {\n        do {\n          if (forceMerge && random().nextBoolean()) {\n            writer.forceMerge(1);\n          }\n          DirectoryReader newReader = DirectoryReader.openIfChanged(open);\n          if (newReader != null) {\n            open.close();\n            open = newReader;\n          }\n          assertEquals(open.numDocs(), 1);\n        } while (done.get() < threads.length);\n      } finally {\n        open.close();\n        for (int i = 0; i < threads.length; i++) {\n          threads[i].join();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","10dae974eb4de913f4a2075cd10fb6dfcba04a99"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4208ed8e426ae5f75a41d8b4ae53f4587e413061":["10dae974eb4de913f4a2075cd10fb6dfcba04a99"],"10dae974eb4de913f4a2075cd10fb6dfcba04a99":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["4208ed8e426ae5f75a41d8b4ae53f4587e413061"],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","10dae974eb4de913f4a2075cd10fb6dfcba04a99"]},"commit2Childs":{"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","10dae974eb4de913f4a2075cd10fb6dfcba04a99","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"10dae974eb4de913f4a2075cd10fb6dfcba04a99":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","4208ed8e426ae5f75a41d8b4ae53f4587e413061","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"4208ed8e426ae5f75a41d8b4ae53f4587e413061":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":[]},"heads":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","cd5edd1f2b162a5cfa08efd17851a07373a96817","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}