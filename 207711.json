{"path":"lucene/spatial/src/java/org/apache/lucene/spatial/prefix/NumberRangePrefixTreeFacets#compute(NumberRangePrefixTreeStrategy,IndexReaderContext,Bits,Shape,int).mjava","commits":[{"id":"b2c05e4efde014c90e420f5f7c2966499682635c","date":1419397169,"type":0,"author":"David Wayne Smiley","isMerge":false,"pathNew":"lucene/spatial/src/java/org/apache/lucene/spatial/prefix/NumberRangePrefixTreeFacets#compute(NumberRangePrefixTreeStrategy,IndexReaderContext,Bits,Shape,int).mjava","pathOld":"/dev/null","sourceNew":"  public static Facets compute(NumberRangePrefixTreeStrategy strategy,\n                               IndexReaderContext context, final Bits acceptDocs, Shape queryShape, int facetLevel)\n      throws IOException {\n\n    Facets facets = new Facets(facetLevel);\n\n    // TODO should we pre-create all parent buckets? It's not necessary, but the client/user may find it convenient to\n    //   have so it needn't do a bunch of calendar work itself to ascertain which buckets are missing. It would\n    //   also then easily allow us to have a too-many-facets exception (e.g. you ask for a millisecond bucket for\n    //   the entire year). We could do that now but we would only be able to throw if the actual counts get to the\n    //   threshold vs. being able to know the possible values consistently a-priori which is much preferred. Now on the\n    //   other hand, we can facet over extremely sparse data sets without needless parent buckets.\n\n    //We collect per-leaf\n    final List<LeafReaderContext> leaves = context.leaves();\n    for (final LeafReaderContext leafCtx : leaves) {\n      //determine leaf acceptDocs\n      Bits leafAcceptDocs;\n      if (acceptDocs == null) {\n        leafAcceptDocs = leafCtx.reader().getLiveDocs();\n      } else if (leaves.size() == 1) {\n        leafAcceptDocs = acceptDocs;\n      } else {\n        leafAcceptDocs = new Bits() {//note: it'd be nice if Lucene's BitsSlice was public.\n\n          final int docBase = leafCtx.docBase;\n\n          @Override\n          public boolean get(int index) {\n            return acceptDocs.get(docBase + index);\n          }\n\n          @Override\n          public int length() {\n            return leafCtx.reader().maxDoc();\n          }\n        };\n      }\n\n      facets = compute(strategy, leafCtx, leafAcceptDocs, queryShape, facets);\n    }\n    return facets;\n\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"478e85d406c2ea05f4e5028248b9a8e43f300885","date":1421346780,"type":4,"author":"David Wayne Smiley","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/spatial/src/java/org/apache/lucene/spatial/prefix/NumberRangePrefixTreeFacets#compute(NumberRangePrefixTreeStrategy,IndexReaderContext,Bits,Shape,int).mjava","sourceNew":null,"sourceOld":"  public static Facets compute(NumberRangePrefixTreeStrategy strategy,\n                               IndexReaderContext context, final Bits acceptDocs, Shape queryShape, int facetLevel)\n      throws IOException {\n\n    Facets facets = new Facets(facetLevel);\n\n    // TODO should we pre-create all parent buckets? It's not necessary, but the client/user may find it convenient to\n    //   have so it needn't do a bunch of calendar work itself to ascertain which buckets are missing. It would\n    //   also then easily allow us to have a too-many-facets exception (e.g. you ask for a millisecond bucket for\n    //   the entire year). We could do that now but we would only be able to throw if the actual counts get to the\n    //   threshold vs. being able to know the possible values consistently a-priori which is much preferred. Now on the\n    //   other hand, we can facet over extremely sparse data sets without needless parent buckets.\n\n    //We collect per-leaf\n    final List<LeafReaderContext> leaves = context.leaves();\n    for (final LeafReaderContext leafCtx : leaves) {\n      //determine leaf acceptDocs\n      Bits leafAcceptDocs;\n      if (acceptDocs == null) {\n        leafAcceptDocs = leafCtx.reader().getLiveDocs();\n      } else if (leaves.size() == 1) {\n        leafAcceptDocs = acceptDocs;\n      } else {\n        leafAcceptDocs = new Bits() {//note: it'd be nice if Lucene's BitsSlice was public.\n\n          final int docBase = leafCtx.docBase;\n\n          @Override\n          public boolean get(int index) {\n            return acceptDocs.get(docBase + index);\n          }\n\n          @Override\n          public int length() {\n            return leafCtx.reader().maxDoc();\n          }\n        };\n      }\n\n      facets = compute(strategy, leafCtx, leafAcceptDocs, queryShape, facets);\n    }\n    return facets;\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"478e85d406c2ea05f4e5028248b9a8e43f300885":["b2c05e4efde014c90e420f5f7c2966499682635c"],"b2c05e4efde014c90e420f5f7c2966499682635c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["478e85d406c2ea05f4e5028248b9a8e43f300885"]},"commit2Childs":{"478e85d406c2ea05f4e5028248b9a8e43f300885":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"b2c05e4efde014c90e420f5f7c2966499682635c":["478e85d406c2ea05f4e5028248b9a8e43f300885"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b2c05e4efde014c90e420f5f7c2966499682635c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}