{"path":"lucene/src/test-framework/java/org/apache/lucene/analysis/MockTokenizer#incrementToken().mjava","commits":[{"id":"7b91922b55d15444d554721b352861d028eb8278","date":1320421415,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test-framework/java/org/apache/lucene/analysis/MockTokenizer#incrementToken().mjava","pathOld":"lucene/src/test-framework/org/apache/lucene/analysis/MockTokenizer#incrementToken().mjava","sourceNew":"  @Override\n  public final boolean incrementToken() throws IOException {\n    assert !enableChecks || (streamState == State.RESET || streamState == State.INCREMENT) \n                            : \"incrementToken() called while in wrong state: \" + streamState;\n    clearAttributes();\n    for (;;) {\n      int startOffset = off;\n      int cp = readCodePoint();\n      if (cp < 0) {\n        break;\n      } else if (isTokenChar(cp)) {\n        int endOffset;\n        do {\n          char chars[] = Character.toChars(normalize(cp));\n          for (int i = 0; i < chars.length; i++)\n            termAtt.append(chars[i]);\n          endOffset = off;\n          if (termAtt.length() >= maxTokenLength) {\n            break;\n          }\n          cp = readCodePoint();\n        } while (cp >= 0 && isTokenChar(cp));\n        offsetAtt.setOffset(correctOffset(startOffset), correctOffset(endOffset));\n        streamState = State.INCREMENT;\n        return true;\n      }\n    }\n    streamState = State.INCREMENT_FALSE;\n    return false;\n  }\n\n","sourceOld":"  @Override\n  public final boolean incrementToken() throws IOException {\n    assert !enableChecks || (streamState == State.RESET || streamState == State.INCREMENT) \n                            : \"incrementToken() called while in wrong state: \" + streamState;\n    clearAttributes();\n    for (;;) {\n      int startOffset = off;\n      int cp = readCodePoint();\n      if (cp < 0) {\n        break;\n      } else if (isTokenChar(cp)) {\n        int endOffset;\n        do {\n          char chars[] = Character.toChars(normalize(cp));\n          for (int i = 0; i < chars.length; i++)\n            termAtt.append(chars[i]);\n          endOffset = off;\n          if (termAtt.length() >= maxTokenLength) {\n            break;\n          }\n          cp = readCodePoint();\n        } while (cp >= 0 && isTokenChar(cp));\n        offsetAtt.setOffset(correctOffset(startOffset), correctOffset(endOffset));\n        streamState = State.INCREMENT;\n        return true;\n      }\n    }\n    streamState = State.INCREMENT_FALSE;\n    return false;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b8851e523e638323ef17b2c8e44eb34ba16365e0","date":1328091897,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test-framework/java/org/apache/lucene/analysis/MockTokenizer#incrementToken().mjava","pathOld":"lucene/src/test-framework/java/org/apache/lucene/analysis/MockTokenizer#incrementToken().mjava","sourceNew":"  @Override\n  public final boolean incrementToken() throws IOException {\n    assert !enableChecks || (streamState == State.RESET || streamState == State.INCREMENT) \n                            : \"incrementToken() called while in wrong state: \" + streamState;\n    clearAttributes();\n    for (;;) {\n      int startOffset = off;\n      int cp = readCodePoint();\n      if (cp < 0) {\n        break;\n      } else if (isTokenChar(cp)) {\n        int endOffset;\n        do {\n          char chars[] = Character.toChars(normalize(cp));\n          for (int i = 0; i < chars.length; i++)\n            termAtt.append(chars[i]);\n          endOffset = off;\n          if (termAtt.length() >= maxTokenLength) {\n            break;\n          }\n          cp = readCodePoint();\n        } while (cp >= 0 && isTokenChar(cp));\n        \n        int correctedStartOffset = correctOffset(startOffset);\n        int correctedEndOffset = correctOffset(endOffset);\n        assert correctedStartOffset >= 0;\n        assert correctedEndOffset >= 0;\n        assert correctedStartOffset >= lastOffset;\n        lastOffset = correctedStartOffset;\n        assert correctedEndOffset >= correctedStartOffset;\n        offsetAtt.setOffset(correctedStartOffset, correctedEndOffset);\n        streamState = State.INCREMENT;\n        return true;\n      }\n    }\n    streamState = State.INCREMENT_FALSE;\n    return false;\n  }\n\n","sourceOld":"  @Override\n  public final boolean incrementToken() throws IOException {\n    assert !enableChecks || (streamState == State.RESET || streamState == State.INCREMENT) \n                            : \"incrementToken() called while in wrong state: \" + streamState;\n    clearAttributes();\n    for (;;) {\n      int startOffset = off;\n      int cp = readCodePoint();\n      if (cp < 0) {\n        break;\n      } else if (isTokenChar(cp)) {\n        int endOffset;\n        do {\n          char chars[] = Character.toChars(normalize(cp));\n          for (int i = 0; i < chars.length; i++)\n            termAtt.append(chars[i]);\n          endOffset = off;\n          if (termAtt.length() >= maxTokenLength) {\n            break;\n          }\n          cp = readCodePoint();\n        } while (cp >= 0 && isTokenChar(cp));\n        offsetAtt.setOffset(correctOffset(startOffset), correctOffset(endOffset));\n        streamState = State.INCREMENT;\n        return true;\n      }\n    }\n    streamState = State.INCREMENT_FALSE;\n    return false;\n  }\n\n","bugFix":["fcbc12aa8147f5203ca283e7252ba4280d6ffd16"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/MockTokenizer#incrementToken().mjava","pathOld":"lucene/src/test-framework/java/org/apache/lucene/analysis/MockTokenizer#incrementToken().mjava","sourceNew":"  @Override\n  public final boolean incrementToken() throws IOException {\n    assert !enableChecks || (streamState == State.RESET || streamState == State.INCREMENT) \n                            : \"incrementToken() called while in wrong state: \" + streamState;\n    clearAttributes();\n    for (;;) {\n      int startOffset = off;\n      int cp = readCodePoint();\n      if (cp < 0) {\n        break;\n      } else if (isTokenChar(cp)) {\n        int endOffset;\n        do {\n          char chars[] = Character.toChars(normalize(cp));\n          for (int i = 0; i < chars.length; i++)\n            termAtt.append(chars[i]);\n          endOffset = off;\n          if (termAtt.length() >= maxTokenLength) {\n            break;\n          }\n          cp = readCodePoint();\n        } while (cp >= 0 && isTokenChar(cp));\n        \n        int correctedStartOffset = correctOffset(startOffset);\n        int correctedEndOffset = correctOffset(endOffset);\n        assert correctedStartOffset >= 0;\n        assert correctedEndOffset >= 0;\n        assert correctedStartOffset >= lastOffset;\n        lastOffset = correctedStartOffset;\n        assert correctedEndOffset >= correctedStartOffset;\n        offsetAtt.setOffset(correctedStartOffset, correctedEndOffset);\n        streamState = State.INCREMENT;\n        return true;\n      }\n    }\n    streamState = State.INCREMENT_FALSE;\n    return false;\n  }\n\n","sourceOld":"  @Override\n  public final boolean incrementToken() throws IOException {\n    assert !enableChecks || (streamState == State.RESET || streamState == State.INCREMENT) \n                            : \"incrementToken() called while in wrong state: \" + streamState;\n    clearAttributes();\n    for (;;) {\n      int startOffset = off;\n      int cp = readCodePoint();\n      if (cp < 0) {\n        break;\n      } else if (isTokenChar(cp)) {\n        int endOffset;\n        do {\n          char chars[] = Character.toChars(normalize(cp));\n          for (int i = 0; i < chars.length; i++)\n            termAtt.append(chars[i]);\n          endOffset = off;\n          if (termAtt.length() >= maxTokenLength) {\n            break;\n          }\n          cp = readCodePoint();\n        } while (cp >= 0 && isTokenChar(cp));\n        \n        int correctedStartOffset = correctOffset(startOffset);\n        int correctedEndOffset = correctOffset(endOffset);\n        assert correctedStartOffset >= 0;\n        assert correctedEndOffset >= 0;\n        assert correctedStartOffset >= lastOffset;\n        lastOffset = correctedStartOffset;\n        assert correctedEndOffset >= correctedStartOffset;\n        offsetAtt.setOffset(correctedStartOffset, correctedEndOffset);\n        streamState = State.INCREMENT;\n        return true;\n      }\n    }\n    streamState = State.INCREMENT_FALSE;\n    return false;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"7b91922b55d15444d554721b352861d028eb8278":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["b8851e523e638323ef17b2c8e44eb34ba16365e0"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b8851e523e638323ef17b2c8e44eb34ba16365e0":["7b91922b55d15444d554721b352861d028eb8278"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"7b91922b55d15444d554721b352861d028eb8278":["b8851e523e638323ef17b2c8e44eb34ba16365e0"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["7b91922b55d15444d554721b352861d028eb8278"],"b8851e523e638323ef17b2c8e44eb34ba16365e0":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}