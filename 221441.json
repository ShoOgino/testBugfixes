{"path":"solr/core/src/test/org/apache/solr/schema/TestPointFields#testDatePointFieldMultiValuedRangeFacet().mjava","commits":[{"id":"daa9f76a48e97bb2d40fc67ecdaad33d166d596e","date":1488856307,"type":0,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/schema/TestPointFields#testDatePointFieldMultiValuedRangeFacet().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testDatePointFieldMultiValuedRangeFacet() throws Exception {\n    doTestDatePointFieldMultiValuedRangeFacet(\"number_p_dt_mv_dv\", \"number_p_dt_mv\");\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"17e844d4f9ba6804f10747d7e51e83a9a8868c94","date":1500054875,"type":3,"author":"Steve Rowe","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/schema/TestPointFields#testDatePointFieldMultiValuedRangeFacet().mjava","pathOld":"solr/core/src/test/org/apache/solr/schema/TestPointFields#testDatePointFieldMultiValuedRangeFacet().mjava","sourceNew":"  @Test\n  public void testDatePointFieldMultiValuedRangeFacet() throws Exception {\n    String docValuesField = \"number_p_dt_mv_dv\";\n    SchemaField dvSchemaField = h.getCore().getLatestSchema().getField(docValuesField);\n    assertTrue(dvSchemaField.multiValued());\n    assertTrue(dvSchemaField.hasDocValues());\n    assertTrue(dvSchemaField.getType() instanceof PointField);\n    \n    String nonDocValuesField = \"number_p_dt_mv\";\n    SchemaField nonDvSchemaField = h.getCore().getLatestSchema().getField(nonDocValuesField);\n    assertTrue(nonDvSchemaField.multiValued());\n    assertFalse(nonDvSchemaField.hasDocValues());\n    assertTrue(nonDvSchemaField.getType() instanceof PointField);\n\n    int numValues = 20 * RANDOM_MULTIPLIER;\n    int numBuckets = numValues / 2;\n    List<Long> values;\n    List<PosVal<Long>> sortedValues;\n    long min, max;\n    do {\n      values = getRandomLongs(numValues, false, MAX_DATE_EPOCH_MILLIS);\n      sortedValues = toAscendingPosVals(values, true);\n      min = sortedValues.get(0).val;\n      max = sortedValues.get(sortedValues.size() - 1).val;\n    } while (max > MAX_DATE_EPOCH_MILLIS || min < MIN_DATE_EPOCH_MILLIS);\n    long initialGap = BigInteger.valueOf(max).subtract(BigInteger.valueOf(min))\n        .divide(BigInteger.valueOf(numBuckets)).longValueExact();\n    DateGapCeiling gap = new DateGapCeiling(BigInteger.valueOf(max + initialGap).subtract(BigInteger.valueOf(min)) // padding for rounding\n        .divide(BigInteger.valueOf(numBuckets)).longValueExact());\n    List<Set<Integer>> docIdBucket = new ArrayList<>(numBuckets);\n    for (int i = 0 ; i < numBuckets ; ++i) {\n      docIdBucket.add(new HashSet<>());\n    }\n    int bucketNum = 0;\n    long minBucketVal = min;\n    // System.err.println(\"min:\" + Instant.ofEpochMilli(min) + \"   max: \" + Instant.ofEpochMilli(max) + \"   gap: \" + gap);\n    // System.err.println(\"bucketNum: \" + bucketNum + \"   minBucketVal: \" + Instant.ofEpochMilli(minBucketVal));\n    for (PosVal<Long> value : sortedValues) {\n      // System.err.println(\"value: \" + Instant.ofEpochMilli(value.val));\n      while (value.val >= gap.addTo(minBucketVal)) {\n        ++bucketNum;\n        minBucketVal = gap.addTo(minBucketVal);\n        // System.err.println(\"bucketNum: \" + bucketNum + \"   minBucketVal: \" + Instant.ofEpochMilli(minBucketVal));\n      }\n      docIdBucket.get(bucketNum).add(value.pos / 2); // each doc gets two consecutive values \n    }\n    for (int i = 0 ; i < numValues ; i += 2) {\n      assertU(adoc(\"id\", String.valueOf(i / 2),\n          docValuesField, Instant.ofEpochMilli(values.get(i)).toString(),\n          docValuesField, Instant.ofEpochMilli(values.get(i + 1)).toString(),\n          nonDocValuesField, Instant.ofEpochMilli(values.get(i)).toString(),\n          nonDocValuesField, Instant.ofEpochMilli(values.get(i + 1)).toString()));\n    }\n    assertU(commit());\n\n    String minDate = Instant.ofEpochMilli(min).toString();\n    String maxDate = Instant.ofEpochMilli(max).toString();\n    String[] testStrings = new String[numBuckets + 1];\n    testStrings[numBuckets] = \"//*[@numFound='\" + (numValues / 2) + \"']\";\n    minBucketVal = min;\n    for (int i = 0 ; i < numBuckets ; minBucketVal = gap.addTo(minBucketVal), ++i) {\n      testStrings[i] = \"//lst[@name='facet_counts']/lst[@name='facet_ranges']/lst[@name='\" + docValuesField\n          + \"']/lst[@name='counts']/int[@name='\" + Instant.ofEpochMilli(minBucketVal) \n          + \"'][.='\" + docIdBucket.get(i).size() + \"']\";\n    }\n\n    assertQ(req(\"q\", \"*:*\", \"facet\", \"true\", \"facet.range\", docValuesField,\n        \"facet.range.start\", minDate, \"facet.range.end\", maxDate,\n        \"facet.range.gap\", gap.toString(), \"indent\", \"on\"),\n        testStrings);\n    assertQ(req(\"q\", \"*:*\", \"facet\", \"true\", \"facet.range\", docValuesField,\n        \"facet.range.start\", minDate, \"facet.range.end\", maxDate,\n        \"facet.range.gap\", gap.toString(), \"facet.range.method\", \"dv\", \"indent\", \"on\"),\n        testStrings);\n\n    minBucketVal = min;\n    for (int i = 0 ; i < numBuckets ; minBucketVal = gap.addTo(minBucketVal), ++i) {\n      testStrings[i] = \"//lst[@name='facet_counts']/lst[@name='facet_ranges']/lst[@name='\" + nonDocValuesField\n          + \"']/lst[@name='counts']/int[@name='\" + Instant.ofEpochMilli(minBucketVal)\n          + \"'][.='\" + docIdBucket.get(i).size() + \"']\";\n    }\n    // Range Faceting with method = filter should work\n    assertQ(req(\"q\", \"*:*\", \"facet\", \"true\", \"facet.range\", nonDocValuesField,\n        \"facet.range.start\", minDate, \"facet.range.end\", maxDate,\n        \"facet.range.gap\", gap.toString(), \"facet.range.method\", \"filter\", \"indent\", \"on\"),\n        testStrings);\n    // this should actually use filter method instead of dv\n    assertQ(req(\"q\", \"*:*\", \"facet\", \"true\", \"facet.range\", nonDocValuesField,\n        \"facet.range.start\", minDate, \"facet.range.end\", maxDate,\n        \"facet.range.gap\", gap.toString(), \"facet.range.method\", \"dv\", \"indent\", \"on\"),\n        testStrings);\n  }\n\n","sourceOld":"  @Test\n  public void testDatePointFieldMultiValuedRangeFacet() throws Exception {\n    doTestDatePointFieldMultiValuedRangeFacet(\"number_p_dt_mv_dv\", \"number_p_dt_mv\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"aaf90fc29510e72665ac7934f34c3d1c25efad64","date":1500354819,"type":3,"author":"Cao Manh Dat","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/schema/TestPointFields#testDatePointFieldMultiValuedRangeFacet().mjava","pathOld":"solr/core/src/test/org/apache/solr/schema/TestPointFields#testDatePointFieldMultiValuedRangeFacet().mjava","sourceNew":"  @Test\n  public void testDatePointFieldMultiValuedRangeFacet() throws Exception {\n    String docValuesField = \"number_p_dt_mv_dv\";\n    SchemaField dvSchemaField = h.getCore().getLatestSchema().getField(docValuesField);\n    assertTrue(dvSchemaField.multiValued());\n    assertTrue(dvSchemaField.hasDocValues());\n    assertTrue(dvSchemaField.getType() instanceof PointField);\n    \n    String nonDocValuesField = \"number_p_dt_mv\";\n    SchemaField nonDvSchemaField = h.getCore().getLatestSchema().getField(nonDocValuesField);\n    assertTrue(nonDvSchemaField.multiValued());\n    assertFalse(nonDvSchemaField.hasDocValues());\n    assertTrue(nonDvSchemaField.getType() instanceof PointField);\n\n    int numValues = 20 * RANDOM_MULTIPLIER;\n    int numBuckets = numValues / 2;\n    List<Long> values;\n    List<PosVal<Long>> sortedValues;\n    long min, max;\n    do {\n      values = getRandomLongs(numValues, false, MAX_DATE_EPOCH_MILLIS);\n      sortedValues = toAscendingPosVals(values, true);\n      min = sortedValues.get(0).val;\n      max = sortedValues.get(sortedValues.size() - 1).val;\n    } while (max > MAX_DATE_EPOCH_MILLIS || min < MIN_DATE_EPOCH_MILLIS);\n    long initialGap = BigInteger.valueOf(max).subtract(BigInteger.valueOf(min))\n        .divide(BigInteger.valueOf(numBuckets)).longValueExact();\n    DateGapCeiling gap = new DateGapCeiling(BigInteger.valueOf(max + initialGap).subtract(BigInteger.valueOf(min)) // padding for rounding\n        .divide(BigInteger.valueOf(numBuckets)).longValueExact());\n    List<Set<Integer>> docIdBucket = new ArrayList<>(numBuckets);\n    for (int i = 0 ; i < numBuckets ; ++i) {\n      docIdBucket.add(new HashSet<>());\n    }\n    int bucketNum = 0;\n    long minBucketVal = min;\n    // System.err.println(\"min:\" + Instant.ofEpochMilli(min) + \"   max: \" + Instant.ofEpochMilli(max) + \"   gap: \" + gap);\n    // System.err.println(\"bucketNum: \" + bucketNum + \"   minBucketVal: \" + Instant.ofEpochMilli(minBucketVal));\n    for (PosVal<Long> value : sortedValues) {\n      // System.err.println(\"value: \" + Instant.ofEpochMilli(value.val));\n      while (value.val >= gap.addTo(minBucketVal)) {\n        ++bucketNum;\n        minBucketVal = gap.addTo(minBucketVal);\n        // System.err.println(\"bucketNum: \" + bucketNum + \"   minBucketVal: \" + Instant.ofEpochMilli(minBucketVal));\n      }\n      docIdBucket.get(bucketNum).add(value.pos / 2); // each doc gets two consecutive values \n    }\n    for (int i = 0 ; i < numValues ; i += 2) {\n      assertU(adoc(\"id\", String.valueOf(i / 2),\n          docValuesField, Instant.ofEpochMilli(values.get(i)).toString(),\n          docValuesField, Instant.ofEpochMilli(values.get(i + 1)).toString(),\n          nonDocValuesField, Instant.ofEpochMilli(values.get(i)).toString(),\n          nonDocValuesField, Instant.ofEpochMilli(values.get(i + 1)).toString()));\n    }\n    assertU(commit());\n\n    String minDate = Instant.ofEpochMilli(min).toString();\n    String maxDate = Instant.ofEpochMilli(max).toString();\n    String[] testStrings = new String[numBuckets + 1];\n    testStrings[numBuckets] = \"//*[@numFound='\" + (numValues / 2) + \"']\";\n    minBucketVal = min;\n    for (int i = 0 ; i < numBuckets ; minBucketVal = gap.addTo(minBucketVal), ++i) {\n      testStrings[i] = \"//lst[@name='facet_counts']/lst[@name='facet_ranges']/lst[@name='\" + docValuesField\n          + \"']/lst[@name='counts']/int[@name='\" + Instant.ofEpochMilli(minBucketVal) \n          + \"'][.='\" + docIdBucket.get(i).size() + \"']\";\n    }\n\n    assertQ(req(\"q\", \"*:*\", \"facet\", \"true\", \"facet.range\", docValuesField,\n        \"facet.range.start\", minDate, \"facet.range.end\", maxDate,\n        \"facet.range.gap\", gap.toString(), \"indent\", \"on\"),\n        testStrings);\n    assertQ(req(\"q\", \"*:*\", \"facet\", \"true\", \"facet.range\", docValuesField,\n        \"facet.range.start\", minDate, \"facet.range.end\", maxDate,\n        \"facet.range.gap\", gap.toString(), \"facet.range.method\", \"dv\", \"indent\", \"on\"),\n        testStrings);\n\n    minBucketVal = min;\n    for (int i = 0 ; i < numBuckets ; minBucketVal = gap.addTo(minBucketVal), ++i) {\n      testStrings[i] = \"//lst[@name='facet_counts']/lst[@name='facet_ranges']/lst[@name='\" + nonDocValuesField\n          + \"']/lst[@name='counts']/int[@name='\" + Instant.ofEpochMilli(minBucketVal)\n          + \"'][.='\" + docIdBucket.get(i).size() + \"']\";\n    }\n    // Range Faceting with method = filter should work\n    assertQ(req(\"q\", \"*:*\", \"facet\", \"true\", \"facet.range\", nonDocValuesField,\n        \"facet.range.start\", minDate, \"facet.range.end\", maxDate,\n        \"facet.range.gap\", gap.toString(), \"facet.range.method\", \"filter\", \"indent\", \"on\"),\n        testStrings);\n    // this should actually use filter method instead of dv\n    assertQ(req(\"q\", \"*:*\", \"facet\", \"true\", \"facet.range\", nonDocValuesField,\n        \"facet.range.start\", minDate, \"facet.range.end\", maxDate,\n        \"facet.range.gap\", gap.toString(), \"facet.range.method\", \"dv\", \"indent\", \"on\"),\n        testStrings);\n  }\n\n","sourceOld":"  @Test\n  public void testDatePointFieldMultiValuedRangeFacet() throws Exception {\n    doTestDatePointFieldMultiValuedRangeFacet(\"number_p_dt_mv_dv\", \"number_p_dt_mv\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"daa9f76a48e97bb2d40fc67ecdaad33d166d596e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"aaf90fc29510e72665ac7934f34c3d1c25efad64":["daa9f76a48e97bb2d40fc67ecdaad33d166d596e","17e844d4f9ba6804f10747d7e51e83a9a8868c94"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"17e844d4f9ba6804f10747d7e51e83a9a8868c94":["daa9f76a48e97bb2d40fc67ecdaad33d166d596e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["17e844d4f9ba6804f10747d7e51e83a9a8868c94"]},"commit2Childs":{"daa9f76a48e97bb2d40fc67ecdaad33d166d596e":["aaf90fc29510e72665ac7934f34c3d1c25efad64","17e844d4f9ba6804f10747d7e51e83a9a8868c94"],"aaf90fc29510e72665ac7934f34c3d1c25efad64":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["daa9f76a48e97bb2d40fc67ecdaad33d166d596e"],"17e844d4f9ba6804f10747d7e51e83a9a8868c94":["aaf90fc29510e72665ac7934f34c3d1c25efad64","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["aaf90fc29510e72665ac7934f34c3d1c25efad64","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}