{"path":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#rehashPostings(int).mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#rehashPostings(int).mjava","pathOld":"src/java/org/apache/lucene/index/TermsHashPerField#rehashPostings(int).mjava","sourceNew":"  /** Called when postings hash is too small (> 50%\n   *  occupied) or too large (< 20% occupied). */\n  void rehashPostings(final int newSize) {\n\n    final int newMask = newSize-1;\n\n    RawPostingList[] newHash = new RawPostingList[newSize];\n    for(int i=0;i<postingsHashSize;i++) {\n      RawPostingList p0 = postingsHash[i];\n      if (p0 != null) {\n        int code;\n        if (perThread.primary) {\n          final int start = p0.textStart & DocumentsWriter.CHAR_BLOCK_MASK;\n          final char[] text = charPool.buffers[p0.textStart >> DocumentsWriter.CHAR_BLOCK_SHIFT];\n          int pos = start;\n          while(text[pos] != 0xffff)\n            pos++;\n          code = 0;\n          while (pos > start)\n            code = (code*31) + text[--pos];\n        } else\n          code = p0.textStart;\n\n        int hashPos = code & newMask;\n        assert hashPos >= 0;\n        if (newHash[hashPos] != null) {\n          final int inc = ((code>>8)+code)|1;\n          do {\n            code += inc;\n            hashPos = code & newMask;\n          } while (newHash[hashPos] != null);\n        }\n        newHash[hashPos] = p0;\n      }\n    }\n\n    postingsHashMask = newMask;\n    postingsHash = newHash;\n    postingsHashSize = newSize;\n    postingsHashHalfSize = newSize >> 1;\n  }\n\n","sourceOld":"  /** Called when postings hash is too small (> 50%\n   *  occupied) or too large (< 20% occupied). */\n  void rehashPostings(final int newSize) {\n\n    final int newMask = newSize-1;\n\n    RawPostingList[] newHash = new RawPostingList[newSize];\n    for(int i=0;i<postingsHashSize;i++) {\n      RawPostingList p0 = postingsHash[i];\n      if (p0 != null) {\n        int code;\n        if (perThread.primary) {\n          final int start = p0.textStart & DocumentsWriter.CHAR_BLOCK_MASK;\n          final char[] text = charPool.buffers[p0.textStart >> DocumentsWriter.CHAR_BLOCK_SHIFT];\n          int pos = start;\n          while(text[pos] != 0xffff)\n            pos++;\n          code = 0;\n          while (pos > start)\n            code = (code*31) + text[--pos];\n        } else\n          code = p0.textStart;\n\n        int hashPos = code & newMask;\n        assert hashPos >= 0;\n        if (newHash[hashPos] != null) {\n          final int inc = ((code>>8)+code)|1;\n          do {\n            code += inc;\n            hashPos = code & newMask;\n          } while (newHash[hashPos] != null);\n        }\n        newHash[hashPos] = p0;\n      }\n    }\n\n    postingsHashMask = newMask;\n    postingsHash = newHash;\n    postingsHashSize = newSize;\n    postingsHashHalfSize = newSize >> 1;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"741ed634ca00f7fcf06280bd2bf3f7eb9b605cc9","date":1269379515,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#rehashPostings(int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#rehashPostings(int).mjava","sourceNew":"  /** Called when postings hash is too small (> 50%\n   *  occupied) or too large (< 20% occupied). */\n  void rehashPostings(final int newSize) {\n\n    final int newMask = newSize-1;\n\n    int[] newHash = new int[newSize];\n    Arrays.fill(newHash, -1);\n    for(int i=0;i<postingsHashSize;i++) {\n      int termID = postingsHash[i];\n      if (termID != -1) {\n        int code;\n        if (perThread.primary) {\n          final int textStart = postingsArray.textStarts[termID];\n          final int start = textStart & DocumentsWriter.CHAR_BLOCK_MASK;\n          final char[] text = charPool.buffers[textStart >> DocumentsWriter.CHAR_BLOCK_SHIFT];\n          int pos = start;\n          while(text[pos] != 0xffff)\n            pos++;\n          code = 0;\n          while (pos > start)\n            code = (code*31) + text[--pos];\n        } else\n          code = postingsArray.textStarts[termID];\n\n        int hashPos = code & newMask;\n        assert hashPos >= 0;\n        if (newHash[hashPos] != -1) {\n          final int inc = ((code>>8)+code)|1;\n          do {\n            code += inc;\n            hashPos = code & newMask;\n          } while (newHash[hashPos] != -1);\n        }\n        newHash[hashPos] = termID;\n      }\n    }\n\n    postingsHashMask = newMask;\n    postingsHash = newHash;\n    postingsHashSize = newSize;\n    postingsHashHalfSize = newSize >> 1;\n  }\n\n","sourceOld":"  /** Called when postings hash is too small (> 50%\n   *  occupied) or too large (< 20% occupied). */\n  void rehashPostings(final int newSize) {\n\n    final int newMask = newSize-1;\n\n    RawPostingList[] newHash = new RawPostingList[newSize];\n    for(int i=0;i<postingsHashSize;i++) {\n      RawPostingList p0 = postingsHash[i];\n      if (p0 != null) {\n        int code;\n        if (perThread.primary) {\n          final int start = p0.textStart & DocumentsWriter.CHAR_BLOCK_MASK;\n          final char[] text = charPool.buffers[p0.textStart >> DocumentsWriter.CHAR_BLOCK_SHIFT];\n          int pos = start;\n          while(text[pos] != 0xffff)\n            pos++;\n          code = 0;\n          while (pos > start)\n            code = (code*31) + text[--pos];\n        } else\n          code = p0.textStart;\n\n        int hashPos = code & newMask;\n        assert hashPos >= 0;\n        if (newHash[hashPos] != null) {\n          final int inc = ((code>>8)+code)|1;\n          do {\n            code += inc;\n            hashPos = code & newMask;\n          } while (newHash[hashPos] != null);\n        }\n        newHash[hashPos] = p0;\n      }\n    }\n\n    postingsHashMask = newMask;\n    postingsHash = newHash;\n    postingsHashSize = newSize;\n    postingsHashHalfSize = newSize >> 1;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"955c32f886db6f6356c9fcdea6b1f1cb4effda24","date":1270581567,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#rehashPostings(int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#rehashPostings(int).mjava","sourceNew":"  /** Called when postings hash is too small (> 50%\n   *  occupied) or too large (< 20% occupied). */\n  void rehashPostings(final int newSize) {\n\n    final int newMask = newSize-1;\n\n    int[] newHash = new int[newSize];\n    Arrays.fill(newHash, -1);\n    for(int i=0;i<postingsHashSize;i++) {\n      int termID = postingsHash[i];\n      if (termID != -1) {\n        int code;\n        if (perThread.primary) {\n          final int textStart = postingsArray.textStarts[termID];\n          final int start = textStart & DocumentsWriter.BYTE_BLOCK_MASK;\n          final byte[] text = bytePool.buffers[textStart >> DocumentsWriter.BYTE_BLOCK_SHIFT];\n          code = 0;\n\n          final int len;\n          int pos;\n          if ((text[start] & 0x80) == 0) {\n            // length is 1 byte\n            len = text[start];\n            pos = start+1;\n          } else {\n            len = (text[start]&0x7f) + ((text[start+1]&0xff)<<7);\n            pos = start+2;\n          }\n\n          final int endPos = pos+len;\n          while(pos < endPos) {\n            code = (code*31) + text[pos++];\n          }\n        } else {\n          code = postingsArray.textStarts[termID];\n        }\n\n        int hashPos = code & newMask;\n        assert hashPos >= 0;\n        if (newHash[hashPos] != -1) {\n          final int inc = ((code>>8)+code)|1;\n          do {\n            code += inc;\n            hashPos = code & newMask;\n          } while (newHash[hashPos] != -1);\n        }\n        newHash[hashPos] = termID;\n      }\n    }\n\n    postingsHashMask = newMask;\n    postingsHash = newHash;\n\n    postingsHashSize = newSize;\n    postingsHashHalfSize = newSize >> 1;\n  }\n\n","sourceOld":"  /** Called when postings hash is too small (> 50%\n   *  occupied) or too large (< 20% occupied). */\n  void rehashPostings(final int newSize) {\n\n    final int newMask = newSize-1;\n\n    int[] newHash = new int[newSize];\n    Arrays.fill(newHash, -1);\n    for(int i=0;i<postingsHashSize;i++) {\n      int termID = postingsHash[i];\n      if (termID != -1) {\n        int code;\n        if (perThread.primary) {\n          final int textStart = postingsArray.textStarts[termID];\n          final int start = textStart & DocumentsWriter.CHAR_BLOCK_MASK;\n          final char[] text = charPool.buffers[textStart >> DocumentsWriter.CHAR_BLOCK_SHIFT];\n          int pos = start;\n          while(text[pos] != 0xffff)\n            pos++;\n          code = 0;\n          while (pos > start)\n            code = (code*31) + text[--pos];\n        } else\n          code = postingsArray.textStarts[termID];\n\n        int hashPos = code & newMask;\n        assert hashPos >= 0;\n        if (newHash[hashPos] != -1) {\n          final int inc = ((code>>8)+code)|1;\n          do {\n            code += inc;\n            hashPos = code & newMask;\n          } while (newHash[hashPos] != -1);\n        }\n        newHash[hashPos] = termID;\n      }\n    }\n\n    postingsHashMask = newMask;\n    postingsHash = newHash;\n    postingsHashSize = newSize;\n    postingsHashHalfSize = newSize >> 1;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6c18273ea5b3974d2f30117f46f1ae416c28f727","date":1279708040,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#rehashPostings(int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#rehashPostings(int).mjava","sourceNew":"  /** Called when postings hash is too small (> 50%\n   *  occupied) or too large (< 20% occupied). */\n  void rehashPostings(final int newSize) {\n\n    final int newMask = newSize-1;\n\n    int[] newHash = new int[newSize];\n    Arrays.fill(newHash, -1);\n    for(int i=0;i<postingsHashSize;i++) {\n      int termID = postingsHash[i];\n      if (termID != -1) {\n        int code;\n        if (termsHash.primary) {\n          final int textStart = postingsArray.textStarts[termID];\n          final int start = textStart & DocumentsWriterRAMAllocator.BYTE_BLOCK_MASK;\n          final byte[] text = bytePool.buffers[textStart >> DocumentsWriterRAMAllocator.BYTE_BLOCK_SHIFT];\n          code = 0;\n\n          final int len;\n          int pos;\n          if ((text[start] & 0x80) == 0) {\n            // length is 1 byte\n            len = text[start];\n            pos = start+1;\n          } else {\n            len = (text[start]&0x7f) + ((text[start+1]&0xff)<<7);\n            pos = start+2;\n          }\n\n          final int endPos = pos+len;\n          while(pos < endPos) {\n            code = (code*31) + text[pos++];\n          }\n        } else {\n          code = postingsArray.textStarts[termID];\n        }\n\n        int hashPos = code & newMask;\n        assert hashPos >= 0;\n        if (newHash[hashPos] != -1) {\n          final int inc = ((code>>8)+code)|1;\n          do {\n            code += inc;\n            hashPos = code & newMask;\n          } while (newHash[hashPos] != -1);\n        }\n        newHash[hashPos] = termID;\n      }\n    }\n\n    postingsHashMask = newMask;\n    postingsHash = newHash;\n\n    postingsHashSize = newSize;\n    postingsHashHalfSize = newSize >> 1;\n  }\n\n","sourceOld":"  /** Called when postings hash is too small (> 50%\n   *  occupied) or too large (< 20% occupied). */\n  void rehashPostings(final int newSize) {\n\n    final int newMask = newSize-1;\n\n    int[] newHash = new int[newSize];\n    Arrays.fill(newHash, -1);\n    for(int i=0;i<postingsHashSize;i++) {\n      int termID = postingsHash[i];\n      if (termID != -1) {\n        int code;\n        if (perThread.primary) {\n          final int textStart = postingsArray.textStarts[termID];\n          final int start = textStart & DocumentsWriter.BYTE_BLOCK_MASK;\n          final byte[] text = bytePool.buffers[textStart >> DocumentsWriter.BYTE_BLOCK_SHIFT];\n          code = 0;\n\n          final int len;\n          int pos;\n          if ((text[start] & 0x80) == 0) {\n            // length is 1 byte\n            len = text[start];\n            pos = start+1;\n          } else {\n            len = (text[start]&0x7f) + ((text[start+1]&0xff)<<7);\n            pos = start+2;\n          }\n\n          final int endPos = pos+len;\n          while(pos < endPos) {\n            code = (code*31) + text[pos++];\n          }\n        } else {\n          code = postingsArray.textStarts[termID];\n        }\n\n        int hashPos = code & newMask;\n        assert hashPos >= 0;\n        if (newHash[hashPos] != -1) {\n          final int inc = ((code>>8)+code)|1;\n          do {\n            code += inc;\n            hashPos = code & newMask;\n          } while (newHash[hashPos] != -1);\n        }\n        newHash[hashPos] = termID;\n      }\n    }\n\n    postingsHashMask = newMask;\n    postingsHash = newHash;\n\n    postingsHashSize = newSize;\n    postingsHashHalfSize = newSize >> 1;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5d6c52f55ea3ba9a5b1d5a6dd17f79bc7d308392","date":1286023472,"type":4,"author":"Simon Willnauer","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#rehashPostings(int).mjava","sourceNew":null,"sourceOld":"  /** Called when postings hash is too small (> 50%\n   *  occupied) or too large (< 20% occupied). */\n  void rehashPostings(final int newSize) {\n\n    final int newMask = newSize-1;\n\n    int[] newHash = new int[newSize];\n    Arrays.fill(newHash, -1);\n    for(int i=0;i<postingsHashSize;i++) {\n      int termID = postingsHash[i];\n      if (termID != -1) {\n        int code;\n        if (perThread.primary) {\n          final int textStart = postingsArray.textStarts[termID];\n          final int start = textStart & DocumentsWriter.BYTE_BLOCK_MASK;\n          final byte[] text = bytePool.buffers[textStart >> DocumentsWriter.BYTE_BLOCK_SHIFT];\n          code = 0;\n\n          final int len;\n          int pos;\n          if ((text[start] & 0x80) == 0) {\n            // length is 1 byte\n            len = text[start];\n            pos = start+1;\n          } else {\n            len = (text[start]&0x7f) + ((text[start+1]&0xff)<<7);\n            pos = start+2;\n          }\n\n          final int endPos = pos+len;\n          while(pos < endPos) {\n            code = (code*31) + text[pos++];\n          }\n        } else {\n          code = postingsArray.textStarts[termID];\n        }\n\n        int hashPos = code & newMask;\n        assert hashPos >= 0;\n        if (newHash[hashPos] != -1) {\n          final int inc = ((code>>8)+code)|1;\n          do {\n            code += inc;\n            hashPos = code & newMask;\n          } while (newHash[hashPos] != -1);\n        }\n        newHash[hashPos] = termID;\n      }\n    }\n\n    postingsHashMask = newMask;\n    postingsHash = newHash;\n\n    postingsHashSize = newSize;\n    postingsHashHalfSize = newSize >> 1;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":4,"author":"Michael Busch","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#rehashPostings(int).mjava","sourceNew":null,"sourceOld":"  /** Called when postings hash is too small (> 50%\n   *  occupied) or too large (< 20% occupied). */\n  void rehashPostings(final int newSize) {\n\n    final int newMask = newSize-1;\n\n    int[] newHash = new int[newSize];\n    Arrays.fill(newHash, -1);\n    for(int i=0;i<postingsHashSize;i++) {\n      int termID = postingsHash[i];\n      if (termID != -1) {\n        int code;\n        if (termsHash.primary) {\n          final int textStart = postingsArray.textStarts[termID];\n          final int start = textStart & DocumentsWriterRAMAllocator.BYTE_BLOCK_MASK;\n          final byte[] text = bytePool.buffers[textStart >> DocumentsWriterRAMAllocator.BYTE_BLOCK_SHIFT];\n          code = 0;\n\n          final int len;\n          int pos;\n          if ((text[start] & 0x80) == 0) {\n            // length is 1 byte\n            len = text[start];\n            pos = start+1;\n          } else {\n            len = (text[start]&0x7f) + ((text[start+1]&0xff)<<7);\n            pos = start+2;\n          }\n\n          final int endPos = pos+len;\n          while(pos < endPos) {\n            code = (code*31) + text[pos++];\n          }\n        } else {\n          code = postingsArray.textStarts[termID];\n        }\n\n        int hashPos = code & newMask;\n        assert hashPos >= 0;\n        if (newHash[hashPos] != -1) {\n          final int inc = ((code>>8)+code)|1;\n          do {\n            code += inc;\n            hashPos = code & newMask;\n          } while (newHash[hashPos] != -1);\n        }\n        newHash[hashPos] = termID;\n      }\n    }\n\n    postingsHashMask = newMask;\n    postingsHash = newHash;\n\n    postingsHashSize = newSize;\n    postingsHashHalfSize = newSize >> 1;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"5d6c52f55ea3ba9a5b1d5a6dd17f79bc7d308392":["955c32f886db6f6356c9fcdea6b1f1cb4effda24"],"6c18273ea5b3974d2f30117f46f1ae416c28f727":["955c32f886db6f6356c9fcdea6b1f1cb4effda24"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"741ed634ca00f7fcf06280bd2bf3f7eb9b605cc9":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"955c32f886db6f6356c9fcdea6b1f1cb4effda24":["741ed634ca00f7fcf06280bd2bf3f7eb9b605cc9"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["6c18273ea5b3974d2f30117f46f1ae416c28f727","5d6c52f55ea3ba9a5b1d5a6dd17f79bc7d308392"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["5d6c52f55ea3ba9a5b1d5a6dd17f79bc7d308392"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"5d6c52f55ea3ba9a5b1d5a6dd17f79bc7d308392":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"6c18273ea5b3974d2f30117f46f1ae416c28f727":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"741ed634ca00f7fcf06280bd2bf3f7eb9b605cc9":["955c32f886db6f6356c9fcdea6b1f1cb4effda24"],"955c32f886db6f6356c9fcdea6b1f1cb4effda24":["5d6c52f55ea3ba9a5b1d5a6dd17f79bc7d308392","6c18273ea5b3974d2f30117f46f1ae416c28f727"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["741ed634ca00f7fcf06280bd2bf3f7eb9b605cc9"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}