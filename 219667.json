{"path":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyShardSplitTest#doTest().mjava","commits":[{"id":"0beaed456aa3358e5e4a99ea2aea994ef6c81de3","date":1365434191,"type":0,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyShardSplitTest#doTest().mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n    \n    waitForThingsToLevelOut(15);\n    printLayout();\n    \n    PlainIdRouter router = new PlainIdRouter();\n    final List<DocRouter.Range> ranges = router.partitionRange(2,\n        router.fullRange());\n    final int[] docCounts = new int[ranges.size()];\n    Thread indexThread = null;\n    OverseerRestarter killer = null;\n    Thread killerThread = null;\n    final SolrServer solrServer = clients.get(0);\n    \n    try {\n      solrServer.deleteByQuery(\"*:*\");\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument();\n        doc.addField(\"id\", i);\n        solrServer.add(doc);\n        \n        // todo - hook in custom hashing\n        byte[] bytes = String.valueOf(i).getBytes(\"UTF-8\");\n        int hash = Hash.murmurhash3_x86_32(bytes, 0, bytes.length, 0);\n        for (int i2 = 0; i2 < ranges.size(); i2++) {\n          DocRouter.Range range = ranges.get(i2);\n          if (range.includes(hash)) docCounts[i2]++;\n        }\n      }\n      solrServer.commit();\n      \n      waitForRecoveriesToFinish(false);\n      \n      indexThread = new Thread() {\n        @Override\n        public void run() {\n          for (int i = 101; i < 201; i++) {\n            try {\n              SolrInputDocument doc = new SolrInputDocument();\n              doc.addField(\"id\", i);\n              solrServer.add(doc);\n              \n              // todo - hook in custom hashing\n              byte[] bytes = String.valueOf(i).getBytes(\"UTF-8\");\n              int hash = Hash.murmurhash3_x86_32(bytes, 0, bytes.length, 0);\n              for (int i2 = 0; i2 < ranges.size(); i2++) {\n                DocRouter.Range range = ranges.get(i2);\n                if (range.includes(hash)) docCounts[i2]++;\n              }\n              Thread.sleep(100);\n            } catch (Exception e) {\n              log.error(\"Exception while adding doc\", e);\n            }\n          }\n        }\n      };\n      indexThread.start();\n      \n      // kill the leader\n      CloudJettyRunner leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      log.info(\"Cluster State: \"\n          + cloudClient.getZkStateReader().getClusterState());\n      \n      chaosMonkey.killJetty(leaderJetty);\n      \n      Thread.sleep(2000);\n      \n      waitForThingsToLevelOut(90);\n      \n      Thread.sleep(1000);\n      checkShardConsistency(false, true);\n      \n      CloudJettyRunner deadJetty = leaderJetty;\n      \n      // TODO: Check total docs ?\n      // long cloudClientDocs = cloudClient.query(new\n      // SolrQuery(\"*:*\")).getResults().getNumFound();\n      \n      // Wait until new leader is elected\n      while (deadJetty == leaderJetty) {\n        updateMappingsFromZk(this.jettys, this.clients);\n        leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      }\n      \n      // bring back dead node\n      ChaosMonkey.start(deadJetty.jetty); // he is not the leader anymore\n      \n      waitTillRecovered();\n      \n      // Kill the overseer\n      // TODO: Actually kill the Overseer instance\n      killer = new OverseerRestarter(zkServer.getZkAddress());\n      killerThread = new Thread(killer);\n      killerThread.start();\n      killCounter.incrementAndGet();\n      \n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(\"action\",\n          CollectionParams.CollectionAction.SPLITSHARD.toString());\n      params.set(\"collection\", \"collection1\");\n      params.set(\"shard\", \"shard1\");\n      SolrRequest request = new QueryRequest(params);\n      request.setPath(\"/admin/collections\");\n      \n      String baseUrl = ((HttpSolrServer) shardToJetty.get(\"shard1\").get(0).client.solrClient)\n          .getBaseURL();\n      baseUrl = baseUrl.substring(0, baseUrl.length() - \"collection1\".length());\n      \n      HttpSolrServer baseServer = new HttpSolrServer(baseUrl);\n      baseServer.setConnectionTimeout(15000);\n      baseServer.setSoTimeout((int) (CollectionsHandler.DEFAULT_ZK_TIMEOUT * 5));\n      baseServer.request(request);\n      \n      System.out.println(\"Layout after split: \\n\");\n      printLayout();\n      \n       // distributed commit on all shards\n    } finally {\n      if(indexThread != null)\n        indexThread.join();\n      if (solrServer != null)\n        solrServer.commit();\n      if (killer != null) {\n        killer.run = false;\n        if (killerThread != null) {\n          killerThread.join();\n        }\n      }\n    }\n    \n    SolrQuery query = new SolrQuery(\"*:*\").setRows(0).setFields(\"id\");\n    query.set(\"distrib\", false);\n    \n    String shard1_0_url = cloudClient.getZkStateReader().getLeaderUrl(\n        AbstractFullDistribZkTestBase.DEFAULT_COLLECTION, \"shard1_0\",\n        DEFAULT_CONNECTION_TIMEOUT);\n    HttpSolrServer shard1_0Server = new HttpSolrServer(shard1_0_url);\n    QueryResponse response = shard1_0Server.query(query);\n    long shard10Count = response.getResults().getNumFound();\n    System.out.println(\"Resp: shard: shard1_0 url: \" + shard1_0_url + \"\\n\"\n        + response.getResponse());\n    \n    String shard1_1_url = cloudClient.getZkStateReader().getLeaderUrl(\n        AbstractFullDistribZkTestBase.DEFAULT_COLLECTION, \"shard1_1\",\n        DEFAULT_CONNECTION_TIMEOUT);\n    HttpSolrServer shard1_1Server = new HttpSolrServer(shard1_1_url);\n    response = shard1_1Server.query(query);\n    long shard11Count = response.getResults().getNumFound();\n    System.out.println(\"Resp: shard: shard1_1 url: \" + shard1_1_url + \"\\n\"\n        + response.getResponse());\n    \n    for (int i = 0; i < docCounts.length; i++) {\n      int docCount = docCounts[i];\n      System.out\n          .println(\"Expected docCount for shard1_\" + i + \" = \" + docCount);\n    }\n    \n    assertEquals(\"Wrong doc count on shard1_0\", docCounts[0], shard10Count);\n    assertEquals(\"Wrong doc count on shard1_1\", docCounts[1], shard11Count);\n    \n    // todo - can't call waitForThingsToLevelOut because it looks for\n    // jettys of all shards\n    // and the new sub-shards don't have any.\n    waitForRecoveriesToFinish(true);\n    // waitForThingsToLevelOut(15);\n    \n    // todo - more and better tests\n    \n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e4daf0e37630dc4d06c6bcf53c19bfb09e0ba6dd","date":1365523175,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyShardSplitTest#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyShardSplitTest#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n    \n    waitForThingsToLevelOut(15);\n    printLayout();\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n    Thread indexThread = null;\n    OverseerRestarter killer = null;\n    Thread killerThread = null;\n    final SolrServer solrServer = clients.get(0);\n    \n    try {\n      solrServer.deleteByQuery(\"*:*\");\n      for (int i = 0; i < 100; i++) {\n        indexr(\"id\", i);\n        \n        // todo - hook in custom hashing\n        byte[] bytes = String.valueOf(i).getBytes(\"UTF-8\");\n        int hash = Hash.murmurhash3_x86_32(bytes, 0, bytes.length, 0);\n        for (int i2 = 0; i2 < ranges.size(); i2++) {\n          DocRouter.Range range = ranges.get(i2);\n          if (range.includes(hash)) docCounts[i2]++;\n        }\n      }\n      solrServer.commit();\n      \n      waitForRecoveriesToFinish(false);\n      \n      indexThread = new Thread() {\n        @Override\n        public void run() {\n          for (int i = 101; i < 201; i++) {\n            try {\n              indexr(\"id\", i);\n              \n              // todo - hook in custom hashing\n              byte[] bytes = String.valueOf(i).getBytes(\"UTF-8\");\n              int hash = Hash.murmurhash3_x86_32(bytes, 0, bytes.length, 0);\n              for (int i2 = 0; i2 < ranges.size(); i2++) {\n                DocRouter.Range range = ranges.get(i2);\n                if (range.includes(hash)) docCounts[i2]++;\n              }\n              Thread.sleep(100);\n            } catch (Exception e) {\n              log.error(\"Exception while adding doc\", e);\n            }\n          }\n        }\n      };\n      indexThread.start();\n      \n      // kill the leader\n      CloudJettyRunner leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      log.info(\"Cluster State: \"\n          + cloudClient.getZkStateReader().getClusterState());\n      \n      chaosMonkey.killJetty(leaderJetty);\n      \n      Thread.sleep(2000);\n      \n      waitForThingsToLevelOut(90);\n      \n      Thread.sleep(1000);\n      checkShardConsistency(false, true);\n      \n      CloudJettyRunner deadJetty = leaderJetty;\n      \n      // TODO: Check total docs ?\n      // long cloudClientDocs = cloudClient.query(new\n      // SolrQuery(\"*:*\")).getResults().getNumFound();\n      \n      // Wait until new leader is elected\n      while (deadJetty == leaderJetty) {\n        updateMappingsFromZk(this.jettys, this.clients);\n        leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      }\n      \n      // bring back dead node\n      ChaosMonkey.start(deadJetty.jetty); // he is not the leader anymore\n      \n      waitTillRecovered();\n      \n      // Kill the overseer\n      // TODO: Actually kill the Overseer instance\n      killer = new OverseerRestarter(zkServer.getZkAddress());\n      killerThread = new Thread(killer);\n      killerThread.start();\n      killCounter.incrementAndGet();\n      \n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(\"action\",\n          CollectionParams.CollectionAction.SPLITSHARD.toString());\n      params.set(\"collection\", \"collection1\");\n      params.set(\"shard\", \"shard1\");\n      SolrRequest request = new QueryRequest(params);\n      request.setPath(\"/admin/collections\");\n      \n      String baseUrl = ((HttpSolrServer) shardToJetty.get(\"shard1\").get(0).client.solrClient)\n          .getBaseURL();\n      baseUrl = baseUrl.substring(0, baseUrl.length() - \"collection1\".length());\n      \n      HttpSolrServer baseServer = new HttpSolrServer(baseUrl);\n      baseServer.setConnectionTimeout(15000);\n      baseServer.setSoTimeout((int) (CollectionsHandler.DEFAULT_ZK_TIMEOUT * 5));\n      baseServer.request(request);\n      \n      System.out.println(\"Layout after split: \\n\");\n      printLayout();\n      \n       // distributed commit on all shards\n    } finally {\n      if(indexThread != null)\n        indexThread.join();\n      if (solrServer != null)\n        solrServer.commit();\n      if (killer != null) {\n        killer.run = false;\n        if (killerThread != null) {\n          killerThread.join();\n        }\n      }\n    }\n    \n    SolrQuery query = new SolrQuery(\"*:*\").setRows(0).setFields(\"id\");\n    query.set(\"distrib\", false);\n    \n    String shard1_0_url = cloudClient.getZkStateReader().getLeaderUrl(\n        AbstractFullDistribZkTestBase.DEFAULT_COLLECTION, \"shard1_0\",\n        DEFAULT_CONNECTION_TIMEOUT);\n    HttpSolrServer shard1_0Server = new HttpSolrServer(shard1_0_url);\n    QueryResponse response = shard1_0Server.query(query);\n    long shard10Count = response.getResults().getNumFound();\n    System.out.println(\"Resp: shard: shard1_0 url: \" + shard1_0_url + \"\\n\"\n        + response.getResponse());\n    \n    String shard1_1_url = cloudClient.getZkStateReader().getLeaderUrl(\n        AbstractFullDistribZkTestBase.DEFAULT_COLLECTION, \"shard1_1\",\n        DEFAULT_CONNECTION_TIMEOUT);\n    HttpSolrServer shard1_1Server = new HttpSolrServer(shard1_1_url);\n    response = shard1_1Server.query(query);\n    long shard11Count = response.getResults().getNumFound();\n    System.out.println(\"Resp: shard: shard1_1 url: \" + shard1_1_url + \"\\n\"\n        + response.getResponse());\n    \n    for (int i = 0; i < docCounts.length; i++) {\n      int docCount = docCounts[i];\n      System.out\n          .println(\"Expected docCount for shard1_\" + i + \" = \" + docCount);\n    }\n    \n    assertEquals(\"Wrong doc count on shard1_0\", docCounts[0], shard10Count);\n    assertEquals(\"Wrong doc count on shard1_1\", docCounts[1], shard11Count);\n\n    Slice slice1_0 = null, slice1_1 = null;\n    int i = 0;\n    for (i = 0; i < 10; i++) {\n      ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n      zkStateReader.updateClusterState(true);\n      clusterState = zkStateReader.getClusterState();\n      slice1_0 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, \"shard1_0\");\n      slice1_1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, \"shard1_1\");\n      if (Slice.ACTIVE.equals(slice1_0.getState()) && Slice.ACTIVE.equals(slice1_1.getState()))\n        break;\n      Thread.sleep(500);\n    }\n\n    log.info(\"ShardSplitTest waited for {} ms for shard state to be set to active\", i * 500);\n\n    assertNotNull(\"Cluster state does not contain shard1_0\", slice1_0);\n    assertNotNull(\"Cluster state does not contain shard1_0\", slice1_1);\n    assertEquals(\"shard1_0 is not active\", Slice.ACTIVE, slice1_0.getState());\n    assertEquals(\"shard1_1 is not active\", Slice.ACTIVE, slice1_1.getState());\n    assertEquals(\"Wrong number of replicas created for shard1_0\", numReplicas, slice1_0.getReplicas().size());\n    assertEquals(\"Wrong number of replicas created for shard1_1\", numReplicas, slice1_1.getReplicas().size());\n    \n    // todo - can't call waitForThingsToLevelOut because it looks for\n    // jettys of all shards\n    // and the new sub-shards don't have any.\n    waitForRecoveriesToFinish(true);\n    // waitForThingsToLevelOut(15);\n    \n    // todo - more and better tests\n    \n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n    \n    waitForThingsToLevelOut(15);\n    printLayout();\n    \n    PlainIdRouter router = new PlainIdRouter();\n    final List<DocRouter.Range> ranges = router.partitionRange(2,\n        router.fullRange());\n    final int[] docCounts = new int[ranges.size()];\n    Thread indexThread = null;\n    OverseerRestarter killer = null;\n    Thread killerThread = null;\n    final SolrServer solrServer = clients.get(0);\n    \n    try {\n      solrServer.deleteByQuery(\"*:*\");\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument();\n        doc.addField(\"id\", i);\n        solrServer.add(doc);\n        \n        // todo - hook in custom hashing\n        byte[] bytes = String.valueOf(i).getBytes(\"UTF-8\");\n        int hash = Hash.murmurhash3_x86_32(bytes, 0, bytes.length, 0);\n        for (int i2 = 0; i2 < ranges.size(); i2++) {\n          DocRouter.Range range = ranges.get(i2);\n          if (range.includes(hash)) docCounts[i2]++;\n        }\n      }\n      solrServer.commit();\n      \n      waitForRecoveriesToFinish(false);\n      \n      indexThread = new Thread() {\n        @Override\n        public void run() {\n          for (int i = 101; i < 201; i++) {\n            try {\n              SolrInputDocument doc = new SolrInputDocument();\n              doc.addField(\"id\", i);\n              solrServer.add(doc);\n              \n              // todo - hook in custom hashing\n              byte[] bytes = String.valueOf(i).getBytes(\"UTF-8\");\n              int hash = Hash.murmurhash3_x86_32(bytes, 0, bytes.length, 0);\n              for (int i2 = 0; i2 < ranges.size(); i2++) {\n                DocRouter.Range range = ranges.get(i2);\n                if (range.includes(hash)) docCounts[i2]++;\n              }\n              Thread.sleep(100);\n            } catch (Exception e) {\n              log.error(\"Exception while adding doc\", e);\n            }\n          }\n        }\n      };\n      indexThread.start();\n      \n      // kill the leader\n      CloudJettyRunner leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      log.info(\"Cluster State: \"\n          + cloudClient.getZkStateReader().getClusterState());\n      \n      chaosMonkey.killJetty(leaderJetty);\n      \n      Thread.sleep(2000);\n      \n      waitForThingsToLevelOut(90);\n      \n      Thread.sleep(1000);\n      checkShardConsistency(false, true);\n      \n      CloudJettyRunner deadJetty = leaderJetty;\n      \n      // TODO: Check total docs ?\n      // long cloudClientDocs = cloudClient.query(new\n      // SolrQuery(\"*:*\")).getResults().getNumFound();\n      \n      // Wait until new leader is elected\n      while (deadJetty == leaderJetty) {\n        updateMappingsFromZk(this.jettys, this.clients);\n        leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      }\n      \n      // bring back dead node\n      ChaosMonkey.start(deadJetty.jetty); // he is not the leader anymore\n      \n      waitTillRecovered();\n      \n      // Kill the overseer\n      // TODO: Actually kill the Overseer instance\n      killer = new OverseerRestarter(zkServer.getZkAddress());\n      killerThread = new Thread(killer);\n      killerThread.start();\n      killCounter.incrementAndGet();\n      \n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(\"action\",\n          CollectionParams.CollectionAction.SPLITSHARD.toString());\n      params.set(\"collection\", \"collection1\");\n      params.set(\"shard\", \"shard1\");\n      SolrRequest request = new QueryRequest(params);\n      request.setPath(\"/admin/collections\");\n      \n      String baseUrl = ((HttpSolrServer) shardToJetty.get(\"shard1\").get(0).client.solrClient)\n          .getBaseURL();\n      baseUrl = baseUrl.substring(0, baseUrl.length() - \"collection1\".length());\n      \n      HttpSolrServer baseServer = new HttpSolrServer(baseUrl);\n      baseServer.setConnectionTimeout(15000);\n      baseServer.setSoTimeout((int) (CollectionsHandler.DEFAULT_ZK_TIMEOUT * 5));\n      baseServer.request(request);\n      \n      System.out.println(\"Layout after split: \\n\");\n      printLayout();\n      \n       // distributed commit on all shards\n    } finally {\n      if(indexThread != null)\n        indexThread.join();\n      if (solrServer != null)\n        solrServer.commit();\n      if (killer != null) {\n        killer.run = false;\n        if (killerThread != null) {\n          killerThread.join();\n        }\n      }\n    }\n    \n    SolrQuery query = new SolrQuery(\"*:*\").setRows(0).setFields(\"id\");\n    query.set(\"distrib\", false);\n    \n    String shard1_0_url = cloudClient.getZkStateReader().getLeaderUrl(\n        AbstractFullDistribZkTestBase.DEFAULT_COLLECTION, \"shard1_0\",\n        DEFAULT_CONNECTION_TIMEOUT);\n    HttpSolrServer shard1_0Server = new HttpSolrServer(shard1_0_url);\n    QueryResponse response = shard1_0Server.query(query);\n    long shard10Count = response.getResults().getNumFound();\n    System.out.println(\"Resp: shard: shard1_0 url: \" + shard1_0_url + \"\\n\"\n        + response.getResponse());\n    \n    String shard1_1_url = cloudClient.getZkStateReader().getLeaderUrl(\n        AbstractFullDistribZkTestBase.DEFAULT_COLLECTION, \"shard1_1\",\n        DEFAULT_CONNECTION_TIMEOUT);\n    HttpSolrServer shard1_1Server = new HttpSolrServer(shard1_1_url);\n    response = shard1_1Server.query(query);\n    long shard11Count = response.getResults().getNumFound();\n    System.out.println(\"Resp: shard: shard1_1 url: \" + shard1_1_url + \"\\n\"\n        + response.getResponse());\n    \n    for (int i = 0; i < docCounts.length; i++) {\n      int docCount = docCounts[i];\n      System.out\n          .println(\"Expected docCount for shard1_\" + i + \" = \" + docCount);\n    }\n    \n    assertEquals(\"Wrong doc count on shard1_0\", docCounts[0], shard10Count);\n    assertEquals(\"Wrong doc count on shard1_1\", docCounts[1], shard11Count);\n    \n    // todo - can't call waitForThingsToLevelOut because it looks for\n    // jettys of all shards\n    // and the new sub-shards don't have any.\n    waitForRecoveriesToFinish(true);\n    // waitForThingsToLevelOut(15);\n    \n    // todo - more and better tests\n    \n  }\n\n","bugFix":null,"bugIntro":["2dbed1dd58810b079506c1e4cd13ce80e646faed","344b0840364d990b29b97467bfcc766ff8325d11"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8305fcb8f629f095ee305d1e994a80e521be2ff3","date":1365921762,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyShardSplitTest#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyShardSplitTest#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n    \n    waitForThingsToLevelOut(15);\n    printLayout();\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n    Thread indexThread = null;\n    OverseerRestarter killer = null;\n    Thread killerThread = null;\n    final SolrServer solrServer = clients.get(0);\n    \n    try {\n      solrServer.deleteByQuery(\"*:*\");\n      for (int i = 0; i < 100; i++) {\n        indexr(\"id\", i);\n        \n        // todo - hook in custom hashing\n        byte[] bytes = String.valueOf(i).getBytes(\"UTF-8\");\n        int hash = Hash.murmurhash3_x86_32(bytes, 0, bytes.length, 0);\n        for (int i2 = 0; i2 < ranges.size(); i2++) {\n          DocRouter.Range range = ranges.get(i2);\n          if (range.includes(hash)) docCounts[i2]++;\n        }\n      }\n      solrServer.commit();\n      \n      waitForRecoveriesToFinish(false);\n      \n      indexThread = new Thread() {\n        @Override\n        public void run() {\n          for (int i = 101; i < 201; i++) {\n            try {\n              indexr(\"id\", i);\n              \n              // todo - hook in custom hashing\n              byte[] bytes = String.valueOf(i).getBytes(\"UTF-8\");\n              int hash = Hash.murmurhash3_x86_32(bytes, 0, bytes.length, 0);\n              for (int i2 = 0; i2 < ranges.size(); i2++) {\n                DocRouter.Range range = ranges.get(i2);\n                if (range.includes(hash)) docCounts[i2]++;\n              }\n              Thread.sleep(100);\n            } catch (Exception e) {\n              log.error(\"Exception while adding doc\", e);\n            }\n          }\n        }\n      };\n      indexThread.start();\n      \n      // kill the leader\n      CloudJettyRunner leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      log.info(\"Cluster State: \"\n          + cloudClient.getZkStateReader().getClusterState());\n      \n      chaosMonkey.killJetty(leaderJetty);\n      \n      Thread.sleep(2000);\n      \n      waitForThingsToLevelOut(90);\n      \n      Thread.sleep(1000);\n      checkShardConsistency(false, true);\n      \n      CloudJettyRunner deadJetty = leaderJetty;\n      \n      // TODO: Check total docs ?\n      // long cloudClientDocs = cloudClient.query(new\n      // SolrQuery(\"*:*\")).getResults().getNumFound();\n      \n      // Wait until new leader is elected\n      while (deadJetty == leaderJetty) {\n        updateMappingsFromZk(this.jettys, this.clients);\n        leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      }\n      \n      // bring back dead node\n      ChaosMonkey.start(deadJetty.jetty); // he is not the leader anymore\n      \n      waitTillRecovered();\n      \n      // Kill the overseer\n      // TODO: Actually kill the Overseer instance\n      killer = new OverseerRestarter(zkServer.getZkAddress());\n      killerThread = new Thread(killer);\n      killerThread.start();\n      killCounter.incrementAndGet();\n      \n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(\"action\",\n          CollectionParams.CollectionAction.SPLITSHARD.toString());\n      params.set(\"collection\", \"collection1\");\n      params.set(\"shard\", \"shard1\");\n      SolrRequest request = new QueryRequest(params);\n      request.setPath(\"/admin/collections\");\n      \n      String baseUrl = ((HttpSolrServer) shardToJetty.get(\"shard1\").get(0).client.solrClient)\n          .getBaseURL();\n      baseUrl = baseUrl.substring(0, baseUrl.length() - \"collection1\".length());\n      \n      HttpSolrServer baseServer = new HttpSolrServer(baseUrl);\n      baseServer.setConnectionTimeout(15000);\n      baseServer.setSoTimeout((int) (CollectionsHandler.DEFAULT_ZK_TIMEOUT * 5));\n      baseServer.request(request);\n      \n      System.out.println(\"Layout after split: \\n\");\n      printLayout();\n      \n       // distributed commit on all shards\n    } finally {\n      if(indexThread != null)\n        indexThread.join();\n      if (solrServer != null)\n        solrServer.commit();\n      if (killer != null) {\n        killer.run = false;\n        if (killerThread != null) {\n          killerThread.join();\n        }\n      }\n    }\n    \n    SolrQuery query = new SolrQuery(\"*:*\").setRows(0).setFields(\"id\");\n    query.set(\"distrib\", false);\n    \n    String shard1_0_url = cloudClient.getZkStateReader().getLeaderUrl(\n        AbstractFullDistribZkTestBase.DEFAULT_COLLECTION, \"shard1_0\",\n        DEFAULT_CONNECTION_TIMEOUT);\n    HttpSolrServer shard1_0Server = new HttpSolrServer(shard1_0_url);\n    QueryResponse response = shard1_0Server.query(query);\n    long shard10Count = response.getResults().getNumFound();\n    System.out.println(\"Resp: shard: shard1_0 url: \" + shard1_0_url + \"\\n\"\n        + response.getResponse());\n    \n    String shard1_1_url = cloudClient.getZkStateReader().getLeaderUrl(\n        AbstractFullDistribZkTestBase.DEFAULT_COLLECTION, \"shard1_1\",\n        DEFAULT_CONNECTION_TIMEOUT);\n    HttpSolrServer shard1_1Server = new HttpSolrServer(shard1_1_url);\n    QueryResponse response2 = shard1_1Server.query(query);\n    long shard11Count = response2.getResults().getNumFound();\n    System.out.println(\"Resp: shard: shard1_1 url: \" + shard1_1_url + \"\\n\"\n        + response2.getResponse());\n    \n    for (int i = 0; i < docCounts.length; i++) {\n      int docCount = docCounts[i];\n      System.out\n          .println(\"Expected docCount for shard1_\" + i + \" = \" + docCount);\n    }\n\n    // DEBUGGING CODE\n    log.info(\"Actual docCount for shard1_0 = {}\", shard10Count);\n    log.info(\"Actual docCount for shard1_1 = {}\", shard11Count);\n    Map<String, String> idVsVersion = new HashMap<String, String>();\n    Map<String, SolrDocument> shard10Docs = new HashMap<String, SolrDocument>();\n    Map<String, SolrDocument> shard11Docs = new HashMap<String, SolrDocument>();\n    for (int i = 0; i < response.getResults().size(); i++) {\n      SolrDocument document = response.getResults().get(i);\n      idVsVersion.put(document.getFieldValue(\"id\").toString(), document.getFieldValue(\"_version_\").toString());\n      SolrDocument old = shard10Docs.put(document.getFieldValue(\"id\").toString(), document);\n      if (old != null) {\n        log.error(\"EXTRA: ID: \" + document.getFieldValue(\"id\") + \" on shard1_0. Old version: \" + old.getFieldValue(\"_version_\") + \" new version: \" + document.getFieldValue(\"_version_\"));\n      }\n    }\n    for (int i = 0; i < response2.getResults().size(); i++) {\n      SolrDocument document = response2.getResults().get(i);\n      String value = document.getFieldValue(\"id\").toString();\n      String version = idVsVersion.get(value);\n      if (version != null) {\n        log.error(\"DUPLICATE: ID: \" + value + \" , shard1_0Version: \" + version + \" shard1_1Version:\" + document.getFieldValue(\"_version_\"));\n      }\n      SolrDocument old = shard11Docs.put(document.getFieldValue(\"id\").toString(), document);\n      if (old != null) {\n        log.error(\"EXTRA: ID: \" + document.getFieldValue(\"id\") + \" on shard1_1. Old version: \" + old.getFieldValue(\"_version_\") + \" new version: \" + document.getFieldValue(\"_version_\"));\n      }\n    }\n    // END DEBUGGING CODE\n    \n    assertEquals(\"Wrong doc count on shard1_0\", docCounts[0], shard10Count);\n    assertEquals(\"Wrong doc count on shard1_1\", docCounts[1], shard11Count);\n\n    Slice slice1_0 = null, slice1_1 = null;\n    int i = 0;\n    for (i = 0; i < 10; i++) {\n      ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n      zkStateReader.updateClusterState(true);\n      clusterState = zkStateReader.getClusterState();\n      slice1_0 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, \"shard1_0\");\n      slice1_1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, \"shard1_1\");\n      if (Slice.ACTIVE.equals(slice1_0.getState()) && Slice.ACTIVE.equals(slice1_1.getState()))\n        break;\n      Thread.sleep(500);\n    }\n\n    log.info(\"ShardSplitTest waited for {} ms for shard state to be set to active\", i * 500);\n\n    assertNotNull(\"Cluster state does not contain shard1_0\", slice1_0);\n    assertNotNull(\"Cluster state does not contain shard1_0\", slice1_1);\n    assertEquals(\"shard1_0 is not active\", Slice.ACTIVE, slice1_0.getState());\n    assertEquals(\"shard1_1 is not active\", Slice.ACTIVE, slice1_1.getState());\n    assertEquals(\"Wrong number of replicas created for shard1_0\", numReplicas, slice1_0.getReplicas().size());\n    assertEquals(\"Wrong number of replicas created for shard1_1\", numReplicas, slice1_1.getReplicas().size());\n    \n    // todo - can't call waitForThingsToLevelOut because it looks for\n    // jettys of all shards\n    // and the new sub-shards don't have any.\n    waitForRecoveriesToFinish(true);\n    // waitForThingsToLevelOut(15);\n    \n    // todo - more and better tests\n    \n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n    \n    waitForThingsToLevelOut(15);\n    printLayout();\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n    Thread indexThread = null;\n    OverseerRestarter killer = null;\n    Thread killerThread = null;\n    final SolrServer solrServer = clients.get(0);\n    \n    try {\n      solrServer.deleteByQuery(\"*:*\");\n      for (int i = 0; i < 100; i++) {\n        indexr(\"id\", i);\n        \n        // todo - hook in custom hashing\n        byte[] bytes = String.valueOf(i).getBytes(\"UTF-8\");\n        int hash = Hash.murmurhash3_x86_32(bytes, 0, bytes.length, 0);\n        for (int i2 = 0; i2 < ranges.size(); i2++) {\n          DocRouter.Range range = ranges.get(i2);\n          if (range.includes(hash)) docCounts[i2]++;\n        }\n      }\n      solrServer.commit();\n      \n      waitForRecoveriesToFinish(false);\n      \n      indexThread = new Thread() {\n        @Override\n        public void run() {\n          for (int i = 101; i < 201; i++) {\n            try {\n              indexr(\"id\", i);\n              \n              // todo - hook in custom hashing\n              byte[] bytes = String.valueOf(i).getBytes(\"UTF-8\");\n              int hash = Hash.murmurhash3_x86_32(bytes, 0, bytes.length, 0);\n              for (int i2 = 0; i2 < ranges.size(); i2++) {\n                DocRouter.Range range = ranges.get(i2);\n                if (range.includes(hash)) docCounts[i2]++;\n              }\n              Thread.sleep(100);\n            } catch (Exception e) {\n              log.error(\"Exception while adding doc\", e);\n            }\n          }\n        }\n      };\n      indexThread.start();\n      \n      // kill the leader\n      CloudJettyRunner leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      log.info(\"Cluster State: \"\n          + cloudClient.getZkStateReader().getClusterState());\n      \n      chaosMonkey.killJetty(leaderJetty);\n      \n      Thread.sleep(2000);\n      \n      waitForThingsToLevelOut(90);\n      \n      Thread.sleep(1000);\n      checkShardConsistency(false, true);\n      \n      CloudJettyRunner deadJetty = leaderJetty;\n      \n      // TODO: Check total docs ?\n      // long cloudClientDocs = cloudClient.query(new\n      // SolrQuery(\"*:*\")).getResults().getNumFound();\n      \n      // Wait until new leader is elected\n      while (deadJetty == leaderJetty) {\n        updateMappingsFromZk(this.jettys, this.clients);\n        leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      }\n      \n      // bring back dead node\n      ChaosMonkey.start(deadJetty.jetty); // he is not the leader anymore\n      \n      waitTillRecovered();\n      \n      // Kill the overseer\n      // TODO: Actually kill the Overseer instance\n      killer = new OverseerRestarter(zkServer.getZkAddress());\n      killerThread = new Thread(killer);\n      killerThread.start();\n      killCounter.incrementAndGet();\n      \n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(\"action\",\n          CollectionParams.CollectionAction.SPLITSHARD.toString());\n      params.set(\"collection\", \"collection1\");\n      params.set(\"shard\", \"shard1\");\n      SolrRequest request = new QueryRequest(params);\n      request.setPath(\"/admin/collections\");\n      \n      String baseUrl = ((HttpSolrServer) shardToJetty.get(\"shard1\").get(0).client.solrClient)\n          .getBaseURL();\n      baseUrl = baseUrl.substring(0, baseUrl.length() - \"collection1\".length());\n      \n      HttpSolrServer baseServer = new HttpSolrServer(baseUrl);\n      baseServer.setConnectionTimeout(15000);\n      baseServer.setSoTimeout((int) (CollectionsHandler.DEFAULT_ZK_TIMEOUT * 5));\n      baseServer.request(request);\n      \n      System.out.println(\"Layout after split: \\n\");\n      printLayout();\n      \n       // distributed commit on all shards\n    } finally {\n      if(indexThread != null)\n        indexThread.join();\n      if (solrServer != null)\n        solrServer.commit();\n      if (killer != null) {\n        killer.run = false;\n        if (killerThread != null) {\n          killerThread.join();\n        }\n      }\n    }\n    \n    SolrQuery query = new SolrQuery(\"*:*\").setRows(0).setFields(\"id\");\n    query.set(\"distrib\", false);\n    \n    String shard1_0_url = cloudClient.getZkStateReader().getLeaderUrl(\n        AbstractFullDistribZkTestBase.DEFAULT_COLLECTION, \"shard1_0\",\n        DEFAULT_CONNECTION_TIMEOUT);\n    HttpSolrServer shard1_0Server = new HttpSolrServer(shard1_0_url);\n    QueryResponse response = shard1_0Server.query(query);\n    long shard10Count = response.getResults().getNumFound();\n    System.out.println(\"Resp: shard: shard1_0 url: \" + shard1_0_url + \"\\n\"\n        + response.getResponse());\n    \n    String shard1_1_url = cloudClient.getZkStateReader().getLeaderUrl(\n        AbstractFullDistribZkTestBase.DEFAULT_COLLECTION, \"shard1_1\",\n        DEFAULT_CONNECTION_TIMEOUT);\n    HttpSolrServer shard1_1Server = new HttpSolrServer(shard1_1_url);\n    response = shard1_1Server.query(query);\n    long shard11Count = response.getResults().getNumFound();\n    System.out.println(\"Resp: shard: shard1_1 url: \" + shard1_1_url + \"\\n\"\n        + response.getResponse());\n    \n    for (int i = 0; i < docCounts.length; i++) {\n      int docCount = docCounts[i];\n      System.out\n          .println(\"Expected docCount for shard1_\" + i + \" = \" + docCount);\n    }\n    \n    assertEquals(\"Wrong doc count on shard1_0\", docCounts[0], shard10Count);\n    assertEquals(\"Wrong doc count on shard1_1\", docCounts[1], shard11Count);\n\n    Slice slice1_0 = null, slice1_1 = null;\n    int i = 0;\n    for (i = 0; i < 10; i++) {\n      ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n      zkStateReader.updateClusterState(true);\n      clusterState = zkStateReader.getClusterState();\n      slice1_0 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, \"shard1_0\");\n      slice1_1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, \"shard1_1\");\n      if (Slice.ACTIVE.equals(slice1_0.getState()) && Slice.ACTIVE.equals(slice1_1.getState()))\n        break;\n      Thread.sleep(500);\n    }\n\n    log.info(\"ShardSplitTest waited for {} ms for shard state to be set to active\", i * 500);\n\n    assertNotNull(\"Cluster state does not contain shard1_0\", slice1_0);\n    assertNotNull(\"Cluster state does not contain shard1_0\", slice1_1);\n    assertEquals(\"shard1_0 is not active\", Slice.ACTIVE, slice1_0.getState());\n    assertEquals(\"shard1_1 is not active\", Slice.ACTIVE, slice1_1.getState());\n    assertEquals(\"Wrong number of replicas created for shard1_0\", numReplicas, slice1_0.getReplicas().size());\n    assertEquals(\"Wrong number of replicas created for shard1_1\", numReplicas, slice1_1.getReplicas().size());\n    \n    // todo - can't call waitForThingsToLevelOut because it looks for\n    // jettys of all shards\n    // and the new sub-shards don't have any.\n    waitForRecoveriesToFinish(true);\n    // waitForThingsToLevelOut(15);\n    \n    // todo - more and better tests\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8735477f53284dd67c6335828378cadf20cddabc","date":1365956061,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyShardSplitTest#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyShardSplitTest#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    waitForThingsToLevelOut(15);\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    Thread indexThread = null;\n    OverseerRestarter killer = null;\n    Thread killerThread = null;\n    final SolrServer solrServer = clients.get(0);\n\n    try {\n      del(\"*:*\");\n      for (int id = 0; id < 100; id++) {\n        indexAndUpdateCount(ranges, docCounts, id);\n      }\n      commit();\n\n      indexThread = new Thread() {\n        @Override\n        public void run() {\n          for (int id = 101; id < atLeast(401); id++) {\n            try {\n              indexAndUpdateCount(ranges, docCounts, id);\n              Thread.sleep(atLeast(25));\n            } catch (Exception e) {\n              log.error(\"Exception while adding doc\", e);\n            }\n          }\n        }\n      };\n      indexThread.start();\n\n      // kill the leader\n      CloudJettyRunner leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      chaosMonkey.killJetty(leaderJetty);\n\n      Thread.sleep(2000);\n\n      waitForThingsToLevelOut(90);\n\n      Thread.sleep(1000);\n      checkShardConsistency(false, true);\n\n      CloudJettyRunner deadJetty = leaderJetty;\n\n      // TODO: Check total docs ?\n      // long cloudClientDocs = cloudClient.query(new\n      // SolrQuery(\"*:*\")).getResults().getNumFound();\n\n      // Wait until new leader is elected\n      while (deadJetty == leaderJetty) {\n        updateMappingsFromZk(this.jettys, this.clients);\n        leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      }\n\n      // bring back dead node\n      ChaosMonkey.start(deadJetty.jetty); // he is not the leader anymore\n\n      waitTillRecovered();\n\n      // Kill the overseer\n      // TODO: Actually kill the Overseer instance\n      killer = new OverseerRestarter(zkServer.getZkAddress());\n      killerThread = new Thread(killer);\n      killerThread.start();\n      killCounter.incrementAndGet();\n\n      splitShard(SHARD1);\n\n      log.info(\"Layout after split: \\n\");\n      printLayout();\n\n      // distributed commit on all shards\n    } finally {\n      if (indexThread != null)\n        indexThread.join();\n      if (solrServer != null)\n        solrServer.commit();\n      if (killer != null) {\n        killer.run = false;\n        if (killerThread != null) {\n          killerThread.join();\n        }\n      }\n    }\n\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n\n    // todo - can't call waitForThingsToLevelOut because it looks for\n    // jettys of all shards\n    // and the new sub-shards don't have any.\n    waitForRecoveriesToFinish(true);\n    // waitForThingsToLevelOut(15);\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n    \n    waitForThingsToLevelOut(15);\n    printLayout();\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n    Thread indexThread = null;\n    OverseerRestarter killer = null;\n    Thread killerThread = null;\n    final SolrServer solrServer = clients.get(0);\n    \n    try {\n      solrServer.deleteByQuery(\"*:*\");\n      for (int i = 0; i < 100; i++) {\n        indexr(\"id\", i);\n        \n        // todo - hook in custom hashing\n        byte[] bytes = String.valueOf(i).getBytes(\"UTF-8\");\n        int hash = Hash.murmurhash3_x86_32(bytes, 0, bytes.length, 0);\n        for (int i2 = 0; i2 < ranges.size(); i2++) {\n          DocRouter.Range range = ranges.get(i2);\n          if (range.includes(hash)) docCounts[i2]++;\n        }\n      }\n      solrServer.commit();\n      \n      waitForRecoveriesToFinish(false);\n      \n      indexThread = new Thread() {\n        @Override\n        public void run() {\n          for (int i = 101; i < 201; i++) {\n            try {\n              indexr(\"id\", i);\n              \n              // todo - hook in custom hashing\n              byte[] bytes = String.valueOf(i).getBytes(\"UTF-8\");\n              int hash = Hash.murmurhash3_x86_32(bytes, 0, bytes.length, 0);\n              for (int i2 = 0; i2 < ranges.size(); i2++) {\n                DocRouter.Range range = ranges.get(i2);\n                if (range.includes(hash)) docCounts[i2]++;\n              }\n              Thread.sleep(100);\n            } catch (Exception e) {\n              log.error(\"Exception while adding doc\", e);\n            }\n          }\n        }\n      };\n      indexThread.start();\n      \n      // kill the leader\n      CloudJettyRunner leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      log.info(\"Cluster State: \"\n          + cloudClient.getZkStateReader().getClusterState());\n      \n      chaosMonkey.killJetty(leaderJetty);\n      \n      Thread.sleep(2000);\n      \n      waitForThingsToLevelOut(90);\n      \n      Thread.sleep(1000);\n      checkShardConsistency(false, true);\n      \n      CloudJettyRunner deadJetty = leaderJetty;\n      \n      // TODO: Check total docs ?\n      // long cloudClientDocs = cloudClient.query(new\n      // SolrQuery(\"*:*\")).getResults().getNumFound();\n      \n      // Wait until new leader is elected\n      while (deadJetty == leaderJetty) {\n        updateMappingsFromZk(this.jettys, this.clients);\n        leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      }\n      \n      // bring back dead node\n      ChaosMonkey.start(deadJetty.jetty); // he is not the leader anymore\n      \n      waitTillRecovered();\n      \n      // Kill the overseer\n      // TODO: Actually kill the Overseer instance\n      killer = new OverseerRestarter(zkServer.getZkAddress());\n      killerThread = new Thread(killer);\n      killerThread.start();\n      killCounter.incrementAndGet();\n      \n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(\"action\",\n          CollectionParams.CollectionAction.SPLITSHARD.toString());\n      params.set(\"collection\", \"collection1\");\n      params.set(\"shard\", \"shard1\");\n      SolrRequest request = new QueryRequest(params);\n      request.setPath(\"/admin/collections\");\n      \n      String baseUrl = ((HttpSolrServer) shardToJetty.get(\"shard1\").get(0).client.solrClient)\n          .getBaseURL();\n      baseUrl = baseUrl.substring(0, baseUrl.length() - \"collection1\".length());\n      \n      HttpSolrServer baseServer = new HttpSolrServer(baseUrl);\n      baseServer.setConnectionTimeout(15000);\n      baseServer.setSoTimeout((int) (CollectionsHandler.DEFAULT_ZK_TIMEOUT * 5));\n      baseServer.request(request);\n      \n      System.out.println(\"Layout after split: \\n\");\n      printLayout();\n      \n       // distributed commit on all shards\n    } finally {\n      if(indexThread != null)\n        indexThread.join();\n      if (solrServer != null)\n        solrServer.commit();\n      if (killer != null) {\n        killer.run = false;\n        if (killerThread != null) {\n          killerThread.join();\n        }\n      }\n    }\n    \n    SolrQuery query = new SolrQuery(\"*:*\").setRows(0).setFields(\"id\");\n    query.set(\"distrib\", false);\n    \n    String shard1_0_url = cloudClient.getZkStateReader().getLeaderUrl(\n        AbstractFullDistribZkTestBase.DEFAULT_COLLECTION, \"shard1_0\",\n        DEFAULT_CONNECTION_TIMEOUT);\n    HttpSolrServer shard1_0Server = new HttpSolrServer(shard1_0_url);\n    QueryResponse response = shard1_0Server.query(query);\n    long shard10Count = response.getResults().getNumFound();\n    System.out.println(\"Resp: shard: shard1_0 url: \" + shard1_0_url + \"\\n\"\n        + response.getResponse());\n    \n    String shard1_1_url = cloudClient.getZkStateReader().getLeaderUrl(\n        AbstractFullDistribZkTestBase.DEFAULT_COLLECTION, \"shard1_1\",\n        DEFAULT_CONNECTION_TIMEOUT);\n    HttpSolrServer shard1_1Server = new HttpSolrServer(shard1_1_url);\n    QueryResponse response2 = shard1_1Server.query(query);\n    long shard11Count = response2.getResults().getNumFound();\n    System.out.println(\"Resp: shard: shard1_1 url: \" + shard1_1_url + \"\\n\"\n        + response2.getResponse());\n    \n    for (int i = 0; i < docCounts.length; i++) {\n      int docCount = docCounts[i];\n      System.out\n          .println(\"Expected docCount for shard1_\" + i + \" = \" + docCount);\n    }\n\n    // DEBUGGING CODE\n    log.info(\"Actual docCount for shard1_0 = {}\", shard10Count);\n    log.info(\"Actual docCount for shard1_1 = {}\", shard11Count);\n    Map<String, String> idVsVersion = new HashMap<String, String>();\n    Map<String, SolrDocument> shard10Docs = new HashMap<String, SolrDocument>();\n    Map<String, SolrDocument> shard11Docs = new HashMap<String, SolrDocument>();\n    for (int i = 0; i < response.getResults().size(); i++) {\n      SolrDocument document = response.getResults().get(i);\n      idVsVersion.put(document.getFieldValue(\"id\").toString(), document.getFieldValue(\"_version_\").toString());\n      SolrDocument old = shard10Docs.put(document.getFieldValue(\"id\").toString(), document);\n      if (old != null) {\n        log.error(\"EXTRA: ID: \" + document.getFieldValue(\"id\") + \" on shard1_0. Old version: \" + old.getFieldValue(\"_version_\") + \" new version: \" + document.getFieldValue(\"_version_\"));\n      }\n    }\n    for (int i = 0; i < response2.getResults().size(); i++) {\n      SolrDocument document = response2.getResults().get(i);\n      String value = document.getFieldValue(\"id\").toString();\n      String version = idVsVersion.get(value);\n      if (version != null) {\n        log.error(\"DUPLICATE: ID: \" + value + \" , shard1_0Version: \" + version + \" shard1_1Version:\" + document.getFieldValue(\"_version_\"));\n      }\n      SolrDocument old = shard11Docs.put(document.getFieldValue(\"id\").toString(), document);\n      if (old != null) {\n        log.error(\"EXTRA: ID: \" + document.getFieldValue(\"id\") + \" on shard1_1. Old version: \" + old.getFieldValue(\"_version_\") + \" new version: \" + document.getFieldValue(\"_version_\"));\n      }\n    }\n    // END DEBUGGING CODE\n    \n    assertEquals(\"Wrong doc count on shard1_0\", docCounts[0], shard10Count);\n    assertEquals(\"Wrong doc count on shard1_1\", docCounts[1], shard11Count);\n\n    Slice slice1_0 = null, slice1_1 = null;\n    int i = 0;\n    for (i = 0; i < 10; i++) {\n      ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n      zkStateReader.updateClusterState(true);\n      clusterState = zkStateReader.getClusterState();\n      slice1_0 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, \"shard1_0\");\n      slice1_1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, \"shard1_1\");\n      if (Slice.ACTIVE.equals(slice1_0.getState()) && Slice.ACTIVE.equals(slice1_1.getState()))\n        break;\n      Thread.sleep(500);\n    }\n\n    log.info(\"ShardSplitTest waited for {} ms for shard state to be set to active\", i * 500);\n\n    assertNotNull(\"Cluster state does not contain shard1_0\", slice1_0);\n    assertNotNull(\"Cluster state does not contain shard1_0\", slice1_1);\n    assertEquals(\"shard1_0 is not active\", Slice.ACTIVE, slice1_0.getState());\n    assertEquals(\"shard1_1 is not active\", Slice.ACTIVE, slice1_1.getState());\n    assertEquals(\"Wrong number of replicas created for shard1_0\", numReplicas, slice1_0.getReplicas().size());\n    assertEquals(\"Wrong number of replicas created for shard1_1\", numReplicas, slice1_1.getReplicas().size());\n    \n    // todo - can't call waitForThingsToLevelOut because it looks for\n    // jettys of all shards\n    // and the new sub-shards don't have any.\n    waitForRecoveriesToFinish(true);\n    // waitForThingsToLevelOut(15);\n    \n    // todo - more and better tests\n    \n  }\n\n","bugFix":null,"bugIntro":["2dbed1dd58810b079506c1e4cd13ce80e646faed","6776b3c3ed554ace17893a807da5b7a0a6d364c8"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6776b3c3ed554ace17893a807da5b7a0a6d364c8","date":1367964133,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyShardSplitTest#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyShardSplitTest#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    waitForThingsToLevelOut(15);\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    Thread indexThread = null;\n    OverseerRestarter killer = null;\n    Thread killerThread = null;\n    final SolrServer solrServer = clients.get(0);\n\n    try {\n      del(\"*:*\");\n      for (int id = 0; id < 100; id++) {\n        indexAndUpdateCount(ranges, docCounts, id);\n      }\n      commit();\n\n      indexThread = new Thread() {\n        @Override\n        public void run() {\n          int max = atLeast(401);\n          for (int id = 101; id < max; id++) {\n            try {\n              indexAndUpdateCount(ranges, docCounts, id);\n              Thread.sleep(atLeast(25));\n            } catch (Exception e) {\n              log.error(\"Exception while adding doc\", e);\n            }\n          }\n        }\n      };\n      indexThread.start();\n\n      // kill the leader\n      CloudJettyRunner leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      chaosMonkey.killJetty(leaderJetty);\n\n      Thread.sleep(2000);\n\n      waitForThingsToLevelOut(90);\n\n      Thread.sleep(1000);\n      checkShardConsistency(false, true);\n\n      CloudJettyRunner deadJetty = leaderJetty;\n\n      // TODO: Check total docs ?\n      // long cloudClientDocs = cloudClient.query(new\n      // SolrQuery(\"*:*\")).getResults().getNumFound();\n\n      // Wait until new leader is elected\n      while (deadJetty == leaderJetty) {\n        updateMappingsFromZk(this.jettys, this.clients);\n        leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      }\n\n      // bring back dead node\n      ChaosMonkey.start(deadJetty.jetty); // he is not the leader anymore\n\n      waitTillRecovered();\n\n      // Kill the overseer\n      // TODO: Actually kill the Overseer instance\n      killer = new OverseerRestarter(zkServer.getZkAddress());\n      killerThread = new Thread(killer);\n      killerThread.start();\n      killCounter.incrementAndGet();\n\n      splitShard(SHARD1);\n\n      log.info(\"Layout after split: \\n\");\n      printLayout();\n\n      // distributed commit on all shards\n    } finally {\n      if (indexThread != null)\n        indexThread.join();\n      if (solrServer != null)\n        solrServer.commit();\n      if (killer != null) {\n        killer.run = false;\n        if (killerThread != null) {\n          killerThread.join();\n        }\n      }\n    }\n\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n\n    // todo - can't call waitForThingsToLevelOut because it looks for\n    // jettys of all shards\n    // and the new sub-shards don't have any.\n    waitForRecoveriesToFinish(true);\n    // waitForThingsToLevelOut(15);\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    waitForThingsToLevelOut(15);\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    Thread indexThread = null;\n    OverseerRestarter killer = null;\n    Thread killerThread = null;\n    final SolrServer solrServer = clients.get(0);\n\n    try {\n      del(\"*:*\");\n      for (int id = 0; id < 100; id++) {\n        indexAndUpdateCount(ranges, docCounts, id);\n      }\n      commit();\n\n      indexThread = new Thread() {\n        @Override\n        public void run() {\n          for (int id = 101; id < atLeast(401); id++) {\n            try {\n              indexAndUpdateCount(ranges, docCounts, id);\n              Thread.sleep(atLeast(25));\n            } catch (Exception e) {\n              log.error(\"Exception while adding doc\", e);\n            }\n          }\n        }\n      };\n      indexThread.start();\n\n      // kill the leader\n      CloudJettyRunner leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      chaosMonkey.killJetty(leaderJetty);\n\n      Thread.sleep(2000);\n\n      waitForThingsToLevelOut(90);\n\n      Thread.sleep(1000);\n      checkShardConsistency(false, true);\n\n      CloudJettyRunner deadJetty = leaderJetty;\n\n      // TODO: Check total docs ?\n      // long cloudClientDocs = cloudClient.query(new\n      // SolrQuery(\"*:*\")).getResults().getNumFound();\n\n      // Wait until new leader is elected\n      while (deadJetty == leaderJetty) {\n        updateMappingsFromZk(this.jettys, this.clients);\n        leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      }\n\n      // bring back dead node\n      ChaosMonkey.start(deadJetty.jetty); // he is not the leader anymore\n\n      waitTillRecovered();\n\n      // Kill the overseer\n      // TODO: Actually kill the Overseer instance\n      killer = new OverseerRestarter(zkServer.getZkAddress());\n      killerThread = new Thread(killer);\n      killerThread.start();\n      killCounter.incrementAndGet();\n\n      splitShard(SHARD1);\n\n      log.info(\"Layout after split: \\n\");\n      printLayout();\n\n      // distributed commit on all shards\n    } finally {\n      if (indexThread != null)\n        indexThread.join();\n      if (solrServer != null)\n        solrServer.commit();\n      if (killer != null) {\n        killer.run = false;\n        if (killerThread != null) {\n          killerThread.join();\n        }\n      }\n    }\n\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n\n    // todo - can't call waitForThingsToLevelOut because it looks for\n    // jettys of all shards\n    // and the new sub-shards don't have any.\n    waitForRecoveriesToFinish(true);\n    // waitForThingsToLevelOut(15);\n  }\n\n","bugFix":["8735477f53284dd67c6335828378cadf20cddabc"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2dbed1dd58810b079506c1e4cd13ce80e646faed","date":1368050251,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyShardSplitTest#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyShardSplitTest#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    waitForThingsToLevelOut(15);\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    Thread indexThread = null;\n    OverseerRestarter killer = null;\n    Thread killerThread = null;\n    final SolrServer solrServer = clients.get(0);\n\n    try {\n      del(\"*:*\");\n      for (int id = 0; id < 100; id++) {\n        indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id));\n      }\n      commit();\n\n      indexThread = new Thread() {\n        @Override\n        public void run() {\n          int max = atLeast(401);\n          for (int id = 101; id < max; id++) {\n            try {\n              indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id));\n              Thread.sleep(atLeast(25));\n            } catch (Exception e) {\n              log.error(\"Exception while adding doc\", e);\n            }\n          }\n        }\n      };\n      indexThread.start();\n\n      // kill the leader\n      CloudJettyRunner leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      chaosMonkey.killJetty(leaderJetty);\n\n      Thread.sleep(2000);\n\n      waitForThingsToLevelOut(90);\n\n      Thread.sleep(1000);\n      checkShardConsistency(false, true);\n\n      CloudJettyRunner deadJetty = leaderJetty;\n\n      // TODO: Check total docs ?\n      // long cloudClientDocs = cloudClient.query(new\n      // SolrQuery(\"*:*\")).getResults().getNumFound();\n\n      // Wait until new leader is elected\n      while (deadJetty == leaderJetty) {\n        updateMappingsFromZk(this.jettys, this.clients);\n        leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      }\n\n      // bring back dead node\n      ChaosMonkey.start(deadJetty.jetty); // he is not the leader anymore\n\n      waitTillRecovered();\n\n      // Kill the overseer\n      // TODO: Actually kill the Overseer instance\n      killer = new OverseerRestarter(zkServer.getZkAddress());\n      killerThread = new Thread(killer);\n      killerThread.start();\n      killCounter.incrementAndGet();\n\n      splitShard(SHARD1);\n\n      log.info(\"Layout after split: \\n\");\n      printLayout();\n\n      // distributed commit on all shards\n    } finally {\n      if (indexThread != null)\n        indexThread.join();\n      if (solrServer != null)\n        solrServer.commit();\n      if (killer != null) {\n        killer.run = false;\n        if (killerThread != null) {\n          killerThread.join();\n        }\n      }\n    }\n\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n\n    // todo - can't call waitForThingsToLevelOut because it looks for\n    // jettys of all shards\n    // and the new sub-shards don't have any.\n    waitForRecoveriesToFinish(true);\n    // waitForThingsToLevelOut(15);\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    waitForThingsToLevelOut(15);\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    Thread indexThread = null;\n    OverseerRestarter killer = null;\n    Thread killerThread = null;\n    final SolrServer solrServer = clients.get(0);\n\n    try {\n      del(\"*:*\");\n      for (int id = 0; id < 100; id++) {\n        indexAndUpdateCount(ranges, docCounts, id);\n      }\n      commit();\n\n      indexThread = new Thread() {\n        @Override\n        public void run() {\n          int max = atLeast(401);\n          for (int id = 101; id < max; id++) {\n            try {\n              indexAndUpdateCount(ranges, docCounts, id);\n              Thread.sleep(atLeast(25));\n            } catch (Exception e) {\n              log.error(\"Exception while adding doc\", e);\n            }\n          }\n        }\n      };\n      indexThread.start();\n\n      // kill the leader\n      CloudJettyRunner leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      chaosMonkey.killJetty(leaderJetty);\n\n      Thread.sleep(2000);\n\n      waitForThingsToLevelOut(90);\n\n      Thread.sleep(1000);\n      checkShardConsistency(false, true);\n\n      CloudJettyRunner deadJetty = leaderJetty;\n\n      // TODO: Check total docs ?\n      // long cloudClientDocs = cloudClient.query(new\n      // SolrQuery(\"*:*\")).getResults().getNumFound();\n\n      // Wait until new leader is elected\n      while (deadJetty == leaderJetty) {\n        updateMappingsFromZk(this.jettys, this.clients);\n        leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      }\n\n      // bring back dead node\n      ChaosMonkey.start(deadJetty.jetty); // he is not the leader anymore\n\n      waitTillRecovered();\n\n      // Kill the overseer\n      // TODO: Actually kill the Overseer instance\n      killer = new OverseerRestarter(zkServer.getZkAddress());\n      killerThread = new Thread(killer);\n      killerThread.start();\n      killCounter.incrementAndGet();\n\n      splitShard(SHARD1);\n\n      log.info(\"Layout after split: \\n\");\n      printLayout();\n\n      // distributed commit on all shards\n    } finally {\n      if (indexThread != null)\n        indexThread.join();\n      if (solrServer != null)\n        solrServer.commit();\n      if (killer != null) {\n        killer.run = false;\n        if (killerThread != null) {\n          killerThread.join();\n        }\n      }\n    }\n\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n\n    // todo - can't call waitForThingsToLevelOut because it looks for\n    // jettys of all shards\n    // and the new sub-shards don't have any.\n    waitForRecoveriesToFinish(true);\n    // waitForThingsToLevelOut(15);\n  }\n\n","bugFix":["e4daf0e37630dc4d06c6bcf53c19bfb09e0ba6dd","8735477f53284dd67c6335828378cadf20cddabc"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8f1ea787bab5bdb5e72685e55424898da05509b6","date":1370289750,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyShardSplitTest#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyShardSplitTest#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    waitForThingsToLevelOut(15);\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    Thread indexThread = null;\n    OverseerRestarter killer = null;\n    Thread killerThread = null;\n    final SolrServer solrServer = clients.get(0);\n\n    try {\n      del(\"*:*\");\n      for (int id = 0; id < 100; id++) {\n        indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n      }\n      commit();\n\n      indexThread = new Thread() {\n        @Override\n        public void run() {\n          int max = atLeast(401);\n          for (int id = 101; id < max; id++) {\n            try {\n              indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n              Thread.sleep(atLeast(25));\n            } catch (Exception e) {\n              log.error(\"Exception while adding doc\", e);\n            }\n          }\n        }\n      };\n      indexThread.start();\n\n      // kill the leader\n      CloudJettyRunner leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      chaosMonkey.killJetty(leaderJetty);\n\n      Thread.sleep(2000);\n\n      waitForThingsToLevelOut(90);\n\n      Thread.sleep(1000);\n      checkShardConsistency(false, true);\n\n      CloudJettyRunner deadJetty = leaderJetty;\n\n      // TODO: Check total docs ?\n      // long cloudClientDocs = cloudClient.query(new\n      // SolrQuery(\"*:*\")).getResults().getNumFound();\n\n      // Wait until new leader is elected\n      while (deadJetty == leaderJetty) {\n        updateMappingsFromZk(this.jettys, this.clients);\n        leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      }\n\n      // bring back dead node\n      ChaosMonkey.start(deadJetty.jetty); // he is not the leader anymore\n\n      waitTillRecovered();\n\n      // Kill the overseer\n      // TODO: Actually kill the Overseer instance\n      killer = new OverseerRestarter(zkServer.getZkAddress());\n      killerThread = new Thread(killer);\n      killerThread.start();\n      killCounter.incrementAndGet();\n\n      splitShard(SHARD1);\n\n      log.info(\"Layout after split: \\n\");\n      printLayout();\n\n      // distributed commit on all shards\n    } finally {\n      if (indexThread != null)\n        indexThread.join();\n      if (solrServer != null)\n        solrServer.commit();\n      if (killer != null) {\n        killer.run = false;\n        if (killerThread != null) {\n          killerThread.join();\n        }\n      }\n    }\n\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n\n    // todo - can't call waitForThingsToLevelOut because it looks for\n    // jettys of all shards\n    // and the new sub-shards don't have any.\n    waitForRecoveriesToFinish(true);\n    // waitForThingsToLevelOut(15);\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    waitForThingsToLevelOut(15);\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    Thread indexThread = null;\n    OverseerRestarter killer = null;\n    Thread killerThread = null;\n    final SolrServer solrServer = clients.get(0);\n\n    try {\n      del(\"*:*\");\n      for (int id = 0; id < 100; id++) {\n        indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id));\n      }\n      commit();\n\n      indexThread = new Thread() {\n        @Override\n        public void run() {\n          int max = atLeast(401);\n          for (int id = 101; id < max; id++) {\n            try {\n              indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id));\n              Thread.sleep(atLeast(25));\n            } catch (Exception e) {\n              log.error(\"Exception while adding doc\", e);\n            }\n          }\n        }\n      };\n      indexThread.start();\n\n      // kill the leader\n      CloudJettyRunner leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      chaosMonkey.killJetty(leaderJetty);\n\n      Thread.sleep(2000);\n\n      waitForThingsToLevelOut(90);\n\n      Thread.sleep(1000);\n      checkShardConsistency(false, true);\n\n      CloudJettyRunner deadJetty = leaderJetty;\n\n      // TODO: Check total docs ?\n      // long cloudClientDocs = cloudClient.query(new\n      // SolrQuery(\"*:*\")).getResults().getNumFound();\n\n      // Wait until new leader is elected\n      while (deadJetty == leaderJetty) {\n        updateMappingsFromZk(this.jettys, this.clients);\n        leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      }\n\n      // bring back dead node\n      ChaosMonkey.start(deadJetty.jetty); // he is not the leader anymore\n\n      waitTillRecovered();\n\n      // Kill the overseer\n      // TODO: Actually kill the Overseer instance\n      killer = new OverseerRestarter(zkServer.getZkAddress());\n      killerThread = new Thread(killer);\n      killerThread.start();\n      killCounter.incrementAndGet();\n\n      splitShard(SHARD1);\n\n      log.info(\"Layout after split: \\n\");\n      printLayout();\n\n      // distributed commit on all shards\n    } finally {\n      if (indexThread != null)\n        indexThread.join();\n      if (solrServer != null)\n        solrServer.commit();\n      if (killer != null) {\n        killer.run = false;\n        if (killerThread != null) {\n          killerThread.join();\n        }\n      }\n    }\n\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n\n    // todo - can't call waitForThingsToLevelOut because it looks for\n    // jettys of all shards\n    // and the new sub-shards don't have any.\n    waitForRecoveriesToFinish(true);\n    // waitForThingsToLevelOut(15);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1816753738ff1f27f11b38030e83c0ded050b7a4","date":1380106089,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyShardSplitTest#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyShardSplitTest#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    waitForThingsToLevelOut(15);\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    Thread indexThread = null;\n    OverseerRestarter killer = null;\n    Thread killerThread = null;\n    final SolrServer solrServer = clients.get(0);\n\n    try {\n      del(\"*:*\");\n      for (int id = 0; id < 100; id++) {\n        indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n      }\n      commit();\n\n      indexThread = new Thread() {\n        @Override\n        public void run() {\n          int max = atLeast(401);\n          for (int id = 101; id < max; id++) {\n            try {\n              indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n              Thread.sleep(atLeast(25));\n            } catch (Exception e) {\n              log.error(\"Exception while adding doc\", e);\n            }\n          }\n        }\n      };\n      indexThread.start();\n\n      // kill the leader\n      CloudJettyRunner leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      chaosMonkey.killJetty(leaderJetty);\n\n      Thread.sleep(2000);\n\n      waitForThingsToLevelOut(90);\n\n      Thread.sleep(1000);\n      checkShardConsistency(false, true);\n\n      CloudJettyRunner deadJetty = leaderJetty;\n\n      // TODO: Check total docs ?\n      // long cloudClientDocs = cloudClient.query(new\n      // SolrQuery(\"*:*\")).getResults().getNumFound();\n\n      // Wait until new leader is elected\n      while (deadJetty == leaderJetty) {\n        updateMappingsFromZk(this.jettys, this.clients);\n        leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      }\n\n      // bring back dead node\n      ChaosMonkey.start(deadJetty.jetty); // he is not the leader anymore\n\n      waitTillRecovered();\n\n      // Kill the overseer\n      // TODO: Actually kill the Overseer instance\n      killer = new OverseerRestarter(zkServer.getZkAddress());\n      killerThread = new Thread(killer);\n      killerThread.start();\n      killCounter.incrementAndGet();\n\n      splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n\n      log.info(\"Layout after split: \\n\");\n      printLayout();\n\n      // distributed commit on all shards\n    } finally {\n      if (indexThread != null)\n        indexThread.join();\n      if (solrServer != null)\n        solrServer.commit();\n      if (killer != null) {\n        killer.run = false;\n        if (killerThread != null) {\n          killerThread.join();\n        }\n      }\n    }\n\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n\n    // todo - can't call waitForThingsToLevelOut because it looks for\n    // jettys of all shards\n    // and the new sub-shards don't have any.\n    waitForRecoveriesToFinish(true);\n    // waitForThingsToLevelOut(15);\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    waitForThingsToLevelOut(15);\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    Thread indexThread = null;\n    OverseerRestarter killer = null;\n    Thread killerThread = null;\n    final SolrServer solrServer = clients.get(0);\n\n    try {\n      del(\"*:*\");\n      for (int id = 0; id < 100; id++) {\n        indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n      }\n      commit();\n\n      indexThread = new Thread() {\n        @Override\n        public void run() {\n          int max = atLeast(401);\n          for (int id = 101; id < max; id++) {\n            try {\n              indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n              Thread.sleep(atLeast(25));\n            } catch (Exception e) {\n              log.error(\"Exception while adding doc\", e);\n            }\n          }\n        }\n      };\n      indexThread.start();\n\n      // kill the leader\n      CloudJettyRunner leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      chaosMonkey.killJetty(leaderJetty);\n\n      Thread.sleep(2000);\n\n      waitForThingsToLevelOut(90);\n\n      Thread.sleep(1000);\n      checkShardConsistency(false, true);\n\n      CloudJettyRunner deadJetty = leaderJetty;\n\n      // TODO: Check total docs ?\n      // long cloudClientDocs = cloudClient.query(new\n      // SolrQuery(\"*:*\")).getResults().getNumFound();\n\n      // Wait until new leader is elected\n      while (deadJetty == leaderJetty) {\n        updateMappingsFromZk(this.jettys, this.clients);\n        leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      }\n\n      // bring back dead node\n      ChaosMonkey.start(deadJetty.jetty); // he is not the leader anymore\n\n      waitTillRecovered();\n\n      // Kill the overseer\n      // TODO: Actually kill the Overseer instance\n      killer = new OverseerRestarter(zkServer.getZkAddress());\n      killerThread = new Thread(killer);\n      killerThread.start();\n      killCounter.incrementAndGet();\n\n      splitShard(SHARD1);\n\n      log.info(\"Layout after split: \\n\");\n      printLayout();\n\n      // distributed commit on all shards\n    } finally {\n      if (indexThread != null)\n        indexThread.join();\n      if (solrServer != null)\n        solrServer.commit();\n      if (killer != null) {\n        killer.run = false;\n        if (killerThread != null) {\n          killerThread.join();\n        }\n      }\n    }\n\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n\n    // todo - can't call waitForThingsToLevelOut because it looks for\n    // jettys of all shards\n    // and the new sub-shards don't have any.\n    waitForRecoveriesToFinish(true);\n    // waitForThingsToLevelOut(15);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2e73db80cda3387e197641256d964f8c1c3992c7","date":1380978036,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyShardSplitTest#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyShardSplitTest#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    waitForThingsToLevelOut(15);\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    Thread indexThread = null;\n    OverseerRestarter killer = null;\n    Thread killerThread = null;\n    final SolrServer solrServer = clients.get(0);\n\n    try {\n      del(\"*:*\");\n      for (int id = 0; id < 100; id++) {\n        indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n      }\n      commit();\n\n      indexThread = new Thread() {\n        @Override\n        public void run() {\n          int max = atLeast(401);\n          for (int id = 101; id < max; id++) {\n            try {\n              indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n              Thread.sleep(atLeast(25));\n            } catch (Exception e) {\n              log.error(\"Exception while adding doc\", e);\n            }\n          }\n        }\n      };\n      indexThread.start();\n\n      // kill the leader\n      CloudJettyRunner leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      chaosMonkey.killJetty(leaderJetty);\n\n      Thread.sleep(2000);\n\n      waitForThingsToLevelOut(90);\n\n      Thread.sleep(1000);\n      checkShardConsistency(false, true);\n\n      CloudJettyRunner deadJetty = leaderJetty;\n\n      // TODO: Check total docs ?\n      // long cloudClientDocs = cloudClient.query(new\n      // SolrQuery(\"*:*\")).getResults().getNumFound();\n\n      // Wait until new leader is elected\n      while (deadJetty == leaderJetty) {\n        updateMappingsFromZk(this.jettys, this.clients);\n        leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      }\n\n      // bring back dead node\n      ChaosMonkey.start(deadJetty.jetty); // he is not the leader anymore\n\n      waitTillRecovered();\n\n      // Kill the overseer\n      // TODO: Actually kill the Overseer instance\n      killer = new OverseerRestarter(zkServer.getZkAddress());\n      killerThread = new Thread(killer);\n      killerThread.start();\n      killCounter.incrementAndGet();\n\n      splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, null);\n\n      log.info(\"Layout after split: \\n\");\n      printLayout();\n\n      // distributed commit on all shards\n    } finally {\n      if (indexThread != null)\n        indexThread.join();\n      if (solrServer != null)\n        solrServer.commit();\n      if (killer != null) {\n        killer.run = false;\n        if (killerThread != null) {\n          killerThread.join();\n        }\n      }\n    }\n\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n\n    // todo - can't call waitForThingsToLevelOut because it looks for\n    // jettys of all shards\n    // and the new sub-shards don't have any.\n    waitForRecoveriesToFinish(true);\n    // waitForThingsToLevelOut(15);\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    waitForThingsToLevelOut(15);\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    Thread indexThread = null;\n    OverseerRestarter killer = null;\n    Thread killerThread = null;\n    final SolrServer solrServer = clients.get(0);\n\n    try {\n      del(\"*:*\");\n      for (int id = 0; id < 100; id++) {\n        indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n      }\n      commit();\n\n      indexThread = new Thread() {\n        @Override\n        public void run() {\n          int max = atLeast(401);\n          for (int id = 101; id < max; id++) {\n            try {\n              indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n              Thread.sleep(atLeast(25));\n            } catch (Exception e) {\n              log.error(\"Exception while adding doc\", e);\n            }\n          }\n        }\n      };\n      indexThread.start();\n\n      // kill the leader\n      CloudJettyRunner leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      chaosMonkey.killJetty(leaderJetty);\n\n      Thread.sleep(2000);\n\n      waitForThingsToLevelOut(90);\n\n      Thread.sleep(1000);\n      checkShardConsistency(false, true);\n\n      CloudJettyRunner deadJetty = leaderJetty;\n\n      // TODO: Check total docs ?\n      // long cloudClientDocs = cloudClient.query(new\n      // SolrQuery(\"*:*\")).getResults().getNumFound();\n\n      // Wait until new leader is elected\n      while (deadJetty == leaderJetty) {\n        updateMappingsFromZk(this.jettys, this.clients);\n        leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      }\n\n      // bring back dead node\n      ChaosMonkey.start(deadJetty.jetty); // he is not the leader anymore\n\n      waitTillRecovered();\n\n      // Kill the overseer\n      // TODO: Actually kill the Overseer instance\n      killer = new OverseerRestarter(zkServer.getZkAddress());\n      killerThread = new Thread(killer);\n      killerThread.start();\n      killCounter.incrementAndGet();\n\n      splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n\n      log.info(\"Layout after split: \\n\");\n      printLayout();\n\n      // distributed commit on all shards\n    } finally {\n      if (indexThread != null)\n        indexThread.join();\n      if (solrServer != null)\n        solrServer.commit();\n      if (killer != null) {\n        killer.run = false;\n        if (killerThread != null) {\n          killerThread.join();\n        }\n      }\n    }\n\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n\n    // todo - can't call waitForThingsToLevelOut because it looks for\n    // jettys of all shards\n    // and the new sub-shards don't have any.\n    waitForRecoveriesToFinish(true);\n    // waitForThingsToLevelOut(15);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d9d5abf772262a05c74afddcadc95c4bdab07f1f","date":1381747682,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyShardSplitTest#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyShardSplitTest#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    waitForThingsToLevelOut(15);\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    Thread indexThread = null;\n    OverseerRestarter killer = null;\n    Thread killerThread = null;\n    final SolrServer solrServer = clients.get(0);\n\n    try {\n      del(\"*:*\");\n      for (int id = 0; id < 100; id++) {\n        indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n      }\n      commit();\n\n      indexThread = new Thread() {\n        @Override\n        public void run() {\n          int max = atLeast(401);\n          for (int id = 101; id < max; id++) {\n            try {\n              indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n              Thread.sleep(atLeast(25));\n            } catch (Exception e) {\n              log.error(\"Exception while adding doc\", e);\n            }\n          }\n        }\n      };\n      indexThread.start();\n\n      // kill the leader\n      CloudJettyRunner leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      chaosMonkey.killJetty(leaderJetty);\n\n      Thread.sleep(2000);\n\n      waitForThingsToLevelOut(90);\n\n      Thread.sleep(1000);\n      checkShardConsistency(false, true);\n\n      CloudJettyRunner deadJetty = leaderJetty;\n\n      // TODO: Check total docs ?\n      // long cloudClientDocs = cloudClient.query(new\n      // SolrQuery(\"*:*\")).getResults().getNumFound();\n\n      // Wait until new leader is elected\n      while (deadJetty == leaderJetty) {\n        updateMappingsFromZk(this.jettys, this.clients);\n        leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      }\n\n      // bring back dead node\n      ChaosMonkey.start(deadJetty.jetty); // he is not the leader anymore\n\n      waitTillRecovered();\n\n      // Kill the overseer\n      // TODO: Actually kill the Overseer instance\n      killer = new OverseerRestarter(zkServer.getZkAddress());\n      killerThread = new Thread(killer);\n      killerThread.start();\n      killCounter.incrementAndGet();\n\n      splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, null, null);\n\n      log.info(\"Layout after split: \\n\");\n      printLayout();\n\n      // distributed commit on all shards\n    } finally {\n      if (indexThread != null)\n        indexThread.join();\n      if (solrServer != null)\n        solrServer.commit();\n      if (killer != null) {\n        killer.run = false;\n        if (killerThread != null) {\n          killerThread.join();\n        }\n      }\n    }\n\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n\n    // todo - can't call waitForThingsToLevelOut because it looks for\n    // jettys of all shards\n    // and the new sub-shards don't have any.\n    waitForRecoveriesToFinish(true);\n    // waitForThingsToLevelOut(15);\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    waitForThingsToLevelOut(15);\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    Thread indexThread = null;\n    OverseerRestarter killer = null;\n    Thread killerThread = null;\n    final SolrServer solrServer = clients.get(0);\n\n    try {\n      del(\"*:*\");\n      for (int id = 0; id < 100; id++) {\n        indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n      }\n      commit();\n\n      indexThread = new Thread() {\n        @Override\n        public void run() {\n          int max = atLeast(401);\n          for (int id = 101; id < max; id++) {\n            try {\n              indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n              Thread.sleep(atLeast(25));\n            } catch (Exception e) {\n              log.error(\"Exception while adding doc\", e);\n            }\n          }\n        }\n      };\n      indexThread.start();\n\n      // kill the leader\n      CloudJettyRunner leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      chaosMonkey.killJetty(leaderJetty);\n\n      Thread.sleep(2000);\n\n      waitForThingsToLevelOut(90);\n\n      Thread.sleep(1000);\n      checkShardConsistency(false, true);\n\n      CloudJettyRunner deadJetty = leaderJetty;\n\n      // TODO: Check total docs ?\n      // long cloudClientDocs = cloudClient.query(new\n      // SolrQuery(\"*:*\")).getResults().getNumFound();\n\n      // Wait until new leader is elected\n      while (deadJetty == leaderJetty) {\n        updateMappingsFromZk(this.jettys, this.clients);\n        leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      }\n\n      // bring back dead node\n      ChaosMonkey.start(deadJetty.jetty); // he is not the leader anymore\n\n      waitTillRecovered();\n\n      // Kill the overseer\n      // TODO: Actually kill the Overseer instance\n      killer = new OverseerRestarter(zkServer.getZkAddress());\n      killerThread = new Thread(killer);\n      killerThread.start();\n      killCounter.incrementAndGet();\n\n      splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, null);\n\n      log.info(\"Layout after split: \\n\");\n      printLayout();\n\n      // distributed commit on all shards\n    } finally {\n      if (indexThread != null)\n        indexThread.join();\n      if (solrServer != null)\n        solrServer.commit();\n      if (killer != null) {\n        killer.run = false;\n        if (killerThread != null) {\n          killerThread.join();\n        }\n      }\n    }\n\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n\n    // todo - can't call waitForThingsToLevelOut because it looks for\n    // jettys of all shards\n    // and the new sub-shards don't have any.\n    waitForRecoveriesToFinish(true);\n    // waitForThingsToLevelOut(15);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bafca15d8e408346a67f4282ad1143b88023893b","date":1420034748,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyShardSplitTest#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyShardSplitTest#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    waitForThingsToLevelOut(15);\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    Thread indexThread = null;\n    OverseerRestarter killer = null;\n    Thread killerThread = null;\n    final SolrClient solrClient = clients.get(0);\n\n    try {\n      del(\"*:*\");\n      for (int id = 0; id < 100; id++) {\n        indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n      }\n      commit();\n\n      indexThread = new Thread() {\n        @Override\n        public void run() {\n          int max = atLeast(401);\n          for (int id = 101; id < max; id++) {\n            try {\n              indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n              Thread.sleep(atLeast(25));\n            } catch (Exception e) {\n              log.error(\"Exception while adding doc\", e);\n            }\n          }\n        }\n      };\n      indexThread.start();\n\n      // kill the leader\n      CloudJettyRunner leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      chaosMonkey.killJetty(leaderJetty);\n\n      Thread.sleep(2000);\n\n      waitForThingsToLevelOut(90);\n\n      Thread.sleep(1000);\n      checkShardConsistency(false, true);\n\n      CloudJettyRunner deadJetty = leaderJetty;\n\n      // TODO: Check total docs ?\n      // long cloudClientDocs = cloudClient.query(new\n      // SolrQuery(\"*:*\")).getResults().getNumFound();\n\n      // Wait until new leader is elected\n      while (deadJetty == leaderJetty) {\n        updateMappingsFromZk(this.jettys, this.clients);\n        leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      }\n\n      // bring back dead node\n      ChaosMonkey.start(deadJetty.jetty); // he is not the leader anymore\n\n      waitTillRecovered();\n\n      // Kill the overseer\n      // TODO: Actually kill the Overseer instance\n      killer = new OverseerRestarter(zkServer.getZkAddress());\n      killerThread = new Thread(killer);\n      killerThread.start();\n      killCounter.incrementAndGet();\n\n      splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, null, null);\n\n      log.info(\"Layout after split: \\n\");\n      printLayout();\n\n      // distributed commit on all shards\n    } finally {\n      if (indexThread != null)\n        indexThread.join();\n      if (solrClient != null)\n        solrClient.commit();\n      if (killer != null) {\n        killer.run = false;\n        if (killerThread != null) {\n          killerThread.join();\n        }\n      }\n    }\n\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n\n    // todo - can't call waitForThingsToLevelOut because it looks for\n    // jettys of all shards\n    // and the new sub-shards don't have any.\n    waitForRecoveriesToFinish(true);\n    // waitForThingsToLevelOut(15);\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    waitForThingsToLevelOut(15);\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    Thread indexThread = null;\n    OverseerRestarter killer = null;\n    Thread killerThread = null;\n    final SolrServer solrServer = clients.get(0);\n\n    try {\n      del(\"*:*\");\n      for (int id = 0; id < 100; id++) {\n        indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n      }\n      commit();\n\n      indexThread = new Thread() {\n        @Override\n        public void run() {\n          int max = atLeast(401);\n          for (int id = 101; id < max; id++) {\n            try {\n              indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n              Thread.sleep(atLeast(25));\n            } catch (Exception e) {\n              log.error(\"Exception while adding doc\", e);\n            }\n          }\n        }\n      };\n      indexThread.start();\n\n      // kill the leader\n      CloudJettyRunner leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      chaosMonkey.killJetty(leaderJetty);\n\n      Thread.sleep(2000);\n\n      waitForThingsToLevelOut(90);\n\n      Thread.sleep(1000);\n      checkShardConsistency(false, true);\n\n      CloudJettyRunner deadJetty = leaderJetty;\n\n      // TODO: Check total docs ?\n      // long cloudClientDocs = cloudClient.query(new\n      // SolrQuery(\"*:*\")).getResults().getNumFound();\n\n      // Wait until new leader is elected\n      while (deadJetty == leaderJetty) {\n        updateMappingsFromZk(this.jettys, this.clients);\n        leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      }\n\n      // bring back dead node\n      ChaosMonkey.start(deadJetty.jetty); // he is not the leader anymore\n\n      waitTillRecovered();\n\n      // Kill the overseer\n      // TODO: Actually kill the Overseer instance\n      killer = new OverseerRestarter(zkServer.getZkAddress());\n      killerThread = new Thread(killer);\n      killerThread.start();\n      killCounter.incrementAndGet();\n\n      splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, null, null);\n\n      log.info(\"Layout after split: \\n\");\n      printLayout();\n\n      // distributed commit on all shards\n    } finally {\n      if (indexThread != null)\n        indexThread.join();\n      if (solrServer != null)\n        solrServer.commit();\n      if (killer != null) {\n        killer.run = false;\n        if (killerThread != null) {\n          killerThread.join();\n        }\n      }\n    }\n\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n\n    // todo - can't call waitForThingsToLevelOut because it looks for\n    // jettys of all shards\n    // and the new sub-shards don't have any.\n    waitForRecoveriesToFinish(true);\n    // waitForThingsToLevelOut(15);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"abb23fcc2461782ab204e61213240feb77d355aa","date":1422029612,"type":5,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyShardSplitTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyShardSplitTest#doTest().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    waitForThingsToLevelOut(15);\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    Thread indexThread = null;\n    OverseerRestarter killer = null;\n    Thread killerThread = null;\n    final SolrClient solrClient = clients.get(0);\n\n    try {\n      del(\"*:*\");\n      for (int id = 0; id < 100; id++) {\n        indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n      }\n      commit();\n\n      indexThread = new Thread() {\n        @Override\n        public void run() {\n          int max = atLeast(401);\n          for (int id = 101; id < max; id++) {\n            try {\n              indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n              Thread.sleep(atLeast(25));\n            } catch (Exception e) {\n              log.error(\"Exception while adding doc\", e);\n            }\n          }\n        }\n      };\n      indexThread.start();\n\n      // kill the leader\n      CloudJettyRunner leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      chaosMonkey.killJetty(leaderJetty);\n\n      Thread.sleep(2000);\n\n      waitForThingsToLevelOut(90);\n\n      Thread.sleep(1000);\n      checkShardConsistency(false, true);\n\n      CloudJettyRunner deadJetty = leaderJetty;\n\n      // TODO: Check total docs ?\n      // long cloudClientDocs = cloudClient.query(new\n      // SolrQuery(\"*:*\")).getResults().getNumFound();\n\n      // Wait until new leader is elected\n      while (deadJetty == leaderJetty) {\n        updateMappingsFromZk(this.jettys, this.clients);\n        leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      }\n\n      // bring back dead node\n      ChaosMonkey.start(deadJetty.jetty); // he is not the leader anymore\n\n      waitTillRecovered();\n\n      // Kill the overseer\n      // TODO: Actually kill the Overseer instance\n      killer = new OverseerRestarter(zkServer.getZkAddress());\n      killerThread = new Thread(killer);\n      killerThread.start();\n      killCounter.incrementAndGet();\n\n      splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, null, null);\n\n      log.info(\"Layout after split: \\n\");\n      printLayout();\n\n      // distributed commit on all shards\n    } finally {\n      if (indexThread != null)\n        indexThread.join();\n      if (solrClient != null)\n        solrClient.commit();\n      if (killer != null) {\n        killer.run = false;\n        if (killerThread != null) {\n          killerThread.join();\n        }\n      }\n    }\n\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n\n    // todo - can't call waitForThingsToLevelOut because it looks for\n    // jettys of all shards\n    // and the new sub-shards don't have any.\n    waitForRecoveriesToFinish(true);\n    // waitForThingsToLevelOut(15);\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    waitForThingsToLevelOut(15);\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    Thread indexThread = null;\n    OverseerRestarter killer = null;\n    Thread killerThread = null;\n    final SolrClient solrClient = clients.get(0);\n\n    try {\n      del(\"*:*\");\n      for (int id = 0; id < 100; id++) {\n        indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n      }\n      commit();\n\n      indexThread = new Thread() {\n        @Override\n        public void run() {\n          int max = atLeast(401);\n          for (int id = 101; id < max; id++) {\n            try {\n              indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n              Thread.sleep(atLeast(25));\n            } catch (Exception e) {\n              log.error(\"Exception while adding doc\", e);\n            }\n          }\n        }\n      };\n      indexThread.start();\n\n      // kill the leader\n      CloudJettyRunner leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      chaosMonkey.killJetty(leaderJetty);\n\n      Thread.sleep(2000);\n\n      waitForThingsToLevelOut(90);\n\n      Thread.sleep(1000);\n      checkShardConsistency(false, true);\n\n      CloudJettyRunner deadJetty = leaderJetty;\n\n      // TODO: Check total docs ?\n      // long cloudClientDocs = cloudClient.query(new\n      // SolrQuery(\"*:*\")).getResults().getNumFound();\n\n      // Wait until new leader is elected\n      while (deadJetty == leaderJetty) {\n        updateMappingsFromZk(this.jettys, this.clients);\n        leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      }\n\n      // bring back dead node\n      ChaosMonkey.start(deadJetty.jetty); // he is not the leader anymore\n\n      waitTillRecovered();\n\n      // Kill the overseer\n      // TODO: Actually kill the Overseer instance\n      killer = new OverseerRestarter(zkServer.getZkAddress());\n      killerThread = new Thread(killer);\n      killerThread.start();\n      killCounter.incrementAndGet();\n\n      splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, null, null);\n\n      log.info(\"Layout after split: \\n\");\n      printLayout();\n\n      // distributed commit on all shards\n    } finally {\n      if (indexThread != null)\n        indexThread.join();\n      if (solrClient != null)\n        solrClient.commit();\n      if (killer != null) {\n        killer.run = false;\n        if (killerThread != null) {\n          killerThread.join();\n        }\n      }\n    }\n\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n\n    // todo - can't call waitForThingsToLevelOut because it looks for\n    // jettys of all shards\n    // and the new sub-shards don't have any.\n    waitForRecoveriesToFinish(true);\n    // waitForThingsToLevelOut(15);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"1816753738ff1f27f11b38030e83c0ded050b7a4":["8f1ea787bab5bdb5e72685e55424898da05509b6"],"2dbed1dd58810b079506c1e4cd13ce80e646faed":["6776b3c3ed554ace17893a807da5b7a0a6d364c8"],"abb23fcc2461782ab204e61213240feb77d355aa":["bafca15d8e408346a67f4282ad1143b88023893b"],"6776b3c3ed554ace17893a807da5b7a0a6d364c8":["8735477f53284dd67c6335828378cadf20cddabc"],"8f1ea787bab5bdb5e72685e55424898da05509b6":["2dbed1dd58810b079506c1e4cd13ce80e646faed"],"bafca15d8e408346a67f4282ad1143b88023893b":["d9d5abf772262a05c74afddcadc95c4bdab07f1f"],"8735477f53284dd67c6335828378cadf20cddabc":["8305fcb8f629f095ee305d1e994a80e521be2ff3"],"0beaed456aa3358e5e4a99ea2aea994ef6c81de3":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"8305fcb8f629f095ee305d1e994a80e521be2ff3":["e4daf0e37630dc4d06c6bcf53c19bfb09e0ba6dd"],"e4daf0e37630dc4d06c6bcf53c19bfb09e0ba6dd":["0beaed456aa3358e5e4a99ea2aea994ef6c81de3"],"2e73db80cda3387e197641256d964f8c1c3992c7":["1816753738ff1f27f11b38030e83c0ded050b7a4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d9d5abf772262a05c74afddcadc95c4bdab07f1f":["2e73db80cda3387e197641256d964f8c1c3992c7"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["abb23fcc2461782ab204e61213240feb77d355aa"]},"commit2Childs":{"1816753738ff1f27f11b38030e83c0ded050b7a4":["2e73db80cda3387e197641256d964f8c1c3992c7"],"2dbed1dd58810b079506c1e4cd13ce80e646faed":["8f1ea787bab5bdb5e72685e55424898da05509b6"],"6776b3c3ed554ace17893a807da5b7a0a6d364c8":["2dbed1dd58810b079506c1e4cd13ce80e646faed"],"abb23fcc2461782ab204e61213240feb77d355aa":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"8f1ea787bab5bdb5e72685e55424898da05509b6":["1816753738ff1f27f11b38030e83c0ded050b7a4"],"bafca15d8e408346a67f4282ad1143b88023893b":["abb23fcc2461782ab204e61213240feb77d355aa"],"8735477f53284dd67c6335828378cadf20cddabc":["6776b3c3ed554ace17893a807da5b7a0a6d364c8"],"0beaed456aa3358e5e4a99ea2aea994ef6c81de3":["e4daf0e37630dc4d06c6bcf53c19bfb09e0ba6dd"],"8305fcb8f629f095ee305d1e994a80e521be2ff3":["8735477f53284dd67c6335828378cadf20cddabc"],"e4daf0e37630dc4d06c6bcf53c19bfb09e0ba6dd":["8305fcb8f629f095ee305d1e994a80e521be2ff3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["0beaed456aa3358e5e4a99ea2aea994ef6c81de3"],"2e73db80cda3387e197641256d964f8c1c3992c7":["d9d5abf772262a05c74afddcadc95c4bdab07f1f"],"d9d5abf772262a05c74afddcadc95c4bdab07f1f":["bafca15d8e408346a67f4282ad1143b88023893b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}