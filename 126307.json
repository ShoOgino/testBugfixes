{"path":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","pathOld":"contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","sourceNew":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    String fieldName = StringHelper.intern(field);\n    int[] termCounts = new int[0];\n    \n    IndexReader reader = null;\n    TermEnum termEnum = null;\n    TermDocs termDocs = null;\n    try {\n      reader = IndexReader.open(dir, true);\n      termCounts = new int[reader.maxDoc()];\n      try {\n        termEnum = reader.terms(new Term(field));\n        try {\n          termDocs = reader.termDocs();\n          do {\n            Term term = termEnum.term();\n            if (term != null && term.field().equals(fieldName)) {\n              termDocs.seek(termEnum.term());\n              while (termDocs.next()) {\n                termCounts[termDocs.doc()] += termDocs.freq();\n              }\n            }\n          } while (termEnum.next());\n          \n        } finally {\n          if (null != termDocs) termDocs.close();\n        }\n      } finally {\n        if (null != termEnum) termEnum.close();\n      }\n    } finally {\n      if (null != reader) reader.close();\n    }\n    \n    try {\n      reader = IndexReader.open(dir, false); \n      for (int d = 0; d < termCounts.length; d++) {\n        if (! reader.isDeleted(d)) {\n          if (sim == null)\n            reader.setNorm(d, fieldName, Similarity.encodeNorm(1.0f));\n          else\n            reader.setNorm(d, fieldName, sim.encodeNormValue(sim.lengthNorm(fieldName, termCounts[d])));\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","sourceOld":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    String fieldName = StringHelper.intern(field);\n    int[] termCounts = new int[0];\n    \n    IndexReader reader = null;\n    TermEnum termEnum = null;\n    TermDocs termDocs = null;\n    try {\n      reader = IndexReader.open(dir, true);\n      termCounts = new int[reader.maxDoc()];\n      try {\n        termEnum = reader.terms(new Term(field));\n        try {\n          termDocs = reader.termDocs();\n          do {\n            Term term = termEnum.term();\n            if (term != null && term.field().equals(fieldName)) {\n              termDocs.seek(termEnum.term());\n              while (termDocs.next()) {\n                termCounts[termDocs.doc()] += termDocs.freq();\n              }\n            }\n          } while (termEnum.next());\n          \n        } finally {\n          if (null != termDocs) termDocs.close();\n        }\n      } finally {\n        if (null != termEnum) termEnum.close();\n      }\n    } finally {\n      if (null != reader) reader.close();\n    }\n    \n    try {\n      reader = IndexReader.open(dir, false); \n      for (int d = 0; d < termCounts.length; d++) {\n        if (! reader.isDeleted(d)) {\n          if (sim == null)\n            reader.setNorm(d, fieldName, Similarity.encodeNorm(1.0f));\n          else\n            reader.setNorm(d, fieldName, sim.encodeNormValue(sim.lengthNorm(fieldName, termCounts[d])));\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"955c32f886db6f6356c9fcdea6b1f1cb4effda24","date":1270581567,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","sourceNew":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    String fieldName = StringHelper.intern(field);\n    \n    IndexReader reader = null;\n    try {\n      reader = IndexReader.open(dir, false);\n\n      final List<IndexReader> subReaders = new ArrayList<IndexReader>();\n      ReaderUtil.gatherSubReaders(subReaders, reader);\n\n      for(IndexReader subReader : subReaders) {\n        final Bits delDocs = subReader.getDeletedDocs();\n\n        int[] termCounts = new int[subReader.maxDoc()];\n        Fields fields = subReader.fields();\n        if (fields != null) {\n          Terms terms = fields.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator();\n            DocsEnum docs = null;\n            while(termsEnum.next() != null) {\n              docs = termsEnum.docs(delDocs, docs);\n              while(true) {\n                int docID = docs.nextDoc();\n                if (docID != docs.NO_MORE_DOCS) {\n                  termCounts[docID] += docs.freq();\n                } else {\n                  break;\n                }\n              }\n            }\n          }\n        }\n\n        for (int d = 0; d < termCounts.length; d++) {\n          if (delDocs == null || !delDocs.get(d)) {\n            if (sim == null) {\n              subReader.setNorm(d, fieldName, Similarity.encodeNorm(1.0f));\n            } else {\n              subReader.setNorm(d, fieldName, sim.encodeNormValue(sim.lengthNorm(fieldName, termCounts[d])));\n            }\n          }\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","sourceOld":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    String fieldName = StringHelper.intern(field);\n    int[] termCounts = new int[0];\n    \n    IndexReader reader = null;\n    TermEnum termEnum = null;\n    TermDocs termDocs = null;\n    try {\n      reader = IndexReader.open(dir, true);\n      termCounts = new int[reader.maxDoc()];\n      try {\n        termEnum = reader.terms(new Term(field));\n        try {\n          termDocs = reader.termDocs();\n          do {\n            Term term = termEnum.term();\n            if (term != null && term.field().equals(fieldName)) {\n              termDocs.seek(termEnum.term());\n              while (termDocs.next()) {\n                termCounts[termDocs.doc()] += termDocs.freq();\n              }\n            }\n          } while (termEnum.next());\n          \n        } finally {\n          if (null != termDocs) termDocs.close();\n        }\n      } finally {\n        if (null != termEnum) termEnum.close();\n      }\n    } finally {\n      if (null != reader) reader.close();\n    }\n    \n    try {\n      reader = IndexReader.open(dir, false); \n      for (int d = 0; d < termCounts.length; d++) {\n        if (! reader.isDeleted(d)) {\n          if (sim == null)\n            reader.setNorm(d, fieldName, Similarity.encodeNorm(1.0f));\n          else\n            reader.setNorm(d, fieldName, sim.encodeNormValue(sim.lengthNorm(fieldName, termCounts[d])));\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4e8cc373c801e54cec75daf9f52792cb4b17f536","date":1291116159,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","sourceNew":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    String fieldName = StringHelper.intern(field);\n    \n    IndexReader reader = null;\n    try {\n      reader = IndexReader.open(dir, false);\n\n      final List<IndexReader> subReaders = new ArrayList<IndexReader>();\n      ReaderUtil.gatherSubReaders(subReaders, reader);\n\n      for(IndexReader subReader : subReaders) {\n        final Bits delDocs = subReader.getDeletedDocs();\n\n        int[] termCounts = new int[subReader.maxDoc()];\n        Fields fields = subReader.fields();\n        if (fields != null) {\n          Terms terms = fields.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator();\n            DocsEnum docs = null;\n            while(termsEnum.next() != null) {\n              docs = termsEnum.docs(delDocs, docs);\n              while(true) {\n                int docID = docs.nextDoc();\n                if (docID != docs.NO_MORE_DOCS) {\n                  termCounts[docID] += docs.freq();\n                } else {\n                  break;\n                }\n              }\n            }\n          }\n        }\n\n        for (int d = 0; d < termCounts.length; d++) {\n          if (delDocs == null || !delDocs.get(d)) {\n            subReader.setNorm(d, fieldName, sim.encodeNormValue(sim.lengthNorm(fieldName, termCounts[d])));\n          }\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","sourceOld":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    String fieldName = StringHelper.intern(field);\n    \n    IndexReader reader = null;\n    try {\n      reader = IndexReader.open(dir, false);\n\n      final List<IndexReader> subReaders = new ArrayList<IndexReader>();\n      ReaderUtil.gatherSubReaders(subReaders, reader);\n\n      for(IndexReader subReader : subReaders) {\n        final Bits delDocs = subReader.getDeletedDocs();\n\n        int[] termCounts = new int[subReader.maxDoc()];\n        Fields fields = subReader.fields();\n        if (fields != null) {\n          Terms terms = fields.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator();\n            DocsEnum docs = null;\n            while(termsEnum.next() != null) {\n              docs = termsEnum.docs(delDocs, docs);\n              while(true) {\n                int docID = docs.nextDoc();\n                if (docID != docs.NO_MORE_DOCS) {\n                  termCounts[docID] += docs.freq();\n                } else {\n                  break;\n                }\n              }\n            }\n          }\n        }\n\n        for (int d = 0; d < termCounts.length; d++) {\n          if (delDocs == null || !delDocs.get(d)) {\n            if (sim == null) {\n              subReader.setNorm(d, fieldName, Similarity.encodeNorm(1.0f));\n            } else {\n              subReader.setNorm(d, fieldName, sim.encodeNormValue(sim.lengthNorm(fieldName, termCounts[d])));\n            }\n          }\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3bb13258feba31ab676502787ab2e1779f129b7a","date":1291596436,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","sourceNew":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    String fieldName = StringHelper.intern(field);\n    \n    IndexReader reader = null;\n    try {\n      reader = IndexReader.open(dir, false);\n\n      final List<IndexReader> subReaders = new ArrayList<IndexReader>();\n      ReaderUtil.gatherSubReaders(subReaders, reader);\n\n      for(IndexReader subReader : subReaders) {\n        final Bits delDocs = subReader.getDeletedDocs();\n\n        int[] termCounts = new int[subReader.maxDoc()];\n        Fields fields = subReader.fields();\n        if (fields != null) {\n          Terms terms = fields.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator();\n            DocsEnum docs = null;\n            while(termsEnum.next() != null) {\n              docs = termsEnum.docs(delDocs, docs);\n              while(true) {\n                int docID = docs.nextDoc();\n                if (docID != docs.NO_MORE_DOCS) {\n                  termCounts[docID] += docs.freq();\n                } else {\n                  break;\n                }\n              }\n            }\n          }\n        }\n\n        for (int d = 0; d < termCounts.length; d++) {\n          if (delDocs == null || !delDocs.get(d)) {\n            subReader.setNorm(d, fieldName, sim.encodeNormValue(sim.lengthNorm(fieldName, termCounts[d])));\n          }\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","sourceOld":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    String fieldName = StringHelper.intern(field);\n    \n    IndexReader reader = null;\n    try {\n      reader = IndexReader.open(dir, false);\n\n      final List<IndexReader> subReaders = new ArrayList<IndexReader>();\n      ReaderUtil.gatherSubReaders(subReaders, reader);\n\n      for(IndexReader subReader : subReaders) {\n        final Bits delDocs = subReader.getDeletedDocs();\n\n        int[] termCounts = new int[subReader.maxDoc()];\n        Fields fields = subReader.fields();\n        if (fields != null) {\n          Terms terms = fields.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator();\n            DocsEnum docs = null;\n            while(termsEnum.next() != null) {\n              docs = termsEnum.docs(delDocs, docs);\n              while(true) {\n                int docID = docs.nextDoc();\n                if (docID != docs.NO_MORE_DOCS) {\n                  termCounts[docID] += docs.freq();\n                } else {\n                  break;\n                }\n              }\n            }\n          }\n        }\n\n        for (int d = 0; d < termCounts.length; d++) {\n          if (delDocs == null || !delDocs.get(d)) {\n            if (sim == null) {\n              subReader.setNorm(d, fieldName, Similarity.encodeNorm(1.0f));\n            } else {\n              subReader.setNorm(d, fieldName, sim.encodeNormValue(sim.lengthNorm(fieldName, termCounts[d])));\n            }\n          }\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","sourceNew":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    String fieldName = StringHelper.intern(field);\n    \n    IndexReader reader = null;\n    try {\n      reader = IndexReader.open(dir, false);\n\n      final List<IndexReader> subReaders = new ArrayList<IndexReader>();\n      ReaderUtil.gatherSubReaders(subReaders, reader);\n\n      for(IndexReader subReader : subReaders) {\n        final Bits delDocs = subReader.getDeletedDocs();\n\n        int[] termCounts = new int[subReader.maxDoc()];\n        Fields fields = subReader.fields();\n        if (fields != null) {\n          Terms terms = fields.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator();\n            DocsEnum docs = null;\n            while(termsEnum.next() != null) {\n              docs = termsEnum.docs(delDocs, docs);\n              while(true) {\n                int docID = docs.nextDoc();\n                if (docID != docs.NO_MORE_DOCS) {\n                  termCounts[docID] += docs.freq();\n                } else {\n                  break;\n                }\n              }\n            }\n          }\n        }\n\n        for (int d = 0; d < termCounts.length; d++) {\n          if (delDocs == null || !delDocs.get(d)) {\n            subReader.setNorm(d, fieldName, sim.encodeNormValue(sim.lengthNorm(fieldName, termCounts[d])));\n          }\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","sourceOld":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    String fieldName = StringHelper.intern(field);\n    \n    IndexReader reader = null;\n    try {\n      reader = IndexReader.open(dir, false);\n\n      final List<IndexReader> subReaders = new ArrayList<IndexReader>();\n      ReaderUtil.gatherSubReaders(subReaders, reader);\n\n      for(IndexReader subReader : subReaders) {\n        final Bits delDocs = subReader.getDeletedDocs();\n\n        int[] termCounts = new int[subReader.maxDoc()];\n        Fields fields = subReader.fields();\n        if (fields != null) {\n          Terms terms = fields.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator();\n            DocsEnum docs = null;\n            while(termsEnum.next() != null) {\n              docs = termsEnum.docs(delDocs, docs);\n              while(true) {\n                int docID = docs.nextDoc();\n                if (docID != docs.NO_MORE_DOCS) {\n                  termCounts[docID] += docs.freq();\n                } else {\n                  break;\n                }\n              }\n            }\n          }\n        }\n\n        for (int d = 0; d < termCounts.length; d++) {\n          if (delDocs == null || !delDocs.get(d)) {\n            if (sim == null) {\n              subReader.setNorm(d, fieldName, Similarity.encodeNorm(1.0f));\n            } else {\n              subReader.setNorm(d, fieldName, sim.encodeNormValue(sim.lengthNorm(fieldName, termCounts[d])));\n            }\n          }\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3e00f80591de714c6975f454e33e0fa5218b5902","date":1294514405,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","sourceNew":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    String fieldName = StringHelper.intern(field);\n    \n    IndexReader reader = null;\n    try {\n      reader = IndexReader.open(dir, false);\n\n      final List<IndexReader> subReaders = new ArrayList<IndexReader>();\n      ReaderUtil.gatherSubReaders(subReaders, reader);\n\n      final FieldInvertState invertState = new FieldInvertState();\n      for(IndexReader subReader : subReaders) {\n        final Bits delDocs = subReader.getDeletedDocs();\n\n        int[] termCounts = new int[subReader.maxDoc()];\n        Fields fields = subReader.fields();\n        if (fields != null) {\n          Terms terms = fields.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator();\n            DocsEnum docs = null;\n            while(termsEnum.next() != null) {\n              docs = termsEnum.docs(delDocs, docs);\n              while(true) {\n                int docID = docs.nextDoc();\n                if (docID != docs.NO_MORE_DOCS) {\n                  termCounts[docID] += docs.freq();\n                } else {\n                  break;\n                }\n              }\n            }\n          }\n        }\n\n        invertState.setBoost(1.0f);\n        for (int d = 0; d < termCounts.length; d++) {\n          if (delDocs == null || !delDocs.get(d)) {\n            invertState.setLength(termCounts[d]);\n            subReader.setNorm(d, fieldName, sim.encodeNormValue(sim.computeNorm(fieldName, invertState)));\n          }\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","sourceOld":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    String fieldName = StringHelper.intern(field);\n    \n    IndexReader reader = null;\n    try {\n      reader = IndexReader.open(dir, false);\n\n      final List<IndexReader> subReaders = new ArrayList<IndexReader>();\n      ReaderUtil.gatherSubReaders(subReaders, reader);\n\n      for(IndexReader subReader : subReaders) {\n        final Bits delDocs = subReader.getDeletedDocs();\n\n        int[] termCounts = new int[subReader.maxDoc()];\n        Fields fields = subReader.fields();\n        if (fields != null) {\n          Terms terms = fields.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator();\n            DocsEnum docs = null;\n            while(termsEnum.next() != null) {\n              docs = termsEnum.docs(delDocs, docs);\n              while(true) {\n                int docID = docs.nextDoc();\n                if (docID != docs.NO_MORE_DOCS) {\n                  termCounts[docID] += docs.freq();\n                } else {\n                  break;\n                }\n              }\n            }\n          }\n        }\n\n        for (int d = 0; d < termCounts.length; d++) {\n          if (delDocs == null || !delDocs.get(d)) {\n            subReader.setNorm(d, fieldName, sim.encodeNormValue(sim.lengthNorm(fieldName, termCounts[d])));\n          }\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"868da859b43505d9d2a023bfeae6dd0c795f5295","date":1294948401,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","sourceNew":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    String fieldName = StringHelper.intern(field);\n    \n    IndexReader reader = null;\n    try {\n      reader = IndexReader.open(dir, false);\n\n      final List<IndexReader> subReaders = new ArrayList<IndexReader>();\n      ReaderUtil.gatherSubReaders(subReaders, reader);\n\n      final FieldInvertState invertState = new FieldInvertState();\n      for(IndexReader subReader : subReaders) {\n        final Bits delDocs = subReader.getDeletedDocs();\n\n        int[] termCounts = new int[subReader.maxDoc()];\n        Fields fields = subReader.fields();\n        if (fields != null) {\n          Terms terms = fields.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator();\n            DocsEnum docs = null;\n            while(termsEnum.next() != null) {\n              docs = termsEnum.docs(delDocs, docs);\n              while(true) {\n                int docID = docs.nextDoc();\n                if (docID != docs.NO_MORE_DOCS) {\n                  termCounts[docID] += docs.freq();\n                } else {\n                  break;\n                }\n              }\n            }\n          }\n        }\n\n        invertState.setBoost(1.0f);\n        for (int d = 0; d < termCounts.length; d++) {\n          if (delDocs == null || !delDocs.get(d)) {\n            invertState.setLength(termCounts[d]);\n            subReader.setNorm(d, fieldName, sim.encodeNormValue(sim.computeNorm(fieldName, invertState)));\n          }\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","sourceOld":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    String fieldName = StringHelper.intern(field);\n    \n    IndexReader reader = null;\n    try {\n      reader = IndexReader.open(dir, false);\n\n      final List<IndexReader> subReaders = new ArrayList<IndexReader>();\n      ReaderUtil.gatherSubReaders(subReaders, reader);\n\n      for(IndexReader subReader : subReaders) {\n        final Bits delDocs = subReader.getDeletedDocs();\n\n        int[] termCounts = new int[subReader.maxDoc()];\n        Fields fields = subReader.fields();\n        if (fields != null) {\n          Terms terms = fields.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator();\n            DocsEnum docs = null;\n            while(termsEnum.next() != null) {\n              docs = termsEnum.docs(delDocs, docs);\n              while(true) {\n                int docID = docs.nextDoc();\n                if (docID != docs.NO_MORE_DOCS) {\n                  termCounts[docID] += docs.freq();\n                } else {\n                  break;\n                }\n              }\n            }\n          }\n        }\n\n        for (int d = 0; d < termCounts.length; d++) {\n          if (delDocs == null || !delDocs.get(d)) {\n            subReader.setNorm(d, fieldName, sim.encodeNormValue(sim.lengthNorm(fieldName, termCounts[d])));\n          }\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fd9325c7ff9928fabe81c28553b41fc7aa57dfab","date":1295896411,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","sourceNew":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    String fieldName = StringHelper.intern(field);\n    Similarity fieldSim = sim.get(field); \n    IndexReader reader = null;\n    try {\n      reader = IndexReader.open(dir, false);\n\n      final List<IndexReader> subReaders = new ArrayList<IndexReader>();\n      ReaderUtil.gatherSubReaders(subReaders, reader);\n\n      final FieldInvertState invertState = new FieldInvertState();\n      for(IndexReader subReader : subReaders) {\n        final Bits delDocs = subReader.getDeletedDocs();\n\n        int[] termCounts = new int[subReader.maxDoc()];\n        Fields fields = subReader.fields();\n        if (fields != null) {\n          Terms terms = fields.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator();\n            DocsEnum docs = null;\n            while(termsEnum.next() != null) {\n              docs = termsEnum.docs(delDocs, docs);\n              while(true) {\n                int docID = docs.nextDoc();\n                if (docID != docs.NO_MORE_DOCS) {\n                  termCounts[docID] += docs.freq();\n                } else {\n                  break;\n                }\n              }\n            }\n          }\n        }\n\n        invertState.setBoost(1.0f);\n        for (int d = 0; d < termCounts.length; d++) {\n          if (delDocs == null || !delDocs.get(d)) {\n            invertState.setLength(termCounts[d]);\n            subReader.setNorm(d, fieldName, fieldSim.encodeNormValue(fieldSim.computeNorm(fieldName, invertState)));\n          }\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","sourceOld":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    String fieldName = StringHelper.intern(field);\n    \n    IndexReader reader = null;\n    try {\n      reader = IndexReader.open(dir, false);\n\n      final List<IndexReader> subReaders = new ArrayList<IndexReader>();\n      ReaderUtil.gatherSubReaders(subReaders, reader);\n\n      final FieldInvertState invertState = new FieldInvertState();\n      for(IndexReader subReader : subReaders) {\n        final Bits delDocs = subReader.getDeletedDocs();\n\n        int[] termCounts = new int[subReader.maxDoc()];\n        Fields fields = subReader.fields();\n        if (fields != null) {\n          Terms terms = fields.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator();\n            DocsEnum docs = null;\n            while(termsEnum.next() != null) {\n              docs = termsEnum.docs(delDocs, docs);\n              while(true) {\n                int docID = docs.nextDoc();\n                if (docID != docs.NO_MORE_DOCS) {\n                  termCounts[docID] += docs.freq();\n                } else {\n                  break;\n                }\n              }\n            }\n          }\n        }\n\n        invertState.setBoost(1.0f);\n        for (int d = 0; d < termCounts.length; d++) {\n          if (delDocs == null || !delDocs.get(d)) {\n            invertState.setLength(termCounts[d]);\n            subReader.setNorm(d, fieldName, sim.encodeNormValue(sim.computeNorm(fieldName, invertState)));\n          }\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bb9b72f7c3d7827c64dd4ec580ded81778da361d","date":1295897920,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","sourceNew":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    String fieldName = StringHelper.intern(field);\n    Similarity fieldSim = sim.get(field); \n    IndexReader reader = null;\n    try {\n      reader = IndexReader.open(dir, false);\n\n      final List<IndexReader> subReaders = new ArrayList<IndexReader>();\n      ReaderUtil.gatherSubReaders(subReaders, reader);\n\n      final FieldInvertState invertState = new FieldInvertState();\n      for(IndexReader subReader : subReaders) {\n        final Bits delDocs = subReader.getDeletedDocs();\n\n        int[] termCounts = new int[subReader.maxDoc()];\n        Fields fields = subReader.fields();\n        if (fields != null) {\n          Terms terms = fields.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator();\n            DocsEnum docs = null;\n            while(termsEnum.next() != null) {\n              docs = termsEnum.docs(delDocs, docs);\n              while(true) {\n                int docID = docs.nextDoc();\n                if (docID != docs.NO_MORE_DOCS) {\n                  termCounts[docID] += docs.freq();\n                } else {\n                  break;\n                }\n              }\n            }\n          }\n        }\n\n        invertState.setBoost(1.0f);\n        for (int d = 0; d < termCounts.length; d++) {\n          if (delDocs == null || !delDocs.get(d)) {\n            invertState.setLength(termCounts[d]);\n            subReader.setNorm(d, fieldName, fieldSim.encodeNormValue(fieldSim.computeNorm(fieldName, invertState)));\n          }\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","sourceOld":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    String fieldName = StringHelper.intern(field);\n    \n    IndexReader reader = null;\n    try {\n      reader = IndexReader.open(dir, false);\n\n      final List<IndexReader> subReaders = new ArrayList<IndexReader>();\n      ReaderUtil.gatherSubReaders(subReaders, reader);\n\n      final FieldInvertState invertState = new FieldInvertState();\n      for(IndexReader subReader : subReaders) {\n        final Bits delDocs = subReader.getDeletedDocs();\n\n        int[] termCounts = new int[subReader.maxDoc()];\n        Fields fields = subReader.fields();\n        if (fields != null) {\n          Terms terms = fields.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator();\n            DocsEnum docs = null;\n            while(termsEnum.next() != null) {\n              docs = termsEnum.docs(delDocs, docs);\n              while(true) {\n                int docID = docs.nextDoc();\n                if (docID != docs.NO_MORE_DOCS) {\n                  termCounts[docID] += docs.freq();\n                } else {\n                  break;\n                }\n              }\n            }\n          }\n        }\n\n        invertState.setBoost(1.0f);\n        for (int d = 0; d < termCounts.length; d++) {\n          if (delDocs == null || !delDocs.get(d)) {\n            invertState.setLength(termCounts[d]);\n            subReader.setNorm(d, fieldName, sim.encodeNormValue(sim.computeNorm(fieldName, invertState)));\n          }\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","sourceNew":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    String fieldName = StringHelper.intern(field);\n    Similarity fieldSim = sim.get(field); \n    IndexReader reader = null;\n    try {\n      reader = IndexReader.open(dir, false);\n\n      final List<IndexReader> subReaders = new ArrayList<IndexReader>();\n      ReaderUtil.gatherSubReaders(subReaders, reader);\n\n      final FieldInvertState invertState = new FieldInvertState();\n      for(IndexReader subReader : subReaders) {\n        final Bits delDocs = subReader.getDeletedDocs();\n\n        int[] termCounts = new int[subReader.maxDoc()];\n        Fields fields = subReader.fields();\n        if (fields != null) {\n          Terms terms = fields.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator();\n            DocsEnum docs = null;\n            while(termsEnum.next() != null) {\n              docs = termsEnum.docs(delDocs, docs);\n              while(true) {\n                int docID = docs.nextDoc();\n                if (docID != docs.NO_MORE_DOCS) {\n                  termCounts[docID] += docs.freq();\n                } else {\n                  break;\n                }\n              }\n            }\n          }\n        }\n\n        invertState.setBoost(1.0f);\n        for (int d = 0; d < termCounts.length; d++) {\n          if (delDocs == null || !delDocs.get(d)) {\n            invertState.setLength(termCounts[d]);\n            subReader.setNorm(d, fieldName, fieldSim.encodeNormValue(fieldSim.computeNorm(fieldName, invertState)));\n          }\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","sourceOld":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    String fieldName = StringHelper.intern(field);\n    \n    IndexReader reader = null;\n    try {\n      reader = IndexReader.open(dir, false);\n\n      final List<IndexReader> subReaders = new ArrayList<IndexReader>();\n      ReaderUtil.gatherSubReaders(subReaders, reader);\n\n      for(IndexReader subReader : subReaders) {\n        final Bits delDocs = subReader.getDeletedDocs();\n\n        int[] termCounts = new int[subReader.maxDoc()];\n        Fields fields = subReader.fields();\n        if (fields != null) {\n          Terms terms = fields.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator();\n            DocsEnum docs = null;\n            while(termsEnum.next() != null) {\n              docs = termsEnum.docs(delDocs, docs);\n              while(true) {\n                int docID = docs.nextDoc();\n                if (docID != docs.NO_MORE_DOCS) {\n                  termCounts[docID] += docs.freq();\n                } else {\n                  break;\n                }\n              }\n            }\n          }\n        }\n\n        for (int d = 0; d < termCounts.length; d++) {\n          if (delDocs == null || !delDocs.get(d)) {\n            subReader.setNorm(d, fieldName, sim.encodeNormValue(sim.lengthNorm(fieldName, termCounts[d])));\n          }\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5ce8d53d5582eaa6a0c771c9b119d480f41da59c","date":1297466174,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","sourceNew":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    String fieldName = StringHelper.intern(field);\n    Similarity fieldSim = sim.get(field); \n    IndexReader reader = null;\n    try {\n      reader = IndexReader.open(dir, false);\n\n      final List<IndexReader> subReaders = new ArrayList<IndexReader>();\n      ReaderUtil.gatherSubReaders(subReaders, reader);\n\n      final FieldInvertState invertState = new FieldInvertState();\n      for(IndexReader subReader : subReaders) {\n        final Bits delDocs = subReader.getDeletedDocs();\n\n        int[] termCounts = new int[subReader.maxDoc()];\n        Fields fields = subReader.fields();\n        if (fields != null) {\n          Terms terms = fields.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator();\n            DocsEnum docs = null;\n            while(termsEnum.next() != null) {\n              docs = termsEnum.docs(delDocs, docs);\n              while(true) {\n                int docID = docs.nextDoc();\n                if (docID != docs.NO_MORE_DOCS) {\n                  termCounts[docID] += docs.freq();\n                } else {\n                  break;\n                }\n              }\n            }\n          }\n        }\n\n        invertState.setBoost(1.0f);\n        for (int d = 0; d < termCounts.length; d++) {\n          if (delDocs == null || !delDocs.get(d)) {\n            invertState.setLength(termCounts[d]);\n            subReader.setNorm(d, fieldName, fieldSim.encodeNormValue(fieldSim.computeNorm(invertState)));\n          }\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","sourceOld":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    String fieldName = StringHelper.intern(field);\n    Similarity fieldSim = sim.get(field); \n    IndexReader reader = null;\n    try {\n      reader = IndexReader.open(dir, false);\n\n      final List<IndexReader> subReaders = new ArrayList<IndexReader>();\n      ReaderUtil.gatherSubReaders(subReaders, reader);\n\n      final FieldInvertState invertState = new FieldInvertState();\n      for(IndexReader subReader : subReaders) {\n        final Bits delDocs = subReader.getDeletedDocs();\n\n        int[] termCounts = new int[subReader.maxDoc()];\n        Fields fields = subReader.fields();\n        if (fields != null) {\n          Terms terms = fields.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator();\n            DocsEnum docs = null;\n            while(termsEnum.next() != null) {\n              docs = termsEnum.docs(delDocs, docs);\n              while(true) {\n                int docID = docs.nextDoc();\n                if (docID != docs.NO_MORE_DOCS) {\n                  termCounts[docID] += docs.freq();\n                } else {\n                  break;\n                }\n              }\n            }\n          }\n        }\n\n        invertState.setBoost(1.0f);\n        for (int d = 0; d < termCounts.length; d++) {\n          if (delDocs == null || !delDocs.get(d)) {\n            invertState.setLength(termCounts[d]);\n            subReader.setNorm(d, fieldName, fieldSim.encodeNormValue(fieldSim.computeNorm(fieldName, invertState)));\n          }\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f1bdbf92da222965b46c0a942c3857ba56e5c638","date":1298297608,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","sourceNew":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    String fieldName = StringHelper.intern(field);\n    Similarity fieldSim = sim.get(field); \n    IndexReader reader = null;\n    try {\n      reader = IndexReader.open(dir, false);\n\n      final List<IndexReader> subReaders = new ArrayList<IndexReader>();\n      ReaderUtil.gatherSubReaders(subReaders, reader);\n\n      final FieldInvertState invertState = new FieldInvertState();\n      for(IndexReader subReader : subReaders) {\n        final Bits delDocs = subReader.getDeletedDocs();\n\n        int[] termCounts = new int[subReader.maxDoc()];\n        Fields fields = subReader.fields();\n        if (fields != null) {\n          Terms terms = fields.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator();\n            DocsEnum docs = null;\n            while(termsEnum.next() != null) {\n              docs = termsEnum.docs(delDocs, docs);\n              while(true) {\n                int docID = docs.nextDoc();\n                if (docID != docs.NO_MORE_DOCS) {\n                  termCounts[docID] += docs.freq();\n                } else {\n                  break;\n                }\n              }\n            }\n          }\n        }\n\n        invertState.setBoost(1.0f);\n        for (int d = 0; d < termCounts.length; d++) {\n          if (delDocs == null || !delDocs.get(d)) {\n            invertState.setLength(termCounts[d]);\n            subReader.setNorm(d, fieldName, fieldSim.encodeNormValue(fieldSim.computeNorm(invertState)));\n          }\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","sourceOld":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    String fieldName = StringHelper.intern(field);\n    Similarity fieldSim = sim.get(field); \n    IndexReader reader = null;\n    try {\n      reader = IndexReader.open(dir, false);\n\n      final List<IndexReader> subReaders = new ArrayList<IndexReader>();\n      ReaderUtil.gatherSubReaders(subReaders, reader);\n\n      final FieldInvertState invertState = new FieldInvertState();\n      for(IndexReader subReader : subReaders) {\n        final Bits delDocs = subReader.getDeletedDocs();\n\n        int[] termCounts = new int[subReader.maxDoc()];\n        Fields fields = subReader.fields();\n        if (fields != null) {\n          Terms terms = fields.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator();\n            DocsEnum docs = null;\n            while(termsEnum.next() != null) {\n              docs = termsEnum.docs(delDocs, docs);\n              while(true) {\n                int docID = docs.nextDoc();\n                if (docID != docs.NO_MORE_DOCS) {\n                  termCounts[docID] += docs.freq();\n                } else {\n                  break;\n                }\n              }\n            }\n          }\n        }\n\n        invertState.setBoost(1.0f);\n        for (int d = 0; d < termCounts.length; d++) {\n          if (delDocs == null || !delDocs.get(d)) {\n            invertState.setLength(termCounts[d]);\n            subReader.setNorm(d, fieldName, fieldSim.encodeNormValue(fieldSim.computeNorm(fieldName, invertState)));\n          }\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bde51b089eb7f86171eb3406e38a274743f9b7ac","date":1298336439,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","sourceNew":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    String fieldName = StringHelper.intern(field);\n    Similarity fieldSim = sim.get(field); \n    IndexReader reader = null;\n    try {\n      reader = IndexReader.open(dir, false);\n\n      final List<IndexReader> subReaders = new ArrayList<IndexReader>();\n      ReaderUtil.gatherSubReaders(subReaders, reader);\n\n      final FieldInvertState invertState = new FieldInvertState();\n      for(IndexReader subReader : subReaders) {\n        final Bits delDocs = subReader.getDeletedDocs();\n\n        int[] termCounts = new int[subReader.maxDoc()];\n        Fields fields = subReader.fields();\n        if (fields != null) {\n          Terms terms = fields.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator();\n            DocsEnum docs = null;\n            while(termsEnum.next() != null) {\n              docs = termsEnum.docs(delDocs, docs);\n              while(true) {\n                int docID = docs.nextDoc();\n                if (docID != docs.NO_MORE_DOCS) {\n                  termCounts[docID] += docs.freq();\n                } else {\n                  break;\n                }\n              }\n            }\n          }\n        }\n\n        invertState.setBoost(1.0f);\n        for (int d = 0; d < termCounts.length; d++) {\n          if (delDocs == null || !delDocs.get(d)) {\n            invertState.setLength(termCounts[d]);\n            subReader.setNorm(d, fieldName, fieldSim.encodeNormValue(fieldSim.computeNorm(invertState)));\n          }\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","sourceOld":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    String fieldName = StringHelper.intern(field);\n    Similarity fieldSim = sim.get(field); \n    IndexReader reader = null;\n    try {\n      reader = IndexReader.open(dir, false);\n\n      final List<IndexReader> subReaders = new ArrayList<IndexReader>();\n      ReaderUtil.gatherSubReaders(subReaders, reader);\n\n      final FieldInvertState invertState = new FieldInvertState();\n      for(IndexReader subReader : subReaders) {\n        final Bits delDocs = subReader.getDeletedDocs();\n\n        int[] termCounts = new int[subReader.maxDoc()];\n        Fields fields = subReader.fields();\n        if (fields != null) {\n          Terms terms = fields.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator();\n            DocsEnum docs = null;\n            while(termsEnum.next() != null) {\n              docs = termsEnum.docs(delDocs, docs);\n              while(true) {\n                int docID = docs.nextDoc();\n                if (docID != docs.NO_MORE_DOCS) {\n                  termCounts[docID] += docs.freq();\n                } else {\n                  break;\n                }\n              }\n            }\n          }\n        }\n\n        invertState.setBoost(1.0f);\n        for (int d = 0; d < termCounts.length; d++) {\n          if (delDocs == null || !delDocs.get(d)) {\n            invertState.setLength(termCounts[d]);\n            subReader.setNorm(d, fieldName, fieldSim.encodeNormValue(fieldSim.computeNorm(fieldName, invertState)));\n          }\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fafef7c83fe8e0b3ca9298d5d75d6b943dc28153","date":1308670974,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","sourceNew":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    Similarity fieldSim = sim.get(field); \n    IndexReader reader = null;\n    try {\n      reader = IndexReader.open(dir, false);\n\n      final List<IndexReader> subReaders = new ArrayList<IndexReader>();\n      ReaderUtil.gatherSubReaders(subReaders, reader);\n\n      final FieldInvertState invertState = new FieldInvertState();\n      for(IndexReader subReader : subReaders) {\n        final Bits delDocs = subReader.getDeletedDocs();\n\n        int[] termCounts = new int[subReader.maxDoc()];\n        Fields fields = subReader.fields();\n        if (fields != null) {\n          Terms terms = fields.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator();\n            DocsEnum docs = null;\n            while(termsEnum.next() != null) {\n              docs = termsEnum.docs(delDocs, docs);\n              while(true) {\n                int docID = docs.nextDoc();\n                if (docID != docs.NO_MORE_DOCS) {\n                  termCounts[docID] += docs.freq();\n                } else {\n                  break;\n                }\n              }\n            }\n          }\n        }\n\n        invertState.setBoost(1.0f);\n        for (int d = 0; d < termCounts.length; d++) {\n          if (delDocs == null || !delDocs.get(d)) {\n            invertState.setLength(termCounts[d]);\n            subReader.setNorm(d, field, fieldSim.encodeNormValue(fieldSim.computeNorm(invertState)));\n          }\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","sourceOld":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    String fieldName = StringHelper.intern(field);\n    Similarity fieldSim = sim.get(field); \n    IndexReader reader = null;\n    try {\n      reader = IndexReader.open(dir, false);\n\n      final List<IndexReader> subReaders = new ArrayList<IndexReader>();\n      ReaderUtil.gatherSubReaders(subReaders, reader);\n\n      final FieldInvertState invertState = new FieldInvertState();\n      for(IndexReader subReader : subReaders) {\n        final Bits delDocs = subReader.getDeletedDocs();\n\n        int[] termCounts = new int[subReader.maxDoc()];\n        Fields fields = subReader.fields();\n        if (fields != null) {\n          Terms terms = fields.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator();\n            DocsEnum docs = null;\n            while(termsEnum.next() != null) {\n              docs = termsEnum.docs(delDocs, docs);\n              while(true) {\n                int docID = docs.nextDoc();\n                if (docID != docs.NO_MORE_DOCS) {\n                  termCounts[docID] += docs.freq();\n                } else {\n                  break;\n                }\n              }\n            }\n          }\n        }\n\n        invertState.setBoost(1.0f);\n        for (int d = 0; d < termCounts.length; d++) {\n          if (delDocs == null || !delDocs.get(d)) {\n            invertState.setLength(termCounts[d]);\n            subReader.setNorm(d, fieldName, fieldSim.encodeNormValue(fieldSim.computeNorm(invertState)));\n          }\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2553b00f699380c64959ccb27991289aae87be2e","date":1309290151,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","sourceNew":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    Similarity fieldSim = sim.get(field); \n    IndexReader reader = null;\n    try {\n      reader = IndexReader.open(dir, false);\n\n      final List<IndexReader> subReaders = new ArrayList<IndexReader>();\n      ReaderUtil.gatherSubReaders(subReaders, reader);\n\n      final FieldInvertState invertState = new FieldInvertState();\n      for(IndexReader subReader : subReaders) {\n        final Bits delDocs = subReader.getDeletedDocs();\n\n        int[] termCounts = new int[subReader.maxDoc()];\n        Fields fields = subReader.fields();\n        if (fields != null) {\n          Terms terms = fields.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator();\n            DocsEnum docs = null;\n            while(termsEnum.next() != null) {\n              docs = termsEnum.docs(delDocs, docs);\n              while(true) {\n                int docID = docs.nextDoc();\n                if (docID != docs.NO_MORE_DOCS) {\n                  termCounts[docID] += docs.freq();\n                } else {\n                  break;\n                }\n              }\n            }\n          }\n        }\n\n        invertState.setBoost(1.0f);\n        for (int d = 0; d < termCounts.length; d++) {\n          if (delDocs == null || !delDocs.get(d)) {\n            invertState.setLength(termCounts[d]);\n            subReader.setNorm(d, field, fieldSim.encodeNormValue(fieldSim.computeNorm(invertState)));\n          }\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","sourceOld":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    String fieldName = StringHelper.intern(field);\n    Similarity fieldSim = sim.get(field); \n    IndexReader reader = null;\n    try {\n      reader = IndexReader.open(dir, false);\n\n      final List<IndexReader> subReaders = new ArrayList<IndexReader>();\n      ReaderUtil.gatherSubReaders(subReaders, reader);\n\n      final FieldInvertState invertState = new FieldInvertState();\n      for(IndexReader subReader : subReaders) {\n        final Bits delDocs = subReader.getDeletedDocs();\n\n        int[] termCounts = new int[subReader.maxDoc()];\n        Fields fields = subReader.fields();\n        if (fields != null) {\n          Terms terms = fields.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator();\n            DocsEnum docs = null;\n            while(termsEnum.next() != null) {\n              docs = termsEnum.docs(delDocs, docs);\n              while(true) {\n                int docID = docs.nextDoc();\n                if (docID != docs.NO_MORE_DOCS) {\n                  termCounts[docID] += docs.freq();\n                } else {\n                  break;\n                }\n              }\n            }\n          }\n        }\n\n        invertState.setBoost(1.0f);\n        for (int d = 0; d < termCounts.length; d++) {\n          if (delDocs == null || !delDocs.get(d)) {\n            invertState.setLength(termCounts[d]);\n            subReader.setNorm(d, fieldName, fieldSim.encodeNormValue(fieldSim.computeNorm(invertState)));\n          }\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e7bd246bb7bc35ac22edfee9157e034dfc4e65eb","date":1309960478,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","sourceNew":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    Similarity fieldSim = sim.get(field); \n    IndexReader reader = null;\n    try {\n      reader = IndexReader.open(dir, false);\n\n      final List<IndexReader> subReaders = new ArrayList<IndexReader>();\n      ReaderUtil.gatherSubReaders(subReaders, reader);\n\n      final FieldInvertState invertState = new FieldInvertState();\n      for(IndexReader subReader : subReaders) {\n        final Bits liveDocs = subReader.getLiveDocs();\n\n        int[] termCounts = new int[subReader.maxDoc()];\n        Fields fields = subReader.fields();\n        if (fields != null) {\n          Terms terms = fields.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator();\n            DocsEnum docs = null;\n            while(termsEnum.next() != null) {\n              docs = termsEnum.docs(liveDocs, docs);\n              while(true) {\n                int docID = docs.nextDoc();\n                if (docID != docs.NO_MORE_DOCS) {\n                  termCounts[docID] += docs.freq();\n                } else {\n                  break;\n                }\n              }\n            }\n          }\n        }\n\n        invertState.setBoost(1.0f);\n        for (int d = 0; d < termCounts.length; d++) {\n          if (liveDocs == null || liveDocs.get(d)) {\n            invertState.setLength(termCounts[d]);\n            subReader.setNorm(d, field, fieldSim.encodeNormValue(fieldSim.computeNorm(invertState)));\n          }\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","sourceOld":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    Similarity fieldSim = sim.get(field); \n    IndexReader reader = null;\n    try {\n      reader = IndexReader.open(dir, false);\n\n      final List<IndexReader> subReaders = new ArrayList<IndexReader>();\n      ReaderUtil.gatherSubReaders(subReaders, reader);\n\n      final FieldInvertState invertState = new FieldInvertState();\n      for(IndexReader subReader : subReaders) {\n        final Bits delDocs = subReader.getDeletedDocs();\n\n        int[] termCounts = new int[subReader.maxDoc()];\n        Fields fields = subReader.fields();\n        if (fields != null) {\n          Terms terms = fields.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator();\n            DocsEnum docs = null;\n            while(termsEnum.next() != null) {\n              docs = termsEnum.docs(delDocs, docs);\n              while(true) {\n                int docID = docs.nextDoc();\n                if (docID != docs.NO_MORE_DOCS) {\n                  termCounts[docID] += docs.freq();\n                } else {\n                  break;\n                }\n              }\n            }\n          }\n        }\n\n        invertState.setBoost(1.0f);\n        for (int d = 0; d < termCounts.length; d++) {\n          if (delDocs == null || !delDocs.get(d)) {\n            invertState.setLength(termCounts[d]);\n            subReader.setNorm(d, field, fieldSim.encodeNormValue(fieldSim.computeNorm(invertState)));\n          }\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"817d8435e9135b756f08ce6710ab0baac51bdf88","date":1309986993,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","sourceNew":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    Similarity fieldSim = sim.get(field); \n    IndexReader reader = null;\n    try {\n      reader = IndexReader.open(dir, false);\n\n      final List<IndexReader> subReaders = new ArrayList<IndexReader>();\n      ReaderUtil.gatherSubReaders(subReaders, reader);\n\n      final FieldInvertState invertState = new FieldInvertState();\n      for(IndexReader subReader : subReaders) {\n        final Bits liveDocs = subReader.getLiveDocs();\n\n        int[] termCounts = new int[subReader.maxDoc()];\n        Fields fields = subReader.fields();\n        if (fields != null) {\n          Terms terms = fields.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator();\n            DocsEnum docs = null;\n            while(termsEnum.next() != null) {\n              docs = termsEnum.docs(liveDocs, docs);\n              while(true) {\n                int docID = docs.nextDoc();\n                if (docID != docs.NO_MORE_DOCS) {\n                  termCounts[docID] += docs.freq();\n                } else {\n                  break;\n                }\n              }\n            }\n          }\n        }\n\n        invertState.setBoost(1.0f);\n        for (int d = 0; d < termCounts.length; d++) {\n          if (liveDocs == null || liveDocs.get(d)) {\n            invertState.setLength(termCounts[d]);\n            subReader.setNorm(d, field, fieldSim.encodeNormValue(fieldSim.computeNorm(invertState)));\n          }\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","sourceOld":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    Similarity fieldSim = sim.get(field); \n    IndexReader reader = null;\n    try {\n      reader = IndexReader.open(dir, false);\n\n      final List<IndexReader> subReaders = new ArrayList<IndexReader>();\n      ReaderUtil.gatherSubReaders(subReaders, reader);\n\n      final FieldInvertState invertState = new FieldInvertState();\n      for(IndexReader subReader : subReaders) {\n        final Bits delDocs = subReader.getDeletedDocs();\n\n        int[] termCounts = new int[subReader.maxDoc()];\n        Fields fields = subReader.fields();\n        if (fields != null) {\n          Terms terms = fields.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator();\n            DocsEnum docs = null;\n            while(termsEnum.next() != null) {\n              docs = termsEnum.docs(delDocs, docs);\n              while(true) {\n                int docID = docs.nextDoc();\n                if (docID != docs.NO_MORE_DOCS) {\n                  termCounts[docID] += docs.freq();\n                } else {\n                  break;\n                }\n              }\n            }\n          }\n        }\n\n        invertState.setBoost(1.0f);\n        for (int d = 0; d < termCounts.length; d++) {\n          if (delDocs == null || !delDocs.get(d)) {\n            invertState.setLength(termCounts[d]);\n            subReader.setNorm(d, field, fieldSim.encodeNormValue(fieldSim.computeNorm(invertState)));\n          }\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d083e83f225b11e5fdd900e83d26ddb385b6955c","date":1310029438,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","sourceNew":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    Similarity fieldSim = sim.get(field); \n    IndexReader reader = null;\n    try {\n      reader = IndexReader.open(dir, false);\n\n      final List<IndexReader> subReaders = new ArrayList<IndexReader>();\n      ReaderUtil.gatherSubReaders(subReaders, reader);\n\n      final FieldInvertState invertState = new FieldInvertState();\n      for(IndexReader subReader : subReaders) {\n        final Bits liveDocs = subReader.getLiveDocs();\n\n        int[] termCounts = new int[subReader.maxDoc()];\n        Fields fields = subReader.fields();\n        if (fields != null) {\n          Terms terms = fields.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator();\n            DocsEnum docs = null;\n            while(termsEnum.next() != null) {\n              docs = termsEnum.docs(liveDocs, docs);\n              while(true) {\n                int docID = docs.nextDoc();\n                if (docID != docs.NO_MORE_DOCS) {\n                  termCounts[docID] += docs.freq();\n                } else {\n                  break;\n                }\n              }\n            }\n          }\n        }\n\n        invertState.setBoost(1.0f);\n        for (int d = 0; d < termCounts.length; d++) {\n          if (liveDocs == null || liveDocs.get(d)) {\n            invertState.setLength(termCounts[d]);\n            subReader.setNorm(d, field, fieldSim.encodeNormValue(fieldSim.computeNorm(invertState)));\n          }\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","sourceOld":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    String fieldName = StringHelper.intern(field);\n    Similarity fieldSim = sim.get(field); \n    IndexReader reader = null;\n    try {\n      reader = IndexReader.open(dir, false);\n\n      final List<IndexReader> subReaders = new ArrayList<IndexReader>();\n      ReaderUtil.gatherSubReaders(subReaders, reader);\n\n      final FieldInvertState invertState = new FieldInvertState();\n      for(IndexReader subReader : subReaders) {\n        final Bits delDocs = subReader.getDeletedDocs();\n\n        int[] termCounts = new int[subReader.maxDoc()];\n        Fields fields = subReader.fields();\n        if (fields != null) {\n          Terms terms = fields.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator();\n            DocsEnum docs = null;\n            while(termsEnum.next() != null) {\n              docs = termsEnum.docs(delDocs, docs);\n              while(true) {\n                int docID = docs.nextDoc();\n                if (docID != docs.NO_MORE_DOCS) {\n                  termCounts[docID] += docs.freq();\n                } else {\n                  break;\n                }\n              }\n            }\n          }\n        }\n\n        invertState.setBoost(1.0f);\n        for (int d = 0; d < termCounts.length; d++) {\n          if (delDocs == null || !delDocs.get(d)) {\n            invertState.setLength(termCounts[d]);\n            subReader.setNorm(d, fieldName, fieldSim.encodeNormValue(fieldSim.computeNorm(invertState)));\n          }\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0f3cee3d20b0c786e6fca20539454262e29edcab","date":1310101685,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","sourceNew":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    Similarity fieldSim = sim.get(field); \n    IndexReader reader = null;\n    try {\n      reader = IndexReader.open(dir, false);\n\n      final List<IndexReader> subReaders = new ArrayList<IndexReader>();\n      ReaderUtil.gatherSubReaders(subReaders, reader);\n\n      final FieldInvertState invertState = new FieldInvertState();\n      for(IndexReader subReader : subReaders) {\n        final Bits liveDocs = subReader.getLiveDocs();\n\n        int[] termCounts = new int[subReader.maxDoc()];\n        Fields fields = subReader.fields();\n        if (fields != null) {\n          Terms terms = fields.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator();\n            DocsEnum docs = null;\n            while(termsEnum.next() != null) {\n              docs = termsEnum.docs(liveDocs, docs);\n              while(true) {\n                int docID = docs.nextDoc();\n                if (docID != docs.NO_MORE_DOCS) {\n                  termCounts[docID] += docs.freq();\n                } else {\n                  break;\n                }\n              }\n            }\n          }\n        }\n\n        invertState.setBoost(1.0f);\n        for (int d = 0; d < termCounts.length; d++) {\n          if (liveDocs == null || liveDocs.get(d)) {\n            invertState.setLength(termCounts[d]);\n            subReader.setNorm(d, field, fieldSim.computeNorm(invertState));\n          }\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","sourceOld":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    Similarity fieldSim = sim.get(field); \n    IndexReader reader = null;\n    try {\n      reader = IndexReader.open(dir, false);\n\n      final List<IndexReader> subReaders = new ArrayList<IndexReader>();\n      ReaderUtil.gatherSubReaders(subReaders, reader);\n\n      final FieldInvertState invertState = new FieldInvertState();\n      for(IndexReader subReader : subReaders) {\n        final Bits liveDocs = subReader.getLiveDocs();\n\n        int[] termCounts = new int[subReader.maxDoc()];\n        Fields fields = subReader.fields();\n        if (fields != null) {\n          Terms terms = fields.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator();\n            DocsEnum docs = null;\n            while(termsEnum.next() != null) {\n              docs = termsEnum.docs(liveDocs, docs);\n              while(true) {\n                int docID = docs.nextDoc();\n                if (docID != docs.NO_MORE_DOCS) {\n                  termCounts[docID] += docs.freq();\n                } else {\n                  break;\n                }\n              }\n            }\n          }\n        }\n\n        invertState.setBoost(1.0f);\n        for (int d = 0; d < termCounts.length; d++) {\n          if (liveDocs == null || liveDocs.get(d)) {\n            invertState.setLength(termCounts[d]);\n            subReader.setNorm(d, field, fieldSim.encodeNormValue(fieldSim.computeNorm(invertState)));\n          }\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f0b9507caf22f292ac0e5e59f62db4275adf4511","date":1310107283,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","sourceNew":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    Similarity fieldSim = sim.get(field); \n    IndexReader reader = null;\n    try {\n      reader = IndexReader.open(dir, false);\n\n      final List<IndexReader> subReaders = new ArrayList<IndexReader>();\n      ReaderUtil.gatherSubReaders(subReaders, reader);\n\n      final FieldInvertState invertState = new FieldInvertState();\n      for(IndexReader subReader : subReaders) {\n        final Bits liveDocs = subReader.getLiveDocs();\n\n        int[] termCounts = new int[subReader.maxDoc()];\n        Fields fields = subReader.fields();\n        if (fields != null) {\n          Terms terms = fields.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator();\n            DocsEnum docs = null;\n            while(termsEnum.next() != null) {\n              docs = termsEnum.docs(liveDocs, docs);\n              while(true) {\n                int docID = docs.nextDoc();\n                if (docID != docs.NO_MORE_DOCS) {\n                  termCounts[docID] += docs.freq();\n                } else {\n                  break;\n                }\n              }\n            }\n          }\n        }\n\n        invertState.setBoost(1.0f);\n        for (int d = 0; d < termCounts.length; d++) {\n          if (liveDocs == null || liveDocs.get(d)) {\n            invertState.setLength(termCounts[d]);\n            subReader.setNorm(d, field, fieldSim.computeNorm(invertState));\n          }\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","sourceOld":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    Similarity fieldSim = sim.get(field); \n    IndexReader reader = null;\n    try {\n      reader = IndexReader.open(dir, false);\n\n      final List<IndexReader> subReaders = new ArrayList<IndexReader>();\n      ReaderUtil.gatherSubReaders(subReaders, reader);\n\n      final FieldInvertState invertState = new FieldInvertState();\n      for(IndexReader subReader : subReaders) {\n        final Bits liveDocs = subReader.getLiveDocs();\n\n        int[] termCounts = new int[subReader.maxDoc()];\n        Fields fields = subReader.fields();\n        if (fields != null) {\n          Terms terms = fields.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator();\n            DocsEnum docs = null;\n            while(termsEnum.next() != null) {\n              docs = termsEnum.docs(liveDocs, docs);\n              while(true) {\n                int docID = docs.nextDoc();\n                if (docID != docs.NO_MORE_DOCS) {\n                  termCounts[docID] += docs.freq();\n                } else {\n                  break;\n                }\n              }\n            }\n          }\n        }\n\n        invertState.setBoost(1.0f);\n        for (int d = 0; d < termCounts.length; d++) {\n          if (liveDocs == null || liveDocs.get(d)) {\n            invertState.setLength(termCounts[d]);\n            subReader.setNorm(d, field, fieldSim.encodeNormValue(fieldSim.computeNorm(invertState)));\n          }\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1291e4568eb7d9463d751627596ef14baf4c1603","date":1310112572,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","sourceNew":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    Similarity fieldSim = sim.get(field); \n    IndexReader reader = null;\n    try {\n      reader = IndexReader.open(dir, false);\n\n      final List<IndexReader> subReaders = new ArrayList<IndexReader>();\n      ReaderUtil.gatherSubReaders(subReaders, reader);\n\n      final FieldInvertState invertState = new FieldInvertState();\n      for(IndexReader subReader : subReaders) {\n        final Bits liveDocs = subReader.getLiveDocs();\n\n        int[] termCounts = new int[subReader.maxDoc()];\n        Fields fields = subReader.fields();\n        if (fields != null) {\n          Terms terms = fields.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator();\n            DocsEnum docs = null;\n            while(termsEnum.next() != null) {\n              docs = termsEnum.docs(liveDocs, docs);\n              while(true) {\n                int docID = docs.nextDoc();\n                if (docID != docs.NO_MORE_DOCS) {\n                  termCounts[docID] += docs.freq();\n                } else {\n                  break;\n                }\n              }\n            }\n          }\n        }\n\n        invertState.setBoost(1.0f);\n        for (int d = 0; d < termCounts.length; d++) {\n          if (liveDocs == null || liveDocs.get(d)) {\n            invertState.setLength(termCounts[d]);\n            subReader.setNorm(d, field, fieldSim.computeNorm(invertState));\n          }\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","sourceOld":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    Similarity fieldSim = sim.get(field); \n    IndexReader reader = null;\n    try {\n      reader = IndexReader.open(dir, false);\n\n      final List<IndexReader> subReaders = new ArrayList<IndexReader>();\n      ReaderUtil.gatherSubReaders(subReaders, reader);\n\n      final FieldInvertState invertState = new FieldInvertState();\n      for(IndexReader subReader : subReaders) {\n        final Bits liveDocs = subReader.getLiveDocs();\n\n        int[] termCounts = new int[subReader.maxDoc()];\n        Fields fields = subReader.fields();\n        if (fields != null) {\n          Terms terms = fields.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator();\n            DocsEnum docs = null;\n            while(termsEnum.next() != null) {\n              docs = termsEnum.docs(liveDocs, docs);\n              while(true) {\n                int docID = docs.nextDoc();\n                if (docID != docs.NO_MORE_DOCS) {\n                  termCounts[docID] += docs.freq();\n                } else {\n                  break;\n                }\n              }\n            }\n          }\n        }\n\n        invertState.setBoost(1.0f);\n        for (int d = 0; d < termCounts.length; d++) {\n          if (liveDocs == null || liveDocs.get(d)) {\n            invertState.setLength(termCounts[d]);\n            subReader.setNorm(d, field, fieldSim.encodeNormValue(fieldSim.computeNorm(invertState)));\n          }\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3cc749c053615f5871f3b95715fe292f34e70a53","date":1321470575,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","sourceNew":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    Similarity fieldSim = sim.get(field); \n    IndexReader reader = null;\n    try {\n      reader = IndexReader.open(dir, false);\n\n      final List<IndexReader> subReaders = new ArrayList<IndexReader>();\n      ReaderUtil.gatherSubReaders(subReaders, reader);\n\n      final FieldInvertState invertState = new FieldInvertState();\n      for(IndexReader subReader : subReaders) {\n        final Bits liveDocs = subReader.getLiveDocs();\n\n        int[] termCounts = new int[subReader.maxDoc()];\n        Fields fields = subReader.fields();\n        if (fields != null) {\n          Terms terms = fields.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator(null);\n            DocsEnum docs = null;\n            while(termsEnum.next() != null) {\n              docs = termsEnum.docs(liveDocs, docs);\n              while(true) {\n                int docID = docs.nextDoc();\n                if (docID != docs.NO_MORE_DOCS) {\n                  termCounts[docID] += docs.freq();\n                } else {\n                  break;\n                }\n              }\n            }\n          }\n        }\n\n        invertState.setBoost(1.0f);\n        for (int d = 0; d < termCounts.length; d++) {\n          if (liveDocs == null || liveDocs.get(d)) {\n            invertState.setLength(termCounts[d]);\n            subReader.setNorm(d, field, fieldSim.computeNorm(invertState));\n          }\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","sourceOld":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    Similarity fieldSim = sim.get(field); \n    IndexReader reader = null;\n    try {\n      reader = IndexReader.open(dir, false);\n\n      final List<IndexReader> subReaders = new ArrayList<IndexReader>();\n      ReaderUtil.gatherSubReaders(subReaders, reader);\n\n      final FieldInvertState invertState = new FieldInvertState();\n      for(IndexReader subReader : subReaders) {\n        final Bits liveDocs = subReader.getLiveDocs();\n\n        int[] termCounts = new int[subReader.maxDoc()];\n        Fields fields = subReader.fields();\n        if (fields != null) {\n          Terms terms = fields.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator();\n            DocsEnum docs = null;\n            while(termsEnum.next() != null) {\n              docs = termsEnum.docs(liveDocs, docs);\n              while(true) {\n                int docID = docs.nextDoc();\n                if (docID != docs.NO_MORE_DOCS) {\n                  termCounts[docID] += docs.freq();\n                } else {\n                  break;\n                }\n              }\n            }\n          }\n        }\n\n        invertState.setBoost(1.0f);\n        for (int d = 0; d < termCounts.length; d++) {\n          if (liveDocs == null || liveDocs.get(d)) {\n            invertState.setLength(termCounts[d]);\n            subReader.setNorm(d, field, fieldSim.computeNorm(invertState));\n          }\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4122a26e1fd0457a340616673a3d3aada370f713","date":1322955654,"type":4,"author":"Uwe Schindler","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","sourceNew":null,"sourceOld":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    Similarity fieldSim = sim.get(field); \n    IndexReader reader = null;\n    try {\n      reader = IndexReader.open(dir, false);\n\n      final List<IndexReader> subReaders = new ArrayList<IndexReader>();\n      ReaderUtil.gatherSubReaders(subReaders, reader);\n\n      final FieldInvertState invertState = new FieldInvertState();\n      for(IndexReader subReader : subReaders) {\n        final Bits liveDocs = subReader.getLiveDocs();\n\n        int[] termCounts = new int[subReader.maxDoc()];\n        Fields fields = subReader.fields();\n        if (fields != null) {\n          Terms terms = fields.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator(null);\n            DocsEnum docs = null;\n            while(termsEnum.next() != null) {\n              docs = termsEnum.docs(liveDocs, docs);\n              while(true) {\n                int docID = docs.nextDoc();\n                if (docID != docs.NO_MORE_DOCS) {\n                  termCounts[docID] += docs.freq();\n                } else {\n                  break;\n                }\n              }\n            }\n          }\n        }\n\n        invertState.setBoost(1.0f);\n        for (int d = 0; d < termCounts.length; d++) {\n          if (liveDocs == null || liveDocs.get(d)) {\n            invertState.setLength(termCounts[d]);\n            subReader.setNorm(d, field, fieldSim.computeNorm(invertState));\n          }\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"872cff1d3a554e0cd64014cd97f88d3002b0f491","date":1323024658,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","sourceNew":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    Similarity fieldSim = sim.get(field); \n    IndexReader reader = null;\n    try {\n      reader = IndexReader.open(dir, false);\n\n      final List<IndexReader> subReaders = new ArrayList<IndexReader>();\n      ReaderUtil.gatherSubReaders(subReaders, reader);\n\n      final FieldInvertState invertState = new FieldInvertState();\n      for(IndexReader subReader : subReaders) {\n        final Bits liveDocs = subReader.getLiveDocs();\n\n        int[] termCounts = new int[subReader.maxDoc()];\n        Fields fields = subReader.fields();\n        if (fields != null) {\n          Terms terms = fields.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator(null);\n            DocsEnum docs = null;\n            DocsEnum docsAndFreqs = null;\n            while(termsEnum.next() != null) {\n              docsAndFreqs = termsEnum.docs(liveDocs, docsAndFreqs, true);\n              final DocsEnum docs2;\n              if (docsAndFreqs != null) {\n                docs2 = docsAndFreqs;\n              } else {\n                docs2 = docs = termsEnum.docs(liveDocs, docs, false);\n              }\n              while(true) {\n                int docID = docs2.nextDoc();\n                if (docID != docs.NO_MORE_DOCS) {\n                  termCounts[docID] += docsAndFreqs == null ? 1 : docsAndFreqs.freq();\n                } else {\n                  break;\n                }\n              }\n            }\n          }\n        }\n\n        invertState.setBoost(1.0f);\n        for (int d = 0; d < termCounts.length; d++) {\n          if (liveDocs == null || liveDocs.get(d)) {\n            invertState.setLength(termCounts[d]);\n            subReader.setNorm(d, field, fieldSim.computeNorm(invertState));\n          }\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","sourceOld":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    Similarity fieldSim = sim.get(field); \n    IndexReader reader = null;\n    try {\n      reader = IndexReader.open(dir, false);\n\n      final List<IndexReader> subReaders = new ArrayList<IndexReader>();\n      ReaderUtil.gatherSubReaders(subReaders, reader);\n\n      final FieldInvertState invertState = new FieldInvertState();\n      for(IndexReader subReader : subReaders) {\n        final Bits liveDocs = subReader.getLiveDocs();\n\n        int[] termCounts = new int[subReader.maxDoc()];\n        Fields fields = subReader.fields();\n        if (fields != null) {\n          Terms terms = fields.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator(null);\n            DocsEnum docs = null;\n            while(termsEnum.next() != null) {\n              docs = termsEnum.docs(liveDocs, docs);\n              while(true) {\n                int docID = docs.nextDoc();\n                if (docID != docs.NO_MORE_DOCS) {\n                  termCounts[docID] += docs.freq();\n                } else {\n                  break;\n                }\n              }\n            }\n          }\n        }\n\n        invertState.setBoost(1.0f);\n        for (int d = 0; d < termCounts.length; d++) {\n          if (liveDocs == null || liveDocs.get(d)) {\n            invertState.setLength(termCounts[d]);\n            subReader.setNorm(d, field, fieldSim.computeNorm(invertState));\n          }\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3615ce4a1f785ae1b779244de52c6a7d99227e60","date":1323422019,"type":4,"author":"Uwe Schindler","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","sourceNew":null,"sourceOld":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    Similarity fieldSim = sim.get(field); \n    IndexReader reader = null;\n    try {\n      reader = IndexReader.open(dir, false);\n\n      final List<IndexReader> subReaders = new ArrayList<IndexReader>();\n      ReaderUtil.gatherSubReaders(subReaders, reader);\n\n      final FieldInvertState invertState = new FieldInvertState();\n      for(IndexReader subReader : subReaders) {\n        final Bits liveDocs = subReader.getLiveDocs();\n\n        int[] termCounts = new int[subReader.maxDoc()];\n        Fields fields = subReader.fields();\n        if (fields != null) {\n          Terms terms = fields.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator(null);\n            DocsEnum docs = null;\n            DocsEnum docsAndFreqs = null;\n            while(termsEnum.next() != null) {\n              docsAndFreqs = termsEnum.docs(liveDocs, docsAndFreqs, true);\n              final DocsEnum docs2;\n              if (docsAndFreqs != null) {\n                docs2 = docsAndFreqs;\n              } else {\n                docs2 = docs = termsEnum.docs(liveDocs, docs, false);\n              }\n              while(true) {\n                int docID = docs2.nextDoc();\n                if (docID != docs.NO_MORE_DOCS) {\n                  termCounts[docID] += docsAndFreqs == null ? 1 : docsAndFreqs.freq();\n                } else {\n                  break;\n                }\n              }\n            }\n          }\n        }\n\n        invertState.setBoost(1.0f);\n        for (int d = 0; d < termCounts.length; d++) {\n          if (liveDocs == null || liveDocs.get(d)) {\n            invertState.setLength(termCounts[d]);\n            subReader.setNorm(d, field, fieldSim.computeNorm(invertState));\n          }\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","date":1323437438,"type":4,"author":"Robert Muir","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","sourceNew":null,"sourceOld":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    Similarity fieldSim = sim.get(field); \n    IndexReader reader = null;\n    try {\n      reader = IndexReader.open(dir, false);\n\n      final List<IndexReader> subReaders = new ArrayList<IndexReader>();\n      ReaderUtil.gatherSubReaders(subReaders, reader);\n\n      final FieldInvertState invertState = new FieldInvertState();\n      for(IndexReader subReader : subReaders) {\n        final Bits liveDocs = subReader.getLiveDocs();\n\n        int[] termCounts = new int[subReader.maxDoc()];\n        Fields fields = subReader.fields();\n        if (fields != null) {\n          Terms terms = fields.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator(null);\n            DocsEnum docs = null;\n            DocsEnum docsAndFreqs = null;\n            while(termsEnum.next() != null) {\n              docsAndFreqs = termsEnum.docs(liveDocs, docsAndFreqs, true);\n              final DocsEnum docs2;\n              if (docsAndFreqs != null) {\n                docs2 = docsAndFreqs;\n              } else {\n                docs2 = docs = termsEnum.docs(liveDocs, docs, false);\n              }\n              while(true) {\n                int docID = docs2.nextDoc();\n                if (docID != docs.NO_MORE_DOCS) {\n                  termCounts[docID] += docsAndFreqs == null ? 1 : docsAndFreqs.freq();\n                } else {\n                  break;\n                }\n              }\n            }\n          }\n        }\n\n        invertState.setBoost(1.0f);\n        for (int d = 0; d < termCounts.length; d++) {\n          if (liveDocs == null || liveDocs.get(d)) {\n            invertState.setLength(termCounts[d]);\n            subReader.setNorm(d, field, fieldSim.computeNorm(invertState));\n          }\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"f1bdbf92da222965b46c0a942c3857ba56e5c638":["29ef99d61cda9641b6250bf9567329a6e65f901d","5ce8d53d5582eaa6a0c771c9b119d480f41da59c"],"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":["872cff1d3a554e0cd64014cd97f88d3002b0f491","3615ce4a1f785ae1b779244de52c6a7d99227e60"],"fafef7c83fe8e0b3ca9298d5d75d6b943dc28153":["5ce8d53d5582eaa6a0c771c9b119d480f41da59c"],"e7bd246bb7bc35ac22edfee9157e034dfc4e65eb":["fafef7c83fe8e0b3ca9298d5d75d6b943dc28153"],"955c32f886db6f6356c9fcdea6b1f1cb4effda24":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["955c32f886db6f6356c9fcdea6b1f1cb4effda24","4e8cc373c801e54cec75daf9f52792cb4b17f536"],"bb9b72f7c3d7827c64dd4ec580ded81778da361d":["868da859b43505d9d2a023bfeae6dd0c795f5295","fd9325c7ff9928fabe81c28553b41fc7aa57dfab"],"fd9325c7ff9928fabe81c28553b41fc7aa57dfab":["3e00f80591de714c6975f454e33e0fa5218b5902"],"3e00f80591de714c6975f454e33e0fa5218b5902":["4e8cc373c801e54cec75daf9f52792cb4b17f536"],"f0b9507caf22f292ac0e5e59f62db4275adf4511":["817d8435e9135b756f08ce6710ab0baac51bdf88","0f3cee3d20b0c786e6fca20539454262e29edcab"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["3bb13258feba31ab676502787ab2e1779f129b7a","fd9325c7ff9928fabe81c28553b41fc7aa57dfab"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["bb9b72f7c3d7827c64dd4ec580ded81778da361d","5ce8d53d5582eaa6a0c771c9b119d480f41da59c"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"0f3cee3d20b0c786e6fca20539454262e29edcab":["e7bd246bb7bc35ac22edfee9157e034dfc4e65eb"],"3cc749c053615f5871f3b95715fe292f34e70a53":["0f3cee3d20b0c786e6fca20539454262e29edcab"],"872cff1d3a554e0cd64014cd97f88d3002b0f491":["3cc749c053615f5871f3b95715fe292f34e70a53"],"2553b00f699380c64959ccb27991289aae87be2e":["5ce8d53d5582eaa6a0c771c9b119d480f41da59c","fafef7c83fe8e0b3ca9298d5d75d6b943dc28153"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["5ce8d53d5582eaa6a0c771c9b119d480f41da59c","e7bd246bb7bc35ac22edfee9157e034dfc4e65eb"],"817d8435e9135b756f08ce6710ab0baac51bdf88":["2553b00f699380c64959ccb27991289aae87be2e","e7bd246bb7bc35ac22edfee9157e034dfc4e65eb"],"1291e4568eb7d9463d751627596ef14baf4c1603":["d083e83f225b11e5fdd900e83d26ddb385b6955c","0f3cee3d20b0c786e6fca20539454262e29edcab"],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["872cff1d3a554e0cd64014cd97f88d3002b0f491","4122a26e1fd0457a340616673a3d3aada370f713"],"5ce8d53d5582eaa6a0c771c9b119d480f41da59c":["fd9325c7ff9928fabe81c28553b41fc7aa57dfab"],"4122a26e1fd0457a340616673a3d3aada370f713":["3cc749c053615f5871f3b95715fe292f34e70a53"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","3e00f80591de714c6975f454e33e0fa5218b5902"],"3bb13258feba31ab676502787ab2e1779f129b7a":["955c32f886db6f6356c9fcdea6b1f1cb4effda24","4e8cc373c801e54cec75daf9f52792cb4b17f536"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"4e8cc373c801e54cec75daf9f52792cb4b17f536":["955c32f886db6f6356c9fcdea6b1f1cb4effda24"]},"commit2Childs":{"f1bdbf92da222965b46c0a942c3857ba56e5c638":[],"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":[],"fafef7c83fe8e0b3ca9298d5d75d6b943dc28153":["e7bd246bb7bc35ac22edfee9157e034dfc4e65eb","2553b00f699380c64959ccb27991289aae87be2e"],"e7bd246bb7bc35ac22edfee9157e034dfc4e65eb":["0f3cee3d20b0c786e6fca20539454262e29edcab","d083e83f225b11e5fdd900e83d26ddb385b6955c","817d8435e9135b756f08ce6710ab0baac51bdf88"],"955c32f886db6f6356c9fcdea6b1f1cb4effda24":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","3bb13258feba31ab676502787ab2e1779f129b7a","4e8cc373c801e54cec75daf9f52792cb4b17f536"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["868da859b43505d9d2a023bfeae6dd0c795f5295"],"bb9b72f7c3d7827c64dd4ec580ded81778da361d":["bde51b089eb7f86171eb3406e38a274743f9b7ac"],"fd9325c7ff9928fabe81c28553b41fc7aa57dfab":["bb9b72f7c3d7827c64dd4ec580ded81778da361d","29ef99d61cda9641b6250bf9567329a6e65f901d","5ce8d53d5582eaa6a0c771c9b119d480f41da59c"],"3e00f80591de714c6975f454e33e0fa5218b5902":["fd9325c7ff9928fabe81c28553b41fc7aa57dfab","868da859b43505d9d2a023bfeae6dd0c795f5295"],"f0b9507caf22f292ac0e5e59f62db4275adf4511":[],"29ef99d61cda9641b6250bf9567329a6e65f901d":["f1bdbf92da222965b46c0a942c3857ba56e5c638"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["955c32f886db6f6356c9fcdea6b1f1cb4effda24"],"0f3cee3d20b0c786e6fca20539454262e29edcab":["f0b9507caf22f292ac0e5e59f62db4275adf4511","3cc749c053615f5871f3b95715fe292f34e70a53","1291e4568eb7d9463d751627596ef14baf4c1603"],"3cc749c053615f5871f3b95715fe292f34e70a53":["872cff1d3a554e0cd64014cd97f88d3002b0f491","4122a26e1fd0457a340616673a3d3aada370f713"],"872cff1d3a554e0cd64014cd97f88d3002b0f491":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","3615ce4a1f785ae1b779244de52c6a7d99227e60"],"2553b00f699380c64959ccb27991289aae87be2e":["817d8435e9135b756f08ce6710ab0baac51bdf88"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["1291e4568eb7d9463d751627596ef14baf4c1603"],"817d8435e9135b756f08ce6710ab0baac51bdf88":["f0b9507caf22f292ac0e5e59f62db4275adf4511"],"1291e4568eb7d9463d751627596ef14baf4c1603":[],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"5ce8d53d5582eaa6a0c771c9b119d480f41da59c":["f1bdbf92da222965b46c0a942c3857ba56e5c638","fafef7c83fe8e0b3ca9298d5d75d6b943dc28153","bde51b089eb7f86171eb3406e38a274743f9b7ac","2553b00f699380c64959ccb27991289aae87be2e","d083e83f225b11e5fdd900e83d26ddb385b6955c"],"4122a26e1fd0457a340616673a3d3aada370f713":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["bb9b72f7c3d7827c64dd4ec580ded81778da361d"],"3bb13258feba31ab676502787ab2e1779f129b7a":["29ef99d61cda9641b6250bf9567329a6e65f901d"],"4e8cc373c801e54cec75daf9f52792cb4b17f536":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","3e00f80591de714c6975f454e33e0fa5218b5902","3bb13258feba31ab676502787ab2e1779f129b7a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["f1bdbf92da222965b46c0a942c3857ba56e5c638","ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","f0b9507caf22f292ac0e5e59f62db4275adf4511","bde51b089eb7f86171eb3406e38a274743f9b7ac","1291e4568eb7d9463d751627596ef14baf4c1603","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}