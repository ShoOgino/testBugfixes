{"path":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/BlockTermsWriter.TermsWriter#finishTerm(BytesRef,TermStats).mjava","commits":[{"id":"038e2a9b07e2f8ae58336613cea227bf8b973484","date":1346850972,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/BlockTermsWriter.TermsWriter#finishTerm(BytesRef,TermStats).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/BlockTermsWriter.TermsWriter#finishTerm(BytesRef,TermStats).mjava","sourceNew":"    @Override\n    public void finishTerm(BytesRef text, TermStats stats) throws IOException {\n\n      assert stats.docFreq > 0;\n      //System.out.println(\"BTW: finishTerm term=\" + fieldInfo.name + \":\" + text.utf8ToString() + \" \" + text + \" seg=\" + segment + \" df=\" + stats.docFreq);\n\n      final boolean isIndexTerm = fieldIndexWriter.checkIndexTerm(text, stats);\n\n      if (isIndexTerm) {\n        if (pendingCount > 0) {\n          // Instead of writing each term, live, we gather terms\n          // in RAM in a pending buffer, and then write the\n          // entire block in between index terms:\n          flushBlock();\n        }\n        fieldIndexWriter.add(text, stats, out.getFilePointer());\n        //System.out.println(\"  index term!\");\n      }\n\n      if (pendingTerms.length == pendingCount) {\n        final TermEntry[] newArray = new TermEntry[ArrayUtil.oversize(pendingCount+1, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(pendingTerms, 0, newArray, 0, pendingCount);\n        for(int i=pendingCount;i<newArray.length;i++) {\n          newArray[i] = new TermEntry();\n        }\n        pendingTerms = newArray;\n      }\n      final TermEntry te = pendingTerms[pendingCount];\n      te.term.copyBytes(text);\n      te.stats = stats;\n\n      pendingCount++;\n\n      postingsWriter.finishTerm(stats);\n      numTerms++;\n    }\n\n","sourceOld":"    @Override\n    public void finishTerm(BytesRef text, TermStats stats) throws IOException {\n\n      assert stats.docFreq > 0;\n      //System.out.println(\"BTW: finishTerm term=\" + fieldInfo.name + \":\" + text.utf8ToString() + \" \" + text + \" seg=\" + segment + \" df=\" + stats.docFreq);\n\n      final boolean isIndexTerm = fieldIndexWriter.checkIndexTerm(text, stats);\n\n      if (isIndexTerm) {\n        if (pendingCount > 0) {\n          // Instead of writing each term, live, we gather terms\n          // in RAM in a pending buffer, and then write the\n          // entire block in between index terms:\n          flushBlock();\n        }\n        fieldIndexWriter.add(text, stats, out.getFilePointer());\n        //System.out.println(\"  index term!\");\n      }\n\n      if (pendingTerms.length == pendingCount) {\n        final TermEntry[] newArray = new TermEntry[ArrayUtil.oversize(pendingCount+1, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(pendingTerms, 0, newArray, 0, pendingCount);\n        for(int i=pendingCount;i<newArray.length;i++) {\n          newArray[i] = new TermEntry();\n        }\n        pendingTerms = newArray;\n      }\n      final TermEntry te = pendingTerms[pendingCount];\n      te.term.copyBytes(text);\n      te.stats = stats;\n\n      pendingCount++;\n\n      postingsWriter.finishTerm(stats);\n      numTerms++;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1a88d7b0899b7d22dcbd4cf8ca35d9ec9850ab98","date":1377268487,"type":3,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/BlockTermsWriter.TermsWriter#finishTerm(BytesRef,TermStats).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/BlockTermsWriter.TermsWriter#finishTerm(BytesRef,TermStats).mjava","sourceNew":"    @Override\n    public void finishTerm(BytesRef text, TermStats stats) throws IOException {\n\n      assert stats.docFreq > 0;\n      //System.out.println(\"BTW: finishTerm term=\" + fieldInfo.name + \":\" + text.utf8ToString() + \" \" + text + \" seg=\" + segment + \" df=\" + stats.docFreq);\n\n      final boolean isIndexTerm = fieldIndexWriter.checkIndexTerm(text, stats);\n\n      if (isIndexTerm) {\n        if (pendingCount > 0) {\n          // Instead of writing each term, live, we gather terms\n          // in RAM in a pending buffer, and then write the\n          // entire block in between index terms:\n          flushBlock();\n        }\n        fieldIndexWriter.add(text, stats, out.getFilePointer());\n        //System.out.println(\"  index term!\");\n      }\n\n      if (pendingTerms.length == pendingCount) {\n        final TermEntry[] newArray = new TermEntry[ArrayUtil.oversize(pendingCount+1, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(pendingTerms, 0, newArray, 0, pendingCount);\n        for(int i=pendingCount;i<newArray.length;i++) {\n          newArray[i] = new TermEntry();\n        }\n        pendingTerms = newArray;\n      }\n      final TermEntry te = pendingTerms[pendingCount];\n      te.term.copyBytes(text);\n      te.state = postingsWriter.newTermState();\n      te.state.docFreq = stats.docFreq;\n      te.state.totalTermFreq = stats.totalTermFreq;\n      postingsWriter.finishTerm(te.state);\n\n      pendingCount++;\n      numTerms++;\n    }\n\n","sourceOld":"    @Override\n    public void finishTerm(BytesRef text, TermStats stats) throws IOException {\n\n      assert stats.docFreq > 0;\n      //System.out.println(\"BTW: finishTerm term=\" + fieldInfo.name + \":\" + text.utf8ToString() + \" \" + text + \" seg=\" + segment + \" df=\" + stats.docFreq);\n\n      final boolean isIndexTerm = fieldIndexWriter.checkIndexTerm(text, stats);\n\n      if (isIndexTerm) {\n        if (pendingCount > 0) {\n          // Instead of writing each term, live, we gather terms\n          // in RAM in a pending buffer, and then write the\n          // entire block in between index terms:\n          flushBlock();\n        }\n        fieldIndexWriter.add(text, stats, out.getFilePointer());\n        //System.out.println(\"  index term!\");\n      }\n\n      if (pendingTerms.length == pendingCount) {\n        final TermEntry[] newArray = new TermEntry[ArrayUtil.oversize(pendingCount+1, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(pendingTerms, 0, newArray, 0, pendingCount);\n        for(int i=pendingCount;i<newArray.length;i++) {\n          newArray[i] = new TermEntry();\n        }\n        pendingTerms = newArray;\n      }\n      final TermEntry te = pendingTerms[pendingCount];\n      te.term.copyBytes(text);\n      te.stats = stats;\n\n      pendingCount++;\n\n      postingsWriter.finishTerm(stats);\n      numTerms++;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2f948dd442d23baa6cbb28daf77c8db78b351329","date":1378742876,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/BlockTermsWriter.TermsWriter#finishTerm(BytesRef,TermStats).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/BlockTermsWriter.TermsWriter#finishTerm(BytesRef,TermStats).mjava","sourceNew":"    @Override\n    public void finishTerm(BytesRef text, TermStats stats) throws IOException {\n\n      assert stats.docFreq > 0;\n      //System.out.println(\"BTW: finishTerm term=\" + fieldInfo.name + \":\" + text.utf8ToString() + \" \" + text + \" seg=\" + segment + \" df=\" + stats.docFreq);\n\n      final boolean isIndexTerm = fieldIndexWriter.checkIndexTerm(text, stats);\n\n      if (isIndexTerm) {\n        if (pendingCount > 0) {\n          // Instead of writing each term, live, we gather terms\n          // in RAM in a pending buffer, and then write the\n          // entire block in between index terms:\n          flushBlock();\n        }\n        fieldIndexWriter.add(text, stats, out.getFilePointer());\n        //System.out.println(\"  index term!\");\n      }\n\n      if (pendingTerms.length == pendingCount) {\n        final TermEntry[] newArray = new TermEntry[ArrayUtil.oversize(pendingCount+1, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(pendingTerms, 0, newArray, 0, pendingCount);\n        for(int i=pendingCount;i<newArray.length;i++) {\n          newArray[i] = new TermEntry();\n        }\n        pendingTerms = newArray;\n      }\n      final TermEntry te = pendingTerms[pendingCount];\n      te.term.copyBytes(text);\n      te.state = postingsWriter.newTermState();\n      te.state.docFreq = stats.docFreq;\n      te.state.totalTermFreq = stats.totalTermFreq;\n      postingsWriter.finishTerm(te.state);\n\n      pendingCount++;\n      numTerms++;\n    }\n\n","sourceOld":"    @Override\n    public void finishTerm(BytesRef text, TermStats stats) throws IOException {\n\n      assert stats.docFreq > 0;\n      //System.out.println(\"BTW: finishTerm term=\" + fieldInfo.name + \":\" + text.utf8ToString() + \" \" + text + \" seg=\" + segment + \" df=\" + stats.docFreq);\n\n      final boolean isIndexTerm = fieldIndexWriter.checkIndexTerm(text, stats);\n\n      if (isIndexTerm) {\n        if (pendingCount > 0) {\n          // Instead of writing each term, live, we gather terms\n          // in RAM in a pending buffer, and then write the\n          // entire block in between index terms:\n          flushBlock();\n        }\n        fieldIndexWriter.add(text, stats, out.getFilePointer());\n        //System.out.println(\"  index term!\");\n      }\n\n      if (pendingTerms.length == pendingCount) {\n        final TermEntry[] newArray = new TermEntry[ArrayUtil.oversize(pendingCount+1, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(pendingTerms, 0, newArray, 0, pendingCount);\n        for(int i=pendingCount;i<newArray.length;i++) {\n          newArray[i] = new TermEntry();\n        }\n        pendingTerms = newArray;\n      }\n      final TermEntry te = pendingTerms[pendingCount];\n      te.term.copyBytes(text);\n      te.stats = stats;\n\n      pendingCount++;\n\n      postingsWriter.finishTerm(stats);\n      numTerms++;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fa80a35d7c4b2b1e83082b275e3e8328ab93db52","date":1381766157,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/BlockTermsWriter.TermsWriter#write(BytesRef,TermsEnum).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/BlockTermsWriter.TermsWriter#finishTerm(BytesRef,TermStats).mjava","sourceNew":"    void write(BytesRef text, TermsEnum termsEnum) throws IOException {\n\n      BlockTermState state = postingsWriter.writeTerm(text, termsEnum, docsSeen);\n      if (state == null) {\n        // No docs for this term:\n        return;\n      }\n      sumDocFreq += state.docFreq;\n      sumTotalTermFreq += state.totalTermFreq;\n\n      assert state.docFreq > 0;\n      //System.out.println(\"BTW: finishTerm term=\" + fieldInfo.name + \":\" + text.utf8ToString() + \" \" + text + \" seg=\" + segment + \" df=\" + stats.docFreq);\n\n      TermStats stats = new TermStats(state.docFreq, state.totalTermFreq);\n      final boolean isIndexTerm = fieldIndexWriter.checkIndexTerm(text, stats);\n\n      if (isIndexTerm) {\n        if (pendingCount > 0) {\n          // Instead of writing each term, live, we gather terms\n          // in RAM in a pending buffer, and then write the\n          // entire block in between index terms:\n          flushBlock();\n        }\n        fieldIndexWriter.add(text, stats, out.getFilePointer());\n        //System.out.println(\"  index term!\");\n      }\n\n      if (pendingTerms.length == pendingCount) {\n        final TermEntry[] newArray = new TermEntry[ArrayUtil.oversize(pendingCount+1, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(pendingTerms, 0, newArray, 0, pendingCount);\n        for(int i=pendingCount;i<newArray.length;i++) {\n          newArray[i] = new TermEntry();\n        }\n        pendingTerms = newArray;\n      }\n      final TermEntry te = pendingTerms[pendingCount];\n      te.term.copyBytes(text);\n      te.state = state;\n\n      pendingCount++;\n      numTerms++;\n    }\n\n","sourceOld":"    @Override\n    public void finishTerm(BytesRef text, TermStats stats) throws IOException {\n\n      assert stats.docFreq > 0;\n      //System.out.println(\"BTW: finishTerm term=\" + fieldInfo.name + \":\" + text.utf8ToString() + \" \" + text + \" seg=\" + segment + \" df=\" + stats.docFreq);\n\n      final boolean isIndexTerm = fieldIndexWriter.checkIndexTerm(text, stats);\n\n      if (isIndexTerm) {\n        if (pendingCount > 0) {\n          // Instead of writing each term, live, we gather terms\n          // in RAM in a pending buffer, and then write the\n          // entire block in between index terms:\n          flushBlock();\n        }\n        fieldIndexWriter.add(text, stats, out.getFilePointer());\n        //System.out.println(\"  index term!\");\n      }\n\n      if (pendingTerms.length == pendingCount) {\n        final TermEntry[] newArray = new TermEntry[ArrayUtil.oversize(pendingCount+1, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(pendingTerms, 0, newArray, 0, pendingCount);\n        for(int i=pendingCount;i<newArray.length;i++) {\n          newArray[i] = new TermEntry();\n        }\n        pendingTerms = newArray;\n      }\n      final TermEntry te = pendingTerms[pendingCount];\n      te.term.copyBytes(text);\n      te.state = postingsWriter.newTermState();\n      te.state.docFreq = stats.docFreq;\n      te.state.totalTermFreq = stats.totalTermFreq;\n      postingsWriter.finishTerm(te.state);\n\n      pendingCount++;\n      numTerms++;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"1a88d7b0899b7d22dcbd4cf8ca35d9ec9850ab98":["038e2a9b07e2f8ae58336613cea227bf8b973484"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"fa80a35d7c4b2b1e83082b275e3e8328ab93db52":["2f948dd442d23baa6cbb28daf77c8db78b351329"],"2f948dd442d23baa6cbb28daf77c8db78b351329":["038e2a9b07e2f8ae58336613cea227bf8b973484","1a88d7b0899b7d22dcbd4cf8ca35d9ec9850ab98"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["fa80a35d7c4b2b1e83082b275e3e8328ab93db52"],"038e2a9b07e2f8ae58336613cea227bf8b973484":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"1a88d7b0899b7d22dcbd4cf8ca35d9ec9850ab98":["2f948dd442d23baa6cbb28daf77c8db78b351329"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["038e2a9b07e2f8ae58336613cea227bf8b973484"],"fa80a35d7c4b2b1e83082b275e3e8328ab93db52":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"2f948dd442d23baa6cbb28daf77c8db78b351329":["fa80a35d7c4b2b1e83082b275e3e8328ab93db52"],"038e2a9b07e2f8ae58336613cea227bf8b973484":["1a88d7b0899b7d22dcbd4cf8ca35d9ec9850ab98","2f948dd442d23baa6cbb28daf77c8db78b351329"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}