{"path":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionOnCommitTest#oneShardTest().mjava","commits":[{"id":"84f20f331d8001864545c7021812d8c6509c7593","date":1517216128,"type":1,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionOnCommitTest#oneShardTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/LeaderInitiatedRecoveryOnCommitTest#oneShardTest().mjava","sourceNew":"  private void oneShardTest() throws Exception {\n    log.info(\"Running oneShardTest\");\n\n    // create a collection that has 1 shard and 3 replicas\n    String testCollectionName = \"c8n_1x3_commits\";\n    createCollection(testCollectionName, \"conf1\", 1, 3, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    List<Replica> notLeaders =\n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 3, 30);\n    assertTrue(\"Expected 2 replicas for collection \" + testCollectionName\n            + \" but found \" + notLeaders.size() + \"; clusterState: \"\n            + printClusterStateInfo(),\n        notLeaders.size() == 2);\n\n    log.info(\"All replicas active for \"+testCollectionName);\n\n    // let's put the leader in its own partition, no replicas can contact it now\n    Replica leader = cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    log.info(\"Creating partition to leader at \"+leader.getCoreUrl());\n    SocketProxy leaderProxy = getProxyForReplica(leader);\n    leaderProxy.close();\n\n    Replica replica = notLeaders.get(0);\n    sendCommitWithRetry(replica);\n    Thread.sleep(sleepMsBeforeHealPartition);\n\n    cloudClient.getZkStateReader().forceUpdateCollection(testCollectionName); // get the latest state\n    leader = cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    assertSame(\"Leader was not active\", Replica.State.ACTIVE, leader.getState());\n\n    log.info(\"Healing partitioned replica at \"+leader.getCoreUrl());\n    leaderProxy.reopen();\n    Thread.sleep(sleepMsBeforeHealPartition);\n\n    // try to clean up\n    attemptCollectionDelete(cloudClient, testCollectionName);\n\n    log.info(\"oneShardTest completed OK\");\n  }\n\n","sourceOld":"  private void oneShardTest() throws Exception {\n    log.info(\"Running oneShardTest\");\n\n    // create a collection that has 1 shard and 3 replicas\n    String testCollectionName = \"c8n_1x3_commits\";\n    createCollection(testCollectionName, \"conf1\", 1, 3, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    List<Replica> notLeaders =\n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 3, 30);\n    assertTrue(\"Expected 2 replicas for collection \" + testCollectionName\n            + \" but found \" + notLeaders.size() + \"; clusterState: \"\n            + printClusterStateInfo(),\n        notLeaders.size() == 2);\n\n    log.info(\"All replicas active for \"+testCollectionName);\n\n    // let's put the leader in its own partition, no replicas can contact it now\n    Replica leader = cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    log.info(\"Creating partition to leader at \"+leader.getCoreUrl());\n    SocketProxy leaderProxy = getProxyForReplica(leader);\n    leaderProxy.close();\n\n    Replica replica = notLeaders.get(0);\n    sendCommitWithRetry(replica);\n    Thread.sleep(sleepMsBeforeHealPartition);\n\n    cloudClient.getZkStateReader().forceUpdateCollection(testCollectionName); // get the latest state\n    leader = cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    assertSame(\"Leader was not active\", Replica.State.ACTIVE, leader.getState());\n\n    log.info(\"Healing partitioned replica at \"+leader.getCoreUrl());\n    leaderProxy.reopen();\n    Thread.sleep(sleepMsBeforeHealPartition);\n\n    // try to clean up\n    attemptCollectionDelete(cloudClient, testCollectionName);\n\n    log.info(\"oneShardTest completed OK\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bb222a3f9d9421d5c95afce73013fbd8de07ea1f","date":1543514331,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionOnCommitTest#oneShardTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionOnCommitTest#oneShardTest().mjava","sourceNew":"  private void oneShardTest() throws Exception {\n    log.info(\"Running oneShardTest\");\n\n    // create a collection that has 1 shard and 3 replicas\n    String testCollectionName = \"c8n_1x3_commits\";\n    createCollection(testCollectionName, \"conf1\", 1, 3, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    List<Replica> notLeaders =\n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 3, 30);\n    assertTrue(\"Expected 2 replicas for collection \" + testCollectionName\n            + \" but found \" + notLeaders.size() + \"; clusterState: \"\n            + printClusterStateInfo(),\n        notLeaders.size() == 2);\n\n    log.info(\"All replicas active for \"+testCollectionName);\n\n    // let's put the leader in its own partition, no replicas can contact it now\n    Replica leader = cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    log.info(\"Creating partition to leader at \"+leader.getCoreUrl());\n\n    SocketProxy leaderProxy = getProxyForReplica(leader);\n    leaderProxy.close();\n\n    Replica replica = notLeaders.get(0);\n    sendCommitWithRetry(replica);\n    Thread.sleep(sleepMsBeforeHealPartition);\n\n    cloudClient.getZkStateReader().forceUpdateCollection(testCollectionName); // get the latest state\n    leader = cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    assertSame(\"Leader was not active\", Replica.State.ACTIVE, leader.getState());\n\n    log.info(\"Healing partitioned replica at \"+leader.getCoreUrl());\n    leaderProxy.reopen();\n    Thread.sleep(sleepMsBeforeHealPartition);\n\n    // try to clean up\n    attemptCollectionDelete(cloudClient, testCollectionName);\n\n    log.info(\"oneShardTest completed OK\");\n  }\n\n","sourceOld":"  private void oneShardTest() throws Exception {\n    log.info(\"Running oneShardTest\");\n\n    // create a collection that has 1 shard and 3 replicas\n    String testCollectionName = \"c8n_1x3_commits\";\n    createCollection(testCollectionName, \"conf1\", 1, 3, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    List<Replica> notLeaders =\n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 3, 30);\n    assertTrue(\"Expected 2 replicas for collection \" + testCollectionName\n            + \" but found \" + notLeaders.size() + \"; clusterState: \"\n            + printClusterStateInfo(),\n        notLeaders.size() == 2);\n\n    log.info(\"All replicas active for \"+testCollectionName);\n\n    // let's put the leader in its own partition, no replicas can contact it now\n    Replica leader = cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    log.info(\"Creating partition to leader at \"+leader.getCoreUrl());\n    SocketProxy leaderProxy = getProxyForReplica(leader);\n    leaderProxy.close();\n\n    Replica replica = notLeaders.get(0);\n    sendCommitWithRetry(replica);\n    Thread.sleep(sleepMsBeforeHealPartition);\n\n    cloudClient.getZkStateReader().forceUpdateCollection(testCollectionName); // get the latest state\n    leader = cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    assertSame(\"Leader was not active\", Replica.State.ACTIVE, leader.getState());\n\n    log.info(\"Healing partitioned replica at \"+leader.getCoreUrl());\n    leaderProxy.reopen();\n    Thread.sleep(sleepMsBeforeHealPartition);\n\n    // try to clean up\n    attemptCollectionDelete(cloudClient, testCollectionName);\n\n    log.info(\"oneShardTest completed OK\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a966532d92cf9ba2856f15a8140151bb6b518e4b","date":1588290631,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionOnCommitTest#oneShardTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionOnCommitTest#oneShardTest().mjava","sourceNew":"  private void oneShardTest() throws Exception {\n    log.info(\"Running oneShardTest\");\n\n    // create a collection that has 1 shard and 3 replicas\n    String testCollectionName = \"c8n_1x3_commits\";\n    createCollection(testCollectionName, \"conf1\", 1, 3, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    List<Replica> notLeaders =\n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 3, 30);\n    assertTrue(\"Expected 2 replicas for collection \" + testCollectionName\n            + \" but found \" + notLeaders.size() + \"; clusterState: \"\n            + printClusterStateInfo(),\n        notLeaders.size() == 2);\n\n    log.info(\"All replicas active for {}\", testCollectionName);\n\n    // let's put the leader in its own partition, no replicas can contact it now\n    Replica leader = cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    if (log.isInfoEnabled()) {\n      log.info(\"Creating partition to leader at {}\", leader.getCoreUrl());\n    }\n\n    SocketProxy leaderProxy = getProxyForReplica(leader);\n    leaderProxy.close();\n\n    Replica replica = notLeaders.get(0);\n    sendCommitWithRetry(replica);\n    Thread.sleep(sleepMsBeforeHealPartition);\n\n    cloudClient.getZkStateReader().forceUpdateCollection(testCollectionName); // get the latest state\n    leader = cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    assertSame(\"Leader was not active\", Replica.State.ACTIVE, leader.getState());\n\n    if (log.isInfoEnabled()) {\n      log.info(\"Healing partitioned replica at {}\", leader.getCoreUrl());\n    }\n    leaderProxy.reopen();\n    Thread.sleep(sleepMsBeforeHealPartition);\n\n    // try to clean up\n    attemptCollectionDelete(cloudClient, testCollectionName);\n\n    log.info(\"oneShardTest completed OK\");\n  }\n\n","sourceOld":"  private void oneShardTest() throws Exception {\n    log.info(\"Running oneShardTest\");\n\n    // create a collection that has 1 shard and 3 replicas\n    String testCollectionName = \"c8n_1x3_commits\";\n    createCollection(testCollectionName, \"conf1\", 1, 3, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    List<Replica> notLeaders =\n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 3, 30);\n    assertTrue(\"Expected 2 replicas for collection \" + testCollectionName\n            + \" but found \" + notLeaders.size() + \"; clusterState: \"\n            + printClusterStateInfo(),\n        notLeaders.size() == 2);\n\n    log.info(\"All replicas active for \"+testCollectionName);\n\n    // let's put the leader in its own partition, no replicas can contact it now\n    Replica leader = cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    log.info(\"Creating partition to leader at \"+leader.getCoreUrl());\n\n    SocketProxy leaderProxy = getProxyForReplica(leader);\n    leaderProxy.close();\n\n    Replica replica = notLeaders.get(0);\n    sendCommitWithRetry(replica);\n    Thread.sleep(sleepMsBeforeHealPartition);\n\n    cloudClient.getZkStateReader().forceUpdateCollection(testCollectionName); // get the latest state\n    leader = cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    assertSame(\"Leader was not active\", Replica.State.ACTIVE, leader.getState());\n\n    log.info(\"Healing partitioned replica at \"+leader.getCoreUrl());\n    leaderProxy.reopen();\n    Thread.sleep(sleepMsBeforeHealPartition);\n\n    // try to clean up\n    attemptCollectionDelete(cloudClient, testCollectionName);\n\n    log.info(\"oneShardTest completed OK\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e","date":1594223844,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionOnCommitTest#oneShardTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionOnCommitTest#oneShardTest().mjava","sourceNew":"  private void oneShardTest() throws Exception {\n    log.info(\"Running oneShardTest\");\n\n    // create a collection that has 1 shard and 3 replicas\n    String testCollectionName = \"c8n_1x3_commits\";\n    createCollection(testCollectionName, \"conf1\", 1, 3);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    List<Replica> notLeaders =\n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 3, 30);\n    assertTrue(\"Expected 2 replicas for collection \" + testCollectionName\n            + \" but found \" + notLeaders.size() + \"; clusterState: \"\n            + printClusterStateInfo(),\n        notLeaders.size() == 2);\n\n    log.info(\"All replicas active for {}\", testCollectionName);\n\n    // let's put the leader in its own partition, no replicas can contact it now\n    Replica leader = cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    if (log.isInfoEnabled()) {\n      log.info(\"Creating partition to leader at {}\", leader.getCoreUrl());\n    }\n\n    SocketProxy leaderProxy = getProxyForReplica(leader);\n    leaderProxy.close();\n\n    Replica replica = notLeaders.get(0);\n    sendCommitWithRetry(replica);\n    Thread.sleep(sleepMsBeforeHealPartition);\n\n    cloudClient.getZkStateReader().forceUpdateCollection(testCollectionName); // get the latest state\n    leader = cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    assertSame(\"Leader was not active\", Replica.State.ACTIVE, leader.getState());\n\n    if (log.isInfoEnabled()) {\n      log.info(\"Healing partitioned replica at {}\", leader.getCoreUrl());\n    }\n    leaderProxy.reopen();\n    Thread.sleep(sleepMsBeforeHealPartition);\n\n    // try to clean up\n    attemptCollectionDelete(cloudClient, testCollectionName);\n\n    log.info(\"oneShardTest completed OK\");\n  }\n\n","sourceOld":"  private void oneShardTest() throws Exception {\n    log.info(\"Running oneShardTest\");\n\n    // create a collection that has 1 shard and 3 replicas\n    String testCollectionName = \"c8n_1x3_commits\";\n    createCollection(testCollectionName, \"conf1\", 1, 3, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    List<Replica> notLeaders =\n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 3, 30);\n    assertTrue(\"Expected 2 replicas for collection \" + testCollectionName\n            + \" but found \" + notLeaders.size() + \"; clusterState: \"\n            + printClusterStateInfo(),\n        notLeaders.size() == 2);\n\n    log.info(\"All replicas active for {}\", testCollectionName);\n\n    // let's put the leader in its own partition, no replicas can contact it now\n    Replica leader = cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    if (log.isInfoEnabled()) {\n      log.info(\"Creating partition to leader at {}\", leader.getCoreUrl());\n    }\n\n    SocketProxy leaderProxy = getProxyForReplica(leader);\n    leaderProxy.close();\n\n    Replica replica = notLeaders.get(0);\n    sendCommitWithRetry(replica);\n    Thread.sleep(sleepMsBeforeHealPartition);\n\n    cloudClient.getZkStateReader().forceUpdateCollection(testCollectionName); // get the latest state\n    leader = cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    assertSame(\"Leader was not active\", Replica.State.ACTIVE, leader.getState());\n\n    if (log.isInfoEnabled()) {\n      log.info(\"Healing partitioned replica at {}\", leader.getCoreUrl());\n    }\n    leaderProxy.reopen();\n    Thread.sleep(sleepMsBeforeHealPartition);\n\n    // try to clean up\n    attemptCollectionDelete(cloudClient, testCollectionName);\n\n    log.info(\"oneShardTest completed OK\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["84f20f331d8001864545c7021812d8c6509c7593"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"84f20f331d8001864545c7021812d8c6509c7593":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a966532d92cf9ba2856f15a8140151bb6b518e4b":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e":["a966532d92cf9ba2856f15a8140151bb6b518e4b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["e46a76bb135597b8bf35930cfdb3702bdd1cbe6e"]},"commit2Childs":{"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["a966532d92cf9ba2856f15a8140151bb6b518e4b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["84f20f331d8001864545c7021812d8c6509c7593"],"84f20f331d8001864545c7021812d8c6509c7593":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"a966532d92cf9ba2856f15a8140151bb6b518e4b":["e46a76bb135597b8bf35930cfdb3702bdd1cbe6e"],"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}