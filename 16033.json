{"path":"solr/core/src/test/org/apache/solr/cloud/autoscaling/TestPolicyCloud#testDataProviderPerReplicaDetails().mjava","commits":[{"id":"1bbcda32e5cd37ef61ea1190bacd080308e22070","date":1508850553,"type":0,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/TestPolicyCloud#testDataProviderPerReplicaDetails().mjava","pathOld":"/dev/null","sourceNew":"  public void testDataProviderPerReplicaDetails() throws Exception {\n    CollectionAdminRequest.createCollection(\"perReplicaDataColl\", \"conf\", 1, 5)\n        .process(cluster.getSolrClient());\n\n    DocCollection coll = getCollectionState(\"perReplicaDataColl\");\n    String autoScaleJson = \"{\" +\n        \"  'cluster-preferences': [\" +\n        \"    { maximize : freedisk , precision: 50},\" +\n        \"    { minimize : cores, precision: 2}\" +\n        \"  ],\" +\n        \"  'cluster-policy': [\" +\n        \"    { replica : '0' , 'nodeRole': 'overseer'},\" +\n        \"    { 'replica': '<2', 'shard': '#ANY', 'node': '#ANY'\" +\n        \"    }\" +\n        \"  ],\" +\n        \"  'policies': {\" +\n        \"    'policy1': [\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'node': '#ANY'},\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'sysprop.rack': 'rack1'}\" +\n        \"    ]\" +\n        \"  }\" +\n        \"}\";\n    AutoScalingConfig config = new AutoScalingConfig((Map<String, Object>) Utils.fromJSONString(autoScaleJson));\n    SolrCloudManager cloudManager = new SolrClientCloudManager(new ZkDistributedQueueFactory(cluster.getZkClient()), cluster.getSolrClient());\n    Policy.Session session = config.getPolicy().createSession(cloudManager);\n\n    AtomicInteger count = new AtomicInteger(0);\n    for (Row row : session.getSorted()) {\n      row.collectionVsShardVsReplicas.forEach((c, shardVsReplicas) -> shardVsReplicas.forEach((s, replicaInfos) -> {\n        for (ReplicaInfo replicaInfo : replicaInfos) {\n          if (replicaInfo.getVariables().containsKey(Suggestion.ConditionType.CORE_IDX.tagName)) count.incrementAndGet();\n        }\n      }));\n    }\n    assertTrue(count.get() > 0);\n\n    CollectionAdminRequest.deleteCollection(\"perReplicaDataColl\").process(cluster.getSolrClient());\n\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e8972c9f22193dd2a876d8bd6418457bc5b9dcd7","date":1528898850,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/TestPolicyCloud#testDataProviderPerReplicaDetails().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/TestPolicyCloud#testDataProviderPerReplicaDetails().mjava","sourceNew":"  public void testDataProviderPerReplicaDetails() throws Exception {\n    CollectionAdminRequest.createCollection(\"perReplicaDataColl\", \"conf\", 1, 5)\n        .process(cluster.getSolrClient());\n\n    DocCollection coll = getCollectionState(\"perReplicaDataColl\");\n    String autoScaleJson = \"{\" +\n        \"  'cluster-preferences': [\" +\n        \"    { maximize : freedisk , precision: 50},\" +\n        \"    { minimize : cores, precision: 2}\" +\n        \"  ],\" +\n        \"  'cluster-policy': [\" +\n        \"    { replica : '0' , 'nodeRole': 'overseer'},\" +\n        \"    { 'replica': '<2', 'shard': '#ANY', 'node': '#ANY'\" +\n        \"    }\" +\n        \"  ],\" +\n        \"  'policies': {\" +\n        \"    'policy1': [\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'node': '#ANY'},\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'sysprop.rack': 'rack1'}\" +\n        \"    ]\" +\n        \"  }\" +\n        \"}\";\n    AutoScalingConfig config = new AutoScalingConfig((Map<String, Object>) Utils.fromJSONString(autoScaleJson));\n    AtomicInteger count = new AtomicInteger(0);\n    SolrCloudManager cloudManager = new SolrClientCloudManager(new ZkDistributedQueueFactory(cluster.getZkClient()), cluster.getSolrClient());\n    String nodeName = cloudManager.getClusterStateProvider().getLiveNodes().iterator().next();\n    SolrClientNodeStateProvider nodeStateProvider = (SolrClientNodeStateProvider) cloudManager.getNodeStateProvider();\n    Map<String, Map<String, List<ReplicaInfo>>> result = nodeStateProvider.getReplicaInfo(nodeName, Collections.singleton(\"UPDATE./update.requests\"));\n    nodeStateProvider.forEachReplica(nodeName, replicaInfo -> {\n      if (replicaInfo.getVariables().containsKey(\"UPDATE./update.requests\")) count.incrementAndGet();\n    });\n    assertTrue(count.get() > 0);\n\n    Policy.Session session = config.getPolicy().createSession(cloudManager);\n\n    count .set(0);\n    for (Row row : session.getSorted()) {\n      row.collectionVsShardVsReplicas.forEach((c, shardVsReplicas) -> shardVsReplicas.forEach((s, replicaInfos) -> {\n        for (ReplicaInfo replicaInfo : replicaInfos) {\n          if (replicaInfo.getVariables().containsKey(Suggestion.ConditionType.CORE_IDX.tagName)) count.incrementAndGet();\n        }\n      }));\n    }\n    assertTrue(count.get() > 0);\n\n    CollectionAdminRequest.deleteCollection(\"perReplicaDataColl\").process(cluster.getSolrClient());\n\n  }\n\n","sourceOld":"  public void testDataProviderPerReplicaDetails() throws Exception {\n    CollectionAdminRequest.createCollection(\"perReplicaDataColl\", \"conf\", 1, 5)\n        .process(cluster.getSolrClient());\n\n    DocCollection coll = getCollectionState(\"perReplicaDataColl\");\n    String autoScaleJson = \"{\" +\n        \"  'cluster-preferences': [\" +\n        \"    { maximize : freedisk , precision: 50},\" +\n        \"    { minimize : cores, precision: 2}\" +\n        \"  ],\" +\n        \"  'cluster-policy': [\" +\n        \"    { replica : '0' , 'nodeRole': 'overseer'},\" +\n        \"    { 'replica': '<2', 'shard': '#ANY', 'node': '#ANY'\" +\n        \"    }\" +\n        \"  ],\" +\n        \"  'policies': {\" +\n        \"    'policy1': [\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'node': '#ANY'},\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'sysprop.rack': 'rack1'}\" +\n        \"    ]\" +\n        \"  }\" +\n        \"}\";\n    AutoScalingConfig config = new AutoScalingConfig((Map<String, Object>) Utils.fromJSONString(autoScaleJson));\n    SolrCloudManager cloudManager = new SolrClientCloudManager(new ZkDistributedQueueFactory(cluster.getZkClient()), cluster.getSolrClient());\n    Policy.Session session = config.getPolicy().createSession(cloudManager);\n\n    AtomicInteger count = new AtomicInteger(0);\n    for (Row row : session.getSorted()) {\n      row.collectionVsShardVsReplicas.forEach((c, shardVsReplicas) -> shardVsReplicas.forEach((s, replicaInfos) -> {\n        for (ReplicaInfo replicaInfo : replicaInfos) {\n          if (replicaInfo.getVariables().containsKey(Suggestion.ConditionType.CORE_IDX.tagName)) count.incrementAndGet();\n        }\n      }));\n    }\n    assertTrue(count.get() > 0);\n\n    CollectionAdminRequest.deleteCollection(\"perReplicaDataColl\").process(cluster.getSolrClient());\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26","date":1531589977,"type":3,"author":"Michael Braun","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/TestPolicyCloud#testDataProviderPerReplicaDetails().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/TestPolicyCloud#testDataProviderPerReplicaDetails().mjava","sourceNew":"  public void testDataProviderPerReplicaDetails() throws Exception {\n    CollectionAdminRequest.createCollection(\"perReplicaDataColl\", \"conf\", 1, 5)\n        .process(cluster.getSolrClient());\n\n    DocCollection coll = getCollectionState(\"perReplicaDataColl\");\n    String autoScaleJson = \"{\" +\n        \"  'cluster-preferences': [\" +\n        \"    { maximize : freedisk , precision: 50},\" +\n        \"    { minimize : cores, precision: 2}\" +\n        \"  ],\" +\n        \"  'cluster-policy': [\" +\n        \"    { replica : '0' , 'nodeRole': 'overseer'},\" +\n        \"    { 'replica': '<2', 'shard': '#ANY', 'node': '#ANY'\" +\n        \"    }\" +\n        \"  ],\" +\n        \"  'policies': {\" +\n        \"    'policy1': [\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'node': '#ANY'},\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'sysprop.rack': 'rack1'}\" +\n        \"    ]\" +\n        \"  }\" +\n        \"}\";\n    AutoScalingConfig config = new AutoScalingConfig((Map<String, Object>) Utils.fromJSONString(autoScaleJson));\n    AtomicInteger count = new AtomicInteger(0);\n    SolrCloudManager cloudManager = new SolrClientCloudManager(new ZkDistributedQueueFactory(cluster.getZkClient()), cluster.getSolrClient());\n    String nodeName = cloudManager.getClusterStateProvider().getLiveNodes().iterator().next();\n    SolrClientNodeStateProvider nodeStateProvider = (SolrClientNodeStateProvider) cloudManager.getNodeStateProvider();\n    Map<String, Map<String, List<ReplicaInfo>>> result = nodeStateProvider.getReplicaInfo(nodeName, Collections.singleton(\"UPDATE./update.requests\"));\n    nodeStateProvider.forEachReplica(nodeName, replicaInfo -> {\n      if (replicaInfo.getVariables().containsKey(\"UPDATE./update.requests\")) count.incrementAndGet();\n    });\n    assertTrue(count.get() > 0);\n\n    Policy.Session session = config.getPolicy().createSession(cloudManager);\n\n    count .set(0);\n    for (Row row : session.getSorted()) {\n      row.collectionVsShardVsReplicas.forEach((c, shardVsReplicas) -> shardVsReplicas.forEach((s, replicaInfos) -> {\n        for (ReplicaInfo replicaInfo : replicaInfos) {\n          if (replicaInfo.getVariables().containsKey(Suggestion.ConditionType.CORE_IDX.tagName)) count.incrementAndGet();\n        }\n      }));\n    }\n    assertTrue(count.get() > 0);\n\n    CollectionAdminRequest.deleteCollection(\"perReplicaDataColl\").process(cluster.getSolrClient());\n\n  }\n\n","sourceOld":"  public void testDataProviderPerReplicaDetails() throws Exception {\n    CollectionAdminRequest.createCollection(\"perReplicaDataColl\", \"conf\", 1, 5)\n        .process(cluster.getSolrClient());\n\n    DocCollection coll = getCollectionState(\"perReplicaDataColl\");\n    String autoScaleJson = \"{\" +\n        \"  'cluster-preferences': [\" +\n        \"    { maximize : freedisk , precision: 50},\" +\n        \"    { minimize : cores, precision: 2}\" +\n        \"  ],\" +\n        \"  'cluster-policy': [\" +\n        \"    { replica : '0' , 'nodeRole': 'overseer'},\" +\n        \"    { 'replica': '<2', 'shard': '#ANY', 'node': '#ANY'\" +\n        \"    }\" +\n        \"  ],\" +\n        \"  'policies': {\" +\n        \"    'policy1': [\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'node': '#ANY'},\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'sysprop.rack': 'rack1'}\" +\n        \"    ]\" +\n        \"  }\" +\n        \"}\";\n    AutoScalingConfig config = new AutoScalingConfig((Map<String, Object>) Utils.fromJSONString(autoScaleJson));\n    SolrCloudManager cloudManager = new SolrClientCloudManager(new ZkDistributedQueueFactory(cluster.getZkClient()), cluster.getSolrClient());\n    Policy.Session session = config.getPolicy().createSession(cloudManager);\n\n    AtomicInteger count = new AtomicInteger(0);\n    for (Row row : session.getSorted()) {\n      row.collectionVsShardVsReplicas.forEach((c, shardVsReplicas) -> shardVsReplicas.forEach((s, replicaInfos) -> {\n        for (ReplicaInfo replicaInfo : replicaInfos) {\n          if (replicaInfo.getVariables().containsKey(Suggestion.ConditionType.CORE_IDX.tagName)) count.incrementAndGet();\n        }\n      }));\n    }\n    assertTrue(count.get() > 0);\n\n    CollectionAdminRequest.deleteCollection(\"perReplicaDataColl\").process(cluster.getSolrClient());\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"78231225260fb5b3bf9920f203d71477d5501c65","date":1531726165,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/TestPolicyCloud#testDataProviderPerReplicaDetails().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/TestPolicyCloud#testDataProviderPerReplicaDetails().mjava","sourceNew":"  public void testDataProviderPerReplicaDetails() throws Exception {\n    CollectionAdminRequest.createCollection(\"perReplicaDataColl\", \"conf\", 1, 5)\n        .process(cluster.getSolrClient());\n\n    DocCollection coll = getCollectionState(\"perReplicaDataColl\");\n    String autoScaleJson = \"{\" +\n        \"  'cluster-preferences': [\" +\n        \"    { maximize : freedisk , precision: 50},\" +\n        \"    { minimize : cores, precision: 2}\" +\n        \"  ],\" +\n        \"  'cluster-policy': [\" +\n        \"    { replica : '0' , 'nodeRole': 'overseer'},\" +\n        \"    { 'replica': '<2', 'shard': '#ANY', 'node': '#ANY'\" +\n        \"    }\" +\n        \"  ],\" +\n        \"  'policies': {\" +\n        \"    'policy1': [\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'node': '#ANY'},\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'sysprop.rack': 'rack1'}\" +\n        \"    ]\" +\n        \"  }\" +\n        \"}\";\n    AutoScalingConfig config = new AutoScalingConfig((Map<String, Object>) Utils.fromJSONString(autoScaleJson));\n    AtomicInteger count = new AtomicInteger(0);\n    SolrCloudManager cloudManager = new SolrClientCloudManager(new ZkDistributedQueueFactory(cluster.getZkClient()), cluster.getSolrClient());\n    String nodeName = cloudManager.getClusterStateProvider().getLiveNodes().iterator().next();\n    SolrClientNodeStateProvider nodeStateProvider = (SolrClientNodeStateProvider) cloudManager.getNodeStateProvider();\n    Map<String, Map<String, List<ReplicaInfo>>> result = nodeStateProvider.getReplicaInfo(nodeName, Collections.singleton(\"UPDATE./update.requests\"));\n    nodeStateProvider.forEachReplica(nodeName, replicaInfo -> {\n      if (replicaInfo.getVariables().containsKey(\"UPDATE./update.requests\")) count.incrementAndGet();\n    });\n    assertTrue(count.get() > 0);\n\n    Policy.Session session = config.getPolicy().createSession(cloudManager);\n\n    for (Row row : session.getSortedNodes()) {\n      Object val = row.getVal(Suggestion.ConditionType.TOTALDISK.tagName, null);\n      log.info(\"node: {} , totaldisk : {}, freedisk : {}\", row.node, val, row.getVal(\"freedisk\",null));\n      assertTrue(val != null);\n\n    }\n\n    count .set(0);\n    for (Row row : session.getSortedNodes()) {\n      row.collectionVsShardVsReplicas.forEach((c, shardVsReplicas) -> shardVsReplicas.forEach((s, replicaInfos) -> {\n        for (ReplicaInfo replicaInfo : replicaInfos) {\n          if (replicaInfo.getVariables().containsKey(Suggestion.ConditionType.CORE_IDX.tagName)) count.incrementAndGet();\n        }\n      }));\n    }\n    assertTrue(count.get() > 0);\n\n    CollectionAdminRequest.deleteCollection(\"perReplicaDataColl\").process(cluster.getSolrClient());\n\n  }\n\n","sourceOld":"  public void testDataProviderPerReplicaDetails() throws Exception {\n    CollectionAdminRequest.createCollection(\"perReplicaDataColl\", \"conf\", 1, 5)\n        .process(cluster.getSolrClient());\n\n    DocCollection coll = getCollectionState(\"perReplicaDataColl\");\n    String autoScaleJson = \"{\" +\n        \"  'cluster-preferences': [\" +\n        \"    { maximize : freedisk , precision: 50},\" +\n        \"    { minimize : cores, precision: 2}\" +\n        \"  ],\" +\n        \"  'cluster-policy': [\" +\n        \"    { replica : '0' , 'nodeRole': 'overseer'},\" +\n        \"    { 'replica': '<2', 'shard': '#ANY', 'node': '#ANY'\" +\n        \"    }\" +\n        \"  ],\" +\n        \"  'policies': {\" +\n        \"    'policy1': [\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'node': '#ANY'},\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'sysprop.rack': 'rack1'}\" +\n        \"    ]\" +\n        \"  }\" +\n        \"}\";\n    AutoScalingConfig config = new AutoScalingConfig((Map<String, Object>) Utils.fromJSONString(autoScaleJson));\n    AtomicInteger count = new AtomicInteger(0);\n    SolrCloudManager cloudManager = new SolrClientCloudManager(new ZkDistributedQueueFactory(cluster.getZkClient()), cluster.getSolrClient());\n    String nodeName = cloudManager.getClusterStateProvider().getLiveNodes().iterator().next();\n    SolrClientNodeStateProvider nodeStateProvider = (SolrClientNodeStateProvider) cloudManager.getNodeStateProvider();\n    Map<String, Map<String, List<ReplicaInfo>>> result = nodeStateProvider.getReplicaInfo(nodeName, Collections.singleton(\"UPDATE./update.requests\"));\n    nodeStateProvider.forEachReplica(nodeName, replicaInfo -> {\n      if (replicaInfo.getVariables().containsKey(\"UPDATE./update.requests\")) count.incrementAndGet();\n    });\n    assertTrue(count.get() > 0);\n\n    Policy.Session session = config.getPolicy().createSession(cloudManager);\n\n    count .set(0);\n    for (Row row : session.getSorted()) {\n      row.collectionVsShardVsReplicas.forEach((c, shardVsReplicas) -> shardVsReplicas.forEach((s, replicaInfos) -> {\n        for (ReplicaInfo replicaInfo : replicaInfos) {\n          if (replicaInfo.getVariables().containsKey(Suggestion.ConditionType.CORE_IDX.tagName)) count.incrementAndGet();\n        }\n      }));\n    }\n    assertTrue(count.get() > 0);\n\n    CollectionAdminRequest.deleteCollection(\"perReplicaDataColl\").process(cluster.getSolrClient());\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a10a24d2afdf00bbe1013706b80c989315772dc9","date":1531726431,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/TestPolicyCloud#testDataProviderPerReplicaDetails().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/TestPolicyCloud#testDataProviderPerReplicaDetails().mjava","sourceNew":"  public void testDataProviderPerReplicaDetails() throws Exception {\n    CollectionAdminRequest.createCollection(\"perReplicaDataColl\", \"conf\", 1, 5)\n        .process(cluster.getSolrClient());\n\n    DocCollection coll = getCollectionState(\"perReplicaDataColl\");\n    String autoScaleJson = \"{\" +\n        \"  'cluster-preferences': [\" +\n        \"    { maximize : freedisk , precision: 50},\" +\n        \"    { minimize : cores, precision: 2}\" +\n        \"  ],\" +\n        \"  'cluster-policy': [\" +\n        \"    { replica : '0' , 'nodeRole': 'overseer'},\" +\n        \"    { 'replica': '<2', 'shard': '#ANY', 'node': '#ANY'\" +\n        \"    }\" +\n        \"  ],\" +\n        \"  'policies': {\" +\n        \"    'policy1': [\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'node': '#ANY'},\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'sysprop.rack': 'rack1'}\" +\n        \"    ]\" +\n        \"  }\" +\n        \"}\";\n    AutoScalingConfig config = new AutoScalingConfig((Map<String, Object>) Utils.fromJSONString(autoScaleJson));\n    AtomicInteger count = new AtomicInteger(0);\n    SolrCloudManager cloudManager = new SolrClientCloudManager(new ZkDistributedQueueFactory(cluster.getZkClient()), cluster.getSolrClient());\n    String nodeName = cloudManager.getClusterStateProvider().getLiveNodes().iterator().next();\n    SolrClientNodeStateProvider nodeStateProvider = (SolrClientNodeStateProvider) cloudManager.getNodeStateProvider();\n    Map<String, Map<String, List<ReplicaInfo>>> result = nodeStateProvider.getReplicaInfo(nodeName, Collections.singleton(\"UPDATE./update.requests\"));\n    nodeStateProvider.forEachReplica(nodeName, replicaInfo -> {\n      if (replicaInfo.getVariables().containsKey(\"UPDATE./update.requests\")) count.incrementAndGet();\n    });\n    assertTrue(count.get() > 0);\n\n    Policy.Session session = config.getPolicy().createSession(cloudManager);\n\n    count .set(0);\n    for (Row row : session.getSorted()) {\n      row.collectionVsShardVsReplicas.forEach((c, shardVsReplicas) -> shardVsReplicas.forEach((s, replicaInfos) -> {\n        for (ReplicaInfo replicaInfo : replicaInfos) {\n          if (replicaInfo.getVariables().containsKey(Suggestion.ConditionType.CORE_IDX.tagName)) count.incrementAndGet();\n        }\n      }));\n    }\n    assertTrue(count.get() > 0);\n\n    CollectionAdminRequest.deleteCollection(\"perReplicaDataColl\").process(cluster.getSolrClient());\n\n  }\n\n","sourceOld":"  public void testDataProviderPerReplicaDetails() throws Exception {\n    CollectionAdminRequest.createCollection(\"perReplicaDataColl\", \"conf\", 1, 5)\n        .process(cluster.getSolrClient());\n\n    DocCollection coll = getCollectionState(\"perReplicaDataColl\");\n    String autoScaleJson = \"{\" +\n        \"  'cluster-preferences': [\" +\n        \"    { maximize : freedisk , precision: 50},\" +\n        \"    { minimize : cores, precision: 2}\" +\n        \"  ],\" +\n        \"  'cluster-policy': [\" +\n        \"    { replica : '0' , 'nodeRole': 'overseer'},\" +\n        \"    { 'replica': '<2', 'shard': '#ANY', 'node': '#ANY'\" +\n        \"    }\" +\n        \"  ],\" +\n        \"  'policies': {\" +\n        \"    'policy1': [\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'node': '#ANY'},\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'sysprop.rack': 'rack1'}\" +\n        \"    ]\" +\n        \"  }\" +\n        \"}\";\n    AutoScalingConfig config = new AutoScalingConfig((Map<String, Object>) Utils.fromJSONString(autoScaleJson));\n    AtomicInteger count = new AtomicInteger(0);\n    SolrCloudManager cloudManager = new SolrClientCloudManager(new ZkDistributedQueueFactory(cluster.getZkClient()), cluster.getSolrClient());\n    String nodeName = cloudManager.getClusterStateProvider().getLiveNodes().iterator().next();\n    SolrClientNodeStateProvider nodeStateProvider = (SolrClientNodeStateProvider) cloudManager.getNodeStateProvider();\n    Map<String, Map<String, List<ReplicaInfo>>> result = nodeStateProvider.getReplicaInfo(nodeName, Collections.singleton(\"UPDATE./update.requests\"));\n    nodeStateProvider.forEachReplica(nodeName, replicaInfo -> {\n      if (replicaInfo.getVariables().containsKey(\"UPDATE./update.requests\")) count.incrementAndGet();\n    });\n    assertTrue(count.get() > 0);\n\n    Policy.Session session = config.getPolicy().createSession(cloudManager);\n\n    for (Row row : session.getSortedNodes()) {\n      Object val = row.getVal(Suggestion.ConditionType.TOTALDISK.tagName, null);\n      log.info(\"node: {} , totaldisk : {}, freedisk : {}\", row.node, val, row.getVal(\"freedisk\",null));\n      assertTrue(val != null);\n\n    }\n\n    count .set(0);\n    for (Row row : session.getSortedNodes()) {\n      row.collectionVsShardVsReplicas.forEach((c, shardVsReplicas) -> shardVsReplicas.forEach((s, replicaInfos) -> {\n        for (ReplicaInfo replicaInfo : replicaInfos) {\n          if (replicaInfo.getVariables().containsKey(Suggestion.ConditionType.CORE_IDX.tagName)) count.incrementAndGet();\n        }\n      }));\n    }\n    assertTrue(count.get() > 0);\n\n    CollectionAdminRequest.deleteCollection(\"perReplicaDataColl\").process(cluster.getSolrClient());\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8f91616b62c917fffa5286c4ef2d21b10cc56f8e","date":1531726562,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/TestPolicyCloud#testDataProviderPerReplicaDetails().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/TestPolicyCloud#testDataProviderPerReplicaDetails().mjava","sourceNew":"  public void testDataProviderPerReplicaDetails() throws Exception {\n    CollectionAdminRequest.createCollection(\"perReplicaDataColl\", \"conf\", 1, 5)\n        .process(cluster.getSolrClient());\n\n    DocCollection coll = getCollectionState(\"perReplicaDataColl\");\n    String autoScaleJson = \"{\" +\n        \"  'cluster-preferences': [\" +\n        \"    { maximize : freedisk , precision: 50},\" +\n        \"    { minimize : cores, precision: 2}\" +\n        \"  ],\" +\n        \"  'cluster-policy': [\" +\n        \"    { replica : '0' , 'nodeRole': 'overseer'},\" +\n        \"    { 'replica': '<2', 'shard': '#ANY', 'node': '#ANY'\" +\n        \"    }\" +\n        \"  ],\" +\n        \"  'policies': {\" +\n        \"    'policy1': [\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'node': '#ANY'},\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'sysprop.rack': 'rack1'}\" +\n        \"    ]\" +\n        \"  }\" +\n        \"}\";\n    AutoScalingConfig config = new AutoScalingConfig((Map<String, Object>) Utils.fromJSONString(autoScaleJson));\n    AtomicInteger count = new AtomicInteger(0);\n    SolrCloudManager cloudManager = new SolrClientCloudManager(new ZkDistributedQueueFactory(cluster.getZkClient()), cluster.getSolrClient());\n    String nodeName = cloudManager.getClusterStateProvider().getLiveNodes().iterator().next();\n    SolrClientNodeStateProvider nodeStateProvider = (SolrClientNodeStateProvider) cloudManager.getNodeStateProvider();\n    Map<String, Map<String, List<ReplicaInfo>>> result = nodeStateProvider.getReplicaInfo(nodeName, Collections.singleton(\"UPDATE./update.requests\"));\n    nodeStateProvider.forEachReplica(nodeName, replicaInfo -> {\n      if (replicaInfo.getVariables().containsKey(\"UPDATE./update.requests\")) count.incrementAndGet();\n    });\n    assertTrue(count.get() > 0);\n\n    Policy.Session session = config.getPolicy().createSession(cloudManager);\n\n    for (Row row : session.getSortedNodes()) {\n      Object val = row.getVal(Suggestion.ConditionType.TOTALDISK.tagName, null);\n      log.info(\"node: {} , totaldisk : {}, freedisk : {}\", row.node, val, row.getVal(\"freedisk\",null));\n      assertTrue(val != null);\n\n    }\n\n    count .set(0);\n    for (Row row : session.getSortedNodes()) {\n      row.collectionVsShardVsReplicas.forEach((c, shardVsReplicas) -> shardVsReplicas.forEach((s, replicaInfos) -> {\n        for (ReplicaInfo replicaInfo : replicaInfos) {\n          if (replicaInfo.getVariables().containsKey(Suggestion.ConditionType.CORE_IDX.tagName)) count.incrementAndGet();\n        }\n      }));\n    }\n    assertTrue(count.get() > 0);\n\n    CollectionAdminRequest.deleteCollection(\"perReplicaDataColl\").process(cluster.getSolrClient());\n\n  }\n\n","sourceOld":"  public void testDataProviderPerReplicaDetails() throws Exception {\n    CollectionAdminRequest.createCollection(\"perReplicaDataColl\", \"conf\", 1, 5)\n        .process(cluster.getSolrClient());\n\n    DocCollection coll = getCollectionState(\"perReplicaDataColl\");\n    String autoScaleJson = \"{\" +\n        \"  'cluster-preferences': [\" +\n        \"    { maximize : freedisk , precision: 50},\" +\n        \"    { minimize : cores, precision: 2}\" +\n        \"  ],\" +\n        \"  'cluster-policy': [\" +\n        \"    { replica : '0' , 'nodeRole': 'overseer'},\" +\n        \"    { 'replica': '<2', 'shard': '#ANY', 'node': '#ANY'\" +\n        \"    }\" +\n        \"  ],\" +\n        \"  'policies': {\" +\n        \"    'policy1': [\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'node': '#ANY'},\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'sysprop.rack': 'rack1'}\" +\n        \"    ]\" +\n        \"  }\" +\n        \"}\";\n    AutoScalingConfig config = new AutoScalingConfig((Map<String, Object>) Utils.fromJSONString(autoScaleJson));\n    AtomicInteger count = new AtomicInteger(0);\n    SolrCloudManager cloudManager = new SolrClientCloudManager(new ZkDistributedQueueFactory(cluster.getZkClient()), cluster.getSolrClient());\n    String nodeName = cloudManager.getClusterStateProvider().getLiveNodes().iterator().next();\n    SolrClientNodeStateProvider nodeStateProvider = (SolrClientNodeStateProvider) cloudManager.getNodeStateProvider();\n    Map<String, Map<String, List<ReplicaInfo>>> result = nodeStateProvider.getReplicaInfo(nodeName, Collections.singleton(\"UPDATE./update.requests\"));\n    nodeStateProvider.forEachReplica(nodeName, replicaInfo -> {\n      if (replicaInfo.getVariables().containsKey(\"UPDATE./update.requests\")) count.incrementAndGet();\n    });\n    assertTrue(count.get() > 0);\n\n    Policy.Session session = config.getPolicy().createSession(cloudManager);\n\n    count .set(0);\n    for (Row row : session.getSorted()) {\n      row.collectionVsShardVsReplicas.forEach((c, shardVsReplicas) -> shardVsReplicas.forEach((s, replicaInfos) -> {\n        for (ReplicaInfo replicaInfo : replicaInfos) {\n          if (replicaInfo.getVariables().containsKey(Suggestion.ConditionType.CORE_IDX.tagName)) count.incrementAndGet();\n        }\n      }));\n    }\n    assertTrue(count.get() > 0);\n\n    CollectionAdminRequest.deleteCollection(\"perReplicaDataColl\").process(cluster.getSolrClient());\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","date":1531905561,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/TestPolicyCloud#testDataProviderPerReplicaDetails().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/TestPolicyCloud#testDataProviderPerReplicaDetails().mjava","sourceNew":"  public void testDataProviderPerReplicaDetails() throws Exception {\n    CollectionAdminRequest.createCollection(\"perReplicaDataColl\", \"conf\", 1, 5)\n        .process(cluster.getSolrClient());\n\n    DocCollection coll = getCollectionState(\"perReplicaDataColl\");\n    String autoScaleJson = \"{\" +\n        \"  'cluster-preferences': [\" +\n        \"    { maximize : freedisk , precision: 50},\" +\n        \"    { minimize : cores, precision: 2}\" +\n        \"  ],\" +\n        \"  'cluster-policy': [\" +\n        \"    { replica : '0' , 'nodeRole': 'overseer'},\" +\n        \"    { 'replica': '<2', 'shard': '#ANY', 'node': '#ANY'\" +\n        \"    }\" +\n        \"  ],\" +\n        \"  'policies': {\" +\n        \"    'policy1': [\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'node': '#ANY'},\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'sysprop.rack': 'rack1'}\" +\n        \"    ]\" +\n        \"  }\" +\n        \"}\";\n    AutoScalingConfig config = new AutoScalingConfig((Map<String, Object>) Utils.fromJSONString(autoScaleJson));\n    AtomicInteger count = new AtomicInteger(0);\n    SolrCloudManager cloudManager = new SolrClientCloudManager(new ZkDistributedQueueFactory(cluster.getZkClient()), cluster.getSolrClient());\n    String nodeName = cloudManager.getClusterStateProvider().getLiveNodes().iterator().next();\n    SolrClientNodeStateProvider nodeStateProvider = (SolrClientNodeStateProvider) cloudManager.getNodeStateProvider();\n    Map<String, Map<String, List<ReplicaInfo>>> result = nodeStateProvider.getReplicaInfo(nodeName, Collections.singleton(\"UPDATE./update.requests\"));\n    nodeStateProvider.forEachReplica(nodeName, replicaInfo -> {\n      if (replicaInfo.getVariables().containsKey(\"UPDATE./update.requests\")) count.incrementAndGet();\n    });\n    assertTrue(count.get() > 0);\n\n    Policy.Session session = config.getPolicy().createSession(cloudManager);\n\n    for (Row row : session.getSortedNodes()) {\n      Object val = row.getVal(Suggestion.ConditionType.TOTALDISK.tagName, null);\n      log.info(\"node: {} , totaldisk : {}, freedisk : {}\", row.node, val, row.getVal(\"freedisk\",null));\n      assertTrue(val != null);\n\n    }\n\n    count .set(0);\n    for (Row row : session.getSortedNodes()) {\n      row.collectionVsShardVsReplicas.forEach((c, shardVsReplicas) -> shardVsReplicas.forEach((s, replicaInfos) -> {\n        for (ReplicaInfo replicaInfo : replicaInfos) {\n          if (replicaInfo.getVariables().containsKey(Suggestion.ConditionType.CORE_IDX.tagName)) count.incrementAndGet();\n        }\n      }));\n    }\n    assertTrue(count.get() > 0);\n\n    CollectionAdminRequest.deleteCollection(\"perReplicaDataColl\").process(cluster.getSolrClient());\n\n  }\n\n","sourceOld":"  public void testDataProviderPerReplicaDetails() throws Exception {\n    CollectionAdminRequest.createCollection(\"perReplicaDataColl\", \"conf\", 1, 5)\n        .process(cluster.getSolrClient());\n\n    DocCollection coll = getCollectionState(\"perReplicaDataColl\");\n    String autoScaleJson = \"{\" +\n        \"  'cluster-preferences': [\" +\n        \"    { maximize : freedisk , precision: 50},\" +\n        \"    { minimize : cores, precision: 2}\" +\n        \"  ],\" +\n        \"  'cluster-policy': [\" +\n        \"    { replica : '0' , 'nodeRole': 'overseer'},\" +\n        \"    { 'replica': '<2', 'shard': '#ANY', 'node': '#ANY'\" +\n        \"    }\" +\n        \"  ],\" +\n        \"  'policies': {\" +\n        \"    'policy1': [\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'node': '#ANY'},\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'sysprop.rack': 'rack1'}\" +\n        \"    ]\" +\n        \"  }\" +\n        \"}\";\n    AutoScalingConfig config = new AutoScalingConfig((Map<String, Object>) Utils.fromJSONString(autoScaleJson));\n    SolrCloudManager cloudManager = new SolrClientCloudManager(new ZkDistributedQueueFactory(cluster.getZkClient()), cluster.getSolrClient());\n    Policy.Session session = config.getPolicy().createSession(cloudManager);\n\n    AtomicInteger count = new AtomicInteger(0);\n    for (Row row : session.getSorted()) {\n      row.collectionVsShardVsReplicas.forEach((c, shardVsReplicas) -> shardVsReplicas.forEach((s, replicaInfos) -> {\n        for (ReplicaInfo replicaInfo : replicaInfos) {\n          if (replicaInfo.getVariables().containsKey(Suggestion.ConditionType.CORE_IDX.tagName)) count.incrementAndGet();\n        }\n      }));\n    }\n    assertTrue(count.get() > 0);\n\n    CollectionAdminRequest.deleteCollection(\"perReplicaDataColl\").process(cluster.getSolrClient());\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"427edb17549d4bb82462a16eec4ee0533d12d5b7","date":1533006754,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/TestPolicyCloud#testDataProviderPerReplicaDetails().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/TestPolicyCloud#testDataProviderPerReplicaDetails().mjava","sourceNew":"  public void testDataProviderPerReplicaDetails() throws Exception {\n    CollectionAdminRequest.createCollection(\"perReplicaDataColl\", \"conf\", 1, 5)\n        .process(cluster.getSolrClient());\n\n    DocCollection coll = getCollectionState(\"perReplicaDataColl\");\n    String autoScaleJson = \"{\" +\n        \"  'cluster-preferences': [\" +\n        \"    { maximize : freedisk , precision: 50},\" +\n        \"    { minimize : cores, precision: 2}\" +\n        \"  ],\" +\n        \"  'cluster-policy': [\" +\n        \"    { replica : '0' , 'nodeRole': 'overseer'},\" +\n        \"    { 'replica': '<2', 'shard': '#ANY', 'node': '#ANY'\" +\n        \"    }\" +\n        \"  ],\" +\n        \"  'policies': {\" +\n        \"    'policy1': [\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'node': '#ANY'},\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'sysprop.rack': 'rack1'}\" +\n        \"    ]\" +\n        \"  }\" +\n        \"}\";\n    AutoScalingConfig config = new AutoScalingConfig((Map<String, Object>) Utils.fromJSONString(autoScaleJson));\n    AtomicInteger count = new AtomicInteger(0);\n    SolrCloudManager cloudManager = new SolrClientCloudManager(new ZkDistributedQueueFactory(cluster.getZkClient()), cluster.getSolrClient());\n    String nodeName = cloudManager.getClusterStateProvider().getLiveNodes().iterator().next();\n    SolrClientNodeStateProvider nodeStateProvider = (SolrClientNodeStateProvider) cloudManager.getNodeStateProvider();\n    Map<String, Map<String, List<ReplicaInfo>>> result = nodeStateProvider.getReplicaInfo(nodeName, Collections.singleton(\"UPDATE./update.requests\"));\n    nodeStateProvider.forEachReplica(nodeName, replicaInfo -> {\n      if (replicaInfo.getVariables().containsKey(\"UPDATE./update.requests\")) count.incrementAndGet();\n    });\n    assertTrue(count.get() > 0);\n\n    Policy.Session session = config.getPolicy().createSession(cloudManager);\n\n    for (Row row : session.getSortedNodes()) {\n      Object val = row.getVal(Type.TOTALDISK.tagName, null);\n      log.info(\"node: {} , totaldisk : {}, freedisk : {}\", row.node, val, row.getVal(\"freedisk\",null));\n      assertTrue(val != null);\n\n    }\n\n    count .set(0);\n    for (Row row : session.getSortedNodes()) {\n      row.collectionVsShardVsReplicas.forEach((c, shardVsReplicas) -> shardVsReplicas.forEach((s, replicaInfos) -> {\n        for (ReplicaInfo replicaInfo : replicaInfos) {\n          if (replicaInfo.getVariables().containsKey(Type.CORE_IDX.tagName)) count.incrementAndGet();\n        }\n      }));\n    }\n    assertTrue(count.get() > 0);\n\n    CollectionAdminRequest.deleteCollection(\"perReplicaDataColl\").process(cluster.getSolrClient());\n\n  }\n\n","sourceOld":"  public void testDataProviderPerReplicaDetails() throws Exception {\n    CollectionAdminRequest.createCollection(\"perReplicaDataColl\", \"conf\", 1, 5)\n        .process(cluster.getSolrClient());\n\n    DocCollection coll = getCollectionState(\"perReplicaDataColl\");\n    String autoScaleJson = \"{\" +\n        \"  'cluster-preferences': [\" +\n        \"    { maximize : freedisk , precision: 50},\" +\n        \"    { minimize : cores, precision: 2}\" +\n        \"  ],\" +\n        \"  'cluster-policy': [\" +\n        \"    { replica : '0' , 'nodeRole': 'overseer'},\" +\n        \"    { 'replica': '<2', 'shard': '#ANY', 'node': '#ANY'\" +\n        \"    }\" +\n        \"  ],\" +\n        \"  'policies': {\" +\n        \"    'policy1': [\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'node': '#ANY'},\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'sysprop.rack': 'rack1'}\" +\n        \"    ]\" +\n        \"  }\" +\n        \"}\";\n    AutoScalingConfig config = new AutoScalingConfig((Map<String, Object>) Utils.fromJSONString(autoScaleJson));\n    AtomicInteger count = new AtomicInteger(0);\n    SolrCloudManager cloudManager = new SolrClientCloudManager(new ZkDistributedQueueFactory(cluster.getZkClient()), cluster.getSolrClient());\n    String nodeName = cloudManager.getClusterStateProvider().getLiveNodes().iterator().next();\n    SolrClientNodeStateProvider nodeStateProvider = (SolrClientNodeStateProvider) cloudManager.getNodeStateProvider();\n    Map<String, Map<String, List<ReplicaInfo>>> result = nodeStateProvider.getReplicaInfo(nodeName, Collections.singleton(\"UPDATE./update.requests\"));\n    nodeStateProvider.forEachReplica(nodeName, replicaInfo -> {\n      if (replicaInfo.getVariables().containsKey(\"UPDATE./update.requests\")) count.incrementAndGet();\n    });\n    assertTrue(count.get() > 0);\n\n    Policy.Session session = config.getPolicy().createSession(cloudManager);\n\n    for (Row row : session.getSortedNodes()) {\n      Object val = row.getVal(Suggestion.ConditionType.TOTALDISK.tagName, null);\n      log.info(\"node: {} , totaldisk : {}, freedisk : {}\", row.node, val, row.getVal(\"freedisk\",null));\n      assertTrue(val != null);\n\n    }\n\n    count .set(0);\n    for (Row row : session.getSortedNodes()) {\n      row.collectionVsShardVsReplicas.forEach((c, shardVsReplicas) -> shardVsReplicas.forEach((s, replicaInfos) -> {\n        for (ReplicaInfo replicaInfo : replicaInfos) {\n          if (replicaInfo.getVariables().containsKey(Suggestion.ConditionType.CORE_IDX.tagName)) count.incrementAndGet();\n        }\n      }));\n    }\n    assertTrue(count.get() > 0);\n\n    CollectionAdminRequest.deleteCollection(\"perReplicaDataColl\").process(cluster.getSolrClient());\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bb222a3f9d9421d5c95afce73013fbd8de07ea1f","date":1543514331,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/TestPolicyCloud#testDataProviderPerReplicaDetails().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/TestPolicyCloud#testDataProviderPerReplicaDetails().mjava","sourceNew":"  public void testDataProviderPerReplicaDetails() throws Exception {\n    CollectionAdminRequest.createCollection(\"perReplicaDataColl\", \"conf\", 1, 5)\n        .process(cluster.getSolrClient());\n    cluster.waitForActiveCollection(\"perReplicaDataColl\", 1, 5);\n    DocCollection coll = getCollectionState(\"perReplicaDataColl\");\n    String autoScaleJson = \"{\" +\n        \"  'cluster-preferences': [\" +\n        \"    { maximize : freedisk , precision: 50},\" +\n        \"    { minimize : cores, precision: 2}\" +\n        \"  ],\" +\n        \"  'cluster-policy': [\" +\n        \"    { replica : '0' , 'nodeRole': 'overseer'},\" +\n        \"    { 'replica': '<2', 'shard': '#ANY', 'node': '#ANY'\" +\n        \"    }\" +\n        \"  ],\" +\n        \"  'policies': {\" +\n        \"    'policy1': [\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'node': '#ANY'},\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'sysprop.rack': 'rack1'}\" +\n        \"    ]\" +\n        \"  }\" +\n        \"}\";\n    AutoScalingConfig config = new AutoScalingConfig((Map<String, Object>) Utils.fromJSONString(autoScaleJson));\n    AtomicInteger count = new AtomicInteger(0);\n    SolrCloudManager cloudManager = new SolrClientCloudManager(new ZkDistributedQueueFactory(cluster.getZkClient()), cluster.getSolrClient());\n    String nodeName = cloudManager.getClusterStateProvider().getLiveNodes().iterator().next();\n    SolrClientNodeStateProvider nodeStateProvider = (SolrClientNodeStateProvider) cloudManager.getNodeStateProvider();\n    Map<String, Map<String, List<ReplicaInfo>>> result = nodeStateProvider.getReplicaInfo(nodeName, Collections.singleton(\"UPDATE./update.requests\"));\n    nodeStateProvider.forEachReplica(nodeName, replicaInfo -> {\n      if (replicaInfo.getVariables().containsKey(\"UPDATE./update.requests\")) count.incrementAndGet();\n    });\n    assertTrue(count.get() > 0);\n\n    Policy.Session session = config.getPolicy().createSession(cloudManager);\n\n    for (Row row : session.getSortedNodes()) {\n      Object val = row.getVal(Type.TOTALDISK.tagName, null);\n      log.info(\"node: {} , totaldisk : {}, freedisk : {}\", row.node, val, row.getVal(\"freedisk\",null));\n      assertTrue(val != null);\n\n    }\n\n    count .set(0);\n    for (Row row : session.getSortedNodes()) {\n      row.collectionVsShardVsReplicas.forEach((c, shardVsReplicas) -> shardVsReplicas.forEach((s, replicaInfos) -> {\n        for (ReplicaInfo replicaInfo : replicaInfos) {\n          if (replicaInfo.getVariables().containsKey(Type.CORE_IDX.tagName)) count.incrementAndGet();\n        }\n      }));\n    }\n    assertTrue(count.get() > 0);\n\n    CollectionAdminRequest.deleteCollection(\"perReplicaDataColl\").process(cluster.getSolrClient());\n\n  }\n\n","sourceOld":"  public void testDataProviderPerReplicaDetails() throws Exception {\n    CollectionAdminRequest.createCollection(\"perReplicaDataColl\", \"conf\", 1, 5)\n        .process(cluster.getSolrClient());\n\n    DocCollection coll = getCollectionState(\"perReplicaDataColl\");\n    String autoScaleJson = \"{\" +\n        \"  'cluster-preferences': [\" +\n        \"    { maximize : freedisk , precision: 50},\" +\n        \"    { minimize : cores, precision: 2}\" +\n        \"  ],\" +\n        \"  'cluster-policy': [\" +\n        \"    { replica : '0' , 'nodeRole': 'overseer'},\" +\n        \"    { 'replica': '<2', 'shard': '#ANY', 'node': '#ANY'\" +\n        \"    }\" +\n        \"  ],\" +\n        \"  'policies': {\" +\n        \"    'policy1': [\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'node': '#ANY'},\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'sysprop.rack': 'rack1'}\" +\n        \"    ]\" +\n        \"  }\" +\n        \"}\";\n    AutoScalingConfig config = new AutoScalingConfig((Map<String, Object>) Utils.fromJSONString(autoScaleJson));\n    AtomicInteger count = new AtomicInteger(0);\n    SolrCloudManager cloudManager = new SolrClientCloudManager(new ZkDistributedQueueFactory(cluster.getZkClient()), cluster.getSolrClient());\n    String nodeName = cloudManager.getClusterStateProvider().getLiveNodes().iterator().next();\n    SolrClientNodeStateProvider nodeStateProvider = (SolrClientNodeStateProvider) cloudManager.getNodeStateProvider();\n    Map<String, Map<String, List<ReplicaInfo>>> result = nodeStateProvider.getReplicaInfo(nodeName, Collections.singleton(\"UPDATE./update.requests\"));\n    nodeStateProvider.forEachReplica(nodeName, replicaInfo -> {\n      if (replicaInfo.getVariables().containsKey(\"UPDATE./update.requests\")) count.incrementAndGet();\n    });\n    assertTrue(count.get() > 0);\n\n    Policy.Session session = config.getPolicy().createSession(cloudManager);\n\n    for (Row row : session.getSortedNodes()) {\n      Object val = row.getVal(Type.TOTALDISK.tagName, null);\n      log.info(\"node: {} , totaldisk : {}, freedisk : {}\", row.node, val, row.getVal(\"freedisk\",null));\n      assertTrue(val != null);\n\n    }\n\n    count .set(0);\n    for (Row row : session.getSortedNodes()) {\n      row.collectionVsShardVsReplicas.forEach((c, shardVsReplicas) -> shardVsReplicas.forEach((s, replicaInfos) -> {\n        for (ReplicaInfo replicaInfo : replicaInfos) {\n          if (replicaInfo.getVariables().containsKey(Type.CORE_IDX.tagName)) count.incrementAndGet();\n        }\n      }));\n    }\n    assertTrue(count.get() > 0);\n\n    CollectionAdminRequest.deleteCollection(\"perReplicaDataColl\").process(cluster.getSolrClient());\n\n  }\n\n","bugFix":["1bbcda32e5cd37ef61ea1190bacd080308e22070"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f6ae69e36b15b227a219d4e334ccf5f58fb8affd","date":1562804219,"type":3,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/TestPolicyCloud#testDataProviderPerReplicaDetails().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/TestPolicyCloud#testDataProviderPerReplicaDetails().mjava","sourceNew":"  public void testDataProviderPerReplicaDetails() throws Exception {\n    CollectionAdminRequest.createCollection(\"perReplicaDataColl\", \"conf\", 1, 5)\n        .process(cluster.getSolrClient());\n    cluster.waitForActiveCollection(\"perReplicaDataColl\", 1, 5);\n    DocCollection coll = getCollectionState(\"perReplicaDataColl\");\n    String autoScaleJson = \"{\" +\n        \"  'cluster-preferences': [\" +\n        \"    { maximize : freedisk , precision: 50},\" +\n        \"    { minimize : cores, precision: 2}\" +\n        \"  ],\" +\n        \"  'cluster-policy': [\" +\n        \"    { replica : '0' , 'nodeRole': 'overseer'},\" +\n        \"    { 'replica': '<2', 'shard': '#ANY', 'node': '#ANY'\" +\n        \"    }\" +\n        \"  ],\" +\n        \"  'policies': {\" +\n        \"    'policy1': [\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'node': '#ANY'},\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'sysprop.rack': 'rack1'}\" +\n        \"    ]\" +\n        \"  }\" +\n        \"}\";\n    AutoScalingConfig config = new AutoScalingConfig((Map<String, Object>) Utils.fromJSONString(autoScaleJson));\n    AtomicInteger count = new AtomicInteger(0);\n    SolrCloudManager cloudManager = new SolrClientCloudManager(new ZkDistributedQueueFactory(cluster.getZkClient()), cluster.getSolrClient());\n    String nodeName = cloudManager.getClusterStateProvider().getLiveNodes().iterator().next();\n    SolrClientNodeStateProvider nodeStateProvider = (SolrClientNodeStateProvider) cloudManager.getNodeStateProvider();\n    Map<String, Map<String, List<ReplicaInfo>>> result = nodeStateProvider.getReplicaInfo(nodeName, Collections.singleton(\"UPDATE./update.requests\"));\n    nodeStateProvider.forEachReplica(nodeName, replicaInfo -> {\n      if (replicaInfo.getVariables().containsKey(\"UPDATE./update.requests\")) count.incrementAndGet();\n    });\n    assertTrue(count.get() > 0);\n\n    Policy.Session session = config.getPolicy().createSession(cloudManager);\n\n    for (Row row : session.getSortedNodes()) {\n      Object val = row.getVal(Type.TOTALDISK.tagName, null);\n      log.info(\"node: {} , totaldisk : {}, freedisk : {}\", row.node, val, row.getVal(\"freedisk\",null));\n      assertTrue(val != null);\n\n    }\n\n    count .set(0);\n    for (Row row : session.getSortedNodes()) {\n      row.collectionVsShardVsReplicas.forEach((c, shardVsReplicas) -> shardVsReplicas.forEach((s, replicaInfos) -> {\n        for (ReplicaInfo replicaInfo : replicaInfos) {\n          if (replicaInfo.getVariables().containsKey(Type.CORE_IDX.tagName)) count.incrementAndGet();\n        }\n      }));\n    }\n    assertTrue(count.get() > 0);\n\n  }\n\n","sourceOld":"  public void testDataProviderPerReplicaDetails() throws Exception {\n    CollectionAdminRequest.createCollection(\"perReplicaDataColl\", \"conf\", 1, 5)\n        .process(cluster.getSolrClient());\n    cluster.waitForActiveCollection(\"perReplicaDataColl\", 1, 5);\n    DocCollection coll = getCollectionState(\"perReplicaDataColl\");\n    String autoScaleJson = \"{\" +\n        \"  'cluster-preferences': [\" +\n        \"    { maximize : freedisk , precision: 50},\" +\n        \"    { minimize : cores, precision: 2}\" +\n        \"  ],\" +\n        \"  'cluster-policy': [\" +\n        \"    { replica : '0' , 'nodeRole': 'overseer'},\" +\n        \"    { 'replica': '<2', 'shard': '#ANY', 'node': '#ANY'\" +\n        \"    }\" +\n        \"  ],\" +\n        \"  'policies': {\" +\n        \"    'policy1': [\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'node': '#ANY'},\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'sysprop.rack': 'rack1'}\" +\n        \"    ]\" +\n        \"  }\" +\n        \"}\";\n    AutoScalingConfig config = new AutoScalingConfig((Map<String, Object>) Utils.fromJSONString(autoScaleJson));\n    AtomicInteger count = new AtomicInteger(0);\n    SolrCloudManager cloudManager = new SolrClientCloudManager(new ZkDistributedQueueFactory(cluster.getZkClient()), cluster.getSolrClient());\n    String nodeName = cloudManager.getClusterStateProvider().getLiveNodes().iterator().next();\n    SolrClientNodeStateProvider nodeStateProvider = (SolrClientNodeStateProvider) cloudManager.getNodeStateProvider();\n    Map<String, Map<String, List<ReplicaInfo>>> result = nodeStateProvider.getReplicaInfo(nodeName, Collections.singleton(\"UPDATE./update.requests\"));\n    nodeStateProvider.forEachReplica(nodeName, replicaInfo -> {\n      if (replicaInfo.getVariables().containsKey(\"UPDATE./update.requests\")) count.incrementAndGet();\n    });\n    assertTrue(count.get() > 0);\n\n    Policy.Session session = config.getPolicy().createSession(cloudManager);\n\n    for (Row row : session.getSortedNodes()) {\n      Object val = row.getVal(Type.TOTALDISK.tagName, null);\n      log.info(\"node: {} , totaldisk : {}, freedisk : {}\", row.node, val, row.getVal(\"freedisk\",null));\n      assertTrue(val != null);\n\n    }\n\n    count .set(0);\n    for (Row row : session.getSortedNodes()) {\n      row.collectionVsShardVsReplicas.forEach((c, shardVsReplicas) -> shardVsReplicas.forEach((s, replicaInfos) -> {\n        for (ReplicaInfo replicaInfo : replicaInfos) {\n          if (replicaInfo.getVariables().containsKey(Type.CORE_IDX.tagName)) count.incrementAndGet();\n        }\n      }));\n    }\n    assertTrue(count.get() > 0);\n\n    CollectionAdminRequest.deleteCollection(\"perReplicaDataColl\").process(cluster.getSolrClient());\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0db34e17d2075ee456deda8012ce5ec6e0bdcd19","date":1583264540,"type":3,"author":"Tomas Fernandez Lobbe","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/TestPolicyCloud#testDataProviderPerReplicaDetails().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/TestPolicyCloud#testDataProviderPerReplicaDetails().mjava","sourceNew":"  public void testDataProviderPerReplicaDetails() throws Exception {\n    CollectionAdminRequest.createCollection(\"perReplicaDataColl\", \"conf\", 1, 5)\n        .process(cluster.getSolrClient());\n    cluster.waitForActiveCollection(\"perReplicaDataColl\", 1, 5);\n    DocCollection coll = getCollectionState(\"perReplicaDataColl\");\n    String autoScaleJson = \"{\" +\n        \"  'cluster-preferences': [\" +\n        \"    { maximize : freedisk , precision: 50},\" +\n        \"    { minimize : cores, precision: 2}\" +\n        \"  ],\" +\n        \"  'cluster-policy': [\" +\n        \"    { replica : '0' , 'nodeRole': 'overseer'},\" +\n        \"    { 'replica': '<2', 'shard': '#ANY', 'node': '#ANY'\" +\n        \"    }\" +\n        \"  ],\" +\n        \"  'policies': {\" +\n        \"    'policy1': [\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'node': '#ANY'},\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'sysprop.rack': 'rack1'}\" +\n        \"    ]\" +\n        \"  }\" +\n        \"}\";\n    AutoScalingConfig config = new AutoScalingConfig((Map<String, Object>) Utils.fromJSONString(autoScaleJson));\n    AtomicInteger count = new AtomicInteger(0);\n    try (SolrCloudManager cloudManager = new SolrClientCloudManager(new ZkDistributedQueueFactory(cluster.getZkClient()), cluster.getSolrClient())) {\n      String nodeName = cloudManager.getClusterStateProvider().getLiveNodes().iterator().next();\n      SolrClientNodeStateProvider nodeStateProvider = (SolrClientNodeStateProvider) cloudManager.getNodeStateProvider();\n      Map<String, Map<String, List<ReplicaInfo>>> result = nodeStateProvider.getReplicaInfo(nodeName, Collections.singleton(\"UPDATE./update.requests\"));\n      nodeStateProvider.forEachReplica(nodeName, replicaInfo -> {\n        if (replicaInfo.getVariables().containsKey(\"UPDATE./update.requests\")) count.incrementAndGet();\n      });\n      assertTrue(count.get() > 0);\n\n      Policy.Session session = config.getPolicy().createSession(cloudManager);\n\n      for (Row row : session.getSortedNodes()) {\n        Object val = row.getVal(Type.TOTALDISK.tagName, null);\n        log.info(\"node: {} , totaldisk : {}, freedisk : {}\", row.node, val, row.getVal(\"freedisk\",null));\n        assertTrue(val != null);\n\n      }\n\n      count .set(0);\n      for (Row row : session.getSortedNodes()) {\n        row.collectionVsShardVsReplicas.forEach((c, shardVsReplicas) -> shardVsReplicas.forEach((s, replicaInfos) -> {\n          for (ReplicaInfo replicaInfo : replicaInfos) {\n            if (replicaInfo.getVariables().containsKey(Type.CORE_IDX.tagName)) count.incrementAndGet();\n          }\n        }));\n      }\n      assertTrue(count.get() > 0);\n    }\n  }\n\n","sourceOld":"  public void testDataProviderPerReplicaDetails() throws Exception {\n    CollectionAdminRequest.createCollection(\"perReplicaDataColl\", \"conf\", 1, 5)\n        .process(cluster.getSolrClient());\n    cluster.waitForActiveCollection(\"perReplicaDataColl\", 1, 5);\n    DocCollection coll = getCollectionState(\"perReplicaDataColl\");\n    String autoScaleJson = \"{\" +\n        \"  'cluster-preferences': [\" +\n        \"    { maximize : freedisk , precision: 50},\" +\n        \"    { minimize : cores, precision: 2}\" +\n        \"  ],\" +\n        \"  'cluster-policy': [\" +\n        \"    { replica : '0' , 'nodeRole': 'overseer'},\" +\n        \"    { 'replica': '<2', 'shard': '#ANY', 'node': '#ANY'\" +\n        \"    }\" +\n        \"  ],\" +\n        \"  'policies': {\" +\n        \"    'policy1': [\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'node': '#ANY'},\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'sysprop.rack': 'rack1'}\" +\n        \"    ]\" +\n        \"  }\" +\n        \"}\";\n    AutoScalingConfig config = new AutoScalingConfig((Map<String, Object>) Utils.fromJSONString(autoScaleJson));\n    AtomicInteger count = new AtomicInteger(0);\n    SolrCloudManager cloudManager = new SolrClientCloudManager(new ZkDistributedQueueFactory(cluster.getZkClient()), cluster.getSolrClient());\n    String nodeName = cloudManager.getClusterStateProvider().getLiveNodes().iterator().next();\n    SolrClientNodeStateProvider nodeStateProvider = (SolrClientNodeStateProvider) cloudManager.getNodeStateProvider();\n    Map<String, Map<String, List<ReplicaInfo>>> result = nodeStateProvider.getReplicaInfo(nodeName, Collections.singleton(\"UPDATE./update.requests\"));\n    nodeStateProvider.forEachReplica(nodeName, replicaInfo -> {\n      if (replicaInfo.getVariables().containsKey(\"UPDATE./update.requests\")) count.incrementAndGet();\n    });\n    assertTrue(count.get() > 0);\n\n    Policy.Session session = config.getPolicy().createSession(cloudManager);\n\n    for (Row row : session.getSortedNodes()) {\n      Object val = row.getVal(Type.TOTALDISK.tagName, null);\n      log.info(\"node: {} , totaldisk : {}, freedisk : {}\", row.node, val, row.getVal(\"freedisk\",null));\n      assertTrue(val != null);\n\n    }\n\n    count .set(0);\n    for (Row row : session.getSortedNodes()) {\n      row.collectionVsShardVsReplicas.forEach((c, shardVsReplicas) -> shardVsReplicas.forEach((s, replicaInfos) -> {\n        for (ReplicaInfo replicaInfo : replicaInfos) {\n          if (replicaInfo.getVariables().containsKey(Type.CORE_IDX.tagName)) count.incrementAndGet();\n        }\n      }));\n    }\n    assertTrue(count.get() > 0);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fe9f2c4a0d7ac164e4bdd4eee7f87131aec83fd4","date":1588172214,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/TestPolicyCloud#testDataProviderPerReplicaDetails().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/TestPolicyCloud#testDataProviderPerReplicaDetails().mjava","sourceNew":"  public void testDataProviderPerReplicaDetails() throws Exception {\n    CollectionAdminRequest.createCollection(\"perReplicaDataColl\", \"conf\", 1, 5)\n        .process(cluster.getSolrClient());\n    cluster.waitForActiveCollection(\"perReplicaDataColl\", 1, 5);\n    DocCollection coll = getCollectionState(\"perReplicaDataColl\");\n    String autoScaleJson = \"{\" +\n        \"  'cluster-preferences': [\" +\n        \"    { maximize : freedisk , precision: 50},\" +\n        \"    { minimize : cores, precision: 2}\" +\n        \"  ],\" +\n        \"  'cluster-policy': [\" +\n        \"    { replica : '0' , 'nodeRole': 'overseer'},\" +\n        \"    { 'replica': '<2', 'shard': '#ANY', 'node': '#ANY'\" +\n        \"    }\" +\n        \"  ],\" +\n        \"  'policies': {\" +\n        \"    'policy1': [\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'node': '#ANY'},\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'sysprop.rack': 'rack1'}\" +\n        \"    ]\" +\n        \"  }\" +\n        \"}\";\n    AutoScalingConfig config = new AutoScalingConfig((Map<String, Object>) Utils.fromJSONString(autoScaleJson));\n    AtomicInteger count = new AtomicInteger(0);\n    try (SolrCloudManager cloudManager = new SolrClientCloudManager(new ZkDistributedQueueFactory(cluster.getZkClient()), cluster.getSolrClient())) {\n      String nodeName = cloudManager.getClusterStateProvider().getLiveNodes().iterator().next();\n      SolrClientNodeStateProvider nodeStateProvider = (SolrClientNodeStateProvider) cloudManager.getNodeStateProvider();\n      Map<String, Map<String, List<ReplicaInfo>>> result = nodeStateProvider.getReplicaInfo(nodeName, Collections.singleton(\"UPDATE./update.requests\"));\n      nodeStateProvider.forEachReplica(nodeName, replicaInfo -> {\n        if (replicaInfo.getVariables().containsKey(\"UPDATE./update.requests\")) count.incrementAndGet();\n      });\n      assertTrue(count.get() > 0);\n\n      Policy.Session session = config.getPolicy().createSession(cloudManager);\n\n      for (Row row : session.getSortedNodes()) {\n        Object val = row.getVal(Type.TOTALDISK.tagName, null);\n        if (log.isInfoEnabled()) {\n          log.info(\"node: {} , totaldisk : {}, freedisk : {}\", row.node, val, row.getVal(\"freedisk\", null));\n        }\n        assertTrue(val != null);\n\n      }\n\n      count .set(0);\n      for (Row row : session.getSortedNodes()) {\n        row.collectionVsShardVsReplicas.forEach((c, shardVsReplicas) -> shardVsReplicas.forEach((s, replicaInfos) -> {\n          for (ReplicaInfo replicaInfo : replicaInfos) {\n            if (replicaInfo.getVariables().containsKey(Type.CORE_IDX.tagName)) count.incrementAndGet();\n          }\n        }));\n      }\n      assertTrue(count.get() > 0);\n    }\n  }\n\n","sourceOld":"  public void testDataProviderPerReplicaDetails() throws Exception {\n    CollectionAdminRequest.createCollection(\"perReplicaDataColl\", \"conf\", 1, 5)\n        .process(cluster.getSolrClient());\n    cluster.waitForActiveCollection(\"perReplicaDataColl\", 1, 5);\n    DocCollection coll = getCollectionState(\"perReplicaDataColl\");\n    String autoScaleJson = \"{\" +\n        \"  'cluster-preferences': [\" +\n        \"    { maximize : freedisk , precision: 50},\" +\n        \"    { minimize : cores, precision: 2}\" +\n        \"  ],\" +\n        \"  'cluster-policy': [\" +\n        \"    { replica : '0' , 'nodeRole': 'overseer'},\" +\n        \"    { 'replica': '<2', 'shard': '#ANY', 'node': '#ANY'\" +\n        \"    }\" +\n        \"  ],\" +\n        \"  'policies': {\" +\n        \"    'policy1': [\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'node': '#ANY'},\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'sysprop.rack': 'rack1'}\" +\n        \"    ]\" +\n        \"  }\" +\n        \"}\";\n    AutoScalingConfig config = new AutoScalingConfig((Map<String, Object>) Utils.fromJSONString(autoScaleJson));\n    AtomicInteger count = new AtomicInteger(0);\n    try (SolrCloudManager cloudManager = new SolrClientCloudManager(new ZkDistributedQueueFactory(cluster.getZkClient()), cluster.getSolrClient())) {\n      String nodeName = cloudManager.getClusterStateProvider().getLiveNodes().iterator().next();\n      SolrClientNodeStateProvider nodeStateProvider = (SolrClientNodeStateProvider) cloudManager.getNodeStateProvider();\n      Map<String, Map<String, List<ReplicaInfo>>> result = nodeStateProvider.getReplicaInfo(nodeName, Collections.singleton(\"UPDATE./update.requests\"));\n      nodeStateProvider.forEachReplica(nodeName, replicaInfo -> {\n        if (replicaInfo.getVariables().containsKey(\"UPDATE./update.requests\")) count.incrementAndGet();\n      });\n      assertTrue(count.get() > 0);\n\n      Policy.Session session = config.getPolicy().createSession(cloudManager);\n\n      for (Row row : session.getSortedNodes()) {\n        Object val = row.getVal(Type.TOTALDISK.tagName, null);\n        log.info(\"node: {} , totaldisk : {}, freedisk : {}\", row.node, val, row.getVal(\"freedisk\",null));\n        assertTrue(val != null);\n\n      }\n\n      count .set(0);\n      for (Row row : session.getSortedNodes()) {\n        row.collectionVsShardVsReplicas.forEach((c, shardVsReplicas) -> shardVsReplicas.forEach((s, replicaInfos) -> {\n          for (ReplicaInfo replicaInfo : replicaInfos) {\n            if (replicaInfo.getVariables().containsKey(Type.CORE_IDX.tagName)) count.incrementAndGet();\n          }\n        }));\n      }\n      assertTrue(count.get() > 0);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"aa2585c33d5d66a1c837c312221eb55ddb3c4300","date":1592493170,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/TestPolicyCloud#testDataProviderPerReplicaDetails().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/TestPolicyCloud#testDataProviderPerReplicaDetails().mjava","sourceNew":"  public void testDataProviderPerReplicaDetails() throws Exception {\n    CollectionAdminRequest.createCollection(\"perReplicaDataColl\", \"conf\", 1, 5)\n        .process(cluster.getSolrClient());\n    cluster.waitForActiveCollection(\"perReplicaDataColl\", 1, 5);\n    DocCollection coll = getCollectionState(\"perReplicaDataColl\");\n    String autoScaleJson = \"{\" +\n        \"  'cluster-preferences': [\" +\n        \"    { maximize : freedisk , precision: 50},\" +\n        \"    { minimize : cores, precision: 2}\" +\n        \"  ],\" +\n        \"  'cluster-policy': [\" +\n        \"    { replica : '0' , 'nodeRole': 'overseer'},\" +\n        \"    { 'replica': '<2', 'shard': '#ANY', 'node': '#ANY'\" +\n        \"    }\" +\n        \"  ],\" +\n        \"  'policies': {\" +\n        \"    'policy1': [\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'node': '#ANY'},\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'sysprop.rack': 'rack1'}\" +\n        \"    ]\" +\n        \"  }\" +\n        \"}\";\n    @SuppressWarnings({\"unchecked\"})\n    AutoScalingConfig config = new AutoScalingConfig((Map<String, Object>) Utils.fromJSONString(autoScaleJson));\n    AtomicInteger count = new AtomicInteger(0);\n    try (SolrCloudManager cloudManager = new SolrClientCloudManager(new ZkDistributedQueueFactory(cluster.getZkClient()), cluster.getSolrClient())) {\n      String nodeName = cloudManager.getClusterStateProvider().getLiveNodes().iterator().next();\n      SolrClientNodeStateProvider nodeStateProvider = (SolrClientNodeStateProvider) cloudManager.getNodeStateProvider();\n      Map<String, Map<String, List<ReplicaInfo>>> result = nodeStateProvider.getReplicaInfo(nodeName, Collections.singleton(\"UPDATE./update.requests\"));\n      nodeStateProvider.forEachReplica(nodeName, replicaInfo -> {\n        if (replicaInfo.getVariables().containsKey(\"UPDATE./update.requests\")) count.incrementAndGet();\n      });\n      assertTrue(count.get() > 0);\n\n      Policy.Session session = config.getPolicy().createSession(cloudManager);\n\n      for (Row row : session.getSortedNodes()) {\n        Object val = row.getVal(Type.TOTALDISK.tagName, null);\n        if (log.isInfoEnabled()) {\n          log.info(\"node: {} , totaldisk : {}, freedisk : {}\", row.node, val, row.getVal(\"freedisk\", null));\n        }\n        assertTrue(val != null);\n\n      }\n\n      count .set(0);\n      for (Row row : session.getSortedNodes()) {\n        row.collectionVsShardVsReplicas.forEach((c, shardVsReplicas) -> shardVsReplicas.forEach((s, replicaInfos) -> {\n          for (ReplicaInfo replicaInfo : replicaInfos) {\n            if (replicaInfo.getVariables().containsKey(Type.CORE_IDX.tagName)) count.incrementAndGet();\n          }\n        }));\n      }\n      assertTrue(count.get() > 0);\n    }\n  }\n\n","sourceOld":"  public void testDataProviderPerReplicaDetails() throws Exception {\n    CollectionAdminRequest.createCollection(\"perReplicaDataColl\", \"conf\", 1, 5)\n        .process(cluster.getSolrClient());\n    cluster.waitForActiveCollection(\"perReplicaDataColl\", 1, 5);\n    DocCollection coll = getCollectionState(\"perReplicaDataColl\");\n    String autoScaleJson = \"{\" +\n        \"  'cluster-preferences': [\" +\n        \"    { maximize : freedisk , precision: 50},\" +\n        \"    { minimize : cores, precision: 2}\" +\n        \"  ],\" +\n        \"  'cluster-policy': [\" +\n        \"    { replica : '0' , 'nodeRole': 'overseer'},\" +\n        \"    { 'replica': '<2', 'shard': '#ANY', 'node': '#ANY'\" +\n        \"    }\" +\n        \"  ],\" +\n        \"  'policies': {\" +\n        \"    'policy1': [\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'node': '#ANY'},\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'sysprop.rack': 'rack1'}\" +\n        \"    ]\" +\n        \"  }\" +\n        \"}\";\n    AutoScalingConfig config = new AutoScalingConfig((Map<String, Object>) Utils.fromJSONString(autoScaleJson));\n    AtomicInteger count = new AtomicInteger(0);\n    try (SolrCloudManager cloudManager = new SolrClientCloudManager(new ZkDistributedQueueFactory(cluster.getZkClient()), cluster.getSolrClient())) {\n      String nodeName = cloudManager.getClusterStateProvider().getLiveNodes().iterator().next();\n      SolrClientNodeStateProvider nodeStateProvider = (SolrClientNodeStateProvider) cloudManager.getNodeStateProvider();\n      Map<String, Map<String, List<ReplicaInfo>>> result = nodeStateProvider.getReplicaInfo(nodeName, Collections.singleton(\"UPDATE./update.requests\"));\n      nodeStateProvider.forEachReplica(nodeName, replicaInfo -> {\n        if (replicaInfo.getVariables().containsKey(\"UPDATE./update.requests\")) count.incrementAndGet();\n      });\n      assertTrue(count.get() > 0);\n\n      Policy.Session session = config.getPolicy().createSession(cloudManager);\n\n      for (Row row : session.getSortedNodes()) {\n        Object val = row.getVal(Type.TOTALDISK.tagName, null);\n        if (log.isInfoEnabled()) {\n          log.info(\"node: {} , totaldisk : {}, freedisk : {}\", row.node, val, row.getVal(\"freedisk\", null));\n        }\n        assertTrue(val != null);\n\n      }\n\n      count .set(0);\n      for (Row row : session.getSortedNodes()) {\n        row.collectionVsShardVsReplicas.forEach((c, shardVsReplicas) -> shardVsReplicas.forEach((s, replicaInfos) -> {\n          for (ReplicaInfo replicaInfo : replicaInfos) {\n            if (replicaInfo.getVariables().containsKey(Type.CORE_IDX.tagName)) count.incrementAndGet();\n          }\n        }));\n      }\n      assertTrue(count.get() > 0);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7e8ce2f9d2ddfcf5cfa7e73b8b2af287a2a276fd","date":1594731683,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/TestPolicyCloud#testDataProviderPerReplicaDetails().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/TestPolicyCloud#testDataProviderPerReplicaDetails().mjava","sourceNew":"  public void testDataProviderPerReplicaDetails() throws Exception {\n    CollectionAdminRequest.createCollection(\"perReplicaDataColl\", \"conf\", 1, 5)\n        .process(cluster.getSolrClient());\n    cluster.waitForActiveCollection(\"perReplicaDataColl\", 1, 5);\n    DocCollection coll = getCollectionState(\"perReplicaDataColl\");\n    String autoScaleJson = \"{\" +\n        \"  'cluster-preferences': [\" +\n        \"    { maximize : freedisk , precision: 50},\" +\n        \"    { minimize : cores, precision: 2}\" +\n        \"  ],\" +\n        \"  'cluster-policy': [\" +\n        \"    { replica : '0' , 'nodeRole': 'overseer'},\" +\n        \"    { 'replica': '<2', 'shard': '#ANY', 'node': '#ANY'\" +\n        \"    }\" +\n        \"  ],\" +\n        \"  'policies': {\" +\n        \"    'policy1': [\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'node': '#ANY'},\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'sysprop.rack': 'rack1'}\" +\n        \"    ]\" +\n        \"  }\" +\n        \"}\";\n    @SuppressWarnings({\"unchecked\"})\n    AutoScalingConfig config = new AutoScalingConfig((Map<String, Object>) Utils.fromJSONString(autoScaleJson));\n    AtomicInteger count = new AtomicInteger(0);\n    try (SolrCloudManager cloudManager = new SolrClientCloudManager(new ZkDistributedQueueFactory(cluster.getZkClient()), cluster.getSolrClient())) {\n      String nodeName = cloudManager.getClusterStateProvider().getLiveNodes().iterator().next();\n      SolrClientNodeStateProvider nodeStateProvider = (SolrClientNodeStateProvider) cloudManager.getNodeStateProvider();\n      Map<String, Map<String, List<Replica>>> result = nodeStateProvider.getReplicaInfo(nodeName, Collections.singleton(\"UPDATE./update.requests\"));\n      nodeStateProvider.forEachReplica(nodeName, replicaInfo -> {\n        if (replicaInfo.getProperties().containsKey(\"UPDATE./update.requests\")) count.incrementAndGet();\n      });\n      assertTrue(count.get() > 0);\n\n      Policy.Session session = config.getPolicy().createSession(cloudManager);\n\n      for (Row row : session.getSortedNodes()) {\n        Object val = row.getVal(Type.TOTALDISK.tagName, null);\n        if (log.isInfoEnabled()) {\n          log.info(\"node: {} , totaldisk : {}, freedisk : {}\", row.node, val, row.getVal(\"freedisk\", null));\n        }\n        assertTrue(val != null);\n\n      }\n\n      count .set(0);\n      for (Row row : session.getSortedNodes()) {\n        row.collectionVsShardVsReplicas.forEach((c, shardVsReplicas) -> shardVsReplicas.forEach((s, replicaInfos) -> {\n          for (Replica replicaInfo : replicaInfos) {\n            if (replicaInfo.getProperties().containsKey(Type.CORE_IDX.tagName)) count.incrementAndGet();\n          }\n        }));\n      }\n      assertTrue(count.get() > 0);\n    }\n  }\n\n","sourceOld":"  public void testDataProviderPerReplicaDetails() throws Exception {\n    CollectionAdminRequest.createCollection(\"perReplicaDataColl\", \"conf\", 1, 5)\n        .process(cluster.getSolrClient());\n    cluster.waitForActiveCollection(\"perReplicaDataColl\", 1, 5);\n    DocCollection coll = getCollectionState(\"perReplicaDataColl\");\n    String autoScaleJson = \"{\" +\n        \"  'cluster-preferences': [\" +\n        \"    { maximize : freedisk , precision: 50},\" +\n        \"    { minimize : cores, precision: 2}\" +\n        \"  ],\" +\n        \"  'cluster-policy': [\" +\n        \"    { replica : '0' , 'nodeRole': 'overseer'},\" +\n        \"    { 'replica': '<2', 'shard': '#ANY', 'node': '#ANY'\" +\n        \"    }\" +\n        \"  ],\" +\n        \"  'policies': {\" +\n        \"    'policy1': [\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'node': '#ANY'},\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'sysprop.rack': 'rack1'}\" +\n        \"    ]\" +\n        \"  }\" +\n        \"}\";\n    @SuppressWarnings({\"unchecked\"})\n    AutoScalingConfig config = new AutoScalingConfig((Map<String, Object>) Utils.fromJSONString(autoScaleJson));\n    AtomicInteger count = new AtomicInteger(0);\n    try (SolrCloudManager cloudManager = new SolrClientCloudManager(new ZkDistributedQueueFactory(cluster.getZkClient()), cluster.getSolrClient())) {\n      String nodeName = cloudManager.getClusterStateProvider().getLiveNodes().iterator().next();\n      SolrClientNodeStateProvider nodeStateProvider = (SolrClientNodeStateProvider) cloudManager.getNodeStateProvider();\n      Map<String, Map<String, List<ReplicaInfo>>> result = nodeStateProvider.getReplicaInfo(nodeName, Collections.singleton(\"UPDATE./update.requests\"));\n      nodeStateProvider.forEachReplica(nodeName, replicaInfo -> {\n        if (replicaInfo.getVariables().containsKey(\"UPDATE./update.requests\")) count.incrementAndGet();\n      });\n      assertTrue(count.get() > 0);\n\n      Policy.Session session = config.getPolicy().createSession(cloudManager);\n\n      for (Row row : session.getSortedNodes()) {\n        Object val = row.getVal(Type.TOTALDISK.tagName, null);\n        if (log.isInfoEnabled()) {\n          log.info(\"node: {} , totaldisk : {}, freedisk : {}\", row.node, val, row.getVal(\"freedisk\", null));\n        }\n        assertTrue(val != null);\n\n      }\n\n      count .set(0);\n      for (Row row : session.getSortedNodes()) {\n        row.collectionVsShardVsReplicas.forEach((c, shardVsReplicas) -> shardVsReplicas.forEach((s, replicaInfos) -> {\n          for (ReplicaInfo replicaInfo : replicaInfos) {\n            if (replicaInfo.getVariables().containsKey(Type.CORE_IDX.tagName)) count.incrementAndGet();\n          }\n        }));\n      }\n      assertTrue(count.get() > 0);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3f504512a03d978990cbff30db0522b354e846db","date":1595247421,"type":4,"author":"Ishan Chattopadhyaya","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/TestPolicyCloud#testDataProviderPerReplicaDetails().mjava","sourceNew":null,"sourceOld":"  public void testDataProviderPerReplicaDetails() throws Exception {\n    CollectionAdminRequest.createCollection(\"perReplicaDataColl\", \"conf\", 1, 5)\n        .process(cluster.getSolrClient());\n    cluster.waitForActiveCollection(\"perReplicaDataColl\", 1, 5);\n    DocCollection coll = getCollectionState(\"perReplicaDataColl\");\n    String autoScaleJson = \"{\" +\n        \"  'cluster-preferences': [\" +\n        \"    { maximize : freedisk , precision: 50},\" +\n        \"    { minimize : cores, precision: 2}\" +\n        \"  ],\" +\n        \"  'cluster-policy': [\" +\n        \"    { replica : '0' , 'nodeRole': 'overseer'},\" +\n        \"    { 'replica': '<2', 'shard': '#ANY', 'node': '#ANY'\" +\n        \"    }\" +\n        \"  ],\" +\n        \"  'policies': {\" +\n        \"    'policy1': [\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'node': '#ANY'},\" +\n        \"      { 'replica': '<2', 'shard': '#EACH', 'sysprop.rack': 'rack1'}\" +\n        \"    ]\" +\n        \"  }\" +\n        \"}\";\n    @SuppressWarnings({\"unchecked\"})\n    AutoScalingConfig config = new AutoScalingConfig((Map<String, Object>) Utils.fromJSONString(autoScaleJson));\n    AtomicInteger count = new AtomicInteger(0);\n    try (SolrCloudManager cloudManager = new SolrClientCloudManager(new ZkDistributedQueueFactory(cluster.getZkClient()), cluster.getSolrClient())) {\n      String nodeName = cloudManager.getClusterStateProvider().getLiveNodes().iterator().next();\n      SolrClientNodeStateProvider nodeStateProvider = (SolrClientNodeStateProvider) cloudManager.getNodeStateProvider();\n      Map<String, Map<String, List<Replica>>> result = nodeStateProvider.getReplicaInfo(nodeName, Collections.singleton(\"UPDATE./update.requests\"));\n      nodeStateProvider.forEachReplica(nodeName, replicaInfo -> {\n        if (replicaInfo.getProperties().containsKey(\"UPDATE./update.requests\")) count.incrementAndGet();\n      });\n      assertTrue(count.get() > 0);\n\n      Policy.Session session = config.getPolicy().createSession(cloudManager);\n\n      for (Row row : session.getSortedNodes()) {\n        Object val = row.getVal(Type.TOTALDISK.tagName, null);\n        if (log.isInfoEnabled()) {\n          log.info(\"node: {} , totaldisk : {}, freedisk : {}\", row.node, val, row.getVal(\"freedisk\", null));\n        }\n        assertTrue(val != null);\n\n      }\n\n      count .set(0);\n      for (Row row : session.getSortedNodes()) {\n        row.collectionVsShardVsReplicas.forEach((c, shardVsReplicas) -> shardVsReplicas.forEach((s, replicaInfos) -> {\n          for (Replica replicaInfo : replicaInfos) {\n            if (replicaInfo.getProperties().containsKey(Type.CORE_IDX.tagName)) count.incrementAndGet();\n          }\n        }));\n      }\n      assertTrue(count.get() > 0);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"3f504512a03d978990cbff30db0522b354e846db":["7e8ce2f9d2ddfcf5cfa7e73b8b2af287a2a276fd"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["427edb17549d4bb82462a16eec4ee0533d12d5b7"],"78231225260fb5b3bf9920f203d71477d5501c65":["e8972c9f22193dd2a876d8bd6418457bc5b9dcd7"],"0db34e17d2075ee456deda8012ce5ec6e0bdcd19":["f6ae69e36b15b227a219d4e334ccf5f58fb8affd"],"8f91616b62c917fffa5286c4ef2d21b10cc56f8e":["a10a24d2afdf00bbe1013706b80c989315772dc9"],"a10a24d2afdf00bbe1013706b80c989315772dc9":["78231225260fb5b3bf9920f203d71477d5501c65"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":["1bbcda32e5cd37ef61ea1190bacd080308e22070","8f91616b62c917fffa5286c4ef2d21b10cc56f8e"],"7e8ce2f9d2ddfcf5cfa7e73b8b2af287a2a276fd":["aa2585c33d5d66a1c837c312221eb55ddb3c4300"],"aa2585c33d5d66a1c837c312221eb55ddb3c4300":["fe9f2c4a0d7ac164e4bdd4eee7f87131aec83fd4"],"f6ae69e36b15b227a219d4e334ccf5f58fb8affd":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"427edb17549d4bb82462a16eec4ee0533d12d5b7":["8f91616b62c917fffa5286c4ef2d21b10cc56f8e"],"fe9f2c4a0d7ac164e4bdd4eee7f87131aec83fd4":["0db34e17d2075ee456deda8012ce5ec6e0bdcd19"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"1bbcda32e5cd37ef61ea1190bacd080308e22070":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"e8972c9f22193dd2a876d8bd6418457bc5b9dcd7":["1bbcda32e5cd37ef61ea1190bacd080308e22070"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3f504512a03d978990cbff30db0522b354e846db"],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":["1bbcda32e5cd37ef61ea1190bacd080308e22070","e8972c9f22193dd2a876d8bd6418457bc5b9dcd7"]},"commit2Childs":{"3f504512a03d978990cbff30db0522b354e846db":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["f6ae69e36b15b227a219d4e334ccf5f58fb8affd"],"78231225260fb5b3bf9920f203d71477d5501c65":["a10a24d2afdf00bbe1013706b80c989315772dc9"],"0db34e17d2075ee456deda8012ce5ec6e0bdcd19":["fe9f2c4a0d7ac164e4bdd4eee7f87131aec83fd4"],"8f91616b62c917fffa5286c4ef2d21b10cc56f8e":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","427edb17549d4bb82462a16eec4ee0533d12d5b7"],"a10a24d2afdf00bbe1013706b80c989315772dc9":["8f91616b62c917fffa5286c4ef2d21b10cc56f8e"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":[],"7e8ce2f9d2ddfcf5cfa7e73b8b2af287a2a276fd":["3f504512a03d978990cbff30db0522b354e846db"],"aa2585c33d5d66a1c837c312221eb55ddb3c4300":["7e8ce2f9d2ddfcf5cfa7e73b8b2af287a2a276fd"],"f6ae69e36b15b227a219d4e334ccf5f58fb8affd":["0db34e17d2075ee456deda8012ce5ec6e0bdcd19"],"427edb17549d4bb82462a16eec4ee0533d12d5b7":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"fe9f2c4a0d7ac164e4bdd4eee7f87131aec83fd4":["aa2585c33d5d66a1c837c312221eb55ddb3c4300"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["1bbcda32e5cd37ef61ea1190bacd080308e22070"],"1bbcda32e5cd37ef61ea1190bacd080308e22070":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","e8972c9f22193dd2a876d8bd6418457bc5b9dcd7","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"e8972c9f22193dd2a876d8bd6418457bc5b9dcd7":["78231225260fb5b3bf9920f203d71477d5501c65","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":[]},"heads":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","cd5edd1f2b162a5cfa08efd17851a07373a96817","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}