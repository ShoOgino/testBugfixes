{"path":"lucene/core/src/test/org/apache/lucene/codecs/compressing/TestCompressingStoredFieldsFormat#testDeletePartiallyWrittenFilesIfAbort().mjava","commits":[{"id":"25308800fd7565ab31e6353077a56bba68fb0668","date":1355337658,"type":0,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/compressing/TestCompressingStoredFieldsFormat#testDeletePartiallyWrittenFilesIfAbort().mjava","pathOld":"/dev/null","sourceNew":"  @Test(expected=IllegalArgumentException.class)\n  public void testDeletePartiallyWrittenFilesIfAbort() throws IOException {\n    final Document validDoc = new Document();\n    validDoc.add(new IntField(\"id\", 0, Store.YES));\n    iw.addDocument(validDoc);\n    iw.commit();\n    \n    // make sure that #writeField will fail to trigger an abort\n    final Document invalidDoc = new Document();\n    FieldType fieldType = new FieldType();\n    fieldType.setStored(true);\n    invalidDoc.add(new Field(\"invalid\", fieldType) {\n      \n      @Override\n      public String stringValue() {\n        return null;\n      }\n      \n    });\n    \n    try {\n      iw.addDocument(invalidDoc);\n      iw.commit();\n    }\n    finally {\n      int counter = 0;\n      for (String fileName : dir.listAll()) {\n        if (fileName.endsWith(\".fdt\") || fileName.endsWith(\".fdx\")) {\n          counter++;\n        }\n      }\n      // Only one .fdt and one .fdx files must have been found\n      assertEquals(2, counter);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["e390cd18556ba5c7850f9d277a2977e978bd44be"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c5ca059c94d972d0b56f1fefd39024a5a77f992a","date":1355349348,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/compressing/TestCompressingStoredFieldsFormat#testDeletePartiallyWrittenFilesIfAbort().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/compressing/TestCompressingStoredFieldsFormat#testDeletePartiallyWrittenFilesIfAbort().mjava","sourceNew":"  @Test(expected=IllegalArgumentException.class)\n  public void testDeletePartiallyWrittenFilesIfAbort() throws IOException {\n    // disable CFS because this test checks file names\n    iwConf.setMergePolicy(newLogMergePolicy(false));\n    iw.close();\n    iw = new RandomIndexWriter(random(), dir, iwConf);\n\n    final Document validDoc = new Document();\n    validDoc.add(new IntField(\"id\", 0, Store.YES));\n    iw.addDocument(validDoc);\n    iw.commit();\n    \n    // make sure that #writeField will fail to trigger an abort\n    final Document invalidDoc = new Document();\n    FieldType fieldType = new FieldType();\n    fieldType.setStored(true);\n    invalidDoc.add(new Field(\"invalid\", fieldType) {\n      \n      @Override\n      public String stringValue() {\n        return null;\n      }\n      \n    });\n    \n    try {\n      iw.addDocument(invalidDoc);\n      iw.commit();\n    }\n    finally {\n      int counter = 0;\n      for (String fileName : dir.listAll()) {\n        if (fileName.endsWith(\".fdt\") || fileName.endsWith(\".fdx\")) {\n          counter++;\n        }\n      }\n      // Only one .fdt and one .fdx files must have been found\n      assertEquals(2, counter);\n    }\n  }\n\n","sourceOld":"  @Test(expected=IllegalArgumentException.class)\n  public void testDeletePartiallyWrittenFilesIfAbort() throws IOException {\n    final Document validDoc = new Document();\n    validDoc.add(new IntField(\"id\", 0, Store.YES));\n    iw.addDocument(validDoc);\n    iw.commit();\n    \n    // make sure that #writeField will fail to trigger an abort\n    final Document invalidDoc = new Document();\n    FieldType fieldType = new FieldType();\n    fieldType.setStored(true);\n    invalidDoc.add(new Field(\"invalid\", fieldType) {\n      \n      @Override\n      public String stringValue() {\n        return null;\n      }\n      \n    });\n    \n    try {\n      iw.addDocument(invalidDoc);\n      iw.commit();\n    }\n    finally {\n      int counter = 0;\n      for (String fileName : dir.listAll()) {\n        if (fileName.endsWith(\".fdt\") || fileName.endsWith(\".fdx\")) {\n          counter++;\n        }\n      }\n      // Only one .fdt and one .fdx files must have been found\n      assertEquals(2, counter);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d3fcb70cf561547c7bb1506e0cf32ca7b1287064","date":1357616416,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/compressing/TestCompressingStoredFieldsFormat#testDeletePartiallyWrittenFilesIfAbort().mjava","pathOld":"/dev/null","sourceNew":"  @Test(expected=IllegalArgumentException.class)\n  public void testDeletePartiallyWrittenFilesIfAbort() throws IOException {\n    // disable CFS because this test checks file names\n    iwConf.setMergePolicy(newLogMergePolicy(false));\n    iw.close();\n    iw = new RandomIndexWriter(random(), dir, iwConf);\n\n    final Document validDoc = new Document();\n    validDoc.add(new IntField(\"id\", 0, Store.YES));\n    iw.addDocument(validDoc);\n    iw.commit();\n    \n    // make sure that #writeField will fail to trigger an abort\n    final Document invalidDoc = new Document();\n    FieldType fieldType = new FieldType();\n    fieldType.setStored(true);\n    invalidDoc.add(new Field(\"invalid\", fieldType) {\n      \n      @Override\n      public String stringValue() {\n        return null;\n      }\n      \n    });\n    \n    try {\n      iw.addDocument(invalidDoc);\n      iw.commit();\n    }\n    finally {\n      int counter = 0;\n      for (String fileName : dir.listAll()) {\n        if (fileName.endsWith(\".fdt\") || fileName.endsWith(\".fdx\")) {\n          counter++;\n        }\n      }\n      // Only one .fdt and one .fdx files must have been found\n      assertEquals(2, counter);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"70b55953b6a72596cb534ead735a8b849a473cac","date":1363634568,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/compressing/TestCompressingStoredFieldsFormat#testDeletePartiallyWrittenFilesIfAbort().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/compressing/TestCompressingStoredFieldsFormat#testDeletePartiallyWrittenFilesIfAbort().mjava","sourceNew":"  @Test(expected=IllegalArgumentException.class)\n  public void testDeletePartiallyWrittenFilesIfAbort() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwConf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwConf.setMaxBufferedDocs(RandomInts.randomIntBetween(random(), 2, 30));\n    iwConf.setCodec(CompressingCodec.randomInstance(random()));\n    // disable CFS because this test checks file names\n    iwConf.setMergePolicy(newLogMergePolicy(false));\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwConf);\n\n    final Document validDoc = new Document();\n    validDoc.add(new IntField(\"id\", 0, Store.YES));\n    iw.addDocument(validDoc);\n    iw.commit();\n    \n    // make sure that #writeField will fail to trigger an abort\n    final Document invalidDoc = new Document();\n    FieldType fieldType = new FieldType();\n    fieldType.setStored(true);\n    invalidDoc.add(new Field(\"invalid\", fieldType) {\n      \n      @Override\n      public String stringValue() {\n        return null;\n      }\n      \n    });\n    \n    try {\n      iw.addDocument(invalidDoc);\n      iw.commit();\n    }\n    finally {\n      int counter = 0;\n      for (String fileName : dir.listAll()) {\n        if (fileName.endsWith(\".fdt\") || fileName.endsWith(\".fdx\")) {\n          counter++;\n        }\n      }\n      // Only one .fdt and one .fdx files must have been found\n      assertEquals(2, counter);\n      iw.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  @Test(expected=IllegalArgumentException.class)\n  public void testDeletePartiallyWrittenFilesIfAbort() throws IOException {\n    // disable CFS because this test checks file names\n    iwConf.setMergePolicy(newLogMergePolicy(false));\n    iw.close();\n    iw = new RandomIndexWriter(random(), dir, iwConf);\n\n    final Document validDoc = new Document();\n    validDoc.add(new IntField(\"id\", 0, Store.YES));\n    iw.addDocument(validDoc);\n    iw.commit();\n    \n    // make sure that #writeField will fail to trigger an abort\n    final Document invalidDoc = new Document();\n    FieldType fieldType = new FieldType();\n    fieldType.setStored(true);\n    invalidDoc.add(new Field(\"invalid\", fieldType) {\n      \n      @Override\n      public String stringValue() {\n        return null;\n      }\n      \n    });\n    \n    try {\n      iw.addDocument(invalidDoc);\n      iw.commit();\n    }\n    finally {\n      int counter = 0;\n      for (String fileName : dir.listAll()) {\n        if (fileName.endsWith(\".fdt\") || fileName.endsWith(\".fdx\")) {\n          counter++;\n        }\n      }\n      // Only one .fdt and one .fdx files must have been found\n      assertEquals(2, counter);\n    }\n  }\n\n","bugFix":null,"bugIntro":["e390cd18556ba5c7850f9d277a2977e978bd44be","71da933d30aea361ccc224d6544c451cbf49916d"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"088a7ef694fd43d5d9a4d200c4005865f773d1e7","date":1371136274,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/compressing/TestCompressingStoredFieldsFormat#testDeletePartiallyWrittenFilesIfAbort().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/compressing/TestCompressingStoredFieldsFormat#testDeletePartiallyWrittenFilesIfAbort().mjava","sourceNew":"  @Test(expected=IllegalArgumentException.class)\n  public void testDeletePartiallyWrittenFilesIfAbort() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwConf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwConf.setMaxBufferedDocs(RandomInts.randomIntBetween(random(), 2, 30));\n    iwConf.setCodec(CompressingCodec.randomInstance(random()));\n    // disable CFS because this test checks file names\n    iwConf.setMergePolicy(newLogMergePolicy(false));\n    iwConf.setUseCompoundFile(false);\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwConf);\n\n    final Document validDoc = new Document();\n    validDoc.add(new IntField(\"id\", 0, Store.YES));\n    iw.addDocument(validDoc);\n    iw.commit();\n    \n    // make sure that #writeField will fail to trigger an abort\n    final Document invalidDoc = new Document();\n    FieldType fieldType = new FieldType();\n    fieldType.setStored(true);\n    invalidDoc.add(new Field(\"invalid\", fieldType) {\n      \n      @Override\n      public String stringValue() {\n        return null;\n      }\n      \n    });\n    \n    try {\n      iw.addDocument(invalidDoc);\n      iw.commit();\n    }\n    finally {\n      int counter = 0;\n      for (String fileName : dir.listAll()) {\n        if (fileName.endsWith(\".fdt\") || fileName.endsWith(\".fdx\")) {\n          counter++;\n        }\n      }\n      // Only one .fdt and one .fdx files must have been found\n      assertEquals(2, counter);\n      iw.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  @Test(expected=IllegalArgumentException.class)\n  public void testDeletePartiallyWrittenFilesIfAbort() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwConf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwConf.setMaxBufferedDocs(RandomInts.randomIntBetween(random(), 2, 30));\n    iwConf.setCodec(CompressingCodec.randomInstance(random()));\n    // disable CFS because this test checks file names\n    iwConf.setMergePolicy(newLogMergePolicy(false));\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwConf);\n\n    final Document validDoc = new Document();\n    validDoc.add(new IntField(\"id\", 0, Store.YES));\n    iw.addDocument(validDoc);\n    iw.commit();\n    \n    // make sure that #writeField will fail to trigger an abort\n    final Document invalidDoc = new Document();\n    FieldType fieldType = new FieldType();\n    fieldType.setStored(true);\n    invalidDoc.add(new Field(\"invalid\", fieldType) {\n      \n      @Override\n      public String stringValue() {\n        return null;\n      }\n      \n    });\n    \n    try {\n      iw.addDocument(invalidDoc);\n      iw.commit();\n    }\n    finally {\n      int counter = 0;\n      for (String fileName : dir.listAll()) {\n        if (fileName.endsWith(\".fdt\") || fileName.endsWith(\".fdx\")) {\n          counter++;\n        }\n      }\n      // Only one .fdt and one .fdx files must have been found\n      assertEquals(2, counter);\n      iw.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/compressing/TestCompressingStoredFieldsFormat#testDeletePartiallyWrittenFilesIfAbort().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/compressing/TestCompressingStoredFieldsFormat#testDeletePartiallyWrittenFilesIfAbort().mjava","sourceNew":"  @Test(expected=IllegalArgumentException.class)\n  public void testDeletePartiallyWrittenFilesIfAbort() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwConf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwConf.setMaxBufferedDocs(RandomInts.randomIntBetween(random(), 2, 30));\n    iwConf.setCodec(CompressingCodec.randomInstance(random()));\n    // disable CFS because this test checks file names\n    iwConf.setMergePolicy(newLogMergePolicy(false));\n    iwConf.setUseCompoundFile(false);\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwConf);\n\n    final Document validDoc = new Document();\n    validDoc.add(new IntField(\"id\", 0, Store.YES));\n    iw.addDocument(validDoc);\n    iw.commit();\n    \n    // make sure that #writeField will fail to trigger an abort\n    final Document invalidDoc = new Document();\n    FieldType fieldType = new FieldType();\n    fieldType.setStored(true);\n    invalidDoc.add(new Field(\"invalid\", fieldType) {\n      \n      @Override\n      public String stringValue() {\n        return null;\n      }\n      \n    });\n    \n    try {\n      iw.addDocument(invalidDoc);\n      iw.commit();\n    }\n    finally {\n      int counter = 0;\n      for (String fileName : dir.listAll()) {\n        if (fileName.endsWith(\".fdt\") || fileName.endsWith(\".fdx\")) {\n          counter++;\n        }\n      }\n      // Only one .fdt and one .fdx files must have been found\n      assertEquals(2, counter);\n      iw.shutdown();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  @Test(expected=IllegalArgumentException.class)\n  public void testDeletePartiallyWrittenFilesIfAbort() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwConf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwConf.setMaxBufferedDocs(RandomInts.randomIntBetween(random(), 2, 30));\n    iwConf.setCodec(CompressingCodec.randomInstance(random()));\n    // disable CFS because this test checks file names\n    iwConf.setMergePolicy(newLogMergePolicy(false));\n    iwConf.setUseCompoundFile(false);\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwConf);\n\n    final Document validDoc = new Document();\n    validDoc.add(new IntField(\"id\", 0, Store.YES));\n    iw.addDocument(validDoc);\n    iw.commit();\n    \n    // make sure that #writeField will fail to trigger an abort\n    final Document invalidDoc = new Document();\n    FieldType fieldType = new FieldType();\n    fieldType.setStored(true);\n    invalidDoc.add(new Field(\"invalid\", fieldType) {\n      \n      @Override\n      public String stringValue() {\n        return null;\n      }\n      \n    });\n    \n    try {\n      iw.addDocument(invalidDoc);\n      iw.commit();\n    }\n    finally {\n      int counter = 0;\n      for (String fileName : dir.listAll()) {\n        if (fileName.endsWith(\".fdt\") || fileName.endsWith(\".fdx\")) {\n          counter++;\n        }\n      }\n      // Only one .fdt and one .fdx files must have been found\n      assertEquals(2, counter);\n      iw.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"db5ed22fc16d9c24d899d1b6fd7c088e11d19a03","date":1399586248,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/compressing/TestCompressingStoredFieldsFormat#testDeletePartiallyWrittenFilesIfAbort().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/compressing/TestCompressingStoredFieldsFormat#testDeletePartiallyWrittenFilesIfAbort().mjava","sourceNew":"  @Test(expected=IllegalArgumentException.class)\n  public void testDeletePartiallyWrittenFilesIfAbort() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwConf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwConf.setMaxBufferedDocs(RandomInts.randomIntBetween(random(), 2, 30));\n    iwConf.setCodec(CompressingCodec.randomInstance(random()));\n    // disable CFS because this test checks file names\n    iwConf.setMergePolicy(newLogMergePolicy(false));\n    iwConf.setUseCompoundFile(false);\n\n    // Cannot use RIW because this test wants CFS to stay off:\n    IndexWriter iw = new IndexWriter(dir, iwConf);\n\n    final Document validDoc = new Document();\n    validDoc.add(new IntField(\"id\", 0, Store.YES));\n    iw.addDocument(validDoc);\n    iw.commit();\n    \n    // make sure that #writeField will fail to trigger an abort\n    final Document invalidDoc = new Document();\n    FieldType fieldType = new FieldType();\n    fieldType.setStored(true);\n    invalidDoc.add(new Field(\"invalid\", fieldType) {\n      \n      @Override\n      public String stringValue() {\n        // TODO: really bad & scary that this causes IW to\n        // abort the segment!!  We should fix this.\n        return null;\n      }\n      \n    });\n    \n    try {\n      iw.addDocument(invalidDoc);\n      iw.commit();\n    }\n    finally {\n      int counter = 0;\n      for (String fileName : dir.listAll()) {\n        if (fileName.endsWith(\".fdt\") || fileName.endsWith(\".fdx\")) {\n          counter++;\n        }\n      }\n      // Only one .fdt and one .fdx files must have been found\n      assertEquals(2, counter);\n      iw.shutdown();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  @Test(expected=IllegalArgumentException.class)\n  public void testDeletePartiallyWrittenFilesIfAbort() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwConf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwConf.setMaxBufferedDocs(RandomInts.randomIntBetween(random(), 2, 30));\n    iwConf.setCodec(CompressingCodec.randomInstance(random()));\n    // disable CFS because this test checks file names\n    iwConf.setMergePolicy(newLogMergePolicy(false));\n    iwConf.setUseCompoundFile(false);\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwConf);\n\n    final Document validDoc = new Document();\n    validDoc.add(new IntField(\"id\", 0, Store.YES));\n    iw.addDocument(validDoc);\n    iw.commit();\n    \n    // make sure that #writeField will fail to trigger an abort\n    final Document invalidDoc = new Document();\n    FieldType fieldType = new FieldType();\n    fieldType.setStored(true);\n    invalidDoc.add(new Field(\"invalid\", fieldType) {\n      \n      @Override\n      public String stringValue() {\n        return null;\n      }\n      \n    });\n    \n    try {\n      iw.addDocument(invalidDoc);\n      iw.commit();\n    }\n    finally {\n      int counter = 0;\n      for (String fileName : dir.listAll()) {\n        if (fileName.endsWith(\".fdt\") || fileName.endsWith(\".fdx\")) {\n          counter++;\n        }\n      }\n      // Only one .fdt and one .fdx files must have been found\n      assertEquals(2, counter);\n      iw.shutdown();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/compressing/TestCompressingStoredFieldsFormat#testDeletePartiallyWrittenFilesIfAbort().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/compressing/TestCompressingStoredFieldsFormat#testDeletePartiallyWrittenFilesIfAbort().mjava","sourceNew":"  @Test(expected=IllegalArgumentException.class)\n  public void testDeletePartiallyWrittenFilesIfAbort() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwConf = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwConf.setMaxBufferedDocs(RandomInts.randomIntBetween(random(), 2, 30));\n    iwConf.setCodec(CompressingCodec.randomInstance(random()));\n    // disable CFS because this test checks file names\n    iwConf.setMergePolicy(newLogMergePolicy(false));\n    iwConf.setUseCompoundFile(false);\n\n    // Cannot use RIW because this test wants CFS to stay off:\n    IndexWriter iw = new IndexWriter(dir, iwConf);\n\n    final Document validDoc = new Document();\n    validDoc.add(new IntField(\"id\", 0, Store.YES));\n    iw.addDocument(validDoc);\n    iw.commit();\n    \n    // make sure that #writeField will fail to trigger an abort\n    final Document invalidDoc = new Document();\n    FieldType fieldType = new FieldType();\n    fieldType.setStored(true);\n    invalidDoc.add(new Field(\"invalid\", fieldType) {\n      \n      @Override\n      public String stringValue() {\n        // TODO: really bad & scary that this causes IW to\n        // abort the segment!!  We should fix this.\n        return null;\n      }\n      \n    });\n    \n    try {\n      iw.addDocument(invalidDoc);\n      iw.commit();\n    }\n    finally {\n      int counter = 0;\n      for (String fileName : dir.listAll()) {\n        if (fileName.endsWith(\".fdt\") || fileName.endsWith(\".fdx\")) {\n          counter++;\n        }\n      }\n      // Only one .fdt and one .fdx files must have been found\n      assertEquals(2, counter);\n      iw.shutdown();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  @Test(expected=IllegalArgumentException.class)\n  public void testDeletePartiallyWrittenFilesIfAbort() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwConf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwConf.setMaxBufferedDocs(RandomInts.randomIntBetween(random(), 2, 30));\n    iwConf.setCodec(CompressingCodec.randomInstance(random()));\n    // disable CFS because this test checks file names\n    iwConf.setMergePolicy(newLogMergePolicy(false));\n    iwConf.setUseCompoundFile(false);\n\n    // Cannot use RIW because this test wants CFS to stay off:\n    IndexWriter iw = new IndexWriter(dir, iwConf);\n\n    final Document validDoc = new Document();\n    validDoc.add(new IntField(\"id\", 0, Store.YES));\n    iw.addDocument(validDoc);\n    iw.commit();\n    \n    // make sure that #writeField will fail to trigger an abort\n    final Document invalidDoc = new Document();\n    FieldType fieldType = new FieldType();\n    fieldType.setStored(true);\n    invalidDoc.add(new Field(\"invalid\", fieldType) {\n      \n      @Override\n      public String stringValue() {\n        // TODO: really bad & scary that this causes IW to\n        // abort the segment!!  We should fix this.\n        return null;\n      }\n      \n    });\n    \n    try {\n      iw.addDocument(invalidDoc);\n      iw.commit();\n    }\n    finally {\n      int counter = 0;\n      for (String fileName : dir.listAll()) {\n        if (fileName.endsWith(\".fdt\") || fileName.endsWith(\".fdx\")) {\n          counter++;\n        }\n      }\n      // Only one .fdt and one .fdx files must have been found\n      assertEquals(2, counter);\n      iw.shutdown();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/compressing/TestCompressingStoredFieldsFormat#testDeletePartiallyWrittenFilesIfAbort().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/compressing/TestCompressingStoredFieldsFormat#testDeletePartiallyWrittenFilesIfAbort().mjava","sourceNew":"  @Test(expected=IllegalArgumentException.class)\n  public void testDeletePartiallyWrittenFilesIfAbort() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwConf = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwConf.setMaxBufferedDocs(RandomInts.randomIntBetween(random(), 2, 30));\n    iwConf.setCodec(CompressingCodec.randomInstance(random()));\n    // disable CFS because this test checks file names\n    iwConf.setMergePolicy(newLogMergePolicy(false));\n    iwConf.setUseCompoundFile(false);\n\n    // Cannot use RIW because this test wants CFS to stay off:\n    IndexWriter iw = new IndexWriter(dir, iwConf);\n\n    final Document validDoc = new Document();\n    validDoc.add(new IntField(\"id\", 0, Store.YES));\n    iw.addDocument(validDoc);\n    iw.commit();\n    \n    // make sure that #writeField will fail to trigger an abort\n    final Document invalidDoc = new Document();\n    FieldType fieldType = new FieldType();\n    fieldType.setStored(true);\n    invalidDoc.add(new Field(\"invalid\", fieldType) {\n      \n      @Override\n      public String stringValue() {\n        // TODO: really bad & scary that this causes IW to\n        // abort the segment!!  We should fix this.\n        return null;\n      }\n      \n    });\n    \n    try {\n      iw.addDocument(invalidDoc);\n      iw.commit();\n    }\n    finally {\n      int counter = 0;\n      for (String fileName : dir.listAll()) {\n        if (fileName.endsWith(\".fdt\") || fileName.endsWith(\".fdx\")) {\n          counter++;\n        }\n      }\n      // Only one .fdt and one .fdx files must have been found\n      assertEquals(2, counter);\n      iw.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  @Test(expected=IllegalArgumentException.class)\n  public void testDeletePartiallyWrittenFilesIfAbort() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwConf = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwConf.setMaxBufferedDocs(RandomInts.randomIntBetween(random(), 2, 30));\n    iwConf.setCodec(CompressingCodec.randomInstance(random()));\n    // disable CFS because this test checks file names\n    iwConf.setMergePolicy(newLogMergePolicy(false));\n    iwConf.setUseCompoundFile(false);\n\n    // Cannot use RIW because this test wants CFS to stay off:\n    IndexWriter iw = new IndexWriter(dir, iwConf);\n\n    final Document validDoc = new Document();\n    validDoc.add(new IntField(\"id\", 0, Store.YES));\n    iw.addDocument(validDoc);\n    iw.commit();\n    \n    // make sure that #writeField will fail to trigger an abort\n    final Document invalidDoc = new Document();\n    FieldType fieldType = new FieldType();\n    fieldType.setStored(true);\n    invalidDoc.add(new Field(\"invalid\", fieldType) {\n      \n      @Override\n      public String stringValue() {\n        // TODO: really bad & scary that this causes IW to\n        // abort the segment!!  We should fix this.\n        return null;\n      }\n      \n    });\n    \n    try {\n      iw.addDocument(invalidDoc);\n      iw.commit();\n    }\n    finally {\n      int counter = 0;\n      for (String fileName : dir.listAll()) {\n        if (fileName.endsWith(\".fdt\") || fileName.endsWith(\".fdx\")) {\n          counter++;\n        }\n      }\n      // Only one .fdt and one .fdx files must have been found\n      assertEquals(2, counter);\n      iw.shutdown();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"98d2deb8c96c79ebef084a1f8e5a1a6c08608f13","date":1409346855,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/compressing/TestCompressingStoredFieldsFormat#testDeletePartiallyWrittenFilesIfAbort().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/compressing/TestCompressingStoredFieldsFormat#testDeletePartiallyWrittenFilesIfAbort().mjava","sourceNew":"  @Test(expected=IllegalArgumentException.class)\n  public void testDeletePartiallyWrittenFilesIfAbort() throws IOException {\n    Directory dir = newDirectory();\n    // test explicitly needs files to always be actually deleted\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setEnableVirusScanner(false);\n    }\n    IndexWriterConfig iwConf = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwConf.setMaxBufferedDocs(RandomInts.randomIntBetween(random(), 2, 30));\n    iwConf.setCodec(CompressingCodec.randomInstance(random()));\n    // disable CFS because this test checks file names\n    iwConf.setMergePolicy(newLogMergePolicy(false));\n    iwConf.setUseCompoundFile(false);\n\n    // Cannot use RIW because this test wants CFS to stay off:\n    IndexWriter iw = new IndexWriter(dir, iwConf);\n\n    final Document validDoc = new Document();\n    validDoc.add(new IntField(\"id\", 0, Store.YES));\n    iw.addDocument(validDoc);\n    iw.commit();\n    \n    // make sure that #writeField will fail to trigger an abort\n    final Document invalidDoc = new Document();\n    FieldType fieldType = new FieldType();\n    fieldType.setStored(true);\n    invalidDoc.add(new Field(\"invalid\", fieldType) {\n      \n      @Override\n      public String stringValue() {\n        // TODO: really bad & scary that this causes IW to\n        // abort the segment!!  We should fix this.\n        return null;\n      }\n      \n    });\n    \n    try {\n      iw.addDocument(invalidDoc);\n      iw.commit();\n    }\n    finally {\n      int counter = 0;\n      for (String fileName : dir.listAll()) {\n        if (fileName.endsWith(\".fdt\") || fileName.endsWith(\".fdx\")) {\n          counter++;\n        }\n      }\n      // Only one .fdt and one .fdx files must have been found\n      assertEquals(2, counter);\n      iw.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  @Test(expected=IllegalArgumentException.class)\n  public void testDeletePartiallyWrittenFilesIfAbort() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwConf = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwConf.setMaxBufferedDocs(RandomInts.randomIntBetween(random(), 2, 30));\n    iwConf.setCodec(CompressingCodec.randomInstance(random()));\n    // disable CFS because this test checks file names\n    iwConf.setMergePolicy(newLogMergePolicy(false));\n    iwConf.setUseCompoundFile(false);\n\n    // Cannot use RIW because this test wants CFS to stay off:\n    IndexWriter iw = new IndexWriter(dir, iwConf);\n\n    final Document validDoc = new Document();\n    validDoc.add(new IntField(\"id\", 0, Store.YES));\n    iw.addDocument(validDoc);\n    iw.commit();\n    \n    // make sure that #writeField will fail to trigger an abort\n    final Document invalidDoc = new Document();\n    FieldType fieldType = new FieldType();\n    fieldType.setStored(true);\n    invalidDoc.add(new Field(\"invalid\", fieldType) {\n      \n      @Override\n      public String stringValue() {\n        // TODO: really bad & scary that this causes IW to\n        // abort the segment!!  We should fix this.\n        return null;\n      }\n      \n    });\n    \n    try {\n      iw.addDocument(invalidDoc);\n      iw.commit();\n    }\n    finally {\n      int counter = 0;\n      for (String fileName : dir.listAll()) {\n        if (fileName.endsWith(\".fdt\") || fileName.endsWith(\".fdx\")) {\n          counter++;\n        }\n      }\n      // Only one .fdt and one .fdx files must have been found\n      assertEquals(2, counter);\n      iw.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"474b77fc1ee62c3fc1c73ceb19cc975cb03667ac","date":1417363109,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/compressing/TestCompressingStoredFieldsFormat#testDeletePartiallyWrittenFilesIfAbort().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/compressing/TestCompressingStoredFieldsFormat#testDeletePartiallyWrittenFilesIfAbort().mjava","sourceNew":"  @Test(expected=IllegalArgumentException.class)\n  public void testDeletePartiallyWrittenFilesIfAbort() throws IOException {\n    Directory dir = newDirectory();\n    // test explicitly needs files to always be actually deleted\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setEnableVirusScanner(false);\n    }\n    IndexWriterConfig iwConf = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwConf.setMaxBufferedDocs(RandomInts.randomIntBetween(random(), 2, 30));\n    iwConf.setCodec(CompressingCodec.randomInstance(random()));\n    // disable CFS because this test checks file names\n    iwConf.setMergePolicy(newLogMergePolicy(false));\n    iwConf.setUseCompoundFile(false);\n\n    // Cannot use RIW because this test wants CFS to stay off:\n    IndexWriter iw = new IndexWriter(dir, iwConf);\n\n    final Document validDoc = new Document();\n    validDoc.add(new IntField(\"id\", 0, Store.YES));\n    iw.addDocument(validDoc);\n    iw.commit();\n    \n    // make sure that #writeField will fail to trigger an abort\n    final Document invalidDoc = new Document();\n    FieldType fieldType = new FieldType();\n    fieldType.setStored(true);\n    invalidDoc.add(new Field(\"invalid\", fieldType) {\n      \n      @Override\n      public String stringValue() {\n        // TODO: really bad & scary that this causes IW to\n        // abort the segment!!  We should fix this.\n        return null;\n      }\n      \n    });\n    \n    try {\n      iw.addDocument(invalidDoc);\n      iw.commit();\n    }\n    finally {\n      // next event will cause IW to delete the old files: we use prepareCommit just as example\n      iw.prepareCommit();\n      int counter = 0;\n      for (String fileName : dir.listAll()) {\n        if (fileName.endsWith(\".fdt\") || fileName.endsWith(\".fdx\")) {\n          counter++;\n        }\n      }\n      // Only one .fdt and one .fdx files must have been found\n      assertEquals(2, counter);\n      iw.rollback();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  @Test(expected=IllegalArgumentException.class)\n  public void testDeletePartiallyWrittenFilesIfAbort() throws IOException {\n    Directory dir = newDirectory();\n    // test explicitly needs files to always be actually deleted\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setEnableVirusScanner(false);\n    }\n    IndexWriterConfig iwConf = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwConf.setMaxBufferedDocs(RandomInts.randomIntBetween(random(), 2, 30));\n    iwConf.setCodec(CompressingCodec.randomInstance(random()));\n    // disable CFS because this test checks file names\n    iwConf.setMergePolicy(newLogMergePolicy(false));\n    iwConf.setUseCompoundFile(false);\n\n    // Cannot use RIW because this test wants CFS to stay off:\n    IndexWriter iw = new IndexWriter(dir, iwConf);\n\n    final Document validDoc = new Document();\n    validDoc.add(new IntField(\"id\", 0, Store.YES));\n    iw.addDocument(validDoc);\n    iw.commit();\n    \n    // make sure that #writeField will fail to trigger an abort\n    final Document invalidDoc = new Document();\n    FieldType fieldType = new FieldType();\n    fieldType.setStored(true);\n    invalidDoc.add(new Field(\"invalid\", fieldType) {\n      \n      @Override\n      public String stringValue() {\n        // TODO: really bad & scary that this causes IW to\n        // abort the segment!!  We should fix this.\n        return null;\n      }\n      \n    });\n    \n    try {\n      iw.addDocument(invalidDoc);\n      iw.commit();\n    }\n    finally {\n      int counter = 0;\n      for (String fileName : dir.listAll()) {\n        if (fileName.endsWith(\".fdt\") || fileName.endsWith(\".fdx\")) {\n          counter++;\n        }\n      }\n      // Only one .fdt and one .fdx files must have been found\n      assertEquals(2, counter);\n      iw.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9299079153fd7895bf3cf6835cf7019af2ba89b3","date":1417813477,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/compressing/TestCompressingStoredFieldsFormat#testDeletePartiallyWrittenFilesIfAbort().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/compressing/TestCompressingStoredFieldsFormat#testDeletePartiallyWrittenFilesIfAbort().mjava","sourceNew":"  @Test(expected=IllegalArgumentException.class)\n  public void testDeletePartiallyWrittenFilesIfAbort() throws IOException {\n    Directory dir = newDirectory();\n    // test explicitly needs files to always be actually deleted\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setEnableVirusScanner(false);\n    }\n    IndexWriterConfig iwConf = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwConf.setMaxBufferedDocs(RandomInts.randomIntBetween(random(), 2, 30));\n    iwConf.setCodec(CompressingCodec.randomInstance(random()));\n    // disable CFS because this test checks file names\n    iwConf.setMergePolicy(newLogMergePolicy(false));\n    iwConf.setUseCompoundFile(false);\n\n    // Cannot use RIW because this test wants CFS to stay off:\n    IndexWriter iw = new IndexWriter(dir, iwConf);\n\n    final Document validDoc = new Document();\n    validDoc.add(new IntField(\"id\", 0, Store.YES));\n    iw.addDocument(validDoc);\n    iw.commit();\n    \n    // make sure that #writeField will fail to trigger an abort\n    final Document invalidDoc = new Document();\n    FieldType fieldType = new FieldType();\n    fieldType.setStored(true);\n    invalidDoc.add(new Field(\"invalid\", fieldType) {\n      \n      @Override\n      public String stringValue() {\n        // TODO: really bad & scary that this causes IW to\n        // abort the segment!!  We should fix this.\n        return null;\n      }\n      \n    });\n    \n    try {\n      iw.addDocument(invalidDoc);\n      iw.commit();\n    }\n    finally {\n      // Abort should have closed the deleter:\n      dir.close();\n    }\n  }\n\n","sourceOld":"  @Test(expected=IllegalArgumentException.class)\n  public void testDeletePartiallyWrittenFilesIfAbort() throws IOException {\n    Directory dir = newDirectory();\n    // test explicitly needs files to always be actually deleted\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setEnableVirusScanner(false);\n    }\n    IndexWriterConfig iwConf = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwConf.setMaxBufferedDocs(RandomInts.randomIntBetween(random(), 2, 30));\n    iwConf.setCodec(CompressingCodec.randomInstance(random()));\n    // disable CFS because this test checks file names\n    iwConf.setMergePolicy(newLogMergePolicy(false));\n    iwConf.setUseCompoundFile(false);\n\n    // Cannot use RIW because this test wants CFS to stay off:\n    IndexWriter iw = new IndexWriter(dir, iwConf);\n\n    final Document validDoc = new Document();\n    validDoc.add(new IntField(\"id\", 0, Store.YES));\n    iw.addDocument(validDoc);\n    iw.commit();\n    \n    // make sure that #writeField will fail to trigger an abort\n    final Document invalidDoc = new Document();\n    FieldType fieldType = new FieldType();\n    fieldType.setStored(true);\n    invalidDoc.add(new Field(\"invalid\", fieldType) {\n      \n      @Override\n      public String stringValue() {\n        // TODO: really bad & scary that this causes IW to\n        // abort the segment!!  We should fix this.\n        return null;\n      }\n      \n    });\n    \n    try {\n      iw.addDocument(invalidDoc);\n      iw.commit();\n    }\n    finally {\n      // next event will cause IW to delete the old files: we use prepareCommit just as example\n      iw.prepareCommit();\n      int counter = 0;\n      for (String fileName : dir.listAll()) {\n        if (fileName.endsWith(\".fdt\") || fileName.endsWith(\".fdx\")) {\n          counter++;\n        }\n      }\n      // Only one .fdt and one .fdx files must have been found\n      assertEquals(2, counter);\n      iw.rollback();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":["e390cd18556ba5c7850f9d277a2977e978bd44be"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e390cd18556ba5c7850f9d277a2977e978bd44be","date":1423083957,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/compressing/TestCompressingStoredFieldsFormat#testDeletePartiallyWrittenFilesIfAbort().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/compressing/TestCompressingStoredFieldsFormat#testDeletePartiallyWrittenFilesIfAbort().mjava","sourceNew":"  public void testDeletePartiallyWrittenFilesIfAbort() throws IOException {\n    Directory dir = newDirectory();\n    // test explicitly needs files to always be actually deleted\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setEnableVirusScanner(false);\n    }\n    IndexWriterConfig iwConf = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwConf.setMaxBufferedDocs(RandomInts.randomIntBetween(random(), 2, 30));\n    iwConf.setCodec(CompressingCodec.randomInstance(random()));\n    // disable CFS because this test checks file names\n    iwConf.setMergePolicy(newLogMergePolicy(false));\n    iwConf.setUseCompoundFile(false);\n\n    // Cannot use RIW because this test wants CFS to stay off:\n    IndexWriter iw = new IndexWriter(dir, iwConf);\n\n    final Document validDoc = new Document();\n    validDoc.add(new IntField(\"id\", 0, Store.YES));\n    iw.addDocument(validDoc);\n    iw.commit();\n    \n    // make sure that #writeField will fail to trigger an abort\n    final Document invalidDoc = new Document();\n    FieldType fieldType = new FieldType();\n    fieldType.setStored(true);\n    invalidDoc.add(new Field(\"invalid\", fieldType) {\n      \n      @Override\n      public String stringValue() {\n        // TODO: really bad & scary that this causes IW to\n        // abort the segment!!  We should fix this.\n        return null;\n      }\n      \n    });\n    \n    try {\n      iw.addDocument(invalidDoc);\n      iw.commit();\n    } catch(IllegalArgumentException iae) {\n      // expected\n      assertEquals(iae, iw.getTragicException());\n    }\n    // Writer should be closed by tragedy\n    assertFalse(iw.isOpen());\n    dir.close();\n  }\n\n","sourceOld":"  @Test(expected=IllegalArgumentException.class)\n  public void testDeletePartiallyWrittenFilesIfAbort() throws IOException {\n    Directory dir = newDirectory();\n    // test explicitly needs files to always be actually deleted\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setEnableVirusScanner(false);\n    }\n    IndexWriterConfig iwConf = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwConf.setMaxBufferedDocs(RandomInts.randomIntBetween(random(), 2, 30));\n    iwConf.setCodec(CompressingCodec.randomInstance(random()));\n    // disable CFS because this test checks file names\n    iwConf.setMergePolicy(newLogMergePolicy(false));\n    iwConf.setUseCompoundFile(false);\n\n    // Cannot use RIW because this test wants CFS to stay off:\n    IndexWriter iw = new IndexWriter(dir, iwConf);\n\n    final Document validDoc = new Document();\n    validDoc.add(new IntField(\"id\", 0, Store.YES));\n    iw.addDocument(validDoc);\n    iw.commit();\n    \n    // make sure that #writeField will fail to trigger an abort\n    final Document invalidDoc = new Document();\n    FieldType fieldType = new FieldType();\n    fieldType.setStored(true);\n    invalidDoc.add(new Field(\"invalid\", fieldType) {\n      \n      @Override\n      public String stringValue() {\n        // TODO: really bad & scary that this causes IW to\n        // abort the segment!!  We should fix this.\n        return null;\n      }\n      \n    });\n    \n    try {\n      iw.addDocument(invalidDoc);\n      iw.commit();\n    }\n    finally {\n      // Abort should have closed the deleter:\n      dir.close();\n    }\n  }\n\n","bugFix":["70b55953b6a72596cb534ead735a8b849a473cac","9299079153fd7895bf3cf6835cf7019af2ba89b3","25308800fd7565ab31e6353077a56bba68fb0668"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b52491e71f0d5d0f0160d6ed0d39e0dd661be68a","date":1429550638,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/test-framework/src/test/org/apache/lucene/codecs/compressing/TestCompressingStoredFieldsFormat#testDeletePartiallyWrittenFilesIfAbort().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/compressing/TestCompressingStoredFieldsFormat#testDeletePartiallyWrittenFilesIfAbort().mjava","sourceNew":"  public void testDeletePartiallyWrittenFilesIfAbort() throws IOException {\n    Directory dir = newDirectory();\n    // test explicitly needs files to always be actually deleted\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setEnableVirusScanner(false);\n    }\n    IndexWriterConfig iwConf = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwConf.setMaxBufferedDocs(RandomInts.randomIntBetween(random(), 2, 30));\n    iwConf.setCodec(CompressingCodec.randomInstance(random()));\n    // disable CFS because this test checks file names\n    iwConf.setMergePolicy(newLogMergePolicy(false));\n    iwConf.setUseCompoundFile(false);\n\n    // Cannot use RIW because this test wants CFS to stay off:\n    IndexWriter iw = new IndexWriter(dir, iwConf);\n\n    final Document validDoc = new Document();\n    validDoc.add(new IntField(\"id\", 0, Store.YES));\n    iw.addDocument(validDoc);\n    iw.commit();\n    \n    // make sure that #writeField will fail to trigger an abort\n    final Document invalidDoc = new Document();\n    FieldType fieldType = new FieldType();\n    fieldType.setStored(true);\n    invalidDoc.add(new Field(\"invalid\", fieldType) {\n      \n      @Override\n      public String stringValue() {\n        // TODO: really bad & scary that this causes IW to\n        // abort the segment!!  We should fix this.\n        return null;\n      }\n      \n    });\n    \n    try {\n      iw.addDocument(invalidDoc);\n      iw.commit();\n    } catch(IllegalArgumentException iae) {\n      // expected\n      assertEquals(iae, iw.getTragicException());\n    }\n    // Writer should be closed by tragedy\n    assertFalse(iw.isOpen());\n    dir.close();\n  }\n\n","sourceOld":"  public void testDeletePartiallyWrittenFilesIfAbort() throws IOException {\n    Directory dir = newDirectory();\n    // test explicitly needs files to always be actually deleted\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setEnableVirusScanner(false);\n    }\n    IndexWriterConfig iwConf = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwConf.setMaxBufferedDocs(RandomInts.randomIntBetween(random(), 2, 30));\n    iwConf.setCodec(CompressingCodec.randomInstance(random()));\n    // disable CFS because this test checks file names\n    iwConf.setMergePolicy(newLogMergePolicy(false));\n    iwConf.setUseCompoundFile(false);\n\n    // Cannot use RIW because this test wants CFS to stay off:\n    IndexWriter iw = new IndexWriter(dir, iwConf);\n\n    final Document validDoc = new Document();\n    validDoc.add(new IntField(\"id\", 0, Store.YES));\n    iw.addDocument(validDoc);\n    iw.commit();\n    \n    // make sure that #writeField will fail to trigger an abort\n    final Document invalidDoc = new Document();\n    FieldType fieldType = new FieldType();\n    fieldType.setStored(true);\n    invalidDoc.add(new Field(\"invalid\", fieldType) {\n      \n      @Override\n      public String stringValue() {\n        // TODO: really bad & scary that this causes IW to\n        // abort the segment!!  We should fix this.\n        return null;\n      }\n      \n    });\n    \n    try {\n      iw.addDocument(invalidDoc);\n      iw.commit();\n    } catch(IllegalArgumentException iae) {\n      // expected\n      assertEquals(iae, iw.getTragicException());\n    }\n    // Writer should be closed by tragedy\n    assertFalse(iw.isOpen());\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","c5ca059c94d972d0b56f1fefd39024a5a77f992a"],"db5ed22fc16d9c24d899d1b6fd7c088e11d19a03":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["db5ed22fc16d9c24d899d1b6fd7c088e11d19a03"],"98d2deb8c96c79ebef084a1f8e5a1a6c08608f13":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"b52491e71f0d5d0f0160d6ed0d39e0dd661be68a":["e390cd18556ba5c7850f9d277a2977e978bd44be"],"474b77fc1ee62c3fc1c73ceb19cc975cb03667ac":["98d2deb8c96c79ebef084a1f8e5a1a6c08608f13"],"25308800fd7565ab31e6353077a56bba68fb0668":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"088a7ef694fd43d5d9a4d200c4005865f773d1e7":["70b55953b6a72596cb534ead735a8b849a473cac"],"e390cd18556ba5c7850f9d277a2977e978bd44be":["9299079153fd7895bf3cf6835cf7019af2ba89b3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"9299079153fd7895bf3cf6835cf7019af2ba89b3":["474b77fc1ee62c3fc1c73ceb19cc975cb03667ac"],"70b55953b6a72596cb534ead735a8b849a473cac":["c5ca059c94d972d0b56f1fefd39024a5a77f992a"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["088a7ef694fd43d5d9a4d200c4005865f773d1e7"],"c5ca059c94d972d0b56f1fefd39024a5a77f992a":["25308800fd7565ab31e6353077a56bba68fb0668"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b52491e71f0d5d0f0160d6ed0d39e0dd661be68a"]},"commit2Childs":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":[],"db5ed22fc16d9c24d899d1b6fd7c088e11d19a03":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"98d2deb8c96c79ebef084a1f8e5a1a6c08608f13":["474b77fc1ee62c3fc1c73ceb19cc975cb03667ac"],"b52491e71f0d5d0f0160d6ed0d39e0dd661be68a":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"474b77fc1ee62c3fc1c73ceb19cc975cb03667ac":["9299079153fd7895bf3cf6835cf7019af2ba89b3"],"25308800fd7565ab31e6353077a56bba68fb0668":["c5ca059c94d972d0b56f1fefd39024a5a77f992a"],"088a7ef694fd43d5d9a4d200c4005865f773d1e7":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"e390cd18556ba5c7850f9d277a2977e978bd44be":["b52491e71f0d5d0f0160d6ed0d39e0dd661be68a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","25308800fd7565ab31e6353077a56bba68fb0668"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["98d2deb8c96c79ebef084a1f8e5a1a6c08608f13"],"70b55953b6a72596cb534ead735a8b849a473cac":["088a7ef694fd43d5d9a4d200c4005865f773d1e7"],"9299079153fd7895bf3cf6835cf7019af2ba89b3":["e390cd18556ba5c7850f9d277a2977e978bd44be"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["db5ed22fc16d9c24d899d1b6fd7c088e11d19a03"],"c5ca059c94d972d0b56f1fefd39024a5a77f992a":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","70b55953b6a72596cb534ead735a8b849a473cac"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}