{"path":"lucene/test-framework/src/java/org/apache/lucene/codecs/asserting/AssertingPostingsFormat.AssertingFieldsConsumer#write(Fields,NormsProducer).mjava","commits":[{"id":"622a708571e534680618b3c5e0c28ac539a47776","date":1517406892,"type":1,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/codecs/asserting/AssertingPostingsFormat.AssertingFieldsConsumer#write(Fields,NormsProducer).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/codecs/asserting/AssertingPostingsFormat.AssertingFieldsConsumer#write(Fields).mjava","sourceNew":"    @Override\n    public void write(Fields fields, NormsProducer norms) throws IOException {\n      in.write(fields, norms);\n\n      // TODO: more asserts?  can we somehow run a\n      // \"limited\" CheckIndex here???  Or ... can we improve\n      // AssertingFieldsProducer and us it also to wrap the\n      // incoming Fields here?\n \n      String lastField = null;\n\n      for(String field : fields) {\n\n        FieldInfo fieldInfo = writeState.fieldInfos.fieldInfo(field);\n        assert fieldInfo != null;\n        assert lastField == null || lastField.compareTo(field) < 0;\n        lastField = field;\n\n        Terms terms = fields.terms(field);\n        if (terms == null) {\n          continue;\n        }\n        assert terms != null;\n\n        TermsEnum termsEnum = terms.iterator();\n        BytesRefBuilder lastTerm = null;\n        PostingsEnum postingsEnum = null;\n\n        boolean hasFreqs = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0;\n        boolean hasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        boolean hasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        boolean hasPayloads = terms.hasPayloads();\n\n        assert hasPositions == terms.hasPositions();\n        assert hasOffsets == terms.hasOffsets();\n\n        while(true) {\n          BytesRef term = termsEnum.next();\n          if (term == null) {\n            break;\n          }\n          assert lastTerm == null || lastTerm.get().compareTo(term) < 0;\n          if (lastTerm == null) {\n            lastTerm = new BytesRefBuilder();\n            lastTerm.append(term);\n          } else {\n            lastTerm.copyBytes(term);\n          }\n\n          int flags = 0;\n          if (hasPositions == false) {\n            if (hasFreqs) {\n              flags = flags | PostingsEnum.FREQS;\n            }\n            postingsEnum = termsEnum.postings(postingsEnum, flags);\n          } else {\n            flags = PostingsEnum.POSITIONS;\n            if (hasPayloads) {\n              flags |= PostingsEnum.PAYLOADS;\n            }\n            if (hasOffsets) {\n              flags = flags | PostingsEnum.OFFSETS;\n            }\n            postingsEnum = termsEnum.postings(postingsEnum, flags);\n          }\n\n          assert postingsEnum != null : \"termsEnum=\" + termsEnum + \" hasPositions=\" + hasPositions;\n\n          int lastDocID = -1;\n\n          while(true) {\n            int docID = postingsEnum.nextDoc();\n            if (docID == PostingsEnum.NO_MORE_DOCS) {\n              break;\n            }\n            assert docID > lastDocID;\n            lastDocID = docID;\n            if (hasFreqs) {\n              int freq = postingsEnum.freq();\n              assert freq > 0;\n\n              if (hasPositions) {\n                int lastPos = -1;\n                int lastStartOffset = -1;\n                for(int i=0;i<freq;i++) {\n                  int pos = postingsEnum.nextPosition();\n                  assert pos >= lastPos: \"pos=\" + pos + \" vs lastPos=\" + lastPos + \" i=\" + i + \" freq=\" + freq;\n                  assert pos <= IndexWriter.MAX_POSITION: \"pos=\" + pos + \" is > IndexWriter.MAX_POSITION=\" + IndexWriter.MAX_POSITION;\n                  lastPos = pos;\n\n                  if (hasOffsets) {\n                    int startOffset = postingsEnum.startOffset();\n                    int endOffset = postingsEnum.endOffset();\n                    assert endOffset >= startOffset;\n                    assert startOffset >= lastStartOffset;\n                    lastStartOffset = startOffset;\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n\n","sourceOld":"    @Override\n    public void write(Fields fields) throws IOException {\n      in.write(fields);\n\n      // TODO: more asserts?  can we somehow run a\n      // \"limited\" CheckIndex here???  Or ... can we improve\n      // AssertingFieldsProducer and us it also to wrap the\n      // incoming Fields here?\n \n      String lastField = null;\n\n      for(String field : fields) {\n\n        FieldInfo fieldInfo = writeState.fieldInfos.fieldInfo(field);\n        assert fieldInfo != null;\n        assert lastField == null || lastField.compareTo(field) < 0;\n        lastField = field;\n\n        Terms terms = fields.terms(field);\n        if (terms == null) {\n          continue;\n        }\n        assert terms != null;\n\n        TermsEnum termsEnum = terms.iterator();\n        BytesRefBuilder lastTerm = null;\n        PostingsEnum postingsEnum = null;\n\n        boolean hasFreqs = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0;\n        boolean hasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        boolean hasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        boolean hasPayloads = terms.hasPayloads();\n\n        assert hasPositions == terms.hasPositions();\n        assert hasOffsets == terms.hasOffsets();\n\n        while(true) {\n          BytesRef term = termsEnum.next();\n          if (term == null) {\n            break;\n          }\n          assert lastTerm == null || lastTerm.get().compareTo(term) < 0;\n          if (lastTerm == null) {\n            lastTerm = new BytesRefBuilder();\n            lastTerm.append(term);\n          } else {\n            lastTerm.copyBytes(term);\n          }\n\n          int flags = 0;\n          if (hasPositions == false) {\n            if (hasFreqs) {\n              flags = flags | PostingsEnum.FREQS;\n            }\n            postingsEnum = termsEnum.postings(postingsEnum, flags);\n          } else {\n            flags = PostingsEnum.POSITIONS;\n            if (hasPayloads) {\n              flags |= PostingsEnum.PAYLOADS;\n            }\n            if (hasOffsets) {\n              flags = flags | PostingsEnum.OFFSETS;\n            }\n            postingsEnum = termsEnum.postings(postingsEnum, flags);\n          }\n\n          assert postingsEnum != null : \"termsEnum=\" + termsEnum + \" hasPositions=\" + hasPositions;\n\n          int lastDocID = -1;\n\n          while(true) {\n            int docID = postingsEnum.nextDoc();\n            if (docID == PostingsEnum.NO_MORE_DOCS) {\n              break;\n            }\n            assert docID > lastDocID;\n            lastDocID = docID;\n            if (hasFreqs) {\n              int freq = postingsEnum.freq();\n              assert freq > 0;\n\n              if (hasPositions) {\n                int lastPos = -1;\n                int lastStartOffset = -1;\n                for(int i=0;i<freq;i++) {\n                  int pos = postingsEnum.nextPosition();\n                  assert pos >= lastPos: \"pos=\" + pos + \" vs lastPos=\" + lastPos + \" i=\" + i + \" freq=\" + freq;\n                  assert pos <= IndexWriter.MAX_POSITION: \"pos=\" + pos + \" is > IndexWriter.MAX_POSITION=\" + IndexWriter.MAX_POSITION;\n                  lastPos = pos;\n\n                  if (hasOffsets) {\n                    int startOffset = postingsEnum.startOffset();\n                    int endOffset = postingsEnum.endOffset();\n                    assert endOffset >= startOffset;\n                    assert startOffset >= lastStartOffset;\n                    lastStartOffset = startOffset;\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"622a708571e534680618b3c5e0c28ac539a47776":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["622a708571e534680618b3c5e0c28ac539a47776"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["622a708571e534680618b3c5e0c28ac539a47776"],"622a708571e534680618b3c5e0c28ac539a47776":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}