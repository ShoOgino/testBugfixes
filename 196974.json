{"path":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionTokenStream#toAutomaton(TokenStream).mjava","commits":[{"id":"07e29e9a1cbba8cc30091c3e4f8e9eac7ec7d22a","date":1427495869,"type":0,"author":"Areek Zillur","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionTokenStream#toAutomaton(TokenStream).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Converts <code>tokenStream</code> to an automaton\n   */\n  public Automaton toAutomaton(TokenStream tokenStream) throws IOException {\n    // TODO refactor this\n    // maybe we could hook up a modified automaton from TermAutomatonQuery here?\n    Automaton automaton = null;\n    try {\n      // Create corresponding automaton: labels are bytes\n      // from each analyzed token, with byte 0 used as\n      // separator between tokens:\n      final TokenStreamToAutomaton tsta;\n      if (preserveSep) {\n        tsta = new EscapingTokenStreamToAutomaton((char) SEP_LABEL);\n      } else {\n        // When we're not preserving sep, we don't steal 0xff\n        // byte, so we don't need to do any escaping:\n        tsta = new TokenStreamToAutomaton();\n      }\n      tsta.setPreservePositionIncrements(preservePositionIncrements);\n\n      automaton = tsta.toAutomaton(tokenStream);\n    } finally {\n      IOUtils.closeWhileHandlingException(tokenStream);\n    }\n\n    // TODO: we can optimize this somewhat by determinizing\n    // while we convert\n    automaton = replaceSep(automaton, preserveSep, SEP_LABEL);\n    // This automaton should not blow up during determinize:\n    return Operations.determinize(automaton, maxGraphExpansions);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":0,"author":"Ryan Ernst","isMerge":true,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionTokenStream#toAutomaton(TokenStream).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Converts <code>tokenStream</code> to an automaton\n   */\n  public Automaton toAutomaton(TokenStream tokenStream) throws IOException {\n    // TODO refactor this\n    // maybe we could hook up a modified automaton from TermAutomatonQuery here?\n    Automaton automaton = null;\n    try {\n      // Create corresponding automaton: labels are bytes\n      // from each analyzed token, with byte 0 used as\n      // separator between tokens:\n      final TokenStreamToAutomaton tsta;\n      if (preserveSep) {\n        tsta = new EscapingTokenStreamToAutomaton((char) SEP_LABEL);\n      } else {\n        // When we're not preserving sep, we don't steal 0xff\n        // byte, so we don't need to do any escaping:\n        tsta = new TokenStreamToAutomaton();\n      }\n      tsta.setPreservePositionIncrements(preservePositionIncrements);\n\n      automaton = tsta.toAutomaton(tokenStream);\n    } finally {\n      IOUtils.closeWhileHandlingException(tokenStream);\n    }\n\n    // TODO: we can optimize this somewhat by determinizing\n    // while we convert\n    automaton = replaceSep(automaton, preserveSep, SEP_LABEL);\n    // This automaton should not blow up during determinize:\n    return Operations.determinize(automaton, maxGraphExpansions);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8c33f6677a2078739058f81eca1df69d12cd62b0","date":1432799589,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionTokenStream#toAutomaton(boolean).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionTokenStream#toAutomaton(TokenStream).mjava","sourceNew":"  /**\n   * Converts the tokenStream to an automaton\n   */\n  public Automaton toAutomaton(boolean unicodeAware) throws IOException {\n    // TODO refactor this\n    // maybe we could hook up a modified automaton from TermAutomatonQuery here?\n    Automaton automaton = null;\n    try {\n      // Create corresponding automaton: labels are bytes\n      // from each analyzed token, with byte 0 used as\n      // separator between tokens:\n      final TokenStreamToAutomaton tsta;\n      if (preserveSep) {\n        tsta = new EscapingTokenStreamToAutomaton((char) SEP_LABEL);\n      } else {\n        // When we're not preserving sep, we don't steal 0xff\n        // byte, so we don't need to do any escaping:\n        tsta = new TokenStreamToAutomaton();\n      }\n      tsta.setPreservePositionIncrements(preservePositionIncrements);\n      tsta.setUnicodeArcs(unicodeAware);\n\n      automaton = tsta.toAutomaton(input);\n    } finally {\n      IOUtils.closeWhileHandlingException(input);\n    }\n\n    // TODO: we can optimize this somewhat by determinizing\n    // while we convert\n    automaton = replaceSep(automaton, preserveSep, SEP_LABEL);\n    // This automaton should not blow up during determinize:\n    return Operations.determinize(automaton, maxGraphExpansions);\n  }\n\n","sourceOld":"  /**\n   * Converts <code>tokenStream</code> to an automaton\n   */\n  public Automaton toAutomaton(TokenStream tokenStream) throws IOException {\n    // TODO refactor this\n    // maybe we could hook up a modified automaton from TermAutomatonQuery here?\n    Automaton automaton = null;\n    try {\n      // Create corresponding automaton: labels are bytes\n      // from each analyzed token, with byte 0 used as\n      // separator between tokens:\n      final TokenStreamToAutomaton tsta;\n      if (preserveSep) {\n        tsta = new EscapingTokenStreamToAutomaton((char) SEP_LABEL);\n      } else {\n        // When we're not preserving sep, we don't steal 0xff\n        // byte, so we don't need to do any escaping:\n        tsta = new TokenStreamToAutomaton();\n      }\n      tsta.setPreservePositionIncrements(preservePositionIncrements);\n\n      automaton = tsta.toAutomaton(tokenStream);\n    } finally {\n      IOUtils.closeWhileHandlingException(tokenStream);\n    }\n\n    // TODO: we can optimize this somewhat by determinizing\n    // while we convert\n    automaton = replaceSep(automaton, preserveSep, SEP_LABEL);\n    // This automaton should not blow up during determinize:\n    return Operations.determinize(automaton, maxGraphExpansions);\n  }\n\n","bugFix":null,"bugIntro":["509ddf2b18aec24f54a1cbabf7d15ed537d61ff2"],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","07e29e9a1cbba8cc30091c3e4f8e9eac7ec7d22a"],"07e29e9a1cbba8cc30091c3e4f8e9eac7ec7d22a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"8c33f6677a2078739058f81eca1df69d12cd62b0":["07e29e9a1cbba8cc30091c3e4f8e9eac7ec7d22a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["8c33f6677a2078739058f81eca1df69d12cd62b0"]},"commit2Childs":{"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"07e29e9a1cbba8cc30091c3e4f8e9eac7ec7d22a":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","8c33f6677a2078739058f81eca1df69d12cd62b0"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","07e29e9a1cbba8cc30091c3e4f8e9eac7ec7d22a"],"8c33f6677a2078739058f81eca1df69d12cd62b0":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}