{"path":"solr/core/src/test/org/apache/solr/store/blockcache/BlockCacheTest#testCacheConcurrent().mjava","commits":[{"id":"8702182bc92026984124976ef1fa3393bdcbbc05","date":1487384465,"type":0,"author":"yonik","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/store/blockcache/BlockCacheTest#testCacheConcurrent().mjava","pathOld":"/dev/null","sourceNew":"  // Sanity test the underlying concurrent map that BlockCache is using, in the same way that we use it.\n  @Test\n  @AwaitsFix(bugUrl = \"https://issues.apache.org/jira/browse/SOLR-10141\")\n  public void testCacheConcurrent() throws Exception {\n    Random rnd = random();\n\n    final int blocksInTest = 400;\n    final int maxEntries = blocksInTest/2;\n\n    final int nThreads=64;\n    final int nReads=10000000;\n    final int readsPerThread=nReads/nThreads;\n    final int readLastBlockOdds=10; // odds (1 in N) of the next block operation being on the same block as the previous operation... helps flush concurrency issues\n    final boolean updateAnyway = true; // sometimes insert a new entry for the key even if one was found\n\n    final AtomicLong hits = new AtomicLong();\n    final AtomicLong removals = new AtomicLong();\n    final AtomicLong inserts = new AtomicLong();\n\n    RemovalListener<Long,Val> listener = (k, v, removalCause) -> {\n      assert v.key == k;\n      if (!v.live.compareAndSet(true, false)) {\n        throw new RuntimeException(\"listener called more than once! k=\" + k + \" v=\" + v + \" removalCause=\" + removalCause);\n        // return;  // use this variant if listeners may be called more than once\n      }\n      removals.incrementAndGet();\n    };\n\n\n    com.github.benmanes.caffeine.cache.Cache<Long,Val> cache = Caffeine.newBuilder()\n        .removalListener(listener)\n        .maximumSize(maxEntries)\n        .executor(Runnable::run)\n        .build();\n\n    final AtomicBoolean failed = new AtomicBoolean(false);\n    final AtomicLong lastBlock = new AtomicLong();\n    final AtomicLong maxObservedSize = new AtomicLong();\n\n    Thread[] threads = new Thread[nThreads];\n    for (int i=0; i<threads.length; i++) {\n      final long seed = rnd.nextLong();\n\n      threads[i] = new Thread() {\n        Random r;\n        @Override\n        public void run() {\n          try {\n            r = new Random(seed);\n            test(readsPerThread);\n          } catch (Throwable e) {\n            failed.set(true);\n            e.printStackTrace();\n          }\n        }\n\n        public void test(int iter) {\n          for (int i=0; i<iter; i++) {\n            test();\n          }\n        }\n\n        public void test() {\n          long block = r.nextInt(blocksInTest);\n          if (readLastBlockOdds > 0 && r.nextInt(readLastBlockOdds) == 0) block = lastBlock.get();  // some percent of the time, try to read the last block another thread was just reading/writing\n          lastBlock.set(block);\n\n          Long k = block;\n          Val v = cache.getIfPresent(k);\n          if (v != null) {\n            hits.incrementAndGet();\n            assert k.equals(v.key);\n          }\n\n          if (v == null || updateAnyway && r.nextBoolean()) {\n            v = new Val();\n            v.key = k;\n            cache.put(k, v);\n            inserts.incrementAndGet();\n          }\n\n          long sz = cache.asMap().size();\n          if (sz > maxObservedSize.get()) maxObservedSize.set(sz);  // race condition here, but an estimate is OK\n\n        }\n      };\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n\n    // Thread.sleep(1000); // need to wait if executor is used for listener?\n    long cacheSize = cache.asMap().size();\n    System.out.println(\"Done! # of Elements = \" + cacheSize + \" inserts=\" + inserts.get() + \" removals=\" + removals.get() + \" hits=\" + hits.get() +  \" maxObservedSize=\" + maxObservedSize);\n    assert inserts.get() - removals.get() == cacheSize;\n    assertFalse( failed.get() );\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["bc0da9d1991d13114641b7b59db56458cde6af62"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bc0da9d1991d13114641b7b59db56458cde6af62","date":1487715305,"type":3,"author":"yonik","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/store/blockcache/BlockCacheTest#testCacheConcurrent().mjava","pathOld":"solr/core/src/test/org/apache/solr/store/blockcache/BlockCacheTest#testCacheConcurrent().mjava","sourceNew":"  // Sanity test the underlying concurrent map that BlockCache is using, in the same way that we use it.\n  @Test\n  public void testCacheConcurrent() throws Exception {\n    Random rnd = random();\n\n    // TODO: introduce more randomness in cache size, hit rate, etc\n    final int blocksInTest = 400;\n    final int maxEntries = blocksInTest/2;\n\n    final int nThreads=64;\n    final int nReads=1000000;\n    final int readsPerThread=nReads/nThreads;\n    final int readLastBlockOdds=10; // odds (1 in N) of the next block operation being on the same block as the previous operation... helps flush concurrency issues\n    final boolean updateAnyway = true; // sometimes insert a new entry for the key even if one was found\n\n    final AtomicLong hits = new AtomicLong();\n    final AtomicLong removals = new AtomicLong();\n    final AtomicLong inserts = new AtomicLong();\n\n    RemovalListener<Long,Val> listener = (k, v, removalCause) -> {\n      assert v.key == k;\n      if (!v.live.compareAndSet(true, false)) {\n        throw new RuntimeException(\"listener called more than once! k=\" + k + \" v=\" + v + \" removalCause=\" + removalCause);\n        // return;  // use this variant if listeners may be called more than once\n      }\n      removals.incrementAndGet();\n    };\n\n\n    com.github.benmanes.caffeine.cache.Cache<Long,Val> cache = Caffeine.newBuilder()\n        .removalListener(listener)\n        .maximumSize(maxEntries)\n        .executor(Runnable::run)\n        .build();\n\n    final AtomicBoolean failed = new AtomicBoolean(false);\n    final AtomicLong lastBlock = new AtomicLong();\n    final AtomicLong maxObservedSize = new AtomicLong();\n\n    Thread[] threads = new Thread[nThreads];\n    for (int i=0; i<threads.length; i++) {\n      final long seed = rnd.nextLong();\n\n      threads[i] = new Thread() {\n        Random r;\n        @Override\n        public void run() {\n          try {\n            r = new Random(seed);\n            test(readsPerThread);\n          } catch (Throwable e) {\n            failed.set(true);\n            e.printStackTrace();\n          }\n        }\n\n        public void test(int iter) {\n          for (int i=0; i<iter; i++) {\n            test();\n          }\n        }\n\n        public void test() {\n          long block = r.nextInt(blocksInTest);\n          if (readLastBlockOdds > 0 && r.nextInt(readLastBlockOdds) == 0) block = lastBlock.get();  // some percent of the time, try to read the last block another thread was just reading/writing\n          lastBlock.set(block);\n\n          Long k = block;\n          Val v = cache.getIfPresent(k);\n          if (v != null) {\n            hits.incrementAndGet();\n            assert k.equals(v.key);\n          }\n\n          if (v == null || updateAnyway && r.nextBoolean()) {\n            v = new Val();\n            v.key = k;\n            cache.put(k, v);\n            inserts.incrementAndGet();\n          }\n\n          long sz = cache.asMap().size();\n          if (sz > maxObservedSize.get()) maxObservedSize.set(sz);  // race condition here, but an estimate is OK\n\n        }\n      };\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n\n    // Thread.sleep(1000); // need to wait if executor is used for listener?\n    long cacheSize = cache.asMap().size();\n    System.out.println(\"Done! # of Elements = \" + cacheSize + \" inserts=\" + inserts.get() + \" removals=\" + removals.get() + \" hits=\" + hits.get() +  \" maxObservedSize=\" + maxObservedSize);\n    assert inserts.get() - removals.get() == cacheSize;\n    assertFalse( failed.get() );\n  }\n\n","sourceOld":"  // Sanity test the underlying concurrent map that BlockCache is using, in the same way that we use it.\n  @Test\n  @AwaitsFix(bugUrl = \"https://issues.apache.org/jira/browse/SOLR-10141\")\n  public void testCacheConcurrent() throws Exception {\n    Random rnd = random();\n\n    final int blocksInTest = 400;\n    final int maxEntries = blocksInTest/2;\n\n    final int nThreads=64;\n    final int nReads=10000000;\n    final int readsPerThread=nReads/nThreads;\n    final int readLastBlockOdds=10; // odds (1 in N) of the next block operation being on the same block as the previous operation... helps flush concurrency issues\n    final boolean updateAnyway = true; // sometimes insert a new entry for the key even if one was found\n\n    final AtomicLong hits = new AtomicLong();\n    final AtomicLong removals = new AtomicLong();\n    final AtomicLong inserts = new AtomicLong();\n\n    RemovalListener<Long,Val> listener = (k, v, removalCause) -> {\n      assert v.key == k;\n      if (!v.live.compareAndSet(true, false)) {\n        throw new RuntimeException(\"listener called more than once! k=\" + k + \" v=\" + v + \" removalCause=\" + removalCause);\n        // return;  // use this variant if listeners may be called more than once\n      }\n      removals.incrementAndGet();\n    };\n\n\n    com.github.benmanes.caffeine.cache.Cache<Long,Val> cache = Caffeine.newBuilder()\n        .removalListener(listener)\n        .maximumSize(maxEntries)\n        .executor(Runnable::run)\n        .build();\n\n    final AtomicBoolean failed = new AtomicBoolean(false);\n    final AtomicLong lastBlock = new AtomicLong();\n    final AtomicLong maxObservedSize = new AtomicLong();\n\n    Thread[] threads = new Thread[nThreads];\n    for (int i=0; i<threads.length; i++) {\n      final long seed = rnd.nextLong();\n\n      threads[i] = new Thread() {\n        Random r;\n        @Override\n        public void run() {\n          try {\n            r = new Random(seed);\n            test(readsPerThread);\n          } catch (Throwable e) {\n            failed.set(true);\n            e.printStackTrace();\n          }\n        }\n\n        public void test(int iter) {\n          for (int i=0; i<iter; i++) {\n            test();\n          }\n        }\n\n        public void test() {\n          long block = r.nextInt(blocksInTest);\n          if (readLastBlockOdds > 0 && r.nextInt(readLastBlockOdds) == 0) block = lastBlock.get();  // some percent of the time, try to read the last block another thread was just reading/writing\n          lastBlock.set(block);\n\n          Long k = block;\n          Val v = cache.getIfPresent(k);\n          if (v != null) {\n            hits.incrementAndGet();\n            assert k.equals(v.key);\n          }\n\n          if (v == null || updateAnyway && r.nextBoolean()) {\n            v = new Val();\n            v.key = k;\n            cache.put(k, v);\n            inserts.incrementAndGet();\n          }\n\n          long sz = cache.asMap().size();\n          if (sz > maxObservedSize.get()) maxObservedSize.set(sz);  // race condition here, but an estimate is OK\n\n        }\n      };\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n\n    // Thread.sleep(1000); // need to wait if executor is used for listener?\n    long cacheSize = cache.asMap().size();\n    System.out.println(\"Done! # of Elements = \" + cacheSize + \" inserts=\" + inserts.get() + \" removals=\" + removals.get() + \" hits=\" + hits.get() +  \" maxObservedSize=\" + maxObservedSize);\n    assert inserts.get() - removals.get() == cacheSize;\n    assertFalse( failed.get() );\n  }\n\n","bugFix":["8702182bc92026984124976ef1fa3393bdcbbc05"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"22ed7c5d31f5bc56287c6c61a259c48159dad150","date":1488376297,"type":3,"author":"yonik","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/store/blockcache/BlockCacheTest#testCacheConcurrent().mjava","pathOld":"solr/core/src/test/org/apache/solr/store/blockcache/BlockCacheTest#testCacheConcurrent().mjava","sourceNew":"  // Sanity test the underlying concurrent map that BlockCache is using, in the same way that we use it.\n  @Test\n  public void testCacheConcurrent() throws Exception {\n    Random rnd = random();\n\n    // TODO: introduce more randomness in cache size, hit rate, etc\n    final int blocksInTest = 400;\n    final int maxEntries = blocksInTest/2;\n\n    final int nThreads=64;\n    final int nReads=1000000;\n    final int readsPerThread=nReads/nThreads;\n    final int readLastBlockOdds=10; // odds (1 in N) of the next block operation being on the same block as the previous operation... helps flush concurrency issues\n    final int updateAnywayOdds = 3; // sometimes insert a new entry for the key even if one was found\n    final int invalidateOdds = 20; // sometimes invalidate an entry\n\n    final AtomicLong hits = new AtomicLong();\n    final AtomicLong removals = new AtomicLong();\n    final AtomicLong inserts = new AtomicLong();\n\n    RemovalListener<Long,Val> listener = (k, v, removalCause) -> {\n      assert v.key == k;\n      if (!v.live.compareAndSet(true, false)) {\n        throw new RuntimeException(\"listener called more than once! k=\" + k + \" v=\" + v + \" removalCause=\" + removalCause);\n        // return;  // use this variant if listeners may be called more than once\n      }\n      removals.incrementAndGet();\n    };\n\n\n    com.github.benmanes.caffeine.cache.Cache<Long,Val> cache = Caffeine.newBuilder()\n        .removalListener(listener)\n        .maximumSize(maxEntries)\n        .executor(Runnable::run)\n        .build();\n\n    final AtomicBoolean failed = new AtomicBoolean(false);\n    final AtomicLong lastBlock = new AtomicLong();\n    final AtomicLong maxObservedSize = new AtomicLong();\n\n    Thread[] threads = new Thread[nThreads];\n    for (int i=0; i<threads.length; i++) {\n      final long seed = rnd.nextLong();\n\n      threads[i] = new Thread() {\n        Random r;\n        @Override\n        public void run() {\n          try {\n            r = new Random(seed);\n            test(readsPerThread);\n          } catch (Throwable e) {\n            failed.set(true);\n            e.printStackTrace();\n          }\n        }\n\n        public void test(int iter) {\n          for (int i=0; i<iter; i++) {\n            test();\n          }\n        }\n\n        boolean odds(int odds) {\n          return odds > 0 && r.nextInt(odds)==0;\n        }\n\n        long getBlock() {\n          long block;\n          if (odds(readLastBlockOdds)) {\n            block = lastBlock.get();  // some percent of the time, try to read the last block another thread was just reading/writing\n          } else {\n            block = r.nextInt(blocksInTest);\n            lastBlock.set(block);\n          }\n          return block;\n        }\n\n        public void test() {\n          Long k = getBlock();\n\n          if (odds(invalidateOdds)) {\n            // This tests that invalidate always ends up calling the removal listener exactly once\n            // even if the entry may be in the process of concurrent removal in a different thread.\n            // This also inadvertently tests concurrently inserting, getting, and invalidating the same key, which we don't need in Solr's BlockCache.\n            cache.invalidate(k);\n          }\n\n          Val v = cache.getIfPresent(k);\n          if (v != null) {\n            hits.incrementAndGet();\n            assert k.equals(v.key);\n          }\n\n          if (v == null || odds(updateAnywayOdds)) {\n            v = new Val();\n            v.key = k;\n            cache.put(k, v);\n            inserts.incrementAndGet();\n          }\n\n          long sz = cache.estimatedSize();\n          if (sz > maxObservedSize.get()) maxObservedSize.set(sz);  // race condition here, but an estimate is OK\n\n        }\n      };\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n\n    // Thread.sleep(1000); // need to wait if executor is used for listener?\n    long cacheSize = cache.estimatedSize();\n    System.out.println(\"Done! # of Elements = \" + cacheSize + \" inserts=\" + inserts.get() + \" removals=\" + removals.get() + \" hits=\" + hits.get() +  \" maxObservedSize=\" + maxObservedSize);\n    assert inserts.get() - removals.get() == cacheSize;\n    assertFalse( failed.get() );\n  }\n\n","sourceOld":"  // Sanity test the underlying concurrent map that BlockCache is using, in the same way that we use it.\n  @Test\n  public void testCacheConcurrent() throws Exception {\n    Random rnd = random();\n\n    // TODO: introduce more randomness in cache size, hit rate, etc\n    final int blocksInTest = 400;\n    final int maxEntries = blocksInTest/2;\n\n    final int nThreads=64;\n    final int nReads=1000000;\n    final int readsPerThread=nReads/nThreads;\n    final int readLastBlockOdds=10; // odds (1 in N) of the next block operation being on the same block as the previous operation... helps flush concurrency issues\n    final boolean updateAnyway = true; // sometimes insert a new entry for the key even if one was found\n\n    final AtomicLong hits = new AtomicLong();\n    final AtomicLong removals = new AtomicLong();\n    final AtomicLong inserts = new AtomicLong();\n\n    RemovalListener<Long,Val> listener = (k, v, removalCause) -> {\n      assert v.key == k;\n      if (!v.live.compareAndSet(true, false)) {\n        throw new RuntimeException(\"listener called more than once! k=\" + k + \" v=\" + v + \" removalCause=\" + removalCause);\n        // return;  // use this variant if listeners may be called more than once\n      }\n      removals.incrementAndGet();\n    };\n\n\n    com.github.benmanes.caffeine.cache.Cache<Long,Val> cache = Caffeine.newBuilder()\n        .removalListener(listener)\n        .maximumSize(maxEntries)\n        .executor(Runnable::run)\n        .build();\n\n    final AtomicBoolean failed = new AtomicBoolean(false);\n    final AtomicLong lastBlock = new AtomicLong();\n    final AtomicLong maxObservedSize = new AtomicLong();\n\n    Thread[] threads = new Thread[nThreads];\n    for (int i=0; i<threads.length; i++) {\n      final long seed = rnd.nextLong();\n\n      threads[i] = new Thread() {\n        Random r;\n        @Override\n        public void run() {\n          try {\n            r = new Random(seed);\n            test(readsPerThread);\n          } catch (Throwable e) {\n            failed.set(true);\n            e.printStackTrace();\n          }\n        }\n\n        public void test(int iter) {\n          for (int i=0; i<iter; i++) {\n            test();\n          }\n        }\n\n        public void test() {\n          long block = r.nextInt(blocksInTest);\n          if (readLastBlockOdds > 0 && r.nextInt(readLastBlockOdds) == 0) block = lastBlock.get();  // some percent of the time, try to read the last block another thread was just reading/writing\n          lastBlock.set(block);\n\n          Long k = block;\n          Val v = cache.getIfPresent(k);\n          if (v != null) {\n            hits.incrementAndGet();\n            assert k.equals(v.key);\n          }\n\n          if (v == null || updateAnyway && r.nextBoolean()) {\n            v = new Val();\n            v.key = k;\n            cache.put(k, v);\n            inserts.incrementAndGet();\n          }\n\n          long sz = cache.asMap().size();\n          if (sz > maxObservedSize.get()) maxObservedSize.set(sz);  // race condition here, but an estimate is OK\n\n        }\n      };\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n\n    // Thread.sleep(1000); // need to wait if executor is used for listener?\n    long cacheSize = cache.asMap().size();\n    System.out.println(\"Done! # of Elements = \" + cacheSize + \" inserts=\" + inserts.get() + \" removals=\" + removals.get() + \" hits=\" + hits.get() +  \" maxObservedSize=\" + maxObservedSize);\n    assert inserts.get() - removals.get() == cacheSize;\n    assertFalse( failed.get() );\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"87f0484c38f986062889ed50f3bf3bd462848c26","date":1570108628,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/store/blockcache/BlockCacheTest#testCacheConcurrent().mjava","pathOld":"solr/core/src/test/org/apache/solr/store/blockcache/BlockCacheTest#testCacheConcurrent().mjava","sourceNew":"  // Sanity test the underlying concurrent map that BlockCache is using, in the same way that we use it.\n  @Test\n  public void testCacheConcurrent() throws Exception {\n    Random rnd = random();\n\n    // TODO: introduce more randomness in cache size, hit rate, etc\n    final int blocksInTest = 400;\n    final int maxEntries = blocksInTest / 2;\n\n    final int nThreads = 64;\n    final int nReads = 1000000;\n    final int readsPerThread = nReads / nThreads;\n    final int readLastBlockOdds = 10; // odds (1 in N) of the next block operation being on the same block as the previous operation... helps flush concurrency issues\n    final int updateAnywayOdds = 3; // sometimes insert a new entry for the key even if one was found\n    final int invalidateOdds = 20; // sometimes invalidate an entry\n\n    final AtomicLong hits = new AtomicLong();\n    final AtomicLong removals = new AtomicLong();\n    final AtomicLong inserts = new AtomicLong();\n\n    RemovalListener<Long, Val> listener = (k, v, removalCause) -> {\n      removals.incrementAndGet();\n      if (v == null) {\n        if (removalCause != RemovalCause.COLLECTED) {\n          throw new RuntimeException(\"Null value for key \" + k + \", removalCause=\" + removalCause);\n        } else {\n          return;\n        }\n      }\n      assertEquals(\"cache key differs from value's key\", (Long) k, (Long) v.key);\n      if (!v.live.compareAndSet(true, false)) {\n        throw new RuntimeException(\"listener called more than once! k=\" + k + \" v=\" + v + \" removalCause=\" + removalCause);\n        // return;  // use this variant if listeners may be called more than once\n      }\n    };\n\n\n    com.github.benmanes.caffeine.cache.Cache<Long, Val> cache = Caffeine.newBuilder()\n        .removalListener(listener)\n        .maximumSize(maxEntries)\n        .executor(Runnable::run)\n        .build();\n\n    final AtomicBoolean failed = new AtomicBoolean(false);\n    final AtomicLong lastBlock = new AtomicLong();\n    final AtomicLong maxObservedSize = new AtomicLong();\n\n    Thread[] threads = new Thread[nThreads];\n    for (int i = 0; i < threads.length; i++) {\n      final long seed = rnd.nextLong();\n\n      threads[i] = new Thread() {\n        Random r;\n\n        @Override\n        public void run() {\n          try {\n            r = new Random(seed);\n            test(readsPerThread);\n          } catch (Throwable e) {\n            failed.set(true);\n            e.printStackTrace();\n          }\n        }\n\n        public void test(int iter) {\n          for (int i = 0; i < iter; i++) {\n            test();\n          }\n        }\n\n        boolean odds(int odds) {\n          return odds > 0 && r.nextInt(odds) == 0;\n        }\n\n        long getBlock() {\n          long block;\n          if (odds(readLastBlockOdds)) {\n            block = lastBlock.get();  // some percent of the time, try to read the last block another thread was just reading/writing\n          } else {\n            block = r.nextInt(blocksInTest);\n            lastBlock.set(block);\n          }\n          return block;\n        }\n\n        public void test() {\n          Long k = getBlock();\n\n          if (odds(invalidateOdds)) {\n            // This tests that invalidate always ends up calling the removal listener exactly once\n            // even if the entry may be in the process of concurrent removal in a different thread.\n            // This also inadvertently tests concurrently inserting, getting, and invalidating the same key, which we don't need in Solr's BlockCache.\n            cache.invalidate(k);\n          }\n\n          Val v = cache.getIfPresent(k);\n          if (v != null) {\n            hits.incrementAndGet();\n            assertEquals(\"cache key differs from value's key\", (Long) k, (Long) v.key);\n          }\n\n          if (v == null || odds(updateAnywayOdds)) {\n            v = new Val();\n            v.key = k;\n            cache.put(k, v);\n            inserts.incrementAndGet();\n          }\n\n          long sz = cache.estimatedSize();\n          if (sz > maxObservedSize.get()) maxObservedSize.set(sz);  // race condition here, but an estimate is OK\n\n        }\n      };\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n\n    // Thread.sleep(1000); // need to wait if executor is used for listener?\n    long cacheSize = cache.estimatedSize();\n    System.out.println(\"Done! # of Elements = \" + cacheSize + \" inserts=\" + inserts.get() + \" removals=\" + removals.get() + \" hits=\" + hits.get() + \" maxObservedSize=\" + maxObservedSize);\n    assertEquals(\"cache size different from (inserts - removal)\", cacheSize,  inserts.get() - removals.get());\n    assertFalse(failed.get());\n  }\n\n","sourceOld":"  // Sanity test the underlying concurrent map that BlockCache is using, in the same way that we use it.\n  @Test\n  public void testCacheConcurrent() throws Exception {\n    Random rnd = random();\n\n    // TODO: introduce more randomness in cache size, hit rate, etc\n    final int blocksInTest = 400;\n    final int maxEntries = blocksInTest/2;\n\n    final int nThreads=64;\n    final int nReads=1000000;\n    final int readsPerThread=nReads/nThreads;\n    final int readLastBlockOdds=10; // odds (1 in N) of the next block operation being on the same block as the previous operation... helps flush concurrency issues\n    final int updateAnywayOdds = 3; // sometimes insert a new entry for the key even if one was found\n    final int invalidateOdds = 20; // sometimes invalidate an entry\n\n    final AtomicLong hits = new AtomicLong();\n    final AtomicLong removals = new AtomicLong();\n    final AtomicLong inserts = new AtomicLong();\n\n    RemovalListener<Long,Val> listener = (k, v, removalCause) -> {\n      assert v.key == k;\n      if (!v.live.compareAndSet(true, false)) {\n        throw new RuntimeException(\"listener called more than once! k=\" + k + \" v=\" + v + \" removalCause=\" + removalCause);\n        // return;  // use this variant if listeners may be called more than once\n      }\n      removals.incrementAndGet();\n    };\n\n\n    com.github.benmanes.caffeine.cache.Cache<Long,Val> cache = Caffeine.newBuilder()\n        .removalListener(listener)\n        .maximumSize(maxEntries)\n        .executor(Runnable::run)\n        .build();\n\n    final AtomicBoolean failed = new AtomicBoolean(false);\n    final AtomicLong lastBlock = new AtomicLong();\n    final AtomicLong maxObservedSize = new AtomicLong();\n\n    Thread[] threads = new Thread[nThreads];\n    for (int i=0; i<threads.length; i++) {\n      final long seed = rnd.nextLong();\n\n      threads[i] = new Thread() {\n        Random r;\n        @Override\n        public void run() {\n          try {\n            r = new Random(seed);\n            test(readsPerThread);\n          } catch (Throwable e) {\n            failed.set(true);\n            e.printStackTrace();\n          }\n        }\n\n        public void test(int iter) {\n          for (int i=0; i<iter; i++) {\n            test();\n          }\n        }\n\n        boolean odds(int odds) {\n          return odds > 0 && r.nextInt(odds)==0;\n        }\n\n        long getBlock() {\n          long block;\n          if (odds(readLastBlockOdds)) {\n            block = lastBlock.get();  // some percent of the time, try to read the last block another thread was just reading/writing\n          } else {\n            block = r.nextInt(blocksInTest);\n            lastBlock.set(block);\n          }\n          return block;\n        }\n\n        public void test() {\n          Long k = getBlock();\n\n          if (odds(invalidateOdds)) {\n            // This tests that invalidate always ends up calling the removal listener exactly once\n            // even if the entry may be in the process of concurrent removal in a different thread.\n            // This also inadvertently tests concurrently inserting, getting, and invalidating the same key, which we don't need in Solr's BlockCache.\n            cache.invalidate(k);\n          }\n\n          Val v = cache.getIfPresent(k);\n          if (v != null) {\n            hits.incrementAndGet();\n            assert k.equals(v.key);\n          }\n\n          if (v == null || odds(updateAnywayOdds)) {\n            v = new Val();\n            v.key = k;\n            cache.put(k, v);\n            inserts.incrementAndGet();\n          }\n\n          long sz = cache.estimatedSize();\n          if (sz > maxObservedSize.get()) maxObservedSize.set(sz);  // race condition here, but an estimate is OK\n\n        }\n      };\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n\n    // Thread.sleep(1000); // need to wait if executor is used for listener?\n    long cacheSize = cache.estimatedSize();\n    System.out.println(\"Done! # of Elements = \" + cacheSize + \" inserts=\" + inserts.get() + \" removals=\" + removals.get() + \" hits=\" + hits.get() +  \" maxObservedSize=\" + maxObservedSize);\n    assert inserts.get() - removals.get() == cacheSize;\n    assertFalse( failed.get() );\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b0b597c65628ca9e73913a07e81691f8229bae35","date":1571224353,"type":3,"author":"jimczi","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/store/blockcache/BlockCacheTest#testCacheConcurrent().mjava","pathOld":"solr/core/src/test/org/apache/solr/store/blockcache/BlockCacheTest#testCacheConcurrent().mjava","sourceNew":"  // Sanity test the underlying concurrent map that BlockCache is using, in the same way that we use it.\n  @Test\n  public void testCacheConcurrent() throws Exception {\n    Random rnd = random();\n\n    // TODO: introduce more randomness in cache size, hit rate, etc\n    final int blocksInTest = 400;\n    final int maxEntries = blocksInTest / 2;\n\n    final int nThreads = 64;\n    final int nReads = 1000000;\n    final int readsPerThread = nReads / nThreads;\n    final int readLastBlockOdds = 10; // odds (1 in N) of the next block operation being on the same block as the previous operation... helps flush concurrency issues\n    final int updateAnywayOdds = 3; // sometimes insert a new entry for the key even if one was found\n    final int invalidateOdds = 20; // sometimes invalidate an entry\n\n    final AtomicLong hits = new AtomicLong();\n    final AtomicLong removals = new AtomicLong();\n    final AtomicLong inserts = new AtomicLong();\n\n    RemovalListener<Long, Val> listener = (k, v, removalCause) -> {\n      removals.incrementAndGet();\n      if (v == null) {\n        if (removalCause != RemovalCause.COLLECTED) {\n          throw new RuntimeException(\"Null value for key \" + k + \", removalCause=\" + removalCause);\n        } else {\n          return;\n        }\n      }\n      assertEquals(\"cache key differs from value's key\", (Long) k, (Long) v.key);\n      if (!v.live.compareAndSet(true, false)) {\n        throw new RuntimeException(\"listener called more than once! k=\" + k + \" v=\" + v + \" removalCause=\" + removalCause);\n        // return;  // use this variant if listeners may be called more than once\n      }\n    };\n\n\n    com.github.benmanes.caffeine.cache.Cache<Long, Val> cache = Caffeine.newBuilder()\n        .removalListener(listener)\n        .maximumSize(maxEntries)\n        .executor(Runnable::run)\n        .build();\n\n    final AtomicBoolean failed = new AtomicBoolean(false);\n    final AtomicLong lastBlock = new AtomicLong();\n    final AtomicLong maxObservedSize = new AtomicLong();\n\n    Thread[] threads = new Thread[nThreads];\n    for (int i = 0; i < threads.length; i++) {\n      final long seed = rnd.nextLong();\n\n      threads[i] = new Thread() {\n        Random r;\n\n        @Override\n        public void run() {\n          try {\n            r = new Random(seed);\n            test(readsPerThread);\n          } catch (Throwable e) {\n            failed.set(true);\n            e.printStackTrace();\n          }\n        }\n\n        public void test(int iter) {\n          for (int i = 0; i < iter; i++) {\n            test();\n          }\n        }\n\n        boolean odds(int odds) {\n          return odds > 0 && r.nextInt(odds) == 0;\n        }\n\n        long getBlock() {\n          long block;\n          if (odds(readLastBlockOdds)) {\n            block = lastBlock.get();  // some percent of the time, try to read the last block another thread was just reading/writing\n          } else {\n            block = r.nextInt(blocksInTest);\n            lastBlock.set(block);\n          }\n          return block;\n        }\n\n        public void test() {\n          Long k = getBlock();\n\n          if (odds(invalidateOdds)) {\n            // This tests that invalidate always ends up calling the removal listener exactly once\n            // even if the entry may be in the process of concurrent removal in a different thread.\n            // This also inadvertently tests concurrently inserting, getting, and invalidating the same key, which we don't need in Solr's BlockCache.\n            cache.invalidate(k);\n          }\n\n          Val v = cache.getIfPresent(k);\n          if (v != null) {\n            hits.incrementAndGet();\n            assertEquals(\"cache key differs from value's key\", (Long) k, (Long) v.key);\n          }\n\n          if (v == null || odds(updateAnywayOdds)) {\n            v = new Val();\n            v.key = k;\n            cache.put(k, v);\n            inserts.incrementAndGet();\n          }\n\n          long sz = cache.estimatedSize();\n          if (sz > maxObservedSize.get()) maxObservedSize.set(sz);  // race condition here, but an estimate is OK\n\n        }\n      };\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n\n    // Thread.sleep(1000); // need to wait if executor is used for listener?\n    long cacheSize = cache.estimatedSize();\n    System.out.println(\"Done! # of Elements = \" + cacheSize + \" inserts=\" + inserts.get() + \" removals=\" + removals.get() + \" hits=\" + hits.get() + \" maxObservedSize=\" + maxObservedSize);\n    assertEquals(\"cache size different from (inserts - removal)\", cacheSize,  inserts.get() - removals.get());\n    assertFalse(failed.get());\n  }\n\n","sourceOld":"  // Sanity test the underlying concurrent map that BlockCache is using, in the same way that we use it.\n  @Test\n  public void testCacheConcurrent() throws Exception {\n    Random rnd = random();\n\n    // TODO: introduce more randomness in cache size, hit rate, etc\n    final int blocksInTest = 400;\n    final int maxEntries = blocksInTest/2;\n\n    final int nThreads=64;\n    final int nReads=1000000;\n    final int readsPerThread=nReads/nThreads;\n    final int readLastBlockOdds=10; // odds (1 in N) of the next block operation being on the same block as the previous operation... helps flush concurrency issues\n    final int updateAnywayOdds = 3; // sometimes insert a new entry for the key even if one was found\n    final int invalidateOdds = 20; // sometimes invalidate an entry\n\n    final AtomicLong hits = new AtomicLong();\n    final AtomicLong removals = new AtomicLong();\n    final AtomicLong inserts = new AtomicLong();\n\n    RemovalListener<Long,Val> listener = (k, v, removalCause) -> {\n      assert v.key == k;\n      if (!v.live.compareAndSet(true, false)) {\n        throw new RuntimeException(\"listener called more than once! k=\" + k + \" v=\" + v + \" removalCause=\" + removalCause);\n        // return;  // use this variant if listeners may be called more than once\n      }\n      removals.incrementAndGet();\n    };\n\n\n    com.github.benmanes.caffeine.cache.Cache<Long,Val> cache = Caffeine.newBuilder()\n        .removalListener(listener)\n        .maximumSize(maxEntries)\n        .executor(Runnable::run)\n        .build();\n\n    final AtomicBoolean failed = new AtomicBoolean(false);\n    final AtomicLong lastBlock = new AtomicLong();\n    final AtomicLong maxObservedSize = new AtomicLong();\n\n    Thread[] threads = new Thread[nThreads];\n    for (int i=0; i<threads.length; i++) {\n      final long seed = rnd.nextLong();\n\n      threads[i] = new Thread() {\n        Random r;\n        @Override\n        public void run() {\n          try {\n            r = new Random(seed);\n            test(readsPerThread);\n          } catch (Throwable e) {\n            failed.set(true);\n            e.printStackTrace();\n          }\n        }\n\n        public void test(int iter) {\n          for (int i=0; i<iter; i++) {\n            test();\n          }\n        }\n\n        boolean odds(int odds) {\n          return odds > 0 && r.nextInt(odds)==0;\n        }\n\n        long getBlock() {\n          long block;\n          if (odds(readLastBlockOdds)) {\n            block = lastBlock.get();  // some percent of the time, try to read the last block another thread was just reading/writing\n          } else {\n            block = r.nextInt(blocksInTest);\n            lastBlock.set(block);\n          }\n          return block;\n        }\n\n        public void test() {\n          Long k = getBlock();\n\n          if (odds(invalidateOdds)) {\n            // This tests that invalidate always ends up calling the removal listener exactly once\n            // even if the entry may be in the process of concurrent removal in a different thread.\n            // This also inadvertently tests concurrently inserting, getting, and invalidating the same key, which we don't need in Solr's BlockCache.\n            cache.invalidate(k);\n          }\n\n          Val v = cache.getIfPresent(k);\n          if (v != null) {\n            hits.incrementAndGet();\n            assert k.equals(v.key);\n          }\n\n          if (v == null || odds(updateAnywayOdds)) {\n            v = new Val();\n            v.key = k;\n            cache.put(k, v);\n            inserts.incrementAndGet();\n          }\n\n          long sz = cache.estimatedSize();\n          if (sz > maxObservedSize.get()) maxObservedSize.set(sz);  // race condition here, but an estimate is OK\n\n        }\n      };\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n\n    // Thread.sleep(1000); // need to wait if executor is used for listener?\n    long cacheSize = cache.estimatedSize();\n    System.out.println(\"Done! # of Elements = \" + cacheSize + \" inserts=\" + inserts.get() + \" removals=\" + removals.get() + \" hits=\" + hits.get() +  \" maxObservedSize=\" + maxObservedSize);\n    assert inserts.get() - removals.get() == cacheSize;\n    assertFalse( failed.get() );\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"aa2585c33d5d66a1c837c312221eb55ddb3c4300","date":1592493170,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/store/blockcache/BlockCacheTest#testCacheConcurrent().mjava","pathOld":"solr/core/src/test/org/apache/solr/store/blockcache/BlockCacheTest#testCacheConcurrent().mjava","sourceNew":"  // Sanity test the underlying concurrent map that BlockCache is using, in the same way that we use it.\n  @Test\n  public void testCacheConcurrent() throws Exception {\n    Random rnd = random();\n\n    // TODO: introduce more randomness in cache size, hit rate, etc\n    final int blocksInTest = 400;\n    final int maxEntries = blocksInTest / 2;\n\n    final int nThreads = 64;\n    final int nReads = 1000000;\n    final int readsPerThread = nReads / nThreads;\n    final int readLastBlockOdds = 10; // odds (1 in N) of the next block operation being on the same block as the previous operation... helps flush concurrency issues\n    final int updateAnywayOdds = 3; // sometimes insert a new entry for the key even if one was found\n    final int invalidateOdds = 20; // sometimes invalidate an entry\n\n    final AtomicLong hits = new AtomicLong();\n    final AtomicLong removals = new AtomicLong();\n    final AtomicLong inserts = new AtomicLong();\n\n    RemovalListener<Long, Val> listener = (k, v, removalCause) -> {\n      removals.incrementAndGet();\n      if (v == null) {\n        if (removalCause != RemovalCause.COLLECTED) {\n          throw new RuntimeException(\"Null value for key \" + k + \", removalCause=\" + removalCause);\n        } else {\n          return;\n        }\n      }\n      assertEquals(\"cache key differs from value's key\", k, (Long) v.key);\n      if (!v.live.compareAndSet(true, false)) {\n        throw new RuntimeException(\"listener called more than once! k=\" + k + \" v=\" + v + \" removalCause=\" + removalCause);\n        // return;  // use this variant if listeners may be called more than once\n      }\n    };\n\n\n    com.github.benmanes.caffeine.cache.Cache<Long, Val> cache = Caffeine.newBuilder()\n        .removalListener(listener)\n        .maximumSize(maxEntries)\n        .executor(Runnable::run)\n        .build();\n\n    final AtomicBoolean failed = new AtomicBoolean(false);\n    final AtomicLong lastBlock = new AtomicLong();\n    final AtomicLong maxObservedSize = new AtomicLong();\n\n    Thread[] threads = new Thread[nThreads];\n    for (int i = 0; i < threads.length; i++) {\n      final long seed = rnd.nextLong();\n\n      threads[i] = new Thread() {\n        Random r;\n\n        @Override\n        public void run() {\n          try {\n            r = new Random(seed);\n            test(readsPerThread);\n          } catch (Throwable e) {\n            failed.set(true);\n            e.printStackTrace();\n          }\n        }\n\n        public void test(int iter) {\n          for (int i = 0; i < iter; i++) {\n            test();\n          }\n        }\n\n        boolean odds(int odds) {\n          return odds > 0 && r.nextInt(odds) == 0;\n        }\n\n        long getBlock() {\n          long block;\n          if (odds(readLastBlockOdds)) {\n            block = lastBlock.get();  // some percent of the time, try to read the last block another thread was just reading/writing\n          } else {\n            block = r.nextInt(blocksInTest);\n            lastBlock.set(block);\n          }\n          return block;\n        }\n\n        public void test() {\n          Long k = getBlock();\n\n          if (odds(invalidateOdds)) {\n            // This tests that invalidate always ends up calling the removal listener exactly once\n            // even if the entry may be in the process of concurrent removal in a different thread.\n            // This also inadvertently tests concurrently inserting, getting, and invalidating the same key, which we don't need in Solr's BlockCache.\n            cache.invalidate(k);\n          }\n\n          Val v = cache.getIfPresent(k);\n          if (v != null) {\n            hits.incrementAndGet();\n            assertEquals(\"cache key differs from value's key\", k, (Long) v.key);\n          }\n\n          if (v == null || odds(updateAnywayOdds)) {\n            v = new Val();\n            v.key = k;\n            cache.put(k, v);\n            inserts.incrementAndGet();\n          }\n\n          long sz = cache.estimatedSize();\n          if (sz > maxObservedSize.get()) maxObservedSize.set(sz);  // race condition here, but an estimate is OK\n\n        }\n      };\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n\n    // Thread.sleep(1000); // need to wait if executor is used for listener?\n    long cacheSize = cache.estimatedSize();\n    System.out.println(\"Done! # of Elements = \" + cacheSize + \" inserts=\" + inserts.get() + \" removals=\" + removals.get() + \" hits=\" + hits.get() + \" maxObservedSize=\" + maxObservedSize);\n    assertEquals(\"cache size different from (inserts - removal)\", cacheSize,  inserts.get() - removals.get());\n    assertFalse(failed.get());\n  }\n\n","sourceOld":"  // Sanity test the underlying concurrent map that BlockCache is using, in the same way that we use it.\n  @Test\n  public void testCacheConcurrent() throws Exception {\n    Random rnd = random();\n\n    // TODO: introduce more randomness in cache size, hit rate, etc\n    final int blocksInTest = 400;\n    final int maxEntries = blocksInTest / 2;\n\n    final int nThreads = 64;\n    final int nReads = 1000000;\n    final int readsPerThread = nReads / nThreads;\n    final int readLastBlockOdds = 10; // odds (1 in N) of the next block operation being on the same block as the previous operation... helps flush concurrency issues\n    final int updateAnywayOdds = 3; // sometimes insert a new entry for the key even if one was found\n    final int invalidateOdds = 20; // sometimes invalidate an entry\n\n    final AtomicLong hits = new AtomicLong();\n    final AtomicLong removals = new AtomicLong();\n    final AtomicLong inserts = new AtomicLong();\n\n    RemovalListener<Long, Val> listener = (k, v, removalCause) -> {\n      removals.incrementAndGet();\n      if (v == null) {\n        if (removalCause != RemovalCause.COLLECTED) {\n          throw new RuntimeException(\"Null value for key \" + k + \", removalCause=\" + removalCause);\n        } else {\n          return;\n        }\n      }\n      assertEquals(\"cache key differs from value's key\", (Long) k, (Long) v.key);\n      if (!v.live.compareAndSet(true, false)) {\n        throw new RuntimeException(\"listener called more than once! k=\" + k + \" v=\" + v + \" removalCause=\" + removalCause);\n        // return;  // use this variant if listeners may be called more than once\n      }\n    };\n\n\n    com.github.benmanes.caffeine.cache.Cache<Long, Val> cache = Caffeine.newBuilder()\n        .removalListener(listener)\n        .maximumSize(maxEntries)\n        .executor(Runnable::run)\n        .build();\n\n    final AtomicBoolean failed = new AtomicBoolean(false);\n    final AtomicLong lastBlock = new AtomicLong();\n    final AtomicLong maxObservedSize = new AtomicLong();\n\n    Thread[] threads = new Thread[nThreads];\n    for (int i = 0; i < threads.length; i++) {\n      final long seed = rnd.nextLong();\n\n      threads[i] = new Thread() {\n        Random r;\n\n        @Override\n        public void run() {\n          try {\n            r = new Random(seed);\n            test(readsPerThread);\n          } catch (Throwable e) {\n            failed.set(true);\n            e.printStackTrace();\n          }\n        }\n\n        public void test(int iter) {\n          for (int i = 0; i < iter; i++) {\n            test();\n          }\n        }\n\n        boolean odds(int odds) {\n          return odds > 0 && r.nextInt(odds) == 0;\n        }\n\n        long getBlock() {\n          long block;\n          if (odds(readLastBlockOdds)) {\n            block = lastBlock.get();  // some percent of the time, try to read the last block another thread was just reading/writing\n          } else {\n            block = r.nextInt(blocksInTest);\n            lastBlock.set(block);\n          }\n          return block;\n        }\n\n        public void test() {\n          Long k = getBlock();\n\n          if (odds(invalidateOdds)) {\n            // This tests that invalidate always ends up calling the removal listener exactly once\n            // even if the entry may be in the process of concurrent removal in a different thread.\n            // This also inadvertently tests concurrently inserting, getting, and invalidating the same key, which we don't need in Solr's BlockCache.\n            cache.invalidate(k);\n          }\n\n          Val v = cache.getIfPresent(k);\n          if (v != null) {\n            hits.incrementAndGet();\n            assertEquals(\"cache key differs from value's key\", (Long) k, (Long) v.key);\n          }\n\n          if (v == null || odds(updateAnywayOdds)) {\n            v = new Val();\n            v.key = k;\n            cache.put(k, v);\n            inserts.incrementAndGet();\n          }\n\n          long sz = cache.estimatedSize();\n          if (sz > maxObservedSize.get()) maxObservedSize.set(sz);  // race condition here, but an estimate is OK\n\n        }\n      };\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n\n    // Thread.sleep(1000); // need to wait if executor is used for listener?\n    long cacheSize = cache.estimatedSize();\n    System.out.println(\"Done! # of Elements = \" + cacheSize + \" inserts=\" + inserts.get() + \" removals=\" + removals.get() + \" hits=\" + hits.get() + \" maxObservedSize=\" + maxObservedSize);\n    assertEquals(\"cache size different from (inserts - removal)\", cacheSize,  inserts.get() - removals.get());\n    assertFalse(failed.get());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"22ed7c5d31f5bc56287c6c61a259c48159dad150":["bc0da9d1991d13114641b7b59db56458cde6af62"],"aa2585c33d5d66a1c837c312221eb55ddb3c4300":["87f0484c38f986062889ed50f3bf3bd462848c26"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"bc0da9d1991d13114641b7b59db56458cde6af62":["8702182bc92026984124976ef1fa3393bdcbbc05"],"8702182bc92026984124976ef1fa3393bdcbbc05":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"87f0484c38f986062889ed50f3bf3bd462848c26":["22ed7c5d31f5bc56287c6c61a259c48159dad150"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["aa2585c33d5d66a1c837c312221eb55ddb3c4300"],"b0b597c65628ca9e73913a07e81691f8229bae35":["22ed7c5d31f5bc56287c6c61a259c48159dad150","87f0484c38f986062889ed50f3bf3bd462848c26"]},"commit2Childs":{"22ed7c5d31f5bc56287c6c61a259c48159dad150":["87f0484c38f986062889ed50f3bf3bd462848c26","b0b597c65628ca9e73913a07e81691f8229bae35"],"aa2585c33d5d66a1c837c312221eb55ddb3c4300":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["8702182bc92026984124976ef1fa3393bdcbbc05"],"bc0da9d1991d13114641b7b59db56458cde6af62":["22ed7c5d31f5bc56287c6c61a259c48159dad150"],"8702182bc92026984124976ef1fa3393bdcbbc05":["bc0da9d1991d13114641b7b59db56458cde6af62"],"87f0484c38f986062889ed50f3bf3bd462848c26":["aa2585c33d5d66a1c837c312221eb55ddb3c4300","b0b597c65628ca9e73913a07e81691f8229bae35"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"b0b597c65628ca9e73913a07e81691f8229bae35":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817","b0b597c65628ca9e73913a07e81691f8229bae35"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}