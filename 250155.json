{"path":"solr/core/src/test/org/apache/solr/search/TestRangeQuery#testRangeQueries().mjava","commits":[{"id":"c903c3d15906a3da96b8c0c2fb704491005fdbdb","date":1453508227,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRangeQuery#testRangeQueries().mjava","pathOld":"solr/src/test/org/apache/solr/search/TestRangeQuery#testRangeQueries().mjava","sourceNew":"  @Test\n  public void testRangeQueries() throws Exception {\n    // ensure that we aren't losing precision on any fields in addition to testing other non-numeric fields\n    // that aren't tested in testRandomRangeQueries()\n\n    int i=2000000000;\n    long l=500000000000000000L;\n    double d=0.3333333333333333;\n\n    // first 3 values will be indexed, the last two won't be\n    String[] ints = {\"\"+(i-1), \"\"+(i), \"\"+(i+1),   \"\"+(i-2), \"\"+(i+2)};\n    String[] longs = {\"\"+(l-1), \"\"+(l), \"\"+(l+1),  \"\"+(l-2), \"\"+(l+2)};\n    String[] doubles = {\"\"+(d-1e-16), \"\"+(d), \"\"+(d+1e-16),   \"\"+(d-2e-16), \"\"+(d+2e-16)};\n    String[] strings = {\"aaa\",\"bbb\",\"ccc\",  \"aa\",\"cccc\" };\n    String[] dates = {\"1999-12-31T23:59:59.999Z\",\"2000-01-01T00:00:00.000Z\",\"2000-01-01T00:00:00.001Z\",  \"1999-12-31T23:59:59.998Z\",\"2000-01-01T00:00:00.002Z\" };\n\n    // fields that normal range queries should work on\n    Map<String,String[]> norm_fields = new HashMap<String,String[]>();\n    norm_fields.put(\"foo_i\", ints);\n    norm_fields.put(\"foo_l\", longs);\n    norm_fields.put(\"foo_d\", doubles);\n\n    norm_fields.put(\"foo_ti\", ints);\n    norm_fields.put(\"foo_tl\", longs);\n    norm_fields.put(\"foo_td\", doubles);\n    norm_fields.put(\"foo_tdt\", dates);\n\n    norm_fields.put(\"foo_s\", strings);\n    norm_fields.put(\"foo_dt\", dates);\n\n\n    // fields that frange queries should work on\n    Map<String,String[]> frange_fields = new HashMap<String,String[]>();\n    frange_fields.put(\"foo_i\", ints);\n    frange_fields.put(\"foo_l\", longs);\n    frange_fields.put(\"foo_d\", doubles);\n\n    frange_fields.put(\"foo_ti\", ints);\n    frange_fields.put(\"foo_tl\", longs);\n    frange_fields.put(\"foo_td\", doubles);\n    frange_fields.put(\"foo_tdt\", dates);\n\n    frange_fields.put(\"foo_pi\", ints);\n    frange_fields.put(\"foo_pl\", longs);\n    frange_fields.put(\"foo_pd\", doubles);\n\n    frange_fields.put(\"foo_s\", strings);\n    frange_fields.put(\"foo_dt\", dates);\n\n    Map<String,String[]> all_fields = new HashMap<String,String[]>();\n    all_fields.putAll(norm_fields);\n    all_fields.putAll(frange_fields);\n\n    for (int j=0; j<ints.length-2; j++) {\n      List<String> fields = new ArrayList<String>();\n      fields.add(\"id\");\n      fields.add(\"\"+j);\n      for (Map.Entry<String,String[]> entry : all_fields.entrySet()) {\n        fields.add(entry.getKey());\n        fields.add(entry.getValue()[j]);\n      }\n      assertU(adoc(fields.toArray(new String[fields.size()])));\n    }\n\n    assertU(commit());\n\n    // simple test of a function rather than just the field\n    assertQ(req(\"{!frange l=0 u=2}id\"), \"*[count(//doc)=3]\");\n    assertQ(req(\"{!frange l=0 u=2}product(id,2)\"), \"*[count(//doc)=2]\");\n    assertQ(req(\"{!frange l=100 u=102}sum(id,100)\"), \"*[count(//doc)=3]\");\n\n\n    for (Map.Entry<String,String[]> entry : norm_fields.entrySet()) {\n      String f = entry.getKey();\n      String[] v = entry.getValue();\n\n      assertQ(req(f + \":[* TO *]\" ), \"*[count(//doc)=3]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=3]\");\n      assertQ(req(f + \":[\"+v[1]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=2]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[1]+\"]\"), \"*[count(//doc)=2]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[0]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[1]+\" TO \"+v[1]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[2]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[3]+\" TO \"+v[3]+\"]\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":[\"+v[4]+\" TO \"+v[4]+\"]\"), \"*[count(//doc)=0]\");\n\n      assertQ(req(f + \":{\"+v[0]+\" TO \"+v[2]+\"}\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":{\"+v[1]+\" TO \"+v[2]+\"}\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":{\"+v[0]+\" TO \"+v[1]+\"}\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":{\"+v[3]+\" TO \"+v[4]+\"}\"), \"*[count(//doc)=3]\");\n    }\n\n    for (Map.Entry<String,String[]> entry : frange_fields.entrySet()) {\n      String f = entry.getKey();\n      String[] v = entry.getValue();\n\n      assertQ(req(\"{!frange}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[0]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[1]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[2]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[3]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[4]+\"}\"+f ), \"*[count(//doc)=0]\");\n\n      assertQ(req(\"{!frange\" + \" u=\"+v[0]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[1]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[3]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[0]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[1]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[2]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[3]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[4]+\"}\"+f ), \"*[count(//doc)=0]\");\n\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[0]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[1]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[3]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n\n      assertQ(req(\"{!frange incl=true incu=true\" + \" l=\" +v[0] +\" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange incl=false incu=false\" + \" l=\" +v[0] +\" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incl=false incu=false\" + \" l=\" +v[3] +\" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n    }\n\n  }\n\n","sourceOld":"  @Test\n  public void testRangeQueries() throws Exception {\n    // ensure that we aren't losing precision on any fields in addition to testing other non-numeric fields\n    // that aren't tested in testRandomRangeQueries()\n\n    int i=2000000000;\n    long l=500000000000000000L;\n    double d=0.3333333333333333;\n\n    // first 3 values will be indexed, the last two won't be\n    String[] ints = {\"\"+(i-1), \"\"+(i), \"\"+(i+1),   \"\"+(i-2), \"\"+(i+2)};\n    String[] longs = {\"\"+(l-1), \"\"+(l), \"\"+(l+1),  \"\"+(l-2), \"\"+(l+2)};\n    String[] doubles = {\"\"+(d-1e-16), \"\"+(d), \"\"+(d+1e-16),   \"\"+(d-2e-16), \"\"+(d+2e-16)};\n    String[] strings = {\"aaa\",\"bbb\",\"ccc\",  \"aa\",\"cccc\" };\n    String[] dates = {\"1999-12-31T23:59:59.999Z\",\"2000-01-01T00:00:00.000Z\",\"2000-01-01T00:00:00.001Z\",  \"1999-12-31T23:59:59.998Z\",\"2000-01-01T00:00:00.002Z\" };\n\n    // fields that normal range queries should work on\n    Map<String,String[]> norm_fields = new HashMap<String,String[]>();\n    norm_fields.put(\"foo_i\", ints);\n    norm_fields.put(\"foo_l\", longs);\n    norm_fields.put(\"foo_d\", doubles);\n\n    norm_fields.put(\"foo_ti\", ints);\n    norm_fields.put(\"foo_tl\", longs);\n    norm_fields.put(\"foo_td\", doubles);\n    norm_fields.put(\"foo_tdt\", dates);\n\n    norm_fields.put(\"foo_s\", strings);\n    norm_fields.put(\"foo_dt\", dates);\n\n\n    // fields that frange queries should work on\n    Map<String,String[]> frange_fields = new HashMap<String,String[]>();\n    frange_fields.put(\"foo_i\", ints);\n    frange_fields.put(\"foo_l\", longs);\n    frange_fields.put(\"foo_d\", doubles);\n\n    frange_fields.put(\"foo_ti\", ints);\n    frange_fields.put(\"foo_tl\", longs);\n    frange_fields.put(\"foo_td\", doubles);\n    frange_fields.put(\"foo_tdt\", dates);\n\n    frange_fields.put(\"foo_pi\", ints);\n    frange_fields.put(\"foo_pl\", longs);\n    frange_fields.put(\"foo_pd\", doubles);\n\n    frange_fields.put(\"foo_s\", strings);\n    frange_fields.put(\"foo_dt\", dates);\n\n    Map<String,String[]> all_fields = new HashMap<String,String[]>();\n    all_fields.putAll(norm_fields);\n    all_fields.putAll(frange_fields);\n\n    for (int j=0; j<ints.length-2; j++) {\n      List<String> fields = new ArrayList<String>();\n      fields.add(\"id\");\n      fields.add(\"\"+j);\n      for (Map.Entry<String,String[]> entry : all_fields.entrySet()) {\n        fields.add(entry.getKey());\n        fields.add(entry.getValue()[j]);\n      }\n      assertU(adoc(fields.toArray(new String[fields.size()])));\n    }\n\n    assertU(commit());\n\n    // simple test of a function rather than just the field\n    assertQ(req(\"{!frange l=0 u=2}id\"), \"*[count(//doc)=3]\");\n    assertQ(req(\"{!frange l=0 u=2}product(id,2)\"), \"*[count(//doc)=2]\");\n    assertQ(req(\"{!frange l=100 u=102}sum(id,100)\"), \"*[count(//doc)=3]\");\n\n\n    for (Map.Entry<String,String[]> entry : norm_fields.entrySet()) {\n      String f = entry.getKey();\n      String[] v = entry.getValue();\n\n      assertQ(req(f + \":[* TO *]\" ), \"*[count(//doc)=3]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=3]\");\n      assertQ(req(f + \":[\"+v[1]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=2]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[1]+\"]\"), \"*[count(//doc)=2]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[0]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[1]+\" TO \"+v[1]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[2]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[3]+\" TO \"+v[3]+\"]\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":[\"+v[4]+\" TO \"+v[4]+\"]\"), \"*[count(//doc)=0]\");\n\n      assertQ(req(f + \":{\"+v[0]+\" TO \"+v[2]+\"}\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":{\"+v[1]+\" TO \"+v[2]+\"}\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":{\"+v[0]+\" TO \"+v[1]+\"}\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":{\"+v[3]+\" TO \"+v[4]+\"}\"), \"*[count(//doc)=3]\");\n    }\n\n    for (Map.Entry<String,String[]> entry : frange_fields.entrySet()) {\n      String f = entry.getKey();\n      String[] v = entry.getValue();\n\n      assertQ(req(\"{!frange}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[0]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[1]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[2]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[3]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[4]+\"}\"+f ), \"*[count(//doc)=0]\");\n\n      assertQ(req(\"{!frange\" + \" u=\"+v[0]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[1]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[3]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[0]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[1]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[2]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[3]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[4]+\"}\"+f ), \"*[count(//doc)=0]\");\n\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[0]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[1]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[3]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n\n      assertQ(req(\"{!frange incl=true incu=true\" + \" l=\" +v[0] +\" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange incl=false incu=false\" + \" l=\" +v[0] +\" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incl=false incu=false\" + \" l=\" +v[3] +\" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a258fbb26824fd104ed795e5d9033d2d040049ee","date":1453508252,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRangeQuery#testRangeQueries().mjava","pathOld":"solr/src/test/org/apache/solr/search/TestRangeQuery#testRangeQueries().mjava","sourceNew":"  @Test\n  public void testRangeQueries() throws Exception {\n    // ensure that we aren't losing precision on any fields in addition to testing other non-numeric fields\n    // that aren't tested in testRandomRangeQueries()\n\n    int i=2000000000;\n    long l=500000000000000000L;\n    double d=0.3333333333333333;\n\n    // first 3 values will be indexed, the last two won't be\n    String[] ints = {\"\"+(i-1), \"\"+(i), \"\"+(i+1),   \"\"+(i-2), \"\"+(i+2)};\n    String[] longs = {\"\"+(l-1), \"\"+(l), \"\"+(l+1),  \"\"+(l-2), \"\"+(l+2)};\n    String[] doubles = {\"\"+(d-1e-16), \"\"+(d), \"\"+(d+1e-16),   \"\"+(d-2e-16), \"\"+(d+2e-16)};\n    String[] strings = {\"aaa\",\"bbb\",\"ccc\",  \"aa\",\"cccc\" };\n    String[] dates = {\"1999-12-31T23:59:59.999Z\",\"2000-01-01T00:00:00.000Z\",\"2000-01-01T00:00:00.001Z\",  \"1999-12-31T23:59:59.998Z\",\"2000-01-01T00:00:00.002Z\" };\n\n    // fields that normal range queries should work on\n    Map<String,String[]> norm_fields = new HashMap<String,String[]>();\n    norm_fields.put(\"foo_i\", ints);\n    norm_fields.put(\"foo_l\", longs);\n    norm_fields.put(\"foo_d\", doubles);\n\n    norm_fields.put(\"foo_ti\", ints);\n    norm_fields.put(\"foo_tl\", longs);\n    norm_fields.put(\"foo_td\", doubles);\n    norm_fields.put(\"foo_tdt\", dates);\n\n    norm_fields.put(\"foo_s\", strings);\n    norm_fields.put(\"foo_dt\", dates);\n\n\n    // fields that frange queries should work on\n    Map<String,String[]> frange_fields = new HashMap<String,String[]>();\n    frange_fields.put(\"foo_i\", ints);\n    frange_fields.put(\"foo_l\", longs);\n    frange_fields.put(\"foo_d\", doubles);\n\n    frange_fields.put(\"foo_ti\", ints);\n    frange_fields.put(\"foo_tl\", longs);\n    frange_fields.put(\"foo_td\", doubles);\n    frange_fields.put(\"foo_tdt\", dates);\n\n    frange_fields.put(\"foo_pi\", ints);\n    frange_fields.put(\"foo_pl\", longs);\n    frange_fields.put(\"foo_pd\", doubles);\n\n    frange_fields.put(\"foo_s\", strings);\n    frange_fields.put(\"foo_dt\", dates);\n\n    Map<String,String[]> all_fields = new HashMap<String,String[]>();\n    all_fields.putAll(norm_fields);\n    all_fields.putAll(frange_fields);\n\n    for (int j=0; j<ints.length-2; j++) {\n      List<String> fields = new ArrayList<String>();\n      fields.add(\"id\");\n      fields.add(\"\"+j);\n      for (Map.Entry<String,String[]> entry : all_fields.entrySet()) {\n        fields.add(entry.getKey());\n        fields.add(entry.getValue()[j]);\n      }\n      assertU(adoc(fields.toArray(new String[fields.size()])));\n    }\n\n    assertU(commit());\n\n    // simple test of a function rather than just the field\n    assertQ(req(\"{!frange l=0 u=2}id\"), \"*[count(//doc)=3]\");\n    assertQ(req(\"{!frange l=0 u=2}product(id,2)\"), \"*[count(//doc)=2]\");\n    assertQ(req(\"{!frange l=100 u=102}sum(id,100)\"), \"*[count(//doc)=3]\");\n\n\n    for (Map.Entry<String,String[]> entry : norm_fields.entrySet()) {\n      String f = entry.getKey();\n      String[] v = entry.getValue();\n\n      assertQ(req(f + \":[* TO *]\" ), \"*[count(//doc)=3]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=3]\");\n      assertQ(req(f + \":[\"+v[1]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=2]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[1]+\"]\"), \"*[count(//doc)=2]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[0]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[1]+\" TO \"+v[1]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[2]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[3]+\" TO \"+v[3]+\"]\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":[\"+v[4]+\" TO \"+v[4]+\"]\"), \"*[count(//doc)=0]\");\n\n      assertQ(req(f + \":{\"+v[0]+\" TO \"+v[2]+\"}\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":{\"+v[1]+\" TO \"+v[2]+\"}\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":{\"+v[0]+\" TO \"+v[1]+\"}\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":{\"+v[3]+\" TO \"+v[4]+\"}\"), \"*[count(//doc)=3]\");\n    }\n\n    for (Map.Entry<String,String[]> entry : frange_fields.entrySet()) {\n      String f = entry.getKey();\n      String[] v = entry.getValue();\n\n      assertQ(req(\"{!frange}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[0]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[1]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[2]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[3]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[4]+\"}\"+f ), \"*[count(//doc)=0]\");\n\n      assertQ(req(\"{!frange\" + \" u=\"+v[0]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[1]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[3]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[0]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[1]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[2]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[3]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[4]+\"}\"+f ), \"*[count(//doc)=0]\");\n\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[0]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[1]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[3]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n\n      assertQ(req(\"{!frange incl=true incu=true\" + \" l=\" +v[0] +\" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange incl=false incu=false\" + \" l=\" +v[0] +\" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incl=false incu=false\" + \" l=\" +v[3] +\" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n    }\n\n  }\n\n","sourceOld":"  @Test\n  public void testRangeQueries() throws Exception {\n    // ensure that we aren't losing precision on any fields in addition to testing other non-numeric fields\n    // that aren't tested in testRandomRangeQueries()\n\n    int i=2000000000;\n    long l=500000000000000000L;\n    double d=0.3333333333333333;\n\n    // first 3 values will be indexed, the last two won't be\n    String[] ints = {\"\"+(i-1), \"\"+(i), \"\"+(i+1),   \"\"+(i-2), \"\"+(i+2)};\n    String[] longs = {\"\"+(l-1), \"\"+(l), \"\"+(l+1),  \"\"+(l-2), \"\"+(l+2)};\n    String[] doubles = {\"\"+(d-1e-16), \"\"+(d), \"\"+(d+1e-16),   \"\"+(d-2e-16), \"\"+(d+2e-16)};\n    String[] strings = {\"aaa\",\"bbb\",\"ccc\",  \"aa\",\"cccc\" };\n    String[] dates = {\"1999-12-31T23:59:59.999Z\",\"2000-01-01T00:00:00.000Z\",\"2000-01-01T00:00:00.001Z\",  \"1999-12-31T23:59:59.998Z\",\"2000-01-01T00:00:00.002Z\" };\n\n    // fields that normal range queries should work on\n    Map<String,String[]> norm_fields = new HashMap<String,String[]>();\n    norm_fields.put(\"foo_i\", ints);\n    norm_fields.put(\"foo_l\", longs);\n    norm_fields.put(\"foo_d\", doubles);\n\n    norm_fields.put(\"foo_ti\", ints);\n    norm_fields.put(\"foo_tl\", longs);\n    norm_fields.put(\"foo_td\", doubles);\n    norm_fields.put(\"foo_tdt\", dates);\n\n    norm_fields.put(\"foo_s\", strings);\n    norm_fields.put(\"foo_dt\", dates);\n\n\n    // fields that frange queries should work on\n    Map<String,String[]> frange_fields = new HashMap<String,String[]>();\n    frange_fields.put(\"foo_i\", ints);\n    frange_fields.put(\"foo_l\", longs);\n    frange_fields.put(\"foo_d\", doubles);\n\n    frange_fields.put(\"foo_ti\", ints);\n    frange_fields.put(\"foo_tl\", longs);\n    frange_fields.put(\"foo_td\", doubles);\n    frange_fields.put(\"foo_tdt\", dates);\n\n    frange_fields.put(\"foo_pi\", ints);\n    frange_fields.put(\"foo_pl\", longs);\n    frange_fields.put(\"foo_pd\", doubles);\n\n    frange_fields.put(\"foo_s\", strings);\n    frange_fields.put(\"foo_dt\", dates);\n\n    Map<String,String[]> all_fields = new HashMap<String,String[]>();\n    all_fields.putAll(norm_fields);\n    all_fields.putAll(frange_fields);\n\n    for (int j=0; j<ints.length-2; j++) {\n      List<String> fields = new ArrayList<String>();\n      fields.add(\"id\");\n      fields.add(\"\"+j);\n      for (Map.Entry<String,String[]> entry : all_fields.entrySet()) {\n        fields.add(entry.getKey());\n        fields.add(entry.getValue()[j]);\n      }\n      assertU(adoc(fields.toArray(new String[fields.size()])));\n    }\n\n    assertU(commit());\n\n    // simple test of a function rather than just the field\n    assertQ(req(\"{!frange l=0 u=2}id\"), \"*[count(//doc)=3]\");\n    assertQ(req(\"{!frange l=0 u=2}product(id,2)\"), \"*[count(//doc)=2]\");\n    assertQ(req(\"{!frange l=100 u=102}sum(id,100)\"), \"*[count(//doc)=3]\");\n\n\n    for (Map.Entry<String,String[]> entry : norm_fields.entrySet()) {\n      String f = entry.getKey();\n      String[] v = entry.getValue();\n\n      assertQ(req(f + \":[* TO *]\" ), \"*[count(//doc)=3]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=3]\");\n      assertQ(req(f + \":[\"+v[1]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=2]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[1]+\"]\"), \"*[count(//doc)=2]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[0]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[1]+\" TO \"+v[1]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[2]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[3]+\" TO \"+v[3]+\"]\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":[\"+v[4]+\" TO \"+v[4]+\"]\"), \"*[count(//doc)=0]\");\n\n      assertQ(req(f + \":{\"+v[0]+\" TO \"+v[2]+\"}\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":{\"+v[1]+\" TO \"+v[2]+\"}\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":{\"+v[0]+\" TO \"+v[1]+\"}\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":{\"+v[3]+\" TO \"+v[4]+\"}\"), \"*[count(//doc)=3]\");\n    }\n\n    for (Map.Entry<String,String[]> entry : frange_fields.entrySet()) {\n      String f = entry.getKey();\n      String[] v = entry.getValue();\n\n      assertQ(req(\"{!frange}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[0]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[1]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[2]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[3]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[4]+\"}\"+f ), \"*[count(//doc)=0]\");\n\n      assertQ(req(\"{!frange\" + \" u=\"+v[0]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[1]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[3]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[0]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[1]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[2]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[3]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[4]+\"}\"+f ), \"*[count(//doc)=0]\");\n\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[0]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[1]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[3]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n\n      assertQ(req(\"{!frange incl=true incu=true\" + \" l=\" +v[0] +\" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange incl=false incu=false\" + \" l=\" +v[0] +\" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incl=false incu=false\" + \" l=\" +v[3] +\" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":1,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRangeQuery#testRangeQueries().mjava","pathOld":"solr/src/test/org/apache/solr/search/TestRangeQuery#testRangeQueries().mjava","sourceNew":"  @Test\n  public void testRangeQueries() throws Exception {\n    // ensure that we aren't losing precision on any fields in addition to testing other non-numeric fields\n    // that aren't tested in testRandomRangeQueries()\n\n    int i=2000000000;\n    long l=500000000000000000L;\n    double d=0.3333333333333333;\n\n    // first 3 values will be indexed, the last two won't be\n    String[] ints = {\"\"+(i-1), \"\"+(i), \"\"+(i+1),   \"\"+(i-2), \"\"+(i+2)};\n    String[] longs = {\"\"+(l-1), \"\"+(l), \"\"+(l+1),  \"\"+(l-2), \"\"+(l+2)};\n    String[] doubles = {\"\"+(d-1e-16), \"\"+(d), \"\"+(d+1e-16),   \"\"+(d-2e-16), \"\"+(d+2e-16)};\n    String[] strings = {\"aaa\",\"bbb\",\"ccc\",  \"aa\",\"cccc\" };\n    String[] dates = {\"1999-12-31T23:59:59.999Z\",\"2000-01-01T00:00:00.000Z\",\"2000-01-01T00:00:00.001Z\",  \"1999-12-31T23:59:59.998Z\",\"2000-01-01T00:00:00.002Z\" };\n\n    // fields that normal range queries should work on\n    Map<String,String[]> norm_fields = new HashMap<String,String[]>();\n    norm_fields.put(\"foo_i\", ints);\n    norm_fields.put(\"foo_l\", longs);\n    norm_fields.put(\"foo_d\", doubles);\n\n    norm_fields.put(\"foo_ti\", ints);\n    norm_fields.put(\"foo_tl\", longs);\n    norm_fields.put(\"foo_td\", doubles);\n    norm_fields.put(\"foo_tdt\", dates);\n\n    norm_fields.put(\"foo_s\", strings);\n    norm_fields.put(\"foo_dt\", dates);\n\n\n    // fields that frange queries should work on\n    Map<String,String[]> frange_fields = new HashMap<String,String[]>();\n    frange_fields.put(\"foo_i\", ints);\n    frange_fields.put(\"foo_l\", longs);\n    frange_fields.put(\"foo_d\", doubles);\n\n    frange_fields.put(\"foo_ti\", ints);\n    frange_fields.put(\"foo_tl\", longs);\n    frange_fields.put(\"foo_td\", doubles);\n    frange_fields.put(\"foo_tdt\", dates);\n\n    frange_fields.put(\"foo_pi\", ints);\n    frange_fields.put(\"foo_pl\", longs);\n    frange_fields.put(\"foo_pd\", doubles);\n\n    frange_fields.put(\"foo_s\", strings);\n    frange_fields.put(\"foo_dt\", dates);\n\n    Map<String,String[]> all_fields = new HashMap<String,String[]>();\n    all_fields.putAll(norm_fields);\n    all_fields.putAll(frange_fields);\n\n    for (int j=0; j<ints.length-2; j++) {\n      List<String> fields = new ArrayList<String>();\n      fields.add(\"id\");\n      fields.add(\"\"+j);\n      for (Map.Entry<String,String[]> entry : all_fields.entrySet()) {\n        fields.add(entry.getKey());\n        fields.add(entry.getValue()[j]);\n      }\n      assertU(adoc(fields.toArray(new String[fields.size()])));\n    }\n\n    assertU(commit());\n\n    // simple test of a function rather than just the field\n    assertQ(req(\"{!frange l=0 u=2}id\"), \"*[count(//doc)=3]\");\n    assertQ(req(\"{!frange l=0 u=2}product(id,2)\"), \"*[count(//doc)=2]\");\n    assertQ(req(\"{!frange l=100 u=102}sum(id,100)\"), \"*[count(//doc)=3]\");\n\n\n    for (Map.Entry<String,String[]> entry : norm_fields.entrySet()) {\n      String f = entry.getKey();\n      String[] v = entry.getValue();\n\n      assertQ(req(f + \":[* TO *]\" ), \"*[count(//doc)=3]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=3]\");\n      assertQ(req(f + \":[\"+v[1]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=2]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[1]+\"]\"), \"*[count(//doc)=2]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[0]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[1]+\" TO \"+v[1]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[2]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[3]+\" TO \"+v[3]+\"]\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":[\"+v[4]+\" TO \"+v[4]+\"]\"), \"*[count(//doc)=0]\");\n\n      assertQ(req(f + \":{\"+v[0]+\" TO \"+v[2]+\"}\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":{\"+v[1]+\" TO \"+v[2]+\"}\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":{\"+v[0]+\" TO \"+v[1]+\"}\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":{\"+v[3]+\" TO \"+v[4]+\"}\"), \"*[count(//doc)=3]\");\n    }\n\n    for (Map.Entry<String,String[]> entry : frange_fields.entrySet()) {\n      String f = entry.getKey();\n      String[] v = entry.getValue();\n\n      assertQ(req(\"{!frange}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[0]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[1]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[2]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[3]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[4]+\"}\"+f ), \"*[count(//doc)=0]\");\n\n      assertQ(req(\"{!frange\" + \" u=\"+v[0]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[1]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[3]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[0]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[1]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[2]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[3]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[4]+\"}\"+f ), \"*[count(//doc)=0]\");\n\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[0]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[1]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[3]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n\n      assertQ(req(\"{!frange incl=true incu=true\" + \" l=\" +v[0] +\" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange incl=false incu=false\" + \" l=\" +v[0] +\" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incl=false incu=false\" + \" l=\" +v[3] +\" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n    }\n\n  }\n\n","sourceOld":"  @Test\n  public void testRangeQueries() throws Exception {\n    // ensure that we aren't losing precision on any fields in addition to testing other non-numeric fields\n    // that aren't tested in testRandomRangeQueries()\n\n    int i=2000000000;\n    long l=500000000000000000L;\n    double d=0.3333333333333333;\n\n    // first 3 values will be indexed, the last two won't be\n    String[] ints = {\"\"+(i-1), \"\"+(i), \"\"+(i+1),   \"\"+(i-2), \"\"+(i+2)};\n    String[] longs = {\"\"+(l-1), \"\"+(l), \"\"+(l+1),  \"\"+(l-2), \"\"+(l+2)};\n    String[] doubles = {\"\"+(d-1e-16), \"\"+(d), \"\"+(d+1e-16),   \"\"+(d-2e-16), \"\"+(d+2e-16)};\n    String[] strings = {\"aaa\",\"bbb\",\"ccc\",  \"aa\",\"cccc\" };\n    String[] dates = {\"1999-12-31T23:59:59.999Z\",\"2000-01-01T00:00:00.000Z\",\"2000-01-01T00:00:00.001Z\",  \"1999-12-31T23:59:59.998Z\",\"2000-01-01T00:00:00.002Z\" };\n\n    // fields that normal range queries should work on\n    Map<String,String[]> norm_fields = new HashMap<String,String[]>();\n    norm_fields.put(\"foo_i\", ints);\n    norm_fields.put(\"foo_l\", longs);\n    norm_fields.put(\"foo_d\", doubles);\n\n    norm_fields.put(\"foo_ti\", ints);\n    norm_fields.put(\"foo_tl\", longs);\n    norm_fields.put(\"foo_td\", doubles);\n    norm_fields.put(\"foo_tdt\", dates);\n\n    norm_fields.put(\"foo_s\", strings);\n    norm_fields.put(\"foo_dt\", dates);\n\n\n    // fields that frange queries should work on\n    Map<String,String[]> frange_fields = new HashMap<String,String[]>();\n    frange_fields.put(\"foo_i\", ints);\n    frange_fields.put(\"foo_l\", longs);\n    frange_fields.put(\"foo_d\", doubles);\n\n    frange_fields.put(\"foo_ti\", ints);\n    frange_fields.put(\"foo_tl\", longs);\n    frange_fields.put(\"foo_td\", doubles);\n    frange_fields.put(\"foo_tdt\", dates);\n\n    frange_fields.put(\"foo_pi\", ints);\n    frange_fields.put(\"foo_pl\", longs);\n    frange_fields.put(\"foo_pd\", doubles);\n\n    frange_fields.put(\"foo_s\", strings);\n    frange_fields.put(\"foo_dt\", dates);\n\n    Map<String,String[]> all_fields = new HashMap<String,String[]>();\n    all_fields.putAll(norm_fields);\n    all_fields.putAll(frange_fields);\n\n    for (int j=0; j<ints.length-2; j++) {\n      List<String> fields = new ArrayList<String>();\n      fields.add(\"id\");\n      fields.add(\"\"+j);\n      for (Map.Entry<String,String[]> entry : all_fields.entrySet()) {\n        fields.add(entry.getKey());\n        fields.add(entry.getValue()[j]);\n      }\n      assertU(adoc(fields.toArray(new String[fields.size()])));\n    }\n\n    assertU(commit());\n\n    // simple test of a function rather than just the field\n    assertQ(req(\"{!frange l=0 u=2}id\"), \"*[count(//doc)=3]\");\n    assertQ(req(\"{!frange l=0 u=2}product(id,2)\"), \"*[count(//doc)=2]\");\n    assertQ(req(\"{!frange l=100 u=102}sum(id,100)\"), \"*[count(//doc)=3]\");\n\n\n    for (Map.Entry<String,String[]> entry : norm_fields.entrySet()) {\n      String f = entry.getKey();\n      String[] v = entry.getValue();\n\n      assertQ(req(f + \":[* TO *]\" ), \"*[count(//doc)=3]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=3]\");\n      assertQ(req(f + \":[\"+v[1]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=2]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[1]+\"]\"), \"*[count(//doc)=2]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[0]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[1]+\" TO \"+v[1]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[2]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[3]+\" TO \"+v[3]+\"]\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":[\"+v[4]+\" TO \"+v[4]+\"]\"), \"*[count(//doc)=0]\");\n\n      assertQ(req(f + \":{\"+v[0]+\" TO \"+v[2]+\"}\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":{\"+v[1]+\" TO \"+v[2]+\"}\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":{\"+v[0]+\" TO \"+v[1]+\"}\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":{\"+v[3]+\" TO \"+v[4]+\"}\"), \"*[count(//doc)=3]\");\n    }\n\n    for (Map.Entry<String,String[]> entry : frange_fields.entrySet()) {\n      String f = entry.getKey();\n      String[] v = entry.getValue();\n\n      assertQ(req(\"{!frange}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[0]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[1]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[2]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[3]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[4]+\"}\"+f ), \"*[count(//doc)=0]\");\n\n      assertQ(req(\"{!frange\" + \" u=\"+v[0]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[1]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[3]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[0]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[1]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[2]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[3]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[4]+\"}\"+f ), \"*[count(//doc)=0]\");\n\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[0]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[1]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[3]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n\n      assertQ(req(\"{!frange incl=true incu=true\" + \" l=\" +v[0] +\" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange incl=false incu=false\" + \" l=\" +v[0] +\" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incl=false incu=false\" + \" l=\" +v[3] +\" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"461fea4b90072bede0ef2dc0dba66a8c5dbf1356","date":1316194960,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRangeQuery#testRangeQueries().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRangeQuery#testRangeQueries().mjava","sourceNew":"  @Test\n  public void testRangeQueries() throws Exception {\n    // ensure that we aren't losing precision on any fields in addition to testing other non-numeric fields\n    // that aren't tested in testRandomRangeQueries()\n\n    int i=2000000000;\n    long l=500000000000000000L;\n    double d=0.3333333333333333;\n\n    // first 3 values will be indexed, the last two won't be\n    String[] ints = {\"\"+(i-1), \"\"+(i), \"\"+(i+1),   \"\"+(i-2), \"\"+(i+2)};\n    String[] longs = {\"\"+(l-1), \"\"+(l), \"\"+(l+1),  \"\"+(l-2), \"\"+(l+2)};\n    String[] doubles = {\"\"+(d-1e-16), \"\"+(d), \"\"+(d+1e-16),   \"\"+(d-2e-16), \"\"+(d+2e-16)};\n    String[] strings = {\"aaa\",\"bbb\",\"ccc\",  \"aa\",\"cccc\" };\n    String[] dates = {\"0299-12-31T23:59:59.999Z\",\"2000-01-01T00:00:00.000Z\",\"2000-01-01T00:00:00.001Z\",  \"0299-12-31T23:59:59.998Z\",\"2000-01-01T00:00:00.002Z\" };\n\n    // fields that normal range queries should work on\n    Map<String,String[]> norm_fields = new HashMap<String,String[]>();\n    norm_fields.put(\"foo_i\", ints);\n    norm_fields.put(\"foo_l\", longs);\n    norm_fields.put(\"foo_d\", doubles);\n\n    norm_fields.put(\"foo_ti\", ints);\n    norm_fields.put(\"foo_tl\", longs);\n    norm_fields.put(\"foo_td\", doubles);\n    norm_fields.put(\"foo_tdt\", dates);\n\n    norm_fields.put(\"foo_s\", strings);\n    norm_fields.put(\"foo_dt\", dates);\n\n\n    // fields that frange queries should work on\n    Map<String,String[]> frange_fields = new HashMap<String,String[]>();\n    frange_fields.put(\"foo_i\", ints);\n    frange_fields.put(\"foo_l\", longs);\n    frange_fields.put(\"foo_d\", doubles);\n\n    frange_fields.put(\"foo_ti\", ints);\n    frange_fields.put(\"foo_tl\", longs);\n    frange_fields.put(\"foo_td\", doubles);\n    frange_fields.put(\"foo_tdt\", dates);\n\n    frange_fields.put(\"foo_pi\", ints);\n    frange_fields.put(\"foo_pl\", longs);\n    frange_fields.put(\"foo_pd\", doubles);\n\n    frange_fields.put(\"foo_s\", strings);\n    frange_fields.put(\"foo_dt\", dates);\n\n    Map<String,String[]> all_fields = new HashMap<String,String[]>();\n    all_fields.putAll(norm_fields);\n    all_fields.putAll(frange_fields);\n\n    for (int j=0; j<ints.length-2; j++) {\n      List<String> fields = new ArrayList<String>();\n      fields.add(\"id\");\n      fields.add(\"\"+j);\n      for (Map.Entry<String,String[]> entry : all_fields.entrySet()) {\n        fields.add(entry.getKey());\n        fields.add(entry.getValue()[j]);\n      }\n      assertU(adoc(fields.toArray(new String[fields.size()])));\n    }\n\n    assertU(commit());\n\n    // simple test of a function rather than just the field\n    assertQ(req(\"{!frange l=0 u=2}id\"), \"*[count(//doc)=3]\");\n    assertQ(req(\"{!frange l=0 u=2}product(id,2)\"), \"*[count(//doc)=2]\");\n    assertQ(req(\"{!frange l=100 u=102}sum(id,100)\"), \"*[count(//doc)=3]\");\n\n\n    for (Map.Entry<String,String[]> entry : norm_fields.entrySet()) {\n      String f = entry.getKey();\n      String[] v = entry.getValue();\n\n      assertQ(req(f + \":[* TO *]\" ), \"*[count(//doc)=3]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=3]\");\n      assertQ(req(f + \":[\"+v[1]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=2]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[1]+\"]\"), \"*[count(//doc)=2]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[0]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[1]+\" TO \"+v[1]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[2]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[3]+\" TO \"+v[3]+\"]\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":[\"+v[4]+\" TO \"+v[4]+\"]\"), \"*[count(//doc)=0]\");\n\n      assertQ(req(f + \":{\"+v[0]+\" TO \"+v[2]+\"}\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":{\"+v[1]+\" TO \"+v[2]+\"}\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":{\"+v[0]+\" TO \"+v[1]+\"}\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":{\"+v[3]+\" TO \"+v[4]+\"}\"), \"*[count(//doc)=3]\");\n    }\n\n    for (Map.Entry<String,String[]> entry : frange_fields.entrySet()) {\n      String f = entry.getKey();\n      String[] v = entry.getValue();\n\n      assertQ(req(\"{!frange}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[0]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[1]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[2]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[3]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[4]+\"}\"+f ), \"*[count(//doc)=0]\");\n\n      assertQ(req(\"{!frange\" + \" u=\"+v[0]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[1]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[3]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[0]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[1]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[2]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[3]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[4]+\"}\"+f ), \"*[count(//doc)=0]\");\n\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[0]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[1]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[3]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n\n      assertQ(req(\"{!frange incl=true incu=true\" + \" l=\" +v[0] +\" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange incl=false incu=false\" + \" l=\" +v[0] +\" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incl=false incu=false\" + \" l=\" +v[3] +\" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n    }\n\n  }\n\n","sourceOld":"  @Test\n  public void testRangeQueries() throws Exception {\n    // ensure that we aren't losing precision on any fields in addition to testing other non-numeric fields\n    // that aren't tested in testRandomRangeQueries()\n\n    int i=2000000000;\n    long l=500000000000000000L;\n    double d=0.3333333333333333;\n\n    // first 3 values will be indexed, the last two won't be\n    String[] ints = {\"\"+(i-1), \"\"+(i), \"\"+(i+1),   \"\"+(i-2), \"\"+(i+2)};\n    String[] longs = {\"\"+(l-1), \"\"+(l), \"\"+(l+1),  \"\"+(l-2), \"\"+(l+2)};\n    String[] doubles = {\"\"+(d-1e-16), \"\"+(d), \"\"+(d+1e-16),   \"\"+(d-2e-16), \"\"+(d+2e-16)};\n    String[] strings = {\"aaa\",\"bbb\",\"ccc\",  \"aa\",\"cccc\" };\n    String[] dates = {\"1999-12-31T23:59:59.999Z\",\"2000-01-01T00:00:00.000Z\",\"2000-01-01T00:00:00.001Z\",  \"1999-12-31T23:59:59.998Z\",\"2000-01-01T00:00:00.002Z\" };\n\n    // fields that normal range queries should work on\n    Map<String,String[]> norm_fields = new HashMap<String,String[]>();\n    norm_fields.put(\"foo_i\", ints);\n    norm_fields.put(\"foo_l\", longs);\n    norm_fields.put(\"foo_d\", doubles);\n\n    norm_fields.put(\"foo_ti\", ints);\n    norm_fields.put(\"foo_tl\", longs);\n    norm_fields.put(\"foo_td\", doubles);\n    norm_fields.put(\"foo_tdt\", dates);\n\n    norm_fields.put(\"foo_s\", strings);\n    norm_fields.put(\"foo_dt\", dates);\n\n\n    // fields that frange queries should work on\n    Map<String,String[]> frange_fields = new HashMap<String,String[]>();\n    frange_fields.put(\"foo_i\", ints);\n    frange_fields.put(\"foo_l\", longs);\n    frange_fields.put(\"foo_d\", doubles);\n\n    frange_fields.put(\"foo_ti\", ints);\n    frange_fields.put(\"foo_tl\", longs);\n    frange_fields.put(\"foo_td\", doubles);\n    frange_fields.put(\"foo_tdt\", dates);\n\n    frange_fields.put(\"foo_pi\", ints);\n    frange_fields.put(\"foo_pl\", longs);\n    frange_fields.put(\"foo_pd\", doubles);\n\n    frange_fields.put(\"foo_s\", strings);\n    frange_fields.put(\"foo_dt\", dates);\n\n    Map<String,String[]> all_fields = new HashMap<String,String[]>();\n    all_fields.putAll(norm_fields);\n    all_fields.putAll(frange_fields);\n\n    for (int j=0; j<ints.length-2; j++) {\n      List<String> fields = new ArrayList<String>();\n      fields.add(\"id\");\n      fields.add(\"\"+j);\n      for (Map.Entry<String,String[]> entry : all_fields.entrySet()) {\n        fields.add(entry.getKey());\n        fields.add(entry.getValue()[j]);\n      }\n      assertU(adoc(fields.toArray(new String[fields.size()])));\n    }\n\n    assertU(commit());\n\n    // simple test of a function rather than just the field\n    assertQ(req(\"{!frange l=0 u=2}id\"), \"*[count(//doc)=3]\");\n    assertQ(req(\"{!frange l=0 u=2}product(id,2)\"), \"*[count(//doc)=2]\");\n    assertQ(req(\"{!frange l=100 u=102}sum(id,100)\"), \"*[count(//doc)=3]\");\n\n\n    for (Map.Entry<String,String[]> entry : norm_fields.entrySet()) {\n      String f = entry.getKey();\n      String[] v = entry.getValue();\n\n      assertQ(req(f + \":[* TO *]\" ), \"*[count(//doc)=3]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=3]\");\n      assertQ(req(f + \":[\"+v[1]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=2]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[1]+\"]\"), \"*[count(//doc)=2]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[0]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[1]+\" TO \"+v[1]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[2]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[3]+\" TO \"+v[3]+\"]\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":[\"+v[4]+\" TO \"+v[4]+\"]\"), \"*[count(//doc)=0]\");\n\n      assertQ(req(f + \":{\"+v[0]+\" TO \"+v[2]+\"}\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":{\"+v[1]+\" TO \"+v[2]+\"}\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":{\"+v[0]+\" TO \"+v[1]+\"}\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":{\"+v[3]+\" TO \"+v[4]+\"}\"), \"*[count(//doc)=3]\");\n    }\n\n    for (Map.Entry<String,String[]> entry : frange_fields.entrySet()) {\n      String f = entry.getKey();\n      String[] v = entry.getValue();\n\n      assertQ(req(\"{!frange}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[0]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[1]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[2]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[3]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[4]+\"}\"+f ), \"*[count(//doc)=0]\");\n\n      assertQ(req(\"{!frange\" + \" u=\"+v[0]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[1]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[3]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[0]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[1]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[2]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[3]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[4]+\"}\"+f ), \"*[count(//doc)=0]\");\n\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[0]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[1]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[3]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n\n      assertQ(req(\"{!frange incl=true incu=true\" + \" l=\" +v[0] +\" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange incl=false incu=false\" + \" l=\" +v[0] +\" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incl=false incu=false\" + \" l=\" +v[3] +\" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRangeQuery#testRangeQueries().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRangeQuery#testRangeQueries().mjava","sourceNew":"  @Test\n  public void testRangeQueries() throws Exception {\n    // ensure that we aren't losing precision on any fields in addition to testing other non-numeric fields\n    // that aren't tested in testRandomRangeQueries()\n\n    int i=2000000000;\n    long l=500000000000000000L;\n    double d=0.3333333333333333;\n\n    // first 3 values will be indexed, the last two won't be\n    String[] ints = {\"\"+(i-1), \"\"+(i), \"\"+(i+1),   \"\"+(i-2), \"\"+(i+2)};\n    String[] longs = {\"\"+(l-1), \"\"+(l), \"\"+(l+1),  \"\"+(l-2), \"\"+(l+2)};\n    String[] doubles = {\"\"+(d-1e-16), \"\"+(d), \"\"+(d+1e-16),   \"\"+(d-2e-16), \"\"+(d+2e-16)};\n    String[] strings = {\"aaa\",\"bbb\",\"ccc\",  \"aa\",\"cccc\" };\n    String[] dates = {\"0299-12-31T23:59:59.999Z\",\"2000-01-01T00:00:00.000Z\",\"2000-01-01T00:00:00.001Z\",  \"0299-12-31T23:59:59.998Z\",\"2000-01-01T00:00:00.002Z\" };\n\n    // fields that normal range queries should work on\n    Map<String,String[]> norm_fields = new HashMap<>();\n    norm_fields.put(\"foo_i\", ints);\n    norm_fields.put(\"foo_l\", longs);\n    norm_fields.put(\"foo_d\", doubles);\n\n    norm_fields.put(\"foo_ti\", ints);\n    norm_fields.put(\"foo_tl\", longs);\n    norm_fields.put(\"foo_td\", doubles);\n    norm_fields.put(\"foo_tdt\", dates);\n\n    norm_fields.put(\"foo_s\", strings);\n    norm_fields.put(\"foo_dt\", dates);\n\n\n    // fields that frange queries should work on\n    Map<String,String[]> frange_fields = new HashMap<>();\n    frange_fields.put(\"foo_i\", ints);\n    frange_fields.put(\"foo_l\", longs);\n    frange_fields.put(\"foo_d\", doubles);\n\n    frange_fields.put(\"foo_ti\", ints);\n    frange_fields.put(\"foo_tl\", longs);\n    frange_fields.put(\"foo_td\", doubles);\n    frange_fields.put(\"foo_tdt\", dates);\n\n    frange_fields.put(\"foo_pi\", ints);\n    frange_fields.put(\"foo_pl\", longs);\n    frange_fields.put(\"foo_pd\", doubles);\n\n    frange_fields.put(\"foo_s\", strings);\n    frange_fields.put(\"foo_dt\", dates);\n\n    Map<String,String[]> all_fields = new HashMap<>();\n    all_fields.putAll(norm_fields);\n    all_fields.putAll(frange_fields);\n\n    for (int j=0; j<ints.length-2; j++) {\n      List<String> fields = new ArrayList<>();\n      fields.add(\"id\");\n      fields.add(\"\"+j);\n      for (Map.Entry<String,String[]> entry : all_fields.entrySet()) {\n        fields.add(entry.getKey());\n        fields.add(entry.getValue()[j]);\n      }\n      assertU(adoc(fields.toArray(new String[fields.size()])));\n    }\n\n    assertU(commit());\n\n    // simple test of a function rather than just the field\n    assertQ(req(\"{!frange l=0 u=2}id\"), \"*[count(//doc)=3]\");\n    assertQ(req(\"{!frange l=0 u=2}product(id,2)\"), \"*[count(//doc)=2]\");\n    assertQ(req(\"{!frange l=100 u=102}sum(id,100)\"), \"*[count(//doc)=3]\");\n\n\n    for (Map.Entry<String,String[]> entry : norm_fields.entrySet()) {\n      String f = entry.getKey();\n      String[] v = entry.getValue();\n\n      assertQ(req(f + \":[* TO *]\" ), \"*[count(//doc)=3]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=3]\");\n      assertQ(req(f + \":[\"+v[1]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=2]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[1]+\"]\"), \"*[count(//doc)=2]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[0]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[1]+\" TO \"+v[1]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[2]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[3]+\" TO \"+v[3]+\"]\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":[\"+v[4]+\" TO \"+v[4]+\"]\"), \"*[count(//doc)=0]\");\n\n      assertQ(req(f + \":{\"+v[0]+\" TO \"+v[2]+\"}\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":{\"+v[1]+\" TO \"+v[2]+\"}\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":{\"+v[0]+\" TO \"+v[1]+\"}\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":{\"+v[3]+\" TO \"+v[4]+\"}\"), \"*[count(//doc)=3]\");\n    }\n\n    for (Map.Entry<String,String[]> entry : frange_fields.entrySet()) {\n      String f = entry.getKey();\n      String[] v = entry.getValue();\n\n      assertQ(req(\"{!frange}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[0]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[1]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[2]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[3]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[4]+\"}\"+f ), \"*[count(//doc)=0]\");\n\n      assertQ(req(\"{!frange\" + \" u=\"+v[0]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[1]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[3]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[0]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[1]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[2]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[3]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[4]+\"}\"+f ), \"*[count(//doc)=0]\");\n\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[0]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[1]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[3]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n\n      assertQ(req(\"{!frange incl=true incu=true\" + \" l=\" +v[0] +\" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange incl=false incu=false\" + \" l=\" +v[0] +\" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incl=false incu=false\" + \" l=\" +v[3] +\" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n    }\n\n  }\n\n","sourceOld":"  @Test\n  public void testRangeQueries() throws Exception {\n    // ensure that we aren't losing precision on any fields in addition to testing other non-numeric fields\n    // that aren't tested in testRandomRangeQueries()\n\n    int i=2000000000;\n    long l=500000000000000000L;\n    double d=0.3333333333333333;\n\n    // first 3 values will be indexed, the last two won't be\n    String[] ints = {\"\"+(i-1), \"\"+(i), \"\"+(i+1),   \"\"+(i-2), \"\"+(i+2)};\n    String[] longs = {\"\"+(l-1), \"\"+(l), \"\"+(l+1),  \"\"+(l-2), \"\"+(l+2)};\n    String[] doubles = {\"\"+(d-1e-16), \"\"+(d), \"\"+(d+1e-16),   \"\"+(d-2e-16), \"\"+(d+2e-16)};\n    String[] strings = {\"aaa\",\"bbb\",\"ccc\",  \"aa\",\"cccc\" };\n    String[] dates = {\"0299-12-31T23:59:59.999Z\",\"2000-01-01T00:00:00.000Z\",\"2000-01-01T00:00:00.001Z\",  \"0299-12-31T23:59:59.998Z\",\"2000-01-01T00:00:00.002Z\" };\n\n    // fields that normal range queries should work on\n    Map<String,String[]> norm_fields = new HashMap<String,String[]>();\n    norm_fields.put(\"foo_i\", ints);\n    norm_fields.put(\"foo_l\", longs);\n    norm_fields.put(\"foo_d\", doubles);\n\n    norm_fields.put(\"foo_ti\", ints);\n    norm_fields.put(\"foo_tl\", longs);\n    norm_fields.put(\"foo_td\", doubles);\n    norm_fields.put(\"foo_tdt\", dates);\n\n    norm_fields.put(\"foo_s\", strings);\n    norm_fields.put(\"foo_dt\", dates);\n\n\n    // fields that frange queries should work on\n    Map<String,String[]> frange_fields = new HashMap<String,String[]>();\n    frange_fields.put(\"foo_i\", ints);\n    frange_fields.put(\"foo_l\", longs);\n    frange_fields.put(\"foo_d\", doubles);\n\n    frange_fields.put(\"foo_ti\", ints);\n    frange_fields.put(\"foo_tl\", longs);\n    frange_fields.put(\"foo_td\", doubles);\n    frange_fields.put(\"foo_tdt\", dates);\n\n    frange_fields.put(\"foo_pi\", ints);\n    frange_fields.put(\"foo_pl\", longs);\n    frange_fields.put(\"foo_pd\", doubles);\n\n    frange_fields.put(\"foo_s\", strings);\n    frange_fields.put(\"foo_dt\", dates);\n\n    Map<String,String[]> all_fields = new HashMap<String,String[]>();\n    all_fields.putAll(norm_fields);\n    all_fields.putAll(frange_fields);\n\n    for (int j=0; j<ints.length-2; j++) {\n      List<String> fields = new ArrayList<String>();\n      fields.add(\"id\");\n      fields.add(\"\"+j);\n      for (Map.Entry<String,String[]> entry : all_fields.entrySet()) {\n        fields.add(entry.getKey());\n        fields.add(entry.getValue()[j]);\n      }\n      assertU(adoc(fields.toArray(new String[fields.size()])));\n    }\n\n    assertU(commit());\n\n    // simple test of a function rather than just the field\n    assertQ(req(\"{!frange l=0 u=2}id\"), \"*[count(//doc)=3]\");\n    assertQ(req(\"{!frange l=0 u=2}product(id,2)\"), \"*[count(//doc)=2]\");\n    assertQ(req(\"{!frange l=100 u=102}sum(id,100)\"), \"*[count(//doc)=3]\");\n\n\n    for (Map.Entry<String,String[]> entry : norm_fields.entrySet()) {\n      String f = entry.getKey();\n      String[] v = entry.getValue();\n\n      assertQ(req(f + \":[* TO *]\" ), \"*[count(//doc)=3]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=3]\");\n      assertQ(req(f + \":[\"+v[1]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=2]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[1]+\"]\"), \"*[count(//doc)=2]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[0]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[1]+\" TO \"+v[1]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[2]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[3]+\" TO \"+v[3]+\"]\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":[\"+v[4]+\" TO \"+v[4]+\"]\"), \"*[count(//doc)=0]\");\n\n      assertQ(req(f + \":{\"+v[0]+\" TO \"+v[2]+\"}\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":{\"+v[1]+\" TO \"+v[2]+\"}\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":{\"+v[0]+\" TO \"+v[1]+\"}\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":{\"+v[3]+\" TO \"+v[4]+\"}\"), \"*[count(//doc)=3]\");\n    }\n\n    for (Map.Entry<String,String[]> entry : frange_fields.entrySet()) {\n      String f = entry.getKey();\n      String[] v = entry.getValue();\n\n      assertQ(req(\"{!frange}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[0]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[1]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[2]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[3]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[4]+\"}\"+f ), \"*[count(//doc)=0]\");\n\n      assertQ(req(\"{!frange\" + \" u=\"+v[0]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[1]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[3]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[0]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[1]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[2]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[3]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[4]+\"}\"+f ), \"*[count(//doc)=0]\");\n\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[0]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[1]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[3]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n\n      assertQ(req(\"{!frange incl=true incu=true\" + \" l=\" +v[0] +\" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange incl=false incu=false\" + \" l=\" +v[0] +\" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incl=false incu=false\" + \" l=\" +v[3] +\" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2106271e380c198349e0f6eac0395bb462913fab","date":1397072894,"type":3,"author":"Steven Rowe","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRangeQuery#testRangeQueries().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRangeQuery#testRangeQueries().mjava","sourceNew":"  @Test\n  public void testRangeQueries() throws Exception {\n    // ensure that we aren't losing precision on any fields in addition to testing other non-numeric fields\n    // that aren't tested in testRandomRangeQueries()\n\n    int i=2000000000;\n    long l=500000000000000000L;\n    double d=0.3333333333333333;\n\n    // first 3 values will be indexed, the last two won't be\n    String[] ints = {\"\"+(i-1), \"\"+(i), \"\"+(i+1),   \"\"+(i-2), \"\"+(i+2)};\n    String[] longs = {\"\"+(l-1), \"\"+(l), \"\"+(l+1),  \"\"+(l-2), \"\"+(l+2)};\n    String[] doubles = {\"\"+(d-1e-16), \"\"+(d), \"\"+(d+1e-16),   \"\"+(d-2e-16), \"\"+(d+2e-16)};\n    String[] strings = {\"aaa\",\"bbb\",\"ccc\",  \"aa\",\"cccc\" };\n    String[] dates = {\"0299-12-31T23:59:59.999Z\",\"2000-01-01T00:00:00.000Z\",\"2000-01-01T00:00:00.001Z\",  \"0299-12-31T23:59:59.998Z\",\"2000-01-01T00:00:00.002Z\" };\n\n    // fields that normal range queries should work on\n    Map<String,String[]> norm_fields = new HashMap<>();\n    norm_fields.put(\"foo_i\", ints);\n    norm_fields.put(\"foo_l\", longs);\n    norm_fields.put(\"foo_d\", doubles);\n\n    norm_fields.put(\"foo_ti\", ints);\n    norm_fields.put(\"foo_tl\", longs);\n    norm_fields.put(\"foo_td\", doubles);\n    norm_fields.put(\"foo_tdt\", dates);\n\n    norm_fields.put(\"foo_s\", strings);\n    norm_fields.put(\"foo_dt\", dates);\n\n\n    // fields that frange queries should work on\n    Map<String,String[]> frange_fields = new HashMap<>();\n    frange_fields.put(\"foo_i\", ints);\n    frange_fields.put(\"foo_l\", longs);\n    frange_fields.put(\"foo_d\", doubles);\n\n    frange_fields.put(\"foo_ti\", ints);\n    frange_fields.put(\"foo_tl\", longs);\n    frange_fields.put(\"foo_td\", doubles);\n    frange_fields.put(\"foo_tdt\", dates);\n\n    frange_fields.put(\"foo_s\", strings);\n    frange_fields.put(\"foo_dt\", dates);\n\n    Map<String,String[]> all_fields = new HashMap<>();\n    all_fields.putAll(norm_fields);\n    all_fields.putAll(frange_fields);\n\n    for (int j=0; j<ints.length-2; j++) {\n      List<String> fields = new ArrayList<>();\n      fields.add(\"id\");\n      fields.add(\"\"+j);\n      for (Map.Entry<String,String[]> entry : all_fields.entrySet()) {\n        fields.add(entry.getKey());\n        fields.add(entry.getValue()[j]);\n      }\n      assertU(adoc(fields.toArray(new String[fields.size()])));\n    }\n\n    assertU(commit());\n\n    // simple test of a function rather than just the field\n    assertQ(req(\"{!frange l=0 u=2}id\"), \"*[count(//doc)=3]\");\n    assertQ(req(\"{!frange l=0 u=2}product(id,2)\"), \"*[count(//doc)=2]\");\n    assertQ(req(\"{!frange l=100 u=102}sum(id,100)\"), \"*[count(//doc)=3]\");\n\n\n    for (Map.Entry<String,String[]> entry : norm_fields.entrySet()) {\n      String f = entry.getKey();\n      String[] v = entry.getValue();\n\n      assertQ(req(f + \":[* TO *]\" ), \"*[count(//doc)=3]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=3]\");\n      assertQ(req(f + \":[\"+v[1]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=2]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[1]+\"]\"), \"*[count(//doc)=2]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[0]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[1]+\" TO \"+v[1]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[2]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[3]+\" TO \"+v[3]+\"]\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":[\"+v[4]+\" TO \"+v[4]+\"]\"), \"*[count(//doc)=0]\");\n\n      assertQ(req(f + \":{\"+v[0]+\" TO \"+v[2]+\"}\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":{\"+v[1]+\" TO \"+v[2]+\"}\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":{\"+v[0]+\" TO \"+v[1]+\"}\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":{\"+v[3]+\" TO \"+v[4]+\"}\"), \"*[count(//doc)=3]\");\n    }\n\n    for (Map.Entry<String,String[]> entry : frange_fields.entrySet()) {\n      String f = entry.getKey();\n      String[] v = entry.getValue();\n\n      assertQ(req(\"{!frange}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[0]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[1]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[2]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[3]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[4]+\"}\"+f ), \"*[count(//doc)=0]\");\n\n      assertQ(req(\"{!frange\" + \" u=\"+v[0]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[1]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[3]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[0]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[1]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[2]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[3]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[4]+\"}\"+f ), \"*[count(//doc)=0]\");\n\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[0]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[1]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[3]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n\n      assertQ(req(\"{!frange incl=true incu=true\" + \" l=\" +v[0] +\" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange incl=false incu=false\" + \" l=\" +v[0] +\" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incl=false incu=false\" + \" l=\" +v[3] +\" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n    }\n\n  }\n\n","sourceOld":"  @Test\n  public void testRangeQueries() throws Exception {\n    // ensure that we aren't losing precision on any fields in addition to testing other non-numeric fields\n    // that aren't tested in testRandomRangeQueries()\n\n    int i=2000000000;\n    long l=500000000000000000L;\n    double d=0.3333333333333333;\n\n    // first 3 values will be indexed, the last two won't be\n    String[] ints = {\"\"+(i-1), \"\"+(i), \"\"+(i+1),   \"\"+(i-2), \"\"+(i+2)};\n    String[] longs = {\"\"+(l-1), \"\"+(l), \"\"+(l+1),  \"\"+(l-2), \"\"+(l+2)};\n    String[] doubles = {\"\"+(d-1e-16), \"\"+(d), \"\"+(d+1e-16),   \"\"+(d-2e-16), \"\"+(d+2e-16)};\n    String[] strings = {\"aaa\",\"bbb\",\"ccc\",  \"aa\",\"cccc\" };\n    String[] dates = {\"0299-12-31T23:59:59.999Z\",\"2000-01-01T00:00:00.000Z\",\"2000-01-01T00:00:00.001Z\",  \"0299-12-31T23:59:59.998Z\",\"2000-01-01T00:00:00.002Z\" };\n\n    // fields that normal range queries should work on\n    Map<String,String[]> norm_fields = new HashMap<>();\n    norm_fields.put(\"foo_i\", ints);\n    norm_fields.put(\"foo_l\", longs);\n    norm_fields.put(\"foo_d\", doubles);\n\n    norm_fields.put(\"foo_ti\", ints);\n    norm_fields.put(\"foo_tl\", longs);\n    norm_fields.put(\"foo_td\", doubles);\n    norm_fields.put(\"foo_tdt\", dates);\n\n    norm_fields.put(\"foo_s\", strings);\n    norm_fields.put(\"foo_dt\", dates);\n\n\n    // fields that frange queries should work on\n    Map<String,String[]> frange_fields = new HashMap<>();\n    frange_fields.put(\"foo_i\", ints);\n    frange_fields.put(\"foo_l\", longs);\n    frange_fields.put(\"foo_d\", doubles);\n\n    frange_fields.put(\"foo_ti\", ints);\n    frange_fields.put(\"foo_tl\", longs);\n    frange_fields.put(\"foo_td\", doubles);\n    frange_fields.put(\"foo_tdt\", dates);\n\n    frange_fields.put(\"foo_pi\", ints);\n    frange_fields.put(\"foo_pl\", longs);\n    frange_fields.put(\"foo_pd\", doubles);\n\n    frange_fields.put(\"foo_s\", strings);\n    frange_fields.put(\"foo_dt\", dates);\n\n    Map<String,String[]> all_fields = new HashMap<>();\n    all_fields.putAll(norm_fields);\n    all_fields.putAll(frange_fields);\n\n    for (int j=0; j<ints.length-2; j++) {\n      List<String> fields = new ArrayList<>();\n      fields.add(\"id\");\n      fields.add(\"\"+j);\n      for (Map.Entry<String,String[]> entry : all_fields.entrySet()) {\n        fields.add(entry.getKey());\n        fields.add(entry.getValue()[j]);\n      }\n      assertU(adoc(fields.toArray(new String[fields.size()])));\n    }\n\n    assertU(commit());\n\n    // simple test of a function rather than just the field\n    assertQ(req(\"{!frange l=0 u=2}id\"), \"*[count(//doc)=3]\");\n    assertQ(req(\"{!frange l=0 u=2}product(id,2)\"), \"*[count(//doc)=2]\");\n    assertQ(req(\"{!frange l=100 u=102}sum(id,100)\"), \"*[count(//doc)=3]\");\n\n\n    for (Map.Entry<String,String[]> entry : norm_fields.entrySet()) {\n      String f = entry.getKey();\n      String[] v = entry.getValue();\n\n      assertQ(req(f + \":[* TO *]\" ), \"*[count(//doc)=3]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=3]\");\n      assertQ(req(f + \":[\"+v[1]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=2]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[1]+\"]\"), \"*[count(//doc)=2]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[0]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[1]+\" TO \"+v[1]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[2]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[3]+\" TO \"+v[3]+\"]\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":[\"+v[4]+\" TO \"+v[4]+\"]\"), \"*[count(//doc)=0]\");\n\n      assertQ(req(f + \":{\"+v[0]+\" TO \"+v[2]+\"}\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":{\"+v[1]+\" TO \"+v[2]+\"}\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":{\"+v[0]+\" TO \"+v[1]+\"}\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":{\"+v[3]+\" TO \"+v[4]+\"}\"), \"*[count(//doc)=3]\");\n    }\n\n    for (Map.Entry<String,String[]> entry : frange_fields.entrySet()) {\n      String f = entry.getKey();\n      String[] v = entry.getValue();\n\n      assertQ(req(\"{!frange}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[0]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[1]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[2]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[3]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[4]+\"}\"+f ), \"*[count(//doc)=0]\");\n\n      assertQ(req(\"{!frange\" + \" u=\"+v[0]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[1]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[3]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[0]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[1]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[2]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[3]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[4]+\"}\"+f ), \"*[count(//doc)=0]\");\n\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[0]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[1]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[3]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n\n      assertQ(req(\"{!frange incl=true incu=true\" + \" l=\" +v[0] +\" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange incl=false incu=false\" + \" l=\" +v[0] +\" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incl=false incu=false\" + \" l=\" +v[3] +\" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5cb157886ecc78f33fafd9d403e96a4a495503b3","date":1467753535,"type":3,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRangeQuery#testRangeQueries().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRangeQuery#testRangeQueries().mjava","sourceNew":"  @Test\n  public void testRangeQueries() throws Exception {\n    // ensure that we aren't losing precision on any fields in addition to testing other non-numeric fields\n    // that aren't tested in testRandomRangeQueries()\n\n    int i=2000000000;\n    long l=500000000000000000L;\n    double d=0.3333333333333333;\n\n    // first 3 values will be indexed, the last two won't be\n    String[] ints = {\"\"+(i-1), \"\"+(i), \"\"+(i+1),   \"\"+(i-2), \"\"+(i+2)};\n    String[] longs = {\"\"+(l-1), \"\"+(l), \"\"+(l+1),  \"\"+(l-2), \"\"+(l+2)};\n    String[] doubles = {\"\"+(d-1e-16), \"\"+(d), \"\"+(d+1e-16),   \"\"+(d-2e-16), \"\"+(d+2e-16)};\n    String[] strings = {\"aaa\",\"bbb\",\"ccc\",  \"aa\",\"cccc\" };\n    String[] dates = {\"0299-12-31T23:59:59.999Z\",\"2000-01-01T00:00:00.000Z\",\"2000-01-01T00:00:00.001Z\",  \"0299-12-31T23:59:59.998Z\",\"2000-01-01T00:00:00.002Z\" };\n\n    // fields that normal range queries should work on\n    Map<String,String[]> norm_fields = new HashMap<>();\n    norm_fields.put(\"foo_i\", ints);\n    norm_fields.put(\"foo_l\", longs);\n    norm_fields.put(\"foo_d\", doubles);\n\n    norm_fields.put(\"foo_ti\", ints);\n    norm_fields.put(\"foo_tl\", longs);\n    norm_fields.put(\"foo_td\", doubles);\n    norm_fields.put(\"foo_tdt\", dates);\n\n    norm_fields.put(\"foo_s\", strings);\n    norm_fields.put(\"foo_dt\", dates);\n\n\n    // fields that frange queries should work on\n    Map<String,String[]> frange_fields = new HashMap<>();\n    frange_fields.put(\"foo_i\", ints);\n    frange_fields.put(\"foo_l\", longs);\n    frange_fields.put(\"foo_d\", doubles);\n\n    frange_fields.put(\"foo_ti\", ints);\n    frange_fields.put(\"foo_tl\", longs);\n    frange_fields.put(\"foo_td\", doubles);\n    frange_fields.put(\"foo_tdt\", dates);\n\n    frange_fields.put(\"foo_s\", strings);\n    frange_fields.put(\"foo_dt\", dates);\n\n    Map<String,String[]> all_fields = new HashMap<>();\n    all_fields.putAll(norm_fields);\n    all_fields.putAll(frange_fields);\n\n    for (int j=0; j<ints.length-2; j++) {\n      List<String> fields = new ArrayList<>();\n      fields.add(\"id\");\n      fields.add(\"\"+j);\n      for (Map.Entry<String,String[]> entry : all_fields.entrySet()) {\n        fields.add(entry.getKey());\n        fields.add(entry.getValue()[j]);\n      }\n      assertU(adoc(fields.toArray(new String[fields.size()])));\n    }\n\n    assertU(commit());\n\n    // simple test of a function rather than just the field\n    assertQ(req(\"{!frange l=0 u=2}id\"), \"*[count(//doc)=3]\");\n    assertQ(req(\"{!frange l=0 u=2}product(id,2)\"), \"*[count(//doc)=2]\");\n    assertQ(req(\"{!frange l=100 u=102}sum(id,100)\"), \"*[count(//doc)=3]\");\n\n\n    for (Map.Entry<String,String[]> entry : norm_fields.entrySet()) {\n      String f = entry.getKey();\n      String[] v = entry.getValue();\n\n      assertQ(req(f + \":[* TO *]\" ), \"*[count(//doc)=3]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=3]\");\n      assertQ(req(f + \":[\"+v[1]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=2]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[1]+\"]\"), \"*[count(//doc)=2]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[0]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[1]+\" TO \"+v[1]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[2]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[3]+\" TO \"+v[3]+\"]\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":[\"+v[4]+\" TO \"+v[4]+\"]\"), \"*[count(//doc)=0]\");\n\n      assertQ(req(f + \":{\"+v[0]+\" TO \"+v[2]+\"}\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":{\"+v[1]+\" TO \"+v[2]+\"}\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":{\"+v[0]+\" TO \"+v[1]+\"}\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":{\"+v[3]+\" TO \"+v[4]+\"}\"), \"*[count(//doc)=3]\");\n    }\n\n    for (Map.Entry<String,String[]> entry : frange_fields.entrySet()) {\n      String f = entry.getKey();\n      String[] v = entry.getValue();\n\n      assertQ(req(\"{!frange}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[0]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[1]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[2]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[3]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[4]+\"}\"+f ), \"*[count(//doc)=0]\");\n\n      assertQ(req(\"{!frange\" + \" u=\"+v[0]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[1]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[3]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[0]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[1]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[2]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[3]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[4]+\"}\"+f ), \"*[count(//doc)=0]\");\n\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[0]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[1]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[3]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n\n      assertQ(req(\"{!frange incl=true incu=true\" + \" l=\" +v[0] +\" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange incl=false incu=false\" + \" l=\" +v[0] +\" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incl=false incu=false\" + \" l=\" +v[3] +\" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n    }\n\n    // now pick a random range to use to delete (some of) the docs...\n    \n    final boolean incl = random().nextBoolean();\n    final boolean incu = random().nextBoolean();\n    final int expected = 0 + (incl ? 0 : 1) + (incu ? 0 : 1);\n    String dbq = null;\n    if (random().nextBoolean()) { // regular range\n      String field = randomKey(norm_fields);\n      String[] values = norm_fields.get(field);\n      dbq = field + \":\" + (incl ? \"[\" : \"{\") + values[0] + \" TO \" + values[2] + (incu ? \"]\" : \"}\");\n    } else { // frange\n      String field = randomKey(frange_fields);\n      String[] values = frange_fields.get(field);\n      dbq = \"{!frange incl=\" + incl + \" incu=\" + incu + \" l=\" + values[0] + \" u=\" + values[2] + \"}\" + field;\n    }\n    if (random().nextBoolean()) {\n      // wrap in a BQ\n      String field = randomKey(norm_fields);\n      String value = norm_fields.get(field)[1];\n      // wraping shouldn't affect expected\n      dbq = \"(\"+field+\":\\\"\"+value+\"\\\" OR \" + dbq + \")\";\n    }    \n      \n    assertU(delQ(dbq));\n    assertU(commit());\n    assertQ(req(\"q\",\"*:*\",\"_trace_dbq\",dbq),\n            \"*[count(//doc)=\" + expected + \"]\");\n    \n  }\n\n","sourceOld":"  @Test\n  public void testRangeQueries() throws Exception {\n    // ensure that we aren't losing precision on any fields in addition to testing other non-numeric fields\n    // that aren't tested in testRandomRangeQueries()\n\n    int i=2000000000;\n    long l=500000000000000000L;\n    double d=0.3333333333333333;\n\n    // first 3 values will be indexed, the last two won't be\n    String[] ints = {\"\"+(i-1), \"\"+(i), \"\"+(i+1),   \"\"+(i-2), \"\"+(i+2)};\n    String[] longs = {\"\"+(l-1), \"\"+(l), \"\"+(l+1),  \"\"+(l-2), \"\"+(l+2)};\n    String[] doubles = {\"\"+(d-1e-16), \"\"+(d), \"\"+(d+1e-16),   \"\"+(d-2e-16), \"\"+(d+2e-16)};\n    String[] strings = {\"aaa\",\"bbb\",\"ccc\",  \"aa\",\"cccc\" };\n    String[] dates = {\"0299-12-31T23:59:59.999Z\",\"2000-01-01T00:00:00.000Z\",\"2000-01-01T00:00:00.001Z\",  \"0299-12-31T23:59:59.998Z\",\"2000-01-01T00:00:00.002Z\" };\n\n    // fields that normal range queries should work on\n    Map<String,String[]> norm_fields = new HashMap<>();\n    norm_fields.put(\"foo_i\", ints);\n    norm_fields.put(\"foo_l\", longs);\n    norm_fields.put(\"foo_d\", doubles);\n\n    norm_fields.put(\"foo_ti\", ints);\n    norm_fields.put(\"foo_tl\", longs);\n    norm_fields.put(\"foo_td\", doubles);\n    norm_fields.put(\"foo_tdt\", dates);\n\n    norm_fields.put(\"foo_s\", strings);\n    norm_fields.put(\"foo_dt\", dates);\n\n\n    // fields that frange queries should work on\n    Map<String,String[]> frange_fields = new HashMap<>();\n    frange_fields.put(\"foo_i\", ints);\n    frange_fields.put(\"foo_l\", longs);\n    frange_fields.put(\"foo_d\", doubles);\n\n    frange_fields.put(\"foo_ti\", ints);\n    frange_fields.put(\"foo_tl\", longs);\n    frange_fields.put(\"foo_td\", doubles);\n    frange_fields.put(\"foo_tdt\", dates);\n\n    frange_fields.put(\"foo_s\", strings);\n    frange_fields.put(\"foo_dt\", dates);\n\n    Map<String,String[]> all_fields = new HashMap<>();\n    all_fields.putAll(norm_fields);\n    all_fields.putAll(frange_fields);\n\n    for (int j=0; j<ints.length-2; j++) {\n      List<String> fields = new ArrayList<>();\n      fields.add(\"id\");\n      fields.add(\"\"+j);\n      for (Map.Entry<String,String[]> entry : all_fields.entrySet()) {\n        fields.add(entry.getKey());\n        fields.add(entry.getValue()[j]);\n      }\n      assertU(adoc(fields.toArray(new String[fields.size()])));\n    }\n\n    assertU(commit());\n\n    // simple test of a function rather than just the field\n    assertQ(req(\"{!frange l=0 u=2}id\"), \"*[count(//doc)=3]\");\n    assertQ(req(\"{!frange l=0 u=2}product(id,2)\"), \"*[count(//doc)=2]\");\n    assertQ(req(\"{!frange l=100 u=102}sum(id,100)\"), \"*[count(//doc)=3]\");\n\n\n    for (Map.Entry<String,String[]> entry : norm_fields.entrySet()) {\n      String f = entry.getKey();\n      String[] v = entry.getValue();\n\n      assertQ(req(f + \":[* TO *]\" ), \"*[count(//doc)=3]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=3]\");\n      assertQ(req(f + \":[\"+v[1]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=2]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[1]+\"]\"), \"*[count(//doc)=2]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[0]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[1]+\" TO \"+v[1]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[2]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[3]+\" TO \"+v[3]+\"]\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":[\"+v[4]+\" TO \"+v[4]+\"]\"), \"*[count(//doc)=0]\");\n\n      assertQ(req(f + \":{\"+v[0]+\" TO \"+v[2]+\"}\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":{\"+v[1]+\" TO \"+v[2]+\"}\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":{\"+v[0]+\" TO \"+v[1]+\"}\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":{\"+v[3]+\" TO \"+v[4]+\"}\"), \"*[count(//doc)=3]\");\n    }\n\n    for (Map.Entry<String,String[]> entry : frange_fields.entrySet()) {\n      String f = entry.getKey();\n      String[] v = entry.getValue();\n\n      assertQ(req(\"{!frange}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[0]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[1]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[2]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[3]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[4]+\"}\"+f ), \"*[count(//doc)=0]\");\n\n      assertQ(req(\"{!frange\" + \" u=\"+v[0]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[1]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[3]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[0]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[1]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[2]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[3]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[4]+\"}\"+f ), \"*[count(//doc)=0]\");\n\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[0]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[1]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[3]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n\n      assertQ(req(\"{!frange incl=true incu=true\" + \" l=\" +v[0] +\" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange incl=false incu=false\" + \" l=\" +v[0] +\" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incl=false incu=false\" + \" l=\" +v[3] +\" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRangeQuery#testRangeQueries().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRangeQuery#testRangeQueries().mjava","sourceNew":"  @Test\n  public void testRangeQueries() throws Exception {\n    // ensure that we aren't losing precision on any fields in addition to testing other non-numeric fields\n    // that aren't tested in testRandomRangeQueries()\n\n    int i=2000000000;\n    long l=500000000000000000L;\n    double d=0.3333333333333333;\n\n    // first 3 values will be indexed, the last two won't be\n    String[] ints = {\"\"+(i-1), \"\"+(i), \"\"+(i+1),   \"\"+(i-2), \"\"+(i+2)};\n    String[] longs = {\"\"+(l-1), \"\"+(l), \"\"+(l+1),  \"\"+(l-2), \"\"+(l+2)};\n    String[] doubles = {\"\"+(d-1e-16), \"\"+(d), \"\"+(d+1e-16),   \"\"+(d-2e-16), \"\"+(d+2e-16)};\n    String[] strings = {\"aaa\",\"bbb\",\"ccc\",  \"aa\",\"cccc\" };\n    String[] dates = {\"0299-12-31T23:59:59.999Z\",\"2000-01-01T00:00:00.000Z\",\"2000-01-01T00:00:00.001Z\",  \"0299-12-31T23:59:59.998Z\",\"2000-01-01T00:00:00.002Z\" };\n\n    // fields that normal range queries should work on\n    Map<String,String[]> norm_fields = new HashMap<>();\n    norm_fields.put(\"foo_i\", ints);\n    norm_fields.put(\"foo_l\", longs);\n    norm_fields.put(\"foo_d\", doubles);\n\n    norm_fields.put(\"foo_ti\", ints);\n    norm_fields.put(\"foo_tl\", longs);\n    norm_fields.put(\"foo_td\", doubles);\n    norm_fields.put(\"foo_tdt\", dates);\n\n    norm_fields.put(\"foo_s\", strings);\n    norm_fields.put(\"foo_dt\", dates);\n\n\n    // fields that frange queries should work on\n    Map<String,String[]> frange_fields = new HashMap<>();\n    frange_fields.put(\"foo_i\", ints);\n    frange_fields.put(\"foo_l\", longs);\n    frange_fields.put(\"foo_d\", doubles);\n\n    frange_fields.put(\"foo_ti\", ints);\n    frange_fields.put(\"foo_tl\", longs);\n    frange_fields.put(\"foo_td\", doubles);\n    frange_fields.put(\"foo_tdt\", dates);\n\n    frange_fields.put(\"foo_s\", strings);\n    frange_fields.put(\"foo_dt\", dates);\n\n    Map<String,String[]> all_fields = new HashMap<>();\n    all_fields.putAll(norm_fields);\n    all_fields.putAll(frange_fields);\n\n    for (int j=0; j<ints.length-2; j++) {\n      List<String> fields = new ArrayList<>();\n      fields.add(\"id\");\n      fields.add(\"\"+j);\n      for (Map.Entry<String,String[]> entry : all_fields.entrySet()) {\n        fields.add(entry.getKey());\n        fields.add(entry.getValue()[j]);\n      }\n      assertU(adoc(fields.toArray(new String[fields.size()])));\n    }\n\n    assertU(commit());\n\n    // simple test of a function rather than just the field\n    assertQ(req(\"{!frange l=0 u=2}id\"), \"*[count(//doc)=3]\");\n    assertQ(req(\"{!frange l=0 u=2}product(id,2)\"), \"*[count(//doc)=2]\");\n    assertQ(req(\"{!frange l=100 u=102}sum(id,100)\"), \"*[count(//doc)=3]\");\n\n\n    for (Map.Entry<String,String[]> entry : norm_fields.entrySet()) {\n      String f = entry.getKey();\n      String[] v = entry.getValue();\n\n      assertQ(req(f + \":[* TO *]\" ), \"*[count(//doc)=3]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=3]\");\n      assertQ(req(f + \":[\"+v[1]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=2]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[1]+\"]\"), \"*[count(//doc)=2]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[0]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[1]+\" TO \"+v[1]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[2]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[3]+\" TO \"+v[3]+\"]\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":[\"+v[4]+\" TO \"+v[4]+\"]\"), \"*[count(//doc)=0]\");\n\n      assertQ(req(f + \":{\"+v[0]+\" TO \"+v[2]+\"}\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":{\"+v[1]+\" TO \"+v[2]+\"}\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":{\"+v[0]+\" TO \"+v[1]+\"}\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":{\"+v[3]+\" TO \"+v[4]+\"}\"), \"*[count(//doc)=3]\");\n    }\n\n    for (Map.Entry<String,String[]> entry : frange_fields.entrySet()) {\n      String f = entry.getKey();\n      String[] v = entry.getValue();\n\n      assertQ(req(\"{!frange}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[0]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[1]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[2]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[3]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[4]+\"}\"+f ), \"*[count(//doc)=0]\");\n\n      assertQ(req(\"{!frange\" + \" u=\"+v[0]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[1]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[3]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[0]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[1]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[2]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[3]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[4]+\"}\"+f ), \"*[count(//doc)=0]\");\n\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[0]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[1]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[3]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n\n      assertQ(req(\"{!frange incl=true incu=true\" + \" l=\" +v[0] +\" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange incl=false incu=false\" + \" l=\" +v[0] +\" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incl=false incu=false\" + \" l=\" +v[3] +\" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n    }\n\n    // now pick a random range to use to delete (some of) the docs...\n    \n    final boolean incl = random().nextBoolean();\n    final boolean incu = random().nextBoolean();\n    final int expected = 0 + (incl ? 0 : 1) + (incu ? 0 : 1);\n    String dbq = null;\n    if (random().nextBoolean()) { // regular range\n      String field = randomKey(norm_fields);\n      String[] values = norm_fields.get(field);\n      dbq = field + \":\" + (incl ? \"[\" : \"{\") + values[0] + \" TO \" + values[2] + (incu ? \"]\" : \"}\");\n    } else { // frange\n      String field = randomKey(frange_fields);\n      String[] values = frange_fields.get(field);\n      dbq = \"{!frange incl=\" + incl + \" incu=\" + incu + \" l=\" + values[0] + \" u=\" + values[2] + \"}\" + field;\n    }\n    if (random().nextBoolean()) {\n      // wrap in a BQ\n      String field = randomKey(norm_fields);\n      String value = norm_fields.get(field)[1];\n      // wraping shouldn't affect expected\n      dbq = \"(\"+field+\":\\\"\"+value+\"\\\" OR \" + dbq + \")\";\n    }    \n      \n    assertU(delQ(dbq));\n    assertU(commit());\n    assertQ(req(\"q\",\"*:*\",\"_trace_dbq\",dbq),\n            \"*[count(//doc)=\" + expected + \"]\");\n    \n  }\n\n","sourceOld":"  @Test\n  public void testRangeQueries() throws Exception {\n    // ensure that we aren't losing precision on any fields in addition to testing other non-numeric fields\n    // that aren't tested in testRandomRangeQueries()\n\n    int i=2000000000;\n    long l=500000000000000000L;\n    double d=0.3333333333333333;\n\n    // first 3 values will be indexed, the last two won't be\n    String[] ints = {\"\"+(i-1), \"\"+(i), \"\"+(i+1),   \"\"+(i-2), \"\"+(i+2)};\n    String[] longs = {\"\"+(l-1), \"\"+(l), \"\"+(l+1),  \"\"+(l-2), \"\"+(l+2)};\n    String[] doubles = {\"\"+(d-1e-16), \"\"+(d), \"\"+(d+1e-16),   \"\"+(d-2e-16), \"\"+(d+2e-16)};\n    String[] strings = {\"aaa\",\"bbb\",\"ccc\",  \"aa\",\"cccc\" };\n    String[] dates = {\"0299-12-31T23:59:59.999Z\",\"2000-01-01T00:00:00.000Z\",\"2000-01-01T00:00:00.001Z\",  \"0299-12-31T23:59:59.998Z\",\"2000-01-01T00:00:00.002Z\" };\n\n    // fields that normal range queries should work on\n    Map<String,String[]> norm_fields = new HashMap<>();\n    norm_fields.put(\"foo_i\", ints);\n    norm_fields.put(\"foo_l\", longs);\n    norm_fields.put(\"foo_d\", doubles);\n\n    norm_fields.put(\"foo_ti\", ints);\n    norm_fields.put(\"foo_tl\", longs);\n    norm_fields.put(\"foo_td\", doubles);\n    norm_fields.put(\"foo_tdt\", dates);\n\n    norm_fields.put(\"foo_s\", strings);\n    norm_fields.put(\"foo_dt\", dates);\n\n\n    // fields that frange queries should work on\n    Map<String,String[]> frange_fields = new HashMap<>();\n    frange_fields.put(\"foo_i\", ints);\n    frange_fields.put(\"foo_l\", longs);\n    frange_fields.put(\"foo_d\", doubles);\n\n    frange_fields.put(\"foo_ti\", ints);\n    frange_fields.put(\"foo_tl\", longs);\n    frange_fields.put(\"foo_td\", doubles);\n    frange_fields.put(\"foo_tdt\", dates);\n\n    frange_fields.put(\"foo_s\", strings);\n    frange_fields.put(\"foo_dt\", dates);\n\n    Map<String,String[]> all_fields = new HashMap<>();\n    all_fields.putAll(norm_fields);\n    all_fields.putAll(frange_fields);\n\n    for (int j=0; j<ints.length-2; j++) {\n      List<String> fields = new ArrayList<>();\n      fields.add(\"id\");\n      fields.add(\"\"+j);\n      for (Map.Entry<String,String[]> entry : all_fields.entrySet()) {\n        fields.add(entry.getKey());\n        fields.add(entry.getValue()[j]);\n      }\n      assertU(adoc(fields.toArray(new String[fields.size()])));\n    }\n\n    assertU(commit());\n\n    // simple test of a function rather than just the field\n    assertQ(req(\"{!frange l=0 u=2}id\"), \"*[count(//doc)=3]\");\n    assertQ(req(\"{!frange l=0 u=2}product(id,2)\"), \"*[count(//doc)=2]\");\n    assertQ(req(\"{!frange l=100 u=102}sum(id,100)\"), \"*[count(//doc)=3]\");\n\n\n    for (Map.Entry<String,String[]> entry : norm_fields.entrySet()) {\n      String f = entry.getKey();\n      String[] v = entry.getValue();\n\n      assertQ(req(f + \":[* TO *]\" ), \"*[count(//doc)=3]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=3]\");\n      assertQ(req(f + \":[\"+v[1]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=2]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[1]+\"]\"), \"*[count(//doc)=2]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[0]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[1]+\" TO \"+v[1]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[2]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[3]+\" TO \"+v[3]+\"]\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":[\"+v[4]+\" TO \"+v[4]+\"]\"), \"*[count(//doc)=0]\");\n\n      assertQ(req(f + \":{\"+v[0]+\" TO \"+v[2]+\"}\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":{\"+v[1]+\" TO \"+v[2]+\"}\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":{\"+v[0]+\" TO \"+v[1]+\"}\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":{\"+v[3]+\" TO \"+v[4]+\"}\"), \"*[count(//doc)=3]\");\n    }\n\n    for (Map.Entry<String,String[]> entry : frange_fields.entrySet()) {\n      String f = entry.getKey();\n      String[] v = entry.getValue();\n\n      assertQ(req(\"{!frange}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[0]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[1]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[2]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[3]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[4]+\"}\"+f ), \"*[count(//doc)=0]\");\n\n      assertQ(req(\"{!frange\" + \" u=\"+v[0]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[1]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[3]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[0]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[1]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[2]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[3]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[4]+\"}\"+f ), \"*[count(//doc)=0]\");\n\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[0]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[1]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[3]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n\n      assertQ(req(\"{!frange incl=true incu=true\" + \" l=\" +v[0] +\" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange incl=false incu=false\" + \" l=\" +v[0] +\" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incl=false incu=false\" + \" l=\" +v[3] +\" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a71f63026529f3c1f03cfdd664910873ab2369ae","date":1497543264,"type":3,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRangeQuery#testRangeQueries().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRangeQuery#testRangeQueries().mjava","sourceNew":"  @Test\n  public void testRangeQueries() throws Exception {\n    // ensure that we aren't losing precision on any fields in addition to testing other non-numeric fields\n    // that aren't tested in testRandomRangeQueries()\n\n    int i=2000000000;\n    long l=500000000000000000L;\n    double d=0.3333333333333333;\n\n    // first 3 values will be indexed, the last two won't be\n    String[] ints = {\"\"+(i-1), \"\"+(i), \"\"+(i+1),   \"\"+(i-2), \"\"+(i+2)};\n    String[] longs = {\"\"+(l-1), \"\"+(l), \"\"+(l+1),  \"\"+(l-2), \"\"+(l+2)};\n    String[] doubles = {\"\"+(d-1e-16), \"\"+(d), \"\"+(d+1e-16),   \"\"+(d-2e-16), \"\"+(d+2e-16)};\n    String[] strings = {\"aaa\",\"bbb\",\"ccc\",  \"aa\",\"cccc\" };\n    String[] dates = {\"0299-12-31T23:59:59.999Z\",\"2000-01-01T00:00:00.000Z\",\"2000-01-01T00:00:00.001Z\",  \"0299-12-31T23:59:59.998Z\",\"2000-01-01T00:00:00.002Z\" };\n\n    // fields that normal range queries should work on\n    Map<String,String[]> norm_fields = new HashMap<>();\n    norm_fields.put(\"foo_i\", ints);\n    norm_fields.put(\"foo_l\", longs);\n    norm_fields.put(\"foo_d\", doubles);\n\n    norm_fields.put(\"foo_ti\", ints);\n    norm_fields.put(\"foo_tl\", longs);\n    norm_fields.put(\"foo_td\", doubles);\n    norm_fields.put(\"foo_tdt\", dates);\n\n    norm_fields.put(\"foo_s\", strings);\n    norm_fields.put(\"foo_dt\", dates);\n\n\n    // fields that frange queries should work on\n    Map<String,String[]> frange_fields = new HashMap<>();\n    frange_fields.put(\"foo_i\", ints);\n    frange_fields.put(\"foo_l\", longs);\n    frange_fields.put(\"foo_d\", doubles);\n\n    frange_fields.put(\"foo_ti\", ints);\n    frange_fields.put(\"foo_tl\", longs);\n    frange_fields.put(\"foo_td\", doubles);\n    frange_fields.put(\"foo_tdt\", dates);\n\n    frange_fields.put(\"foo_s\", strings);\n    frange_fields.put(\"foo_dt\", dates);\n\n    Map<String,String[]> all_fields = new HashMap<>();\n    all_fields.putAll(norm_fields);\n    all_fields.putAll(frange_fields);\n\n    for (int j=0; j<ints.length-2; j++) {\n      List<String> fields = new ArrayList<>();\n      fields.add(\"id\");\n      fields.add(\"\"+j);\n      for (Map.Entry<String,String[]> entry : all_fields.entrySet()) {\n        fields.add(entry.getKey());\n        fields.add(entry.getValue()[j]);\n      }\n      assertU(adoc(fields.toArray(new String[fields.size()])));\n    }\n\n    assertU(commit());\n\n    // simple test of a function rather than just the field\n    assertQ(req(\"{!frange l=0 u=2}id\"), \"*[count(//doc)=3]\");\n    assertQ(req(\"{!frange l=0 u=2}product(id_i,2)\"), \"*[count(//doc)=2]\");\n    assertQ(req(\"{!frange l=100 u=102}sum(id_i,100)\"), \"*[count(//doc)=3]\");\n\n\n    for (Map.Entry<String,String[]> entry : norm_fields.entrySet()) {\n      String f = entry.getKey();\n      String[] v = entry.getValue();\n\n      assertQ(req(f + \":[* TO *]\" ), \"*[count(//doc)=3]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=3]\");\n      assertQ(req(f + \":[\"+v[1]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=2]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[1]+\"]\"), \"*[count(//doc)=2]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[0]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[1]+\" TO \"+v[1]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[2]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[3]+\" TO \"+v[3]+\"]\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":[\"+v[4]+\" TO \"+v[4]+\"]\"), \"*[count(//doc)=0]\");\n\n      assertQ(req(f + \":{\"+v[0]+\" TO \"+v[2]+\"}\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":{\"+v[1]+\" TO \"+v[2]+\"}\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":{\"+v[0]+\" TO \"+v[1]+\"}\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":{\"+v[3]+\" TO \"+v[4]+\"}\"), \"*[count(//doc)=3]\");\n    }\n\n    for (Map.Entry<String,String[]> entry : frange_fields.entrySet()) {\n      String f = entry.getKey();\n      String[] v = entry.getValue();\n\n      assertQ(req(\"{!frange}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[0]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[1]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[2]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[3]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[4]+\"}\"+f ), \"*[count(//doc)=0]\");\n\n      assertQ(req(\"{!frange\" + \" u=\"+v[0]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[1]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[3]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[0]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[1]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[2]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[3]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[4]+\"}\"+f ), \"*[count(//doc)=0]\");\n\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[0]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[1]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[3]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n\n      assertQ(req(\"{!frange incl=true incu=true\" + \" l=\" +v[0] +\" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange incl=false incu=false\" + \" l=\" +v[0] +\" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incl=false incu=false\" + \" l=\" +v[3] +\" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n    }\n\n    // now pick a random range to use to delete (some of) the docs...\n    \n    final boolean incl = random().nextBoolean();\n    final boolean incu = random().nextBoolean();\n    final int expected = 0 + (incl ? 0 : 1) + (incu ? 0 : 1);\n    String dbq = null;\n    if (random().nextBoolean()) { // regular range\n      String field = randomKey(norm_fields);\n      String[] values = norm_fields.get(field);\n      dbq = field + \":\" + (incl ? \"[\" : \"{\") + values[0] + \" TO \" + values[2] + (incu ? \"]\" : \"}\");\n    } else { // frange\n      String field = randomKey(frange_fields);\n      String[] values = frange_fields.get(field);\n      dbq = \"{!frange incl=\" + incl + \" incu=\" + incu + \" l=\" + values[0] + \" u=\" + values[2] + \"}\" + field;\n    }\n    if (random().nextBoolean()) {\n      // wrap in a BQ\n      String field = randomKey(norm_fields);\n      String value = norm_fields.get(field)[1];\n      // wraping shouldn't affect expected\n      dbq = \"(\"+field+\":\\\"\"+value+\"\\\" OR \" + dbq + \")\";\n    }    \n      \n    assertU(delQ(dbq));\n    assertU(commit());\n    assertQ(req(\"q\",\"*:*\",\"_trace_dbq\",dbq),\n            \"*[count(//doc)=\" + expected + \"]\");\n    \n  }\n\n","sourceOld":"  @Test\n  public void testRangeQueries() throws Exception {\n    // ensure that we aren't losing precision on any fields in addition to testing other non-numeric fields\n    // that aren't tested in testRandomRangeQueries()\n\n    int i=2000000000;\n    long l=500000000000000000L;\n    double d=0.3333333333333333;\n\n    // first 3 values will be indexed, the last two won't be\n    String[] ints = {\"\"+(i-1), \"\"+(i), \"\"+(i+1),   \"\"+(i-2), \"\"+(i+2)};\n    String[] longs = {\"\"+(l-1), \"\"+(l), \"\"+(l+1),  \"\"+(l-2), \"\"+(l+2)};\n    String[] doubles = {\"\"+(d-1e-16), \"\"+(d), \"\"+(d+1e-16),   \"\"+(d-2e-16), \"\"+(d+2e-16)};\n    String[] strings = {\"aaa\",\"bbb\",\"ccc\",  \"aa\",\"cccc\" };\n    String[] dates = {\"0299-12-31T23:59:59.999Z\",\"2000-01-01T00:00:00.000Z\",\"2000-01-01T00:00:00.001Z\",  \"0299-12-31T23:59:59.998Z\",\"2000-01-01T00:00:00.002Z\" };\n\n    // fields that normal range queries should work on\n    Map<String,String[]> norm_fields = new HashMap<>();\n    norm_fields.put(\"foo_i\", ints);\n    norm_fields.put(\"foo_l\", longs);\n    norm_fields.put(\"foo_d\", doubles);\n\n    norm_fields.put(\"foo_ti\", ints);\n    norm_fields.put(\"foo_tl\", longs);\n    norm_fields.put(\"foo_td\", doubles);\n    norm_fields.put(\"foo_tdt\", dates);\n\n    norm_fields.put(\"foo_s\", strings);\n    norm_fields.put(\"foo_dt\", dates);\n\n\n    // fields that frange queries should work on\n    Map<String,String[]> frange_fields = new HashMap<>();\n    frange_fields.put(\"foo_i\", ints);\n    frange_fields.put(\"foo_l\", longs);\n    frange_fields.put(\"foo_d\", doubles);\n\n    frange_fields.put(\"foo_ti\", ints);\n    frange_fields.put(\"foo_tl\", longs);\n    frange_fields.put(\"foo_td\", doubles);\n    frange_fields.put(\"foo_tdt\", dates);\n\n    frange_fields.put(\"foo_s\", strings);\n    frange_fields.put(\"foo_dt\", dates);\n\n    Map<String,String[]> all_fields = new HashMap<>();\n    all_fields.putAll(norm_fields);\n    all_fields.putAll(frange_fields);\n\n    for (int j=0; j<ints.length-2; j++) {\n      List<String> fields = new ArrayList<>();\n      fields.add(\"id\");\n      fields.add(\"\"+j);\n      for (Map.Entry<String,String[]> entry : all_fields.entrySet()) {\n        fields.add(entry.getKey());\n        fields.add(entry.getValue()[j]);\n      }\n      assertU(adoc(fields.toArray(new String[fields.size()])));\n    }\n\n    assertU(commit());\n\n    // simple test of a function rather than just the field\n    assertQ(req(\"{!frange l=0 u=2}id\"), \"*[count(//doc)=3]\");\n    assertQ(req(\"{!frange l=0 u=2}product(id,2)\"), \"*[count(//doc)=2]\");\n    assertQ(req(\"{!frange l=100 u=102}sum(id,100)\"), \"*[count(//doc)=3]\");\n\n\n    for (Map.Entry<String,String[]> entry : norm_fields.entrySet()) {\n      String f = entry.getKey();\n      String[] v = entry.getValue();\n\n      assertQ(req(f + \":[* TO *]\" ), \"*[count(//doc)=3]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=3]\");\n      assertQ(req(f + \":[\"+v[1]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=2]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[1]+\"]\"), \"*[count(//doc)=2]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[0]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[1]+\" TO \"+v[1]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[2]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[3]+\" TO \"+v[3]+\"]\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":[\"+v[4]+\" TO \"+v[4]+\"]\"), \"*[count(//doc)=0]\");\n\n      assertQ(req(f + \":{\"+v[0]+\" TO \"+v[2]+\"}\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":{\"+v[1]+\" TO \"+v[2]+\"}\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":{\"+v[0]+\" TO \"+v[1]+\"}\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":{\"+v[3]+\" TO \"+v[4]+\"}\"), \"*[count(//doc)=3]\");\n    }\n\n    for (Map.Entry<String,String[]> entry : frange_fields.entrySet()) {\n      String f = entry.getKey();\n      String[] v = entry.getValue();\n\n      assertQ(req(\"{!frange}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[0]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[1]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[2]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[3]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[4]+\"}\"+f ), \"*[count(//doc)=0]\");\n\n      assertQ(req(\"{!frange\" + \" u=\"+v[0]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[1]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[3]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[0]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[1]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[2]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[3]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[4]+\"}\"+f ), \"*[count(//doc)=0]\");\n\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[0]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[1]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[3]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n\n      assertQ(req(\"{!frange incl=true incu=true\" + \" l=\" +v[0] +\" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange incl=false incu=false\" + \" l=\" +v[0] +\" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incl=false incu=false\" + \" l=\" +v[3] +\" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n    }\n\n    // now pick a random range to use to delete (some of) the docs...\n    \n    final boolean incl = random().nextBoolean();\n    final boolean incu = random().nextBoolean();\n    final int expected = 0 + (incl ? 0 : 1) + (incu ? 0 : 1);\n    String dbq = null;\n    if (random().nextBoolean()) { // regular range\n      String field = randomKey(norm_fields);\n      String[] values = norm_fields.get(field);\n      dbq = field + \":\" + (incl ? \"[\" : \"{\") + values[0] + \" TO \" + values[2] + (incu ? \"]\" : \"}\");\n    } else { // frange\n      String field = randomKey(frange_fields);\n      String[] values = frange_fields.get(field);\n      dbq = \"{!frange incl=\" + incl + \" incu=\" + incu + \" l=\" + values[0] + \" u=\" + values[2] + \"}\" + field;\n    }\n    if (random().nextBoolean()) {\n      // wrap in a BQ\n      String field = randomKey(norm_fields);\n      String value = norm_fields.get(field)[1];\n      // wraping shouldn't affect expected\n      dbq = \"(\"+field+\":\\\"\"+value+\"\\\" OR \" + dbq + \")\";\n    }    \n      \n    assertU(delQ(dbq));\n    assertU(commit());\n    assertQ(req(\"q\",\"*:*\",\"_trace_dbq\",dbq),\n            \"*[count(//doc)=\" + expected + \"]\");\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9","date":1498028748,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRangeQuery#testRangeQueries().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRangeQuery#testRangeQueries().mjava","sourceNew":"  @Test\n  public void testRangeQueries() throws Exception {\n    // ensure that we aren't losing precision on any fields in addition to testing other non-numeric fields\n    // that aren't tested in testRandomRangeQueries()\n\n    int i=2000000000;\n    long l=500000000000000000L;\n    double d=0.3333333333333333;\n\n    // first 3 values will be indexed, the last two won't be\n    String[] ints = {\"\"+(i-1), \"\"+(i), \"\"+(i+1),   \"\"+(i-2), \"\"+(i+2)};\n    String[] longs = {\"\"+(l-1), \"\"+(l), \"\"+(l+1),  \"\"+(l-2), \"\"+(l+2)};\n    String[] doubles = {\"\"+(d-1e-16), \"\"+(d), \"\"+(d+1e-16),   \"\"+(d-2e-16), \"\"+(d+2e-16)};\n    String[] strings = {\"aaa\",\"bbb\",\"ccc\",  \"aa\",\"cccc\" };\n    String[] dates = {\"0299-12-31T23:59:59.999Z\",\"2000-01-01T00:00:00.000Z\",\"2000-01-01T00:00:00.001Z\",  \"0299-12-31T23:59:59.998Z\",\"2000-01-01T00:00:00.002Z\" };\n\n    // fields that normal range queries should work on\n    Map<String,String[]> norm_fields = new HashMap<>();\n    norm_fields.put(\"foo_i\", ints);\n    norm_fields.put(\"foo_l\", longs);\n    norm_fields.put(\"foo_d\", doubles);\n\n    norm_fields.put(\"foo_ti\", ints);\n    norm_fields.put(\"foo_tl\", longs);\n    norm_fields.put(\"foo_td\", doubles);\n    norm_fields.put(\"foo_tdt\", dates);\n\n    norm_fields.put(\"foo_s\", strings);\n    norm_fields.put(\"foo_dt\", dates);\n\n\n    // fields that frange queries should work on\n    Map<String,String[]> frange_fields = new HashMap<>();\n    frange_fields.put(\"foo_i\", ints);\n    frange_fields.put(\"foo_l\", longs);\n    frange_fields.put(\"foo_d\", doubles);\n\n    frange_fields.put(\"foo_ti\", ints);\n    frange_fields.put(\"foo_tl\", longs);\n    frange_fields.put(\"foo_td\", doubles);\n    frange_fields.put(\"foo_tdt\", dates);\n\n    frange_fields.put(\"foo_s\", strings);\n    frange_fields.put(\"foo_dt\", dates);\n\n    Map<String,String[]> all_fields = new HashMap<>();\n    all_fields.putAll(norm_fields);\n    all_fields.putAll(frange_fields);\n\n    for (int j=0; j<ints.length-2; j++) {\n      List<String> fields = new ArrayList<>();\n      fields.add(\"id\");\n      fields.add(\"\"+j);\n      for (Map.Entry<String,String[]> entry : all_fields.entrySet()) {\n        fields.add(entry.getKey());\n        fields.add(entry.getValue()[j]);\n      }\n      assertU(adoc(fields.toArray(new String[fields.size()])));\n    }\n\n    assertU(commit());\n\n    // simple test of a function rather than just the field\n    assertQ(req(\"{!frange l=0 u=2}id\"), \"*[count(//doc)=3]\");\n    assertQ(req(\"{!frange l=0 u=2}product(id_i,2)\"), \"*[count(//doc)=2]\");\n    assertQ(req(\"{!frange l=100 u=102}sum(id_i,100)\"), \"*[count(//doc)=3]\");\n\n\n    for (Map.Entry<String,String[]> entry : norm_fields.entrySet()) {\n      String f = entry.getKey();\n      String[] v = entry.getValue();\n\n      assertQ(req(f + \":[* TO *]\" ), \"*[count(//doc)=3]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=3]\");\n      assertQ(req(f + \":[\"+v[1]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=2]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[1]+\"]\"), \"*[count(//doc)=2]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[0]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[1]+\" TO \"+v[1]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[2]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[3]+\" TO \"+v[3]+\"]\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":[\"+v[4]+\" TO \"+v[4]+\"]\"), \"*[count(//doc)=0]\");\n\n      assertQ(req(f + \":{\"+v[0]+\" TO \"+v[2]+\"}\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":{\"+v[1]+\" TO \"+v[2]+\"}\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":{\"+v[0]+\" TO \"+v[1]+\"}\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":{\"+v[3]+\" TO \"+v[4]+\"}\"), \"*[count(//doc)=3]\");\n    }\n\n    for (Map.Entry<String,String[]> entry : frange_fields.entrySet()) {\n      String f = entry.getKey();\n      String[] v = entry.getValue();\n\n      assertQ(req(\"{!frange}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[0]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[1]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[2]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[3]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[4]+\"}\"+f ), \"*[count(//doc)=0]\");\n\n      assertQ(req(\"{!frange\" + \" u=\"+v[0]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[1]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[3]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[0]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[1]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[2]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[3]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[4]+\"}\"+f ), \"*[count(//doc)=0]\");\n\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[0]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[1]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[3]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n\n      assertQ(req(\"{!frange incl=true incu=true\" + \" l=\" +v[0] +\" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange incl=false incu=false\" + \" l=\" +v[0] +\" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incl=false incu=false\" + \" l=\" +v[3] +\" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n    }\n\n    // now pick a random range to use to delete (some of) the docs...\n    \n    final boolean incl = random().nextBoolean();\n    final boolean incu = random().nextBoolean();\n    final int expected = 0 + (incl ? 0 : 1) + (incu ? 0 : 1);\n    String dbq = null;\n    if (random().nextBoolean()) { // regular range\n      String field = randomKey(norm_fields);\n      String[] values = norm_fields.get(field);\n      dbq = field + \":\" + (incl ? \"[\" : \"{\") + values[0] + \" TO \" + values[2] + (incu ? \"]\" : \"}\");\n    } else { // frange\n      String field = randomKey(frange_fields);\n      String[] values = frange_fields.get(field);\n      dbq = \"{!frange incl=\" + incl + \" incu=\" + incu + \" l=\" + values[0] + \" u=\" + values[2] + \"}\" + field;\n    }\n    if (random().nextBoolean()) {\n      // wrap in a BQ\n      String field = randomKey(norm_fields);\n      String value = norm_fields.get(field)[1];\n      // wraping shouldn't affect expected\n      dbq = \"(\"+field+\":\\\"\"+value+\"\\\" OR \" + dbq + \")\";\n    }    \n      \n    assertU(delQ(dbq));\n    assertU(commit());\n    assertQ(req(\"q\",\"*:*\",\"_trace_dbq\",dbq),\n            \"*[count(//doc)=\" + expected + \"]\");\n    \n  }\n\n","sourceOld":"  @Test\n  public void testRangeQueries() throws Exception {\n    // ensure that we aren't losing precision on any fields in addition to testing other non-numeric fields\n    // that aren't tested in testRandomRangeQueries()\n\n    int i=2000000000;\n    long l=500000000000000000L;\n    double d=0.3333333333333333;\n\n    // first 3 values will be indexed, the last two won't be\n    String[] ints = {\"\"+(i-1), \"\"+(i), \"\"+(i+1),   \"\"+(i-2), \"\"+(i+2)};\n    String[] longs = {\"\"+(l-1), \"\"+(l), \"\"+(l+1),  \"\"+(l-2), \"\"+(l+2)};\n    String[] doubles = {\"\"+(d-1e-16), \"\"+(d), \"\"+(d+1e-16),   \"\"+(d-2e-16), \"\"+(d+2e-16)};\n    String[] strings = {\"aaa\",\"bbb\",\"ccc\",  \"aa\",\"cccc\" };\n    String[] dates = {\"0299-12-31T23:59:59.999Z\",\"2000-01-01T00:00:00.000Z\",\"2000-01-01T00:00:00.001Z\",  \"0299-12-31T23:59:59.998Z\",\"2000-01-01T00:00:00.002Z\" };\n\n    // fields that normal range queries should work on\n    Map<String,String[]> norm_fields = new HashMap<>();\n    norm_fields.put(\"foo_i\", ints);\n    norm_fields.put(\"foo_l\", longs);\n    norm_fields.put(\"foo_d\", doubles);\n\n    norm_fields.put(\"foo_ti\", ints);\n    norm_fields.put(\"foo_tl\", longs);\n    norm_fields.put(\"foo_td\", doubles);\n    norm_fields.put(\"foo_tdt\", dates);\n\n    norm_fields.put(\"foo_s\", strings);\n    norm_fields.put(\"foo_dt\", dates);\n\n\n    // fields that frange queries should work on\n    Map<String,String[]> frange_fields = new HashMap<>();\n    frange_fields.put(\"foo_i\", ints);\n    frange_fields.put(\"foo_l\", longs);\n    frange_fields.put(\"foo_d\", doubles);\n\n    frange_fields.put(\"foo_ti\", ints);\n    frange_fields.put(\"foo_tl\", longs);\n    frange_fields.put(\"foo_td\", doubles);\n    frange_fields.put(\"foo_tdt\", dates);\n\n    frange_fields.put(\"foo_s\", strings);\n    frange_fields.put(\"foo_dt\", dates);\n\n    Map<String,String[]> all_fields = new HashMap<>();\n    all_fields.putAll(norm_fields);\n    all_fields.putAll(frange_fields);\n\n    for (int j=0; j<ints.length-2; j++) {\n      List<String> fields = new ArrayList<>();\n      fields.add(\"id\");\n      fields.add(\"\"+j);\n      for (Map.Entry<String,String[]> entry : all_fields.entrySet()) {\n        fields.add(entry.getKey());\n        fields.add(entry.getValue()[j]);\n      }\n      assertU(adoc(fields.toArray(new String[fields.size()])));\n    }\n\n    assertU(commit());\n\n    // simple test of a function rather than just the field\n    assertQ(req(\"{!frange l=0 u=2}id\"), \"*[count(//doc)=3]\");\n    assertQ(req(\"{!frange l=0 u=2}product(id,2)\"), \"*[count(//doc)=2]\");\n    assertQ(req(\"{!frange l=100 u=102}sum(id,100)\"), \"*[count(//doc)=3]\");\n\n\n    for (Map.Entry<String,String[]> entry : norm_fields.entrySet()) {\n      String f = entry.getKey();\n      String[] v = entry.getValue();\n\n      assertQ(req(f + \":[* TO *]\" ), \"*[count(//doc)=3]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=3]\");\n      assertQ(req(f + \":[\"+v[1]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=2]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[1]+\"]\"), \"*[count(//doc)=2]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[0]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[1]+\" TO \"+v[1]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[2]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[3]+\" TO \"+v[3]+\"]\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":[\"+v[4]+\" TO \"+v[4]+\"]\"), \"*[count(//doc)=0]\");\n\n      assertQ(req(f + \":{\"+v[0]+\" TO \"+v[2]+\"}\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":{\"+v[1]+\" TO \"+v[2]+\"}\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":{\"+v[0]+\" TO \"+v[1]+\"}\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":{\"+v[3]+\" TO \"+v[4]+\"}\"), \"*[count(//doc)=3]\");\n    }\n\n    for (Map.Entry<String,String[]> entry : frange_fields.entrySet()) {\n      String f = entry.getKey();\n      String[] v = entry.getValue();\n\n      assertQ(req(\"{!frange}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[0]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[1]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[2]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[3]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[4]+\"}\"+f ), \"*[count(//doc)=0]\");\n\n      assertQ(req(\"{!frange\" + \" u=\"+v[0]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[1]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[3]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[0]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[1]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[2]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[3]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[4]+\"}\"+f ), \"*[count(//doc)=0]\");\n\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[0]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[1]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[3]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n\n      assertQ(req(\"{!frange incl=true incu=true\" + \" l=\" +v[0] +\" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange incl=false incu=false\" + \" l=\" +v[0] +\" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incl=false incu=false\" + \" l=\" +v[3] +\" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n    }\n\n    // now pick a random range to use to delete (some of) the docs...\n    \n    final boolean incl = random().nextBoolean();\n    final boolean incu = random().nextBoolean();\n    final int expected = 0 + (incl ? 0 : 1) + (incu ? 0 : 1);\n    String dbq = null;\n    if (random().nextBoolean()) { // regular range\n      String field = randomKey(norm_fields);\n      String[] values = norm_fields.get(field);\n      dbq = field + \":\" + (incl ? \"[\" : \"{\") + values[0] + \" TO \" + values[2] + (incu ? \"]\" : \"}\");\n    } else { // frange\n      String field = randomKey(frange_fields);\n      String[] values = frange_fields.get(field);\n      dbq = \"{!frange incl=\" + incl + \" incu=\" + incu + \" l=\" + values[0] + \" u=\" + values[2] + \"}\" + field;\n    }\n    if (random().nextBoolean()) {\n      // wrap in a BQ\n      String field = randomKey(norm_fields);\n      String value = norm_fields.get(field)[1];\n      // wraping shouldn't affect expected\n      dbq = \"(\"+field+\":\\\"\"+value+\"\\\" OR \" + dbq + \")\";\n    }    \n      \n    assertU(delQ(dbq));\n    assertU(commit());\n    assertQ(req(\"q\",\"*:*\",\"_trace_dbq\",dbq),\n            \"*[count(//doc)=\" + expected + \"]\");\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"28288370235ed02234a64753cdbf0c6ec096304a","date":1498726817,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRangeQuery#testRangeQueries().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRangeQuery#testRangeQueries().mjava","sourceNew":"  @Test\n  public void testRangeQueries() throws Exception {\n    // ensure that we aren't losing precision on any fields in addition to testing other non-numeric fields\n    // that aren't tested in testRandomRangeQueries()\n\n    int i=2000000000;\n    long l=500000000000000000L;\n    double d=0.3333333333333333;\n\n    // first 3 values will be indexed, the last two won't be\n    String[] ints = {\"\"+(i-1), \"\"+(i), \"\"+(i+1),   \"\"+(i-2), \"\"+(i+2)};\n    String[] longs = {\"\"+(l-1), \"\"+(l), \"\"+(l+1),  \"\"+(l-2), \"\"+(l+2)};\n    String[] doubles = {\"\"+(d-1e-16), \"\"+(d), \"\"+(d+1e-16),   \"\"+(d-2e-16), \"\"+(d+2e-16)};\n    String[] strings = {\"aaa\",\"bbb\",\"ccc\",  \"aa\",\"cccc\" };\n    String[] dates = {\"0299-12-31T23:59:59.999Z\",\"2000-01-01T00:00:00.000Z\",\"2000-01-01T00:00:00.001Z\",  \"0299-12-31T23:59:59.998Z\",\"2000-01-01T00:00:00.002Z\" };\n\n    // fields that normal range queries should work on\n    Map<String,String[]> norm_fields = new HashMap<>();\n    norm_fields.put(\"foo_i\", ints);\n    norm_fields.put(\"foo_l\", longs);\n    norm_fields.put(\"foo_d\", doubles);\n\n    norm_fields.put(\"foo_ti\", ints);\n    norm_fields.put(\"foo_tl\", longs);\n    norm_fields.put(\"foo_td\", doubles);\n    norm_fields.put(\"foo_tdt\", dates);\n\n    norm_fields.put(\"foo_s\", strings);\n    norm_fields.put(\"foo_dt\", dates);\n\n\n    // fields that frange queries should work on\n    Map<String,String[]> frange_fields = new HashMap<>();\n    frange_fields.put(\"foo_i\", ints);\n    frange_fields.put(\"foo_l\", longs);\n    frange_fields.put(\"foo_d\", doubles);\n\n    frange_fields.put(\"foo_ti\", ints);\n    frange_fields.put(\"foo_tl\", longs);\n    frange_fields.put(\"foo_td\", doubles);\n    frange_fields.put(\"foo_tdt\", dates);\n\n    frange_fields.put(\"foo_s\", strings);\n    frange_fields.put(\"foo_dt\", dates);\n\n    Map<String,String[]> all_fields = new HashMap<>();\n    all_fields.putAll(norm_fields);\n    all_fields.putAll(frange_fields);\n\n    for (int j=0; j<ints.length-2; j++) {\n      List<String> fields = new ArrayList<>();\n      fields.add(\"id\");\n      fields.add(\"\"+j);\n      for (Map.Entry<String,String[]> entry : all_fields.entrySet()) {\n        fields.add(entry.getKey());\n        fields.add(entry.getValue()[j]);\n      }\n      assertU(adoc(fields.toArray(new String[fields.size()])));\n    }\n\n    assertU(commit());\n\n    // simple test of a function rather than just the field\n    assertQ(req(\"{!frange l=0 u=2}id\"), \"*[count(//doc)=3]\");\n    assertQ(req(\"{!frange l=0 u=2}product(id_i,2)\"), \"*[count(//doc)=2]\");\n    assertQ(req(\"{!frange l=100 u=102}sum(id_i,100)\"), \"*[count(//doc)=3]\");\n\n\n    for (Map.Entry<String,String[]> entry : norm_fields.entrySet()) {\n      String f = entry.getKey();\n      String[] v = entry.getValue();\n\n      assertQ(req(f + \":[* TO *]\" ), \"*[count(//doc)=3]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=3]\");\n      assertQ(req(f + \":[\"+v[1]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=2]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[1]+\"]\"), \"*[count(//doc)=2]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[0]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[1]+\" TO \"+v[1]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[2]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[3]+\" TO \"+v[3]+\"]\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":[\"+v[4]+\" TO \"+v[4]+\"]\"), \"*[count(//doc)=0]\");\n\n      assertQ(req(f + \":{\"+v[0]+\" TO \"+v[2]+\"}\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":{\"+v[1]+\" TO \"+v[2]+\"}\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":{\"+v[0]+\" TO \"+v[1]+\"}\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":{\"+v[3]+\" TO \"+v[4]+\"}\"), \"*[count(//doc)=3]\");\n    }\n\n    for (Map.Entry<String,String[]> entry : frange_fields.entrySet()) {\n      String f = entry.getKey();\n      String[] v = entry.getValue();\n\n      assertQ(req(\"{!frange}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[0]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[1]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[2]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[3]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[4]+\"}\"+f ), \"*[count(//doc)=0]\");\n\n      assertQ(req(\"{!frange\" + \" u=\"+v[0]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[1]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[3]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[0]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[1]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[2]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[3]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[4]+\"}\"+f ), \"*[count(//doc)=0]\");\n\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[0]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[1]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[3]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n\n      assertQ(req(\"{!frange incl=true incu=true\" + \" l=\" +v[0] +\" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange incl=false incu=false\" + \" l=\" +v[0] +\" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incl=false incu=false\" + \" l=\" +v[3] +\" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n    }\n\n    // now pick a random range to use to delete (some of) the docs...\n    \n    final boolean incl = random().nextBoolean();\n    final boolean incu = random().nextBoolean();\n    final int expected = 0 + (incl ? 0 : 1) + (incu ? 0 : 1);\n    String dbq = null;\n    if (random().nextBoolean()) { // regular range\n      String field = randomKey(norm_fields);\n      String[] values = norm_fields.get(field);\n      dbq = field + \":\" + (incl ? \"[\" : \"{\") + values[0] + \" TO \" + values[2] + (incu ? \"]\" : \"}\");\n    } else { // frange\n      String field = randomKey(frange_fields);\n      String[] values = frange_fields.get(field);\n      dbq = \"{!frange incl=\" + incl + \" incu=\" + incu + \" l=\" + values[0] + \" u=\" + values[2] + \"}\" + field;\n    }\n    if (random().nextBoolean()) {\n      // wrap in a BQ\n      String field = randomKey(norm_fields);\n      String value = norm_fields.get(field)[1];\n      // wraping shouldn't affect expected\n      dbq = \"(\"+field+\":\\\"\"+value+\"\\\" OR \" + dbq + \")\";\n    }    \n      \n    assertU(delQ(dbq));\n    assertU(commit());\n    assertQ(req(\"q\",\"*:*\",\"_trace_dbq\",dbq),\n            \"*[count(//doc)=\" + expected + \"]\");\n    \n  }\n\n","sourceOld":"  @Test\n  public void testRangeQueries() throws Exception {\n    // ensure that we aren't losing precision on any fields in addition to testing other non-numeric fields\n    // that aren't tested in testRandomRangeQueries()\n\n    int i=2000000000;\n    long l=500000000000000000L;\n    double d=0.3333333333333333;\n\n    // first 3 values will be indexed, the last two won't be\n    String[] ints = {\"\"+(i-1), \"\"+(i), \"\"+(i+1),   \"\"+(i-2), \"\"+(i+2)};\n    String[] longs = {\"\"+(l-1), \"\"+(l), \"\"+(l+1),  \"\"+(l-2), \"\"+(l+2)};\n    String[] doubles = {\"\"+(d-1e-16), \"\"+(d), \"\"+(d+1e-16),   \"\"+(d-2e-16), \"\"+(d+2e-16)};\n    String[] strings = {\"aaa\",\"bbb\",\"ccc\",  \"aa\",\"cccc\" };\n    String[] dates = {\"0299-12-31T23:59:59.999Z\",\"2000-01-01T00:00:00.000Z\",\"2000-01-01T00:00:00.001Z\",  \"0299-12-31T23:59:59.998Z\",\"2000-01-01T00:00:00.002Z\" };\n\n    // fields that normal range queries should work on\n    Map<String,String[]> norm_fields = new HashMap<>();\n    norm_fields.put(\"foo_i\", ints);\n    norm_fields.put(\"foo_l\", longs);\n    norm_fields.put(\"foo_d\", doubles);\n\n    norm_fields.put(\"foo_ti\", ints);\n    norm_fields.put(\"foo_tl\", longs);\n    norm_fields.put(\"foo_td\", doubles);\n    norm_fields.put(\"foo_tdt\", dates);\n\n    norm_fields.put(\"foo_s\", strings);\n    norm_fields.put(\"foo_dt\", dates);\n\n\n    // fields that frange queries should work on\n    Map<String,String[]> frange_fields = new HashMap<>();\n    frange_fields.put(\"foo_i\", ints);\n    frange_fields.put(\"foo_l\", longs);\n    frange_fields.put(\"foo_d\", doubles);\n\n    frange_fields.put(\"foo_ti\", ints);\n    frange_fields.put(\"foo_tl\", longs);\n    frange_fields.put(\"foo_td\", doubles);\n    frange_fields.put(\"foo_tdt\", dates);\n\n    frange_fields.put(\"foo_s\", strings);\n    frange_fields.put(\"foo_dt\", dates);\n\n    Map<String,String[]> all_fields = new HashMap<>();\n    all_fields.putAll(norm_fields);\n    all_fields.putAll(frange_fields);\n\n    for (int j=0; j<ints.length-2; j++) {\n      List<String> fields = new ArrayList<>();\n      fields.add(\"id\");\n      fields.add(\"\"+j);\n      for (Map.Entry<String,String[]> entry : all_fields.entrySet()) {\n        fields.add(entry.getKey());\n        fields.add(entry.getValue()[j]);\n      }\n      assertU(adoc(fields.toArray(new String[fields.size()])));\n    }\n\n    assertU(commit());\n\n    // simple test of a function rather than just the field\n    assertQ(req(\"{!frange l=0 u=2}id\"), \"*[count(//doc)=3]\");\n    assertQ(req(\"{!frange l=0 u=2}product(id,2)\"), \"*[count(//doc)=2]\");\n    assertQ(req(\"{!frange l=100 u=102}sum(id,100)\"), \"*[count(//doc)=3]\");\n\n\n    for (Map.Entry<String,String[]> entry : norm_fields.entrySet()) {\n      String f = entry.getKey();\n      String[] v = entry.getValue();\n\n      assertQ(req(f + \":[* TO *]\" ), \"*[count(//doc)=3]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=3]\");\n      assertQ(req(f + \":[\"+v[1]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=2]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[1]+\"]\"), \"*[count(//doc)=2]\");\n      assertQ(req(f + \":[\"+v[0]+\" TO \"+v[0]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[1]+\" TO \"+v[1]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[2]+\" TO \"+v[2]+\"]\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":[\"+v[3]+\" TO \"+v[3]+\"]\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":[\"+v[4]+\" TO \"+v[4]+\"]\"), \"*[count(//doc)=0]\");\n\n      assertQ(req(f + \":{\"+v[0]+\" TO \"+v[2]+\"}\"), \"*[count(//doc)=1]\");\n      assertQ(req(f + \":{\"+v[1]+\" TO \"+v[2]+\"}\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":{\"+v[0]+\" TO \"+v[1]+\"}\"), \"*[count(//doc)=0]\");\n      assertQ(req(f + \":{\"+v[3]+\" TO \"+v[4]+\"}\"), \"*[count(//doc)=3]\");\n    }\n\n    for (Map.Entry<String,String[]> entry : frange_fields.entrySet()) {\n      String f = entry.getKey();\n      String[] v = entry.getValue();\n\n      assertQ(req(\"{!frange}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[0]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[1]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[2]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[3]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" l=\"+v[4]+\"}\"+f ), \"*[count(//doc)=0]\");\n\n      assertQ(req(\"{!frange\" + \" u=\"+v[0]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[1]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[3]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange\" + \" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[0]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[1]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[2]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[3]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange incl=false\" + \" l=\"+v[4]+\"}\"+f ), \"*[count(//doc)=0]\");\n\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[0]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[1]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=2]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[3]+\"}\"+f ), \"*[count(//doc)=0]\");\n      assertQ(req(\"{!frange incu=false\" + \" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n\n      assertQ(req(\"{!frange incl=true incu=true\" + \" l=\" +v[0] +\" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=3]\");\n      assertQ(req(\"{!frange incl=false incu=false\" + \" l=\" +v[0] +\" u=\"+v[2]+\"}\"+f ), \"*[count(//doc)=1]\");\n      assertQ(req(\"{!frange incl=false incu=false\" + \" l=\" +v[3] +\" u=\"+v[4]+\"}\"+f ), \"*[count(//doc)=3]\");\n    }\n\n    // now pick a random range to use to delete (some of) the docs...\n    \n    final boolean incl = random().nextBoolean();\n    final boolean incu = random().nextBoolean();\n    final int expected = 0 + (incl ? 0 : 1) + (incu ? 0 : 1);\n    String dbq = null;\n    if (random().nextBoolean()) { // regular range\n      String field = randomKey(norm_fields);\n      String[] values = norm_fields.get(field);\n      dbq = field + \":\" + (incl ? \"[\" : \"{\") + values[0] + \" TO \" + values[2] + (incu ? \"]\" : \"}\");\n    } else { // frange\n      String field = randomKey(frange_fields);\n      String[] values = frange_fields.get(field);\n      dbq = \"{!frange incl=\" + incl + \" incu=\" + incu + \" l=\" + values[0] + \" u=\" + values[2] + \"}\" + field;\n    }\n    if (random().nextBoolean()) {\n      // wrap in a BQ\n      String field = randomKey(norm_fields);\n      String value = norm_fields.get(field)[1];\n      // wraping shouldn't affect expected\n      dbq = \"(\"+field+\":\\\"\"+value+\"\\\" OR \" + dbq + \")\";\n    }    \n      \n    assertU(delQ(dbq));\n    assertU(commit());\n    assertQ(req(\"q\",\"*:*\",\"_trace_dbq\",dbq),\n            \"*[count(//doc)=\" + expected + \"]\");\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["461fea4b90072bede0ef2dc0dba66a8c5dbf1356"],"c26f00b574427b55127e869b935845554afde1fa":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"5cb157886ecc78f33fafd9d403e96a4a495503b3":["2106271e380c198349e0f6eac0395bb462913fab"],"a71f63026529f3c1f03cfdd664910873ab2369ae":["5cb157886ecc78f33fafd9d403e96a4a495503b3"],"461fea4b90072bede0ef2dc0dba66a8c5dbf1356":["c26f00b574427b55127e869b935845554afde1fa"],"28288370235ed02234a64753cdbf0c6ec096304a":["5cb157886ecc78f33fafd9d403e96a4a495503b3","a71f63026529f3c1f03cfdd664910873ab2369ae"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["2106271e380c198349e0f6eac0395bb462913fab","5cb157886ecc78f33fafd9d403e96a4a495503b3"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"2106271e380c198349e0f6eac0395bb462913fab":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a258fbb26824fd104ed795e5d9033d2d040049ee":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9":["5cb157886ecc78f33fafd9d403e96a4a495503b3","a71f63026529f3c1f03cfdd664910873ab2369ae"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["28288370235ed02234a64753cdbf0c6ec096304a"]},"commit2Childs":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["2106271e380c198349e0f6eac0395bb462913fab"],"c26f00b574427b55127e869b935845554afde1fa":["461fea4b90072bede0ef2dc0dba66a8c5dbf1356"],"5cb157886ecc78f33fafd9d403e96a4a495503b3":["a71f63026529f3c1f03cfdd664910873ab2369ae","28288370235ed02234a64753cdbf0c6ec096304a","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9"],"a71f63026529f3c1f03cfdd664910873ab2369ae":["28288370235ed02234a64753cdbf0c6ec096304a","2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9"],"461fea4b90072bede0ef2dc0dba66a8c5dbf1356":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"28288370235ed02234a64753cdbf0c6ec096304a":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["c26f00b574427b55127e869b935845554afde1fa"],"2106271e380c198349e0f6eac0395bb462913fab":["5cb157886ecc78f33fafd9d403e96a4a495503b3","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c26f00b574427b55127e869b935845554afde1fa","c903c3d15906a3da96b8c0c2fb704491005fdbdb","a258fbb26824fd104ed795e5d9033d2d040049ee"],"a258fbb26824fd104ed795e5d9033d2d040049ee":[],"2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","a258fbb26824fd104ed795e5d9033d2d040049ee","2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}