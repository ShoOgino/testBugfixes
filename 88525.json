{"path":"solr/src/java/org/apache/solr/analysis/WordDelimiterFilterFactory#inform(ResourceLoader).mjava","commits":[{"id":"893269407f5c988a4b2ee13c7ffc01ec43136c1d","date":1268598046,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/analysis/WordDelimiterFilterFactory#inform(ResourceLoader).mjava","pathOld":"/dev/null","sourceNew":"  public void inform(ResourceLoader loader) {\n    String wordFiles = args.get(PROTECTED_TOKENS);\n    if (wordFiles != null) {  \n      try {\n        File protectedWordFiles = new File(wordFiles);\n        if (protectedWordFiles.exists()) {\n          List<String> wlist = loader.getLines(wordFiles);\n          //This cast is safe in Lucene\n          protectedWords = new CharArraySet(wlist, false);//No need to go through StopFilter as before, since it just uses a List internally\n        } else  {\n          List<String> files = StrUtils.splitFileNames(wordFiles);\n          for (String file : files) {\n            List<String> wlist = loader.getLines(file.trim());\n            if (protectedWords == null)\n              protectedWords = new CharArraySet(wlist, false);\n            else\n              protectedWords.addAll(wlist);\n          }\n        }\n      } catch (IOException e) {\n        throw new RuntimeException(e);\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8","date":1268599006,"type":4,"author":"Mark Robert Miller","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/src/java/org/apache/solr/analysis/WordDelimiterFilterFactory#inform(ResourceLoader).mjava","sourceNew":null,"sourceOld":"  public void inform(ResourceLoader loader) {\n    String wordFiles = args.get(PROTECTED_TOKENS);\n    if (wordFiles != null) {  \n      try {\n        File protectedWordFiles = new File(wordFiles);\n        if (protectedWordFiles.exists()) {\n          List<String> wlist = loader.getLines(wordFiles);\n          //This cast is safe in Lucene\n          protectedWords = new CharArraySet(wlist, false);//No need to go through StopFilter as before, since it just uses a List internally\n        } else  {\n          List<String> files = StrUtils.splitFileNames(wordFiles);\n          for (String file : files) {\n            List<String> wlist = loader.getLines(file.trim());\n            if (protectedWords == null)\n              protectedWords = new CharArraySet(wlist, false);\n            else\n              protectedWords.addAll(wlist);\n          }\n        }\n      } catch (IOException e) {\n        throw new RuntimeException(e);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ad94625fb8d088209f46650c8097196fec67f00c","date":1453508319,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/analysis/WordDelimiterFilterFactory#inform(ResourceLoader).mjava","pathOld":"src/java/org/apache/solr/analysis/WordDelimiterFilterFactory#inform(ResourceLoader).mjava","sourceNew":"  public void inform(ResourceLoader loader) {\n    String wordFiles = args.get(PROTECTED_TOKENS);\n    if (wordFiles != null) {  \n      try {\n        File protectedWordFiles = new File(wordFiles);\n        if (protectedWordFiles.exists()) {\n          List<String> wlist = loader.getLines(wordFiles);\n          //This cast is safe in Lucene\n          protectedWords = new CharArraySet(wlist, false);//No need to go through StopFilter as before, since it just uses a List internally\n        } else  {\n          List<String> files = StrUtils.splitFileNames(wordFiles);\n          for (String file : files) {\n            List<String> wlist = loader.getLines(file.trim());\n            if (protectedWords == null)\n              protectedWords = new CharArraySet(wlist, false);\n            else\n              protectedWords.addAll(wlist);\n          }\n        }\n      } catch (IOException e) {\n        throw new RuntimeException(e);\n      }\n    }\n  }\n\n","sourceOld":"  public void inform(ResourceLoader loader) {\n    String wordFiles = args.get(PROTECTED_TOKENS);\n    if (wordFiles != null) {  \n      try {\n        File protectedWordFiles = new File(wordFiles);\n        if (protectedWordFiles.exists()) {\n          List<String> wlist = loader.getLines(wordFiles);\n          //This cast is safe in Lucene\n          protectedWords = new CharArraySet(wlist, false);//No need to go through StopFilter as before, since it just uses a List internally\n        } else  {\n          List<String> files = StrUtils.splitFileNames(wordFiles);\n          for (String file : files) {\n            List<String> wlist = loader.getLines(file.trim());\n            if (protectedWords == null)\n              protectedWords = new CharArraySet(wlist, false);\n            else\n              protectedWords.addAll(wlist);\n          }\n        }\n      } catch (IOException e) {\n        throw new RuntimeException(e);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1da8d55113b689b06716246649de6f62430f15c0","date":1453508340,"type":0,"author":"Dawid Weiss","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/analysis/WordDelimiterFilterFactory#inform(ResourceLoader).mjava","pathOld":"/dev/null","sourceNew":"  public void inform(ResourceLoader loader) {\n    String wordFiles = args.get(PROTECTED_TOKENS);\n    if (wordFiles != null) {  \n      try {\n        File protectedWordFiles = new File(wordFiles);\n        if (protectedWordFiles.exists()) {\n          List<String> wlist = loader.getLines(wordFiles);\n          //This cast is safe in Lucene\n          protectedWords = new CharArraySet(wlist, false);//No need to go through StopFilter as before, since it just uses a List internally\n        } else  {\n          List<String> files = StrUtils.splitFileNames(wordFiles);\n          for (String file : files) {\n            List<String> wlist = loader.getLines(file.trim());\n            if (protectedWords == null)\n              protectedWords = new CharArraySet(wlist, false);\n            else\n              protectedWords.addAll(wlist);\n          }\n        }\n      } catch (IOException e) {\n        throw new RuntimeException(e);\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9c8b12bda3f5864b27e3e04df1be4f6736ec067a","date":1270088127,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/analysis/WordDelimiterFilterFactory#inform(ResourceLoader).mjava","pathOld":"solr/src/java/org/apache/solr/analysis/WordDelimiterFilterFactory#inform(ResourceLoader).mjava","sourceNew":"  public void inform(ResourceLoader loader) {\n    String wordFiles = args.get(PROTECTED_TOKENS);\n    if (wordFiles != null) {  \n      try {\n        protectedWords = getWordSet(loader, wordFiles, false);\n      } catch (IOException e) {\n        throw new RuntimeException(e);\n      }\n    }\n  }\n\n","sourceOld":"  public void inform(ResourceLoader loader) {\n    String wordFiles = args.get(PROTECTED_TOKENS);\n    if (wordFiles != null) {  \n      try {\n        File protectedWordFiles = new File(wordFiles);\n        if (protectedWordFiles.exists()) {\n          List<String> wlist = loader.getLines(wordFiles);\n          //This cast is safe in Lucene\n          protectedWords = new CharArraySet(wlist, false);//No need to go through StopFilter as before, since it just uses a List internally\n        } else  {\n          List<String> files = StrUtils.splitFileNames(wordFiles);\n          for (String file : files) {\n            List<String> wlist = loader.getLines(file.trim());\n            if (protectedWords == null)\n              protectedWords = new CharArraySet(wlist, false);\n            else\n              protectedWords.addAll(wlist);\n          }\n        }\n      } catch (IOException e) {\n        throw new RuntimeException(e);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"606b3c3bf20fa12fc44a5bb6a9cba3eca1af28c7","date":1283030744,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/analysis/WordDelimiterFilterFactory#inform(ResourceLoader).mjava","pathOld":"solr/src/java/org/apache/solr/analysis/WordDelimiterFilterFactory#inform(ResourceLoader).mjava","sourceNew":"  public void inform(ResourceLoader loader) {\n    String wordFiles = args.get(PROTECTED_TOKENS);\n    if (wordFiles != null) {  \n      try {\n        protectedWords = getWordSet(loader, wordFiles, false);\n      } catch (IOException e) {\n        throw new RuntimeException(e);\n      }\n    }\n    String types = args.get(TYPES);\n    if (types != null) {\n      try {\n        List<String> files = StrUtils.splitFileNames( types );\n        List<String> wlist = new ArrayList<String>();\n        for( String file : files ){\n          List<String> lines = loader.getLines( file.trim() );\n          wlist.addAll( lines );\n        }\n      typeTable = parseTypes(wlist);\n      } catch (IOException e) {\n        throw new RuntimeException(e);\n      }\n    }\n  }\n\n","sourceOld":"  public void inform(ResourceLoader loader) {\n    String wordFiles = args.get(PROTECTED_TOKENS);\n    if (wordFiles != null) {  \n      try {\n        protectedWords = getWordSet(loader, wordFiles, false);\n      } catch (IOException e) {\n        throw new RuntimeException(e);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/analysis/WordDelimiterFilterFactory#inform(ResourceLoader).mjava","pathOld":"solr/src/java/org/apache/solr/analysis/WordDelimiterFilterFactory#inform(ResourceLoader).mjava","sourceNew":"  public void inform(ResourceLoader loader) {\n    String wordFiles = args.get(PROTECTED_TOKENS);\n    if (wordFiles != null) {  \n      try {\n        protectedWords = getWordSet(loader, wordFiles, false);\n      } catch (IOException e) {\n        throw new RuntimeException(e);\n      }\n    }\n    String types = args.get(TYPES);\n    if (types != null) {\n      try {\n        List<String> files = StrUtils.splitFileNames( types );\n        List<String> wlist = new ArrayList<String>();\n        for( String file : files ){\n          List<String> lines = loader.getLines( file.trim() );\n          wlist.addAll( lines );\n        }\n      typeTable = parseTypes(wlist);\n      } catch (IOException e) {\n        throw new RuntimeException(e);\n      }\n    }\n  }\n\n","sourceOld":"  public void inform(ResourceLoader loader) {\n    String wordFiles = args.get(PROTECTED_TOKENS);\n    if (wordFiles != null) {  \n      try {\n        protectedWords = getWordSet(loader, wordFiles, false);\n      } catch (IOException e) {\n        throw new RuntimeException(e);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c903c3d15906a3da96b8c0c2fb704491005fdbdb","date":1453508227,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/analysis/WordDelimiterFilterFactory#inform(ResourceLoader).mjava","pathOld":"solr/src/java/org/apache/solr/analysis/WordDelimiterFilterFactory#inform(ResourceLoader).mjava","sourceNew":"  public void inform(ResourceLoader loader) {\n    String wordFiles = args.get(PROTECTED_TOKENS);\n    if (wordFiles != null) {  \n      try {\n        protectedWords = getWordSet(loader, wordFiles, false);\n      } catch (IOException e) {\n        throw new RuntimeException(e);\n      }\n    }\n    String types = args.get(TYPES);\n    if (types != null) {\n      try {\n        List<String> files = StrUtils.splitFileNames( types );\n        List<String> wlist = new ArrayList<String>();\n        for( String file : files ){\n          List<String> lines = loader.getLines( file.trim() );\n          wlist.addAll( lines );\n        }\n      typeTable = parseTypes(wlist);\n      } catch (IOException e) {\n        throw new RuntimeException(e);\n      }\n    }\n  }\n\n","sourceOld":"  public void inform(ResourceLoader loader) {\n    String wordFiles = args.get(PROTECTED_TOKENS);\n    if (wordFiles != null) {  \n      try {\n        protectedWords = getWordSet(loader, wordFiles, false);\n      } catch (IOException e) {\n        throw new RuntimeException(e);\n      }\n    }\n    String types = args.get(TYPES);\n    if (types != null) {\n      try {\n        List<String> files = StrUtils.splitFileNames( types );\n        List<String> wlist = new ArrayList<String>();\n        for( String file : files ){\n          List<String> lines = loader.getLines( file.trim() );\n          wlist.addAll( lines );\n        }\n      typeTable = parseTypes(wlist);\n      } catch (IOException e) {\n        throw new RuntimeException(e);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a258fbb26824fd104ed795e5d9033d2d040049ee","date":1453508252,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/analysis/WordDelimiterFilterFactory#inform(ResourceLoader).mjava","pathOld":"solr/src/java/org/apache/solr/analysis/WordDelimiterFilterFactory#inform(ResourceLoader).mjava","sourceNew":"  public void inform(ResourceLoader loader) {\n    String wordFiles = args.get(PROTECTED_TOKENS);\n    if (wordFiles != null) {  \n      try {\n        protectedWords = getWordSet(loader, wordFiles, false);\n      } catch (IOException e) {\n        throw new RuntimeException(e);\n      }\n    }\n    String types = args.get(TYPES);\n    if (types != null) {\n      try {\n        List<String> files = StrUtils.splitFileNames( types );\n        List<String> wlist = new ArrayList<String>();\n        for( String file : files ){\n          List<String> lines = loader.getLines( file.trim() );\n          wlist.addAll( lines );\n        }\n      typeTable = parseTypes(wlist);\n      } catch (IOException e) {\n        throw new RuntimeException(e);\n      }\n    }\n  }\n\n","sourceOld":"  public void inform(ResourceLoader loader) {\n    String wordFiles = args.get(PROTECTED_TOKENS);\n    if (wordFiles != null) {  \n      try {\n        protectedWords = getWordSet(loader, wordFiles, false);\n      } catch (IOException e) {\n        throw new RuntimeException(e);\n      }\n    }\n    String types = args.get(TYPES);\n    if (types != null) {\n      try {\n        List<String> files = StrUtils.splitFileNames( types );\n        List<String> wlist = new ArrayList<String>();\n        for( String file : files ){\n          List<String> lines = loader.getLines( file.trim() );\n          wlist.addAll( lines );\n        }\n      typeTable = parseTypes(wlist);\n      } catch (IOException e) {\n        throw new RuntimeException(e);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":5,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/analysis/WordDelimiterFilterFactory#inform(ResourceLoader).mjava","pathOld":"solr/src/java/org/apache/solr/analysis/WordDelimiterFilterFactory#inform(ResourceLoader).mjava","sourceNew":"  public void inform(ResourceLoader loader) {\n    String wordFiles = args.get(PROTECTED_TOKENS);\n    if (wordFiles != null) {  \n      try {\n        protectedWords = getWordSet(loader, wordFiles, false);\n      } catch (IOException e) {\n        throw new RuntimeException(e);\n      }\n    }\n    String types = args.get(TYPES);\n    if (types != null) {\n      try {\n        List<String> files = StrUtils.splitFileNames( types );\n        List<String> wlist = new ArrayList<String>();\n        for( String file : files ){\n          List<String> lines = loader.getLines( file.trim() );\n          wlist.addAll( lines );\n        }\n      typeTable = parseTypes(wlist);\n      } catch (IOException e) {\n        throw new RuntimeException(e);\n      }\n    }\n  }\n\n","sourceOld":"  public void inform(ResourceLoader loader) {\n    String wordFiles = args.get(PROTECTED_TOKENS);\n    if (wordFiles != null) {  \n      try {\n        protectedWords = getWordSet(loader, wordFiles, false);\n      } catch (IOException e) {\n        throw new RuntimeException(e);\n      }\n    }\n    String types = args.get(TYPES);\n    if (types != null) {\n      try {\n        List<String> files = StrUtils.splitFileNames( types );\n        List<String> wlist = new ArrayList<String>();\n        for( String file : files ){\n          List<String> lines = loader.getLines( file.trim() );\n          wlist.addAll( lines );\n        }\n      typeTable = parseTypes(wlist);\n      } catch (IOException e) {\n        throw new RuntimeException(e);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"893269407f5c988a4b2ee13c7ffc01ec43136c1d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8":["893269407f5c988a4b2ee13c7ffc01ec43136c1d"],"c26f00b574427b55127e869b935845554afde1fa":["606b3c3bf20fa12fc44a5bb6a9cba3eca1af28c7","c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["9c8b12bda3f5864b27e3e04df1be4f6736ec067a","606b3c3bf20fa12fc44a5bb6a9cba3eca1af28c7"],"9c8b12bda3f5864b27e3e04df1be4f6736ec067a":["1da8d55113b689b06716246649de6f62430f15c0"],"1da8d55113b689b06716246649de6f62430f15c0":["a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8","ad94625fb8d088209f46650c8097196fec67f00c"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["606b3c3bf20fa12fc44a5bb6a9cba3eca1af28c7"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a258fbb26824fd104ed795e5d9033d2d040049ee":["606b3c3bf20fa12fc44a5bb6a9cba3eca1af28c7"],"ad94625fb8d088209f46650c8097196fec67f00c":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"606b3c3bf20fa12fc44a5bb6a9cba3eca1af28c7":["9c8b12bda3f5864b27e3e04df1be4f6736ec067a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c26f00b574427b55127e869b935845554afde1fa"]},"commit2Childs":{"893269407f5c988a4b2ee13c7ffc01ec43136c1d":["a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8"],"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8":["1da8d55113b689b06716246649de6f62430f15c0"],"c26f00b574427b55127e869b935845554afde1fa":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["ad94625fb8d088209f46650c8097196fec67f00c"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":[],"9c8b12bda3f5864b27e3e04df1be4f6736ec067a":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","606b3c3bf20fa12fc44a5bb6a9cba3eca1af28c7"],"1da8d55113b689b06716246649de6f62430f15c0":["9c8b12bda3f5864b27e3e04df1be4f6736ec067a"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["c26f00b574427b55127e869b935845554afde1fa"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["893269407f5c988a4b2ee13c7ffc01ec43136c1d"],"a258fbb26824fd104ed795e5d9033d2d040049ee":[],"ad94625fb8d088209f46650c8097196fec67f00c":["1da8d55113b689b06716246649de6f62430f15c0"],"606b3c3bf20fa12fc44a5bb6a9cba3eca1af28c7":["c26f00b574427b55127e869b935845554afde1fa","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","c903c3d15906a3da96b8c0c2fb704491005fdbdb","a258fbb26824fd104ed795e5d9033d2d040049ee"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","a258fbb26824fd104ed795e5d9033d2d040049ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b","a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}