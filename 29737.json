{"path":"lucene/facet/src/java/org/apache/lucene/facet/sortedset/SortedSetDocValuesFacetCounts#countOneSegment(MultiDocValues.OrdinalMap,LeafReader,int,MatchingDocs).mjava","commits":[{"id":"8cfd1df435f04d4287925cca73cf22120f723892","date":1493925365,"type":0,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/facet/src/java/org/apache/lucene/facet/sortedset/SortedSetDocValuesFacetCounts#countOneSegment(MultiDocValues.OrdinalMap,LeafReader,int,MatchingDocs).mjava","pathOld":"/dev/null","sourceNew":"  private void countOneSegment(MultiDocValues.OrdinalMap ordinalMap, LeafReader reader, int segOrd, MatchingDocs hits) throws IOException {\n    SortedSetDocValues segValues = reader.getSortedSetDocValues(field);\n    if (segValues == null) {\n      // nothing to count\n      return;\n    }\n\n    DocIdSetIterator it;\n    if (hits == null) {\n      it = segValues;\n    } else {\n      it = ConjunctionDISI.intersectIterators(Arrays.asList(hits.bits.iterator(), segValues));\n    }\n\n    // TODO: yet another option is to count all segs\n    // first, only in seg-ord space, and then do a\n    // merge-sort-PQ in the end to only \"resolve to\n    // global\" those seg ords that can compete, if we know\n    // we just want top K?  ie, this is the same algo\n    // that'd be used for merging facets across shards\n    // (distributed faceting).  but this has much higher\n    // temp ram req'ts (sum of number of ords across all\n    // segs)\n    if (ordinalMap != null) {\n      final LongValues ordMap = ordinalMap.getGlobalOrds(segOrd);\n\n      int numSegOrds = (int) segValues.getValueCount();\n\n      if (hits != null && hits.totalHits < numSegOrds/10) {\n        //System.out.println(\"    remap as-we-go\");\n        // Remap every ord to global ord as we iterate:\n        for (int doc = it.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = it.nextDoc()) {\n          int term = (int) segValues.nextOrd();\n          while (term != SortedSetDocValues.NO_MORE_ORDS) {\n            //System.out.println(\"      segOrd=\" + segOrd + \" ord=\" + term + \" globalOrd=\" + ordinalMap.getGlobalOrd(segOrd, term));\n            counts[(int) ordMap.get(term)]++;\n            term = (int) segValues.nextOrd();\n          }\n        }\n      } else {\n        //System.out.println(\"    count in seg ord first\");\n\n        // First count in seg-ord space:\n        final int[] segCounts = new int[numSegOrds];\n        for (int doc = it.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = it.nextDoc()) {\n          int term = (int) segValues.nextOrd();\n          while (term != SortedSetDocValues.NO_MORE_ORDS) {\n            //System.out.println(\"      ord=\" + term);\n            segCounts[term]++;\n            term = (int) segValues.nextOrd();\n          }\n        }\n\n        // Then, migrate to global ords:\n        for(int ord=0;ord<numSegOrds;ord++) {\n          int count = segCounts[ord];\n          if (count != 0) {\n            //System.out.println(\"    migrate segOrd=\" + segOrd + \" ord=\" + ord + \" globalOrd=\" + ordinalMap.getGlobalOrd(segOrd, ord));\n            counts[(int) ordMap.get(ord)] += count;\n          }\n        }\n      }\n    } else {\n      // No ord mapping (e.g., single segment index):\n      // just aggregate directly into counts:\n      for (int doc = it.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = it.nextDoc()) {\n        int term = (int) segValues.nextOrd();\n        while (term != SortedSetDocValues.NO_MORE_ORDS) {\n          counts[term]++;\n          term = (int) segValues.nextOrd();\n        }\n      }\n    }\n\n    \n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e9017cf144952056066919f1ebc7897ff9bd71b1","date":1496757600,"type":0,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"lucene/facet/src/java/org/apache/lucene/facet/sortedset/SortedSetDocValuesFacetCounts#countOneSegment(MultiDocValues.OrdinalMap,LeafReader,int,MatchingDocs).mjava","pathOld":"/dev/null","sourceNew":"  private void countOneSegment(MultiDocValues.OrdinalMap ordinalMap, LeafReader reader, int segOrd, MatchingDocs hits) throws IOException {\n    SortedSetDocValues segValues = reader.getSortedSetDocValues(field);\n    if (segValues == null) {\n      // nothing to count\n      return;\n    }\n\n    DocIdSetIterator it;\n    if (hits == null) {\n      it = segValues;\n    } else {\n      it = ConjunctionDISI.intersectIterators(Arrays.asList(hits.bits.iterator(), segValues));\n    }\n\n    // TODO: yet another option is to count all segs\n    // first, only in seg-ord space, and then do a\n    // merge-sort-PQ in the end to only \"resolve to\n    // global\" those seg ords that can compete, if we know\n    // we just want top K?  ie, this is the same algo\n    // that'd be used for merging facets across shards\n    // (distributed faceting).  but this has much higher\n    // temp ram req'ts (sum of number of ords across all\n    // segs)\n    if (ordinalMap != null) {\n      final LongValues ordMap = ordinalMap.getGlobalOrds(segOrd);\n\n      int numSegOrds = (int) segValues.getValueCount();\n\n      if (hits != null && hits.totalHits < numSegOrds/10) {\n        //System.out.println(\"    remap as-we-go\");\n        // Remap every ord to global ord as we iterate:\n        for (int doc = it.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = it.nextDoc()) {\n          int term = (int) segValues.nextOrd();\n          while (term != SortedSetDocValues.NO_MORE_ORDS) {\n            //System.out.println(\"      segOrd=\" + segOrd + \" ord=\" + term + \" globalOrd=\" + ordinalMap.getGlobalOrd(segOrd, term));\n            counts[(int) ordMap.get(term)]++;\n            term = (int) segValues.nextOrd();\n          }\n        }\n      } else {\n        //System.out.println(\"    count in seg ord first\");\n\n        // First count in seg-ord space:\n        final int[] segCounts = new int[numSegOrds];\n        for (int doc = it.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = it.nextDoc()) {\n          int term = (int) segValues.nextOrd();\n          while (term != SortedSetDocValues.NO_MORE_ORDS) {\n            //System.out.println(\"      ord=\" + term);\n            segCounts[term]++;\n            term = (int) segValues.nextOrd();\n          }\n        }\n\n        // Then, migrate to global ords:\n        for(int ord=0;ord<numSegOrds;ord++) {\n          int count = segCounts[ord];\n          if (count != 0) {\n            //System.out.println(\"    migrate segOrd=\" + segOrd + \" ord=\" + ord + \" globalOrd=\" + ordinalMap.getGlobalOrd(segOrd, ord));\n            counts[(int) ordMap.get(ord)] += count;\n          }\n        }\n      }\n    } else {\n      // No ord mapping (e.g., single segment index):\n      // just aggregate directly into counts:\n      for (int doc = it.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = it.nextDoc()) {\n        int term = (int) segValues.nextOrd();\n        while (term != SortedSetDocValues.NO_MORE_ORDS) {\n          counts[term]++;\n          term = (int) segValues.nextOrd();\n        }\n      }\n    }\n\n    \n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"957c610636f393a85a38f1af670540028db13e6b","date":1500044517,"type":5,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/facet/src/java/org/apache/lucene/facet/sortedset/SortedSetDocValuesFacetCounts#countOneSegment(OrdinalMap,LeafReader,int,MatchingDocs).mjava","pathOld":"lucene/facet/src/java/org/apache/lucene/facet/sortedset/SortedSetDocValuesFacetCounts#countOneSegment(MultiDocValues.OrdinalMap,LeafReader,int,MatchingDocs).mjava","sourceNew":"  private void countOneSegment(OrdinalMap ordinalMap, LeafReader reader, int segOrd, MatchingDocs hits) throws IOException {\n    SortedSetDocValues segValues = reader.getSortedSetDocValues(field);\n    if (segValues == null) {\n      // nothing to count\n      return;\n    }\n\n    DocIdSetIterator it;\n    if (hits == null) {\n      it = segValues;\n    } else {\n      it = ConjunctionDISI.intersectIterators(Arrays.asList(hits.bits.iterator(), segValues));\n    }\n\n    // TODO: yet another option is to count all segs\n    // first, only in seg-ord space, and then do a\n    // merge-sort-PQ in the end to only \"resolve to\n    // global\" those seg ords that can compete, if we know\n    // we just want top K?  ie, this is the same algo\n    // that'd be used for merging facets across shards\n    // (distributed faceting).  but this has much higher\n    // temp ram req'ts (sum of number of ords across all\n    // segs)\n    if (ordinalMap != null) {\n      final LongValues ordMap = ordinalMap.getGlobalOrds(segOrd);\n\n      int numSegOrds = (int) segValues.getValueCount();\n\n      if (hits != null && hits.totalHits < numSegOrds/10) {\n        //System.out.println(\"    remap as-we-go\");\n        // Remap every ord to global ord as we iterate:\n        for (int doc = it.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = it.nextDoc()) {\n          int term = (int) segValues.nextOrd();\n          while (term != SortedSetDocValues.NO_MORE_ORDS) {\n            //System.out.println(\"      segOrd=\" + segOrd + \" ord=\" + term + \" globalOrd=\" + ordinalMap.getGlobalOrd(segOrd, term));\n            counts[(int) ordMap.get(term)]++;\n            term = (int) segValues.nextOrd();\n          }\n        }\n      } else {\n        //System.out.println(\"    count in seg ord first\");\n\n        // First count in seg-ord space:\n        final int[] segCounts = new int[numSegOrds];\n        for (int doc = it.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = it.nextDoc()) {\n          int term = (int) segValues.nextOrd();\n          while (term != SortedSetDocValues.NO_MORE_ORDS) {\n            //System.out.println(\"      ord=\" + term);\n            segCounts[term]++;\n            term = (int) segValues.nextOrd();\n          }\n        }\n\n        // Then, migrate to global ords:\n        for(int ord=0;ord<numSegOrds;ord++) {\n          int count = segCounts[ord];\n          if (count != 0) {\n            //System.out.println(\"    migrate segOrd=\" + segOrd + \" ord=\" + ord + \" globalOrd=\" + ordinalMap.getGlobalOrd(segOrd, ord));\n            counts[(int) ordMap.get(ord)] += count;\n          }\n        }\n      }\n    } else {\n      // No ord mapping (e.g., single segment index):\n      // just aggregate directly into counts:\n      for (int doc = it.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = it.nextDoc()) {\n        int term = (int) segValues.nextOrd();\n        while (term != SortedSetDocValues.NO_MORE_ORDS) {\n          counts[term]++;\n          term = (int) segValues.nextOrd();\n        }\n      }\n    }\n\n    \n  }\n\n","sourceOld":"  private void countOneSegment(MultiDocValues.OrdinalMap ordinalMap, LeafReader reader, int segOrd, MatchingDocs hits) throws IOException {\n    SortedSetDocValues segValues = reader.getSortedSetDocValues(field);\n    if (segValues == null) {\n      // nothing to count\n      return;\n    }\n\n    DocIdSetIterator it;\n    if (hits == null) {\n      it = segValues;\n    } else {\n      it = ConjunctionDISI.intersectIterators(Arrays.asList(hits.bits.iterator(), segValues));\n    }\n\n    // TODO: yet another option is to count all segs\n    // first, only in seg-ord space, and then do a\n    // merge-sort-PQ in the end to only \"resolve to\n    // global\" those seg ords that can compete, if we know\n    // we just want top K?  ie, this is the same algo\n    // that'd be used for merging facets across shards\n    // (distributed faceting).  but this has much higher\n    // temp ram req'ts (sum of number of ords across all\n    // segs)\n    if (ordinalMap != null) {\n      final LongValues ordMap = ordinalMap.getGlobalOrds(segOrd);\n\n      int numSegOrds = (int) segValues.getValueCount();\n\n      if (hits != null && hits.totalHits < numSegOrds/10) {\n        //System.out.println(\"    remap as-we-go\");\n        // Remap every ord to global ord as we iterate:\n        for (int doc = it.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = it.nextDoc()) {\n          int term = (int) segValues.nextOrd();\n          while (term != SortedSetDocValues.NO_MORE_ORDS) {\n            //System.out.println(\"      segOrd=\" + segOrd + \" ord=\" + term + \" globalOrd=\" + ordinalMap.getGlobalOrd(segOrd, term));\n            counts[(int) ordMap.get(term)]++;\n            term = (int) segValues.nextOrd();\n          }\n        }\n      } else {\n        //System.out.println(\"    count in seg ord first\");\n\n        // First count in seg-ord space:\n        final int[] segCounts = new int[numSegOrds];\n        for (int doc = it.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = it.nextDoc()) {\n          int term = (int) segValues.nextOrd();\n          while (term != SortedSetDocValues.NO_MORE_ORDS) {\n            //System.out.println(\"      ord=\" + term);\n            segCounts[term]++;\n            term = (int) segValues.nextOrd();\n          }\n        }\n\n        // Then, migrate to global ords:\n        for(int ord=0;ord<numSegOrds;ord++) {\n          int count = segCounts[ord];\n          if (count != 0) {\n            //System.out.println(\"    migrate segOrd=\" + segOrd + \" ord=\" + ord + \" globalOrd=\" + ordinalMap.getGlobalOrd(segOrd, ord));\n            counts[(int) ordMap.get(ord)] += count;\n          }\n        }\n      }\n    } else {\n      // No ord mapping (e.g., single segment index):\n      // just aggregate directly into counts:\n      for (int doc = it.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = it.nextDoc()) {\n        int term = (int) segValues.nextOrd();\n        while (term != SortedSetDocValues.NO_MORE_ORDS) {\n          counts[term]++;\n          term = (int) segValues.nextOrd();\n        }\n      }\n    }\n\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"aaf90fc29510e72665ac7934f34c3d1c25efad64","date":1500354819,"type":5,"author":"Cao Manh Dat","isMerge":true,"pathNew":"lucene/facet/src/java/org/apache/lucene/facet/sortedset/SortedSetDocValuesFacetCounts#countOneSegment(OrdinalMap,LeafReader,int,MatchingDocs).mjava","pathOld":"lucene/facet/src/java/org/apache/lucene/facet/sortedset/SortedSetDocValuesFacetCounts#countOneSegment(MultiDocValues.OrdinalMap,LeafReader,int,MatchingDocs).mjava","sourceNew":"  private void countOneSegment(OrdinalMap ordinalMap, LeafReader reader, int segOrd, MatchingDocs hits) throws IOException {\n    SortedSetDocValues segValues = reader.getSortedSetDocValues(field);\n    if (segValues == null) {\n      // nothing to count\n      return;\n    }\n\n    DocIdSetIterator it;\n    if (hits == null) {\n      it = segValues;\n    } else {\n      it = ConjunctionDISI.intersectIterators(Arrays.asList(hits.bits.iterator(), segValues));\n    }\n\n    // TODO: yet another option is to count all segs\n    // first, only in seg-ord space, and then do a\n    // merge-sort-PQ in the end to only \"resolve to\n    // global\" those seg ords that can compete, if we know\n    // we just want top K?  ie, this is the same algo\n    // that'd be used for merging facets across shards\n    // (distributed faceting).  but this has much higher\n    // temp ram req'ts (sum of number of ords across all\n    // segs)\n    if (ordinalMap != null) {\n      final LongValues ordMap = ordinalMap.getGlobalOrds(segOrd);\n\n      int numSegOrds = (int) segValues.getValueCount();\n\n      if (hits != null && hits.totalHits < numSegOrds/10) {\n        //System.out.println(\"    remap as-we-go\");\n        // Remap every ord to global ord as we iterate:\n        for (int doc = it.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = it.nextDoc()) {\n          int term = (int) segValues.nextOrd();\n          while (term != SortedSetDocValues.NO_MORE_ORDS) {\n            //System.out.println(\"      segOrd=\" + segOrd + \" ord=\" + term + \" globalOrd=\" + ordinalMap.getGlobalOrd(segOrd, term));\n            counts[(int) ordMap.get(term)]++;\n            term = (int) segValues.nextOrd();\n          }\n        }\n      } else {\n        //System.out.println(\"    count in seg ord first\");\n\n        // First count in seg-ord space:\n        final int[] segCounts = new int[numSegOrds];\n        for (int doc = it.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = it.nextDoc()) {\n          int term = (int) segValues.nextOrd();\n          while (term != SortedSetDocValues.NO_MORE_ORDS) {\n            //System.out.println(\"      ord=\" + term);\n            segCounts[term]++;\n            term = (int) segValues.nextOrd();\n          }\n        }\n\n        // Then, migrate to global ords:\n        for(int ord=0;ord<numSegOrds;ord++) {\n          int count = segCounts[ord];\n          if (count != 0) {\n            //System.out.println(\"    migrate segOrd=\" + segOrd + \" ord=\" + ord + \" globalOrd=\" + ordinalMap.getGlobalOrd(segOrd, ord));\n            counts[(int) ordMap.get(ord)] += count;\n          }\n        }\n      }\n    } else {\n      // No ord mapping (e.g., single segment index):\n      // just aggregate directly into counts:\n      for (int doc = it.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = it.nextDoc()) {\n        int term = (int) segValues.nextOrd();\n        while (term != SortedSetDocValues.NO_MORE_ORDS) {\n          counts[term]++;\n          term = (int) segValues.nextOrd();\n        }\n      }\n    }\n\n    \n  }\n\n","sourceOld":"  private void countOneSegment(MultiDocValues.OrdinalMap ordinalMap, LeafReader reader, int segOrd, MatchingDocs hits) throws IOException {\n    SortedSetDocValues segValues = reader.getSortedSetDocValues(field);\n    if (segValues == null) {\n      // nothing to count\n      return;\n    }\n\n    DocIdSetIterator it;\n    if (hits == null) {\n      it = segValues;\n    } else {\n      it = ConjunctionDISI.intersectIterators(Arrays.asList(hits.bits.iterator(), segValues));\n    }\n\n    // TODO: yet another option is to count all segs\n    // first, only in seg-ord space, and then do a\n    // merge-sort-PQ in the end to only \"resolve to\n    // global\" those seg ords that can compete, if we know\n    // we just want top K?  ie, this is the same algo\n    // that'd be used for merging facets across shards\n    // (distributed faceting).  but this has much higher\n    // temp ram req'ts (sum of number of ords across all\n    // segs)\n    if (ordinalMap != null) {\n      final LongValues ordMap = ordinalMap.getGlobalOrds(segOrd);\n\n      int numSegOrds = (int) segValues.getValueCount();\n\n      if (hits != null && hits.totalHits < numSegOrds/10) {\n        //System.out.println(\"    remap as-we-go\");\n        // Remap every ord to global ord as we iterate:\n        for (int doc = it.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = it.nextDoc()) {\n          int term = (int) segValues.nextOrd();\n          while (term != SortedSetDocValues.NO_MORE_ORDS) {\n            //System.out.println(\"      segOrd=\" + segOrd + \" ord=\" + term + \" globalOrd=\" + ordinalMap.getGlobalOrd(segOrd, term));\n            counts[(int) ordMap.get(term)]++;\n            term = (int) segValues.nextOrd();\n          }\n        }\n      } else {\n        //System.out.println(\"    count in seg ord first\");\n\n        // First count in seg-ord space:\n        final int[] segCounts = new int[numSegOrds];\n        for (int doc = it.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = it.nextDoc()) {\n          int term = (int) segValues.nextOrd();\n          while (term != SortedSetDocValues.NO_MORE_ORDS) {\n            //System.out.println(\"      ord=\" + term);\n            segCounts[term]++;\n            term = (int) segValues.nextOrd();\n          }\n        }\n\n        // Then, migrate to global ords:\n        for(int ord=0;ord<numSegOrds;ord++) {\n          int count = segCounts[ord];\n          if (count != 0) {\n            //System.out.println(\"    migrate segOrd=\" + segOrd + \" ord=\" + ord + \" globalOrd=\" + ordinalMap.getGlobalOrd(segOrd, ord));\n            counts[(int) ordMap.get(ord)] += count;\n          }\n        }\n      }\n    } else {\n      // No ord mapping (e.g., single segment index):\n      // just aggregate directly into counts:\n      for (int doc = it.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = it.nextDoc()) {\n        int term = (int) segValues.nextOrd();\n        while (term != SortedSetDocValues.NO_MORE_ORDS) {\n          counts[term]++;\n          term = (int) segValues.nextOrd();\n        }\n      }\n    }\n\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"8cfd1df435f04d4287925cca73cf22120f723892":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"e9017cf144952056066919f1ebc7897ff9bd71b1":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","8cfd1df435f04d4287925cca73cf22120f723892"],"957c610636f393a85a38f1af670540028db13e6b":["8cfd1df435f04d4287925cca73cf22120f723892"],"aaf90fc29510e72665ac7934f34c3d1c25efad64":["e9017cf144952056066919f1ebc7897ff9bd71b1","957c610636f393a85a38f1af670540028db13e6b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["957c610636f393a85a38f1af670540028db13e6b"]},"commit2Childs":{"8cfd1df435f04d4287925cca73cf22120f723892":["e9017cf144952056066919f1ebc7897ff9bd71b1","957c610636f393a85a38f1af670540028db13e6b"],"e9017cf144952056066919f1ebc7897ff9bd71b1":["aaf90fc29510e72665ac7934f34c3d1c25efad64"],"957c610636f393a85a38f1af670540028db13e6b":["aaf90fc29510e72665ac7934f34c3d1c25efad64","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"aaf90fc29510e72665ac7934f34c3d1c25efad64":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["8cfd1df435f04d4287925cca73cf22120f723892","e9017cf144952056066919f1ebc7897ff9bd71b1"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["aaf90fc29510e72665ac7934f34c3d1c25efad64","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}