{"path":"solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simAddReplica(String,ReplicaInfo,boolean).mjava","commits":[{"id":"9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5","date":1556572478,"type":1,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simAddReplica(String,ReplicaInfo,boolean).mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simAddReplica(String,ReplicaInfo,boolean).mjava","sourceNew":"  /**\n   * Add a replica. Note that all details of the replica must be present here, including\n   * node, coreNodeName and SolrCore name.\n   * @param nodeId node id where the replica will be added\n   * @param replicaInfo replica info\n   * @param runLeaderElection if true then run a leader election after adding the replica.\n   */\n  public void simAddReplica(String nodeId, ReplicaInfo replicaInfo, boolean runLeaderElection) throws Exception {\n    ensureNotClosed();\n    lock.lockInterruptibly();\n    try {\n\n      // make sure SolrCore name is unique across cluster and coreNodeName within collection\n      for (Map.Entry<String, List<ReplicaInfo>> e : nodeReplicaMap.entrySet()) {\n        final List<ReplicaInfo> replicas = e.getValue();\n        synchronized (replicas) {\n          for (ReplicaInfo ri : replicas) {\n            if (ri.getCore().equals(replicaInfo.getCore())) {\n              throw new Exception(\"Duplicate SolrCore name for existing=\" + ri + \" on node \" + e.getKey() + \" and new=\" + replicaInfo);\n            }\n            if (ri.getName().equals(replicaInfo.getName()) && ri.getCollection().equals(replicaInfo.getCollection())) {\n              throw new Exception(\"Duplicate coreNode name for existing=\" + ri + \" on node \" + e.getKey() + \" and new=\" + replicaInfo);\n            }\n          }\n        }\n      }\n      if (!liveNodes.contains(nodeId)) {\n        throw new Exception(\"Target node \" + nodeId + \" is not live: \" + liveNodes);\n      }\n      // verify info\n      if (replicaInfo.getCore() == null) {\n        throw new Exception(\"Missing core: \" + replicaInfo);\n      }\n      // XXX replica info is not supposed to have this as a variable\n      replicaInfo.getVariables().remove(ZkStateReader.SHARD_ID_PROP);\n      if (replicaInfo.getName() == null) {\n        throw new Exception(\"Missing name: \" + replicaInfo);\n      }\n      if (replicaInfo.getNode() == null) {\n        throw new Exception(\"Missing node: \" + replicaInfo);\n      }\n      if (!replicaInfo.getNode().equals(nodeId)) {\n        throw new Exception(\"Wrong node (not \" + nodeId + \"): \" + replicaInfo);\n      }\n      \n      opDelay(replicaInfo.getCollection(), CollectionParams.CollectionAction.ADDREPLICA.name());\n\n      // mark replica as active\n      replicaInfo.getVariables().put(ZkStateReader.STATE_PROP, Replica.State.ACTIVE.toString());\n      // add a property expected in Policy calculations, if missing\n      if (replicaInfo.getVariable(Type.CORE_IDX.metricsAttribute) == null) {\n        replicaInfo.getVariables().put(Type.CORE_IDX.metricsAttribute, new AtomicLong(SimCloudManager.DEFAULT_IDX_SIZE_BYTES));\n        replicaInfo.getVariables().put(Variable.coreidxsize,\n            new AtomicDouble((Double)Type.CORE_IDX.convertVal(SimCloudManager.DEFAULT_IDX_SIZE_BYTES)));\n      }\n      nodeReplicaMap.computeIfAbsent(nodeId, Utils.NEW_SYNCHRONIZED_ARRAYLIST_FUN).add(replicaInfo);\n      colShardReplicaMap.computeIfAbsent(replicaInfo.getCollection(), c -> new ConcurrentHashMap<>())\n          .computeIfAbsent(replicaInfo.getShard(), s -> new ArrayList<>())\n          .add(replicaInfo);\n\n      Map<String, Object> values = cloudManager.getSimNodeStateProvider().simGetAllNodeValues()\n          .computeIfAbsent(nodeId, id -> new ConcurrentHashMap<>(SimCloudManager.createNodeValues(id)));\n      // update the number of cores and freedisk in node values\n      Integer cores = (Integer)values.get(ImplicitSnitch.CORES);\n      if (cores == null) {\n        cores = 0;\n      }\n      cloudManager.getSimNodeStateProvider().simSetNodeValue(nodeId, ImplicitSnitch.CORES, cores + 1);\n      Number disk = (Number)values.get(ImplicitSnitch.DISK);\n      if (disk == null) {\n        disk = SimCloudManager.DEFAULT_FREE_DISK;\n      }\n      long replicaSize = ((Number)replicaInfo.getVariable(Type.CORE_IDX.metricsAttribute)).longValue();\n      Number replicaSizeGB = (Number)Type.CORE_IDX.convertVal(replicaSize);\n      cloudManager.getSimNodeStateProvider().simSetNodeValue(nodeId, ImplicitSnitch.DISK, disk.doubleValue() - replicaSizeGB.doubleValue());\n      // fake metrics\n      String registry = SolrMetricManager.getRegistryName(SolrInfoBean.Group.core, replicaInfo.getCollection(),\n          replicaInfo.getShard(),\n          Utils.parseMetricsReplicaName(replicaInfo.getCollection(), replicaInfo.getCore()));\n      cloudManager.getMetricManager().registry(registry).counter(\"UPDATE./update.requests\");\n      cloudManager.getMetricManager().registry(registry).counter(\"QUERY./select.requests\");\n      cloudManager.getMetricManager().registerGauge(null, registry,\n          () -> replicaSize, \"\", true, Type.CORE_IDX.metricsAttribute);\n      // at this point nuke our cached DocCollection state\n      collectionsStatesRef.set(null);\n      log.trace(\"-- simAddReplica {}\", replicaInfo);\n      if (runLeaderElection) {\n        simRunLeaderElection(replicaInfo.getCollection(), replicaInfo.getShard(), true);\n      }\n    } finally {\n      lock.unlock();\n    }\n  }\n\n","sourceOld":"  /**\n   * Add a replica. Note that all details of the replica must be present here, including\n   * node, coreNodeName and SolrCore name.\n   * @param nodeId node id where the replica will be added\n   * @param replicaInfo replica info\n   * @param runLeaderElection if true then run a leader election after adding the replica.\n   */\n  public void simAddReplica(String nodeId, ReplicaInfo replicaInfo, boolean runLeaderElection) throws Exception {\n    ensureNotClosed();\n    lock.lockInterruptibly();\n    try {\n\n      // make sure SolrCore name is unique across cluster and coreNodeName within collection\n      for (Map.Entry<String, List<ReplicaInfo>> e : nodeReplicaMap.entrySet()) {\n        final List<ReplicaInfo> replicas = e.getValue();\n        synchronized (replicas) {\n          for (ReplicaInfo ri : replicas) {\n            if (ri.getCore().equals(replicaInfo.getCore())) {\n              throw new Exception(\"Duplicate SolrCore name for existing=\" + ri + \" on node \" + e.getKey() + \" and new=\" + replicaInfo);\n            }\n            if (ri.getName().equals(replicaInfo.getName()) && ri.getCollection().equals(replicaInfo.getCollection())) {\n              throw new Exception(\"Duplicate coreNode name for existing=\" + ri + \" on node \" + e.getKey() + \" and new=\" + replicaInfo);\n            }\n          }\n        }\n      }\n      if (!liveNodes.contains(nodeId)) {\n        throw new Exception(\"Target node \" + nodeId + \" is not live: \" + liveNodes);\n      }\n      // verify info\n      if (replicaInfo.getCore() == null) {\n        throw new Exception(\"Missing core: \" + replicaInfo);\n      }\n      // XXX replica info is not supposed to have this as a variable\n      replicaInfo.getVariables().remove(ZkStateReader.SHARD_ID_PROP);\n      if (replicaInfo.getName() == null) {\n        throw new Exception(\"Missing name: \" + replicaInfo);\n      }\n      if (replicaInfo.getNode() == null) {\n        throw new Exception(\"Missing node: \" + replicaInfo);\n      }\n      if (!replicaInfo.getNode().equals(nodeId)) {\n        throw new Exception(\"Wrong node (not \" + nodeId + \"): \" + replicaInfo);\n      }\n      \n      opDelay(replicaInfo.getCollection(), CollectionParams.CollectionAction.ADDREPLICA.name());\n\n      // mark replica as active\n      replicaInfo.getVariables().put(ZkStateReader.STATE_PROP, Replica.State.ACTIVE.toString());\n      // add a property expected in Policy calculations, if missing\n      if (replicaInfo.getVariable(Type.CORE_IDX.metricsAttribute) == null) {\n        replicaInfo.getVariables().put(Type.CORE_IDX.metricsAttribute, new AtomicLong(SimCloudManager.DEFAULT_IDX_SIZE_BYTES));\n        replicaInfo.getVariables().put(Variable.coreidxsize,\n            new AtomicDouble((Double)Type.CORE_IDX.convertVal(SimCloudManager.DEFAULT_IDX_SIZE_BYTES)));\n      }\n      nodeReplicaMap.computeIfAbsent(nodeId, Utils.NEW_SYNCHRONIZED_ARRAYLIST_FUN).add(replicaInfo);\n      colShardReplicaMap.computeIfAbsent(replicaInfo.getCollection(), c -> new ConcurrentHashMap<>())\n          .computeIfAbsent(replicaInfo.getShard(), s -> new ArrayList<>())\n          .add(replicaInfo);\n\n      Map<String, Object> values = cloudManager.getSimNodeStateProvider().simGetAllNodeValues()\n          .computeIfAbsent(nodeId, id -> new ConcurrentHashMap<>(SimCloudManager.createNodeValues(id)));\n      // update the number of cores and freedisk in node values\n      Integer cores = (Integer)values.get(ImplicitSnitch.CORES);\n      if (cores == null) {\n        cores = 0;\n      }\n      cloudManager.getSimNodeStateProvider().simSetNodeValue(nodeId, ImplicitSnitch.CORES, cores + 1);\n      Integer disk = (Integer)values.get(ImplicitSnitch.DISK);\n      if (disk == null) {\n        disk = SimCloudManager.DEFAULT_FREE_DISK;\n      }\n      cloudManager.getSimNodeStateProvider().simSetNodeValue(nodeId, ImplicitSnitch.DISK, disk - 1);\n      // fake metrics\n      String registry = SolrMetricManager.getRegistryName(SolrInfoBean.Group.core, replicaInfo.getCollection(),\n          replicaInfo.getShard(),\n          Utils.parseMetricsReplicaName(replicaInfo.getCollection(), replicaInfo.getCore()));\n      cloudManager.getMetricManager().registry(registry).counter(\"UPDATE./update.requests\");\n      cloudManager.getMetricManager().registry(registry).counter(\"QUERY./select.requests\");\n      cloudManager.getMetricManager().registerGauge(null, registry,\n          () -> ((Number)replicaInfo.getVariable(Type.CORE_IDX.metricsAttribute)).longValue(),\n          \"\", true, \"INDEX.sizeInBytes\");\n      // at this point nuke our cached DocCollection state\n      collectionsStatesRef.set(null);\n      log.trace(\"-- simAddReplica {}\", replicaInfo);\n      if (runLeaderElection) {\n        simRunLeaderElection(replicaInfo.getCollection(), replicaInfo.getShard(), true);\n      }\n    } finally {\n      lock.unlock();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"edf5b262a72d10530eb2f01dc8f19060355b213e","date":1557765866,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simAddReplica(String,ReplicaInfo,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simAddReplica(String,ReplicaInfo,boolean).mjava","sourceNew":"  /**\n   * Add a replica. Note that all details of the replica must be present here, including\n   * node, coreNodeName and SolrCore name.\n   * @param nodeId node id where the replica will be added\n   * @param replicaInfo replica info\n   * @param runLeaderElection if true then run a leader election after adding the replica.\n   */\n  public void simAddReplica(String nodeId, ReplicaInfo replicaInfo, boolean runLeaderElection) throws Exception {\n    ensureNotClosed();\n    lock.lockInterruptibly();\n    try {\n\n      // make sure SolrCore name is unique across cluster and coreNodeName within collection\n      for (Map.Entry<String, List<ReplicaInfo>> e : nodeReplicaMap.entrySet()) {\n        final List<ReplicaInfo> replicas = e.getValue();\n        synchronized (replicas) {\n          for (ReplicaInfo ri : replicas) {\n            if (ri.getCore().equals(replicaInfo.getCore())) {\n              throw new Exception(\"Duplicate SolrCore name for existing=\" + ri + \" on node \" + e.getKey() + \" and new=\" + replicaInfo);\n            }\n            if (ri.getName().equals(replicaInfo.getName()) && ri.getCollection().equals(replicaInfo.getCollection())) {\n              throw new Exception(\"Duplicate coreNode name for existing=\" + ri + \" on node \" + e.getKey() + \" and new=\" + replicaInfo);\n            }\n          }\n        }\n      }\n      if (!liveNodes.contains(nodeId)) {\n        throw new Exception(\"Target node \" + nodeId + \" is not live: \" + liveNodes);\n      }\n      // verify info\n      if (replicaInfo.getCore() == null) {\n        throw new Exception(\"Missing core: \" + replicaInfo);\n      }\n      // XXX replica info is not supposed to have this as a variable\n      replicaInfo.getVariables().remove(ZkStateReader.SHARD_ID_PROP);\n      if (replicaInfo.getName() == null) {\n        throw new Exception(\"Missing name: \" + replicaInfo);\n      }\n      if (replicaInfo.getNode() == null) {\n        throw new Exception(\"Missing node: \" + replicaInfo);\n      }\n      if (!replicaInfo.getNode().equals(nodeId)) {\n        throw new Exception(\"Wrong node (not \" + nodeId + \"): \" + replicaInfo);\n      }\n      \n      opDelay(replicaInfo.getCollection(), CollectionParams.CollectionAction.ADDREPLICA.name());\n\n      // mark replica as active\n      replicaInfo.getVariables().put(ZkStateReader.STATE_PROP, Replica.State.ACTIVE.toString());\n      // add a property expected in Policy calculations, if missing\n      if (replicaInfo.getVariable(Type.CORE_IDX.metricsAttribute) == null) {\n        replicaInfo.getVariables().put(Type.CORE_IDX.metricsAttribute, new AtomicLong(SimCloudManager.DEFAULT_IDX_SIZE_BYTES));\n        replicaInfo.getVariables().put(Variable.coreidxsize,\n            new AtomicDouble((Double)Type.CORE_IDX.convertVal(SimCloudManager.DEFAULT_IDX_SIZE_BYTES)));\n      }\n      nodeReplicaMap.computeIfAbsent(nodeId, Utils.NEW_SYNCHRONIZED_ARRAYLIST_FUN).add(replicaInfo);\n      colShardReplicaMap.computeIfAbsent(replicaInfo.getCollection(), c -> new ConcurrentHashMap<>())\n          .computeIfAbsent(replicaInfo.getShard(), s -> new ArrayList<>())\n          .add(replicaInfo);\n\n      Map<String, Object> values = cloudManager.getSimNodeStateProvider().simGetAllNodeValues()\n          .computeIfAbsent(nodeId, id -> new ConcurrentHashMap<>(SimCloudManager.createNodeValues(id)));\n      // update the number of cores and freedisk in node values\n      Number cores = (Number)values.get(ImplicitSnitch.CORES);\n      if (cores == null) {\n        cores = 0;\n      }\n      cloudManager.getSimNodeStateProvider().simSetNodeValue(nodeId, ImplicitSnitch.CORES, cores.intValue() + 1);\n      Number disk = (Number)values.get(ImplicitSnitch.DISK);\n      if (disk == null) {\n        throw new Exception(\"Missing '\" + ImplicitSnitch.DISK + \"' in node metrics for node \" + nodeId);\n        //disk = SimCloudManager.DEFAULT_FREE_DISK;\n      }\n      long replicaSize = ((Number)replicaInfo.getVariable(Type.CORE_IDX.metricsAttribute)).longValue();\n      Number replicaSizeGB = (Number)Type.CORE_IDX.convertVal(replicaSize);\n      cloudManager.getSimNodeStateProvider().simSetNodeValue(nodeId, ImplicitSnitch.DISK, disk.doubleValue() - replicaSizeGB.doubleValue());\n      // fake metrics\n      String registry = SolrMetricManager.getRegistryName(SolrInfoBean.Group.core, replicaInfo.getCollection(),\n          replicaInfo.getShard(),\n          Utils.parseMetricsReplicaName(replicaInfo.getCollection(), replicaInfo.getCore()));\n      cloudManager.getMetricManager().registry(registry).counter(\"UPDATE./update.requests\");\n      cloudManager.getMetricManager().registry(registry).counter(\"QUERY./select.requests\");\n      cloudManager.getMetricManager().registerGauge(null, registry,\n          () -> replicaSize, \"\", true, Type.CORE_IDX.metricsAttribute);\n      // at this point nuke our cached DocCollection state\n      collectionsStatesRef.set(null);\n      log.trace(\"-- simAddReplica {}\", replicaInfo);\n      if (runLeaderElection) {\n        simRunLeaderElection(replicaInfo.getCollection(), replicaInfo.getShard(), true);\n      }\n    } finally {\n      lock.unlock();\n    }\n  }\n\n","sourceOld":"  /**\n   * Add a replica. Note that all details of the replica must be present here, including\n   * node, coreNodeName and SolrCore name.\n   * @param nodeId node id where the replica will be added\n   * @param replicaInfo replica info\n   * @param runLeaderElection if true then run a leader election after adding the replica.\n   */\n  public void simAddReplica(String nodeId, ReplicaInfo replicaInfo, boolean runLeaderElection) throws Exception {\n    ensureNotClosed();\n    lock.lockInterruptibly();\n    try {\n\n      // make sure SolrCore name is unique across cluster and coreNodeName within collection\n      for (Map.Entry<String, List<ReplicaInfo>> e : nodeReplicaMap.entrySet()) {\n        final List<ReplicaInfo> replicas = e.getValue();\n        synchronized (replicas) {\n          for (ReplicaInfo ri : replicas) {\n            if (ri.getCore().equals(replicaInfo.getCore())) {\n              throw new Exception(\"Duplicate SolrCore name for existing=\" + ri + \" on node \" + e.getKey() + \" and new=\" + replicaInfo);\n            }\n            if (ri.getName().equals(replicaInfo.getName()) && ri.getCollection().equals(replicaInfo.getCollection())) {\n              throw new Exception(\"Duplicate coreNode name for existing=\" + ri + \" on node \" + e.getKey() + \" and new=\" + replicaInfo);\n            }\n          }\n        }\n      }\n      if (!liveNodes.contains(nodeId)) {\n        throw new Exception(\"Target node \" + nodeId + \" is not live: \" + liveNodes);\n      }\n      // verify info\n      if (replicaInfo.getCore() == null) {\n        throw new Exception(\"Missing core: \" + replicaInfo);\n      }\n      // XXX replica info is not supposed to have this as a variable\n      replicaInfo.getVariables().remove(ZkStateReader.SHARD_ID_PROP);\n      if (replicaInfo.getName() == null) {\n        throw new Exception(\"Missing name: \" + replicaInfo);\n      }\n      if (replicaInfo.getNode() == null) {\n        throw new Exception(\"Missing node: \" + replicaInfo);\n      }\n      if (!replicaInfo.getNode().equals(nodeId)) {\n        throw new Exception(\"Wrong node (not \" + nodeId + \"): \" + replicaInfo);\n      }\n      \n      opDelay(replicaInfo.getCollection(), CollectionParams.CollectionAction.ADDREPLICA.name());\n\n      // mark replica as active\n      replicaInfo.getVariables().put(ZkStateReader.STATE_PROP, Replica.State.ACTIVE.toString());\n      // add a property expected in Policy calculations, if missing\n      if (replicaInfo.getVariable(Type.CORE_IDX.metricsAttribute) == null) {\n        replicaInfo.getVariables().put(Type.CORE_IDX.metricsAttribute, new AtomicLong(SimCloudManager.DEFAULT_IDX_SIZE_BYTES));\n        replicaInfo.getVariables().put(Variable.coreidxsize,\n            new AtomicDouble((Double)Type.CORE_IDX.convertVal(SimCloudManager.DEFAULT_IDX_SIZE_BYTES)));\n      }\n      nodeReplicaMap.computeIfAbsent(nodeId, Utils.NEW_SYNCHRONIZED_ARRAYLIST_FUN).add(replicaInfo);\n      colShardReplicaMap.computeIfAbsent(replicaInfo.getCollection(), c -> new ConcurrentHashMap<>())\n          .computeIfAbsent(replicaInfo.getShard(), s -> new ArrayList<>())\n          .add(replicaInfo);\n\n      Map<String, Object> values = cloudManager.getSimNodeStateProvider().simGetAllNodeValues()\n          .computeIfAbsent(nodeId, id -> new ConcurrentHashMap<>(SimCloudManager.createNodeValues(id)));\n      // update the number of cores and freedisk in node values\n      Integer cores = (Integer)values.get(ImplicitSnitch.CORES);\n      if (cores == null) {\n        cores = 0;\n      }\n      cloudManager.getSimNodeStateProvider().simSetNodeValue(nodeId, ImplicitSnitch.CORES, cores + 1);\n      Number disk = (Number)values.get(ImplicitSnitch.DISK);\n      if (disk == null) {\n        disk = SimCloudManager.DEFAULT_FREE_DISK;\n      }\n      long replicaSize = ((Number)replicaInfo.getVariable(Type.CORE_IDX.metricsAttribute)).longValue();\n      Number replicaSizeGB = (Number)Type.CORE_IDX.convertVal(replicaSize);\n      cloudManager.getSimNodeStateProvider().simSetNodeValue(nodeId, ImplicitSnitch.DISK, disk.doubleValue() - replicaSizeGB.doubleValue());\n      // fake metrics\n      String registry = SolrMetricManager.getRegistryName(SolrInfoBean.Group.core, replicaInfo.getCollection(),\n          replicaInfo.getShard(),\n          Utils.parseMetricsReplicaName(replicaInfo.getCollection(), replicaInfo.getCore()));\n      cloudManager.getMetricManager().registry(registry).counter(\"UPDATE./update.requests\");\n      cloudManager.getMetricManager().registry(registry).counter(\"QUERY./select.requests\");\n      cloudManager.getMetricManager().registerGauge(null, registry,\n          () -> replicaSize, \"\", true, Type.CORE_IDX.metricsAttribute);\n      // at this point nuke our cached DocCollection state\n      collectionsStatesRef.set(null);\n      log.trace(\"-- simAddReplica {}\", replicaInfo);\n      if (runLeaderElection) {\n        simRunLeaderElection(replicaInfo.getCollection(), replicaInfo.getShard(), true);\n      }\n    } finally {\n      lock.unlock();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"eb7a329be123e1f46f9d78d74f6d23f33ec81b0a","date":1589907167,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simAddReplica(String,ReplicaInfo,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simAddReplica(String,ReplicaInfo,boolean).mjava","sourceNew":"  /**\n   * Add a replica. Note that all details of the replica must be present here, including\n   * node, coreNodeName and SolrCore name.\n   * @param nodeId node id where the replica will be added\n   * @param replicaInfo replica info\n   * @param runLeaderElection if true then run a leader election after adding the replica.\n   */\n  public void simAddReplica(String nodeId, ReplicaInfo replicaInfo, boolean runLeaderElection) throws Exception {\n    ensureNotClosed();\n    lock.lockInterruptibly();\n    try {\n\n      // make sure SolrCore name is unique across cluster and coreNodeName within collection\n      for (Map.Entry<String, List<ReplicaInfo>> e : nodeReplicaMap.entrySet()) {\n        final List<ReplicaInfo> replicas = e.getValue();\n        synchronized (replicas) {\n          for (ReplicaInfo ri : replicas) {\n            if (ri.getCore().equals(replicaInfo.getCore())) {\n              throw new Exception(\"Duplicate SolrCore name for existing=\" + ri + \" on node \" + e.getKey() + \" and new=\" + replicaInfo);\n            }\n            if (ri.getName().equals(replicaInfo.getName()) && ri.getCollection().equals(replicaInfo.getCollection())) {\n              throw new Exception(\"Duplicate coreNode name for existing=\" + ri + \" on node \" + e.getKey() + \" and new=\" + replicaInfo);\n            }\n          }\n        }\n      }\n      if (!liveNodes.contains(nodeId)) {\n        throw new Exception(\"Target node \" + nodeId + \" is not live: \" + liveNodes);\n      }\n      // verify info\n      if (replicaInfo.getCore() == null) {\n        throw new Exception(\"Missing core: \" + replicaInfo);\n      }\n      // XXX replica info is not supposed to have this as a variable\n      replicaInfo.getVariables().remove(ZkStateReader.SHARD_ID_PROP);\n      if (replicaInfo.getName() == null) {\n        throw new Exception(\"Missing name: \" + replicaInfo);\n      }\n      if (replicaInfo.getNode() == null) {\n        throw new Exception(\"Missing node: \" + replicaInfo);\n      }\n      if (!replicaInfo.getNode().equals(nodeId)) {\n        throw new Exception(\"Wrong node (not \" + nodeId + \"): \" + replicaInfo);\n      }\n      \n      opDelay(replicaInfo.getCollection(), CollectionParams.CollectionAction.ADDREPLICA.name());\n\n      // mark replica as active\n      replicaInfo.getVariables().put(ZkStateReader.STATE_PROP, Replica.State.ACTIVE.toString());\n      // add a property expected in Policy calculations, if missing\n      if (replicaInfo.getVariable(Type.CORE_IDX.metricsAttribute) == null) {\n        replicaInfo.getVariables().put(Type.CORE_IDX.metricsAttribute, new AtomicLong(SimCloudManager.DEFAULT_IDX_SIZE_BYTES));\n        replicaInfo.getVariables().put(Variable.coreidxsize,\n            new AtomicDouble((Double)Type.CORE_IDX.convertVal(SimCloudManager.DEFAULT_IDX_SIZE_BYTES)));\n      }\n      nodeReplicaMap.computeIfAbsent(nodeId, Utils.NEW_SYNCHRONIZED_ARRAYLIST_FUN).add(replicaInfo);\n      colShardReplicaMap.computeIfAbsent(replicaInfo.getCollection(), c -> new ConcurrentHashMap<>())\n          .computeIfAbsent(replicaInfo.getShard(), s -> new ArrayList<>())\n          .add(replicaInfo);\n\n      Map<String, Object> values = cloudManager.getSimNodeStateProvider().simGetAllNodeValues()\n          .computeIfAbsent(nodeId, id -> new ConcurrentHashMap<>(SimCloudManager.createNodeValues(id)));\n      // update the number of cores and freedisk in node values\n      Number cores = (Number)values.get(ImplicitSnitch.CORES);\n      if (cores == null) {\n        cores = 0;\n      }\n      cloudManager.getSimNodeStateProvider().simSetNodeValue(nodeId, ImplicitSnitch.CORES, cores.intValue() + 1);\n      Number disk = (Number)values.get(ImplicitSnitch.DISK);\n      if (disk == null) {\n        throw new Exception(\"Missing '\" + ImplicitSnitch.DISK + \"' in node metrics for node \" + nodeId);\n        //disk = SimCloudManager.DEFAULT_FREE_DISK;\n      }\n      long replicaSize = ((Number)replicaInfo.getVariable(Type.CORE_IDX.metricsAttribute)).longValue();\n      Number replicaSizeGB = (Number)Type.CORE_IDX.convertVal(replicaSize);\n      cloudManager.getSimNodeStateProvider().simSetNodeValue(nodeId, ImplicitSnitch.DISK, disk.doubleValue() - replicaSizeGB.doubleValue());\n      // fake metrics\n      String registry = SolrMetricManager.getRegistryName(SolrInfoBean.Group.core, replicaInfo.getCollection(),\n          replicaInfo.getShard(),\n          Utils.parseMetricsReplicaName(replicaInfo.getCollection(), replicaInfo.getCore()));\n      cloudManager.getMetricManager().registry(registry).counter(\"UPDATE./update.requests\");\n      cloudManager.getMetricManager().registry(registry).counter(\"QUERY./select.requests\");\n      cloudManager.getMetricManager().registerGauge(null, registry,\n          () -> replicaSize, \"\", true, Type.CORE_IDX.metricsAttribute);\n      // at this point nuke our cached DocCollection state\n      collectionsStatesRef.get(replicaInfo.getCollection()).invalidate();\n      log.trace(\"-- simAddReplica {}\", replicaInfo);\n      if (runLeaderElection) {\n        simRunLeaderElection(replicaInfo.getCollection(), replicaInfo.getShard(), true);\n      }\n    } finally {\n      lock.unlock();\n    }\n  }\n\n","sourceOld":"  /**\n   * Add a replica. Note that all details of the replica must be present here, including\n   * node, coreNodeName and SolrCore name.\n   * @param nodeId node id where the replica will be added\n   * @param replicaInfo replica info\n   * @param runLeaderElection if true then run a leader election after adding the replica.\n   */\n  public void simAddReplica(String nodeId, ReplicaInfo replicaInfo, boolean runLeaderElection) throws Exception {\n    ensureNotClosed();\n    lock.lockInterruptibly();\n    try {\n\n      // make sure SolrCore name is unique across cluster and coreNodeName within collection\n      for (Map.Entry<String, List<ReplicaInfo>> e : nodeReplicaMap.entrySet()) {\n        final List<ReplicaInfo> replicas = e.getValue();\n        synchronized (replicas) {\n          for (ReplicaInfo ri : replicas) {\n            if (ri.getCore().equals(replicaInfo.getCore())) {\n              throw new Exception(\"Duplicate SolrCore name for existing=\" + ri + \" on node \" + e.getKey() + \" and new=\" + replicaInfo);\n            }\n            if (ri.getName().equals(replicaInfo.getName()) && ri.getCollection().equals(replicaInfo.getCollection())) {\n              throw new Exception(\"Duplicate coreNode name for existing=\" + ri + \" on node \" + e.getKey() + \" and new=\" + replicaInfo);\n            }\n          }\n        }\n      }\n      if (!liveNodes.contains(nodeId)) {\n        throw new Exception(\"Target node \" + nodeId + \" is not live: \" + liveNodes);\n      }\n      // verify info\n      if (replicaInfo.getCore() == null) {\n        throw new Exception(\"Missing core: \" + replicaInfo);\n      }\n      // XXX replica info is not supposed to have this as a variable\n      replicaInfo.getVariables().remove(ZkStateReader.SHARD_ID_PROP);\n      if (replicaInfo.getName() == null) {\n        throw new Exception(\"Missing name: \" + replicaInfo);\n      }\n      if (replicaInfo.getNode() == null) {\n        throw new Exception(\"Missing node: \" + replicaInfo);\n      }\n      if (!replicaInfo.getNode().equals(nodeId)) {\n        throw new Exception(\"Wrong node (not \" + nodeId + \"): \" + replicaInfo);\n      }\n      \n      opDelay(replicaInfo.getCollection(), CollectionParams.CollectionAction.ADDREPLICA.name());\n\n      // mark replica as active\n      replicaInfo.getVariables().put(ZkStateReader.STATE_PROP, Replica.State.ACTIVE.toString());\n      // add a property expected in Policy calculations, if missing\n      if (replicaInfo.getVariable(Type.CORE_IDX.metricsAttribute) == null) {\n        replicaInfo.getVariables().put(Type.CORE_IDX.metricsAttribute, new AtomicLong(SimCloudManager.DEFAULT_IDX_SIZE_BYTES));\n        replicaInfo.getVariables().put(Variable.coreidxsize,\n            new AtomicDouble((Double)Type.CORE_IDX.convertVal(SimCloudManager.DEFAULT_IDX_SIZE_BYTES)));\n      }\n      nodeReplicaMap.computeIfAbsent(nodeId, Utils.NEW_SYNCHRONIZED_ARRAYLIST_FUN).add(replicaInfo);\n      colShardReplicaMap.computeIfAbsent(replicaInfo.getCollection(), c -> new ConcurrentHashMap<>())\n          .computeIfAbsent(replicaInfo.getShard(), s -> new ArrayList<>())\n          .add(replicaInfo);\n\n      Map<String, Object> values = cloudManager.getSimNodeStateProvider().simGetAllNodeValues()\n          .computeIfAbsent(nodeId, id -> new ConcurrentHashMap<>(SimCloudManager.createNodeValues(id)));\n      // update the number of cores and freedisk in node values\n      Number cores = (Number)values.get(ImplicitSnitch.CORES);\n      if (cores == null) {\n        cores = 0;\n      }\n      cloudManager.getSimNodeStateProvider().simSetNodeValue(nodeId, ImplicitSnitch.CORES, cores.intValue() + 1);\n      Number disk = (Number)values.get(ImplicitSnitch.DISK);\n      if (disk == null) {\n        throw new Exception(\"Missing '\" + ImplicitSnitch.DISK + \"' in node metrics for node \" + nodeId);\n        //disk = SimCloudManager.DEFAULT_FREE_DISK;\n      }\n      long replicaSize = ((Number)replicaInfo.getVariable(Type.CORE_IDX.metricsAttribute)).longValue();\n      Number replicaSizeGB = (Number)Type.CORE_IDX.convertVal(replicaSize);\n      cloudManager.getSimNodeStateProvider().simSetNodeValue(nodeId, ImplicitSnitch.DISK, disk.doubleValue() - replicaSizeGB.doubleValue());\n      // fake metrics\n      String registry = SolrMetricManager.getRegistryName(SolrInfoBean.Group.core, replicaInfo.getCollection(),\n          replicaInfo.getShard(),\n          Utils.parseMetricsReplicaName(replicaInfo.getCollection(), replicaInfo.getCore()));\n      cloudManager.getMetricManager().registry(registry).counter(\"UPDATE./update.requests\");\n      cloudManager.getMetricManager().registry(registry).counter(\"QUERY./select.requests\");\n      cloudManager.getMetricManager().registerGauge(null, registry,\n          () -> replicaSize, \"\", true, Type.CORE_IDX.metricsAttribute);\n      // at this point nuke our cached DocCollection state\n      collectionsStatesRef.set(null);\n      log.trace(\"-- simAddReplica {}\", replicaInfo);\n      if (runLeaderElection) {\n        simRunLeaderElection(replicaInfo.getCollection(), replicaInfo.getShard(), true);\n      }\n    } finally {\n      lock.unlock();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"daa0f21a44e235a2299ea1fa913898b182dd7cce","date":1590952026,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simAddReplica(String,ReplicaInfo,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simAddReplica(String,ReplicaInfo,boolean).mjava","sourceNew":"  /**\n   * Add a replica. Note that all details of the replica must be present here, including\n   * node, coreNodeName and SolrCore name.\n   * @param nodeId node id where the replica will be added\n   * @param replicaInfo replica info\n   * @param runLeaderElection if true then run a leader election after adding the replica.\n   */\n  @SuppressWarnings({\"unchecked\"})\n  public void simAddReplica(String nodeId, ReplicaInfo replicaInfo, boolean runLeaderElection) throws Exception {\n    ensureNotClosed();\n    lock.lockInterruptibly();\n    try {\n\n      // make sure SolrCore name is unique across cluster and coreNodeName within collection\n      for (Map.Entry<String, List<ReplicaInfo>> e : nodeReplicaMap.entrySet()) {\n        final List<ReplicaInfo> replicas = e.getValue();\n        synchronized (replicas) {\n          for (ReplicaInfo ri : replicas) {\n            if (ri.getCore().equals(replicaInfo.getCore())) {\n              throw new Exception(\"Duplicate SolrCore name for existing=\" + ri + \" on node \" + e.getKey() + \" and new=\" + replicaInfo);\n            }\n            if (ri.getName().equals(replicaInfo.getName()) && ri.getCollection().equals(replicaInfo.getCollection())) {\n              throw new Exception(\"Duplicate coreNode name for existing=\" + ri + \" on node \" + e.getKey() + \" and new=\" + replicaInfo);\n            }\n          }\n        }\n      }\n      if (!liveNodes.contains(nodeId)) {\n        throw new Exception(\"Target node \" + nodeId + \" is not live: \" + liveNodes);\n      }\n      // verify info\n      if (replicaInfo.getCore() == null) {\n        throw new Exception(\"Missing core: \" + replicaInfo);\n      }\n      // XXX replica info is not supposed to have this as a variable\n      replicaInfo.getVariables().remove(ZkStateReader.SHARD_ID_PROP);\n      if (replicaInfo.getName() == null) {\n        throw new Exception(\"Missing name: \" + replicaInfo);\n      }\n      if (replicaInfo.getNode() == null) {\n        throw new Exception(\"Missing node: \" + replicaInfo);\n      }\n      if (!replicaInfo.getNode().equals(nodeId)) {\n        throw new Exception(\"Wrong node (not \" + nodeId + \"): \" + replicaInfo);\n      }\n      \n      opDelay(replicaInfo.getCollection(), CollectionParams.CollectionAction.ADDREPLICA.name());\n\n      // mark replica as active\n      replicaInfo.getVariables().put(ZkStateReader.STATE_PROP, Replica.State.ACTIVE.toString());\n      // add a property expected in Policy calculations, if missing\n      if (replicaInfo.getVariable(Type.CORE_IDX.metricsAttribute) == null) {\n        replicaInfo.getVariables().put(Type.CORE_IDX.metricsAttribute, new AtomicLong(SimCloudManager.DEFAULT_IDX_SIZE_BYTES));\n        replicaInfo.getVariables().put(Variable.coreidxsize,\n            new AtomicDouble((Double)Type.CORE_IDX.convertVal(SimCloudManager.DEFAULT_IDX_SIZE_BYTES)));\n      }\n      nodeReplicaMap.computeIfAbsent(nodeId, Utils.NEW_SYNCHRONIZED_ARRAYLIST_FUN).add(replicaInfo);\n      colShardReplicaMap.computeIfAbsent(replicaInfo.getCollection(), c -> new ConcurrentHashMap<>())\n          .computeIfAbsent(replicaInfo.getShard(), s -> new ArrayList<>())\n          .add(replicaInfo);\n\n      Map<String, Object> values = cloudManager.getSimNodeStateProvider().simGetAllNodeValues()\n          .computeIfAbsent(nodeId, id -> new ConcurrentHashMap<>(SimCloudManager.createNodeValues(id)));\n      // update the number of cores and freedisk in node values\n      Number cores = (Number)values.get(ImplicitSnitch.CORES);\n      if (cores == null) {\n        cores = 0;\n      }\n      cloudManager.getSimNodeStateProvider().simSetNodeValue(nodeId, ImplicitSnitch.CORES, cores.intValue() + 1);\n      Number disk = (Number)values.get(ImplicitSnitch.DISK);\n      if (disk == null) {\n        throw new Exception(\"Missing '\" + ImplicitSnitch.DISK + \"' in node metrics for node \" + nodeId);\n        //disk = SimCloudManager.DEFAULT_FREE_DISK;\n      }\n      long replicaSize = ((Number)replicaInfo.getVariable(Type.CORE_IDX.metricsAttribute)).longValue();\n      Number replicaSizeGB = (Number)Type.CORE_IDX.convertVal(replicaSize);\n      cloudManager.getSimNodeStateProvider().simSetNodeValue(nodeId, ImplicitSnitch.DISK, disk.doubleValue() - replicaSizeGB.doubleValue());\n      // fake metrics\n      String registry = SolrMetricManager.getRegistryName(SolrInfoBean.Group.core, replicaInfo.getCollection(),\n          replicaInfo.getShard(),\n          Utils.parseMetricsReplicaName(replicaInfo.getCollection(), replicaInfo.getCore()));\n      cloudManager.getMetricManager().registry(registry).counter(\"UPDATE./update.requests\");\n      cloudManager.getMetricManager().registry(registry).counter(\"QUERY./select.requests\");\n      cloudManager.getMetricManager().registerGauge(null, registry,\n          () -> replicaSize, \"\", true, Type.CORE_IDX.metricsAttribute);\n      // at this point nuke our cached DocCollection state\n      collectionsStatesRef.get(replicaInfo.getCollection()).invalidate();\n      log.trace(\"-- simAddReplica {}\", replicaInfo);\n      if (runLeaderElection) {\n        simRunLeaderElection(replicaInfo.getCollection(), replicaInfo.getShard(), true);\n      }\n    } finally {\n      lock.unlock();\n    }\n  }\n\n","sourceOld":"  /**\n   * Add a replica. Note that all details of the replica must be present here, including\n   * node, coreNodeName and SolrCore name.\n   * @param nodeId node id where the replica will be added\n   * @param replicaInfo replica info\n   * @param runLeaderElection if true then run a leader election after adding the replica.\n   */\n  public void simAddReplica(String nodeId, ReplicaInfo replicaInfo, boolean runLeaderElection) throws Exception {\n    ensureNotClosed();\n    lock.lockInterruptibly();\n    try {\n\n      // make sure SolrCore name is unique across cluster and coreNodeName within collection\n      for (Map.Entry<String, List<ReplicaInfo>> e : nodeReplicaMap.entrySet()) {\n        final List<ReplicaInfo> replicas = e.getValue();\n        synchronized (replicas) {\n          for (ReplicaInfo ri : replicas) {\n            if (ri.getCore().equals(replicaInfo.getCore())) {\n              throw new Exception(\"Duplicate SolrCore name for existing=\" + ri + \" on node \" + e.getKey() + \" and new=\" + replicaInfo);\n            }\n            if (ri.getName().equals(replicaInfo.getName()) && ri.getCollection().equals(replicaInfo.getCollection())) {\n              throw new Exception(\"Duplicate coreNode name for existing=\" + ri + \" on node \" + e.getKey() + \" and new=\" + replicaInfo);\n            }\n          }\n        }\n      }\n      if (!liveNodes.contains(nodeId)) {\n        throw new Exception(\"Target node \" + nodeId + \" is not live: \" + liveNodes);\n      }\n      // verify info\n      if (replicaInfo.getCore() == null) {\n        throw new Exception(\"Missing core: \" + replicaInfo);\n      }\n      // XXX replica info is not supposed to have this as a variable\n      replicaInfo.getVariables().remove(ZkStateReader.SHARD_ID_PROP);\n      if (replicaInfo.getName() == null) {\n        throw new Exception(\"Missing name: \" + replicaInfo);\n      }\n      if (replicaInfo.getNode() == null) {\n        throw new Exception(\"Missing node: \" + replicaInfo);\n      }\n      if (!replicaInfo.getNode().equals(nodeId)) {\n        throw new Exception(\"Wrong node (not \" + nodeId + \"): \" + replicaInfo);\n      }\n      \n      opDelay(replicaInfo.getCollection(), CollectionParams.CollectionAction.ADDREPLICA.name());\n\n      // mark replica as active\n      replicaInfo.getVariables().put(ZkStateReader.STATE_PROP, Replica.State.ACTIVE.toString());\n      // add a property expected in Policy calculations, if missing\n      if (replicaInfo.getVariable(Type.CORE_IDX.metricsAttribute) == null) {\n        replicaInfo.getVariables().put(Type.CORE_IDX.metricsAttribute, new AtomicLong(SimCloudManager.DEFAULT_IDX_SIZE_BYTES));\n        replicaInfo.getVariables().put(Variable.coreidxsize,\n            new AtomicDouble((Double)Type.CORE_IDX.convertVal(SimCloudManager.DEFAULT_IDX_SIZE_BYTES)));\n      }\n      nodeReplicaMap.computeIfAbsent(nodeId, Utils.NEW_SYNCHRONIZED_ARRAYLIST_FUN).add(replicaInfo);\n      colShardReplicaMap.computeIfAbsent(replicaInfo.getCollection(), c -> new ConcurrentHashMap<>())\n          .computeIfAbsent(replicaInfo.getShard(), s -> new ArrayList<>())\n          .add(replicaInfo);\n\n      Map<String, Object> values = cloudManager.getSimNodeStateProvider().simGetAllNodeValues()\n          .computeIfAbsent(nodeId, id -> new ConcurrentHashMap<>(SimCloudManager.createNodeValues(id)));\n      // update the number of cores and freedisk in node values\n      Number cores = (Number)values.get(ImplicitSnitch.CORES);\n      if (cores == null) {\n        cores = 0;\n      }\n      cloudManager.getSimNodeStateProvider().simSetNodeValue(nodeId, ImplicitSnitch.CORES, cores.intValue() + 1);\n      Number disk = (Number)values.get(ImplicitSnitch.DISK);\n      if (disk == null) {\n        throw new Exception(\"Missing '\" + ImplicitSnitch.DISK + \"' in node metrics for node \" + nodeId);\n        //disk = SimCloudManager.DEFAULT_FREE_DISK;\n      }\n      long replicaSize = ((Number)replicaInfo.getVariable(Type.CORE_IDX.metricsAttribute)).longValue();\n      Number replicaSizeGB = (Number)Type.CORE_IDX.convertVal(replicaSize);\n      cloudManager.getSimNodeStateProvider().simSetNodeValue(nodeId, ImplicitSnitch.DISK, disk.doubleValue() - replicaSizeGB.doubleValue());\n      // fake metrics\n      String registry = SolrMetricManager.getRegistryName(SolrInfoBean.Group.core, replicaInfo.getCollection(),\n          replicaInfo.getShard(),\n          Utils.parseMetricsReplicaName(replicaInfo.getCollection(), replicaInfo.getCore()));\n      cloudManager.getMetricManager().registry(registry).counter(\"UPDATE./update.requests\");\n      cloudManager.getMetricManager().registry(registry).counter(\"QUERY./select.requests\");\n      cloudManager.getMetricManager().registerGauge(null, registry,\n          () -> replicaSize, \"\", true, Type.CORE_IDX.metricsAttribute);\n      // at this point nuke our cached DocCollection state\n      collectionsStatesRef.get(replicaInfo.getCollection()).invalidate();\n      log.trace(\"-- simAddReplica {}\", replicaInfo);\n      if (runLeaderElection) {\n        simRunLeaderElection(replicaInfo.getCollection(), replicaInfo.getShard(), true);\n      }\n    } finally {\n      lock.unlock();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7e8ce2f9d2ddfcf5cfa7e73b8b2af287a2a276fd","date":1594731683,"type":5,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simAddReplica(String,Replica,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simAddReplica(String,ReplicaInfo,boolean).mjava","sourceNew":"  /**\n   * Add a replica. Note that all details of the replica must be present here, including\n   * node, coreNodeName and SolrCore name.\n   * @param nodeId node id where the replica will be added\n   * @param replicaInfo replica info\n   * @param runLeaderElection if true then run a leader election after adding the replica.\n   */\n  @SuppressWarnings({\"unchecked\"})\n  public void simAddReplica(String nodeId, Replica replicaInfo, boolean runLeaderElection) throws Exception {\n    ensureNotClosed();\n    lock.lockInterruptibly();\n    try {\n\n      // make sure SolrCore name is unique across cluster and coreNodeName within collection\n      for (Map.Entry<String, List<Replica>> e : nodeReplicaMap.entrySet()) {\n        final List<Replica> replicas = e.getValue();\n        synchronized (replicas) {\n          for (Replica ri : replicas) {\n            if (ri.getCoreName().equals(replicaInfo.getCoreName())) {\n              throw new Exception(\"Duplicate SolrCore name for existing=\" + ri + \" on node \" + e.getKey() + \" and new=\" + replicaInfo);\n            }\n            if (ri.getName().equals(replicaInfo.getName()) && ri.getCollection().equals(replicaInfo.getCollection())) {\n              throw new Exception(\"Duplicate coreNode name for existing=\" + ri + \" on node \" + e.getKey() + \" and new=\" + replicaInfo);\n            }\n          }\n        }\n      }\n      if (!liveNodes.contains(nodeId)) {\n        throw new Exception(\"Target node \" + nodeId + \" is not live: \" + liveNodes);\n      }\n      // verify info\n      if (replicaInfo.getCoreName() == null) {\n        throw new Exception(\"Missing core: \" + replicaInfo);\n      }\n      // XXX replica info is not supposed to have this as a variable\n      replicaInfo.getProperties().remove(ZkStateReader.SHARD_ID_PROP);\n      if (replicaInfo.getName() == null) {\n        throw new Exception(\"Missing name: \" + replicaInfo);\n      }\n      if (replicaInfo.getNodeName() == null) {\n        throw new Exception(\"Missing node: \" + replicaInfo);\n      }\n      if (!replicaInfo.getNodeName().equals(nodeId)) {\n        throw new Exception(\"Wrong node (not \" + nodeId + \"): \" + replicaInfo);\n      }\n      \n      opDelay(replicaInfo.getCollection(), CollectionParams.CollectionAction.ADDREPLICA.name());\n\n      // mark replica as active\n      replicaInfo.setState(Replica.State.ACTIVE);\n      // add a property expected in Policy calculations, if missing\n      if (replicaInfo.get(Type.CORE_IDX.metricsAttribute) == null) {\n        replicaInfo.getProperties().put(Type.CORE_IDX.metricsAttribute, new AtomicLong(SimCloudManager.DEFAULT_IDX_SIZE_BYTES));\n        replicaInfo.getProperties().put(Variable.coreidxsize,\n            new AtomicDouble((Double)Type.CORE_IDX.convertVal(SimCloudManager.DEFAULT_IDX_SIZE_BYTES)));\n      }\n      nodeReplicaMap.computeIfAbsent(nodeId, Utils.NEW_SYNCHRONIZED_ARRAYLIST_FUN).add(replicaInfo);\n      colShardReplicaMap.computeIfAbsent(replicaInfo.getCollection(), c -> new ConcurrentHashMap<>())\n          .computeIfAbsent(replicaInfo.getShard(), s -> new ArrayList<>())\n          .add(replicaInfo);\n\n      Map<String, Object> values = cloudManager.getSimNodeStateProvider().simGetAllNodeValues()\n          .computeIfAbsent(nodeId, id -> new ConcurrentHashMap<>(SimCloudManager.createNodeValues(id)));\n      // update the number of cores and freedisk in node values\n      Number cores = (Number)values.get(ImplicitSnitch.CORES);\n      if (cores == null) {\n        cores = 0;\n      }\n      cloudManager.getSimNodeStateProvider().simSetNodeValue(nodeId, ImplicitSnitch.CORES, cores.intValue() + 1);\n      Number disk = (Number)values.get(ImplicitSnitch.DISK);\n      if (disk == null) {\n        throw new Exception(\"Missing '\" + ImplicitSnitch.DISK + \"' in node metrics for node \" + nodeId);\n        //disk = SimCloudManager.DEFAULT_FREE_DISK;\n      }\n      long replicaSize = ((Number)replicaInfo.get(Type.CORE_IDX.metricsAttribute)).longValue();\n      Number replicaSizeGB = (Number)Type.CORE_IDX.convertVal(replicaSize);\n      cloudManager.getSimNodeStateProvider().simSetNodeValue(nodeId, ImplicitSnitch.DISK, disk.doubleValue() - replicaSizeGB.doubleValue());\n      // fake metrics\n      String registry = SolrMetricManager.getRegistryName(SolrInfoBean.Group.core, replicaInfo.getCollection(),\n          replicaInfo.getShard(),\n          Utils.parseMetricsReplicaName(replicaInfo.getCollection(), replicaInfo.getCoreName()));\n      cloudManager.getMetricManager().registry(registry).counter(\"UPDATE./update.requests\");\n      cloudManager.getMetricManager().registry(registry).counter(\"QUERY./select.requests\");\n      cloudManager.getMetricManager().registerGauge(null, registry,\n          () -> replicaSize, \"\", true, Type.CORE_IDX.metricsAttribute);\n      // at this point nuke our cached DocCollection state\n      collectionsStatesRef.get(replicaInfo.getCollection()).invalidate();\n      log.trace(\"-- simAddReplica {}\", replicaInfo);\n      if (runLeaderElection) {\n        simRunLeaderElection(replicaInfo.getCollection(), replicaInfo.getShard(), true);\n      }\n    } finally {\n      lock.unlock();\n    }\n  }\n\n","sourceOld":"  /**\n   * Add a replica. Note that all details of the replica must be present here, including\n   * node, coreNodeName and SolrCore name.\n   * @param nodeId node id where the replica will be added\n   * @param replicaInfo replica info\n   * @param runLeaderElection if true then run a leader election after adding the replica.\n   */\n  @SuppressWarnings({\"unchecked\"})\n  public void simAddReplica(String nodeId, ReplicaInfo replicaInfo, boolean runLeaderElection) throws Exception {\n    ensureNotClosed();\n    lock.lockInterruptibly();\n    try {\n\n      // make sure SolrCore name is unique across cluster and coreNodeName within collection\n      for (Map.Entry<String, List<ReplicaInfo>> e : nodeReplicaMap.entrySet()) {\n        final List<ReplicaInfo> replicas = e.getValue();\n        synchronized (replicas) {\n          for (ReplicaInfo ri : replicas) {\n            if (ri.getCore().equals(replicaInfo.getCore())) {\n              throw new Exception(\"Duplicate SolrCore name for existing=\" + ri + \" on node \" + e.getKey() + \" and new=\" + replicaInfo);\n            }\n            if (ri.getName().equals(replicaInfo.getName()) && ri.getCollection().equals(replicaInfo.getCollection())) {\n              throw new Exception(\"Duplicate coreNode name for existing=\" + ri + \" on node \" + e.getKey() + \" and new=\" + replicaInfo);\n            }\n          }\n        }\n      }\n      if (!liveNodes.contains(nodeId)) {\n        throw new Exception(\"Target node \" + nodeId + \" is not live: \" + liveNodes);\n      }\n      // verify info\n      if (replicaInfo.getCore() == null) {\n        throw new Exception(\"Missing core: \" + replicaInfo);\n      }\n      // XXX replica info is not supposed to have this as a variable\n      replicaInfo.getVariables().remove(ZkStateReader.SHARD_ID_PROP);\n      if (replicaInfo.getName() == null) {\n        throw new Exception(\"Missing name: \" + replicaInfo);\n      }\n      if (replicaInfo.getNode() == null) {\n        throw new Exception(\"Missing node: \" + replicaInfo);\n      }\n      if (!replicaInfo.getNode().equals(nodeId)) {\n        throw new Exception(\"Wrong node (not \" + nodeId + \"): \" + replicaInfo);\n      }\n      \n      opDelay(replicaInfo.getCollection(), CollectionParams.CollectionAction.ADDREPLICA.name());\n\n      // mark replica as active\n      replicaInfo.getVariables().put(ZkStateReader.STATE_PROP, Replica.State.ACTIVE.toString());\n      // add a property expected in Policy calculations, if missing\n      if (replicaInfo.getVariable(Type.CORE_IDX.metricsAttribute) == null) {\n        replicaInfo.getVariables().put(Type.CORE_IDX.metricsAttribute, new AtomicLong(SimCloudManager.DEFAULT_IDX_SIZE_BYTES));\n        replicaInfo.getVariables().put(Variable.coreidxsize,\n            new AtomicDouble((Double)Type.CORE_IDX.convertVal(SimCloudManager.DEFAULT_IDX_SIZE_BYTES)));\n      }\n      nodeReplicaMap.computeIfAbsent(nodeId, Utils.NEW_SYNCHRONIZED_ARRAYLIST_FUN).add(replicaInfo);\n      colShardReplicaMap.computeIfAbsent(replicaInfo.getCollection(), c -> new ConcurrentHashMap<>())\n          .computeIfAbsent(replicaInfo.getShard(), s -> new ArrayList<>())\n          .add(replicaInfo);\n\n      Map<String, Object> values = cloudManager.getSimNodeStateProvider().simGetAllNodeValues()\n          .computeIfAbsent(nodeId, id -> new ConcurrentHashMap<>(SimCloudManager.createNodeValues(id)));\n      // update the number of cores and freedisk in node values\n      Number cores = (Number)values.get(ImplicitSnitch.CORES);\n      if (cores == null) {\n        cores = 0;\n      }\n      cloudManager.getSimNodeStateProvider().simSetNodeValue(nodeId, ImplicitSnitch.CORES, cores.intValue() + 1);\n      Number disk = (Number)values.get(ImplicitSnitch.DISK);\n      if (disk == null) {\n        throw new Exception(\"Missing '\" + ImplicitSnitch.DISK + \"' in node metrics for node \" + nodeId);\n        //disk = SimCloudManager.DEFAULT_FREE_DISK;\n      }\n      long replicaSize = ((Number)replicaInfo.getVariable(Type.CORE_IDX.metricsAttribute)).longValue();\n      Number replicaSizeGB = (Number)Type.CORE_IDX.convertVal(replicaSize);\n      cloudManager.getSimNodeStateProvider().simSetNodeValue(nodeId, ImplicitSnitch.DISK, disk.doubleValue() - replicaSizeGB.doubleValue());\n      // fake metrics\n      String registry = SolrMetricManager.getRegistryName(SolrInfoBean.Group.core, replicaInfo.getCollection(),\n          replicaInfo.getShard(),\n          Utils.parseMetricsReplicaName(replicaInfo.getCollection(), replicaInfo.getCore()));\n      cloudManager.getMetricManager().registry(registry).counter(\"UPDATE./update.requests\");\n      cloudManager.getMetricManager().registry(registry).counter(\"QUERY./select.requests\");\n      cloudManager.getMetricManager().registerGauge(null, registry,\n          () -> replicaSize, \"\", true, Type.CORE_IDX.metricsAttribute);\n      // at this point nuke our cached DocCollection state\n      collectionsStatesRef.get(replicaInfo.getCollection()).invalidate();\n      log.trace(\"-- simAddReplica {}\", replicaInfo);\n      if (runLeaderElection) {\n        simRunLeaderElection(replicaInfo.getCollection(), replicaInfo.getShard(), true);\n      }\n    } finally {\n      lock.unlock();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"7e8ce2f9d2ddfcf5cfa7e73b8b2af287a2a276fd":["daa0f21a44e235a2299ea1fa913898b182dd7cce"],"daa0f21a44e235a2299ea1fa913898b182dd7cce":["eb7a329be123e1f46f9d78d74f6d23f33ec81b0a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"eb7a329be123e1f46f9d78d74f6d23f33ec81b0a":["edf5b262a72d10530eb2f01dc8f19060355b213e"],"edf5b262a72d10530eb2f01dc8f19060355b213e":["9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5"],"9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["7e8ce2f9d2ddfcf5cfa7e73b8b2af287a2a276fd"]},"commit2Childs":{"7e8ce2f9d2ddfcf5cfa7e73b8b2af287a2a276fd":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"daa0f21a44e235a2299ea1fa913898b182dd7cce":["7e8ce2f9d2ddfcf5cfa7e73b8b2af287a2a276fd"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5"],"eb7a329be123e1f46f9d78d74f6d23f33ec81b0a":["daa0f21a44e235a2299ea1fa913898b182dd7cce"],"edf5b262a72d10530eb2f01dc8f19060355b213e":["eb7a329be123e1f46f9d78d74f6d23f33ec81b0a"],"9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5":["edf5b262a72d10530eb2f01dc8f19060355b213e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}