{"path":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher,boolean).mjava","commits":[{"id":"fb17639909a369c1e64866842e5c213440acc17e","date":1423238093,"type":1,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher).mjava","sourceNew":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher, boolean needsScores) throws IOException {\n    final Weight weight = query.createWeight (searcher, needsScores);\n    return new Weight(FilteredQuery.this) {\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSetIterator.empty() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSetIterator.empty();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          Explanation result = new Explanation\n            (0.0f, \"failure to match filter: \" + f.toString());\n          result.addDetail(inner);\n          return result;\n        }\n      }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredScorer(context, weight, filterDocIdSet);\n      }\n\n      // return a filtering top scorer\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredBulkScorer(context, weight, filterDocIdSet, needsScores);\n\n      }\n    };\n  }\n\n","sourceOld":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher) throws IOException {\n    final Weight weight = query.createWeight (searcher);\n    return new Weight() {\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSetIterator.empty() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSetIterator.empty();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          Explanation result = new Explanation\n            (0.0f, \"failure to match filter: \" + f.toString());\n          result.addDetail(inner);\n          return result;\n        }\n      }\n\n      // return this query\n      @Override\n      public Query getQuery() {\n        return FilteredQuery.this;\n      }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs, boolean needsScores) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredScorer(context, weight, filterDocIdSet, needsScores);\n      }\n\n      // return a filtering top scorer\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context, Bits acceptDocs, boolean needsScores) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredBulkScorer(context, weight, filterDocIdSet, needsScores);\n\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ed5ee3fe575910625535c3ecfeb2c055f2c95738","date":1423238579,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher,boolean).mjava","sourceNew":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher, boolean needsScores) throws IOException {\n    final Weight weight = query.createWeight (searcher, needsScores);\n    return new Weight(FilteredQuery.this) {\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSetIterator.empty() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSetIterator.empty();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          Explanation result = new Explanation\n            (0.0f, \"failure to match filter: \" + f.toString());\n          result.addDetail(inner);\n          return result;\n        }\n      }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredScorer(context, weight, filterDocIdSet);\n      }\n\n      // return a filtering top scorer\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredBulkScorer(context, weight, filterDocIdSet);\n\n      }\n    };\n  }\n\n","sourceOld":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher, boolean needsScores) throws IOException {\n    final Weight weight = query.createWeight (searcher, needsScores);\n    return new Weight(FilteredQuery.this) {\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSetIterator.empty() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSetIterator.empty();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          Explanation result = new Explanation\n            (0.0f, \"failure to match filter: \" + f.toString());\n          result.addDetail(inner);\n          return result;\n        }\n      }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredScorer(context, weight, filterDocIdSet);\n      }\n\n      // return a filtering top scorer\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredBulkScorer(context, weight, filterDocIdSet, needsScores);\n\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"954e59be3da8dc1b046646ad7af4b466852009d3","date":1423482367,"type":5,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher,boolean).mjava","sourceNew":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher, int postingsFlags) throws IOException {\n    final Weight weight = query.createWeight (searcher, postingsFlags);\n    return new Weight(FilteredQuery.this) {\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSetIterator.empty() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSetIterator.empty();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          Explanation result = new Explanation\n            (0.0f, \"failure to match filter: \" + f.toString());\n          result.addDetail(inner);\n          return result;\n        }\n      }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredScorer(context, weight, filterDocIdSet);\n      }\n\n      // return a filtering top scorer\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredBulkScorer(context, weight, filterDocIdSet);\n\n      }\n    };\n  }\n\n","sourceOld":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher, boolean needsScores) throws IOException {\n    final Weight weight = query.createWeight (searcher, needsScores);\n    return new Weight(FilteredQuery.this) {\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSetIterator.empty() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSetIterator.empty();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          Explanation result = new Explanation\n            (0.0f, \"failure to match filter: \" + f.toString());\n          result.addDetail(inner);\n          return result;\n        }\n      }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredScorer(context, weight, filterDocIdSet);\n      }\n\n      // return a filtering top scorer\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredBulkScorer(context, weight, filterDocIdSet);\n\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6a47d642ab24da1a811adce4bda9cc52c520ca13","date":1423483323,"type":1,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher,int).mjava","sourceNew":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher, boolean needsScores) throws IOException {\n    final Weight weight = query.createWeight (searcher, needsScores);\n    return new Weight(FilteredQuery.this) {\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSetIterator.empty() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSetIterator.empty();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          Explanation result = new Explanation\n            (0.0f, \"failure to match filter: \" + f.toString());\n          result.addDetail(inner);\n          return result;\n        }\n      }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredScorer(context, weight, filterDocIdSet);\n      }\n\n      // return a filtering top scorer\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredBulkScorer(context, weight, filterDocIdSet);\n\n      }\n    };\n  }\n\n","sourceOld":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher, int postingsFlags) throws IOException {\n    final Weight weight = query.createWeight (searcher, postingsFlags);\n    return new Weight(FilteredQuery.this) {\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSetIterator.empty() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSetIterator.empty();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          Explanation result = new Explanation\n            (0.0f, \"failure to match filter: \" + f.toString());\n          result.addDetail(inner);\n          return result;\n        }\n      }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredScorer(context, weight, filterDocIdSet);\n      }\n\n      // return a filtering top scorer\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredBulkScorer(context, weight, filterDocIdSet);\n\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"05c52ac194342b760b830342ee8423fcf00e54d0","date":1429197275,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher,boolean).mjava","sourceNew":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher, boolean needsScores) throws IOException {\n    final Weight weight = query.createWeight (searcher, needsScores);\n    return new Weight(FilteredQuery.this) {\n\n      @Override\n      public void extractTerms(Set<Term> terms) {\n        weight.extractTerms(terms);\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSetIterator.empty() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSetIterator.empty();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          Explanation result = new Explanation\n            (0.0f, \"failure to match filter: \" + f.toString());\n          result.addDetail(inner);\n          return result;\n        }\n      }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredScorer(context, weight, filterDocIdSet);\n      }\n\n      // return a filtering top scorer\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredBulkScorer(context, weight, filterDocIdSet);\n\n      }\n    };\n  }\n\n","sourceOld":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher, boolean needsScores) throws IOException {\n    final Weight weight = query.createWeight (searcher, needsScores);\n    return new Weight(FilteredQuery.this) {\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSetIterator.empty() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSetIterator.empty();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          Explanation result = new Explanation\n            (0.0f, \"failure to match filter: \" + f.toString());\n          result.addDetail(inner);\n          return result;\n        }\n      }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredScorer(context, weight, filterDocIdSet);\n      }\n\n      // return a filtering top scorer\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredBulkScorer(context, weight, filterDocIdSet);\n\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ff3285c7b2387faedef0ffb24db20c4cbbd9fd91","date":1429620941,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher,boolean).mjava","sourceNew":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher, boolean needsScores) throws IOException {\n    final Weight weight = query.createWeight (searcher, needsScores);\n    return new Weight(FilteredQuery.this) {\n\n      @Override\n      public void extractTerms(Set<Term> terms) {\n        weight.extractTerms(terms);\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSetIterator.empty() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSetIterator.empty();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          return Explanation.noMatch(\"failure to match filter: \" + f.toString(), inner);\n        }\n      }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredScorer(context, weight, filterDocIdSet);\n      }\n\n      // return a filtering top scorer\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredBulkScorer(context, weight, filterDocIdSet);\n\n      }\n    };\n  }\n\n","sourceOld":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher, boolean needsScores) throws IOException {\n    final Weight weight = query.createWeight (searcher, needsScores);\n    return new Weight(FilteredQuery.this) {\n\n      @Override\n      public void extractTerms(Set<Term> terms) {\n        weight.extractTerms(terms);\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSetIterator.empty() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSetIterator.empty();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          Explanation result = new Explanation\n            (0.0f, \"failure to match filter: \" + f.toString());\n          result.addDetail(inner);\n          return result;\n        }\n      }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredScorer(context, weight, filterDocIdSet);\n      }\n\n      // return a filtering top scorer\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredBulkScorer(context, weight, filterDocIdSet);\n\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1db68e96dd908fcd79ef809095822736aa601d08","date":1434630596,"type":4,"author":"Adrien Grand","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher,boolean).mjava","sourceNew":null,"sourceOld":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher, boolean needsScores) throws IOException {\n    final Weight weight = query.createWeight (searcher, needsScores);\n    return new Weight(FilteredQuery.this) {\n\n      @Override\n      public void extractTerms(Set<Term> terms) {\n        weight.extractTerms(terms);\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSetIterator.empty() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSetIterator.empty();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          return Explanation.noMatch(\"failure to match filter: \" + f.toString(), inner);\n        }\n      }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredScorer(context, weight, filterDocIdSet);\n      }\n\n      // return a filtering top scorer\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredBulkScorer(context, weight, filterDocIdSet);\n\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"6a47d642ab24da1a811adce4bda9cc52c520ca13":["954e59be3da8dc1b046646ad7af4b466852009d3"],"fb17639909a369c1e64866842e5c213440acc17e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"1db68e96dd908fcd79ef809095822736aa601d08":["ff3285c7b2387faedef0ffb24db20c4cbbd9fd91"],"ed5ee3fe575910625535c3ecfeb2c055f2c95738":["fb17639909a369c1e64866842e5c213440acc17e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"ff3285c7b2387faedef0ffb24db20c4cbbd9fd91":["05c52ac194342b760b830342ee8423fcf00e54d0"],"05c52ac194342b760b830342ee8423fcf00e54d0":["6a47d642ab24da1a811adce4bda9cc52c520ca13"],"954e59be3da8dc1b046646ad7af4b466852009d3":["ed5ee3fe575910625535c3ecfeb2c055f2c95738"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["1db68e96dd908fcd79ef809095822736aa601d08"]},"commit2Childs":{"6a47d642ab24da1a811adce4bda9cc52c520ca13":["05c52ac194342b760b830342ee8423fcf00e54d0"],"fb17639909a369c1e64866842e5c213440acc17e":["ed5ee3fe575910625535c3ecfeb2c055f2c95738"],"1db68e96dd908fcd79ef809095822736aa601d08":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["fb17639909a369c1e64866842e5c213440acc17e"],"ed5ee3fe575910625535c3ecfeb2c055f2c95738":["954e59be3da8dc1b046646ad7af4b466852009d3"],"ff3285c7b2387faedef0ffb24db20c4cbbd9fd91":["1db68e96dd908fcd79ef809095822736aa601d08"],"954e59be3da8dc1b046646ad7af4b466852009d3":["6a47d642ab24da1a811adce4bda9cc52c520ca13"],"05c52ac194342b760b830342ee8423fcf00e54d0":["ff3285c7b2387faedef0ffb24db20c4cbbd9fd91"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}