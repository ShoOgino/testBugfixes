{"path":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","commits":[{"id":"f8bf47b67b38083a0c4d9d2e3f53b59a48e8db34","date":1309197122,"type":0,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","pathOld":"/dev/null","sourceNew":"  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries==null || queries.size()==0) {\n      if (setFilter != null)\n        pf.filter = setFilter.getTopFilter();\n      return pf;\n    }\n\n    DocSet answer=null;\n\n    boolean[] neg = new boolean[queries.size()+1];\n    DocSet[] sets = new DocSet[queries.size()+1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    }\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery)q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<Query>(sets.length-end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<Query>(sets.length-end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q==posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz<smallestCount) {\n          smallestCount=sz;\n          smallestIndex=end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer==null) {\n      answer = getPositiveDocSet(matchAllDocsQuery);\n    }\n\n    // do negative queries first to shrink set size\n    for (int i=0; i<end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i=0; i<end; i++) {\n      if (!neg[i] && i!=smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    if (notCached != null) {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<Weight>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createNormalizedWeight(qq));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n    } else {\n      if (postFilters == null) {\n        if (answer == null) {\n          answer = getPositiveDocSet(matchAllDocsQuery);\n        }\n        // \"answer\" is the only part of the filter, so set it.\n        pf.answer = answer;\n      }\n\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    }\n\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i=postFilters.size()-1; i>=0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter)postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2553b00f699380c64959ccb27991289aae87be2e","date":1309290151,"type":0,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","pathOld":"/dev/null","sourceNew":"  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries==null || queries.size()==0) {\n      if (setFilter != null)\n        pf.filter = setFilter.getTopFilter();\n      return pf;\n    }\n\n    DocSet answer=null;\n\n    boolean[] neg = new boolean[queries.size()+1];\n    DocSet[] sets = new DocSet[queries.size()+1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    }\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery)q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<Query>(sets.length-end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<Query>(sets.length-end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q==posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz<smallestCount) {\n          smallestCount=sz;\n          smallestIndex=end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer==null) {\n      answer = getPositiveDocSet(matchAllDocsQuery);\n    }\n\n    // do negative queries first to shrink set size\n    for (int i=0; i<end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i=0; i<end; i++) {\n      if (!neg[i] && i!=smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    if (notCached != null) {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<Weight>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createNormalizedWeight(qq));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n    } else {\n      if (postFilters == null) {\n        if (answer == null) {\n          answer = getPositiveDocSet(matchAllDocsQuery);\n        }\n        // \"answer\" is the only part of the filter, so set it.\n        pf.answer = answer;\n      }\n\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    }\n\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i=postFilters.size()-1; i>=0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter)postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d083e83f225b11e5fdd900e83d26ddb385b6955c","date":1310029438,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","pathOld":"/dev/null","sourceNew":"  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries==null || queries.size()==0) {\n      if (setFilter != null)\n        pf.filter = setFilter.getTopFilter();\n      return pf;\n    }\n\n    DocSet answer=null;\n\n    boolean[] neg = new boolean[queries.size()+1];\n    DocSet[] sets = new DocSet[queries.size()+1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    }\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery)q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<Query>(sets.length-end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<Query>(sets.length-end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q==posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz<smallestCount) {\n          smallestCount=sz;\n          smallestIndex=end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer==null) {\n      answer = getPositiveDocSet(matchAllDocsQuery);\n    }\n\n    // do negative queries first to shrink set size\n    for (int i=0; i<end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i=0; i<end; i++) {\n      if (!neg[i] && i!=smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    if (notCached != null) {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<Weight>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createNormalizedWeight(qq));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n    } else {\n      if (postFilters == null) {\n        if (answer == null) {\n          answer = getPositiveDocSet(matchAllDocsQuery);\n        }\n        // \"answer\" is the only part of the filter, so set it.\n        pf.answer = answer;\n      }\n\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    }\n\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i=postFilters.size()-1; i>=0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter)postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c903c3d15906a3da96b8c0c2fb704491005fdbdb","date":1453508227,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","sourceNew":"  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries==null || queries.size()==0) {\n      if (setFilter != null)\n        pf.filter = setFilter.getTopFilter();\n      return pf;\n    }\n\n    DocSet answer=null;\n\n    boolean[] neg = new boolean[queries.size()+1];\n    DocSet[] sets = new DocSet[queries.size()+1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    }\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery)q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<Query>(sets.length-end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<Query>(sets.length-end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q==posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz<smallestCount) {\n          smallestCount=sz;\n          smallestIndex=end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer==null) {\n      answer = getPositiveDocSet(matchAllDocsQuery);\n    }\n\n    // do negative queries first to shrink set size\n    for (int i=0; i<end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i=0; i<end; i++) {\n      if (!neg[i] && i!=smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    if (notCached != null) {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<Weight>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createNormalizedWeight(qq));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n    } else {\n      if (postFilters == null) {\n        if (answer == null) {\n          answer = getPositiveDocSet(matchAllDocsQuery);\n        }\n        // \"answer\" is the only part of the filter, so set it.\n        pf.answer = answer;\n      }\n\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    }\n\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i=postFilters.size()-1; i>=0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter)postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","sourceOld":"  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries==null || queries.size()==0) {\n      if (setFilter != null)\n        pf.filter = setFilter.getTopFilter();\n      return pf;\n    }\n\n    DocSet answer=null;\n\n    boolean[] neg = new boolean[queries.size()+1];\n    DocSet[] sets = new DocSet[queries.size()+1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    }\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery)q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<Query>(sets.length-end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<Query>(sets.length-end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q==posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz<smallestCount) {\n          smallestCount=sz;\n          smallestIndex=end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer==null) {\n      answer = getPositiveDocSet(matchAllDocsQuery);\n    }\n\n    // do negative queries first to shrink set size\n    for (int i=0; i<end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i=0; i<end; i++) {\n      if (!neg[i] && i!=smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    if (notCached != null) {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<Weight>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createNormalizedWeight(qq));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n    } else {\n      if (postFilters == null) {\n        if (answer == null) {\n          answer = getPositiveDocSet(matchAllDocsQuery);\n        }\n        // \"answer\" is the only part of the filter, so set it.\n        pf.answer = answer;\n      }\n\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    }\n\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i=postFilters.size()-1; i>=0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter)postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a258fbb26824fd104ed795e5d9033d2d040049ee","date":1453508252,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","sourceNew":"  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries==null || queries.size()==0) {\n      if (setFilter != null)\n        pf.filter = setFilter.getTopFilter();\n      return pf;\n    }\n\n    DocSet answer=null;\n\n    boolean[] neg = new boolean[queries.size()+1];\n    DocSet[] sets = new DocSet[queries.size()+1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    }\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery)q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<Query>(sets.length-end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<Query>(sets.length-end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q==posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz<smallestCount) {\n          smallestCount=sz;\n          smallestIndex=end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer==null) {\n      answer = getPositiveDocSet(matchAllDocsQuery);\n    }\n\n    // do negative queries first to shrink set size\n    for (int i=0; i<end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i=0; i<end; i++) {\n      if (!neg[i] && i!=smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    if (notCached != null) {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<Weight>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createNormalizedWeight(qq));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n    } else {\n      if (postFilters == null) {\n        if (answer == null) {\n          answer = getPositiveDocSet(matchAllDocsQuery);\n        }\n        // \"answer\" is the only part of the filter, so set it.\n        pf.answer = answer;\n      }\n\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    }\n\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i=postFilters.size()-1; i>=0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter)postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","sourceOld":"  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries==null || queries.size()==0) {\n      if (setFilter != null)\n        pf.filter = setFilter.getTopFilter();\n      return pf;\n    }\n\n    DocSet answer=null;\n\n    boolean[] neg = new boolean[queries.size()+1];\n    DocSet[] sets = new DocSet[queries.size()+1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    }\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery)q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<Query>(sets.length-end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<Query>(sets.length-end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q==posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz<smallestCount) {\n          smallestCount=sz;\n          smallestIndex=end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer==null) {\n      answer = getPositiveDocSet(matchAllDocsQuery);\n    }\n\n    // do negative queries first to shrink set size\n    for (int i=0; i<end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i=0; i<end; i++) {\n      if (!neg[i] && i!=smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    if (notCached != null) {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<Weight>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createNormalizedWeight(qq));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n    } else {\n      if (postFilters == null) {\n        if (answer == null) {\n          answer = getPositiveDocSet(matchAllDocsQuery);\n        }\n        // \"answer\" is the only part of the filter, so set it.\n        pf.answer = answer;\n      }\n\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    }\n\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i=postFilters.size()-1; i>=0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter)postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":5,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","sourceNew":"  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries==null || queries.size()==0) {\n      if (setFilter != null)\n        pf.filter = setFilter.getTopFilter();\n      return pf;\n    }\n\n    DocSet answer=null;\n\n    boolean[] neg = new boolean[queries.size()+1];\n    DocSet[] sets = new DocSet[queries.size()+1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    }\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery)q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<Query>(sets.length-end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<Query>(sets.length-end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q==posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz<smallestCount) {\n          smallestCount=sz;\n          smallestIndex=end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer==null) {\n      answer = getPositiveDocSet(matchAllDocsQuery);\n    }\n\n    // do negative queries first to shrink set size\n    for (int i=0; i<end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i=0; i<end; i++) {\n      if (!neg[i] && i!=smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    if (notCached != null) {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<Weight>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createNormalizedWeight(qq));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n    } else {\n      if (postFilters == null) {\n        if (answer == null) {\n          answer = getPositiveDocSet(matchAllDocsQuery);\n        }\n        // \"answer\" is the only part of the filter, so set it.\n        pf.answer = answer;\n      }\n\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    }\n\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i=postFilters.size()-1; i>=0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter)postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","sourceOld":"  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries==null || queries.size()==0) {\n      if (setFilter != null)\n        pf.filter = setFilter.getTopFilter();\n      return pf;\n    }\n\n    DocSet answer=null;\n\n    boolean[] neg = new boolean[queries.size()+1];\n    DocSet[] sets = new DocSet[queries.size()+1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    }\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery)q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<Query>(sets.length-end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<Query>(sets.length-end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q==posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz<smallestCount) {\n          smallestCount=sz;\n          smallestIndex=end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer==null) {\n      answer = getPositiveDocSet(matchAllDocsQuery);\n    }\n\n    // do negative queries first to shrink set size\n    for (int i=0; i<end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i=0; i<end; i++) {\n      if (!neg[i] && i!=smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    if (notCached != null) {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<Weight>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createNormalizedWeight(qq));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n    } else {\n      if (postFilters == null) {\n        if (answer == null) {\n          answer = getPositiveDocSet(matchAllDocsQuery);\n        }\n        // \"answer\" is the only part of the filter, so set it.\n        pf.answer = answer;\n      }\n\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    }\n\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i=postFilters.size()-1; i>=0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter)postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["2553b00f699380c64959ccb27991289aae87be2e"],"c26f00b574427b55127e869b935845554afde1fa":["f8bf47b67b38083a0c4d9d2e3f53b59a48e8db34","c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a258fbb26824fd104ed795e5d9033d2d040049ee":["f8bf47b67b38083a0c4d9d2e3f53b59a48e8db34"],"f8bf47b67b38083a0c4d9d2e3f53b59a48e8db34":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"2553b00f699380c64959ccb27991289aae87be2e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","f8bf47b67b38083a0c4d9d2e3f53b59a48e8db34"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","f8bf47b67b38083a0c4d9d2e3f53b59a48e8db34"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c26f00b574427b55127e869b935845554afde1fa"]},"commit2Childs":{"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["c26f00b574427b55127e869b935845554afde1fa"],"c26f00b574427b55127e869b935845554afde1fa":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["f8bf47b67b38083a0c4d9d2e3f53b59a48e8db34","2553b00f699380c64959ccb27991289aae87be2e","d083e83f225b11e5fdd900e83d26ddb385b6955c"],"a258fbb26824fd104ed795e5d9033d2d040049ee":[],"2553b00f699380c64959ccb27991289aae87be2e":["c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"f8bf47b67b38083a0c4d9d2e3f53b59a48e8db34":["c26f00b574427b55127e869b935845554afde1fa","a258fbb26824fd104ed795e5d9033d2d040049ee","2553b00f699380c64959ccb27991289aae87be2e","d083e83f225b11e5fdd900e83d26ddb385b6955c"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a258fbb26824fd104ed795e5d9033d2d040049ee","d083e83f225b11e5fdd900e83d26ddb385b6955c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}