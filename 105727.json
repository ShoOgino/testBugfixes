{"path":"solr/core/src/test/org/apache/solr/cloud/TestStressCloudBlindAtomicUpdates#checkField(String).mjava","commits":[{"id":"106fbee5a2b8105d0628067f2c65cd0fedfc19e7","date":1464121813,"type":0,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestStressCloudBlindAtomicUpdates#checkField(String).mjava","pathOld":"/dev/null","sourceNew":"  public void checkField(final String numericFieldName) throws Exception {\n\n    final CountDownLatch abortLatch = new CountDownLatch(1);\n\n    final int numDocsToCheck = atLeast(37);\n    final int numDocsInIndex = (numDocsToCheck * DOC_ID_INCR);\n    final AtomicLong[] expected = new AtomicLong[numDocsToCheck];\n\n    log.info(\"Testing \" + numericFieldName + \": numDocsToCheck=\" + numDocsToCheck + \", numDocsInIndex=\" + numDocsInIndex + \", incr=\" + DOC_ID_INCR);\n    \n    // seed the index & keep track of what docs exist and with what values\n    for (int id = 0; id < numDocsInIndex; id++) {\n      // NOTE: the field we're mutating is a long, but we seed with a random int,\n      // and we will inc/dec by random smaller ints, to ensure we never over/under flow\n      final int initValue = random().nextInt();\n      SolrInputDocument doc = doc(f(\"id\",\"\"+id), f(numericFieldName, initValue));\n      UpdateResponse rsp = update(doc).process(CLOUD_CLIENT);\n      assertEquals(doc.toString() + \" => \" + rsp.toString(), 0, rsp.getStatus());\n      if (0 == id % DOC_ID_INCR) {\n        expected[(int)(id / DOC_ID_INCR)] = new AtomicLong(initValue);\n      }\n    }\n    assertNotNull(\"Sanity Check no off-by-one in expected init: \", expected[expected.length-1]);\n    \n    \n    // sanity check index contents\n    assertEquals(0, CLOUD_CLIENT.commit().getStatus());\n    assertEquals(numDocsInIndex,\n                 CLOUD_CLIENT.query(params(\"q\", \"*:*\")).getResults().getNumFound());\n\n    // spin up parallel workers to hammer updates\n    List<Future<Worker>> results = new ArrayList<Future<Worker>>(NUM_THREADS);\n    for (int workerId = 0; workerId < NUM_THREADS; workerId++) {\n      Worker worker = new Worker(workerId, expected, abortLatch, new Random(random().nextLong()),\n                                 numericFieldName);\n      // ask for the Worker to be returned in the Future so we can inspect it\n      results.add(EXEC_SERVICE.submit(worker, worker));\n    }\n    // check the results of all our workers\n    for (Future<Worker> r : results) {\n      try {\n        Worker w = r.get();\n        if (! w.getFinishedOk() ) {\n          // quick and dirty sanity check if any workers didn't succeed, but didn't throw an exception either\n          abortLatch.countDown();\n          log.error(\"worker={} didn't finish ok, but didn't throw exception?\", w.workerId);\n        }\n      } catch (ExecutionException ee) {\n        Throwable rootCause = ee.getCause();\n        if (rootCause instanceof Error) {\n          // low level error, or test assertion failure - either way don't leave it wrapped\n          log.error(\"Worker exec Error, throwing root cause\", ee);\n          throw (Error) rootCause;\n        } else { \n          log.error(\"Worker ExecutionException, re-throwing\", ee);\n          throw ee;\n        }\n      }\n    }\n\n    assertEquals(\"Abort latch has changed, why didn't we get an exception from a worker?\",\n                 1L, abortLatch.getCount());\n    \n    TestInjection.reset();\n    waitForRecoveriesToFinish(CLOUD_CLIENT);\n\n    // check all the final index contents match our expectations\n    int incorrectDocs = 0;\n    for (int id = 0; id < numDocsInIndex; id += DOC_ID_INCR) {\n      assert 0 == id % DOC_ID_INCR : \"WTF? \" + id;\n      \n      final long expect = expected[(int)(id / DOC_ID_INCR)].longValue();\n      \n      final String docId = \"\" + id;\n      \n      // sometimes include an fq on the expected value to ensure the updated values\n      // are \"visible\" for searching\n      final SolrParams p = (0 != TestUtil.nextInt(random(), 0,15))\n        ? params() : params(\"fq\",numericFieldName + \":\" + expect);\n      SolrDocument doc = getRandClient(random()).getById(docId, p);\n      \n      final boolean foundWithFilter = (null != doc);\n      if (! foundWithFilter) {\n        // try again w/o fq to see what it does have\n        doc = getRandClient(random()).getById(docId);\n      }\n      \n      Long actual = (null == doc) ? null : (Long) doc.getFirstValue(numericFieldName);\n      if (actual == null || expect != actual.longValue() || ! foundWithFilter) {\n        log.error(\"docId={}, foundWithFilter={}, expected={}, actual={}\",\n                  docId, foundWithFilter, expect, actual);\n        incorrectDocs++;\n      }\n      \n    }\n    assertEquals(\"Some docs had errors -- check logs\", 0, incorrectDocs);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["76b65cf789129cacd84e977b8f1538aec29e0281"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0e121d43b5a10f2df530f406f935102656e9c4e8","date":1464198131,"type":0,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestStressCloudBlindAtomicUpdates#checkField(String).mjava","pathOld":"/dev/null","sourceNew":"  public void checkField(final String numericFieldName) throws Exception {\n\n    final CountDownLatch abortLatch = new CountDownLatch(1);\n\n    final int numDocsToCheck = atLeast(37);\n    final int numDocsInIndex = (numDocsToCheck * DOC_ID_INCR);\n    final AtomicLong[] expected = new AtomicLong[numDocsToCheck];\n\n    log.info(\"Testing \" + numericFieldName + \": numDocsToCheck=\" + numDocsToCheck + \", numDocsInIndex=\" + numDocsInIndex + \", incr=\" + DOC_ID_INCR);\n    \n    // seed the index & keep track of what docs exist and with what values\n    for (int id = 0; id < numDocsInIndex; id++) {\n      // NOTE: the field we're mutating is a long, but we seed with a random int,\n      // and we will inc/dec by random smaller ints, to ensure we never over/under flow\n      final int initValue = random().nextInt();\n      SolrInputDocument doc = doc(f(\"id\",\"\"+id), f(numericFieldName, initValue));\n      UpdateResponse rsp = update(doc).process(CLOUD_CLIENT);\n      assertEquals(doc.toString() + \" => \" + rsp.toString(), 0, rsp.getStatus());\n      if (0 == id % DOC_ID_INCR) {\n        expected[(int)(id / DOC_ID_INCR)] = new AtomicLong(initValue);\n      }\n    }\n    assertNotNull(\"Sanity Check no off-by-one in expected init: \", expected[expected.length-1]);\n    \n    \n    // sanity check index contents\n    assertEquals(0, CLOUD_CLIENT.commit().getStatus());\n    assertEquals(numDocsInIndex,\n                 CLOUD_CLIENT.query(params(\"q\", \"*:*\")).getResults().getNumFound());\n\n    // spin up parallel workers to hammer updates\n    List<Future<Worker>> results = new ArrayList<Future<Worker>>(NUM_THREADS);\n    for (int workerId = 0; workerId < NUM_THREADS; workerId++) {\n      Worker worker = new Worker(workerId, expected, abortLatch, new Random(random().nextLong()),\n                                 numericFieldName);\n      // ask for the Worker to be returned in the Future so we can inspect it\n      results.add(EXEC_SERVICE.submit(worker, worker));\n    }\n    // check the results of all our workers\n    for (Future<Worker> r : results) {\n      try {\n        Worker w = r.get();\n        if (! w.getFinishedOk() ) {\n          // quick and dirty sanity check if any workers didn't succeed, but didn't throw an exception either\n          abortLatch.countDown();\n          log.error(\"worker={} didn't finish ok, but didn't throw exception?\", w.workerId);\n        }\n      } catch (ExecutionException ee) {\n        Throwable rootCause = ee.getCause();\n        if (rootCause instanceof Error) {\n          // low level error, or test assertion failure - either way don't leave it wrapped\n          log.error(\"Worker exec Error, throwing root cause\", ee);\n          throw (Error) rootCause;\n        } else { \n          log.error(\"Worker ExecutionException, re-throwing\", ee);\n          throw ee;\n        }\n      }\n    }\n\n    assertEquals(\"Abort latch has changed, why didn't we get an exception from a worker?\",\n                 1L, abortLatch.getCount());\n    \n    TestInjection.reset();\n    waitForRecoveriesToFinish(CLOUD_CLIENT);\n\n    // check all the final index contents match our expectations\n    int incorrectDocs = 0;\n    for (int id = 0; id < numDocsInIndex; id += DOC_ID_INCR) {\n      assert 0 == id % DOC_ID_INCR : \"WTF? \" + id;\n      \n      final long expect = expected[(int)(id / DOC_ID_INCR)].longValue();\n      \n      final String docId = \"\" + id;\n      \n      // sometimes include an fq on the expected value to ensure the updated values\n      // are \"visible\" for searching\n      final SolrParams p = (0 != TestUtil.nextInt(random(), 0,15))\n        ? params() : params(\"fq\",numericFieldName + \":\" + expect);\n      SolrDocument doc = getRandClient(random()).getById(docId, p);\n      \n      final boolean foundWithFilter = (null != doc);\n      if (! foundWithFilter) {\n        // try again w/o fq to see what it does have\n        doc = getRandClient(random()).getById(docId);\n      }\n      \n      Long actual = (null == doc) ? null : (Long) doc.getFirstValue(numericFieldName);\n      if (actual == null || expect != actual.longValue() || ! foundWithFilter) {\n        log.error(\"docId={}, foundWithFilter={}, expected={}, actual={}\",\n                  docId, foundWithFilter, expect, actual);\n        incorrectDocs++;\n      }\n      \n    }\n    assertEquals(\"Some docs had errors -- check logs\", 0, incorrectDocs);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"83870855d82aba6819217abeff5a40779dbb28b4","date":1464291012,"type":0,"author":"Mike McCandless","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestStressCloudBlindAtomicUpdates#checkField(String).mjava","pathOld":"/dev/null","sourceNew":"  public void checkField(final String numericFieldName) throws Exception {\n\n    final CountDownLatch abortLatch = new CountDownLatch(1);\n\n    final int numDocsToCheck = atLeast(37);\n    final int numDocsInIndex = (numDocsToCheck * DOC_ID_INCR);\n    final AtomicLong[] expected = new AtomicLong[numDocsToCheck];\n\n    log.info(\"Testing \" + numericFieldName + \": numDocsToCheck=\" + numDocsToCheck + \", numDocsInIndex=\" + numDocsInIndex + \", incr=\" + DOC_ID_INCR);\n    \n    // seed the index & keep track of what docs exist and with what values\n    for (int id = 0; id < numDocsInIndex; id++) {\n      // NOTE: the field we're mutating is a long, but we seed with a random int,\n      // and we will inc/dec by random smaller ints, to ensure we never over/under flow\n      final int initValue = random().nextInt();\n      SolrInputDocument doc = doc(f(\"id\",\"\"+id), f(numericFieldName, initValue));\n      UpdateResponse rsp = update(doc).process(CLOUD_CLIENT);\n      assertEquals(doc.toString() + \" => \" + rsp.toString(), 0, rsp.getStatus());\n      if (0 == id % DOC_ID_INCR) {\n        expected[(int)(id / DOC_ID_INCR)] = new AtomicLong(initValue);\n      }\n    }\n    assertNotNull(\"Sanity Check no off-by-one in expected init: \", expected[expected.length-1]);\n    \n    \n    // sanity check index contents\n    assertEquals(0, CLOUD_CLIENT.commit().getStatus());\n    assertEquals(numDocsInIndex,\n                 CLOUD_CLIENT.query(params(\"q\", \"*:*\")).getResults().getNumFound());\n\n    // spin up parallel workers to hammer updates\n    List<Future<Worker>> results = new ArrayList<Future<Worker>>(NUM_THREADS);\n    for (int workerId = 0; workerId < NUM_THREADS; workerId++) {\n      Worker worker = new Worker(workerId, expected, abortLatch, new Random(random().nextLong()),\n                                 numericFieldName);\n      // ask for the Worker to be returned in the Future so we can inspect it\n      results.add(EXEC_SERVICE.submit(worker, worker));\n    }\n    // check the results of all our workers\n    for (Future<Worker> r : results) {\n      try {\n        Worker w = r.get();\n        if (! w.getFinishedOk() ) {\n          // quick and dirty sanity check if any workers didn't succeed, but didn't throw an exception either\n          abortLatch.countDown();\n          log.error(\"worker={} didn't finish ok, but didn't throw exception?\", w.workerId);\n        }\n      } catch (ExecutionException ee) {\n        Throwable rootCause = ee.getCause();\n        if (rootCause instanceof Error) {\n          // low level error, or test assertion failure - either way don't leave it wrapped\n          log.error(\"Worker exec Error, throwing root cause\", ee);\n          throw (Error) rootCause;\n        } else { \n          log.error(\"Worker ExecutionException, re-throwing\", ee);\n          throw ee;\n        }\n      }\n    }\n\n    assertEquals(\"Abort latch has changed, why didn't we get an exception from a worker?\",\n                 1L, abortLatch.getCount());\n    \n    TestInjection.reset();\n    waitForRecoveriesToFinish(CLOUD_CLIENT);\n\n    // check all the final index contents match our expectations\n    int incorrectDocs = 0;\n    for (int id = 0; id < numDocsInIndex; id += DOC_ID_INCR) {\n      assert 0 == id % DOC_ID_INCR : \"WTF? \" + id;\n      \n      final long expect = expected[(int)(id / DOC_ID_INCR)].longValue();\n      \n      final String docId = \"\" + id;\n      \n      // sometimes include an fq on the expected value to ensure the updated values\n      // are \"visible\" for searching\n      final SolrParams p = (0 != TestUtil.nextInt(random(), 0,15))\n        ? params() : params(\"fq\",numericFieldName + \":\" + expect);\n      SolrDocument doc = getRandClient(random()).getById(docId, p);\n      \n      final boolean foundWithFilter = (null != doc);\n      if (! foundWithFilter) {\n        // try again w/o fq to see what it does have\n        doc = getRandClient(random()).getById(docId);\n      }\n      \n      Long actual = (null == doc) ? null : (Long) doc.getFirstValue(numericFieldName);\n      if (actual == null || expect != actual.longValue() || ! foundWithFilter) {\n        log.error(\"docId={}, foundWithFilter={}, expected={}, actual={}\",\n                  docId, foundWithFilter, expect, actual);\n        incorrectDocs++;\n      }\n      \n    }\n    assertEquals(\"Some docs had errors -- check logs\", 0, incorrectDocs);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"37fad704e160205d96f4297e8bf388ba2dee8398","date":1470153013,"type":3,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestStressCloudBlindAtomicUpdates#checkField(String).mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestStressCloudBlindAtomicUpdates#checkField(String).mjava","sourceNew":"  public void checkField(final String numericFieldName) throws Exception {\n\n    final CountDownLatch abortLatch = new CountDownLatch(1);\n\n    final int numDocsToCheck = atLeast(37);\n    final int numDocsInIndex = (numDocsToCheck * DOC_ID_INCR);\n    final AtomicLong[] expected = new AtomicLong[numDocsToCheck];\n\n    log.info(\"Testing \" + numericFieldName + \": numDocsToCheck=\" + numDocsToCheck + \", numDocsInIndex=\" + numDocsInIndex + \", incr=\" + DOC_ID_INCR);\n    \n    // seed the index & keep track of what docs exist and with what values\n    for (int id = 0; id < numDocsInIndex; id++) {\n      // NOTE: the field we're mutating is a long, but we seed with a random int,\n      // and we will inc/dec by random smaller ints, to ensure we never over/under flow\n      final int initValue = random().nextInt();\n      SolrInputDocument doc = doc(f(\"id\",\"\"+id), f(numericFieldName, initValue));\n      UpdateResponse rsp = update(doc).process(CLOUD_CLIENT);\n      assertEquals(doc.toString() + \" => \" + rsp.toString(), 0, rsp.getStatus());\n      if (0 == id % DOC_ID_INCR) {\n        expected[(int)(id / DOC_ID_INCR)] = new AtomicLong(initValue);\n      }\n    }\n    assertNotNull(\"Sanity Check no off-by-one in expected init: \", expected[expected.length-1]);\n    \n    \n    // sanity check index contents\n    waitForRecoveriesToFinish(CLOUD_CLIENT);\n    assertEquals(0, CLOUD_CLIENT.commit().getStatus());\n    assertEquals(numDocsInIndex,\n                 CLOUD_CLIENT.query(params(\"q\", \"*:*\")).getResults().getNumFound());\n\n    startTestInjection();\n    \n    // spin up parallel workers to hammer updates\n    List<Future<Worker>> results = new ArrayList<Future<Worker>>(NUM_THREADS);\n    for (int workerId = 0; workerId < NUM_THREADS; workerId++) {\n      Worker worker = new Worker(workerId, expected, abortLatch, new Random(random().nextLong()),\n                                 numericFieldName);\n      // ask for the Worker to be returned in the Future so we can inspect it\n      results.add(EXEC_SERVICE.submit(worker, worker));\n    }\n    // check the results of all our workers\n    for (Future<Worker> r : results) {\n      try {\n        Worker w = r.get();\n        if (! w.getFinishedOk() ) {\n          // quick and dirty sanity check if any workers didn't succeed, but didn't throw an exception either\n          abortLatch.countDown();\n          log.error(\"worker={} didn't finish ok, but didn't throw exception?\", w.workerId);\n        }\n      } catch (ExecutionException ee) {\n        Throwable rootCause = ee.getCause();\n        if (rootCause instanceof Error) {\n          // low level error, or test assertion failure - either way don't leave it wrapped\n          log.error(\"Worker exec Error, throwing root cause\", ee);\n          throw (Error) rootCause;\n        } else { \n          log.error(\"Worker ExecutionException, re-throwing\", ee);\n          throw ee;\n        }\n      }\n    }\n\n    assertEquals(\"Abort latch has changed, why didn't we get an exception from a worker?\",\n                 1L, abortLatch.getCount());\n    \n    TestInjection.reset();\n    waitForRecoveriesToFinish(CLOUD_CLIENT);\n\n    // check all the final index contents match our expectations\n    int incorrectDocs = 0;\n    for (int id = 0; id < numDocsInIndex; id += DOC_ID_INCR) {\n      assert 0 == id % DOC_ID_INCR : \"WTF? \" + id;\n      \n      final long expect = expected[(int)(id / DOC_ID_INCR)].longValue();\n      \n      final String docId = \"\" + id;\n      \n      // sometimes include an fq on the expected value to ensure the updated values\n      // are \"visible\" for searching\n      final SolrParams p = (0 != TestUtil.nextInt(random(), 0,15))\n        ? params() : params(\"fq\",numericFieldName + \":\" + expect);\n      SolrDocument doc = getRandClient(random()).getById(docId, p);\n      \n      final boolean foundWithFilter = (null != doc);\n      if (! foundWithFilter) {\n        // try again w/o fq to see what it does have\n        doc = getRandClient(random()).getById(docId);\n      }\n      \n      Long actual = (null == doc) ? null : (Long) doc.getFirstValue(numericFieldName);\n      if (actual == null || expect != actual.longValue() || ! foundWithFilter) {\n        log.error(\"docId={}, foundWithFilter={}, expected={}, actual={}\",\n                  docId, foundWithFilter, expect, actual);\n        incorrectDocs++;\n      }\n      \n    }\n    assertEquals(\"Some docs had errors -- check logs\", 0, incorrectDocs);\n  }\n\n","sourceOld":"  public void checkField(final String numericFieldName) throws Exception {\n\n    final CountDownLatch abortLatch = new CountDownLatch(1);\n\n    final int numDocsToCheck = atLeast(37);\n    final int numDocsInIndex = (numDocsToCheck * DOC_ID_INCR);\n    final AtomicLong[] expected = new AtomicLong[numDocsToCheck];\n\n    log.info(\"Testing \" + numericFieldName + \": numDocsToCheck=\" + numDocsToCheck + \", numDocsInIndex=\" + numDocsInIndex + \", incr=\" + DOC_ID_INCR);\n    \n    // seed the index & keep track of what docs exist and with what values\n    for (int id = 0; id < numDocsInIndex; id++) {\n      // NOTE: the field we're mutating is a long, but we seed with a random int,\n      // and we will inc/dec by random smaller ints, to ensure we never over/under flow\n      final int initValue = random().nextInt();\n      SolrInputDocument doc = doc(f(\"id\",\"\"+id), f(numericFieldName, initValue));\n      UpdateResponse rsp = update(doc).process(CLOUD_CLIENT);\n      assertEquals(doc.toString() + \" => \" + rsp.toString(), 0, rsp.getStatus());\n      if (0 == id % DOC_ID_INCR) {\n        expected[(int)(id / DOC_ID_INCR)] = new AtomicLong(initValue);\n      }\n    }\n    assertNotNull(\"Sanity Check no off-by-one in expected init: \", expected[expected.length-1]);\n    \n    \n    // sanity check index contents\n    assertEquals(0, CLOUD_CLIENT.commit().getStatus());\n    assertEquals(numDocsInIndex,\n                 CLOUD_CLIENT.query(params(\"q\", \"*:*\")).getResults().getNumFound());\n\n    // spin up parallel workers to hammer updates\n    List<Future<Worker>> results = new ArrayList<Future<Worker>>(NUM_THREADS);\n    for (int workerId = 0; workerId < NUM_THREADS; workerId++) {\n      Worker worker = new Worker(workerId, expected, abortLatch, new Random(random().nextLong()),\n                                 numericFieldName);\n      // ask for the Worker to be returned in the Future so we can inspect it\n      results.add(EXEC_SERVICE.submit(worker, worker));\n    }\n    // check the results of all our workers\n    for (Future<Worker> r : results) {\n      try {\n        Worker w = r.get();\n        if (! w.getFinishedOk() ) {\n          // quick and dirty sanity check if any workers didn't succeed, but didn't throw an exception either\n          abortLatch.countDown();\n          log.error(\"worker={} didn't finish ok, but didn't throw exception?\", w.workerId);\n        }\n      } catch (ExecutionException ee) {\n        Throwable rootCause = ee.getCause();\n        if (rootCause instanceof Error) {\n          // low level error, or test assertion failure - either way don't leave it wrapped\n          log.error(\"Worker exec Error, throwing root cause\", ee);\n          throw (Error) rootCause;\n        } else { \n          log.error(\"Worker ExecutionException, re-throwing\", ee);\n          throw ee;\n        }\n      }\n    }\n\n    assertEquals(\"Abort latch has changed, why didn't we get an exception from a worker?\",\n                 1L, abortLatch.getCount());\n    \n    TestInjection.reset();\n    waitForRecoveriesToFinish(CLOUD_CLIENT);\n\n    // check all the final index contents match our expectations\n    int incorrectDocs = 0;\n    for (int id = 0; id < numDocsInIndex; id += DOC_ID_INCR) {\n      assert 0 == id % DOC_ID_INCR : \"WTF? \" + id;\n      \n      final long expect = expected[(int)(id / DOC_ID_INCR)].longValue();\n      \n      final String docId = \"\" + id;\n      \n      // sometimes include an fq on the expected value to ensure the updated values\n      // are \"visible\" for searching\n      final SolrParams p = (0 != TestUtil.nextInt(random(), 0,15))\n        ? params() : params(\"fq\",numericFieldName + \":\" + expect);\n      SolrDocument doc = getRandClient(random()).getById(docId, p);\n      \n      final boolean foundWithFilter = (null != doc);\n      if (! foundWithFilter) {\n        // try again w/o fq to see what it does have\n        doc = getRandClient(random()).getById(docId);\n      }\n      \n      Long actual = (null == doc) ? null : (Long) doc.getFirstValue(numericFieldName);\n      if (actual == null || expect != actual.longValue() || ! foundWithFilter) {\n        log.error(\"docId={}, foundWithFilter={}, expected={}, actual={}\",\n                  docId, foundWithFilter, expect, actual);\n        incorrectDocs++;\n      }\n      \n    }\n    assertEquals(\"Some docs had errors -- check logs\", 0, incorrectDocs);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"76b65cf789129cacd84e977b8f1538aec29e0281","date":1470165799,"type":3,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestStressCloudBlindAtomicUpdates#checkField(String).mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestStressCloudBlindAtomicUpdates#checkField(String).mjava","sourceNew":"  public void checkField(final String numericFieldName) throws Exception {\n\n    final CountDownLatch abortLatch = new CountDownLatch(1);\n\n    final int numDocsToCheck = atLeast(37);\n    final int numDocsInIndex = (numDocsToCheck * DOC_ID_INCR);\n    final AtomicLong[] expected = new AtomicLong[numDocsToCheck];\n\n    log.info(\"Testing \" + numericFieldName + \": numDocsToCheck=\" + numDocsToCheck + \", numDocsInIndex=\" + numDocsInIndex + \", incr=\" + DOC_ID_INCR);\n    \n    // seed the index & keep track of what docs exist and with what values\n    for (int id = 0; id < numDocsInIndex; id++) {\n      // NOTE: the field we're mutating is a long, but we seed with a random int,\n      // and we will inc/dec by random smaller ints, to ensure we never over/under flow\n      final int initValue = random().nextInt();\n      SolrInputDocument doc = doc(f(\"id\",\"\"+id), f(numericFieldName, initValue));\n      UpdateResponse rsp = update(doc).process(CLOUD_CLIENT);\n      assertEquals(doc.toString() + \" => \" + rsp.toString(), 0, rsp.getStatus());\n      if (0 == id % DOC_ID_INCR) {\n        expected[(int)(id / DOC_ID_INCR)] = new AtomicLong(initValue);\n      }\n    }\n    assertNotNull(\"Sanity Check no off-by-one in expected init: \", expected[expected.length-1]);\n    \n    \n    // sanity check index contents\n    waitForRecoveriesToFinish(CLOUD_CLIENT);\n    assertEquals(0, CLOUD_CLIENT.commit().getStatus());\n    assertEquals(numDocsInIndex,\n                 CLOUD_CLIENT.query(params(\"q\", \"*:*\")).getResults().getNumFound());\n\n    startTestInjection();\n    \n    // spin up parallel workers to hammer updates\n    List<Future<Worker>> results = new ArrayList<Future<Worker>>(NUM_THREADS);\n    for (int workerId = 0; workerId < NUM_THREADS; workerId++) {\n      Worker worker = new Worker(workerId, expected, abortLatch, new Random(random().nextLong()),\n                                 numericFieldName);\n      // ask for the Worker to be returned in the Future so we can inspect it\n      results.add(EXEC_SERVICE.submit(worker, worker));\n    }\n    // check the results of all our workers\n    for (Future<Worker> r : results) {\n      try {\n        Worker w = r.get();\n        if (! w.getFinishedOk() ) {\n          // quick and dirty sanity check if any workers didn't succeed, but didn't throw an exception either\n          abortLatch.countDown();\n          log.error(\"worker={} didn't finish ok, but didn't throw exception?\", w.workerId);\n        }\n      } catch (ExecutionException ee) {\n        Throwable rootCause = ee.getCause();\n        if (rootCause instanceof Error) {\n          // low level error, or test assertion failure - either way don't leave it wrapped\n          log.error(\"Worker exec Error, throwing root cause\", ee);\n          throw (Error) rootCause;\n        } else { \n          log.error(\"Worker ExecutionException, re-throwing\", ee);\n          throw ee;\n        }\n      }\n    }\n\n    assertEquals(\"Abort latch has changed, why didn't we get an exception from a worker?\",\n                 1L, abortLatch.getCount());\n    \n    TestInjection.reset();\n    waitForRecoveriesToFinish(CLOUD_CLIENT);\n\n    // check all the final index contents match our expectations\n    int incorrectDocs = 0;\n    for (int id = 0; id < numDocsInIndex; id += DOC_ID_INCR) {\n      assert 0 == id % DOC_ID_INCR : \"WTF? \" + id;\n      \n      final long expect = expected[(int)(id / DOC_ID_INCR)].longValue();\n      \n      final String docId = \"\" + id;\n      \n      // sometimes include an fq on the expected value to ensure the updated values\n      // are \"visible\" for searching\n      final SolrParams p = (0 != TestUtil.nextInt(random(), 0,15))\n        ? params() : params(\"fq\",numericFieldName + \":\\\"\" + expect + \"\\\"\");\n      SolrDocument doc = getRandClient(random()).getById(docId, p);\n      \n      final boolean foundWithFilter = (null != doc);\n      if (! foundWithFilter) {\n        // try again w/o fq to see what it does have\n        doc = getRandClient(random()).getById(docId);\n      }\n      \n      Long actual = (null == doc) ? null : (Long) doc.getFirstValue(numericFieldName);\n      if (actual == null || expect != actual.longValue() || ! foundWithFilter) {\n        log.error(\"docId={}, foundWithFilter={}, expected={}, actual={}\",\n                  docId, foundWithFilter, expect, actual);\n        incorrectDocs++;\n      }\n      \n    }\n    assertEquals(\"Some docs had errors -- check logs\", 0, incorrectDocs);\n  }\n\n","sourceOld":"  public void checkField(final String numericFieldName) throws Exception {\n\n    final CountDownLatch abortLatch = new CountDownLatch(1);\n\n    final int numDocsToCheck = atLeast(37);\n    final int numDocsInIndex = (numDocsToCheck * DOC_ID_INCR);\n    final AtomicLong[] expected = new AtomicLong[numDocsToCheck];\n\n    log.info(\"Testing \" + numericFieldName + \": numDocsToCheck=\" + numDocsToCheck + \", numDocsInIndex=\" + numDocsInIndex + \", incr=\" + DOC_ID_INCR);\n    \n    // seed the index & keep track of what docs exist and with what values\n    for (int id = 0; id < numDocsInIndex; id++) {\n      // NOTE: the field we're mutating is a long, but we seed with a random int,\n      // and we will inc/dec by random smaller ints, to ensure we never over/under flow\n      final int initValue = random().nextInt();\n      SolrInputDocument doc = doc(f(\"id\",\"\"+id), f(numericFieldName, initValue));\n      UpdateResponse rsp = update(doc).process(CLOUD_CLIENT);\n      assertEquals(doc.toString() + \" => \" + rsp.toString(), 0, rsp.getStatus());\n      if (0 == id % DOC_ID_INCR) {\n        expected[(int)(id / DOC_ID_INCR)] = new AtomicLong(initValue);\n      }\n    }\n    assertNotNull(\"Sanity Check no off-by-one in expected init: \", expected[expected.length-1]);\n    \n    \n    // sanity check index contents\n    waitForRecoveriesToFinish(CLOUD_CLIENT);\n    assertEquals(0, CLOUD_CLIENT.commit().getStatus());\n    assertEquals(numDocsInIndex,\n                 CLOUD_CLIENT.query(params(\"q\", \"*:*\")).getResults().getNumFound());\n\n    startTestInjection();\n    \n    // spin up parallel workers to hammer updates\n    List<Future<Worker>> results = new ArrayList<Future<Worker>>(NUM_THREADS);\n    for (int workerId = 0; workerId < NUM_THREADS; workerId++) {\n      Worker worker = new Worker(workerId, expected, abortLatch, new Random(random().nextLong()),\n                                 numericFieldName);\n      // ask for the Worker to be returned in the Future so we can inspect it\n      results.add(EXEC_SERVICE.submit(worker, worker));\n    }\n    // check the results of all our workers\n    for (Future<Worker> r : results) {\n      try {\n        Worker w = r.get();\n        if (! w.getFinishedOk() ) {\n          // quick and dirty sanity check if any workers didn't succeed, but didn't throw an exception either\n          abortLatch.countDown();\n          log.error(\"worker={} didn't finish ok, but didn't throw exception?\", w.workerId);\n        }\n      } catch (ExecutionException ee) {\n        Throwable rootCause = ee.getCause();\n        if (rootCause instanceof Error) {\n          // low level error, or test assertion failure - either way don't leave it wrapped\n          log.error(\"Worker exec Error, throwing root cause\", ee);\n          throw (Error) rootCause;\n        } else { \n          log.error(\"Worker ExecutionException, re-throwing\", ee);\n          throw ee;\n        }\n      }\n    }\n\n    assertEquals(\"Abort latch has changed, why didn't we get an exception from a worker?\",\n                 1L, abortLatch.getCount());\n    \n    TestInjection.reset();\n    waitForRecoveriesToFinish(CLOUD_CLIENT);\n\n    // check all the final index contents match our expectations\n    int incorrectDocs = 0;\n    for (int id = 0; id < numDocsInIndex; id += DOC_ID_INCR) {\n      assert 0 == id % DOC_ID_INCR : \"WTF? \" + id;\n      \n      final long expect = expected[(int)(id / DOC_ID_INCR)].longValue();\n      \n      final String docId = \"\" + id;\n      \n      // sometimes include an fq on the expected value to ensure the updated values\n      // are \"visible\" for searching\n      final SolrParams p = (0 != TestUtil.nextInt(random(), 0,15))\n        ? params() : params(\"fq\",numericFieldName + \":\" + expect);\n      SolrDocument doc = getRandClient(random()).getById(docId, p);\n      \n      final boolean foundWithFilter = (null != doc);\n      if (! foundWithFilter) {\n        // try again w/o fq to see what it does have\n        doc = getRandClient(random()).getById(docId);\n      }\n      \n      Long actual = (null == doc) ? null : (Long) doc.getFirstValue(numericFieldName);\n      if (actual == null || expect != actual.longValue() || ! foundWithFilter) {\n        log.error(\"docId={}, foundWithFilter={}, expected={}, actual={}\",\n                  docId, foundWithFilter, expect, actual);\n        incorrectDocs++;\n      }\n      \n    }\n    assertEquals(\"Some docs had errors -- check logs\", 0, incorrectDocs);\n  }\n\n","bugFix":["106fbee5a2b8105d0628067f2c65cd0fedfc19e7"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3b013574eedcdbac35dc7e35b0ee616ffc38895d","date":1470897818,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestStressCloudBlindAtomicUpdates#checkField(String).mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestStressCloudBlindAtomicUpdates#checkField(String).mjava","sourceNew":"  public void checkField(final String numericFieldName) throws Exception {\n\n    final CountDownLatch abortLatch = new CountDownLatch(1);\n\n    final int numDocsToCheck = atLeast(37);\n    final int numDocsInIndex = (numDocsToCheck * DOC_ID_INCR);\n    final AtomicLong[] expected = new AtomicLong[numDocsToCheck];\n\n    log.info(\"Testing \" + numericFieldName + \": numDocsToCheck=\" + numDocsToCheck + \", numDocsInIndex=\" + numDocsInIndex + \", incr=\" + DOC_ID_INCR);\n    \n    // seed the index & keep track of what docs exist and with what values\n    for (int id = 0; id < numDocsInIndex; id++) {\n      // NOTE: the field we're mutating is a long, but we seed with a random int,\n      // and we will inc/dec by random smaller ints, to ensure we never over/under flow\n      final int initValue = random().nextInt();\n      SolrInputDocument doc = doc(f(\"id\",\"\"+id), f(numericFieldName, initValue));\n      UpdateResponse rsp = update(doc).process(CLOUD_CLIENT);\n      assertEquals(doc.toString() + \" => \" + rsp.toString(), 0, rsp.getStatus());\n      if (0 == id % DOC_ID_INCR) {\n        expected[(int)(id / DOC_ID_INCR)] = new AtomicLong(initValue);\n      }\n    }\n    assertNotNull(\"Sanity Check no off-by-one in expected init: \", expected[expected.length-1]);\n    \n    \n    // sanity check index contents\n    waitForRecoveriesToFinish(CLOUD_CLIENT);\n    assertEquals(0, CLOUD_CLIENT.commit().getStatus());\n    assertEquals(numDocsInIndex,\n                 CLOUD_CLIENT.query(params(\"q\", \"*:*\")).getResults().getNumFound());\n\n    startTestInjection();\n    \n    // spin up parallel workers to hammer updates\n    List<Future<Worker>> results = new ArrayList<Future<Worker>>(NUM_THREADS);\n    for (int workerId = 0; workerId < NUM_THREADS; workerId++) {\n      Worker worker = new Worker(workerId, expected, abortLatch, new Random(random().nextLong()),\n                                 numericFieldName);\n      // ask for the Worker to be returned in the Future so we can inspect it\n      results.add(EXEC_SERVICE.submit(worker, worker));\n    }\n    // check the results of all our workers\n    for (Future<Worker> r : results) {\n      try {\n        Worker w = r.get();\n        if (! w.getFinishedOk() ) {\n          // quick and dirty sanity check if any workers didn't succeed, but didn't throw an exception either\n          abortLatch.countDown();\n          log.error(\"worker={} didn't finish ok, but didn't throw exception?\", w.workerId);\n        }\n      } catch (ExecutionException ee) {\n        Throwable rootCause = ee.getCause();\n        if (rootCause instanceof Error) {\n          // low level error, or test assertion failure - either way don't leave it wrapped\n          log.error(\"Worker exec Error, throwing root cause\", ee);\n          throw (Error) rootCause;\n        } else { \n          log.error(\"Worker ExecutionException, re-throwing\", ee);\n          throw ee;\n        }\n      }\n    }\n\n    assertEquals(\"Abort latch has changed, why didn't we get an exception from a worker?\",\n                 1L, abortLatch.getCount());\n    \n    TestInjection.reset();\n    waitForRecoveriesToFinish(CLOUD_CLIENT);\n\n    // check all the final index contents match our expectations\n    int incorrectDocs = 0;\n    for (int id = 0; id < numDocsInIndex; id += DOC_ID_INCR) {\n      assert 0 == id % DOC_ID_INCR : \"WTF? \" + id;\n      \n      final long expect = expected[(int)(id / DOC_ID_INCR)].longValue();\n      \n      final String docId = \"\" + id;\n      \n      // sometimes include an fq on the expected value to ensure the updated values\n      // are \"visible\" for searching\n      final SolrParams p = (0 != TestUtil.nextInt(random(), 0,15))\n        ? params() : params(\"fq\",numericFieldName + \":\\\"\" + expect + \"\\\"\");\n      SolrDocument doc = getRandClient(random()).getById(docId, p);\n      \n      final boolean foundWithFilter = (null != doc);\n      if (! foundWithFilter) {\n        // try again w/o fq to see what it does have\n        doc = getRandClient(random()).getById(docId);\n      }\n      \n      Long actual = (null == doc) ? null : (Long) doc.getFirstValue(numericFieldName);\n      if (actual == null || expect != actual.longValue() || ! foundWithFilter) {\n        log.error(\"docId={}, foundWithFilter={}, expected={}, actual={}\",\n                  docId, foundWithFilter, expect, actual);\n        incorrectDocs++;\n      }\n      \n    }\n    assertEquals(\"Some docs had errors -- check logs\", 0, incorrectDocs);\n  }\n\n","sourceOld":"  public void checkField(final String numericFieldName) throws Exception {\n\n    final CountDownLatch abortLatch = new CountDownLatch(1);\n\n    final int numDocsToCheck = atLeast(37);\n    final int numDocsInIndex = (numDocsToCheck * DOC_ID_INCR);\n    final AtomicLong[] expected = new AtomicLong[numDocsToCheck];\n\n    log.info(\"Testing \" + numericFieldName + \": numDocsToCheck=\" + numDocsToCheck + \", numDocsInIndex=\" + numDocsInIndex + \", incr=\" + DOC_ID_INCR);\n    \n    // seed the index & keep track of what docs exist and with what values\n    for (int id = 0; id < numDocsInIndex; id++) {\n      // NOTE: the field we're mutating is a long, but we seed with a random int,\n      // and we will inc/dec by random smaller ints, to ensure we never over/under flow\n      final int initValue = random().nextInt();\n      SolrInputDocument doc = doc(f(\"id\",\"\"+id), f(numericFieldName, initValue));\n      UpdateResponse rsp = update(doc).process(CLOUD_CLIENT);\n      assertEquals(doc.toString() + \" => \" + rsp.toString(), 0, rsp.getStatus());\n      if (0 == id % DOC_ID_INCR) {\n        expected[(int)(id / DOC_ID_INCR)] = new AtomicLong(initValue);\n      }\n    }\n    assertNotNull(\"Sanity Check no off-by-one in expected init: \", expected[expected.length-1]);\n    \n    \n    // sanity check index contents\n    assertEquals(0, CLOUD_CLIENT.commit().getStatus());\n    assertEquals(numDocsInIndex,\n                 CLOUD_CLIENT.query(params(\"q\", \"*:*\")).getResults().getNumFound());\n\n    // spin up parallel workers to hammer updates\n    List<Future<Worker>> results = new ArrayList<Future<Worker>>(NUM_THREADS);\n    for (int workerId = 0; workerId < NUM_THREADS; workerId++) {\n      Worker worker = new Worker(workerId, expected, abortLatch, new Random(random().nextLong()),\n                                 numericFieldName);\n      // ask for the Worker to be returned in the Future so we can inspect it\n      results.add(EXEC_SERVICE.submit(worker, worker));\n    }\n    // check the results of all our workers\n    for (Future<Worker> r : results) {\n      try {\n        Worker w = r.get();\n        if (! w.getFinishedOk() ) {\n          // quick and dirty sanity check if any workers didn't succeed, but didn't throw an exception either\n          abortLatch.countDown();\n          log.error(\"worker={} didn't finish ok, but didn't throw exception?\", w.workerId);\n        }\n      } catch (ExecutionException ee) {\n        Throwable rootCause = ee.getCause();\n        if (rootCause instanceof Error) {\n          // low level error, or test assertion failure - either way don't leave it wrapped\n          log.error(\"Worker exec Error, throwing root cause\", ee);\n          throw (Error) rootCause;\n        } else { \n          log.error(\"Worker ExecutionException, re-throwing\", ee);\n          throw ee;\n        }\n      }\n    }\n\n    assertEquals(\"Abort latch has changed, why didn't we get an exception from a worker?\",\n                 1L, abortLatch.getCount());\n    \n    TestInjection.reset();\n    waitForRecoveriesToFinish(CLOUD_CLIENT);\n\n    // check all the final index contents match our expectations\n    int incorrectDocs = 0;\n    for (int id = 0; id < numDocsInIndex; id += DOC_ID_INCR) {\n      assert 0 == id % DOC_ID_INCR : \"WTF? \" + id;\n      \n      final long expect = expected[(int)(id / DOC_ID_INCR)].longValue();\n      \n      final String docId = \"\" + id;\n      \n      // sometimes include an fq on the expected value to ensure the updated values\n      // are \"visible\" for searching\n      final SolrParams p = (0 != TestUtil.nextInt(random(), 0,15))\n        ? params() : params(\"fq\",numericFieldName + \":\" + expect);\n      SolrDocument doc = getRandClient(random()).getById(docId, p);\n      \n      final boolean foundWithFilter = (null != doc);\n      if (! foundWithFilter) {\n        // try again w/o fq to see what it does have\n        doc = getRandClient(random()).getById(docId);\n      }\n      \n      Long actual = (null == doc) ? null : (Long) doc.getFirstValue(numericFieldName);\n      if (actual == null || expect != actual.longValue() || ! foundWithFilter) {\n        log.error(\"docId={}, foundWithFilter={}, expected={}, actual={}\",\n                  docId, foundWithFilter, expect, actual);\n        incorrectDocs++;\n      }\n      \n    }\n    assertEquals(\"Some docs had errors -- check logs\", 0, incorrectDocs);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestStressCloudBlindAtomicUpdates#checkField(String).mjava","pathOld":"/dev/null","sourceNew":"  public void checkField(final String numericFieldName) throws Exception {\n\n    final CountDownLatch abortLatch = new CountDownLatch(1);\n\n    final int numDocsToCheck = atLeast(37);\n    final int numDocsInIndex = (numDocsToCheck * DOC_ID_INCR);\n    final AtomicLong[] expected = new AtomicLong[numDocsToCheck];\n\n    log.info(\"Testing \" + numericFieldName + \": numDocsToCheck=\" + numDocsToCheck + \", numDocsInIndex=\" + numDocsInIndex + \", incr=\" + DOC_ID_INCR);\n    \n    // seed the index & keep track of what docs exist and with what values\n    for (int id = 0; id < numDocsInIndex; id++) {\n      // NOTE: the field we're mutating is a long, but we seed with a random int,\n      // and we will inc/dec by random smaller ints, to ensure we never over/under flow\n      final int initValue = random().nextInt();\n      SolrInputDocument doc = doc(f(\"id\",\"\"+id), f(numericFieldName, initValue));\n      UpdateResponse rsp = update(doc).process(CLOUD_CLIENT);\n      assertEquals(doc.toString() + \" => \" + rsp.toString(), 0, rsp.getStatus());\n      if (0 == id % DOC_ID_INCR) {\n        expected[(int)(id / DOC_ID_INCR)] = new AtomicLong(initValue);\n      }\n    }\n    assertNotNull(\"Sanity Check no off-by-one in expected init: \", expected[expected.length-1]);\n    \n    \n    // sanity check index contents\n    waitForRecoveriesToFinish(CLOUD_CLIENT);\n    assertEquals(0, CLOUD_CLIENT.commit().getStatus());\n    assertEquals(numDocsInIndex,\n                 CLOUD_CLIENT.query(params(\"q\", \"*:*\")).getResults().getNumFound());\n\n    startTestInjection();\n    \n    // spin up parallel workers to hammer updates\n    List<Future<Worker>> results = new ArrayList<Future<Worker>>(NUM_THREADS);\n    for (int workerId = 0; workerId < NUM_THREADS; workerId++) {\n      Worker worker = new Worker(workerId, expected, abortLatch, new Random(random().nextLong()),\n                                 numericFieldName);\n      // ask for the Worker to be returned in the Future so we can inspect it\n      results.add(EXEC_SERVICE.submit(worker, worker));\n    }\n    // check the results of all our workers\n    for (Future<Worker> r : results) {\n      try {\n        Worker w = r.get();\n        if (! w.getFinishedOk() ) {\n          // quick and dirty sanity check if any workers didn't succeed, but didn't throw an exception either\n          abortLatch.countDown();\n          log.error(\"worker={} didn't finish ok, but didn't throw exception?\", w.workerId);\n        }\n      } catch (ExecutionException ee) {\n        Throwable rootCause = ee.getCause();\n        if (rootCause instanceof Error) {\n          // low level error, or test assertion failure - either way don't leave it wrapped\n          log.error(\"Worker exec Error, throwing root cause\", ee);\n          throw (Error) rootCause;\n        } else { \n          log.error(\"Worker ExecutionException, re-throwing\", ee);\n          throw ee;\n        }\n      }\n    }\n\n    assertEquals(\"Abort latch has changed, why didn't we get an exception from a worker?\",\n                 1L, abortLatch.getCount());\n    \n    TestInjection.reset();\n    waitForRecoveriesToFinish(CLOUD_CLIENT);\n\n    // check all the final index contents match our expectations\n    int incorrectDocs = 0;\n    for (int id = 0; id < numDocsInIndex; id += DOC_ID_INCR) {\n      assert 0 == id % DOC_ID_INCR : \"WTF? \" + id;\n      \n      final long expect = expected[(int)(id / DOC_ID_INCR)].longValue();\n      \n      final String docId = \"\" + id;\n      \n      // sometimes include an fq on the expected value to ensure the updated values\n      // are \"visible\" for searching\n      final SolrParams p = (0 != TestUtil.nextInt(random(), 0,15))\n        ? params() : params(\"fq\",numericFieldName + \":\\\"\" + expect + \"\\\"\");\n      SolrDocument doc = getRandClient(random()).getById(docId, p);\n      \n      final boolean foundWithFilter = (null != doc);\n      if (! foundWithFilter) {\n        // try again w/o fq to see what it does have\n        doc = getRandClient(random()).getById(docId);\n      }\n      \n      Long actual = (null == doc) ? null : (Long) doc.getFirstValue(numericFieldName);\n      if (actual == null || expect != actual.longValue() || ! foundWithFilter) {\n        log.error(\"docId={}, foundWithFilter={}, expected={}, actual={}\",\n                  docId, foundWithFilter, expect, actual);\n        incorrectDocs++;\n      }\n      \n    }\n    assertEquals(\"Some docs had errors -- check logs\", 0, incorrectDocs);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a966532d92cf9ba2856f15a8140151bb6b518e4b","date":1588290631,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestStressCloudBlindAtomicUpdates#checkField(String).mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestStressCloudBlindAtomicUpdates#checkField(String).mjava","sourceNew":"  public void checkField(final String numericFieldName) throws Exception {\n\n    final CountDownLatch abortLatch = new CountDownLatch(1);\n\n    final int numDocsToCheck = atLeast(37);\n    final int numDocsInIndex = (numDocsToCheck * DOC_ID_INCR);\n    final AtomicLong[] expected = new AtomicLong[numDocsToCheck];\n\n    log.info(\"Testing {}: numDocsToCheck={}, numDocsInIndex={}, incr={}\"\n        , numericFieldName,  numDocsToCheck, numDocsInIndex, DOC_ID_INCR);\n    \n    // seed the index & keep track of what docs exist and with what values\n    for (int id = 0; id < numDocsInIndex; id++) {\n      // NOTE: the field we're mutating is a long, but we seed with a random int,\n      // and we will inc/dec by random smaller ints, to ensure we never over/under flow\n      final int initValue = random().nextInt();\n      SolrInputDocument doc = doc(f(\"id\",\"\"+id), f(numericFieldName, initValue));\n      UpdateResponse rsp = update(doc).process(CLOUD_CLIENT);\n      assertEquals(doc.toString() + \" => \" + rsp.toString(), 0, rsp.getStatus());\n      if (0 == id % DOC_ID_INCR) {\n        expected[(int)(id / DOC_ID_INCR)] = new AtomicLong(initValue);\n      }\n    }\n    assertNotNull(\"Sanity Check no off-by-one in expected init: \", expected[expected.length-1]);\n    \n    \n    // sanity check index contents\n    waitForRecoveriesToFinish(CLOUD_CLIENT);\n    assertEquals(0, CLOUD_CLIENT.commit().getStatus());\n    assertEquals(numDocsInIndex,\n                 CLOUD_CLIENT.query(params(\"q\", \"*:*\")).getResults().getNumFound());\n\n    startTestInjection();\n    \n    // spin up parallel workers to hammer updates\n    List<Future<Worker>> results = new ArrayList<Future<Worker>>(NUM_THREADS);\n    for (int workerId = 0; workerId < NUM_THREADS; workerId++) {\n      Worker worker = new Worker(workerId, expected, abortLatch, new Random(random().nextLong()),\n                                 numericFieldName);\n      // ask for the Worker to be returned in the Future so we can inspect it\n      results.add(EXEC_SERVICE.submit(worker, worker));\n    }\n    // check the results of all our workers\n    for (Future<Worker> r : results) {\n      try {\n        Worker w = r.get();\n        if (! w.getFinishedOk() ) {\n          // quick and dirty sanity check if any workers didn't succeed, but didn't throw an exception either\n          abortLatch.countDown();\n          log.error(\"worker={} didn't finish ok, but didn't throw exception?\", w.workerId);\n        }\n      } catch (ExecutionException ee) {\n        Throwable rootCause = ee.getCause();\n        if (rootCause instanceof Error) {\n          // low level error, or test assertion failure - either way don't leave it wrapped\n          log.error(\"Worker exec Error, throwing root cause\", ee);\n          throw (Error) rootCause;\n        } else { \n          log.error(\"Worker ExecutionException, re-throwing\", ee);\n          throw ee;\n        }\n      }\n    }\n\n    assertEquals(\"Abort latch has changed, why didn't we get an exception from a worker?\",\n                 1L, abortLatch.getCount());\n    \n    TestInjection.reset();\n    waitForRecoveriesToFinish(CLOUD_CLIENT);\n\n    // check all the final index contents match our expectations\n    int incorrectDocs = 0;\n    for (int id = 0; id < numDocsInIndex; id += DOC_ID_INCR) {\n      assert 0 == id % DOC_ID_INCR : \"WTF? \" + id;\n      \n      final long expect = expected[(int)(id / DOC_ID_INCR)].longValue();\n      \n      final String docId = \"\" + id;\n      \n      // sometimes include an fq on the expected value to ensure the updated values\n      // are \"visible\" for searching\n      final SolrParams p = (0 != TestUtil.nextInt(random(), 0,15))\n        ? params() : params(\"fq\",numericFieldName + \":\\\"\" + expect + \"\\\"\");\n      SolrDocument doc = getRandClient(random()).getById(docId, p);\n      \n      final boolean foundWithFilter = (null != doc);\n      if (! foundWithFilter) {\n        // try again w/o fq to see what it does have\n        doc = getRandClient(random()).getById(docId);\n      }\n      \n      Long actual = (null == doc) ? null : (Long) doc.getFirstValue(numericFieldName);\n      if (actual == null || expect != actual.longValue() || ! foundWithFilter) {\n        log.error(\"docId={}, foundWithFilter={}, expected={}, actual={}\",\n                  docId, foundWithFilter, expect, actual);\n        incorrectDocs++;\n      }\n      \n    }\n    assertEquals(\"Some docs had errors -- check logs\", 0, incorrectDocs);\n  }\n\n","sourceOld":"  public void checkField(final String numericFieldName) throws Exception {\n\n    final CountDownLatch abortLatch = new CountDownLatch(1);\n\n    final int numDocsToCheck = atLeast(37);\n    final int numDocsInIndex = (numDocsToCheck * DOC_ID_INCR);\n    final AtomicLong[] expected = new AtomicLong[numDocsToCheck];\n\n    log.info(\"Testing \" + numericFieldName + \": numDocsToCheck=\" + numDocsToCheck + \", numDocsInIndex=\" + numDocsInIndex + \", incr=\" + DOC_ID_INCR);\n    \n    // seed the index & keep track of what docs exist and with what values\n    for (int id = 0; id < numDocsInIndex; id++) {\n      // NOTE: the field we're mutating is a long, but we seed with a random int,\n      // and we will inc/dec by random smaller ints, to ensure we never over/under flow\n      final int initValue = random().nextInt();\n      SolrInputDocument doc = doc(f(\"id\",\"\"+id), f(numericFieldName, initValue));\n      UpdateResponse rsp = update(doc).process(CLOUD_CLIENT);\n      assertEquals(doc.toString() + \" => \" + rsp.toString(), 0, rsp.getStatus());\n      if (0 == id % DOC_ID_INCR) {\n        expected[(int)(id / DOC_ID_INCR)] = new AtomicLong(initValue);\n      }\n    }\n    assertNotNull(\"Sanity Check no off-by-one in expected init: \", expected[expected.length-1]);\n    \n    \n    // sanity check index contents\n    waitForRecoveriesToFinish(CLOUD_CLIENT);\n    assertEquals(0, CLOUD_CLIENT.commit().getStatus());\n    assertEquals(numDocsInIndex,\n                 CLOUD_CLIENT.query(params(\"q\", \"*:*\")).getResults().getNumFound());\n\n    startTestInjection();\n    \n    // spin up parallel workers to hammer updates\n    List<Future<Worker>> results = new ArrayList<Future<Worker>>(NUM_THREADS);\n    for (int workerId = 0; workerId < NUM_THREADS; workerId++) {\n      Worker worker = new Worker(workerId, expected, abortLatch, new Random(random().nextLong()),\n                                 numericFieldName);\n      // ask for the Worker to be returned in the Future so we can inspect it\n      results.add(EXEC_SERVICE.submit(worker, worker));\n    }\n    // check the results of all our workers\n    for (Future<Worker> r : results) {\n      try {\n        Worker w = r.get();\n        if (! w.getFinishedOk() ) {\n          // quick and dirty sanity check if any workers didn't succeed, but didn't throw an exception either\n          abortLatch.countDown();\n          log.error(\"worker={} didn't finish ok, but didn't throw exception?\", w.workerId);\n        }\n      } catch (ExecutionException ee) {\n        Throwable rootCause = ee.getCause();\n        if (rootCause instanceof Error) {\n          // low level error, or test assertion failure - either way don't leave it wrapped\n          log.error(\"Worker exec Error, throwing root cause\", ee);\n          throw (Error) rootCause;\n        } else { \n          log.error(\"Worker ExecutionException, re-throwing\", ee);\n          throw ee;\n        }\n      }\n    }\n\n    assertEquals(\"Abort latch has changed, why didn't we get an exception from a worker?\",\n                 1L, abortLatch.getCount());\n    \n    TestInjection.reset();\n    waitForRecoveriesToFinish(CLOUD_CLIENT);\n\n    // check all the final index contents match our expectations\n    int incorrectDocs = 0;\n    for (int id = 0; id < numDocsInIndex; id += DOC_ID_INCR) {\n      assert 0 == id % DOC_ID_INCR : \"WTF? \" + id;\n      \n      final long expect = expected[(int)(id / DOC_ID_INCR)].longValue();\n      \n      final String docId = \"\" + id;\n      \n      // sometimes include an fq on the expected value to ensure the updated values\n      // are \"visible\" for searching\n      final SolrParams p = (0 != TestUtil.nextInt(random(), 0,15))\n        ? params() : params(\"fq\",numericFieldName + \":\\\"\" + expect + \"\\\"\");\n      SolrDocument doc = getRandClient(random()).getById(docId, p);\n      \n      final boolean foundWithFilter = (null != doc);\n      if (! foundWithFilter) {\n        // try again w/o fq to see what it does have\n        doc = getRandClient(random()).getById(docId);\n      }\n      \n      Long actual = (null == doc) ? null : (Long) doc.getFirstValue(numericFieldName);\n      if (actual == null || expect != actual.longValue() || ! foundWithFilter) {\n        log.error(\"docId={}, foundWithFilter={}, expected={}, actual={}\",\n                  docId, foundWithFilter, expect, actual);\n        incorrectDocs++;\n      }\n      \n    }\n    assertEquals(\"Some docs had errors -- check logs\", 0, incorrectDocs);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"aa2585c33d5d66a1c837c312221eb55ddb3c4300","date":1592493170,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestStressCloudBlindAtomicUpdates#checkField(String).mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestStressCloudBlindAtomicUpdates#checkField(String).mjava","sourceNew":"  public void checkField(final String numericFieldName) throws Exception {\n\n    final CountDownLatch abortLatch = new CountDownLatch(1);\n\n    final int numDocsToCheck = atLeast(37);\n    final int numDocsInIndex = (numDocsToCheck * DOC_ID_INCR);\n    final AtomicLong[] expected = new AtomicLong[numDocsToCheck];\n\n    log.info(\"Testing {}: numDocsToCheck={}, numDocsInIndex={}, incr={}\"\n        , numericFieldName,  numDocsToCheck, numDocsInIndex, DOC_ID_INCR);\n    \n    // seed the index & keep track of what docs exist and with what values\n    for (int id = 0; id < numDocsInIndex; id++) {\n      // NOTE: the field we're mutating is a long, but we seed with a random int,\n      // and we will inc/dec by random smaller ints, to ensure we never over/under flow\n      final int initValue = random().nextInt();\n      SolrInputDocument doc = doc(f(\"id\",\"\"+id), f(numericFieldName, initValue));\n      UpdateResponse rsp = update(doc).process(CLOUD_CLIENT);\n      assertEquals(doc.toString() + \" => \" + rsp.toString(), 0, rsp.getStatus());\n      if (0 == id % DOC_ID_INCR) {\n        expected[id / DOC_ID_INCR] = new AtomicLong(initValue);\n      }\n    }\n    assertNotNull(\"Sanity Check no off-by-one in expected init: \", expected[expected.length-1]);\n    \n    \n    // sanity check index contents\n    waitForRecoveriesToFinish(CLOUD_CLIENT);\n    assertEquals(0, CLOUD_CLIENT.commit().getStatus());\n    assertEquals(numDocsInIndex,\n                 CLOUD_CLIENT.query(params(\"q\", \"*:*\")).getResults().getNumFound());\n\n    startTestInjection();\n    \n    // spin up parallel workers to hammer updates\n    List<Future<Worker>> results = new ArrayList<Future<Worker>>(NUM_THREADS);\n    for (int workerId = 0; workerId < NUM_THREADS; workerId++) {\n      Worker worker = new Worker(workerId, expected, abortLatch, new Random(random().nextLong()),\n                                 numericFieldName);\n      // ask for the Worker to be returned in the Future so we can inspect it\n      results.add(EXEC_SERVICE.submit(worker, worker));\n    }\n    // check the results of all our workers\n    for (Future<Worker> r : results) {\n      try {\n        Worker w = r.get();\n        if (! w.getFinishedOk() ) {\n          // quick and dirty sanity check if any workers didn't succeed, but didn't throw an exception either\n          abortLatch.countDown();\n          log.error(\"worker={} didn't finish ok, but didn't throw exception?\", w.workerId);\n        }\n      } catch (ExecutionException ee) {\n        Throwable rootCause = ee.getCause();\n        if (rootCause instanceof Error) {\n          // low level error, or test assertion failure - either way don't leave it wrapped\n          log.error(\"Worker exec Error, throwing root cause\", ee);\n          throw (Error) rootCause;\n        } else { \n          log.error(\"Worker ExecutionException, re-throwing\", ee);\n          throw ee;\n        }\n      }\n    }\n\n    assertEquals(\"Abort latch has changed, why didn't we get an exception from a worker?\",\n                 1L, abortLatch.getCount());\n    \n    TestInjection.reset();\n    waitForRecoveriesToFinish(CLOUD_CLIENT);\n\n    // check all the final index contents match our expectations\n    int incorrectDocs = 0;\n    for (int id = 0; id < numDocsInIndex; id += DOC_ID_INCR) {\n      assert 0 == id % DOC_ID_INCR : \"WTF? \" + id;\n      \n      final long expect = expected[id / DOC_ID_INCR].longValue();\n      \n      final String docId = \"\" + id;\n      \n      // sometimes include an fq on the expected value to ensure the updated values\n      // are \"visible\" for searching\n      final SolrParams p = (0 != TestUtil.nextInt(random(), 0,15))\n        ? params() : params(\"fq\",numericFieldName + \":\\\"\" + expect + \"\\\"\");\n      SolrDocument doc = getRandClient(random()).getById(docId, p);\n      \n      final boolean foundWithFilter = (null != doc);\n      if (! foundWithFilter) {\n        // try again w/o fq to see what it does have\n        doc = getRandClient(random()).getById(docId);\n      }\n      \n      Long actual = (null == doc) ? null : (Long) doc.getFirstValue(numericFieldName);\n      if (actual == null || expect != actual.longValue() || ! foundWithFilter) {\n        log.error(\"docId={}, foundWithFilter={}, expected={}, actual={}\",\n                  docId, foundWithFilter, expect, actual);\n        incorrectDocs++;\n      }\n      \n    }\n    assertEquals(\"Some docs had errors -- check logs\", 0, incorrectDocs);\n  }\n\n","sourceOld":"  public void checkField(final String numericFieldName) throws Exception {\n\n    final CountDownLatch abortLatch = new CountDownLatch(1);\n\n    final int numDocsToCheck = atLeast(37);\n    final int numDocsInIndex = (numDocsToCheck * DOC_ID_INCR);\n    final AtomicLong[] expected = new AtomicLong[numDocsToCheck];\n\n    log.info(\"Testing {}: numDocsToCheck={}, numDocsInIndex={}, incr={}\"\n        , numericFieldName,  numDocsToCheck, numDocsInIndex, DOC_ID_INCR);\n    \n    // seed the index & keep track of what docs exist and with what values\n    for (int id = 0; id < numDocsInIndex; id++) {\n      // NOTE: the field we're mutating is a long, but we seed with a random int,\n      // and we will inc/dec by random smaller ints, to ensure we never over/under flow\n      final int initValue = random().nextInt();\n      SolrInputDocument doc = doc(f(\"id\",\"\"+id), f(numericFieldName, initValue));\n      UpdateResponse rsp = update(doc).process(CLOUD_CLIENT);\n      assertEquals(doc.toString() + \" => \" + rsp.toString(), 0, rsp.getStatus());\n      if (0 == id % DOC_ID_INCR) {\n        expected[(int)(id / DOC_ID_INCR)] = new AtomicLong(initValue);\n      }\n    }\n    assertNotNull(\"Sanity Check no off-by-one in expected init: \", expected[expected.length-1]);\n    \n    \n    // sanity check index contents\n    waitForRecoveriesToFinish(CLOUD_CLIENT);\n    assertEquals(0, CLOUD_CLIENT.commit().getStatus());\n    assertEquals(numDocsInIndex,\n                 CLOUD_CLIENT.query(params(\"q\", \"*:*\")).getResults().getNumFound());\n\n    startTestInjection();\n    \n    // spin up parallel workers to hammer updates\n    List<Future<Worker>> results = new ArrayList<Future<Worker>>(NUM_THREADS);\n    for (int workerId = 0; workerId < NUM_THREADS; workerId++) {\n      Worker worker = new Worker(workerId, expected, abortLatch, new Random(random().nextLong()),\n                                 numericFieldName);\n      // ask for the Worker to be returned in the Future so we can inspect it\n      results.add(EXEC_SERVICE.submit(worker, worker));\n    }\n    // check the results of all our workers\n    for (Future<Worker> r : results) {\n      try {\n        Worker w = r.get();\n        if (! w.getFinishedOk() ) {\n          // quick and dirty sanity check if any workers didn't succeed, but didn't throw an exception either\n          abortLatch.countDown();\n          log.error(\"worker={} didn't finish ok, but didn't throw exception?\", w.workerId);\n        }\n      } catch (ExecutionException ee) {\n        Throwable rootCause = ee.getCause();\n        if (rootCause instanceof Error) {\n          // low level error, or test assertion failure - either way don't leave it wrapped\n          log.error(\"Worker exec Error, throwing root cause\", ee);\n          throw (Error) rootCause;\n        } else { \n          log.error(\"Worker ExecutionException, re-throwing\", ee);\n          throw ee;\n        }\n      }\n    }\n\n    assertEquals(\"Abort latch has changed, why didn't we get an exception from a worker?\",\n                 1L, abortLatch.getCount());\n    \n    TestInjection.reset();\n    waitForRecoveriesToFinish(CLOUD_CLIENT);\n\n    // check all the final index contents match our expectations\n    int incorrectDocs = 0;\n    for (int id = 0; id < numDocsInIndex; id += DOC_ID_INCR) {\n      assert 0 == id % DOC_ID_INCR : \"WTF? \" + id;\n      \n      final long expect = expected[(int)(id / DOC_ID_INCR)].longValue();\n      \n      final String docId = \"\" + id;\n      \n      // sometimes include an fq on the expected value to ensure the updated values\n      // are \"visible\" for searching\n      final SolrParams p = (0 != TestUtil.nextInt(random(), 0,15))\n        ? params() : params(\"fq\",numericFieldName + \":\\\"\" + expect + \"\\\"\");\n      SolrDocument doc = getRandClient(random()).getById(docId, p);\n      \n      final boolean foundWithFilter = (null != doc);\n      if (! foundWithFilter) {\n        // try again w/o fq to see what it does have\n        doc = getRandClient(random()).getById(docId);\n      }\n      \n      Long actual = (null == doc) ? null : (Long) doc.getFirstValue(numericFieldName);\n      if (actual == null || expect != actual.longValue() || ! foundWithFilter) {\n        log.error(\"docId={}, foundWithFilter={}, expected={}, actual={}\",\n                  docId, foundWithFilter, expect, actual);\n        incorrectDocs++;\n      }\n      \n    }\n    assertEquals(\"Some docs had errors -- check logs\", 0, incorrectDocs);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"aa2585c33d5d66a1c837c312221eb55ddb3c4300":["a966532d92cf9ba2856f15a8140151bb6b518e4b"],"0e121d43b5a10f2df530f406f935102656e9c4e8":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","106fbee5a2b8105d0628067f2c65cd0fedfc19e7"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"83870855d82aba6819217abeff5a40779dbb28b4":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","0e121d43b5a10f2df530f406f935102656e9c4e8"],"a966532d92cf9ba2856f15a8140151bb6b518e4b":["76b65cf789129cacd84e977b8f1538aec29e0281"],"106fbee5a2b8105d0628067f2c65cd0fedfc19e7":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"37fad704e160205d96f4297e8bf388ba2dee8398":["0e121d43b5a10f2df530f406f935102656e9c4e8"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","76b65cf789129cacd84e977b8f1538aec29e0281"],"3b013574eedcdbac35dc7e35b0ee616ffc38895d":["0e121d43b5a10f2df530f406f935102656e9c4e8","76b65cf789129cacd84e977b8f1538aec29e0281"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["aa2585c33d5d66a1c837c312221eb55ddb3c4300"],"76b65cf789129cacd84e977b8f1538aec29e0281":["37fad704e160205d96f4297e8bf388ba2dee8398"]},"commit2Childs":{"aa2585c33d5d66a1c837c312221eb55ddb3c4300":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"0e121d43b5a10f2df530f406f935102656e9c4e8":["83870855d82aba6819217abeff5a40779dbb28b4","37fad704e160205d96f4297e8bf388ba2dee8398","3b013574eedcdbac35dc7e35b0ee616ffc38895d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["0e121d43b5a10f2df530f406f935102656e9c4e8","83870855d82aba6819217abeff5a40779dbb28b4","106fbee5a2b8105d0628067f2c65cd0fedfc19e7","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"83870855d82aba6819217abeff5a40779dbb28b4":[],"a966532d92cf9ba2856f15a8140151bb6b518e4b":["aa2585c33d5d66a1c837c312221eb55ddb3c4300"],"106fbee5a2b8105d0628067f2c65cd0fedfc19e7":["0e121d43b5a10f2df530f406f935102656e9c4e8"],"37fad704e160205d96f4297e8bf388ba2dee8398":["76b65cf789129cacd84e977b8f1538aec29e0281"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"3b013574eedcdbac35dc7e35b0ee616ffc38895d":[],"76b65cf789129cacd84e977b8f1538aec29e0281":["a966532d92cf9ba2856f15a8140151bb6b518e4b","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","3b013574eedcdbac35dc7e35b0ee616ffc38895d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["83870855d82aba6819217abeff5a40779dbb28b4","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","3b013574eedcdbac35dc7e35b0ee616ffc38895d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}