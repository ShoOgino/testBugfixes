{"path":"lucene/facet/src/java/org/apache/lucene/facet/search/TopKFacetResultsHandler#heapDescendants(int,Heap[FacetResultNode],MutableFacetResultNode,FacetArrays,int).mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/facet/src/java/org/apache/lucene/facet/search/TopKFacetResultsHandler#heapDescendants(int,Heap[FacetResultNode],MutableFacetResultNode,FacetArrays,int).mjava","pathOld":"modules/facet/src/java/org/apache/lucene/facet/search/TopKFacetResultsHandler#heapDescendants(int,Heap[FacetResultNode],MutableFacetResultNode,FacetArrays,int).mjava","sourceNew":"  /**\n   * Finds the top K descendants of ordinal, which are at most facetRequest.getDepth()\n   * deeper than facetRequest.getCategoryPath (whose ordinal is input parameter ordinal). \n   * Candidates are restricted to current \"counting list\" and current \"partition\",\n   * they join the overall priority queue pq of size K.  \n   * @return total number of descendants considered here by pq, excluding ordinal itself.\n   */\n  private int heapDescendants(int ordinal, Heap<FacetResultNode> pq,\n      MutableFacetResultNode parentResultNode, FacetArrays facetArrays, int offset) {\n    int partitionSize = facetArrays.getArraysLength();\n    int endOffset = offset + partitionSize;\n    ChildrenArrays childrenArray = taxonomyReader.getChildrenArrays();\n    int[] youngestChild = childrenArray.getYoungestChildArray();\n    int[] olderSibling = childrenArray.getOlderSiblingArray();\n    FacetResultNode reusable = null;\n    int localDepth = 0;\n    int depth = facetRequest.getDepth();\n    int[] ordinalStack = new int[2+Math.min(Short.MAX_VALUE, depth)];\n    int childrenCounter = 0;\n    \n    int tosOrdinal; // top of stack element\n    \n    int yc = youngestChild[ordinal];\n    while (yc >= endOffset) {\n      yc = olderSibling[yc];\n    }\n    // make use of the fact that TaxonomyReader.INVALID_ORDINAL == -1, < endOffset\n    // and it, too, can stop the loop.\n    ordinalStack[++localDepth] = yc;\n    \n    /*\n     * stack holds input parameter ordinal in position 0.\n     * Other elements are < endoffset.\n     * Only top of stack can be TaxonomyReader.INVALID_ORDINAL, and this if and only if\n     * the element below it exhausted all its children: has them all processed.\n     * \n     * stack elements are processed (counted and accumulated) only if they \n     * belong to current partition (between offset and endoffset) and first time\n     * they are on top of stack \n     * \n     * loop as long as stack is not empty of elements other than input ordinal, or for a little while -- it sibling\n     */\n    while (localDepth > 0) {\n      tosOrdinal = ordinalStack[localDepth];\n      if (tosOrdinal == TaxonomyReader.INVALID_ORDINAL) {\n        // element below tos has all its children, and itself, all processed\n        // need to proceed to its sibling\n        localDepth--;\n        // change element now on top of stack to its sibling.\n        ordinalStack[localDepth] = olderSibling[ordinalStack[localDepth]];\n        continue;\n      }\n      // top of stack is not invalid, this is the first time we see it on top of stack.\n      // collect it, if belongs to current partition, and then push its kids on itself, if applicable\n      if (tosOrdinal >= offset) { // tosOrdinal resides in current partition\n        int relativeOrdinal = tosOrdinal % partitionSize;\n        double value = facetRequest.getValueOf(facetArrays, relativeOrdinal);\n        if (value != 0 && !Double.isNaN(value)) {\n          // Count current ordinal -- the TOS\n          if (reusable == null) {\n            reusable = new MutableFacetResultNode(tosOrdinal, value);\n          } else {\n            // it is safe to cast since reusable was created here.\n            ((MutableFacetResultNode)reusable).reset(tosOrdinal, value);\n          }\n          ++childrenCounter;\n          reusable = pq.insertWithOverflow(reusable);\n          if (reusable != null) {\n            // TODO (Facet): is other logic (not add) needed, per aggregator?\n            parentResultNode.increaseResidue(reusable.getValue());\n          }\n        }\n      }\n      if (localDepth < depth) {\n        // push kid of current tos\n        yc = youngestChild[tosOrdinal];\n        while (yc >= endOffset) {\n          yc = olderSibling[yc];\n        }\n        ordinalStack[++localDepth] = yc;\n      } else { // localDepth == depth; current tos exhausted its possible children, mark this by pushing INVALID_ORDINAL\n        ordinalStack[++localDepth] = TaxonomyReader.INVALID_ORDINAL;\n      }\n    } // endof while stack is not empty\n    \n    return childrenCounter; // we're done\n  }\n\n","sourceOld":"  /**\n   * Finds the top K descendants of ordinal, which are at most facetRequest.getDepth()\n   * deeper than facetRequest.getCategoryPath (whose ordinal is input parameter ordinal). \n   * Candidates are restricted to current \"counting list\" and current \"partition\",\n   * they join the overall priority queue pq of size K.  \n   * @return total number of descendants considered here by pq, excluding ordinal itself.\n   */\n  private int heapDescendants(int ordinal, Heap<FacetResultNode> pq,\n      MutableFacetResultNode parentResultNode, FacetArrays facetArrays, int offset) {\n    int partitionSize = facetArrays.getArraysLength();\n    int endOffset = offset + partitionSize;\n    ChildrenArrays childrenArray = taxonomyReader.getChildrenArrays();\n    int[] youngestChild = childrenArray.getYoungestChildArray();\n    int[] olderSibling = childrenArray.getOlderSiblingArray();\n    FacetResultNode reusable = null;\n    int localDepth = 0;\n    int depth = facetRequest.getDepth();\n    int[] ordinalStack = new int[2+Math.min(Short.MAX_VALUE, depth)];\n    int childrenCounter = 0;\n    \n    int tosOrdinal; // top of stack element\n    \n    int yc = youngestChild[ordinal];\n    while (yc >= endOffset) {\n      yc = olderSibling[yc];\n    }\n    // make use of the fact that TaxonomyReader.INVALID_ORDINAL == -1, < endOffset\n    // and it, too, can stop the loop.\n    ordinalStack[++localDepth] = yc;\n    \n    /*\n     * stack holds input parameter ordinal in position 0.\n     * Other elements are < endoffset.\n     * Only top of stack can be TaxonomyReader.INVALID_ORDINAL, and this if and only if\n     * the element below it exhausted all its children: has them all processed.\n     * \n     * stack elements are processed (counted and accumulated) only if they \n     * belong to current partition (between offset and endoffset) and first time\n     * they are on top of stack \n     * \n     * loop as long as stack is not empty of elements other than input ordinal, or for a little while -- it sibling\n     */\n    while (localDepth > 0) {\n      tosOrdinal = ordinalStack[localDepth];\n      if (tosOrdinal == TaxonomyReader.INVALID_ORDINAL) {\n        // element below tos has all its children, and itself, all processed\n        // need to proceed to its sibling\n        localDepth--;\n        // change element now on top of stack to its sibling.\n        ordinalStack[localDepth] = olderSibling[ordinalStack[localDepth]];\n        continue;\n      }\n      // top of stack is not invalid, this is the first time we see it on top of stack.\n      // collect it, if belongs to current partition, and then push its kids on itself, if applicable\n      if (tosOrdinal >= offset) { // tosOrdinal resides in current partition\n        int relativeOrdinal = tosOrdinal % partitionSize;\n        double value = facetRequest.getValueOf(facetArrays, relativeOrdinal);\n        if (value != 0 && !Double.isNaN(value)) {\n          // Count current ordinal -- the TOS\n          if (reusable == null) {\n            reusable = new MutableFacetResultNode(tosOrdinal, value);\n          } else {\n            // it is safe to cast since reusable was created here.\n            ((MutableFacetResultNode)reusable).reset(tosOrdinal, value);\n          }\n          ++childrenCounter;\n          reusable = pq.insertWithOverflow(reusable);\n          if (reusable != null) {\n            // TODO (Facet): is other logic (not add) needed, per aggregator?\n            parentResultNode.increaseResidue(reusable.getValue());\n          }\n        }\n      }\n      if (localDepth < depth) {\n        // push kid of current tos\n        yc = youngestChild[tosOrdinal];\n        while (yc >= endOffset) {\n          yc = olderSibling[yc];\n        }\n        ordinalStack[++localDepth] = yc;\n      } else { // localDepth == depth; current tos exhausted its possible children, mark this by pushing INVALID_ORDINAL\n        ordinalStack[++localDepth] = TaxonomyReader.INVALID_ORDINAL;\n      }\n    } // endof while stack is not empty\n    \n    return childrenCounter; // we're done\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"219dcddcdf2fc13f6271d9e5836bd19c53a4abf1","date":1353511594,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/facet/src/java/org/apache/lucene/facet/search/TopKFacetResultsHandler#heapDescendants(int,Heap[FacetResultNode],MutableFacetResultNode,FacetArrays,int).mjava","pathOld":"lucene/facet/src/java/org/apache/lucene/facet/search/TopKFacetResultsHandler#heapDescendants(int,Heap[FacetResultNode],MutableFacetResultNode,FacetArrays,int).mjava","sourceNew":"  /**\n   * Finds the top K descendants of ordinal, which are at most facetRequest.getDepth()\n   * deeper than facetRequest.getCategoryPath (whose ordinal is input parameter ordinal). \n   * Candidates are restricted to current \"counting list\" and current \"partition\",\n   * they join the overall priority queue pq of size K.  \n   * @return total number of descendants considered here by pq, excluding ordinal itself.\n   */\n  private int heapDescendants(int ordinal, Heap<FacetResultNode> pq,\n      MutableFacetResultNode parentResultNode, FacetArrays facetArrays, int offset) throws IOException {\n    int partitionSize = facetArrays.getArraysLength();\n    int endOffset = offset + partitionSize;\n    ChildrenArrays childrenArray = taxonomyReader.getChildrenArrays();\n    int[] youngestChild = childrenArray.getYoungestChildArray();\n    int[] olderSibling = childrenArray.getOlderSiblingArray();\n    FacetResultNode reusable = null;\n    int localDepth = 0;\n    int depth = facetRequest.getDepth();\n    int[] ordinalStack = new int[2+Math.min(Short.MAX_VALUE, depth)];\n    int childrenCounter = 0;\n    \n    int tosOrdinal; // top of stack element\n    \n    int yc = youngestChild[ordinal];\n    while (yc >= endOffset) {\n      yc = olderSibling[yc];\n    }\n    // make use of the fact that TaxonomyReader.INVALID_ORDINAL == -1, < endOffset\n    // and it, too, can stop the loop.\n    ordinalStack[++localDepth] = yc;\n    \n    /*\n     * stack holds input parameter ordinal in position 0.\n     * Other elements are < endoffset.\n     * Only top of stack can be TaxonomyReader.INVALID_ORDINAL, and this if and only if\n     * the element below it exhausted all its children: has them all processed.\n     * \n     * stack elements are processed (counted and accumulated) only if they \n     * belong to current partition (between offset and endoffset) and first time\n     * they are on top of stack \n     * \n     * loop as long as stack is not empty of elements other than input ordinal, or for a little while -- it sibling\n     */\n    while (localDepth > 0) {\n      tosOrdinal = ordinalStack[localDepth];\n      if (tosOrdinal == TaxonomyReader.INVALID_ORDINAL) {\n        // element below tos has all its children, and itself, all processed\n        // need to proceed to its sibling\n        localDepth--;\n        // change element now on top of stack to its sibling.\n        ordinalStack[localDepth] = olderSibling[ordinalStack[localDepth]];\n        continue;\n      }\n      // top of stack is not invalid, this is the first time we see it on top of stack.\n      // collect it, if belongs to current partition, and then push its kids on itself, if applicable\n      if (tosOrdinal >= offset) { // tosOrdinal resides in current partition\n        int relativeOrdinal = tosOrdinal % partitionSize;\n        double value = facetRequest.getValueOf(facetArrays, relativeOrdinal);\n        if (value != 0 && !Double.isNaN(value)) {\n          // Count current ordinal -- the TOS\n          if (reusable == null) {\n            reusable = new MutableFacetResultNode(tosOrdinal, value);\n          } else {\n            // it is safe to cast since reusable was created here.\n            ((MutableFacetResultNode)reusable).reset(tosOrdinal, value);\n          }\n          ++childrenCounter;\n          reusable = pq.insertWithOverflow(reusable);\n          if (reusable != null) {\n            // TODO (Facet): is other logic (not add) needed, per aggregator?\n            parentResultNode.increaseResidue(reusable.getValue());\n          }\n        }\n      }\n      if (localDepth < depth) {\n        // push kid of current tos\n        yc = youngestChild[tosOrdinal];\n        while (yc >= endOffset) {\n          yc = olderSibling[yc];\n        }\n        ordinalStack[++localDepth] = yc;\n      } else { // localDepth == depth; current tos exhausted its possible children, mark this by pushing INVALID_ORDINAL\n        ordinalStack[++localDepth] = TaxonomyReader.INVALID_ORDINAL;\n      }\n    } // endof while stack is not empty\n    \n    return childrenCounter; // we're done\n  }\n\n","sourceOld":"  /**\n   * Finds the top K descendants of ordinal, which are at most facetRequest.getDepth()\n   * deeper than facetRequest.getCategoryPath (whose ordinal is input parameter ordinal). \n   * Candidates are restricted to current \"counting list\" and current \"partition\",\n   * they join the overall priority queue pq of size K.  \n   * @return total number of descendants considered here by pq, excluding ordinal itself.\n   */\n  private int heapDescendants(int ordinal, Heap<FacetResultNode> pq,\n      MutableFacetResultNode parentResultNode, FacetArrays facetArrays, int offset) {\n    int partitionSize = facetArrays.getArraysLength();\n    int endOffset = offset + partitionSize;\n    ChildrenArrays childrenArray = taxonomyReader.getChildrenArrays();\n    int[] youngestChild = childrenArray.getYoungestChildArray();\n    int[] olderSibling = childrenArray.getOlderSiblingArray();\n    FacetResultNode reusable = null;\n    int localDepth = 0;\n    int depth = facetRequest.getDepth();\n    int[] ordinalStack = new int[2+Math.min(Short.MAX_VALUE, depth)];\n    int childrenCounter = 0;\n    \n    int tosOrdinal; // top of stack element\n    \n    int yc = youngestChild[ordinal];\n    while (yc >= endOffset) {\n      yc = olderSibling[yc];\n    }\n    // make use of the fact that TaxonomyReader.INVALID_ORDINAL == -1, < endOffset\n    // and it, too, can stop the loop.\n    ordinalStack[++localDepth] = yc;\n    \n    /*\n     * stack holds input parameter ordinal in position 0.\n     * Other elements are < endoffset.\n     * Only top of stack can be TaxonomyReader.INVALID_ORDINAL, and this if and only if\n     * the element below it exhausted all its children: has them all processed.\n     * \n     * stack elements are processed (counted and accumulated) only if they \n     * belong to current partition (between offset and endoffset) and first time\n     * they are on top of stack \n     * \n     * loop as long as stack is not empty of elements other than input ordinal, or for a little while -- it sibling\n     */\n    while (localDepth > 0) {\n      tosOrdinal = ordinalStack[localDepth];\n      if (tosOrdinal == TaxonomyReader.INVALID_ORDINAL) {\n        // element below tos has all its children, and itself, all processed\n        // need to proceed to its sibling\n        localDepth--;\n        // change element now on top of stack to its sibling.\n        ordinalStack[localDepth] = olderSibling[ordinalStack[localDepth]];\n        continue;\n      }\n      // top of stack is not invalid, this is the first time we see it on top of stack.\n      // collect it, if belongs to current partition, and then push its kids on itself, if applicable\n      if (tosOrdinal >= offset) { // tosOrdinal resides in current partition\n        int relativeOrdinal = tosOrdinal % partitionSize;\n        double value = facetRequest.getValueOf(facetArrays, relativeOrdinal);\n        if (value != 0 && !Double.isNaN(value)) {\n          // Count current ordinal -- the TOS\n          if (reusable == null) {\n            reusable = new MutableFacetResultNode(tosOrdinal, value);\n          } else {\n            // it is safe to cast since reusable was created here.\n            ((MutableFacetResultNode)reusable).reset(tosOrdinal, value);\n          }\n          ++childrenCounter;\n          reusable = pq.insertWithOverflow(reusable);\n          if (reusable != null) {\n            // TODO (Facet): is other logic (not add) needed, per aggregator?\n            parentResultNode.increaseResidue(reusable.getValue());\n          }\n        }\n      }\n      if (localDepth < depth) {\n        // push kid of current tos\n        yc = youngestChild[tosOrdinal];\n        while (yc >= endOffset) {\n          yc = olderSibling[yc];\n        }\n        ordinalStack[++localDepth] = yc;\n      } else { // localDepth == depth; current tos exhausted its possible children, mark this by pushing INVALID_ORDINAL\n        ordinalStack[++localDepth] = TaxonomyReader.INVALID_ORDINAL;\n      }\n    } // endof while stack is not empty\n    \n    return childrenCounter; // we're done\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3d58d08788c3fd51172ba34474cca42499d6391b","date":1354802133,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/facet/src/java/org/apache/lucene/facet/search/TopKFacetResultsHandler#heapDescendants(int,Heap[FacetResultNode],MutableFacetResultNode,FacetArrays,int).mjava","pathOld":"lucene/facet/src/java/org/apache/lucene/facet/search/TopKFacetResultsHandler#heapDescendants(int,Heap[FacetResultNode],MutableFacetResultNode,FacetArrays,int).mjava","sourceNew":"  /**\n   * Finds the top K descendants of ordinal, which are at most facetRequest.getDepth()\n   * deeper than facetRequest.getCategoryPath (whose ordinal is input parameter ordinal). \n   * Candidates are restricted to current \"counting list\" and current \"partition\",\n   * they join the overall priority queue pq of size K.  \n   * @return total number of descendants considered here by pq, excluding ordinal itself.\n   */\n  private int heapDescendants(int ordinal, Heap<FacetResultNode> pq,\n      MutableFacetResultNode parentResultNode, FacetArrays facetArrays, int offset) throws IOException {\n    int partitionSize = facetArrays.getArraysLength();\n    int endOffset = offset + partitionSize;\n    ParallelTaxonomyArrays childrenArray = taxonomyReader.getParallelTaxonomyArrays();\n    int[] children = childrenArray.children();\n    int[] siblings = childrenArray.siblings();\n    FacetResultNode reusable = null;\n    int localDepth = 0;\n    int depth = facetRequest.getDepth();\n    int[] ordinalStack = new int[2+Math.min(Short.MAX_VALUE, depth)];\n    int childrenCounter = 0;\n    \n    int tosOrdinal; // top of stack element\n    \n    int yc = children[ordinal];\n    while (yc >= endOffset) {\n      yc = siblings[yc];\n    }\n    // make use of the fact that TaxonomyReader.INVALID_ORDINAL == -1, < endOffset\n    // and it, too, can stop the loop.\n    ordinalStack[++localDepth] = yc;\n    \n    /*\n     * stack holds input parameter ordinal in position 0.\n     * Other elements are < endoffset.\n     * Only top of stack can be TaxonomyReader.INVALID_ORDINAL, and this if and only if\n     * the element below it exhausted all its children: has them all processed.\n     * \n     * stack elements are processed (counted and accumulated) only if they \n     * belong to current partition (between offset and endoffset) and first time\n     * they are on top of stack \n     * \n     * loop as long as stack is not empty of elements other than input ordinal, or for a little while -- it sibling\n     */\n    while (localDepth > 0) {\n      tosOrdinal = ordinalStack[localDepth];\n      if (tosOrdinal == TaxonomyReader.INVALID_ORDINAL) {\n        // element below tos has all its children, and itself, all processed\n        // need to proceed to its sibling\n        localDepth--;\n        // change element now on top of stack to its sibling.\n        ordinalStack[localDepth] = siblings[ordinalStack[localDepth]];\n        continue;\n      }\n      // top of stack is not invalid, this is the first time we see it on top of stack.\n      // collect it, if belongs to current partition, and then push its kids on itself, if applicable\n      if (tosOrdinal >= offset) { // tosOrdinal resides in current partition\n        int relativeOrdinal = tosOrdinal % partitionSize;\n        double value = facetRequest.getValueOf(facetArrays, relativeOrdinal);\n        if (value != 0 && !Double.isNaN(value)) {\n          // Count current ordinal -- the TOS\n          if (reusable == null) {\n            reusable = new MutableFacetResultNode(tosOrdinal, value);\n          } else {\n            // it is safe to cast since reusable was created here.\n            ((MutableFacetResultNode)reusable).reset(tosOrdinal, value);\n          }\n          ++childrenCounter;\n          reusable = pq.insertWithOverflow(reusable);\n          if (reusable != null) {\n            // TODO (Facet): is other logic (not add) needed, per aggregator?\n            parentResultNode.increaseResidue(reusable.getValue());\n          }\n        }\n      }\n      if (localDepth < depth) {\n        // push kid of current tos\n        yc = children[tosOrdinal];\n        while (yc >= endOffset) {\n          yc = siblings[yc];\n        }\n        ordinalStack[++localDepth] = yc;\n      } else { // localDepth == depth; current tos exhausted its possible children, mark this by pushing INVALID_ORDINAL\n        ordinalStack[++localDepth] = TaxonomyReader.INVALID_ORDINAL;\n      }\n    } // endof while stack is not empty\n    \n    return childrenCounter; // we're done\n  }\n\n","sourceOld":"  /**\n   * Finds the top K descendants of ordinal, which are at most facetRequest.getDepth()\n   * deeper than facetRequest.getCategoryPath (whose ordinal is input parameter ordinal). \n   * Candidates are restricted to current \"counting list\" and current \"partition\",\n   * they join the overall priority queue pq of size K.  \n   * @return total number of descendants considered here by pq, excluding ordinal itself.\n   */\n  private int heapDescendants(int ordinal, Heap<FacetResultNode> pq,\n      MutableFacetResultNode parentResultNode, FacetArrays facetArrays, int offset) throws IOException {\n    int partitionSize = facetArrays.getArraysLength();\n    int endOffset = offset + partitionSize;\n    ChildrenArrays childrenArray = taxonomyReader.getChildrenArrays();\n    int[] youngestChild = childrenArray.getYoungestChildArray();\n    int[] olderSibling = childrenArray.getOlderSiblingArray();\n    FacetResultNode reusable = null;\n    int localDepth = 0;\n    int depth = facetRequest.getDepth();\n    int[] ordinalStack = new int[2+Math.min(Short.MAX_VALUE, depth)];\n    int childrenCounter = 0;\n    \n    int tosOrdinal; // top of stack element\n    \n    int yc = youngestChild[ordinal];\n    while (yc >= endOffset) {\n      yc = olderSibling[yc];\n    }\n    // make use of the fact that TaxonomyReader.INVALID_ORDINAL == -1, < endOffset\n    // and it, too, can stop the loop.\n    ordinalStack[++localDepth] = yc;\n    \n    /*\n     * stack holds input parameter ordinal in position 0.\n     * Other elements are < endoffset.\n     * Only top of stack can be TaxonomyReader.INVALID_ORDINAL, and this if and only if\n     * the element below it exhausted all its children: has them all processed.\n     * \n     * stack elements are processed (counted and accumulated) only if they \n     * belong to current partition (between offset and endoffset) and first time\n     * they are on top of stack \n     * \n     * loop as long as stack is not empty of elements other than input ordinal, or for a little while -- it sibling\n     */\n    while (localDepth > 0) {\n      tosOrdinal = ordinalStack[localDepth];\n      if (tosOrdinal == TaxonomyReader.INVALID_ORDINAL) {\n        // element below tos has all its children, and itself, all processed\n        // need to proceed to its sibling\n        localDepth--;\n        // change element now on top of stack to its sibling.\n        ordinalStack[localDepth] = olderSibling[ordinalStack[localDepth]];\n        continue;\n      }\n      // top of stack is not invalid, this is the first time we see it on top of stack.\n      // collect it, if belongs to current partition, and then push its kids on itself, if applicable\n      if (tosOrdinal >= offset) { // tosOrdinal resides in current partition\n        int relativeOrdinal = tosOrdinal % partitionSize;\n        double value = facetRequest.getValueOf(facetArrays, relativeOrdinal);\n        if (value != 0 && !Double.isNaN(value)) {\n          // Count current ordinal -- the TOS\n          if (reusable == null) {\n            reusable = new MutableFacetResultNode(tosOrdinal, value);\n          } else {\n            // it is safe to cast since reusable was created here.\n            ((MutableFacetResultNode)reusable).reset(tosOrdinal, value);\n          }\n          ++childrenCounter;\n          reusable = pq.insertWithOverflow(reusable);\n          if (reusable != null) {\n            // TODO (Facet): is other logic (not add) needed, per aggregator?\n            parentResultNode.increaseResidue(reusable.getValue());\n          }\n        }\n      }\n      if (localDepth < depth) {\n        // push kid of current tos\n        yc = youngestChild[tosOrdinal];\n        while (yc >= endOffset) {\n          yc = olderSibling[yc];\n        }\n        ordinalStack[++localDepth] = yc;\n      } else { // localDepth == depth; current tos exhausted its possible children, mark this by pushing INVALID_ORDINAL\n        ordinalStack[++localDepth] = TaxonomyReader.INVALID_ORDINAL;\n      }\n    } // endof while stack is not empty\n    \n    return childrenCounter; // we're done\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"407687e67faf6e1f02a211ca078d8e3eed631027","date":1355157407,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/facet/src/java/org/apache/lucene/facet/search/TopKFacetResultsHandler#heapDescendants(int,Heap[FacetResultNode],MutableFacetResultNode,FacetArrays,int).mjava","pathOld":"lucene/facet/src/java/org/apache/lucene/facet/search/TopKFacetResultsHandler#heapDescendants(int,Heap[FacetResultNode],MutableFacetResultNode,FacetArrays,int).mjava","sourceNew":"  /**\n   * Finds the top K descendants of ordinal, which are at most facetRequest.getDepth()\n   * deeper than facetRequest.getCategoryPath (whose ordinal is input parameter ordinal). \n   * Candidates are restricted to current \"counting list\" and current \"partition\",\n   * they join the overall priority queue pq of size K.  \n   * @return total number of descendants considered here by pq, excluding ordinal itself.\n   */\n  private int heapDescendants(int ordinal, Heap<FacetResultNode> pq,\n      MutableFacetResultNode parentResultNode, FacetArrays facetArrays, int offset) throws IOException {\n    int partitionSize = facetArrays.getArraysLength();\n    int endOffset = offset + partitionSize;\n    ParallelTaxonomyArrays childrenArray = taxonomyReader.getParallelTaxonomyArrays();\n    int[] children = childrenArray.children();\n    int[] siblings = childrenArray.siblings();\n    FacetResultNode reusable = null;\n    int localDepth = 0;\n    int depth = facetRequest.getDepth();\n    int[] ordinalStack = new int[2+Math.min(Short.MAX_VALUE, depth)];\n    int childrenCounter = 0;\n    \n    int tosOrdinal; // top of stack element\n    \n    int yc = children[ordinal];\n    while (yc >= endOffset) {\n      yc = siblings[yc];\n    }\n    // make use of the fact that TaxonomyReader.INVALID_ORDINAL == -1, < endOffset\n    // and it, too, can stop the loop.\n    ordinalStack[++localDepth] = yc;\n    \n    /*\n     * stack holds input parameter ordinal in position 0.\n     * Other elements are < endoffset.\n     * Only top of stack can be TaxonomyReader.INVALID_ORDINAL, and this if and only if\n     * the element below it exhausted all its children: has them all processed.\n     * \n     * stack elements are processed (counted and accumulated) only if they \n     * belong to current partition (between offset and endoffset) and first time\n     * they are on top of stack \n     * \n     * loop as long as stack is not empty of elements other than input ordinal, or for a little while -- it sibling\n     */\n    while (localDepth > 0) {\n      tosOrdinal = ordinalStack[localDepth];\n      if (tosOrdinal == TaxonomyReader.INVALID_ORDINAL) {\n        // element below tos has all its children, and itself, all processed\n        // need to proceed to its sibling\n        localDepth--;\n        // change element now on top of stack to its sibling.\n        ordinalStack[localDepth] = siblings[ordinalStack[localDepth]];\n        continue;\n      }\n      // top of stack is not invalid, this is the first time we see it on top of stack.\n      // collect it, if belongs to current partition, and then push its kids on itself, if applicable\n      if (tosOrdinal >= offset) { // tosOrdinal resides in current partition\n        int relativeOrdinal = tosOrdinal % partitionSize;\n        double value = facetRequest.getValueOf(facetArrays, relativeOrdinal);\n        if (value != 0 && !Double.isNaN(value)) {\n          // Count current ordinal -- the TOS\n          if (reusable == null) {\n            reusable = new MutableFacetResultNode(tosOrdinal, value);\n          } else {\n            // it is safe to cast since reusable was created here.\n            ((MutableFacetResultNode)reusable).reset(tosOrdinal, value);\n          }\n          ++childrenCounter;\n          reusable = pq.insertWithOverflow(reusable);\n          if (reusable != null) {\n            // TODO (Facet): is other logic (not add) needed, per aggregator?\n            parentResultNode.increaseResidue(reusable.getValue());\n          }\n        }\n      }\n      if (localDepth < depth) {\n        // push kid of current tos\n        yc = children[tosOrdinal];\n        while (yc >= endOffset) {\n          yc = siblings[yc];\n        }\n        ordinalStack[++localDepth] = yc;\n      } else { // localDepth == depth; current tos exhausted its possible children, mark this by pushing INVALID_ORDINAL\n        ordinalStack[++localDepth] = TaxonomyReader.INVALID_ORDINAL;\n      }\n    } // endof while stack is not empty\n    \n    return childrenCounter; // we're done\n  }\n\n","sourceOld":"  /**\n   * Finds the top K descendants of ordinal, which are at most facetRequest.getDepth()\n   * deeper than facetRequest.getCategoryPath (whose ordinal is input parameter ordinal). \n   * Candidates are restricted to current \"counting list\" and current \"partition\",\n   * they join the overall priority queue pq of size K.  \n   * @return total number of descendants considered here by pq, excluding ordinal itself.\n   */\n  private int heapDescendants(int ordinal, Heap<FacetResultNode> pq,\n      MutableFacetResultNode parentResultNode, FacetArrays facetArrays, int offset) {\n    int partitionSize = facetArrays.getArraysLength();\n    int endOffset = offset + partitionSize;\n    ChildrenArrays childrenArray = taxonomyReader.getChildrenArrays();\n    int[] youngestChild = childrenArray.getYoungestChildArray();\n    int[] olderSibling = childrenArray.getOlderSiblingArray();\n    FacetResultNode reusable = null;\n    int localDepth = 0;\n    int depth = facetRequest.getDepth();\n    int[] ordinalStack = new int[2+Math.min(Short.MAX_VALUE, depth)];\n    int childrenCounter = 0;\n    \n    int tosOrdinal; // top of stack element\n    \n    int yc = youngestChild[ordinal];\n    while (yc >= endOffset) {\n      yc = olderSibling[yc];\n    }\n    // make use of the fact that TaxonomyReader.INVALID_ORDINAL == -1, < endOffset\n    // and it, too, can stop the loop.\n    ordinalStack[++localDepth] = yc;\n    \n    /*\n     * stack holds input parameter ordinal in position 0.\n     * Other elements are < endoffset.\n     * Only top of stack can be TaxonomyReader.INVALID_ORDINAL, and this if and only if\n     * the element below it exhausted all its children: has them all processed.\n     * \n     * stack elements are processed (counted and accumulated) only if they \n     * belong to current partition (between offset and endoffset) and first time\n     * they are on top of stack \n     * \n     * loop as long as stack is not empty of elements other than input ordinal, or for a little while -- it sibling\n     */\n    while (localDepth > 0) {\n      tosOrdinal = ordinalStack[localDepth];\n      if (tosOrdinal == TaxonomyReader.INVALID_ORDINAL) {\n        // element below tos has all its children, and itself, all processed\n        // need to proceed to its sibling\n        localDepth--;\n        // change element now on top of stack to its sibling.\n        ordinalStack[localDepth] = olderSibling[ordinalStack[localDepth]];\n        continue;\n      }\n      // top of stack is not invalid, this is the first time we see it on top of stack.\n      // collect it, if belongs to current partition, and then push its kids on itself, if applicable\n      if (tosOrdinal >= offset) { // tosOrdinal resides in current partition\n        int relativeOrdinal = tosOrdinal % partitionSize;\n        double value = facetRequest.getValueOf(facetArrays, relativeOrdinal);\n        if (value != 0 && !Double.isNaN(value)) {\n          // Count current ordinal -- the TOS\n          if (reusable == null) {\n            reusable = new MutableFacetResultNode(tosOrdinal, value);\n          } else {\n            // it is safe to cast since reusable was created here.\n            ((MutableFacetResultNode)reusable).reset(tosOrdinal, value);\n          }\n          ++childrenCounter;\n          reusable = pq.insertWithOverflow(reusable);\n          if (reusable != null) {\n            // TODO (Facet): is other logic (not add) needed, per aggregator?\n            parentResultNode.increaseResidue(reusable.getValue());\n          }\n        }\n      }\n      if (localDepth < depth) {\n        // push kid of current tos\n        yc = youngestChild[tosOrdinal];\n        while (yc >= endOffset) {\n          yc = olderSibling[yc];\n        }\n        ordinalStack[++localDepth] = yc;\n      } else { // localDepth == depth; current tos exhausted its possible children, mark this by pushing INVALID_ORDINAL\n        ordinalStack[++localDepth] = TaxonomyReader.INVALID_ORDINAL;\n      }\n    } // endof while stack is not empty\n    \n    return childrenCounter; // we're done\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2a2548b7f050533ac9a884b31cab5fb6f0386fbb","date":1355233860,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/facet/src/java/org/apache/lucene/facet/search/TopKFacetResultsHandler#heapDescendants(int,Heap[FacetResultNode],MutableFacetResultNode,FacetArrays,int).mjava","pathOld":"lucene/facet/src/java/org/apache/lucene/facet/search/TopKFacetResultsHandler#heapDescendants(int,Heap[FacetResultNode],MutableFacetResultNode,FacetArrays,int).mjava","sourceNew":"  /**\n   * Finds the top K descendants of ordinal, which are at most facetRequest.getDepth()\n   * deeper than facetRequest.getCategoryPath (whose ordinal is input parameter ordinal). \n   * Candidates are restricted to current \"counting list\" and current \"partition\",\n   * they join the overall priority queue pq of size K.  \n   * @return total number of descendants considered here by pq, excluding ordinal itself.\n   */\n  private int heapDescendants(int ordinal, Heap<FacetResultNode> pq,\n      MutableFacetResultNode parentResultNode, FacetArrays facetArrays, int offset) throws IOException {\n    int partitionSize = facetArrays.arrayLength;\n    int endOffset = offset + partitionSize;\n    ParallelTaxonomyArrays childrenArray = taxonomyReader.getParallelTaxonomyArrays();\n    int[] children = childrenArray.children();\n    int[] siblings = childrenArray.siblings();\n    FacetResultNode reusable = null;\n    int localDepth = 0;\n    int depth = facetRequest.getDepth();\n    int[] ordinalStack = new int[2+Math.min(Short.MAX_VALUE, depth)];\n    int childrenCounter = 0;\n    \n    int tosOrdinal; // top of stack element\n    \n    int yc = children[ordinal];\n    while (yc >= endOffset) {\n      yc = siblings[yc];\n    }\n    // make use of the fact that TaxonomyReader.INVALID_ORDINAL == -1, < endOffset\n    // and it, too, can stop the loop.\n    ordinalStack[++localDepth] = yc;\n    \n    /*\n     * stack holds input parameter ordinal in position 0.\n     * Other elements are < endoffset.\n     * Only top of stack can be TaxonomyReader.INVALID_ORDINAL, and this if and only if\n     * the element below it exhausted all its children: has them all processed.\n     * \n     * stack elements are processed (counted and accumulated) only if they \n     * belong to current partition (between offset and endoffset) and first time\n     * they are on top of stack \n     * \n     * loop as long as stack is not empty of elements other than input ordinal, or for a little while -- it sibling\n     */\n    while (localDepth > 0) {\n      tosOrdinal = ordinalStack[localDepth];\n      if (tosOrdinal == TaxonomyReader.INVALID_ORDINAL) {\n        // element below tos has all its children, and itself, all processed\n        // need to proceed to its sibling\n        localDepth--;\n        // change element now on top of stack to its sibling.\n        ordinalStack[localDepth] = siblings[ordinalStack[localDepth]];\n        continue;\n      }\n      // top of stack is not invalid, this is the first time we see it on top of stack.\n      // collect it, if belongs to current partition, and then push its kids on itself, if applicable\n      if (tosOrdinal >= offset) { // tosOrdinal resides in current partition\n        int relativeOrdinal = tosOrdinal % partitionSize;\n        double value = facetRequest.getValueOf(facetArrays, relativeOrdinal);\n        if (value != 0 && !Double.isNaN(value)) {\n          // Count current ordinal -- the TOS\n          if (reusable == null) {\n            reusable = new MutableFacetResultNode(tosOrdinal, value);\n          } else {\n            // it is safe to cast since reusable was created here.\n            ((MutableFacetResultNode)reusable).reset(tosOrdinal, value);\n          }\n          ++childrenCounter;\n          reusable = pq.insertWithOverflow(reusable);\n          if (reusable != null) {\n            // TODO (Facet): is other logic (not add) needed, per aggregator?\n            parentResultNode.increaseResidue(reusable.getValue());\n          }\n        }\n      }\n      if (localDepth < depth) {\n        // push kid of current tos\n        yc = children[tosOrdinal];\n        while (yc >= endOffset) {\n          yc = siblings[yc];\n        }\n        ordinalStack[++localDepth] = yc;\n      } else { // localDepth == depth; current tos exhausted its possible children, mark this by pushing INVALID_ORDINAL\n        ordinalStack[++localDepth] = TaxonomyReader.INVALID_ORDINAL;\n      }\n    } // endof while stack is not empty\n    \n    return childrenCounter; // we're done\n  }\n\n","sourceOld":"  /**\n   * Finds the top K descendants of ordinal, which are at most facetRequest.getDepth()\n   * deeper than facetRequest.getCategoryPath (whose ordinal is input parameter ordinal). \n   * Candidates are restricted to current \"counting list\" and current \"partition\",\n   * they join the overall priority queue pq of size K.  \n   * @return total number of descendants considered here by pq, excluding ordinal itself.\n   */\n  private int heapDescendants(int ordinal, Heap<FacetResultNode> pq,\n      MutableFacetResultNode parentResultNode, FacetArrays facetArrays, int offset) throws IOException {\n    int partitionSize = facetArrays.getArraysLength();\n    int endOffset = offset + partitionSize;\n    ParallelTaxonomyArrays childrenArray = taxonomyReader.getParallelTaxonomyArrays();\n    int[] children = childrenArray.children();\n    int[] siblings = childrenArray.siblings();\n    FacetResultNode reusable = null;\n    int localDepth = 0;\n    int depth = facetRequest.getDepth();\n    int[] ordinalStack = new int[2+Math.min(Short.MAX_VALUE, depth)];\n    int childrenCounter = 0;\n    \n    int tosOrdinal; // top of stack element\n    \n    int yc = children[ordinal];\n    while (yc >= endOffset) {\n      yc = siblings[yc];\n    }\n    // make use of the fact that TaxonomyReader.INVALID_ORDINAL == -1, < endOffset\n    // and it, too, can stop the loop.\n    ordinalStack[++localDepth] = yc;\n    \n    /*\n     * stack holds input parameter ordinal in position 0.\n     * Other elements are < endoffset.\n     * Only top of stack can be TaxonomyReader.INVALID_ORDINAL, and this if and only if\n     * the element below it exhausted all its children: has them all processed.\n     * \n     * stack elements are processed (counted and accumulated) only if they \n     * belong to current partition (between offset and endoffset) and first time\n     * they are on top of stack \n     * \n     * loop as long as stack is not empty of elements other than input ordinal, or for a little while -- it sibling\n     */\n    while (localDepth > 0) {\n      tosOrdinal = ordinalStack[localDepth];\n      if (tosOrdinal == TaxonomyReader.INVALID_ORDINAL) {\n        // element below tos has all its children, and itself, all processed\n        // need to proceed to its sibling\n        localDepth--;\n        // change element now on top of stack to its sibling.\n        ordinalStack[localDepth] = siblings[ordinalStack[localDepth]];\n        continue;\n      }\n      // top of stack is not invalid, this is the first time we see it on top of stack.\n      // collect it, if belongs to current partition, and then push its kids on itself, if applicable\n      if (tosOrdinal >= offset) { // tosOrdinal resides in current partition\n        int relativeOrdinal = tosOrdinal % partitionSize;\n        double value = facetRequest.getValueOf(facetArrays, relativeOrdinal);\n        if (value != 0 && !Double.isNaN(value)) {\n          // Count current ordinal -- the TOS\n          if (reusable == null) {\n            reusable = new MutableFacetResultNode(tosOrdinal, value);\n          } else {\n            // it is safe to cast since reusable was created here.\n            ((MutableFacetResultNode)reusable).reset(tosOrdinal, value);\n          }\n          ++childrenCounter;\n          reusable = pq.insertWithOverflow(reusable);\n          if (reusable != null) {\n            // TODO (Facet): is other logic (not add) needed, per aggregator?\n            parentResultNode.increaseResidue(reusable.getValue());\n          }\n        }\n      }\n      if (localDepth < depth) {\n        // push kid of current tos\n        yc = children[tosOrdinal];\n        while (yc >= endOffset) {\n          yc = siblings[yc];\n        }\n        ordinalStack[++localDepth] = yc;\n      } else { // localDepth == depth; current tos exhausted its possible children, mark this by pushing INVALID_ORDINAL\n        ordinalStack[++localDepth] = TaxonomyReader.INVALID_ORDINAL;\n      }\n    } // endof while stack is not empty\n    \n    return childrenCounter; // we're done\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d3fcb70cf561547c7bb1506e0cf32ca7b1287064","date":1357616416,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/facet/src/java/org/apache/lucene/facet/search/TopKFacetResultsHandler#heapDescendants(int,Heap[FacetResultNode],MutableFacetResultNode,FacetArrays,int).mjava","pathOld":"lucene/facet/src/java/org/apache/lucene/facet/search/TopKFacetResultsHandler#heapDescendants(int,Heap[FacetResultNode],MutableFacetResultNode,FacetArrays,int).mjava","sourceNew":"  /**\n   * Finds the top K descendants of ordinal, which are at most facetRequest.getDepth()\n   * deeper than facetRequest.getCategoryPath (whose ordinal is input parameter ordinal). \n   * Candidates are restricted to current \"counting list\" and current \"partition\",\n   * they join the overall priority queue pq of size K.  \n   * @return total number of descendants considered here by pq, excluding ordinal itself.\n   */\n  private int heapDescendants(int ordinal, Heap<FacetResultNode> pq,\n      MutableFacetResultNode parentResultNode, FacetArrays facetArrays, int offset) throws IOException {\n    int partitionSize = facetArrays.arrayLength;\n    int endOffset = offset + partitionSize;\n    ParallelTaxonomyArrays childrenArray = taxonomyReader.getParallelTaxonomyArrays();\n    int[] children = childrenArray.children();\n    int[] siblings = childrenArray.siblings();\n    FacetResultNode reusable = null;\n    int localDepth = 0;\n    int depth = facetRequest.getDepth();\n    int[] ordinalStack = new int[2+Math.min(Short.MAX_VALUE, depth)];\n    int childrenCounter = 0;\n    \n    int tosOrdinal; // top of stack element\n    \n    int yc = children[ordinal];\n    while (yc >= endOffset) {\n      yc = siblings[yc];\n    }\n    // make use of the fact that TaxonomyReader.INVALID_ORDINAL == -1, < endOffset\n    // and it, too, can stop the loop.\n    ordinalStack[++localDepth] = yc;\n    \n    /*\n     * stack holds input parameter ordinal in position 0.\n     * Other elements are < endoffset.\n     * Only top of stack can be TaxonomyReader.INVALID_ORDINAL, and this if and only if\n     * the element below it exhausted all its children: has them all processed.\n     * \n     * stack elements are processed (counted and accumulated) only if they \n     * belong to current partition (between offset and endoffset) and first time\n     * they are on top of stack \n     * \n     * loop as long as stack is not empty of elements other than input ordinal, or for a little while -- it sibling\n     */\n    while (localDepth > 0) {\n      tosOrdinal = ordinalStack[localDepth];\n      if (tosOrdinal == TaxonomyReader.INVALID_ORDINAL) {\n        // element below tos has all its children, and itself, all processed\n        // need to proceed to its sibling\n        localDepth--;\n        // change element now on top of stack to its sibling.\n        ordinalStack[localDepth] = siblings[ordinalStack[localDepth]];\n        continue;\n      }\n      // top of stack is not invalid, this is the first time we see it on top of stack.\n      // collect it, if belongs to current partition, and then push its kids on itself, if applicable\n      if (tosOrdinal >= offset) { // tosOrdinal resides in current partition\n        int relativeOrdinal = tosOrdinal % partitionSize;\n        double value = facetRequest.getValueOf(facetArrays, relativeOrdinal);\n        if (value != 0 && !Double.isNaN(value)) {\n          // Count current ordinal -- the TOS\n          if (reusable == null) {\n            reusable = new MutableFacetResultNode(tosOrdinal, value);\n          } else {\n            // it is safe to cast since reusable was created here.\n            ((MutableFacetResultNode)reusable).reset(tosOrdinal, value);\n          }\n          ++childrenCounter;\n          reusable = pq.insertWithOverflow(reusable);\n          if (reusable != null) {\n            // TODO (Facet): is other logic (not add) needed, per aggregator?\n            parentResultNode.increaseResidue(reusable.getValue());\n          }\n        }\n      }\n      if (localDepth < depth) {\n        // push kid of current tos\n        yc = children[tosOrdinal];\n        while (yc >= endOffset) {\n          yc = siblings[yc];\n        }\n        ordinalStack[++localDepth] = yc;\n      } else { // localDepth == depth; current tos exhausted its possible children, mark this by pushing INVALID_ORDINAL\n        ordinalStack[++localDepth] = TaxonomyReader.INVALID_ORDINAL;\n      }\n    } // endof while stack is not empty\n    \n    return childrenCounter; // we're done\n  }\n\n","sourceOld":"  /**\n   * Finds the top K descendants of ordinal, which are at most facetRequest.getDepth()\n   * deeper than facetRequest.getCategoryPath (whose ordinal is input parameter ordinal). \n   * Candidates are restricted to current \"counting list\" and current \"partition\",\n   * they join the overall priority queue pq of size K.  \n   * @return total number of descendants considered here by pq, excluding ordinal itself.\n   */\n  private int heapDescendants(int ordinal, Heap<FacetResultNode> pq,\n      MutableFacetResultNode parentResultNode, FacetArrays facetArrays, int offset) throws IOException {\n    int partitionSize = facetArrays.getArraysLength();\n    int endOffset = offset + partitionSize;\n    ParallelTaxonomyArrays childrenArray = taxonomyReader.getParallelTaxonomyArrays();\n    int[] children = childrenArray.children();\n    int[] siblings = childrenArray.siblings();\n    FacetResultNode reusable = null;\n    int localDepth = 0;\n    int depth = facetRequest.getDepth();\n    int[] ordinalStack = new int[2+Math.min(Short.MAX_VALUE, depth)];\n    int childrenCounter = 0;\n    \n    int tosOrdinal; // top of stack element\n    \n    int yc = children[ordinal];\n    while (yc >= endOffset) {\n      yc = siblings[yc];\n    }\n    // make use of the fact that TaxonomyReader.INVALID_ORDINAL == -1, < endOffset\n    // and it, too, can stop the loop.\n    ordinalStack[++localDepth] = yc;\n    \n    /*\n     * stack holds input parameter ordinal in position 0.\n     * Other elements are < endoffset.\n     * Only top of stack can be TaxonomyReader.INVALID_ORDINAL, and this if and only if\n     * the element below it exhausted all its children: has them all processed.\n     * \n     * stack elements are processed (counted and accumulated) only if they \n     * belong to current partition (between offset and endoffset) and first time\n     * they are on top of stack \n     * \n     * loop as long as stack is not empty of elements other than input ordinal, or for a little while -- it sibling\n     */\n    while (localDepth > 0) {\n      tosOrdinal = ordinalStack[localDepth];\n      if (tosOrdinal == TaxonomyReader.INVALID_ORDINAL) {\n        // element below tos has all its children, and itself, all processed\n        // need to proceed to its sibling\n        localDepth--;\n        // change element now on top of stack to its sibling.\n        ordinalStack[localDepth] = siblings[ordinalStack[localDepth]];\n        continue;\n      }\n      // top of stack is not invalid, this is the first time we see it on top of stack.\n      // collect it, if belongs to current partition, and then push its kids on itself, if applicable\n      if (tosOrdinal >= offset) { // tosOrdinal resides in current partition\n        int relativeOrdinal = tosOrdinal % partitionSize;\n        double value = facetRequest.getValueOf(facetArrays, relativeOrdinal);\n        if (value != 0 && !Double.isNaN(value)) {\n          // Count current ordinal -- the TOS\n          if (reusable == null) {\n            reusable = new MutableFacetResultNode(tosOrdinal, value);\n          } else {\n            // it is safe to cast since reusable was created here.\n            ((MutableFacetResultNode)reusable).reset(tosOrdinal, value);\n          }\n          ++childrenCounter;\n          reusable = pq.insertWithOverflow(reusable);\n          if (reusable != null) {\n            // TODO (Facet): is other logic (not add) needed, per aggregator?\n            parentResultNode.increaseResidue(reusable.getValue());\n          }\n        }\n      }\n      if (localDepth < depth) {\n        // push kid of current tos\n        yc = children[tosOrdinal];\n        while (yc >= endOffset) {\n          yc = siblings[yc];\n        }\n        ordinalStack[++localDepth] = yc;\n      } else { // localDepth == depth; current tos exhausted its possible children, mark this by pushing INVALID_ORDINAL\n        ordinalStack[++localDepth] = TaxonomyReader.INVALID_ORDINAL;\n      }\n    } // endof while stack is not empty\n    \n    return childrenCounter; // we're done\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"811cdb4a80352766eb0c762e48972707a924e5cd","date":1358767313,"type":5,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/facet/src/java/org/apache/lucene/facet/search/TopKFacetResultsHandler#heapDescendants(int,Heap[FacetResultNode],FacetResultNode,FacetArrays,int).mjava","pathOld":"lucene/facet/src/java/org/apache/lucene/facet/search/TopKFacetResultsHandler#heapDescendants(int,Heap[FacetResultNode],MutableFacetResultNode,FacetArrays,int).mjava","sourceNew":"  /**\n   * Finds the top K descendants of ordinal, which are at most facetRequest.getDepth()\n   * deeper than facetRequest.getCategoryPath (whose ordinal is input parameter ordinal). \n   * Candidates are restricted to current \"counting list\" and current \"partition\",\n   * they join the overall priority queue pq of size K.  \n   * @return total number of descendants considered here by pq, excluding ordinal itself.\n   */\n  private int heapDescendants(int ordinal, Heap<FacetResultNode> pq, FacetResultNode parentResultNode, \n      FacetArrays facetArrays, int offset) throws IOException {\n    int partitionSize = facetArrays.arrayLength;\n    int endOffset = offset + partitionSize;\n    ParallelTaxonomyArrays childrenArray = taxonomyReader.getParallelTaxonomyArrays();\n    int[] children = childrenArray.children();\n    int[] siblings = childrenArray.siblings();\n    FacetResultNode reusable = null;\n    int localDepth = 0;\n    int depth = facetRequest.getDepth();\n    int[] ordinalStack = new int[2+Math.min(Short.MAX_VALUE, depth)];\n    int childrenCounter = 0;\n    \n    int tosOrdinal; // top of stack element\n    \n    int yc = children[ordinal];\n    while (yc >= endOffset) {\n      yc = siblings[yc];\n    }\n    // make use of the fact that TaxonomyReader.INVALID_ORDINAL == -1, < endOffset\n    // and it, too, can stop the loop.\n    ordinalStack[++localDepth] = yc;\n    \n    /*\n     * stack holds input parameter ordinal in position 0.\n     * Other elements are < endoffset.\n     * Only top of stack can be TaxonomyReader.INVALID_ORDINAL, and this if and only if\n     * the element below it exhausted all its children: has them all processed.\n     * \n     * stack elements are processed (counted and accumulated) only if they \n     * belong to current partition (between offset and endoffset) and first time\n     * they are on top of stack \n     * \n     * loop as long as stack is not empty of elements other than input ordinal, or for a little while -- it sibling\n     */\n    while (localDepth > 0) {\n      tosOrdinal = ordinalStack[localDepth];\n      if (tosOrdinal == TaxonomyReader.INVALID_ORDINAL) {\n        // element below tos has all its children, and itself, all processed\n        // need to proceed to its sibling\n        localDepth--;\n        // change element now on top of stack to its sibling.\n        ordinalStack[localDepth] = siblings[ordinalStack[localDepth]];\n        continue;\n      }\n      // top of stack is not invalid, this is the first time we see it on top of stack.\n      // collect it, if belongs to current partition, and then push its kids on itself, if applicable\n      if (tosOrdinal >= offset) { // tosOrdinal resides in current partition\n        int relativeOrdinal = tosOrdinal % partitionSize;\n        double value = facetRequest.getValueOf(facetArrays, relativeOrdinal);\n        if (value != 0 && !Double.isNaN(value)) {\n          // Count current ordinal -- the TOS\n          if (reusable == null) {\n            reusable = new FacetResultNode(tosOrdinal, value);\n          } else {\n            // it is safe to cast since reusable was created here.\n            reusable.ordinal = tosOrdinal;\n            reusable.value = value;\n            reusable.subResults.clear();\n            reusable.label = null;\n            reusable.residue = 0;\n          }\n          ++childrenCounter;\n          reusable = pq.insertWithOverflow(reusable);\n          if (reusable != null) {\n            // TODO (Facet): is other logic (not add) needed, per aggregator?\n            parentResultNode.residue += reusable.value;\n          }\n        }\n      }\n      if (localDepth < depth) {\n        // push kid of current tos\n        yc = children[tosOrdinal];\n        while (yc >= endOffset) {\n          yc = siblings[yc];\n        }\n        ordinalStack[++localDepth] = yc;\n      } else { // localDepth == depth; current tos exhausted its possible children, mark this by pushing INVALID_ORDINAL\n        ordinalStack[++localDepth] = TaxonomyReader.INVALID_ORDINAL;\n      }\n    } // endof while stack is not empty\n    \n    return childrenCounter; // we're done\n  }\n\n","sourceOld":"  /**\n   * Finds the top K descendants of ordinal, which are at most facetRequest.getDepth()\n   * deeper than facetRequest.getCategoryPath (whose ordinal is input parameter ordinal). \n   * Candidates are restricted to current \"counting list\" and current \"partition\",\n   * they join the overall priority queue pq of size K.  \n   * @return total number of descendants considered here by pq, excluding ordinal itself.\n   */\n  private int heapDescendants(int ordinal, Heap<FacetResultNode> pq,\n      MutableFacetResultNode parentResultNode, FacetArrays facetArrays, int offset) throws IOException {\n    int partitionSize = facetArrays.arrayLength;\n    int endOffset = offset + partitionSize;\n    ParallelTaxonomyArrays childrenArray = taxonomyReader.getParallelTaxonomyArrays();\n    int[] children = childrenArray.children();\n    int[] siblings = childrenArray.siblings();\n    FacetResultNode reusable = null;\n    int localDepth = 0;\n    int depth = facetRequest.getDepth();\n    int[] ordinalStack = new int[2+Math.min(Short.MAX_VALUE, depth)];\n    int childrenCounter = 0;\n    \n    int tosOrdinal; // top of stack element\n    \n    int yc = children[ordinal];\n    while (yc >= endOffset) {\n      yc = siblings[yc];\n    }\n    // make use of the fact that TaxonomyReader.INVALID_ORDINAL == -1, < endOffset\n    // and it, too, can stop the loop.\n    ordinalStack[++localDepth] = yc;\n    \n    /*\n     * stack holds input parameter ordinal in position 0.\n     * Other elements are < endoffset.\n     * Only top of stack can be TaxonomyReader.INVALID_ORDINAL, and this if and only if\n     * the element below it exhausted all its children: has them all processed.\n     * \n     * stack elements are processed (counted and accumulated) only if they \n     * belong to current partition (between offset and endoffset) and first time\n     * they are on top of stack \n     * \n     * loop as long as stack is not empty of elements other than input ordinal, or for a little while -- it sibling\n     */\n    while (localDepth > 0) {\n      tosOrdinal = ordinalStack[localDepth];\n      if (tosOrdinal == TaxonomyReader.INVALID_ORDINAL) {\n        // element below tos has all its children, and itself, all processed\n        // need to proceed to its sibling\n        localDepth--;\n        // change element now on top of stack to its sibling.\n        ordinalStack[localDepth] = siblings[ordinalStack[localDepth]];\n        continue;\n      }\n      // top of stack is not invalid, this is the first time we see it on top of stack.\n      // collect it, if belongs to current partition, and then push its kids on itself, if applicable\n      if (tosOrdinal >= offset) { // tosOrdinal resides in current partition\n        int relativeOrdinal = tosOrdinal % partitionSize;\n        double value = facetRequest.getValueOf(facetArrays, relativeOrdinal);\n        if (value != 0 && !Double.isNaN(value)) {\n          // Count current ordinal -- the TOS\n          if (reusable == null) {\n            reusable = new MutableFacetResultNode(tosOrdinal, value);\n          } else {\n            // it is safe to cast since reusable was created here.\n            ((MutableFacetResultNode)reusable).reset(tosOrdinal, value);\n          }\n          ++childrenCounter;\n          reusable = pq.insertWithOverflow(reusable);\n          if (reusable != null) {\n            // TODO (Facet): is other logic (not add) needed, per aggregator?\n            parentResultNode.increaseResidue(reusable.getValue());\n          }\n        }\n      }\n      if (localDepth < depth) {\n        // push kid of current tos\n        yc = children[tosOrdinal];\n        while (yc >= endOffset) {\n          yc = siblings[yc];\n        }\n        ordinalStack[++localDepth] = yc;\n      } else { // localDepth == depth; current tos exhausted its possible children, mark this by pushing INVALID_ORDINAL\n        ordinalStack[++localDepth] = TaxonomyReader.INVALID_ORDINAL;\n      }\n    } // endof while stack is not empty\n    \n    return childrenCounter; // we're done\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"07155cdd910937cdf6877e48884d5782845c8b8b","date":1358796205,"type":5,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/facet/src/java/org/apache/lucene/facet/search/TopKFacetResultsHandler#heapDescendants(int,Heap[FacetResultNode],FacetResultNode,FacetArrays,int).mjava","pathOld":"lucene/facet/src/java/org/apache/lucene/facet/search/TopKFacetResultsHandler#heapDescendants(int,Heap[FacetResultNode],MutableFacetResultNode,FacetArrays,int).mjava","sourceNew":"  /**\n   * Finds the top K descendants of ordinal, which are at most facetRequest.getDepth()\n   * deeper than facetRequest.getCategoryPath (whose ordinal is input parameter ordinal). \n   * Candidates are restricted to current \"counting list\" and current \"partition\",\n   * they join the overall priority queue pq of size K.  \n   * @return total number of descendants considered here by pq, excluding ordinal itself.\n   */\n  private int heapDescendants(int ordinal, Heap<FacetResultNode> pq, FacetResultNode parentResultNode, \n      FacetArrays facetArrays, int offset) throws IOException {\n    int partitionSize = facetArrays.arrayLength;\n    int endOffset = offset + partitionSize;\n    ParallelTaxonomyArrays childrenArray = taxonomyReader.getParallelTaxonomyArrays();\n    int[] children = childrenArray.children();\n    int[] siblings = childrenArray.siblings();\n    FacetResultNode reusable = null;\n    int localDepth = 0;\n    int depth = facetRequest.getDepth();\n    int[] ordinalStack = new int[2+Math.min(Short.MAX_VALUE, depth)];\n    int childrenCounter = 0;\n    \n    int tosOrdinal; // top of stack element\n    \n    int yc = children[ordinal];\n    while (yc >= endOffset) {\n      yc = siblings[yc];\n    }\n    // make use of the fact that TaxonomyReader.INVALID_ORDINAL == -1, < endOffset\n    // and it, too, can stop the loop.\n    ordinalStack[++localDepth] = yc;\n    \n    /*\n     * stack holds input parameter ordinal in position 0.\n     * Other elements are < endoffset.\n     * Only top of stack can be TaxonomyReader.INVALID_ORDINAL, and this if and only if\n     * the element below it exhausted all its children: has them all processed.\n     * \n     * stack elements are processed (counted and accumulated) only if they \n     * belong to current partition (between offset and endoffset) and first time\n     * they are on top of stack \n     * \n     * loop as long as stack is not empty of elements other than input ordinal, or for a little while -- it sibling\n     */\n    while (localDepth > 0) {\n      tosOrdinal = ordinalStack[localDepth];\n      if (tosOrdinal == TaxonomyReader.INVALID_ORDINAL) {\n        // element below tos has all its children, and itself, all processed\n        // need to proceed to its sibling\n        localDepth--;\n        // change element now on top of stack to its sibling.\n        ordinalStack[localDepth] = siblings[ordinalStack[localDepth]];\n        continue;\n      }\n      // top of stack is not invalid, this is the first time we see it on top of stack.\n      // collect it, if belongs to current partition, and then push its kids on itself, if applicable\n      if (tosOrdinal >= offset) { // tosOrdinal resides in current partition\n        int relativeOrdinal = tosOrdinal % partitionSize;\n        double value = facetRequest.getValueOf(facetArrays, relativeOrdinal);\n        if (value != 0 && !Double.isNaN(value)) {\n          // Count current ordinal -- the TOS\n          if (reusable == null) {\n            reusable = new FacetResultNode(tosOrdinal, value);\n          } else {\n            // it is safe to cast since reusable was created here.\n            reusable.ordinal = tosOrdinal;\n            reusable.value = value;\n            reusable.subResults.clear();\n            reusable.label = null;\n            reusable.residue = 0;\n          }\n          ++childrenCounter;\n          reusable = pq.insertWithOverflow(reusable);\n          if (reusable != null) {\n            // TODO (Facet): is other logic (not add) needed, per aggregator?\n            parentResultNode.residue += reusable.value;\n          }\n        }\n      }\n      if (localDepth < depth) {\n        // push kid of current tos\n        yc = children[tosOrdinal];\n        while (yc >= endOffset) {\n          yc = siblings[yc];\n        }\n        ordinalStack[++localDepth] = yc;\n      } else { // localDepth == depth; current tos exhausted its possible children, mark this by pushing INVALID_ORDINAL\n        ordinalStack[++localDepth] = TaxonomyReader.INVALID_ORDINAL;\n      }\n    } // endof while stack is not empty\n    \n    return childrenCounter; // we're done\n  }\n\n","sourceOld":"  /**\n   * Finds the top K descendants of ordinal, which are at most facetRequest.getDepth()\n   * deeper than facetRequest.getCategoryPath (whose ordinal is input parameter ordinal). \n   * Candidates are restricted to current \"counting list\" and current \"partition\",\n   * they join the overall priority queue pq of size K.  \n   * @return total number of descendants considered here by pq, excluding ordinal itself.\n   */\n  private int heapDescendants(int ordinal, Heap<FacetResultNode> pq,\n      MutableFacetResultNode parentResultNode, FacetArrays facetArrays, int offset) throws IOException {\n    int partitionSize = facetArrays.arrayLength;\n    int endOffset = offset + partitionSize;\n    ParallelTaxonomyArrays childrenArray = taxonomyReader.getParallelTaxonomyArrays();\n    int[] children = childrenArray.children();\n    int[] siblings = childrenArray.siblings();\n    FacetResultNode reusable = null;\n    int localDepth = 0;\n    int depth = facetRequest.getDepth();\n    int[] ordinalStack = new int[2+Math.min(Short.MAX_VALUE, depth)];\n    int childrenCounter = 0;\n    \n    int tosOrdinal; // top of stack element\n    \n    int yc = children[ordinal];\n    while (yc >= endOffset) {\n      yc = siblings[yc];\n    }\n    // make use of the fact that TaxonomyReader.INVALID_ORDINAL == -1, < endOffset\n    // and it, too, can stop the loop.\n    ordinalStack[++localDepth] = yc;\n    \n    /*\n     * stack holds input parameter ordinal in position 0.\n     * Other elements are < endoffset.\n     * Only top of stack can be TaxonomyReader.INVALID_ORDINAL, and this if and only if\n     * the element below it exhausted all its children: has them all processed.\n     * \n     * stack elements are processed (counted and accumulated) only if they \n     * belong to current partition (between offset and endoffset) and first time\n     * they are on top of stack \n     * \n     * loop as long as stack is not empty of elements other than input ordinal, or for a little while -- it sibling\n     */\n    while (localDepth > 0) {\n      tosOrdinal = ordinalStack[localDepth];\n      if (tosOrdinal == TaxonomyReader.INVALID_ORDINAL) {\n        // element below tos has all its children, and itself, all processed\n        // need to proceed to its sibling\n        localDepth--;\n        // change element now on top of stack to its sibling.\n        ordinalStack[localDepth] = siblings[ordinalStack[localDepth]];\n        continue;\n      }\n      // top of stack is not invalid, this is the first time we see it on top of stack.\n      // collect it, if belongs to current partition, and then push its kids on itself, if applicable\n      if (tosOrdinal >= offset) { // tosOrdinal resides in current partition\n        int relativeOrdinal = tosOrdinal % partitionSize;\n        double value = facetRequest.getValueOf(facetArrays, relativeOrdinal);\n        if (value != 0 && !Double.isNaN(value)) {\n          // Count current ordinal -- the TOS\n          if (reusable == null) {\n            reusable = new MutableFacetResultNode(tosOrdinal, value);\n          } else {\n            // it is safe to cast since reusable was created here.\n            ((MutableFacetResultNode)reusable).reset(tosOrdinal, value);\n          }\n          ++childrenCounter;\n          reusable = pq.insertWithOverflow(reusable);\n          if (reusable != null) {\n            // TODO (Facet): is other logic (not add) needed, per aggregator?\n            parentResultNode.increaseResidue(reusable.getValue());\n          }\n        }\n      }\n      if (localDepth < depth) {\n        // push kid of current tos\n        yc = children[tosOrdinal];\n        while (yc >= endOffset) {\n          yc = siblings[yc];\n        }\n        ordinalStack[++localDepth] = yc;\n      } else { // localDepth == depth; current tos exhausted its possible children, mark this by pushing INVALID_ORDINAL\n        ordinalStack[++localDepth] = TaxonomyReader.INVALID_ORDINAL;\n      }\n    } // endof while stack is not empty\n    \n    return childrenCounter; // we're done\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["407687e67faf6e1f02a211ca078d8e3eed631027","2a2548b7f050533ac9a884b31cab5fb6f0386fbb"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"2a2548b7f050533ac9a884b31cab5fb6f0386fbb":["3d58d08788c3fd51172ba34474cca42499d6391b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"407687e67faf6e1f02a211ca078d8e3eed631027":["b89678825b68eccaf09e6ab71675fc0b0af1e099","3d58d08788c3fd51172ba34474cca42499d6391b"],"3d58d08788c3fd51172ba34474cca42499d6391b":["219dcddcdf2fc13f6271d9e5836bd19c53a4abf1"],"07155cdd910937cdf6877e48884d5782845c8b8b":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","811cdb4a80352766eb0c762e48972707a924e5cd"],"219dcddcdf2fc13f6271d9e5836bd19c53a4abf1":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["811cdb4a80352766eb0c762e48972707a924e5cd"],"811cdb4a80352766eb0c762e48972707a924e5cd":["2a2548b7f050533ac9a884b31cab5fb6f0386fbb"]},"commit2Childs":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["07155cdd910937cdf6877e48884d5782845c8b8b"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["407687e67faf6e1f02a211ca078d8e3eed631027","219dcddcdf2fc13f6271d9e5836bd19c53a4abf1"],"2a2548b7f050533ac9a884b31cab5fb6f0386fbb":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","811cdb4a80352766eb0c762e48972707a924e5cd"],"407687e67faf6e1f02a211ca078d8e3eed631027":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"3d58d08788c3fd51172ba34474cca42499d6391b":["2a2548b7f050533ac9a884b31cab5fb6f0386fbb","407687e67faf6e1f02a211ca078d8e3eed631027"],"07155cdd910937cdf6877e48884d5782845c8b8b":[],"219dcddcdf2fc13f6271d9e5836bd19c53a4abf1":["3d58d08788c3fd51172ba34474cca42499d6391b"],"811cdb4a80352766eb0c762e48972707a924e5cd":["07155cdd910937cdf6877e48884d5782845c8b8b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["07155cdd910937cdf6877e48884d5782845c8b8b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}