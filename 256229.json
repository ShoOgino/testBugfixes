{"path":"solr/core/src/test/org/apache/solr/cloud/SolrCloudExampleTest#testLoadDocsIntoGettingStartedCollection().mjava","commits":[{"id":"9d62f72d1c60d2be239222de52d5e7b516da5f6f","date":1428554550,"type":0,"author":"Steven Rowe","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/SolrCloudExampleTest#testLoadDocsIntoGettingStartedCollection().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testLoadDocsIntoGettingStartedCollection() throws Exception {\n    waitForThingsToLevelOut(30000);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection initialized OK ... running test logic\");\n\n    String testCollectionName = \"gettingstarted\";\n    File data_driven_schema_configs = new File(ExternalPaths.SCHEMALESS_CONFIGSET);\n    assertTrue(data_driven_schema_configs.getAbsolutePath()+\" not found!\", data_driven_schema_configs.isDirectory());\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    if (liveNodes.isEmpty())\n      fail(\"No live nodes found! Cannot create a collection until there is at least 1 live node in the cluster.\");\n    String firstLiveNode = liveNodes.iterator().next();\n    String solrUrl = cloudClient.getZkStateReader().getBaseUrlForNodeName(firstLiveNode);\n\n    // create the gettingstarted collection just like the bin/solr script would do\n    String[] args = new String[] {\n        \"create_collection\",\n        \"-name\", testCollectionName,\n        \"-shards\", \"2\",\n        \"-replicationFactor\", \"2\",\n        \"-confname\", testCollectionName,\n        \"-confdir\", \"data_driven_schema_configs\",\n        \"-configsetsDir\", data_driven_schema_configs.getParentFile().getParentFile().getAbsolutePath(),\n        \"-solrUrl\", solrUrl\n    };\n    SolrCLI.CreateCollectionTool tool = new SolrCLI.CreateCollectionTool();\n    CommandLine cli = SolrCLI.processCommandLineArgs(SolrCLI.joinCommonAndToolOptions(tool.getOptions()), args);\n    log.info(\"Creating the '\"+testCollectionName+\"' collection using SolrCLI with: \"+solrUrl);\n    tool.runTool(cli);\n    assertTrue(\"Collection '\" + testCollectionName + \"' doesn't exist after trying to create it!\",\n        cloudClient.getZkStateReader().getClusterState().hasCollection(testCollectionName));\n\n    // verify the collection is usable ...\n    ensureAllReplicasAreActive(testCollectionName, \"shard1\", 2, 2, 20);\n    ensureAllReplicasAreActive(testCollectionName, \"shard2\", 2, 2, 10);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    // now index docs like bin/post would do but we can't use SimplePostTool because it uses System.exit when\n    // it encounters an error, which JUnit doesn't like ...\n    log.info(\"Created collection, now posting example docs!\");\n    File exampleDocsDir = new File(ExternalPaths.SOURCE_HOME, \"example/exampledocs\");\n    assertTrue(exampleDocsDir.getAbsolutePath()+\" not found!\", exampleDocsDir.isDirectory());\n\n    File[] xmlFiles = exampleDocsDir.listFiles(new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return name.endsWith(\".xml\");\n      }\n    });\n\n    // if you add/remove example XML docs, you'll have to fix these expected values\n    int expectedXmlFileCount = 14;\n    int expectedXmlDocCount = 32;\n\n    assertTrue(\"Expected 14 example XML files in \"+exampleDocsDir.getAbsolutePath(),\n        xmlFiles.length == expectedXmlFileCount);\n\n    for (File xml : xmlFiles) {\n      ContentStreamUpdateRequest req = new ContentStreamUpdateRequest(\"/update\");\n      req.addFile(xml, \"application/xml\");\n      log.info(\"POSTing \"+xml.getAbsolutePath());\n      cloudClient.request(req);\n    }\n    cloudClient.commit();\n    Thread.sleep(1000);\n\n    QueryResponse qr = cloudClient.query(new SolrQuery(\"*:*\"));\n    int numFound = (int)qr.getResults().getNumFound();\n    assertTrue(\"Expected \"+expectedXmlDocCount+\" docs but *:* found \"+numFound, numFound == expectedXmlDocCount);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection succeeded ... shutting down now!\");\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["fa584ccfc18d85d3efa8a95d58762f54c68fa6bf"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fa584ccfc18d85d3efa8a95d58762f54c68fa6bf","date":1430154566,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/SolrCloudExampleTest#testLoadDocsIntoGettingStartedCollection().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/SolrCloudExampleTest#testLoadDocsIntoGettingStartedCollection().mjava","sourceNew":"  @Test\n  public void testLoadDocsIntoGettingStartedCollection() throws Exception {\n    waitForThingsToLevelOut(30000);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection initialized OK ... running test logic\");\n\n    String testCollectionName = \"gettingstarted\";\n    File data_driven_schema_configs = new File(ExternalPaths.SCHEMALESS_CONFIGSET);\n    assertTrue(data_driven_schema_configs.getAbsolutePath()+\" not found!\", data_driven_schema_configs.isDirectory());\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    if (liveNodes.isEmpty())\n      fail(\"No live nodes found! Cannot create a collection until there is at least 1 live node in the cluster.\");\n    String firstLiveNode = liveNodes.iterator().next();\n    String solrUrl = cloudClient.getZkStateReader().getBaseUrlForNodeName(firstLiveNode);\n\n    // create the gettingstarted collection just like the bin/solr script would do\n    String[] args = new String[] {\n        \"create_collection\",\n        \"-name\", testCollectionName,\n        \"-shards\", \"2\",\n        \"-replicationFactor\", \"2\",\n        \"-confname\", testCollectionName,\n        \"-confdir\", \"data_driven_schema_configs\",\n        \"-configsetsDir\", data_driven_schema_configs.getParentFile().getParentFile().getAbsolutePath(),\n        \"-solrUrl\", solrUrl\n    };\n    SolrCLI.CreateCollectionTool tool = new SolrCLI.CreateCollectionTool();\n    CommandLine cli = SolrCLI.processCommandLineArgs(SolrCLI.joinCommonAndToolOptions(tool.getOptions()), args);\n    log.info(\"Creating the '\"+testCollectionName+\"' collection using SolrCLI with: \"+solrUrl);\n    tool.runTool(cli);\n    assertTrue(\"Collection '\" + testCollectionName + \"' doesn't exist after trying to create it!\",\n        cloudClient.getZkStateReader().getClusterState().hasCollection(testCollectionName));\n\n    // verify the collection is usable ...\n    ensureAllReplicasAreActive(testCollectionName, \"shard1\", 2, 2, 20);\n    ensureAllReplicasAreActive(testCollectionName, \"shard2\", 2, 2, 10);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    // now index docs like bin/post would do but we can't use SimplePostTool because it uses System.exit when\n    // it encounters an error, which JUnit doesn't like ...\n    log.info(\"Created collection, now posting example docs!\");\n    File exampleDocsDir = new File(ExternalPaths.SOURCE_HOME, \"example/exampledocs\");\n    assertTrue(exampleDocsDir.getAbsolutePath()+\" not found!\", exampleDocsDir.isDirectory());\n\n    List<File> xmlFiles = Arrays.asList(exampleDocsDir.listFiles(new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return name.endsWith(\".xml\");\n      }\n    }));\n\n    // force a deterministic random ordering of the files so seeds reproduce regardless of platform/filesystem\n    Collections.sort(xmlFiles, new Comparator<File>() {\n        public int compare(File o1, File o2) {\n          // don't rely on File.compareTo, it's behavior varies by OS\n          return o1.getName().compareTo(o2.getName());\n        }\n      });\n    Collections.shuffle(xmlFiles, new Random(random().nextLong()));\n\n    // if you add/remove example XML docs, you'll have to fix these expected values\n    int expectedXmlFileCount = 14;\n    int expectedXmlDocCount = 32;\n\n    assertEquals(\"Unexpected # of example XML files in \"+exampleDocsDir.getAbsolutePath(),\n                 expectedXmlFileCount, xmlFiles.size());\n    \n    for (File xml : xmlFiles) {\n      ContentStreamUpdateRequest req = new ContentStreamUpdateRequest(\"/update\");\n      req.addFile(xml, \"application/xml\");\n      log.info(\"POSTing \"+xml.getAbsolutePath());\n      cloudClient.request(req);\n    }\n    cloudClient.commit();\n    Thread.sleep(1000);\n\n    QueryResponse qr = cloudClient.query(new SolrQuery(\"*:*\"));\n    int numFound = (int)qr.getResults().getNumFound();\n    assertEquals(\"*:* found unexpected number of documents\", expectedXmlDocCount, numFound);\n                 \n\n    log.info(\"testLoadDocsIntoGettingStartedCollection succeeded ... shutting down now!\");\n  }\n\n","sourceOld":"  @Test\n  public void testLoadDocsIntoGettingStartedCollection() throws Exception {\n    waitForThingsToLevelOut(30000);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection initialized OK ... running test logic\");\n\n    String testCollectionName = \"gettingstarted\";\n    File data_driven_schema_configs = new File(ExternalPaths.SCHEMALESS_CONFIGSET);\n    assertTrue(data_driven_schema_configs.getAbsolutePath()+\" not found!\", data_driven_schema_configs.isDirectory());\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    if (liveNodes.isEmpty())\n      fail(\"No live nodes found! Cannot create a collection until there is at least 1 live node in the cluster.\");\n    String firstLiveNode = liveNodes.iterator().next();\n    String solrUrl = cloudClient.getZkStateReader().getBaseUrlForNodeName(firstLiveNode);\n\n    // create the gettingstarted collection just like the bin/solr script would do\n    String[] args = new String[] {\n        \"create_collection\",\n        \"-name\", testCollectionName,\n        \"-shards\", \"2\",\n        \"-replicationFactor\", \"2\",\n        \"-confname\", testCollectionName,\n        \"-confdir\", \"data_driven_schema_configs\",\n        \"-configsetsDir\", data_driven_schema_configs.getParentFile().getParentFile().getAbsolutePath(),\n        \"-solrUrl\", solrUrl\n    };\n    SolrCLI.CreateCollectionTool tool = new SolrCLI.CreateCollectionTool();\n    CommandLine cli = SolrCLI.processCommandLineArgs(SolrCLI.joinCommonAndToolOptions(tool.getOptions()), args);\n    log.info(\"Creating the '\"+testCollectionName+\"' collection using SolrCLI with: \"+solrUrl);\n    tool.runTool(cli);\n    assertTrue(\"Collection '\" + testCollectionName + \"' doesn't exist after trying to create it!\",\n        cloudClient.getZkStateReader().getClusterState().hasCollection(testCollectionName));\n\n    // verify the collection is usable ...\n    ensureAllReplicasAreActive(testCollectionName, \"shard1\", 2, 2, 20);\n    ensureAllReplicasAreActive(testCollectionName, \"shard2\", 2, 2, 10);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    // now index docs like bin/post would do but we can't use SimplePostTool because it uses System.exit when\n    // it encounters an error, which JUnit doesn't like ...\n    log.info(\"Created collection, now posting example docs!\");\n    File exampleDocsDir = new File(ExternalPaths.SOURCE_HOME, \"example/exampledocs\");\n    assertTrue(exampleDocsDir.getAbsolutePath()+\" not found!\", exampleDocsDir.isDirectory());\n\n    File[] xmlFiles = exampleDocsDir.listFiles(new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return name.endsWith(\".xml\");\n      }\n    });\n\n    // if you add/remove example XML docs, you'll have to fix these expected values\n    int expectedXmlFileCount = 14;\n    int expectedXmlDocCount = 32;\n\n    assertTrue(\"Expected 14 example XML files in \"+exampleDocsDir.getAbsolutePath(),\n        xmlFiles.length == expectedXmlFileCount);\n\n    for (File xml : xmlFiles) {\n      ContentStreamUpdateRequest req = new ContentStreamUpdateRequest(\"/update\");\n      req.addFile(xml, \"application/xml\");\n      log.info(\"POSTing \"+xml.getAbsolutePath());\n      cloudClient.request(req);\n    }\n    cloudClient.commit();\n    Thread.sleep(1000);\n\n    QueryResponse qr = cloudClient.query(new SolrQuery(\"*:*\"));\n    int numFound = (int)qr.getResults().getNumFound();\n    assertTrue(\"Expected \"+expectedXmlDocCount+\" docs but *:* found \"+numFound, numFound == expectedXmlDocCount);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection succeeded ... shutting down now!\");\n  }\n\n","bugFix":["9d62f72d1c60d2be239222de52d5e7b516da5f6f"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"547b9bdc942b65ebcd943738bb12c2a222fcf566","date":1432317527,"type":3,"author":"Timothy Potter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/SolrCloudExampleTest#testLoadDocsIntoGettingStartedCollection().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/SolrCloudExampleTest#testLoadDocsIntoGettingStartedCollection().mjava","sourceNew":"  @Test\n  public void testLoadDocsIntoGettingStartedCollection() throws Exception {\n    waitForThingsToLevelOut(30000);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection initialized OK ... running test logic\");\n\n    String testCollectionName = \"gettingstarted\";\n    File data_driven_schema_configs = new File(ExternalPaths.SCHEMALESS_CONFIGSET);\n    assertTrue(data_driven_schema_configs.getAbsolutePath()+\" not found!\", data_driven_schema_configs.isDirectory());\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    if (liveNodes.isEmpty())\n      fail(\"No live nodes found! Cannot create a collection until there is at least 1 live node in the cluster.\");\n    String firstLiveNode = liveNodes.iterator().next();\n    String solrUrl = cloudClient.getZkStateReader().getBaseUrlForNodeName(firstLiveNode);\n\n    // create the gettingstarted collection just like the bin/solr script would do\n    String[] args = new String[] {\n        \"create_collection\",\n        \"-name\", testCollectionName,\n        \"-shards\", \"2\",\n        \"-replicationFactor\", \"2\",\n        \"-confname\", testCollectionName,\n        \"-confdir\", \"data_driven_schema_configs\",\n        \"-configsetsDir\", data_driven_schema_configs.getParentFile().getParentFile().getAbsolutePath(),\n        \"-solrUrl\", solrUrl\n    };\n    SolrCLI.CreateCollectionTool tool = new SolrCLI.CreateCollectionTool();\n    CommandLine cli = SolrCLI.processCommandLineArgs(SolrCLI.joinCommonAndToolOptions(tool.getOptions()), args);\n    log.info(\"Creating the '\"+testCollectionName+\"' collection using SolrCLI with: \"+solrUrl);\n    tool.runTool(cli);\n    assertTrue(\"Collection '\" + testCollectionName + \"' doesn't exist after trying to create it!\",\n        cloudClient.getZkStateReader().getClusterState().hasCollection(testCollectionName));\n\n    // verify the collection is usable ...\n    ensureAllReplicasAreActive(testCollectionName, \"shard1\", 2, 2, 20);\n    ensureAllReplicasAreActive(testCollectionName, \"shard2\", 2, 2, 10);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    // now index docs like bin/post would do but we can't use SimplePostTool because it uses System.exit when\n    // it encounters an error, which JUnit doesn't like ...\n    log.info(\"Created collection, now posting example docs!\");\n    File exampleDocsDir = new File(ExternalPaths.SOURCE_HOME, \"example/exampledocs\");\n    assertTrue(exampleDocsDir.getAbsolutePath()+\" not found!\", exampleDocsDir.isDirectory());\n\n    List<File> xmlFiles = Arrays.asList(exampleDocsDir.listFiles(new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return name.endsWith(\".xml\");\n      }\n    }));\n\n    // force a deterministic random ordering of the files so seeds reproduce regardless of platform/filesystem\n    Collections.sort(xmlFiles, new Comparator<File>() {\n        public int compare(File o1, File o2) {\n          // don't rely on File.compareTo, it's behavior varies by OS\n          return o1.getName().compareTo(o2.getName());\n        }\n      });\n    Collections.shuffle(xmlFiles, new Random(random().nextLong()));\n\n    // if you add/remove example XML docs, you'll have to fix these expected values\n    int expectedXmlFileCount = 14;\n    int expectedXmlDocCount = 32;\n\n    assertEquals(\"Unexpected # of example XML files in \"+exampleDocsDir.getAbsolutePath(),\n                 expectedXmlFileCount, xmlFiles.size());\n    \n    for (File xml : xmlFiles) {\n      ContentStreamUpdateRequest req = new ContentStreamUpdateRequest(\"/update\");\n      req.addFile(xml, \"application/xml\");\n      log.info(\"POSTing \"+xml.getAbsolutePath());\n      cloudClient.request(req);\n    }\n    cloudClient.commit();\n    Thread.sleep(1000);\n\n    QueryResponse qr = cloudClient.query(new SolrQuery(\"*:*\"));\n    int numFound = (int)qr.getResults().getNumFound();\n    assertEquals(\"*:* found unexpected number of documents\", expectedXmlDocCount, numFound);\n\n    log.info(\"Updating Config for \" + testCollectionName);\n    doTestConfigUpdate(testCollectionName, solrUrl);\n\n    log.info(\"Running healthcheck for \" + testCollectionName);\n    doTestHealthcheck(testCollectionName, cloudClient.getZkHost());\n\n    // verify the delete action works too\n    log.info(\"Running delete for \"+testCollectionName);\n    doTestDeleteAction(testCollectionName, solrUrl);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection succeeded ... shutting down now!\");\n  }\n\n","sourceOld":"  @Test\n  public void testLoadDocsIntoGettingStartedCollection() throws Exception {\n    waitForThingsToLevelOut(30000);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection initialized OK ... running test logic\");\n\n    String testCollectionName = \"gettingstarted\";\n    File data_driven_schema_configs = new File(ExternalPaths.SCHEMALESS_CONFIGSET);\n    assertTrue(data_driven_schema_configs.getAbsolutePath()+\" not found!\", data_driven_schema_configs.isDirectory());\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    if (liveNodes.isEmpty())\n      fail(\"No live nodes found! Cannot create a collection until there is at least 1 live node in the cluster.\");\n    String firstLiveNode = liveNodes.iterator().next();\n    String solrUrl = cloudClient.getZkStateReader().getBaseUrlForNodeName(firstLiveNode);\n\n    // create the gettingstarted collection just like the bin/solr script would do\n    String[] args = new String[] {\n        \"create_collection\",\n        \"-name\", testCollectionName,\n        \"-shards\", \"2\",\n        \"-replicationFactor\", \"2\",\n        \"-confname\", testCollectionName,\n        \"-confdir\", \"data_driven_schema_configs\",\n        \"-configsetsDir\", data_driven_schema_configs.getParentFile().getParentFile().getAbsolutePath(),\n        \"-solrUrl\", solrUrl\n    };\n    SolrCLI.CreateCollectionTool tool = new SolrCLI.CreateCollectionTool();\n    CommandLine cli = SolrCLI.processCommandLineArgs(SolrCLI.joinCommonAndToolOptions(tool.getOptions()), args);\n    log.info(\"Creating the '\"+testCollectionName+\"' collection using SolrCLI with: \"+solrUrl);\n    tool.runTool(cli);\n    assertTrue(\"Collection '\" + testCollectionName + \"' doesn't exist after trying to create it!\",\n        cloudClient.getZkStateReader().getClusterState().hasCollection(testCollectionName));\n\n    // verify the collection is usable ...\n    ensureAllReplicasAreActive(testCollectionName, \"shard1\", 2, 2, 20);\n    ensureAllReplicasAreActive(testCollectionName, \"shard2\", 2, 2, 10);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    // now index docs like bin/post would do but we can't use SimplePostTool because it uses System.exit when\n    // it encounters an error, which JUnit doesn't like ...\n    log.info(\"Created collection, now posting example docs!\");\n    File exampleDocsDir = new File(ExternalPaths.SOURCE_HOME, \"example/exampledocs\");\n    assertTrue(exampleDocsDir.getAbsolutePath()+\" not found!\", exampleDocsDir.isDirectory());\n\n    List<File> xmlFiles = Arrays.asList(exampleDocsDir.listFiles(new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return name.endsWith(\".xml\");\n      }\n    }));\n\n    // force a deterministic random ordering of the files so seeds reproduce regardless of platform/filesystem\n    Collections.sort(xmlFiles, new Comparator<File>() {\n        public int compare(File o1, File o2) {\n          // don't rely on File.compareTo, it's behavior varies by OS\n          return o1.getName().compareTo(o2.getName());\n        }\n      });\n    Collections.shuffle(xmlFiles, new Random(random().nextLong()));\n\n    // if you add/remove example XML docs, you'll have to fix these expected values\n    int expectedXmlFileCount = 14;\n    int expectedXmlDocCount = 32;\n\n    assertEquals(\"Unexpected # of example XML files in \"+exampleDocsDir.getAbsolutePath(),\n                 expectedXmlFileCount, xmlFiles.size());\n    \n    for (File xml : xmlFiles) {\n      ContentStreamUpdateRequest req = new ContentStreamUpdateRequest(\"/update\");\n      req.addFile(xml, \"application/xml\");\n      log.info(\"POSTing \"+xml.getAbsolutePath());\n      cloudClient.request(req);\n    }\n    cloudClient.commit();\n    Thread.sleep(1000);\n\n    QueryResponse qr = cloudClient.query(new SolrQuery(\"*:*\"));\n    int numFound = (int)qr.getResults().getNumFound();\n    assertEquals(\"*:* found unexpected number of documents\", expectedXmlDocCount, numFound);\n                 \n\n    log.info(\"testLoadDocsIntoGettingStartedCollection succeeded ... shutting down now!\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b3e2df0ef4d31d965ccc4afc2ec6349c06c3cccf","date":1432317730,"type":3,"author":"Timothy Potter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/SolrCloudExampleTest#testLoadDocsIntoGettingStartedCollection().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/SolrCloudExampleTest#testLoadDocsIntoGettingStartedCollection().mjava","sourceNew":"  @Test\n  public void testLoadDocsIntoGettingStartedCollection() throws Exception {\n    waitForThingsToLevelOut(30000);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection initialized OK ... running test logic\");\n\n    String testCollectionName = \"gettingstarted\";\n    File data_driven_schema_configs = new File(ExternalPaths.SCHEMALESS_CONFIGSET);\n    assertTrue(data_driven_schema_configs.getAbsolutePath()+\" not found!\", data_driven_schema_configs.isDirectory());\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    if (liveNodes.isEmpty())\n      fail(\"No live nodes found! Cannot create a collection until there is at least 1 live node in the cluster.\");\n    String firstLiveNode = liveNodes.iterator().next();\n    String solrUrl = cloudClient.getZkStateReader().getBaseUrlForNodeName(firstLiveNode);\n\n    // create the gettingstarted collection just like the bin/solr script would do\n    String[] args = new String[] {\n        \"create_collection\",\n        \"-name\", testCollectionName,\n        \"-shards\", \"2\",\n        \"-replicationFactor\", \"2\",\n        \"-confname\", testCollectionName,\n        \"-confdir\", \"data_driven_schema_configs\",\n        \"-configsetsDir\", data_driven_schema_configs.getParentFile().getParentFile().getAbsolutePath(),\n        \"-solrUrl\", solrUrl\n    };\n    SolrCLI.CreateCollectionTool tool = new SolrCLI.CreateCollectionTool();\n    CommandLine cli = SolrCLI.processCommandLineArgs(SolrCLI.joinCommonAndToolOptions(tool.getOptions()), args);\n    log.info(\"Creating the '\"+testCollectionName+\"' collection using SolrCLI with: \"+solrUrl);\n    tool.runTool(cli);\n    assertTrue(\"Collection '\" + testCollectionName + \"' doesn't exist after trying to create it!\",\n        cloudClient.getZkStateReader().getClusterState().hasCollection(testCollectionName));\n\n    // verify the collection is usable ...\n    ensureAllReplicasAreActive(testCollectionName, \"shard1\", 2, 2, 20);\n    ensureAllReplicasAreActive(testCollectionName, \"shard2\", 2, 2, 10);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    // now index docs like bin/post would do but we can't use SimplePostTool because it uses System.exit when\n    // it encounters an error, which JUnit doesn't like ...\n    log.info(\"Created collection, now posting example docs!\");\n    File exampleDocsDir = new File(ExternalPaths.SOURCE_HOME, \"example/exampledocs\");\n    assertTrue(exampleDocsDir.getAbsolutePath()+\" not found!\", exampleDocsDir.isDirectory());\n\n    List<File> xmlFiles = Arrays.asList(exampleDocsDir.listFiles(new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return name.endsWith(\".xml\");\n      }\n    }));\n\n    // force a deterministic random ordering of the files so seeds reproduce regardless of platform/filesystem\n    Collections.sort(xmlFiles, new Comparator<File>() {\n        public int compare(File o1, File o2) {\n          // don't rely on File.compareTo, it's behavior varies by OS\n          return o1.getName().compareTo(o2.getName());\n        }\n      });\n    Collections.shuffle(xmlFiles, new Random(random().nextLong()));\n\n    // if you add/remove example XML docs, you'll have to fix these expected values\n    int expectedXmlFileCount = 14;\n    int expectedXmlDocCount = 32;\n\n    assertEquals(\"Unexpected # of example XML files in \"+exampleDocsDir.getAbsolutePath(),\n                 expectedXmlFileCount, xmlFiles.size());\n    \n    for (File xml : xmlFiles) {\n      ContentStreamUpdateRequest req = new ContentStreamUpdateRequest(\"/update\");\n      req.addFile(xml, \"application/xml\");\n      log.info(\"POSTing \"+xml.getAbsolutePath());\n      cloudClient.request(req);\n    }\n    cloudClient.commit();\n    Thread.sleep(1000);\n\n    QueryResponse qr = cloudClient.query(new SolrQuery(\"*:*\"));\n    int numFound = (int)qr.getResults().getNumFound();\n    assertEquals(\"*:* found unexpected number of documents\", expectedXmlDocCount, numFound);\n                 \n\n    log.info(\"testLoadDocsIntoGettingStartedCollection succeeded ... shutting down now!\");\n  }\n\n","sourceOld":"  @Test\n  public void testLoadDocsIntoGettingStartedCollection() throws Exception {\n    waitForThingsToLevelOut(30000);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection initialized OK ... running test logic\");\n\n    String testCollectionName = \"gettingstarted\";\n    File data_driven_schema_configs = new File(ExternalPaths.SCHEMALESS_CONFIGSET);\n    assertTrue(data_driven_schema_configs.getAbsolutePath()+\" not found!\", data_driven_schema_configs.isDirectory());\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    if (liveNodes.isEmpty())\n      fail(\"No live nodes found! Cannot create a collection until there is at least 1 live node in the cluster.\");\n    String firstLiveNode = liveNodes.iterator().next();\n    String solrUrl = cloudClient.getZkStateReader().getBaseUrlForNodeName(firstLiveNode);\n\n    // create the gettingstarted collection just like the bin/solr script would do\n    String[] args = new String[] {\n        \"create_collection\",\n        \"-name\", testCollectionName,\n        \"-shards\", \"2\",\n        \"-replicationFactor\", \"2\",\n        \"-confname\", testCollectionName,\n        \"-confdir\", \"data_driven_schema_configs\",\n        \"-configsetsDir\", data_driven_schema_configs.getParentFile().getParentFile().getAbsolutePath(),\n        \"-solrUrl\", solrUrl\n    };\n    SolrCLI.CreateCollectionTool tool = new SolrCLI.CreateCollectionTool();\n    CommandLine cli = SolrCLI.processCommandLineArgs(SolrCLI.joinCommonAndToolOptions(tool.getOptions()), args);\n    log.info(\"Creating the '\"+testCollectionName+\"' collection using SolrCLI with: \"+solrUrl);\n    tool.runTool(cli);\n    assertTrue(\"Collection '\" + testCollectionName + \"' doesn't exist after trying to create it!\",\n        cloudClient.getZkStateReader().getClusterState().hasCollection(testCollectionName));\n\n    // verify the collection is usable ...\n    ensureAllReplicasAreActive(testCollectionName, \"shard1\", 2, 2, 20);\n    ensureAllReplicasAreActive(testCollectionName, \"shard2\", 2, 2, 10);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    // now index docs like bin/post would do but we can't use SimplePostTool because it uses System.exit when\n    // it encounters an error, which JUnit doesn't like ...\n    log.info(\"Created collection, now posting example docs!\");\n    File exampleDocsDir = new File(ExternalPaths.SOURCE_HOME, \"example/exampledocs\");\n    assertTrue(exampleDocsDir.getAbsolutePath()+\" not found!\", exampleDocsDir.isDirectory());\n\n    List<File> xmlFiles = Arrays.asList(exampleDocsDir.listFiles(new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return name.endsWith(\".xml\");\n      }\n    }));\n\n    // force a deterministic random ordering of the files so seeds reproduce regardless of platform/filesystem\n    Collections.sort(xmlFiles, new Comparator<File>() {\n        public int compare(File o1, File o2) {\n          // don't rely on File.compareTo, it's behavior varies by OS\n          return o1.getName().compareTo(o2.getName());\n        }\n      });\n    Collections.shuffle(xmlFiles, new Random(random().nextLong()));\n\n    // if you add/remove example XML docs, you'll have to fix these expected values\n    int expectedXmlFileCount = 14;\n    int expectedXmlDocCount = 32;\n\n    assertEquals(\"Unexpected # of example XML files in \"+exampleDocsDir.getAbsolutePath(),\n                 expectedXmlFileCount, xmlFiles.size());\n    \n    for (File xml : xmlFiles) {\n      ContentStreamUpdateRequest req = new ContentStreamUpdateRequest(\"/update\");\n      req.addFile(xml, \"application/xml\");\n      log.info(\"POSTing \"+xml.getAbsolutePath());\n      cloudClient.request(req);\n    }\n    cloudClient.commit();\n    Thread.sleep(1000);\n\n    QueryResponse qr = cloudClient.query(new SolrQuery(\"*:*\"));\n    int numFound = (int)qr.getResults().getNumFound();\n    assertEquals(\"*:* found unexpected number of documents\", expectedXmlDocCount, numFound);\n\n    log.info(\"Updating Config for \" + testCollectionName);\n    doTestConfigUpdate(testCollectionName, solrUrl);\n\n    log.info(\"Running healthcheck for \" + testCollectionName);\n    doTestHealthcheck(testCollectionName, cloudClient.getZkHost());\n\n    // verify the delete action works too\n    log.info(\"Running delete for \"+testCollectionName);\n    doTestDeleteAction(testCollectionName, solrUrl);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection succeeded ... shutting down now!\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"919a9ff0212f46eb240b8716a6d189b06659d3f2","date":1432317985,"type":3,"author":"Timothy Potter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/SolrCloudExampleTest#testLoadDocsIntoGettingStartedCollection().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/SolrCloudExampleTest#testLoadDocsIntoGettingStartedCollection().mjava","sourceNew":"  @Test\n  public void testLoadDocsIntoGettingStartedCollection() throws Exception {\n    waitForThingsToLevelOut(30000);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection initialized OK ... running test logic\");\n\n    String testCollectionName = \"gettingstarted\";\n    File data_driven_schema_configs = new File(ExternalPaths.SCHEMALESS_CONFIGSET);\n    assertTrue(data_driven_schema_configs.getAbsolutePath()+\" not found!\", data_driven_schema_configs.isDirectory());\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    if (liveNodes.isEmpty())\n      fail(\"No live nodes found! Cannot create a collection until there is at least 1 live node in the cluster.\");\n    String firstLiveNode = liveNodes.iterator().next();\n    String solrUrl = cloudClient.getZkStateReader().getBaseUrlForNodeName(firstLiveNode);\n\n    // create the gettingstarted collection just like the bin/solr script would do\n    String[] args = new String[] {\n        \"create_collection\",\n        \"-name\", testCollectionName,\n        \"-shards\", \"2\",\n        \"-replicationFactor\", \"2\",\n        \"-confname\", testCollectionName,\n        \"-confdir\", \"data_driven_schema_configs\",\n        \"-configsetsDir\", data_driven_schema_configs.getParentFile().getParentFile().getAbsolutePath(),\n        \"-solrUrl\", solrUrl\n    };\n    SolrCLI.CreateCollectionTool tool = new SolrCLI.CreateCollectionTool();\n    CommandLine cli = SolrCLI.processCommandLineArgs(SolrCLI.joinCommonAndToolOptions(tool.getOptions()), args);\n    log.info(\"Creating the '\"+testCollectionName+\"' collection using SolrCLI with: \"+solrUrl);\n    tool.runTool(cli);\n    assertTrue(\"Collection '\" + testCollectionName + \"' doesn't exist after trying to create it!\",\n        cloudClient.getZkStateReader().getClusterState().hasCollection(testCollectionName));\n\n    // verify the collection is usable ...\n    ensureAllReplicasAreActive(testCollectionName, \"shard1\", 2, 2, 20);\n    ensureAllReplicasAreActive(testCollectionName, \"shard2\", 2, 2, 10);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    // now index docs like bin/post would do but we can't use SimplePostTool because it uses System.exit when\n    // it encounters an error, which JUnit doesn't like ...\n    log.info(\"Created collection, now posting example docs!\");\n    File exampleDocsDir = new File(ExternalPaths.SOURCE_HOME, \"example/exampledocs\");\n    assertTrue(exampleDocsDir.getAbsolutePath()+\" not found!\", exampleDocsDir.isDirectory());\n\n    List<File> xmlFiles = Arrays.asList(exampleDocsDir.listFiles(new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return name.endsWith(\".xml\");\n      }\n    }));\n\n    // force a deterministic random ordering of the files so seeds reproduce regardless of platform/filesystem\n    Collections.sort(xmlFiles, new Comparator<File>() {\n        public int compare(File o1, File o2) {\n          // don't rely on File.compareTo, it's behavior varies by OS\n          return o1.getName().compareTo(o2.getName());\n        }\n      });\n    Collections.shuffle(xmlFiles, new Random(random().nextLong()));\n\n    // if you add/remove example XML docs, you'll have to fix these expected values\n    int expectedXmlFileCount = 14;\n    int expectedXmlDocCount = 32;\n\n    assertEquals(\"Unexpected # of example XML files in \"+exampleDocsDir.getAbsolutePath(),\n                 expectedXmlFileCount, xmlFiles.size());\n    \n    for (File xml : xmlFiles) {\n      ContentStreamUpdateRequest req = new ContentStreamUpdateRequest(\"/update\");\n      req.addFile(xml, \"application/xml\");\n      log.info(\"POSTing \"+xml.getAbsolutePath());\n      cloudClient.request(req);\n    }\n    cloudClient.commit();\n    Thread.sleep(1000);\n\n    QueryResponse qr = cloudClient.query(new SolrQuery(\"*:*\"));\n    int numFound = (int)qr.getResults().getNumFound();\n    assertEquals(\"*:* found unexpected number of documents\", expectedXmlDocCount, numFound);\n\n    log.info(\"Updating Config for \" + testCollectionName);\n    doTestConfigUpdate(testCollectionName, solrUrl);\n\n    log.info(\"Running healthcheck for \" + testCollectionName);\n    doTestHealthcheck(testCollectionName, cloudClient.getZkHost());\n\n    // verify the delete action works too\n    log.info(\"Running delete for \"+testCollectionName);\n    doTestDeleteAction(testCollectionName, solrUrl);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection succeeded ... shutting down now!\");\n  }\n\n","sourceOld":"  @Test\n  public void testLoadDocsIntoGettingStartedCollection() throws Exception {\n    waitForThingsToLevelOut(30000);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection initialized OK ... running test logic\");\n\n    String testCollectionName = \"gettingstarted\";\n    File data_driven_schema_configs = new File(ExternalPaths.SCHEMALESS_CONFIGSET);\n    assertTrue(data_driven_schema_configs.getAbsolutePath()+\" not found!\", data_driven_schema_configs.isDirectory());\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    if (liveNodes.isEmpty())\n      fail(\"No live nodes found! Cannot create a collection until there is at least 1 live node in the cluster.\");\n    String firstLiveNode = liveNodes.iterator().next();\n    String solrUrl = cloudClient.getZkStateReader().getBaseUrlForNodeName(firstLiveNode);\n\n    // create the gettingstarted collection just like the bin/solr script would do\n    String[] args = new String[] {\n        \"create_collection\",\n        \"-name\", testCollectionName,\n        \"-shards\", \"2\",\n        \"-replicationFactor\", \"2\",\n        \"-confname\", testCollectionName,\n        \"-confdir\", \"data_driven_schema_configs\",\n        \"-configsetsDir\", data_driven_schema_configs.getParentFile().getParentFile().getAbsolutePath(),\n        \"-solrUrl\", solrUrl\n    };\n    SolrCLI.CreateCollectionTool tool = new SolrCLI.CreateCollectionTool();\n    CommandLine cli = SolrCLI.processCommandLineArgs(SolrCLI.joinCommonAndToolOptions(tool.getOptions()), args);\n    log.info(\"Creating the '\"+testCollectionName+\"' collection using SolrCLI with: \"+solrUrl);\n    tool.runTool(cli);\n    assertTrue(\"Collection '\" + testCollectionName + \"' doesn't exist after trying to create it!\",\n        cloudClient.getZkStateReader().getClusterState().hasCollection(testCollectionName));\n\n    // verify the collection is usable ...\n    ensureAllReplicasAreActive(testCollectionName, \"shard1\", 2, 2, 20);\n    ensureAllReplicasAreActive(testCollectionName, \"shard2\", 2, 2, 10);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    // now index docs like bin/post would do but we can't use SimplePostTool because it uses System.exit when\n    // it encounters an error, which JUnit doesn't like ...\n    log.info(\"Created collection, now posting example docs!\");\n    File exampleDocsDir = new File(ExternalPaths.SOURCE_HOME, \"example/exampledocs\");\n    assertTrue(exampleDocsDir.getAbsolutePath()+\" not found!\", exampleDocsDir.isDirectory());\n\n    List<File> xmlFiles = Arrays.asList(exampleDocsDir.listFiles(new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return name.endsWith(\".xml\");\n      }\n    }));\n\n    // force a deterministic random ordering of the files so seeds reproduce regardless of platform/filesystem\n    Collections.sort(xmlFiles, new Comparator<File>() {\n        public int compare(File o1, File o2) {\n          // don't rely on File.compareTo, it's behavior varies by OS\n          return o1.getName().compareTo(o2.getName());\n        }\n      });\n    Collections.shuffle(xmlFiles, new Random(random().nextLong()));\n\n    // if you add/remove example XML docs, you'll have to fix these expected values\n    int expectedXmlFileCount = 14;\n    int expectedXmlDocCount = 32;\n\n    assertEquals(\"Unexpected # of example XML files in \"+exampleDocsDir.getAbsolutePath(),\n                 expectedXmlFileCount, xmlFiles.size());\n    \n    for (File xml : xmlFiles) {\n      ContentStreamUpdateRequest req = new ContentStreamUpdateRequest(\"/update\");\n      req.addFile(xml, \"application/xml\");\n      log.info(\"POSTing \"+xml.getAbsolutePath());\n      cloudClient.request(req);\n    }\n    cloudClient.commit();\n    Thread.sleep(1000);\n\n    QueryResponse qr = cloudClient.query(new SolrQuery(\"*:*\"));\n    int numFound = (int)qr.getResults().getNumFound();\n    assertEquals(\"*:* found unexpected number of documents\", expectedXmlDocCount, numFound);\n                 \n\n    log.info(\"testLoadDocsIntoGettingStartedCollection succeeded ... shutting down now!\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4ca20be81c9284c840498143264e583ccbb8525a","date":1438705932,"type":3,"author":"Timothy Potter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/SolrCloudExampleTest#testLoadDocsIntoGettingStartedCollection().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/SolrCloudExampleTest#testLoadDocsIntoGettingStartedCollection().mjava","sourceNew":"  @Test\n  public void testLoadDocsIntoGettingStartedCollection() throws Exception {\n    waitForThingsToLevelOut(30000);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection initialized OK ... running test logic\");\n\n    String testCollectionName = \"gettingstarted\";\n    File data_driven_schema_configs = new File(ExternalPaths.SCHEMALESS_CONFIGSET);\n    assertTrue(data_driven_schema_configs.getAbsolutePath()+\" not found!\", data_driven_schema_configs.isDirectory());\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    if (liveNodes.isEmpty())\n      fail(\"No live nodes found! Cannot create a collection until there is at least 1 live node in the cluster.\");\n    String firstLiveNode = liveNodes.iterator().next();\n    String solrUrl = cloudClient.getZkStateReader().getBaseUrlForNodeName(firstLiveNode);\n\n    // create the gettingstarted collection just like the bin/solr script would do\n    String[] args = new String[] {\n        \"-name\", testCollectionName,\n        \"-shards\", \"2\",\n        \"-replicationFactor\", \"2\",\n        \"-confname\", testCollectionName,\n        \"-confdir\", \"data_driven_schema_configs\",\n        \"-configsetsDir\", data_driven_schema_configs.getParentFile().getParentFile().getAbsolutePath(),\n        \"-solrUrl\", solrUrl\n    };\n\n    // NOTE: not calling SolrCLI.main as the script does because it calls System.exit which is a no-no in a JUnit test\n\n    SolrCLI.CreateCollectionTool tool = new SolrCLI.CreateCollectionTool();\n    CommandLine cli = SolrCLI.processCommandLineArgs(SolrCLI.joinCommonAndToolOptions(tool.getOptions()), args);\n    log.info(\"Creating the '\"+testCollectionName+\"' collection using SolrCLI with: \"+solrUrl);\n    tool.runTool(cli);\n    assertTrue(\"Collection '\" + testCollectionName + \"' doesn't exist after trying to create it!\",\n        cloudClient.getZkStateReader().getClusterState().hasCollection(testCollectionName));\n\n    // verify the collection is usable ...\n    ensureAllReplicasAreActive(testCollectionName, \"shard1\", 2, 2, 20);\n    ensureAllReplicasAreActive(testCollectionName, \"shard2\", 2, 2, 10);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    // now index docs like bin/post would do but we can't use SimplePostTool because it uses System.exit when\n    // it encounters an error, which JUnit doesn't like ...\n    log.info(\"Created collection, now posting example docs!\");\n    File exampleDocsDir = new File(ExternalPaths.SOURCE_HOME, \"example/exampledocs\");\n    assertTrue(exampleDocsDir.getAbsolutePath()+\" not found!\", exampleDocsDir.isDirectory());\n\n    List<File> xmlFiles = Arrays.asList(exampleDocsDir.listFiles(new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return name.endsWith(\".xml\");\n      }\n    }));\n\n    // force a deterministic random ordering of the files so seeds reproduce regardless of platform/filesystem\n    Collections.sort(xmlFiles, new Comparator<File>() {\n        public int compare(File o1, File o2) {\n          // don't rely on File.compareTo, it's behavior varies by OS\n          return o1.getName().compareTo(o2.getName());\n        }\n      });\n    Collections.shuffle(xmlFiles, new Random(random().nextLong()));\n\n    // if you add/remove example XML docs, you'll have to fix these expected values\n    int expectedXmlFileCount = 14;\n    int expectedXmlDocCount = 32;\n\n    assertEquals(\"Unexpected # of example XML files in \"+exampleDocsDir.getAbsolutePath(),\n                 expectedXmlFileCount, xmlFiles.size());\n    \n    for (File xml : xmlFiles) {\n      ContentStreamUpdateRequest req = new ContentStreamUpdateRequest(\"/update\");\n      req.addFile(xml, \"application/xml\");\n      log.info(\"POSTing \"+xml.getAbsolutePath());\n      cloudClient.request(req);\n    }\n    cloudClient.commit();\n    Thread.sleep(1000);\n\n    QueryResponse qr = cloudClient.query(new SolrQuery(\"*:*\"));\n    int numFound = (int)qr.getResults().getNumFound();\n    assertEquals(\"*:* found unexpected number of documents\", expectedXmlDocCount, numFound);\n\n    log.info(\"Updating Config for \" + testCollectionName);\n    doTestConfigUpdate(testCollectionName, solrUrl);\n\n    log.info(\"Running healthcheck for \" + testCollectionName);\n    doTestHealthcheck(testCollectionName, cloudClient.getZkHost());\n\n    // verify the delete action works too\n    log.info(\"Running delete for \"+testCollectionName);\n    doTestDeleteAction(testCollectionName, solrUrl);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection succeeded ... shutting down now!\");\n  }\n\n","sourceOld":"  @Test\n  public void testLoadDocsIntoGettingStartedCollection() throws Exception {\n    waitForThingsToLevelOut(30000);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection initialized OK ... running test logic\");\n\n    String testCollectionName = \"gettingstarted\";\n    File data_driven_schema_configs = new File(ExternalPaths.SCHEMALESS_CONFIGSET);\n    assertTrue(data_driven_schema_configs.getAbsolutePath()+\" not found!\", data_driven_schema_configs.isDirectory());\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    if (liveNodes.isEmpty())\n      fail(\"No live nodes found! Cannot create a collection until there is at least 1 live node in the cluster.\");\n    String firstLiveNode = liveNodes.iterator().next();\n    String solrUrl = cloudClient.getZkStateReader().getBaseUrlForNodeName(firstLiveNode);\n\n    // create the gettingstarted collection just like the bin/solr script would do\n    String[] args = new String[] {\n        \"create_collection\",\n        \"-name\", testCollectionName,\n        \"-shards\", \"2\",\n        \"-replicationFactor\", \"2\",\n        \"-confname\", testCollectionName,\n        \"-confdir\", \"data_driven_schema_configs\",\n        \"-configsetsDir\", data_driven_schema_configs.getParentFile().getParentFile().getAbsolutePath(),\n        \"-solrUrl\", solrUrl\n    };\n    SolrCLI.CreateCollectionTool tool = new SolrCLI.CreateCollectionTool();\n    CommandLine cli = SolrCLI.processCommandLineArgs(SolrCLI.joinCommonAndToolOptions(tool.getOptions()), args);\n    log.info(\"Creating the '\"+testCollectionName+\"' collection using SolrCLI with: \"+solrUrl);\n    tool.runTool(cli);\n    assertTrue(\"Collection '\" + testCollectionName + \"' doesn't exist after trying to create it!\",\n        cloudClient.getZkStateReader().getClusterState().hasCollection(testCollectionName));\n\n    // verify the collection is usable ...\n    ensureAllReplicasAreActive(testCollectionName, \"shard1\", 2, 2, 20);\n    ensureAllReplicasAreActive(testCollectionName, \"shard2\", 2, 2, 10);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    // now index docs like bin/post would do but we can't use SimplePostTool because it uses System.exit when\n    // it encounters an error, which JUnit doesn't like ...\n    log.info(\"Created collection, now posting example docs!\");\n    File exampleDocsDir = new File(ExternalPaths.SOURCE_HOME, \"example/exampledocs\");\n    assertTrue(exampleDocsDir.getAbsolutePath()+\" not found!\", exampleDocsDir.isDirectory());\n\n    List<File> xmlFiles = Arrays.asList(exampleDocsDir.listFiles(new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return name.endsWith(\".xml\");\n      }\n    }));\n\n    // force a deterministic random ordering of the files so seeds reproduce regardless of platform/filesystem\n    Collections.sort(xmlFiles, new Comparator<File>() {\n        public int compare(File o1, File o2) {\n          // don't rely on File.compareTo, it's behavior varies by OS\n          return o1.getName().compareTo(o2.getName());\n        }\n      });\n    Collections.shuffle(xmlFiles, new Random(random().nextLong()));\n\n    // if you add/remove example XML docs, you'll have to fix these expected values\n    int expectedXmlFileCount = 14;\n    int expectedXmlDocCount = 32;\n\n    assertEquals(\"Unexpected # of example XML files in \"+exampleDocsDir.getAbsolutePath(),\n                 expectedXmlFileCount, xmlFiles.size());\n    \n    for (File xml : xmlFiles) {\n      ContentStreamUpdateRequest req = new ContentStreamUpdateRequest(\"/update\");\n      req.addFile(xml, \"application/xml\");\n      log.info(\"POSTing \"+xml.getAbsolutePath());\n      cloudClient.request(req);\n    }\n    cloudClient.commit();\n    Thread.sleep(1000);\n\n    QueryResponse qr = cloudClient.query(new SolrQuery(\"*:*\"));\n    int numFound = (int)qr.getResults().getNumFound();\n    assertEquals(\"*:* found unexpected number of documents\", expectedXmlDocCount, numFound);\n\n    log.info(\"Updating Config for \" + testCollectionName);\n    doTestConfigUpdate(testCollectionName, solrUrl);\n\n    log.info(\"Running healthcheck for \" + testCollectionName);\n    doTestHealthcheck(testCollectionName, cloudClient.getZkHost());\n\n    // verify the delete action works too\n    log.info(\"Running delete for \"+testCollectionName);\n    doTestDeleteAction(testCollectionName, solrUrl);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection succeeded ... shutting down now!\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a0c04b71951333291abc7f317109a6a5957bd28","date":1457097827,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/SolrCloudExampleTest#testLoadDocsIntoGettingStartedCollection().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/SolrCloudExampleTest#testLoadDocsIntoGettingStartedCollection().mjava","sourceNew":"  @Test\n  public void testLoadDocsIntoGettingStartedCollection() throws Exception {\n    waitForThingsToLevelOut(30000);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection initialized OK ... running test logic\");\n\n    String testCollectionName = \"gettingstarted\";\n    File data_driven_schema_configs = new File(ExternalPaths.SCHEMALESS_CONFIGSET);\n    assertTrue(data_driven_schema_configs.getAbsolutePath()+\" not found!\", data_driven_schema_configs.isDirectory());\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    if (liveNodes.isEmpty())\n      fail(\"No live nodes found! Cannot create a collection until there is at least 1 live node in the cluster.\");\n    String firstLiveNode = liveNodes.iterator().next();\n    String solrUrl = cloudClient.getZkStateReader().getBaseUrlForNodeName(firstLiveNode);\n\n    // create the gettingstarted collection just like the bin/solr script would do\n    String[] args = new String[] {\n        \"-name\", testCollectionName,\n        \"-shards\", \"2\",\n        \"-replicationFactor\", \"2\",\n        \"-confname\", testCollectionName,\n        \"-confdir\", \"data_driven_schema_configs\",\n        \"-configsetsDir\", data_driven_schema_configs.getParentFile().getParentFile().getAbsolutePath(),\n        \"-solrUrl\", solrUrl\n    };\n\n    // NOTE: not calling SolrCLI.main as the script does because it calls System.exit which is a no-no in a JUnit test\n\n    SolrCLI.CreateCollectionTool tool = new SolrCLI.CreateCollectionTool();\n    CommandLine cli = SolrCLI.processCommandLineArgs(SolrCLI.joinCommonAndToolOptions(tool.getOptions()), args);\n    log.info(\"Creating the '\"+testCollectionName+\"' collection using SolrCLI with: \"+solrUrl);\n    tool.runTool(cli);\n    assertTrue(\"Collection '\" + testCollectionName + \"' doesn't exist after trying to create it!\",\n        cloudClient.getZkStateReader().getClusterState().hasCollection(testCollectionName));\n\n    // verify the collection is usable ...\n    ensureAllReplicasAreActive(testCollectionName, \"shard1\", 2, 2, 20);\n    ensureAllReplicasAreActive(testCollectionName, \"shard2\", 2, 2, 10);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    // now index docs like bin/post would do but we can't use SimplePostTool because it uses System.exit when\n    // it encounters an error, which JUnit doesn't like ...\n    log.info(\"Created collection, now posting example docs!\");\n    File exampleDocsDir = new File(ExternalPaths.SOURCE_HOME, \"example/exampledocs\");\n    assertTrue(exampleDocsDir.getAbsolutePath()+\" not found!\", exampleDocsDir.isDirectory());\n\n    List<File> xmlFiles = Arrays.asList(exampleDocsDir.listFiles(new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return name.endsWith(\".xml\");\n      }\n    }));\n\n    // force a deterministic random ordering of the files so seeds reproduce regardless of platform/filesystem\n    Collections.sort(xmlFiles, (o1, o2) -> {\n      // don't rely on File.compareTo, it's behavior varies by OS\n      return o1.getName().compareTo(o2.getName());\n    });\n    Collections.shuffle(xmlFiles, new Random(random().nextLong()));\n\n    // if you add/remove example XML docs, you'll have to fix these expected values\n    int expectedXmlFileCount = 14;\n    int expectedXmlDocCount = 32;\n\n    assertEquals(\"Unexpected # of example XML files in \"+exampleDocsDir.getAbsolutePath(),\n                 expectedXmlFileCount, xmlFiles.size());\n    \n    for (File xml : xmlFiles) {\n      ContentStreamUpdateRequest req = new ContentStreamUpdateRequest(\"/update\");\n      req.addFile(xml, \"application/xml\");\n      log.info(\"POSTing \"+xml.getAbsolutePath());\n      cloudClient.request(req);\n    }\n    cloudClient.commit();\n    Thread.sleep(1000);\n\n    QueryResponse qr = cloudClient.query(new SolrQuery(\"*:*\"));\n    int numFound = (int)qr.getResults().getNumFound();\n    assertEquals(\"*:* found unexpected number of documents\", expectedXmlDocCount, numFound);\n\n    log.info(\"Updating Config for \" + testCollectionName);\n    doTestConfigUpdate(testCollectionName, solrUrl);\n\n    log.info(\"Running healthcheck for \" + testCollectionName);\n    doTestHealthcheck(testCollectionName, cloudClient.getZkHost());\n\n    // verify the delete action works too\n    log.info(\"Running delete for \"+testCollectionName);\n    doTestDeleteAction(testCollectionName, solrUrl);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection succeeded ... shutting down now!\");\n  }\n\n","sourceOld":"  @Test\n  public void testLoadDocsIntoGettingStartedCollection() throws Exception {\n    waitForThingsToLevelOut(30000);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection initialized OK ... running test logic\");\n\n    String testCollectionName = \"gettingstarted\";\n    File data_driven_schema_configs = new File(ExternalPaths.SCHEMALESS_CONFIGSET);\n    assertTrue(data_driven_schema_configs.getAbsolutePath()+\" not found!\", data_driven_schema_configs.isDirectory());\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    if (liveNodes.isEmpty())\n      fail(\"No live nodes found! Cannot create a collection until there is at least 1 live node in the cluster.\");\n    String firstLiveNode = liveNodes.iterator().next();\n    String solrUrl = cloudClient.getZkStateReader().getBaseUrlForNodeName(firstLiveNode);\n\n    // create the gettingstarted collection just like the bin/solr script would do\n    String[] args = new String[] {\n        \"-name\", testCollectionName,\n        \"-shards\", \"2\",\n        \"-replicationFactor\", \"2\",\n        \"-confname\", testCollectionName,\n        \"-confdir\", \"data_driven_schema_configs\",\n        \"-configsetsDir\", data_driven_schema_configs.getParentFile().getParentFile().getAbsolutePath(),\n        \"-solrUrl\", solrUrl\n    };\n\n    // NOTE: not calling SolrCLI.main as the script does because it calls System.exit which is a no-no in a JUnit test\n\n    SolrCLI.CreateCollectionTool tool = new SolrCLI.CreateCollectionTool();\n    CommandLine cli = SolrCLI.processCommandLineArgs(SolrCLI.joinCommonAndToolOptions(tool.getOptions()), args);\n    log.info(\"Creating the '\"+testCollectionName+\"' collection using SolrCLI with: \"+solrUrl);\n    tool.runTool(cli);\n    assertTrue(\"Collection '\" + testCollectionName + \"' doesn't exist after trying to create it!\",\n        cloudClient.getZkStateReader().getClusterState().hasCollection(testCollectionName));\n\n    // verify the collection is usable ...\n    ensureAllReplicasAreActive(testCollectionName, \"shard1\", 2, 2, 20);\n    ensureAllReplicasAreActive(testCollectionName, \"shard2\", 2, 2, 10);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    // now index docs like bin/post would do but we can't use SimplePostTool because it uses System.exit when\n    // it encounters an error, which JUnit doesn't like ...\n    log.info(\"Created collection, now posting example docs!\");\n    File exampleDocsDir = new File(ExternalPaths.SOURCE_HOME, \"example/exampledocs\");\n    assertTrue(exampleDocsDir.getAbsolutePath()+\" not found!\", exampleDocsDir.isDirectory());\n\n    List<File> xmlFiles = Arrays.asList(exampleDocsDir.listFiles(new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return name.endsWith(\".xml\");\n      }\n    }));\n\n    // force a deterministic random ordering of the files so seeds reproduce regardless of platform/filesystem\n    Collections.sort(xmlFiles, new Comparator<File>() {\n        public int compare(File o1, File o2) {\n          // don't rely on File.compareTo, it's behavior varies by OS\n          return o1.getName().compareTo(o2.getName());\n        }\n      });\n    Collections.shuffle(xmlFiles, new Random(random().nextLong()));\n\n    // if you add/remove example XML docs, you'll have to fix these expected values\n    int expectedXmlFileCount = 14;\n    int expectedXmlDocCount = 32;\n\n    assertEquals(\"Unexpected # of example XML files in \"+exampleDocsDir.getAbsolutePath(),\n                 expectedXmlFileCount, xmlFiles.size());\n    \n    for (File xml : xmlFiles) {\n      ContentStreamUpdateRequest req = new ContentStreamUpdateRequest(\"/update\");\n      req.addFile(xml, \"application/xml\");\n      log.info(\"POSTing \"+xml.getAbsolutePath());\n      cloudClient.request(req);\n    }\n    cloudClient.commit();\n    Thread.sleep(1000);\n\n    QueryResponse qr = cloudClient.query(new SolrQuery(\"*:*\"));\n    int numFound = (int)qr.getResults().getNumFound();\n    assertEquals(\"*:* found unexpected number of documents\", expectedXmlDocCount, numFound);\n\n    log.info(\"Updating Config for \" + testCollectionName);\n    doTestConfigUpdate(testCollectionName, solrUrl);\n\n    log.info(\"Running healthcheck for \" + testCollectionName);\n    doTestHealthcheck(testCollectionName, cloudClient.getZkHost());\n\n    // verify the delete action works too\n    log.info(\"Running delete for \"+testCollectionName);\n    doTestDeleteAction(testCollectionName, solrUrl);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection succeeded ... shutting down now!\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6b7179395314ddf699861fdd8c18857152660e84","date":1463787399,"type":3,"author":"Steve Rowe","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/SolrCloudExampleTest#testLoadDocsIntoGettingStartedCollection().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/SolrCloudExampleTest#testLoadDocsIntoGettingStartedCollection().mjava","sourceNew":"  @Test\n  public void testLoadDocsIntoGettingStartedCollection() throws Exception {\n    waitForThingsToLevelOut(30000);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection initialized OK ... running test logic\");\n\n    String testCollectionName = \"gettingstarted\";\n    File data_driven_schema_configs = new File(ExternalPaths.SCHEMALESS_CONFIGSET);\n    assertTrue(data_driven_schema_configs.getAbsolutePath()+\" not found!\", data_driven_schema_configs.isDirectory());\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    if (liveNodes.isEmpty())\n      fail(\"No live nodes found! Cannot create a collection until there is at least 1 live node in the cluster.\");\n    String firstLiveNode = liveNodes.iterator().next();\n    String solrUrl = cloudClient.getZkStateReader().getBaseUrlForNodeName(firstLiveNode);\n\n    // create the gettingstarted collection just like the bin/solr script would do\n    String[] args = new String[] {\n        \"-name\", testCollectionName,\n        \"-shards\", \"2\",\n        \"-replicationFactor\", \"2\",\n        \"-confname\", testCollectionName,\n        \"-confdir\", \"data_driven_schema_configs\",\n        \"-configsetsDir\", data_driven_schema_configs.getParentFile().getParentFile().getAbsolutePath(),\n        \"-solrUrl\", solrUrl\n    };\n\n    // NOTE: not calling SolrCLI.main as the script does because it calls System.exit which is a no-no in a JUnit test\n\n    SolrCLI.CreateCollectionTool tool = new SolrCLI.CreateCollectionTool();\n    CommandLine cli = SolrCLI.processCommandLineArgs(SolrCLI.joinCommonAndToolOptions(tool.getOptions()), args);\n    log.info(\"Creating the '\"+testCollectionName+\"' collection using SolrCLI with: \"+solrUrl);\n    tool.runTool(cli);\n    assertTrue(\"Collection '\" + testCollectionName + \"' doesn't exist after trying to create it!\",\n        cloudClient.getZkStateReader().getClusterState().hasCollection(testCollectionName));\n\n    // verify the collection is usable ...\n    ensureAllReplicasAreActive(testCollectionName, \"shard1\", 2, 2, 20);\n    ensureAllReplicasAreActive(testCollectionName, \"shard2\", 2, 2, 10);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    int invalidToolExitStatus = 1;\n    assertEquals(\"Collection '\" + testCollectionName + \"' created even though it already existed\",\n        invalidToolExitStatus, tool.runTool(cli));\n\n    // now index docs like bin/post would do but we can't use SimplePostTool because it uses System.exit when\n    // it encounters an error, which JUnit doesn't like ...\n    log.info(\"Created collection, now posting example docs!\");\n    File exampleDocsDir = new File(ExternalPaths.SOURCE_HOME, \"example/exampledocs\");\n    assertTrue(exampleDocsDir.getAbsolutePath()+\" not found!\", exampleDocsDir.isDirectory());\n\n    List<File> xmlFiles = Arrays.asList(exampleDocsDir.listFiles(new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return name.endsWith(\".xml\");\n      }\n    }));\n\n    // force a deterministic random ordering of the files so seeds reproduce regardless of platform/filesystem\n    Collections.sort(xmlFiles, (o1, o2) -> {\n      // don't rely on File.compareTo, it's behavior varies by OS\n      return o1.getName().compareTo(o2.getName());\n    });\n    Collections.shuffle(xmlFiles, new Random(random().nextLong()));\n\n    // if you add/remove example XML docs, you'll have to fix these expected values\n    int expectedXmlFileCount = 14;\n    int expectedXmlDocCount = 32;\n\n    assertEquals(\"Unexpected # of example XML files in \"+exampleDocsDir.getAbsolutePath(),\n                 expectedXmlFileCount, xmlFiles.size());\n    \n    for (File xml : xmlFiles) {\n      ContentStreamUpdateRequest req = new ContentStreamUpdateRequest(\"/update\");\n      req.addFile(xml, \"application/xml\");\n      log.info(\"POSTing \"+xml.getAbsolutePath());\n      cloudClient.request(req);\n    }\n    cloudClient.commit();\n    Thread.sleep(1000);\n\n    QueryResponse qr = cloudClient.query(new SolrQuery(\"*:*\"));\n    int numFound = (int)qr.getResults().getNumFound();\n    assertEquals(\"*:* found unexpected number of documents\", expectedXmlDocCount, numFound);\n\n    log.info(\"Updating Config for \" + testCollectionName);\n    doTestConfigUpdate(testCollectionName, solrUrl);\n\n    log.info(\"Running healthcheck for \" + testCollectionName);\n    doTestHealthcheck(testCollectionName, cloudClient.getZkHost());\n\n    // verify the delete action works too\n    log.info(\"Running delete for \"+testCollectionName);\n    doTestDeleteAction(testCollectionName, solrUrl);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection succeeded ... shutting down now!\");\n  }\n\n","sourceOld":"  @Test\n  public void testLoadDocsIntoGettingStartedCollection() throws Exception {\n    waitForThingsToLevelOut(30000);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection initialized OK ... running test logic\");\n\n    String testCollectionName = \"gettingstarted\";\n    File data_driven_schema_configs = new File(ExternalPaths.SCHEMALESS_CONFIGSET);\n    assertTrue(data_driven_schema_configs.getAbsolutePath()+\" not found!\", data_driven_schema_configs.isDirectory());\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    if (liveNodes.isEmpty())\n      fail(\"No live nodes found! Cannot create a collection until there is at least 1 live node in the cluster.\");\n    String firstLiveNode = liveNodes.iterator().next();\n    String solrUrl = cloudClient.getZkStateReader().getBaseUrlForNodeName(firstLiveNode);\n\n    // create the gettingstarted collection just like the bin/solr script would do\n    String[] args = new String[] {\n        \"-name\", testCollectionName,\n        \"-shards\", \"2\",\n        \"-replicationFactor\", \"2\",\n        \"-confname\", testCollectionName,\n        \"-confdir\", \"data_driven_schema_configs\",\n        \"-configsetsDir\", data_driven_schema_configs.getParentFile().getParentFile().getAbsolutePath(),\n        \"-solrUrl\", solrUrl\n    };\n\n    // NOTE: not calling SolrCLI.main as the script does because it calls System.exit which is a no-no in a JUnit test\n\n    SolrCLI.CreateCollectionTool tool = new SolrCLI.CreateCollectionTool();\n    CommandLine cli = SolrCLI.processCommandLineArgs(SolrCLI.joinCommonAndToolOptions(tool.getOptions()), args);\n    log.info(\"Creating the '\"+testCollectionName+\"' collection using SolrCLI with: \"+solrUrl);\n    tool.runTool(cli);\n    assertTrue(\"Collection '\" + testCollectionName + \"' doesn't exist after trying to create it!\",\n        cloudClient.getZkStateReader().getClusterState().hasCollection(testCollectionName));\n\n    // verify the collection is usable ...\n    ensureAllReplicasAreActive(testCollectionName, \"shard1\", 2, 2, 20);\n    ensureAllReplicasAreActive(testCollectionName, \"shard2\", 2, 2, 10);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    // now index docs like bin/post would do but we can't use SimplePostTool because it uses System.exit when\n    // it encounters an error, which JUnit doesn't like ...\n    log.info(\"Created collection, now posting example docs!\");\n    File exampleDocsDir = new File(ExternalPaths.SOURCE_HOME, \"example/exampledocs\");\n    assertTrue(exampleDocsDir.getAbsolutePath()+\" not found!\", exampleDocsDir.isDirectory());\n\n    List<File> xmlFiles = Arrays.asList(exampleDocsDir.listFiles(new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return name.endsWith(\".xml\");\n      }\n    }));\n\n    // force a deterministic random ordering of the files so seeds reproduce regardless of platform/filesystem\n    Collections.sort(xmlFiles, (o1, o2) -> {\n      // don't rely on File.compareTo, it's behavior varies by OS\n      return o1.getName().compareTo(o2.getName());\n    });\n    Collections.shuffle(xmlFiles, new Random(random().nextLong()));\n\n    // if you add/remove example XML docs, you'll have to fix these expected values\n    int expectedXmlFileCount = 14;\n    int expectedXmlDocCount = 32;\n\n    assertEquals(\"Unexpected # of example XML files in \"+exampleDocsDir.getAbsolutePath(),\n                 expectedXmlFileCount, xmlFiles.size());\n    \n    for (File xml : xmlFiles) {\n      ContentStreamUpdateRequest req = new ContentStreamUpdateRequest(\"/update\");\n      req.addFile(xml, \"application/xml\");\n      log.info(\"POSTing \"+xml.getAbsolutePath());\n      cloudClient.request(req);\n    }\n    cloudClient.commit();\n    Thread.sleep(1000);\n\n    QueryResponse qr = cloudClient.query(new SolrQuery(\"*:*\"));\n    int numFound = (int)qr.getResults().getNumFound();\n    assertEquals(\"*:* found unexpected number of documents\", expectedXmlDocCount, numFound);\n\n    log.info(\"Updating Config for \" + testCollectionName);\n    doTestConfigUpdate(testCollectionName, solrUrl);\n\n    log.info(\"Running healthcheck for \" + testCollectionName);\n    doTestHealthcheck(testCollectionName, cloudClient.getZkHost());\n\n    // verify the delete action works too\n    log.info(\"Running delete for \"+testCollectionName);\n    doTestDeleteAction(testCollectionName, solrUrl);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection succeeded ... shutting down now!\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d470c8182e92b264680e34081b75e70a9f2b3c89","date":1463985353,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/SolrCloudExampleTest#testLoadDocsIntoGettingStartedCollection().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/SolrCloudExampleTest#testLoadDocsIntoGettingStartedCollection().mjava","sourceNew":"  @Test\n  public void testLoadDocsIntoGettingStartedCollection() throws Exception {\n    waitForThingsToLevelOut(30000);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection initialized OK ... running test logic\");\n\n    String testCollectionName = \"gettingstarted\";\n    File data_driven_schema_configs = new File(ExternalPaths.SCHEMALESS_CONFIGSET);\n    assertTrue(data_driven_schema_configs.getAbsolutePath()+\" not found!\", data_driven_schema_configs.isDirectory());\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    if (liveNodes.isEmpty())\n      fail(\"No live nodes found! Cannot create a collection until there is at least 1 live node in the cluster.\");\n    String firstLiveNode = liveNodes.iterator().next();\n    String solrUrl = cloudClient.getZkStateReader().getBaseUrlForNodeName(firstLiveNode);\n\n    // create the gettingstarted collection just like the bin/solr script would do\n    String[] args = new String[] {\n        \"-name\", testCollectionName,\n        \"-shards\", \"2\",\n        \"-replicationFactor\", \"2\",\n        \"-confname\", testCollectionName,\n        \"-confdir\", \"data_driven_schema_configs\",\n        \"-configsetsDir\", data_driven_schema_configs.getParentFile().getParentFile().getAbsolutePath(),\n        \"-solrUrl\", solrUrl\n    };\n\n    // NOTE: not calling SolrCLI.main as the script does because it calls System.exit which is a no-no in a JUnit test\n\n    SolrCLI.CreateCollectionTool tool = new SolrCLI.CreateCollectionTool();\n    CommandLine cli = SolrCLI.processCommandLineArgs(SolrCLI.joinCommonAndToolOptions(tool.getOptions()), args);\n    log.info(\"Creating the '\"+testCollectionName+\"' collection using SolrCLI with: \"+solrUrl);\n    tool.runTool(cli);\n    assertTrue(\"Collection '\" + testCollectionName + \"' doesn't exist after trying to create it!\",\n        cloudClient.getZkStateReader().getClusterState().hasCollection(testCollectionName));\n\n    // verify the collection is usable ...\n    ensureAllReplicasAreActive(testCollectionName, \"shard1\", 2, 2, 20);\n    ensureAllReplicasAreActive(testCollectionName, \"shard2\", 2, 2, 10);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    int invalidToolExitStatus = 1;\n    assertEquals(\"Collection '\" + testCollectionName + \"' created even though it already existed\",\n        invalidToolExitStatus, tool.runTool(cli));\n\n    // now index docs like bin/post would do but we can't use SimplePostTool because it uses System.exit when\n    // it encounters an error, which JUnit doesn't like ...\n    log.info(\"Created collection, now posting example docs!\");\n    File exampleDocsDir = new File(ExternalPaths.SOURCE_HOME, \"example/exampledocs\");\n    assertTrue(exampleDocsDir.getAbsolutePath()+\" not found!\", exampleDocsDir.isDirectory());\n\n    List<File> xmlFiles = Arrays.asList(exampleDocsDir.listFiles(new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return name.endsWith(\".xml\");\n      }\n    }));\n\n    // force a deterministic random ordering of the files so seeds reproduce regardless of platform/filesystem\n    Collections.sort(xmlFiles, (o1, o2) -> {\n      // don't rely on File.compareTo, it's behavior varies by OS\n      return o1.getName().compareTo(o2.getName());\n    });\n    Collections.shuffle(xmlFiles, new Random(random().nextLong()));\n\n    // if you add/remove example XML docs, you'll have to fix these expected values\n    int expectedXmlFileCount = 14;\n    int expectedXmlDocCount = 32;\n\n    assertEquals(\"Unexpected # of example XML files in \"+exampleDocsDir.getAbsolutePath(),\n                 expectedXmlFileCount, xmlFiles.size());\n    \n    for (File xml : xmlFiles) {\n      ContentStreamUpdateRequest req = new ContentStreamUpdateRequest(\"/update\");\n      req.addFile(xml, \"application/xml\");\n      log.info(\"POSTing \"+xml.getAbsolutePath());\n      cloudClient.request(req);\n    }\n    cloudClient.commit();\n    Thread.sleep(1000);\n\n    QueryResponse qr = cloudClient.query(new SolrQuery(\"*:*\"));\n    int numFound = (int)qr.getResults().getNumFound();\n    assertEquals(\"*:* found unexpected number of documents\", expectedXmlDocCount, numFound);\n\n    log.info(\"Updating Config for \" + testCollectionName);\n    doTestConfigUpdate(testCollectionName, solrUrl);\n\n    log.info(\"Running healthcheck for \" + testCollectionName);\n    doTestHealthcheck(testCollectionName, cloudClient.getZkHost());\n\n    // verify the delete action works too\n    log.info(\"Running delete for \"+testCollectionName);\n    doTestDeleteAction(testCollectionName, solrUrl);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection succeeded ... shutting down now!\");\n  }\n\n","sourceOld":"  @Test\n  public void testLoadDocsIntoGettingStartedCollection() throws Exception {\n    waitForThingsToLevelOut(30000);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection initialized OK ... running test logic\");\n\n    String testCollectionName = \"gettingstarted\";\n    File data_driven_schema_configs = new File(ExternalPaths.SCHEMALESS_CONFIGSET);\n    assertTrue(data_driven_schema_configs.getAbsolutePath()+\" not found!\", data_driven_schema_configs.isDirectory());\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    if (liveNodes.isEmpty())\n      fail(\"No live nodes found! Cannot create a collection until there is at least 1 live node in the cluster.\");\n    String firstLiveNode = liveNodes.iterator().next();\n    String solrUrl = cloudClient.getZkStateReader().getBaseUrlForNodeName(firstLiveNode);\n\n    // create the gettingstarted collection just like the bin/solr script would do\n    String[] args = new String[] {\n        \"-name\", testCollectionName,\n        \"-shards\", \"2\",\n        \"-replicationFactor\", \"2\",\n        \"-confname\", testCollectionName,\n        \"-confdir\", \"data_driven_schema_configs\",\n        \"-configsetsDir\", data_driven_schema_configs.getParentFile().getParentFile().getAbsolutePath(),\n        \"-solrUrl\", solrUrl\n    };\n\n    // NOTE: not calling SolrCLI.main as the script does because it calls System.exit which is a no-no in a JUnit test\n\n    SolrCLI.CreateCollectionTool tool = new SolrCLI.CreateCollectionTool();\n    CommandLine cli = SolrCLI.processCommandLineArgs(SolrCLI.joinCommonAndToolOptions(tool.getOptions()), args);\n    log.info(\"Creating the '\"+testCollectionName+\"' collection using SolrCLI with: \"+solrUrl);\n    tool.runTool(cli);\n    assertTrue(\"Collection '\" + testCollectionName + \"' doesn't exist after trying to create it!\",\n        cloudClient.getZkStateReader().getClusterState().hasCollection(testCollectionName));\n\n    // verify the collection is usable ...\n    ensureAllReplicasAreActive(testCollectionName, \"shard1\", 2, 2, 20);\n    ensureAllReplicasAreActive(testCollectionName, \"shard2\", 2, 2, 10);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    // now index docs like bin/post would do but we can't use SimplePostTool because it uses System.exit when\n    // it encounters an error, which JUnit doesn't like ...\n    log.info(\"Created collection, now posting example docs!\");\n    File exampleDocsDir = new File(ExternalPaths.SOURCE_HOME, \"example/exampledocs\");\n    assertTrue(exampleDocsDir.getAbsolutePath()+\" not found!\", exampleDocsDir.isDirectory());\n\n    List<File> xmlFiles = Arrays.asList(exampleDocsDir.listFiles(new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return name.endsWith(\".xml\");\n      }\n    }));\n\n    // force a deterministic random ordering of the files so seeds reproduce regardless of platform/filesystem\n    Collections.sort(xmlFiles, (o1, o2) -> {\n      // don't rely on File.compareTo, it's behavior varies by OS\n      return o1.getName().compareTo(o2.getName());\n    });\n    Collections.shuffle(xmlFiles, new Random(random().nextLong()));\n\n    // if you add/remove example XML docs, you'll have to fix these expected values\n    int expectedXmlFileCount = 14;\n    int expectedXmlDocCount = 32;\n\n    assertEquals(\"Unexpected # of example XML files in \"+exampleDocsDir.getAbsolutePath(),\n                 expectedXmlFileCount, xmlFiles.size());\n    \n    for (File xml : xmlFiles) {\n      ContentStreamUpdateRequest req = new ContentStreamUpdateRequest(\"/update\");\n      req.addFile(xml, \"application/xml\");\n      log.info(\"POSTing \"+xml.getAbsolutePath());\n      cloudClient.request(req);\n    }\n    cloudClient.commit();\n    Thread.sleep(1000);\n\n    QueryResponse qr = cloudClient.query(new SolrQuery(\"*:*\"));\n    int numFound = (int)qr.getResults().getNumFound();\n    assertEquals(\"*:* found unexpected number of documents\", expectedXmlDocCount, numFound);\n\n    log.info(\"Updating Config for \" + testCollectionName);\n    doTestConfigUpdate(testCollectionName, solrUrl);\n\n    log.info(\"Running healthcheck for \" + testCollectionName);\n    doTestHealthcheck(testCollectionName, cloudClient.getZkHost());\n\n    // verify the delete action works too\n    log.info(\"Running delete for \"+testCollectionName);\n    doTestDeleteAction(testCollectionName, solrUrl);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection succeeded ... shutting down now!\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/SolrCloudExampleTest#testLoadDocsIntoGettingStartedCollection().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/SolrCloudExampleTest#testLoadDocsIntoGettingStartedCollection().mjava","sourceNew":"  @Test\n  public void testLoadDocsIntoGettingStartedCollection() throws Exception {\n    waitForThingsToLevelOut(30000);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection initialized OK ... running test logic\");\n\n    String testCollectionName = \"gettingstarted\";\n    File data_driven_schema_configs = new File(ExternalPaths.SCHEMALESS_CONFIGSET);\n    assertTrue(data_driven_schema_configs.getAbsolutePath()+\" not found!\", data_driven_schema_configs.isDirectory());\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    if (liveNodes.isEmpty())\n      fail(\"No live nodes found! Cannot create a collection until there is at least 1 live node in the cluster.\");\n    String firstLiveNode = liveNodes.iterator().next();\n    String solrUrl = cloudClient.getZkStateReader().getBaseUrlForNodeName(firstLiveNode);\n\n    // create the gettingstarted collection just like the bin/solr script would do\n    String[] args = new String[] {\n        \"-name\", testCollectionName,\n        \"-shards\", \"2\",\n        \"-replicationFactor\", \"2\",\n        \"-confname\", testCollectionName,\n        \"-confdir\", \"data_driven_schema_configs\",\n        \"-configsetsDir\", data_driven_schema_configs.getParentFile().getParentFile().getAbsolutePath(),\n        \"-solrUrl\", solrUrl\n    };\n\n    // NOTE: not calling SolrCLI.main as the script does because it calls System.exit which is a no-no in a JUnit test\n\n    SolrCLI.CreateCollectionTool tool = new SolrCLI.CreateCollectionTool();\n    CommandLine cli = SolrCLI.processCommandLineArgs(SolrCLI.joinCommonAndToolOptions(tool.getOptions()), args);\n    log.info(\"Creating the '\"+testCollectionName+\"' collection using SolrCLI with: \"+solrUrl);\n    tool.runTool(cli);\n    assertTrue(\"Collection '\" + testCollectionName + \"' doesn't exist after trying to create it!\",\n        cloudClient.getZkStateReader().getClusterState().hasCollection(testCollectionName));\n\n    // verify the collection is usable ...\n    ensureAllReplicasAreActive(testCollectionName, \"shard1\", 2, 2, 20);\n    ensureAllReplicasAreActive(testCollectionName, \"shard2\", 2, 2, 10);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    int invalidToolExitStatus = 1;\n    assertEquals(\"Collection '\" + testCollectionName + \"' created even though it already existed\",\n        invalidToolExitStatus, tool.runTool(cli));\n\n    // now index docs like bin/post would do but we can't use SimplePostTool because it uses System.exit when\n    // it encounters an error, which JUnit doesn't like ...\n    log.info(\"Created collection, now posting example docs!\");\n    File exampleDocsDir = new File(ExternalPaths.SOURCE_HOME, \"example/exampledocs\");\n    assertTrue(exampleDocsDir.getAbsolutePath()+\" not found!\", exampleDocsDir.isDirectory());\n\n    List<File> xmlFiles = Arrays.asList(exampleDocsDir.listFiles(new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return name.endsWith(\".xml\");\n      }\n    }));\n\n    // force a deterministic random ordering of the files so seeds reproduce regardless of platform/filesystem\n    Collections.sort(xmlFiles, (o1, o2) -> {\n      // don't rely on File.compareTo, it's behavior varies by OS\n      return o1.getName().compareTo(o2.getName());\n    });\n    Collections.shuffle(xmlFiles, new Random(random().nextLong()));\n\n    // if you add/remove example XML docs, you'll have to fix these expected values\n    int expectedXmlFileCount = 14;\n    int expectedXmlDocCount = 32;\n\n    assertEquals(\"Unexpected # of example XML files in \"+exampleDocsDir.getAbsolutePath(),\n                 expectedXmlFileCount, xmlFiles.size());\n    \n    for (File xml : xmlFiles) {\n      ContentStreamUpdateRequest req = new ContentStreamUpdateRequest(\"/update\");\n      req.addFile(xml, \"application/xml\");\n      log.info(\"POSTing \"+xml.getAbsolutePath());\n      cloudClient.request(req);\n    }\n    cloudClient.commit();\n    Thread.sleep(1000);\n\n    QueryResponse qr = cloudClient.query(new SolrQuery(\"*:*\"));\n    int numFound = (int)qr.getResults().getNumFound();\n    assertEquals(\"*:* found unexpected number of documents\", expectedXmlDocCount, numFound);\n\n    log.info(\"Updating Config for \" + testCollectionName);\n    doTestConfigUpdate(testCollectionName, solrUrl);\n\n    log.info(\"Running healthcheck for \" + testCollectionName);\n    doTestHealthcheck(testCollectionName, cloudClient.getZkHost());\n\n    // verify the delete action works too\n    log.info(\"Running delete for \"+testCollectionName);\n    doTestDeleteAction(testCollectionName, solrUrl);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection succeeded ... shutting down now!\");\n  }\n\n","sourceOld":"  @Test\n  public void testLoadDocsIntoGettingStartedCollection() throws Exception {\n    waitForThingsToLevelOut(30000);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection initialized OK ... running test logic\");\n\n    String testCollectionName = \"gettingstarted\";\n    File data_driven_schema_configs = new File(ExternalPaths.SCHEMALESS_CONFIGSET);\n    assertTrue(data_driven_schema_configs.getAbsolutePath()+\" not found!\", data_driven_schema_configs.isDirectory());\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    if (liveNodes.isEmpty())\n      fail(\"No live nodes found! Cannot create a collection until there is at least 1 live node in the cluster.\");\n    String firstLiveNode = liveNodes.iterator().next();\n    String solrUrl = cloudClient.getZkStateReader().getBaseUrlForNodeName(firstLiveNode);\n\n    // create the gettingstarted collection just like the bin/solr script would do\n    String[] args = new String[] {\n        \"-name\", testCollectionName,\n        \"-shards\", \"2\",\n        \"-replicationFactor\", \"2\",\n        \"-confname\", testCollectionName,\n        \"-confdir\", \"data_driven_schema_configs\",\n        \"-configsetsDir\", data_driven_schema_configs.getParentFile().getParentFile().getAbsolutePath(),\n        \"-solrUrl\", solrUrl\n    };\n\n    // NOTE: not calling SolrCLI.main as the script does because it calls System.exit which is a no-no in a JUnit test\n\n    SolrCLI.CreateCollectionTool tool = new SolrCLI.CreateCollectionTool();\n    CommandLine cli = SolrCLI.processCommandLineArgs(SolrCLI.joinCommonAndToolOptions(tool.getOptions()), args);\n    log.info(\"Creating the '\"+testCollectionName+\"' collection using SolrCLI with: \"+solrUrl);\n    tool.runTool(cli);\n    assertTrue(\"Collection '\" + testCollectionName + \"' doesn't exist after trying to create it!\",\n        cloudClient.getZkStateReader().getClusterState().hasCollection(testCollectionName));\n\n    // verify the collection is usable ...\n    ensureAllReplicasAreActive(testCollectionName, \"shard1\", 2, 2, 20);\n    ensureAllReplicasAreActive(testCollectionName, \"shard2\", 2, 2, 10);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    // now index docs like bin/post would do but we can't use SimplePostTool because it uses System.exit when\n    // it encounters an error, which JUnit doesn't like ...\n    log.info(\"Created collection, now posting example docs!\");\n    File exampleDocsDir = new File(ExternalPaths.SOURCE_HOME, \"example/exampledocs\");\n    assertTrue(exampleDocsDir.getAbsolutePath()+\" not found!\", exampleDocsDir.isDirectory());\n\n    List<File> xmlFiles = Arrays.asList(exampleDocsDir.listFiles(new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return name.endsWith(\".xml\");\n      }\n    }));\n\n    // force a deterministic random ordering of the files so seeds reproduce regardless of platform/filesystem\n    Collections.sort(xmlFiles, (o1, o2) -> {\n      // don't rely on File.compareTo, it's behavior varies by OS\n      return o1.getName().compareTo(o2.getName());\n    });\n    Collections.shuffle(xmlFiles, new Random(random().nextLong()));\n\n    // if you add/remove example XML docs, you'll have to fix these expected values\n    int expectedXmlFileCount = 14;\n    int expectedXmlDocCount = 32;\n\n    assertEquals(\"Unexpected # of example XML files in \"+exampleDocsDir.getAbsolutePath(),\n                 expectedXmlFileCount, xmlFiles.size());\n    \n    for (File xml : xmlFiles) {\n      ContentStreamUpdateRequest req = new ContentStreamUpdateRequest(\"/update\");\n      req.addFile(xml, \"application/xml\");\n      log.info(\"POSTing \"+xml.getAbsolutePath());\n      cloudClient.request(req);\n    }\n    cloudClient.commit();\n    Thread.sleep(1000);\n\n    QueryResponse qr = cloudClient.query(new SolrQuery(\"*:*\"));\n    int numFound = (int)qr.getResults().getNumFound();\n    assertEquals(\"*:* found unexpected number of documents\", expectedXmlDocCount, numFound);\n\n    log.info(\"Updating Config for \" + testCollectionName);\n    doTestConfigUpdate(testCollectionName, solrUrl);\n\n    log.info(\"Running healthcheck for \" + testCollectionName);\n    doTestHealthcheck(testCollectionName, cloudClient.getZkHost());\n\n    // verify the delete action works too\n    log.info(\"Running delete for \"+testCollectionName);\n    doTestDeleteAction(testCollectionName, solrUrl);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection succeeded ... shutting down now!\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fb239ff148d77d2846f7c73b4b1f0ecb0827c0d5","date":1493061731,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/SolrCloudExampleTest#testLoadDocsIntoGettingStartedCollection().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/SolrCloudExampleTest#testLoadDocsIntoGettingStartedCollection().mjava","sourceNew":"  @Test\n  public void testLoadDocsIntoGettingStartedCollection() throws Exception {\n    waitForThingsToLevelOut(30000);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection initialized OK ... running test logic\");\n\n    String testCollectionName = \"gettingstarted\";\n    File data_driven_schema_configs = new File(ExternalPaths.SCHEMALESS_CONFIGSET);\n    assertTrue(data_driven_schema_configs.getAbsolutePath()+\" not found!\", data_driven_schema_configs.isDirectory());\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    if (liveNodes.isEmpty())\n      fail(\"No live nodes found! Cannot create a collection until there is at least 1 live node in the cluster.\");\n    String firstLiveNode = liveNodes.iterator().next();\n    String solrUrl = cloudClient.getZkStateReader().getBaseUrlForNodeName(firstLiveNode);\n\n    // create the gettingstarted collection just like the bin/solr script would do\n    String[] args = new String[] {\n        \"-name\", testCollectionName,\n        \"-shards\", \"2\",\n        \"-replicationFactor\", \"2\",\n        \"-confname\", testCollectionName,\n        \"-confdir\", \"data_driven_schema_configs\",\n        \"-configsetsDir\", data_driven_schema_configs.getParentFile().getParentFile().getAbsolutePath(),\n        \"-solrUrl\", solrUrl\n    };\n\n    // NOTE: not calling SolrCLI.main as the script does because it calls System.exit which is a no-no in a JUnit test\n\n    SolrCLI.CreateCollectionTool tool = new SolrCLI.CreateCollectionTool();\n    CommandLine cli = SolrCLI.processCommandLineArgs(SolrCLI.joinCommonAndToolOptions(tool.getOptions()), args);\n    log.info(\"Creating the '\"+testCollectionName+\"' collection using SolrCLI with: \"+solrUrl);\n    tool.runTool(cli);\n    assertTrue(\"Collection '\" + testCollectionName + \"' doesn't exist after trying to create it!\",\n        cloudClient.getZkStateReader().getClusterState().hasCollection(testCollectionName));\n\n    // verify the collection is usable ...\n    ensureAllReplicasAreActive(testCollectionName, \"shard1\", 2, 2, 20);\n    ensureAllReplicasAreActive(testCollectionName, \"shard2\", 2, 2, 10);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    int invalidToolExitStatus = 1;\n    assertEquals(\"Collection '\" + testCollectionName + \"' created even though it already existed\",\n        invalidToolExitStatus, tool.runTool(cli));\n\n    // now index docs like bin/post would do but we can't use SimplePostTool because it uses System.exit when\n    // it encounters an error, which JUnit doesn't like ...\n    log.info(\"Created collection, now posting example docs!\");\n    File exampleDocsDir = new File(ExternalPaths.SOURCE_HOME, \"example/exampledocs\");\n    assertTrue(exampleDocsDir.getAbsolutePath()+\" not found!\", exampleDocsDir.isDirectory());\n\n    List<File> xmlFiles = Arrays.asList(exampleDocsDir.listFiles(new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return name.endsWith(\".xml\");\n      }\n    }));\n\n    // force a deterministic random ordering of the files so seeds reproduce regardless of platform/filesystem\n    Collections.sort(xmlFiles, (o1, o2) -> {\n      // don't rely on File.compareTo, it's behavior varies by OS\n      return o1.getName().compareTo(o2.getName());\n    });\n    Collections.shuffle(xmlFiles, new Random(random().nextLong()));\n\n    // if you add/remove example XML docs, you'll have to fix these expected values\n    int expectedXmlFileCount = 14;\n    int expectedXmlDocCount = 32;\n\n    assertEquals(\"Unexpected # of example XML files in \"+exampleDocsDir.getAbsolutePath(),\n                 expectedXmlFileCount, xmlFiles.size());\n    \n    for (File xml : xmlFiles) {\n      ContentStreamUpdateRequest req = new ContentStreamUpdateRequest(\"/update\");\n      req.addFile(xml, \"application/xml\");\n      log.info(\"POSTing \"+xml.getAbsolutePath());\n      cloudClient.request(req);\n    }\n    cloudClient.commit();\n\n    int numFound = 0;\n\n    // give the update a chance to take effect.\n    for (int idx = 0; idx < 100; ++idx) {\n      QueryResponse qr = cloudClient.query(new SolrQuery(\"*:*\"));\n      numFound = (int) qr.getResults().getNumFound();\n      if (numFound == expectedXmlDocCount) break;\n      Thread.sleep(100);\n    }\n    assertEquals(\"*:* found unexpected number of documents\", expectedXmlDocCount, numFound);\n\n    log.info(\"Updating Config for \" + testCollectionName);\n    doTestConfigUpdate(testCollectionName, solrUrl);\n\n    log.info(\"Running healthcheck for \" + testCollectionName);\n    doTestHealthcheck(testCollectionName, cloudClient.getZkHost());\n\n    // verify the delete action works too\n    log.info(\"Running delete for \"+testCollectionName);\n    doTestDeleteAction(testCollectionName, solrUrl);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection succeeded ... shutting down now!\");\n  }\n\n","sourceOld":"  @Test\n  public void testLoadDocsIntoGettingStartedCollection() throws Exception {\n    waitForThingsToLevelOut(30000);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection initialized OK ... running test logic\");\n\n    String testCollectionName = \"gettingstarted\";\n    File data_driven_schema_configs = new File(ExternalPaths.SCHEMALESS_CONFIGSET);\n    assertTrue(data_driven_schema_configs.getAbsolutePath()+\" not found!\", data_driven_schema_configs.isDirectory());\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    if (liveNodes.isEmpty())\n      fail(\"No live nodes found! Cannot create a collection until there is at least 1 live node in the cluster.\");\n    String firstLiveNode = liveNodes.iterator().next();\n    String solrUrl = cloudClient.getZkStateReader().getBaseUrlForNodeName(firstLiveNode);\n\n    // create the gettingstarted collection just like the bin/solr script would do\n    String[] args = new String[] {\n        \"-name\", testCollectionName,\n        \"-shards\", \"2\",\n        \"-replicationFactor\", \"2\",\n        \"-confname\", testCollectionName,\n        \"-confdir\", \"data_driven_schema_configs\",\n        \"-configsetsDir\", data_driven_schema_configs.getParentFile().getParentFile().getAbsolutePath(),\n        \"-solrUrl\", solrUrl\n    };\n\n    // NOTE: not calling SolrCLI.main as the script does because it calls System.exit which is a no-no in a JUnit test\n\n    SolrCLI.CreateCollectionTool tool = new SolrCLI.CreateCollectionTool();\n    CommandLine cli = SolrCLI.processCommandLineArgs(SolrCLI.joinCommonAndToolOptions(tool.getOptions()), args);\n    log.info(\"Creating the '\"+testCollectionName+\"' collection using SolrCLI with: \"+solrUrl);\n    tool.runTool(cli);\n    assertTrue(\"Collection '\" + testCollectionName + \"' doesn't exist after trying to create it!\",\n        cloudClient.getZkStateReader().getClusterState().hasCollection(testCollectionName));\n\n    // verify the collection is usable ...\n    ensureAllReplicasAreActive(testCollectionName, \"shard1\", 2, 2, 20);\n    ensureAllReplicasAreActive(testCollectionName, \"shard2\", 2, 2, 10);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    int invalidToolExitStatus = 1;\n    assertEquals(\"Collection '\" + testCollectionName + \"' created even though it already existed\",\n        invalidToolExitStatus, tool.runTool(cli));\n\n    // now index docs like bin/post would do but we can't use SimplePostTool because it uses System.exit when\n    // it encounters an error, which JUnit doesn't like ...\n    log.info(\"Created collection, now posting example docs!\");\n    File exampleDocsDir = new File(ExternalPaths.SOURCE_HOME, \"example/exampledocs\");\n    assertTrue(exampleDocsDir.getAbsolutePath()+\" not found!\", exampleDocsDir.isDirectory());\n\n    List<File> xmlFiles = Arrays.asList(exampleDocsDir.listFiles(new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return name.endsWith(\".xml\");\n      }\n    }));\n\n    // force a deterministic random ordering of the files so seeds reproduce regardless of platform/filesystem\n    Collections.sort(xmlFiles, (o1, o2) -> {\n      // don't rely on File.compareTo, it's behavior varies by OS\n      return o1.getName().compareTo(o2.getName());\n    });\n    Collections.shuffle(xmlFiles, new Random(random().nextLong()));\n\n    // if you add/remove example XML docs, you'll have to fix these expected values\n    int expectedXmlFileCount = 14;\n    int expectedXmlDocCount = 32;\n\n    assertEquals(\"Unexpected # of example XML files in \"+exampleDocsDir.getAbsolutePath(),\n                 expectedXmlFileCount, xmlFiles.size());\n    \n    for (File xml : xmlFiles) {\n      ContentStreamUpdateRequest req = new ContentStreamUpdateRequest(\"/update\");\n      req.addFile(xml, \"application/xml\");\n      log.info(\"POSTing \"+xml.getAbsolutePath());\n      cloudClient.request(req);\n    }\n    cloudClient.commit();\n    Thread.sleep(1000);\n\n    QueryResponse qr = cloudClient.query(new SolrQuery(\"*:*\"));\n    int numFound = (int)qr.getResults().getNumFound();\n    assertEquals(\"*:* found unexpected number of documents\", expectedXmlDocCount, numFound);\n\n    log.info(\"Updating Config for \" + testCollectionName);\n    doTestConfigUpdate(testCollectionName, solrUrl);\n\n    log.info(\"Running healthcheck for \" + testCollectionName);\n    doTestHealthcheck(testCollectionName, cloudClient.getZkHost());\n\n    // verify the delete action works too\n    log.info(\"Running delete for \"+testCollectionName);\n    doTestDeleteAction(testCollectionName, solrUrl);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection succeeded ... shutting down now!\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e9017cf144952056066919f1ebc7897ff9bd71b1","date":1496757600,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/SolrCloudExampleTest#testLoadDocsIntoGettingStartedCollection().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/SolrCloudExampleTest#testLoadDocsIntoGettingStartedCollection().mjava","sourceNew":"  @Test\n  public void testLoadDocsIntoGettingStartedCollection() throws Exception {\n    waitForThingsToLevelOut(30000);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection initialized OK ... running test logic\");\n\n    String testCollectionName = \"gettingstarted\";\n    File data_driven_schema_configs = new File(ExternalPaths.SCHEMALESS_CONFIGSET);\n    assertTrue(data_driven_schema_configs.getAbsolutePath()+\" not found!\", data_driven_schema_configs.isDirectory());\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    if (liveNodes.isEmpty())\n      fail(\"No live nodes found! Cannot create a collection until there is at least 1 live node in the cluster.\");\n    String firstLiveNode = liveNodes.iterator().next();\n    String solrUrl = cloudClient.getZkStateReader().getBaseUrlForNodeName(firstLiveNode);\n\n    // create the gettingstarted collection just like the bin/solr script would do\n    String[] args = new String[] {\n        \"-name\", testCollectionName,\n        \"-shards\", \"2\",\n        \"-replicationFactor\", \"2\",\n        \"-confname\", testCollectionName,\n        \"-confdir\", \"data_driven_schema_configs\",\n        \"-configsetsDir\", data_driven_schema_configs.getParentFile().getParentFile().getAbsolutePath(),\n        \"-solrUrl\", solrUrl\n    };\n\n    // NOTE: not calling SolrCLI.main as the script does because it calls System.exit which is a no-no in a JUnit test\n\n    SolrCLI.CreateCollectionTool tool = new SolrCLI.CreateCollectionTool();\n    CommandLine cli = SolrCLI.processCommandLineArgs(SolrCLI.joinCommonAndToolOptions(tool.getOptions()), args);\n    log.info(\"Creating the '\"+testCollectionName+\"' collection using SolrCLI with: \"+solrUrl);\n    tool.runTool(cli);\n    assertTrue(\"Collection '\" + testCollectionName + \"' doesn't exist after trying to create it!\",\n        cloudClient.getZkStateReader().getClusterState().hasCollection(testCollectionName));\n\n    // verify the collection is usable ...\n    ensureAllReplicasAreActive(testCollectionName, \"shard1\", 2, 2, 20);\n    ensureAllReplicasAreActive(testCollectionName, \"shard2\", 2, 2, 10);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    int invalidToolExitStatus = 1;\n    assertEquals(\"Collection '\" + testCollectionName + \"' created even though it already existed\",\n        invalidToolExitStatus, tool.runTool(cli));\n\n    // now index docs like bin/post would do but we can't use SimplePostTool because it uses System.exit when\n    // it encounters an error, which JUnit doesn't like ...\n    log.info(\"Created collection, now posting example docs!\");\n    File exampleDocsDir = new File(ExternalPaths.SOURCE_HOME, \"example/exampledocs\");\n    assertTrue(exampleDocsDir.getAbsolutePath()+\" not found!\", exampleDocsDir.isDirectory());\n\n    List<File> xmlFiles = Arrays.asList(exampleDocsDir.listFiles(new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return name.endsWith(\".xml\");\n      }\n    }));\n\n    // force a deterministic random ordering of the files so seeds reproduce regardless of platform/filesystem\n    Collections.sort(xmlFiles, (o1, o2) -> {\n      // don't rely on File.compareTo, it's behavior varies by OS\n      return o1.getName().compareTo(o2.getName());\n    });\n    Collections.shuffle(xmlFiles, new Random(random().nextLong()));\n\n    // if you add/remove example XML docs, you'll have to fix these expected values\n    int expectedXmlFileCount = 14;\n    int expectedXmlDocCount = 32;\n\n    assertEquals(\"Unexpected # of example XML files in \"+exampleDocsDir.getAbsolutePath(),\n                 expectedXmlFileCount, xmlFiles.size());\n    \n    for (File xml : xmlFiles) {\n      ContentStreamUpdateRequest req = new ContentStreamUpdateRequest(\"/update\");\n      req.addFile(xml, \"application/xml\");\n      log.info(\"POSTing \"+xml.getAbsolutePath());\n      cloudClient.request(req);\n    }\n    cloudClient.commit();\n\n    int numFound = 0;\n\n    // give the update a chance to take effect.\n    for (int idx = 0; idx < 100; ++idx) {\n      QueryResponse qr = cloudClient.query(new SolrQuery(\"*:*\"));\n      numFound = (int) qr.getResults().getNumFound();\n      if (numFound == expectedXmlDocCount) break;\n      Thread.sleep(100);\n    }\n    assertEquals(\"*:* found unexpected number of documents\", expectedXmlDocCount, numFound);\n\n    log.info(\"Updating Config for \" + testCollectionName);\n    doTestConfigUpdate(testCollectionName, solrUrl);\n\n    log.info(\"Running healthcheck for \" + testCollectionName);\n    doTestHealthcheck(testCollectionName, cloudClient.getZkHost());\n\n    // verify the delete action works too\n    log.info(\"Running delete for \"+testCollectionName);\n    doTestDeleteAction(testCollectionName, solrUrl);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection succeeded ... shutting down now!\");\n  }\n\n","sourceOld":"  @Test\n  public void testLoadDocsIntoGettingStartedCollection() throws Exception {\n    waitForThingsToLevelOut(30000);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection initialized OK ... running test logic\");\n\n    String testCollectionName = \"gettingstarted\";\n    File data_driven_schema_configs = new File(ExternalPaths.SCHEMALESS_CONFIGSET);\n    assertTrue(data_driven_schema_configs.getAbsolutePath()+\" not found!\", data_driven_schema_configs.isDirectory());\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    if (liveNodes.isEmpty())\n      fail(\"No live nodes found! Cannot create a collection until there is at least 1 live node in the cluster.\");\n    String firstLiveNode = liveNodes.iterator().next();\n    String solrUrl = cloudClient.getZkStateReader().getBaseUrlForNodeName(firstLiveNode);\n\n    // create the gettingstarted collection just like the bin/solr script would do\n    String[] args = new String[] {\n        \"-name\", testCollectionName,\n        \"-shards\", \"2\",\n        \"-replicationFactor\", \"2\",\n        \"-confname\", testCollectionName,\n        \"-confdir\", \"data_driven_schema_configs\",\n        \"-configsetsDir\", data_driven_schema_configs.getParentFile().getParentFile().getAbsolutePath(),\n        \"-solrUrl\", solrUrl\n    };\n\n    // NOTE: not calling SolrCLI.main as the script does because it calls System.exit which is a no-no in a JUnit test\n\n    SolrCLI.CreateCollectionTool tool = new SolrCLI.CreateCollectionTool();\n    CommandLine cli = SolrCLI.processCommandLineArgs(SolrCLI.joinCommonAndToolOptions(tool.getOptions()), args);\n    log.info(\"Creating the '\"+testCollectionName+\"' collection using SolrCLI with: \"+solrUrl);\n    tool.runTool(cli);\n    assertTrue(\"Collection '\" + testCollectionName + \"' doesn't exist after trying to create it!\",\n        cloudClient.getZkStateReader().getClusterState().hasCollection(testCollectionName));\n\n    // verify the collection is usable ...\n    ensureAllReplicasAreActive(testCollectionName, \"shard1\", 2, 2, 20);\n    ensureAllReplicasAreActive(testCollectionName, \"shard2\", 2, 2, 10);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    int invalidToolExitStatus = 1;\n    assertEquals(\"Collection '\" + testCollectionName + \"' created even though it already existed\",\n        invalidToolExitStatus, tool.runTool(cli));\n\n    // now index docs like bin/post would do but we can't use SimplePostTool because it uses System.exit when\n    // it encounters an error, which JUnit doesn't like ...\n    log.info(\"Created collection, now posting example docs!\");\n    File exampleDocsDir = new File(ExternalPaths.SOURCE_HOME, \"example/exampledocs\");\n    assertTrue(exampleDocsDir.getAbsolutePath()+\" not found!\", exampleDocsDir.isDirectory());\n\n    List<File> xmlFiles = Arrays.asList(exampleDocsDir.listFiles(new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return name.endsWith(\".xml\");\n      }\n    }));\n\n    // force a deterministic random ordering of the files so seeds reproduce regardless of platform/filesystem\n    Collections.sort(xmlFiles, (o1, o2) -> {\n      // don't rely on File.compareTo, it's behavior varies by OS\n      return o1.getName().compareTo(o2.getName());\n    });\n    Collections.shuffle(xmlFiles, new Random(random().nextLong()));\n\n    // if you add/remove example XML docs, you'll have to fix these expected values\n    int expectedXmlFileCount = 14;\n    int expectedXmlDocCount = 32;\n\n    assertEquals(\"Unexpected # of example XML files in \"+exampleDocsDir.getAbsolutePath(),\n                 expectedXmlFileCount, xmlFiles.size());\n    \n    for (File xml : xmlFiles) {\n      ContentStreamUpdateRequest req = new ContentStreamUpdateRequest(\"/update\");\n      req.addFile(xml, \"application/xml\");\n      log.info(\"POSTing \"+xml.getAbsolutePath());\n      cloudClient.request(req);\n    }\n    cloudClient.commit();\n    Thread.sleep(1000);\n\n    QueryResponse qr = cloudClient.query(new SolrQuery(\"*:*\"));\n    int numFound = (int)qr.getResults().getNumFound();\n    assertEquals(\"*:* found unexpected number of documents\", expectedXmlDocCount, numFound);\n\n    log.info(\"Updating Config for \" + testCollectionName);\n    doTestConfigUpdate(testCollectionName, solrUrl);\n\n    log.info(\"Running healthcheck for \" + testCollectionName);\n    doTestHealthcheck(testCollectionName, cloudClient.getZkHost());\n\n    // verify the delete action works too\n    log.info(\"Running delete for \"+testCollectionName);\n    doTestDeleteAction(testCollectionName, solrUrl);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection succeeded ... shutting down now!\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6dac22e2c68188d3e5c96ca60febedc05a96f44f","date":1498433282,"type":3,"author":"Ishan Chattopadhyaya","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/SolrCloudExampleTest#testLoadDocsIntoGettingStartedCollection().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/SolrCloudExampleTest#testLoadDocsIntoGettingStartedCollection().mjava","sourceNew":"  @Test\n  public void testLoadDocsIntoGettingStartedCollection() throws Exception {\n    waitForThingsToLevelOut(30000);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection initialized OK ... running test logic\");\n\n    String testCollectionName = \"gettingstarted\";\n    File defaultConfigs = new File(ExternalPaths.DEFAULT_CONFIGSET);\n    assertTrue(defaultConfigs.getAbsolutePath()+\" not found!\", defaultConfigs.isDirectory());\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    if (liveNodes.isEmpty())\n      fail(\"No live nodes found! Cannot create a collection until there is at least 1 live node in the cluster.\");\n    String firstLiveNode = liveNodes.iterator().next();\n    String solrUrl = cloudClient.getZkStateReader().getBaseUrlForNodeName(firstLiveNode);\n\n    // create the gettingstarted collection just like the bin/solr script would do\n    String[] args = new String[] {\n        \"-name\", testCollectionName,\n        \"-shards\", \"2\",\n        \"-replicationFactor\", \"2\",\n        \"-confname\", testCollectionName,\n        \"-confdir\", \"_default\",\n        \"-configsetsDir\", defaultConfigs.getParentFile().getParentFile().getAbsolutePath(),\n        \"-solrUrl\", solrUrl\n    };\n\n    // NOTE: not calling SolrCLI.main as the script does because it calls System.exit which is a no-no in a JUnit test\n\n    SolrCLI.CreateCollectionTool tool = new SolrCLI.CreateCollectionTool();\n    CommandLine cli = SolrCLI.processCommandLineArgs(SolrCLI.joinCommonAndToolOptions(tool.getOptions()), args);\n    log.info(\"Creating the '\"+testCollectionName+\"' collection using SolrCLI with: \"+solrUrl);\n    tool.runTool(cli);\n    assertTrue(\"Collection '\" + testCollectionName + \"' doesn't exist after trying to create it!\",\n        cloudClient.getZkStateReader().getClusterState().hasCollection(testCollectionName));\n\n    // verify the collection is usable ...\n    ensureAllReplicasAreActive(testCollectionName, \"shard1\", 2, 2, 20);\n    ensureAllReplicasAreActive(testCollectionName, \"shard2\", 2, 2, 10);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    int invalidToolExitStatus = 1;\n    assertEquals(\"Collection '\" + testCollectionName + \"' created even though it already existed\",\n        invalidToolExitStatus, tool.runTool(cli));\n\n    // now index docs like bin/post would do but we can't use SimplePostTool because it uses System.exit when\n    // it encounters an error, which JUnit doesn't like ...\n    log.info(\"Created collection, now posting example docs!\");\n    File exampleDocsDir = new File(ExternalPaths.SOURCE_HOME, \"example/exampledocs\");\n    assertTrue(exampleDocsDir.getAbsolutePath()+\" not found!\", exampleDocsDir.isDirectory());\n\n    List<File> xmlFiles = Arrays.asList(exampleDocsDir.listFiles(new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return name.endsWith(\".xml\");\n      }\n    }));\n\n    // force a deterministic random ordering of the files so seeds reproduce regardless of platform/filesystem\n    Collections.sort(xmlFiles, (o1, o2) -> {\n      // don't rely on File.compareTo, it's behavior varies by OS\n      return o1.getName().compareTo(o2.getName());\n    });\n    Collections.shuffle(xmlFiles, new Random(random().nextLong()));\n\n    // if you add/remove example XML docs, you'll have to fix these expected values\n    int expectedXmlFileCount = 14;\n    int expectedXmlDocCount = 32;\n\n    assertEquals(\"Unexpected # of example XML files in \"+exampleDocsDir.getAbsolutePath(),\n                 expectedXmlFileCount, xmlFiles.size());\n    \n    for (File xml : xmlFiles) {\n      ContentStreamUpdateRequest req = new ContentStreamUpdateRequest(\"/update\");\n      req.addFile(xml, \"application/xml\");\n      log.info(\"POSTing \"+xml.getAbsolutePath());\n      cloudClient.request(req);\n    }\n    cloudClient.commit();\n\n    int numFound = 0;\n\n    // give the update a chance to take effect.\n    for (int idx = 0; idx < 100; ++idx) {\n      QueryResponse qr = cloudClient.query(new SolrQuery(\"*:*\"));\n      numFound = (int) qr.getResults().getNumFound();\n      if (numFound == expectedXmlDocCount) break;\n      Thread.sleep(100);\n    }\n    assertEquals(\"*:* found unexpected number of documents\", expectedXmlDocCount, numFound);\n\n    log.info(\"Updating Config for \" + testCollectionName);\n    doTestConfigUpdate(testCollectionName, solrUrl);\n\n    log.info(\"Running healthcheck for \" + testCollectionName);\n    doTestHealthcheck(testCollectionName, cloudClient.getZkHost());\n\n    // verify the delete action works too\n    log.info(\"Running delete for \"+testCollectionName);\n    doTestDeleteAction(testCollectionName, solrUrl);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection succeeded ... shutting down now!\");\n  }\n\n","sourceOld":"  @Test\n  public void testLoadDocsIntoGettingStartedCollection() throws Exception {\n    waitForThingsToLevelOut(30000);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection initialized OK ... running test logic\");\n\n    String testCollectionName = \"gettingstarted\";\n    File data_driven_schema_configs = new File(ExternalPaths.SCHEMALESS_CONFIGSET);\n    assertTrue(data_driven_schema_configs.getAbsolutePath()+\" not found!\", data_driven_schema_configs.isDirectory());\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    if (liveNodes.isEmpty())\n      fail(\"No live nodes found! Cannot create a collection until there is at least 1 live node in the cluster.\");\n    String firstLiveNode = liveNodes.iterator().next();\n    String solrUrl = cloudClient.getZkStateReader().getBaseUrlForNodeName(firstLiveNode);\n\n    // create the gettingstarted collection just like the bin/solr script would do\n    String[] args = new String[] {\n        \"-name\", testCollectionName,\n        \"-shards\", \"2\",\n        \"-replicationFactor\", \"2\",\n        \"-confname\", testCollectionName,\n        \"-confdir\", \"data_driven_schema_configs\",\n        \"-configsetsDir\", data_driven_schema_configs.getParentFile().getParentFile().getAbsolutePath(),\n        \"-solrUrl\", solrUrl\n    };\n\n    // NOTE: not calling SolrCLI.main as the script does because it calls System.exit which is a no-no in a JUnit test\n\n    SolrCLI.CreateCollectionTool tool = new SolrCLI.CreateCollectionTool();\n    CommandLine cli = SolrCLI.processCommandLineArgs(SolrCLI.joinCommonAndToolOptions(tool.getOptions()), args);\n    log.info(\"Creating the '\"+testCollectionName+\"' collection using SolrCLI with: \"+solrUrl);\n    tool.runTool(cli);\n    assertTrue(\"Collection '\" + testCollectionName + \"' doesn't exist after trying to create it!\",\n        cloudClient.getZkStateReader().getClusterState().hasCollection(testCollectionName));\n\n    // verify the collection is usable ...\n    ensureAllReplicasAreActive(testCollectionName, \"shard1\", 2, 2, 20);\n    ensureAllReplicasAreActive(testCollectionName, \"shard2\", 2, 2, 10);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    int invalidToolExitStatus = 1;\n    assertEquals(\"Collection '\" + testCollectionName + \"' created even though it already existed\",\n        invalidToolExitStatus, tool.runTool(cli));\n\n    // now index docs like bin/post would do but we can't use SimplePostTool because it uses System.exit when\n    // it encounters an error, which JUnit doesn't like ...\n    log.info(\"Created collection, now posting example docs!\");\n    File exampleDocsDir = new File(ExternalPaths.SOURCE_HOME, \"example/exampledocs\");\n    assertTrue(exampleDocsDir.getAbsolutePath()+\" not found!\", exampleDocsDir.isDirectory());\n\n    List<File> xmlFiles = Arrays.asList(exampleDocsDir.listFiles(new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return name.endsWith(\".xml\");\n      }\n    }));\n\n    // force a deterministic random ordering of the files so seeds reproduce regardless of platform/filesystem\n    Collections.sort(xmlFiles, (o1, o2) -> {\n      // don't rely on File.compareTo, it's behavior varies by OS\n      return o1.getName().compareTo(o2.getName());\n    });\n    Collections.shuffle(xmlFiles, new Random(random().nextLong()));\n\n    // if you add/remove example XML docs, you'll have to fix these expected values\n    int expectedXmlFileCount = 14;\n    int expectedXmlDocCount = 32;\n\n    assertEquals(\"Unexpected # of example XML files in \"+exampleDocsDir.getAbsolutePath(),\n                 expectedXmlFileCount, xmlFiles.size());\n    \n    for (File xml : xmlFiles) {\n      ContentStreamUpdateRequest req = new ContentStreamUpdateRequest(\"/update\");\n      req.addFile(xml, \"application/xml\");\n      log.info(\"POSTing \"+xml.getAbsolutePath());\n      cloudClient.request(req);\n    }\n    cloudClient.commit();\n\n    int numFound = 0;\n\n    // give the update a chance to take effect.\n    for (int idx = 0; idx < 100; ++idx) {\n      QueryResponse qr = cloudClient.query(new SolrQuery(\"*:*\"));\n      numFound = (int) qr.getResults().getNumFound();\n      if (numFound == expectedXmlDocCount) break;\n      Thread.sleep(100);\n    }\n    assertEquals(\"*:* found unexpected number of documents\", expectedXmlDocCount, numFound);\n\n    log.info(\"Updating Config for \" + testCollectionName);\n    doTestConfigUpdate(testCollectionName, solrUrl);\n\n    log.info(\"Running healthcheck for \" + testCollectionName);\n    doTestHealthcheck(testCollectionName, cloudClient.getZkHost());\n\n    // verify the delete action works too\n    log.info(\"Running delete for \"+testCollectionName);\n    doTestDeleteAction(testCollectionName, solrUrl);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection succeeded ... shutting down now!\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fbedfa79ef95dc2b5b49f7d54d80e0b47867f9b4","date":1498540685,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/SolrCloudExampleTest#testLoadDocsIntoGettingStartedCollection().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/SolrCloudExampleTest#testLoadDocsIntoGettingStartedCollection().mjava","sourceNew":"  @Test\n  public void testLoadDocsIntoGettingStartedCollection() throws Exception {\n    waitForThingsToLevelOut(30000);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection initialized OK ... running test logic\");\n\n    String testCollectionName = \"gettingstarted\";\n    File defaultConfigs = new File(ExternalPaths.DEFAULT_CONFIGSET);\n    assertTrue(defaultConfigs.getAbsolutePath()+\" not found!\", defaultConfigs.isDirectory());\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    if (liveNodes.isEmpty())\n      fail(\"No live nodes found! Cannot create a collection until there is at least 1 live node in the cluster.\");\n    String firstLiveNode = liveNodes.iterator().next();\n    String solrUrl = cloudClient.getZkStateReader().getBaseUrlForNodeName(firstLiveNode);\n\n    // create the gettingstarted collection just like the bin/solr script would do\n    String[] args = new String[] {\n        \"-name\", testCollectionName,\n        \"-shards\", \"2\",\n        \"-replicationFactor\", \"2\",\n        \"-confname\", testCollectionName,\n        \"-confdir\", \"_default\",\n        \"-configsetsDir\", defaultConfigs.getParentFile().getParentFile().getAbsolutePath(),\n        \"-solrUrl\", solrUrl\n    };\n\n    // NOTE: not calling SolrCLI.main as the script does because it calls System.exit which is a no-no in a JUnit test\n\n    SolrCLI.CreateCollectionTool tool = new SolrCLI.CreateCollectionTool();\n    CommandLine cli = SolrCLI.processCommandLineArgs(SolrCLI.joinCommonAndToolOptions(tool.getOptions()), args);\n    log.info(\"Creating the '\"+testCollectionName+\"' collection using SolrCLI with: \"+solrUrl);\n    tool.runTool(cli);\n    assertTrue(\"Collection '\" + testCollectionName + \"' doesn't exist after trying to create it!\",\n        cloudClient.getZkStateReader().getClusterState().hasCollection(testCollectionName));\n\n    // verify the collection is usable ...\n    ensureAllReplicasAreActive(testCollectionName, \"shard1\", 2, 2, 20);\n    ensureAllReplicasAreActive(testCollectionName, \"shard2\", 2, 2, 10);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    int invalidToolExitStatus = 1;\n    assertEquals(\"Collection '\" + testCollectionName + \"' created even though it already existed\",\n        invalidToolExitStatus, tool.runTool(cli));\n\n    // now index docs like bin/post would do but we can't use SimplePostTool because it uses System.exit when\n    // it encounters an error, which JUnit doesn't like ...\n    log.info(\"Created collection, now posting example docs!\");\n    File exampleDocsDir = new File(ExternalPaths.SOURCE_HOME, \"example/exampledocs\");\n    assertTrue(exampleDocsDir.getAbsolutePath()+\" not found!\", exampleDocsDir.isDirectory());\n\n    List<File> xmlFiles = Arrays.asList(exampleDocsDir.listFiles(new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return name.endsWith(\".xml\");\n      }\n    }));\n\n    // force a deterministic random ordering of the files so seeds reproduce regardless of platform/filesystem\n    Collections.sort(xmlFiles, (o1, o2) -> {\n      // don't rely on File.compareTo, it's behavior varies by OS\n      return o1.getName().compareTo(o2.getName());\n    });\n    Collections.shuffle(xmlFiles, new Random(random().nextLong()));\n\n    // if you add/remove example XML docs, you'll have to fix these expected values\n    int expectedXmlFileCount = 14;\n    int expectedXmlDocCount = 32;\n\n    assertEquals(\"Unexpected # of example XML files in \"+exampleDocsDir.getAbsolutePath(),\n                 expectedXmlFileCount, xmlFiles.size());\n    \n    for (File xml : xmlFiles) {\n      ContentStreamUpdateRequest req = new ContentStreamUpdateRequest(\"/update\");\n      req.addFile(xml, \"application/xml\");\n      log.info(\"POSTing \"+xml.getAbsolutePath());\n      cloudClient.request(req);\n    }\n    cloudClient.commit();\n\n    int numFound = 0;\n\n    // give the update a chance to take effect.\n    for (int idx = 0; idx < 100; ++idx) {\n      QueryResponse qr = cloudClient.query(new SolrQuery(\"*:*\"));\n      numFound = (int) qr.getResults().getNumFound();\n      if (numFound == expectedXmlDocCount) break;\n      Thread.sleep(100);\n    }\n    assertEquals(\"*:* found unexpected number of documents\", expectedXmlDocCount, numFound);\n\n    log.info(\"Updating Config for \" + testCollectionName);\n    doTestConfigUpdate(testCollectionName, solrUrl);\n\n    log.info(\"Running healthcheck for \" + testCollectionName);\n    doTestHealthcheck(testCollectionName, cloudClient.getZkHost());\n\n    // verify the delete action works too\n    log.info(\"Running delete for \"+testCollectionName);\n    doTestDeleteAction(testCollectionName, solrUrl);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection succeeded ... shutting down now!\");\n  }\n\n","sourceOld":"  @Test\n  public void testLoadDocsIntoGettingStartedCollection() throws Exception {\n    waitForThingsToLevelOut(30000);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection initialized OK ... running test logic\");\n\n    String testCollectionName = \"gettingstarted\";\n    File data_driven_schema_configs = new File(ExternalPaths.SCHEMALESS_CONFIGSET);\n    assertTrue(data_driven_schema_configs.getAbsolutePath()+\" not found!\", data_driven_schema_configs.isDirectory());\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    if (liveNodes.isEmpty())\n      fail(\"No live nodes found! Cannot create a collection until there is at least 1 live node in the cluster.\");\n    String firstLiveNode = liveNodes.iterator().next();\n    String solrUrl = cloudClient.getZkStateReader().getBaseUrlForNodeName(firstLiveNode);\n\n    // create the gettingstarted collection just like the bin/solr script would do\n    String[] args = new String[] {\n        \"-name\", testCollectionName,\n        \"-shards\", \"2\",\n        \"-replicationFactor\", \"2\",\n        \"-confname\", testCollectionName,\n        \"-confdir\", \"data_driven_schema_configs\",\n        \"-configsetsDir\", data_driven_schema_configs.getParentFile().getParentFile().getAbsolutePath(),\n        \"-solrUrl\", solrUrl\n    };\n\n    // NOTE: not calling SolrCLI.main as the script does because it calls System.exit which is a no-no in a JUnit test\n\n    SolrCLI.CreateCollectionTool tool = new SolrCLI.CreateCollectionTool();\n    CommandLine cli = SolrCLI.processCommandLineArgs(SolrCLI.joinCommonAndToolOptions(tool.getOptions()), args);\n    log.info(\"Creating the '\"+testCollectionName+\"' collection using SolrCLI with: \"+solrUrl);\n    tool.runTool(cli);\n    assertTrue(\"Collection '\" + testCollectionName + \"' doesn't exist after trying to create it!\",\n        cloudClient.getZkStateReader().getClusterState().hasCollection(testCollectionName));\n\n    // verify the collection is usable ...\n    ensureAllReplicasAreActive(testCollectionName, \"shard1\", 2, 2, 20);\n    ensureAllReplicasAreActive(testCollectionName, \"shard2\", 2, 2, 10);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    int invalidToolExitStatus = 1;\n    assertEquals(\"Collection '\" + testCollectionName + \"' created even though it already existed\",\n        invalidToolExitStatus, tool.runTool(cli));\n\n    // now index docs like bin/post would do but we can't use SimplePostTool because it uses System.exit when\n    // it encounters an error, which JUnit doesn't like ...\n    log.info(\"Created collection, now posting example docs!\");\n    File exampleDocsDir = new File(ExternalPaths.SOURCE_HOME, \"example/exampledocs\");\n    assertTrue(exampleDocsDir.getAbsolutePath()+\" not found!\", exampleDocsDir.isDirectory());\n\n    List<File> xmlFiles = Arrays.asList(exampleDocsDir.listFiles(new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return name.endsWith(\".xml\");\n      }\n    }));\n\n    // force a deterministic random ordering of the files so seeds reproduce regardless of platform/filesystem\n    Collections.sort(xmlFiles, (o1, o2) -> {\n      // don't rely on File.compareTo, it's behavior varies by OS\n      return o1.getName().compareTo(o2.getName());\n    });\n    Collections.shuffle(xmlFiles, new Random(random().nextLong()));\n\n    // if you add/remove example XML docs, you'll have to fix these expected values\n    int expectedXmlFileCount = 14;\n    int expectedXmlDocCount = 32;\n\n    assertEquals(\"Unexpected # of example XML files in \"+exampleDocsDir.getAbsolutePath(),\n                 expectedXmlFileCount, xmlFiles.size());\n    \n    for (File xml : xmlFiles) {\n      ContentStreamUpdateRequest req = new ContentStreamUpdateRequest(\"/update\");\n      req.addFile(xml, \"application/xml\");\n      log.info(\"POSTing \"+xml.getAbsolutePath());\n      cloudClient.request(req);\n    }\n    cloudClient.commit();\n\n    int numFound = 0;\n\n    // give the update a chance to take effect.\n    for (int idx = 0; idx < 100; ++idx) {\n      QueryResponse qr = cloudClient.query(new SolrQuery(\"*:*\"));\n      numFound = (int) qr.getResults().getNumFound();\n      if (numFound == expectedXmlDocCount) break;\n      Thread.sleep(100);\n    }\n    assertEquals(\"*:* found unexpected number of documents\", expectedXmlDocCount, numFound);\n\n    log.info(\"Updating Config for \" + testCollectionName);\n    doTestConfigUpdate(testCollectionName, solrUrl);\n\n    log.info(\"Running healthcheck for \" + testCollectionName);\n    doTestHealthcheck(testCollectionName, cloudClient.getZkHost());\n\n    // verify the delete action works too\n    log.info(\"Running delete for \"+testCollectionName);\n    doTestDeleteAction(testCollectionName, solrUrl);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection succeeded ... shutting down now!\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"28288370235ed02234a64753cdbf0c6ec096304a","date":1498726817,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/SolrCloudExampleTest#testLoadDocsIntoGettingStartedCollection().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/SolrCloudExampleTest#testLoadDocsIntoGettingStartedCollection().mjava","sourceNew":"  @Test\n  public void testLoadDocsIntoGettingStartedCollection() throws Exception {\n    waitForThingsToLevelOut(30000);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection initialized OK ... running test logic\");\n\n    String testCollectionName = \"gettingstarted\";\n    File defaultConfigs = new File(ExternalPaths.DEFAULT_CONFIGSET);\n    assertTrue(defaultConfigs.getAbsolutePath()+\" not found!\", defaultConfigs.isDirectory());\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    if (liveNodes.isEmpty())\n      fail(\"No live nodes found! Cannot create a collection until there is at least 1 live node in the cluster.\");\n    String firstLiveNode = liveNodes.iterator().next();\n    String solrUrl = cloudClient.getZkStateReader().getBaseUrlForNodeName(firstLiveNode);\n\n    // create the gettingstarted collection just like the bin/solr script would do\n    String[] args = new String[] {\n        \"-name\", testCollectionName,\n        \"-shards\", \"2\",\n        \"-replicationFactor\", \"2\",\n        \"-confname\", testCollectionName,\n        \"-confdir\", \"_default\",\n        \"-configsetsDir\", defaultConfigs.getParentFile().getParentFile().getAbsolutePath(),\n        \"-solrUrl\", solrUrl\n    };\n\n    // NOTE: not calling SolrCLI.main as the script does because it calls System.exit which is a no-no in a JUnit test\n\n    SolrCLI.CreateCollectionTool tool = new SolrCLI.CreateCollectionTool();\n    CommandLine cli = SolrCLI.processCommandLineArgs(SolrCLI.joinCommonAndToolOptions(tool.getOptions()), args);\n    log.info(\"Creating the '\"+testCollectionName+\"' collection using SolrCLI with: \"+solrUrl);\n    tool.runTool(cli);\n    assertTrue(\"Collection '\" + testCollectionName + \"' doesn't exist after trying to create it!\",\n        cloudClient.getZkStateReader().getClusterState().hasCollection(testCollectionName));\n\n    // verify the collection is usable ...\n    ensureAllReplicasAreActive(testCollectionName, \"shard1\", 2, 2, 20);\n    ensureAllReplicasAreActive(testCollectionName, \"shard2\", 2, 2, 10);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    int invalidToolExitStatus = 1;\n    assertEquals(\"Collection '\" + testCollectionName + \"' created even though it already existed\",\n        invalidToolExitStatus, tool.runTool(cli));\n\n    // now index docs like bin/post would do but we can't use SimplePostTool because it uses System.exit when\n    // it encounters an error, which JUnit doesn't like ...\n    log.info(\"Created collection, now posting example docs!\");\n    File exampleDocsDir = new File(ExternalPaths.SOURCE_HOME, \"example/exampledocs\");\n    assertTrue(exampleDocsDir.getAbsolutePath()+\" not found!\", exampleDocsDir.isDirectory());\n\n    List<File> xmlFiles = Arrays.asList(exampleDocsDir.listFiles(new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return name.endsWith(\".xml\");\n      }\n    }));\n\n    // force a deterministic random ordering of the files so seeds reproduce regardless of platform/filesystem\n    Collections.sort(xmlFiles, (o1, o2) -> {\n      // don't rely on File.compareTo, it's behavior varies by OS\n      return o1.getName().compareTo(o2.getName());\n    });\n    Collections.shuffle(xmlFiles, new Random(random().nextLong()));\n\n    // if you add/remove example XML docs, you'll have to fix these expected values\n    int expectedXmlFileCount = 14;\n    int expectedXmlDocCount = 32;\n\n    assertEquals(\"Unexpected # of example XML files in \"+exampleDocsDir.getAbsolutePath(),\n                 expectedXmlFileCount, xmlFiles.size());\n    \n    for (File xml : xmlFiles) {\n      ContentStreamUpdateRequest req = new ContentStreamUpdateRequest(\"/update\");\n      req.addFile(xml, \"application/xml\");\n      log.info(\"POSTing \"+xml.getAbsolutePath());\n      cloudClient.request(req);\n    }\n    cloudClient.commit();\n\n    int numFound = 0;\n\n    // give the update a chance to take effect.\n    for (int idx = 0; idx < 100; ++idx) {\n      QueryResponse qr = cloudClient.query(new SolrQuery(\"*:*\"));\n      numFound = (int) qr.getResults().getNumFound();\n      if (numFound == expectedXmlDocCount) break;\n      Thread.sleep(100);\n    }\n    assertEquals(\"*:* found unexpected number of documents\", expectedXmlDocCount, numFound);\n\n    log.info(\"Updating Config for \" + testCollectionName);\n    doTestConfigUpdate(testCollectionName, solrUrl);\n\n    log.info(\"Running healthcheck for \" + testCollectionName);\n    doTestHealthcheck(testCollectionName, cloudClient.getZkHost());\n\n    // verify the delete action works too\n    log.info(\"Running delete for \"+testCollectionName);\n    doTestDeleteAction(testCollectionName, solrUrl);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection succeeded ... shutting down now!\");\n  }\n\n","sourceOld":"  @Test\n  public void testLoadDocsIntoGettingStartedCollection() throws Exception {\n    waitForThingsToLevelOut(30000);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection initialized OK ... running test logic\");\n\n    String testCollectionName = \"gettingstarted\";\n    File data_driven_schema_configs = new File(ExternalPaths.SCHEMALESS_CONFIGSET);\n    assertTrue(data_driven_schema_configs.getAbsolutePath()+\" not found!\", data_driven_schema_configs.isDirectory());\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    if (liveNodes.isEmpty())\n      fail(\"No live nodes found! Cannot create a collection until there is at least 1 live node in the cluster.\");\n    String firstLiveNode = liveNodes.iterator().next();\n    String solrUrl = cloudClient.getZkStateReader().getBaseUrlForNodeName(firstLiveNode);\n\n    // create the gettingstarted collection just like the bin/solr script would do\n    String[] args = new String[] {\n        \"-name\", testCollectionName,\n        \"-shards\", \"2\",\n        \"-replicationFactor\", \"2\",\n        \"-confname\", testCollectionName,\n        \"-confdir\", \"data_driven_schema_configs\",\n        \"-configsetsDir\", data_driven_schema_configs.getParentFile().getParentFile().getAbsolutePath(),\n        \"-solrUrl\", solrUrl\n    };\n\n    // NOTE: not calling SolrCLI.main as the script does because it calls System.exit which is a no-no in a JUnit test\n\n    SolrCLI.CreateCollectionTool tool = new SolrCLI.CreateCollectionTool();\n    CommandLine cli = SolrCLI.processCommandLineArgs(SolrCLI.joinCommonAndToolOptions(tool.getOptions()), args);\n    log.info(\"Creating the '\"+testCollectionName+\"' collection using SolrCLI with: \"+solrUrl);\n    tool.runTool(cli);\n    assertTrue(\"Collection '\" + testCollectionName + \"' doesn't exist after trying to create it!\",\n        cloudClient.getZkStateReader().getClusterState().hasCollection(testCollectionName));\n\n    // verify the collection is usable ...\n    ensureAllReplicasAreActive(testCollectionName, \"shard1\", 2, 2, 20);\n    ensureAllReplicasAreActive(testCollectionName, \"shard2\", 2, 2, 10);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    int invalidToolExitStatus = 1;\n    assertEquals(\"Collection '\" + testCollectionName + \"' created even though it already existed\",\n        invalidToolExitStatus, tool.runTool(cli));\n\n    // now index docs like bin/post would do but we can't use SimplePostTool because it uses System.exit when\n    // it encounters an error, which JUnit doesn't like ...\n    log.info(\"Created collection, now posting example docs!\");\n    File exampleDocsDir = new File(ExternalPaths.SOURCE_HOME, \"example/exampledocs\");\n    assertTrue(exampleDocsDir.getAbsolutePath()+\" not found!\", exampleDocsDir.isDirectory());\n\n    List<File> xmlFiles = Arrays.asList(exampleDocsDir.listFiles(new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return name.endsWith(\".xml\");\n      }\n    }));\n\n    // force a deterministic random ordering of the files so seeds reproduce regardless of platform/filesystem\n    Collections.sort(xmlFiles, (o1, o2) -> {\n      // don't rely on File.compareTo, it's behavior varies by OS\n      return o1.getName().compareTo(o2.getName());\n    });\n    Collections.shuffle(xmlFiles, new Random(random().nextLong()));\n\n    // if you add/remove example XML docs, you'll have to fix these expected values\n    int expectedXmlFileCount = 14;\n    int expectedXmlDocCount = 32;\n\n    assertEquals(\"Unexpected # of example XML files in \"+exampleDocsDir.getAbsolutePath(),\n                 expectedXmlFileCount, xmlFiles.size());\n    \n    for (File xml : xmlFiles) {\n      ContentStreamUpdateRequest req = new ContentStreamUpdateRequest(\"/update\");\n      req.addFile(xml, \"application/xml\");\n      log.info(\"POSTing \"+xml.getAbsolutePath());\n      cloudClient.request(req);\n    }\n    cloudClient.commit();\n\n    int numFound = 0;\n\n    // give the update a chance to take effect.\n    for (int idx = 0; idx < 100; ++idx) {\n      QueryResponse qr = cloudClient.query(new SolrQuery(\"*:*\"));\n      numFound = (int) qr.getResults().getNumFound();\n      if (numFound == expectedXmlDocCount) break;\n      Thread.sleep(100);\n    }\n    assertEquals(\"*:* found unexpected number of documents\", expectedXmlDocCount, numFound);\n\n    log.info(\"Updating Config for \" + testCollectionName);\n    doTestConfigUpdate(testCollectionName, solrUrl);\n\n    log.info(\"Running healthcheck for \" + testCollectionName);\n    doTestHealthcheck(testCollectionName, cloudClient.getZkHost());\n\n    // verify the delete action works too\n    log.info(\"Running delete for \"+testCollectionName);\n    doTestDeleteAction(testCollectionName, solrUrl);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection succeeded ... shutting down now!\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4bab9eeea60eefbea2957be27b8d1923095df771","date":1525498218,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/SolrCloudExampleTest#testLoadDocsIntoGettingStartedCollection().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/SolrCloudExampleTest#testLoadDocsIntoGettingStartedCollection().mjava","sourceNew":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 04-May-2018\n  public void testLoadDocsIntoGettingStartedCollection() throws Exception {\n    waitForThingsToLevelOut(30000);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection initialized OK ... running test logic\");\n\n    String testCollectionName = \"gettingstarted\";\n    File defaultConfigs = new File(ExternalPaths.DEFAULT_CONFIGSET);\n    assertTrue(defaultConfigs.getAbsolutePath()+\" not found!\", defaultConfigs.isDirectory());\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    if (liveNodes.isEmpty())\n      fail(\"No live nodes found! Cannot create a collection until there is at least 1 live node in the cluster.\");\n    String firstLiveNode = liveNodes.iterator().next();\n    String solrUrl = cloudClient.getZkStateReader().getBaseUrlForNodeName(firstLiveNode);\n\n    // create the gettingstarted collection just like the bin/solr script would do\n    String[] args = new String[] {\n        \"-name\", testCollectionName,\n        \"-shards\", \"2\",\n        \"-replicationFactor\", \"2\",\n        \"-confname\", testCollectionName,\n        \"-confdir\", \"_default\",\n        \"-configsetsDir\", defaultConfigs.getParentFile().getParentFile().getAbsolutePath(),\n        \"-solrUrl\", solrUrl\n    };\n\n    // NOTE: not calling SolrCLI.main as the script does because it calls System.exit which is a no-no in a JUnit test\n\n    SolrCLI.CreateCollectionTool tool = new SolrCLI.CreateCollectionTool();\n    CommandLine cli = SolrCLI.processCommandLineArgs(SolrCLI.joinCommonAndToolOptions(tool.getOptions()), args);\n    log.info(\"Creating the '\"+testCollectionName+\"' collection using SolrCLI with: \"+solrUrl);\n    tool.runTool(cli);\n    assertTrue(\"Collection '\" + testCollectionName + \"' doesn't exist after trying to create it!\",\n        cloudClient.getZkStateReader().getClusterState().hasCollection(testCollectionName));\n\n    // verify the collection is usable ...\n    ensureAllReplicasAreActive(testCollectionName, \"shard1\", 2, 2, 20);\n    ensureAllReplicasAreActive(testCollectionName, \"shard2\", 2, 2, 10);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    int invalidToolExitStatus = 1;\n    assertEquals(\"Collection '\" + testCollectionName + \"' created even though it already existed\",\n        invalidToolExitStatus, tool.runTool(cli));\n\n    // now index docs like bin/post would do but we can't use SimplePostTool because it uses System.exit when\n    // it encounters an error, which JUnit doesn't like ...\n    log.info(\"Created collection, now posting example docs!\");\n    File exampleDocsDir = new File(ExternalPaths.SOURCE_HOME, \"example/exampledocs\");\n    assertTrue(exampleDocsDir.getAbsolutePath()+\" not found!\", exampleDocsDir.isDirectory());\n\n    List<File> xmlFiles = Arrays.asList(exampleDocsDir.listFiles(new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return name.endsWith(\".xml\");\n      }\n    }));\n\n    // force a deterministic random ordering of the files so seeds reproduce regardless of platform/filesystem\n    Collections.sort(xmlFiles, (o1, o2) -> {\n      // don't rely on File.compareTo, it's behavior varies by OS\n      return o1.getName().compareTo(o2.getName());\n    });\n    Collections.shuffle(xmlFiles, new Random(random().nextLong()));\n\n    // if you add/remove example XML docs, you'll have to fix these expected values\n    int expectedXmlFileCount = 14;\n    int expectedXmlDocCount = 32;\n\n    assertEquals(\"Unexpected # of example XML files in \"+exampleDocsDir.getAbsolutePath(),\n                 expectedXmlFileCount, xmlFiles.size());\n    \n    for (File xml : xmlFiles) {\n      ContentStreamUpdateRequest req = new ContentStreamUpdateRequest(\"/update\");\n      req.addFile(xml, \"application/xml\");\n      log.info(\"POSTing \"+xml.getAbsolutePath());\n      cloudClient.request(req);\n    }\n    cloudClient.commit();\n\n    int numFound = 0;\n\n    // give the update a chance to take effect.\n    for (int idx = 0; idx < 100; ++idx) {\n      QueryResponse qr = cloudClient.query(new SolrQuery(\"*:*\"));\n      numFound = (int) qr.getResults().getNumFound();\n      if (numFound == expectedXmlDocCount) break;\n      Thread.sleep(100);\n    }\n    assertEquals(\"*:* found unexpected number of documents\", expectedXmlDocCount, numFound);\n\n    log.info(\"Updating Config for \" + testCollectionName);\n    doTestConfigUpdate(testCollectionName, solrUrl);\n\n    log.info(\"Running healthcheck for \" + testCollectionName);\n    doTestHealthcheck(testCollectionName, cloudClient.getZkHost());\n\n    // verify the delete action works too\n    log.info(\"Running delete for \"+testCollectionName);\n    doTestDeleteAction(testCollectionName, solrUrl);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection succeeded ... shutting down now!\");\n  }\n\n","sourceOld":"  @Test\n  public void testLoadDocsIntoGettingStartedCollection() throws Exception {\n    waitForThingsToLevelOut(30000);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection initialized OK ... running test logic\");\n\n    String testCollectionName = \"gettingstarted\";\n    File defaultConfigs = new File(ExternalPaths.DEFAULT_CONFIGSET);\n    assertTrue(defaultConfigs.getAbsolutePath()+\" not found!\", defaultConfigs.isDirectory());\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    if (liveNodes.isEmpty())\n      fail(\"No live nodes found! Cannot create a collection until there is at least 1 live node in the cluster.\");\n    String firstLiveNode = liveNodes.iterator().next();\n    String solrUrl = cloudClient.getZkStateReader().getBaseUrlForNodeName(firstLiveNode);\n\n    // create the gettingstarted collection just like the bin/solr script would do\n    String[] args = new String[] {\n        \"-name\", testCollectionName,\n        \"-shards\", \"2\",\n        \"-replicationFactor\", \"2\",\n        \"-confname\", testCollectionName,\n        \"-confdir\", \"_default\",\n        \"-configsetsDir\", defaultConfigs.getParentFile().getParentFile().getAbsolutePath(),\n        \"-solrUrl\", solrUrl\n    };\n\n    // NOTE: not calling SolrCLI.main as the script does because it calls System.exit which is a no-no in a JUnit test\n\n    SolrCLI.CreateCollectionTool tool = new SolrCLI.CreateCollectionTool();\n    CommandLine cli = SolrCLI.processCommandLineArgs(SolrCLI.joinCommonAndToolOptions(tool.getOptions()), args);\n    log.info(\"Creating the '\"+testCollectionName+\"' collection using SolrCLI with: \"+solrUrl);\n    tool.runTool(cli);\n    assertTrue(\"Collection '\" + testCollectionName + \"' doesn't exist after trying to create it!\",\n        cloudClient.getZkStateReader().getClusterState().hasCollection(testCollectionName));\n\n    // verify the collection is usable ...\n    ensureAllReplicasAreActive(testCollectionName, \"shard1\", 2, 2, 20);\n    ensureAllReplicasAreActive(testCollectionName, \"shard2\", 2, 2, 10);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    int invalidToolExitStatus = 1;\n    assertEquals(\"Collection '\" + testCollectionName + \"' created even though it already existed\",\n        invalidToolExitStatus, tool.runTool(cli));\n\n    // now index docs like bin/post would do but we can't use SimplePostTool because it uses System.exit when\n    // it encounters an error, which JUnit doesn't like ...\n    log.info(\"Created collection, now posting example docs!\");\n    File exampleDocsDir = new File(ExternalPaths.SOURCE_HOME, \"example/exampledocs\");\n    assertTrue(exampleDocsDir.getAbsolutePath()+\" not found!\", exampleDocsDir.isDirectory());\n\n    List<File> xmlFiles = Arrays.asList(exampleDocsDir.listFiles(new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return name.endsWith(\".xml\");\n      }\n    }));\n\n    // force a deterministic random ordering of the files so seeds reproduce regardless of platform/filesystem\n    Collections.sort(xmlFiles, (o1, o2) -> {\n      // don't rely on File.compareTo, it's behavior varies by OS\n      return o1.getName().compareTo(o2.getName());\n    });\n    Collections.shuffle(xmlFiles, new Random(random().nextLong()));\n\n    // if you add/remove example XML docs, you'll have to fix these expected values\n    int expectedXmlFileCount = 14;\n    int expectedXmlDocCount = 32;\n\n    assertEquals(\"Unexpected # of example XML files in \"+exampleDocsDir.getAbsolutePath(),\n                 expectedXmlFileCount, xmlFiles.size());\n    \n    for (File xml : xmlFiles) {\n      ContentStreamUpdateRequest req = new ContentStreamUpdateRequest(\"/update\");\n      req.addFile(xml, \"application/xml\");\n      log.info(\"POSTing \"+xml.getAbsolutePath());\n      cloudClient.request(req);\n    }\n    cloudClient.commit();\n\n    int numFound = 0;\n\n    // give the update a chance to take effect.\n    for (int idx = 0; idx < 100; ++idx) {\n      QueryResponse qr = cloudClient.query(new SolrQuery(\"*:*\"));\n      numFound = (int) qr.getResults().getNumFound();\n      if (numFound == expectedXmlDocCount) break;\n      Thread.sleep(100);\n    }\n    assertEquals(\"*:* found unexpected number of documents\", expectedXmlDocCount, numFound);\n\n    log.info(\"Updating Config for \" + testCollectionName);\n    doTestConfigUpdate(testCollectionName, solrUrl);\n\n    log.info(\"Running healthcheck for \" + testCollectionName);\n    doTestHealthcheck(testCollectionName, cloudClient.getZkHost());\n\n    // verify the delete action works too\n    log.info(\"Running delete for \"+testCollectionName);\n    doTestDeleteAction(testCollectionName, solrUrl);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection succeeded ... shutting down now!\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ebe8b79da5c80c6f5588d8dbd750a5f3865019a6","date":1528686294,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/SolrCloudExampleTest#testLoadDocsIntoGettingStartedCollection().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/SolrCloudExampleTest#testLoadDocsIntoGettingStartedCollection().mjava","sourceNew":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 04-May-2018\n  public void testLoadDocsIntoGettingStartedCollection() throws Exception {\n    waitForThingsToLevelOut(30000);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection initialized OK ... running test logic\");\n\n    String testCollectionName = \"gettingstarted\";\n    File defaultConfigs = new File(ExternalPaths.DEFAULT_CONFIGSET);\n    assertTrue(defaultConfigs.getAbsolutePath()+\" not found!\", defaultConfigs.isDirectory());\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    if (liveNodes.isEmpty())\n      fail(\"No live nodes found! Cannot create a collection until there is at least 1 live node in the cluster.\");\n    String firstLiveNode = liveNodes.iterator().next();\n    String solrUrl = cloudClient.getZkStateReader().getBaseUrlForNodeName(firstLiveNode);\n\n    // create the gettingstarted collection just like the bin/solr script would do\n    String[] args = new String[] {\n        \"-name\", testCollectionName,\n        \"-shards\", \"2\",\n        \"-replicationFactor\", \"2\",\n        \"-confname\", testCollectionName,\n        \"-confdir\", \"_default\",\n        \"-configsetsDir\", defaultConfigs.getParentFile().getParentFile().getAbsolutePath(),\n        \"-solrUrl\", solrUrl\n    };\n\n    // NOTE: not calling SolrCLI.main as the script does because it calls System.exit which is a no-no in a JUnit test\n\n    SolrCLI.CreateCollectionTool tool = new SolrCLI.CreateCollectionTool();\n    CommandLine cli = SolrCLI.processCommandLineArgs(SolrCLI.joinCommonAndToolOptions(tool.getOptions()), args);\n    log.info(\"Creating the '\"+testCollectionName+\"' collection using SolrCLI with: \"+solrUrl);\n    tool.runTool(cli);\n    assertTrue(\"Collection '\" + testCollectionName + \"' doesn't exist after trying to create it!\",\n        cloudClient.getZkStateReader().getClusterState().hasCollection(testCollectionName));\n\n    // verify the collection is usable ...\n    ensureAllReplicasAreActive(testCollectionName, \"shard1\", 2, 2, 20);\n    ensureAllReplicasAreActive(testCollectionName, \"shard2\", 2, 2, 10);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    int invalidToolExitStatus = 1;\n    assertEquals(\"Collection '\" + testCollectionName + \"' created even though it already existed\",\n        invalidToolExitStatus, tool.runTool(cli));\n\n    // now index docs like bin/post would do but we can't use SimplePostTool because it uses System.exit when\n    // it encounters an error, which JUnit doesn't like ...\n    log.info(\"Created collection, now posting example docs!\");\n    File exampleDocsDir = new File(ExternalPaths.SOURCE_HOME, \"example/exampledocs\");\n    assertTrue(exampleDocsDir.getAbsolutePath()+\" not found!\", exampleDocsDir.isDirectory());\n\n    List<File> xmlFiles = Arrays.asList(exampleDocsDir.listFiles(new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return name.endsWith(\".xml\");\n      }\n    }));\n\n    // force a deterministic random ordering of the files so seeds reproduce regardless of platform/filesystem\n    Collections.sort(xmlFiles, (o1, o2) -> {\n      // don't rely on File.compareTo, it's behavior varies by OS\n      return o1.getName().compareTo(o2.getName());\n    });\n    Collections.shuffle(xmlFiles, new Random(random().nextLong()));\n\n    // if you add/remove example XML docs, you'll have to fix these expected values\n    int expectedXmlFileCount = 14;\n    int expectedXmlDocCount = 32;\n\n    assertEquals(\"Unexpected # of example XML files in \"+exampleDocsDir.getAbsolutePath(),\n                 expectedXmlFileCount, xmlFiles.size());\n    \n    for (File xml : xmlFiles) {\n      log.info(\"POSTing \"+xml.getAbsolutePath());\n      cloudClient.request(new StreamingUpdateRequest(\"/update\",xml,\"application/xml\"));\n    }\n    cloudClient.commit();\n\n    int numFound = 0;\n\n    // give the update a chance to take effect.\n    for (int idx = 0; idx < 100; ++idx) {\n      QueryResponse qr = cloudClient.query(new SolrQuery(\"*:*\"));\n      numFound = (int) qr.getResults().getNumFound();\n      if (numFound == expectedXmlDocCount) break;\n      Thread.sleep(100);\n    }\n    assertEquals(\"*:* found unexpected number of documents\", expectedXmlDocCount, numFound);\n\n    log.info(\"Updating Config for \" + testCollectionName);\n    doTestConfigUpdate(testCollectionName, solrUrl);\n\n    log.info(\"Running healthcheck for \" + testCollectionName);\n    doTestHealthcheck(testCollectionName, cloudClient.getZkHost());\n\n    // verify the delete action works too\n    log.info(\"Running delete for \"+testCollectionName);\n    doTestDeleteAction(testCollectionName, solrUrl);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection succeeded ... shutting down now!\");\n  }\n\n","sourceOld":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 04-May-2018\n  public void testLoadDocsIntoGettingStartedCollection() throws Exception {\n    waitForThingsToLevelOut(30000);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection initialized OK ... running test logic\");\n\n    String testCollectionName = \"gettingstarted\";\n    File defaultConfigs = new File(ExternalPaths.DEFAULT_CONFIGSET);\n    assertTrue(defaultConfigs.getAbsolutePath()+\" not found!\", defaultConfigs.isDirectory());\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    if (liveNodes.isEmpty())\n      fail(\"No live nodes found! Cannot create a collection until there is at least 1 live node in the cluster.\");\n    String firstLiveNode = liveNodes.iterator().next();\n    String solrUrl = cloudClient.getZkStateReader().getBaseUrlForNodeName(firstLiveNode);\n\n    // create the gettingstarted collection just like the bin/solr script would do\n    String[] args = new String[] {\n        \"-name\", testCollectionName,\n        \"-shards\", \"2\",\n        \"-replicationFactor\", \"2\",\n        \"-confname\", testCollectionName,\n        \"-confdir\", \"_default\",\n        \"-configsetsDir\", defaultConfigs.getParentFile().getParentFile().getAbsolutePath(),\n        \"-solrUrl\", solrUrl\n    };\n\n    // NOTE: not calling SolrCLI.main as the script does because it calls System.exit which is a no-no in a JUnit test\n\n    SolrCLI.CreateCollectionTool tool = new SolrCLI.CreateCollectionTool();\n    CommandLine cli = SolrCLI.processCommandLineArgs(SolrCLI.joinCommonAndToolOptions(tool.getOptions()), args);\n    log.info(\"Creating the '\"+testCollectionName+\"' collection using SolrCLI with: \"+solrUrl);\n    tool.runTool(cli);\n    assertTrue(\"Collection '\" + testCollectionName + \"' doesn't exist after trying to create it!\",\n        cloudClient.getZkStateReader().getClusterState().hasCollection(testCollectionName));\n\n    // verify the collection is usable ...\n    ensureAllReplicasAreActive(testCollectionName, \"shard1\", 2, 2, 20);\n    ensureAllReplicasAreActive(testCollectionName, \"shard2\", 2, 2, 10);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    int invalidToolExitStatus = 1;\n    assertEquals(\"Collection '\" + testCollectionName + \"' created even though it already existed\",\n        invalidToolExitStatus, tool.runTool(cli));\n\n    // now index docs like bin/post would do but we can't use SimplePostTool because it uses System.exit when\n    // it encounters an error, which JUnit doesn't like ...\n    log.info(\"Created collection, now posting example docs!\");\n    File exampleDocsDir = new File(ExternalPaths.SOURCE_HOME, \"example/exampledocs\");\n    assertTrue(exampleDocsDir.getAbsolutePath()+\" not found!\", exampleDocsDir.isDirectory());\n\n    List<File> xmlFiles = Arrays.asList(exampleDocsDir.listFiles(new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return name.endsWith(\".xml\");\n      }\n    }));\n\n    // force a deterministic random ordering of the files so seeds reproduce regardless of platform/filesystem\n    Collections.sort(xmlFiles, (o1, o2) -> {\n      // don't rely on File.compareTo, it's behavior varies by OS\n      return o1.getName().compareTo(o2.getName());\n    });\n    Collections.shuffle(xmlFiles, new Random(random().nextLong()));\n\n    // if you add/remove example XML docs, you'll have to fix these expected values\n    int expectedXmlFileCount = 14;\n    int expectedXmlDocCount = 32;\n\n    assertEquals(\"Unexpected # of example XML files in \"+exampleDocsDir.getAbsolutePath(),\n                 expectedXmlFileCount, xmlFiles.size());\n    \n    for (File xml : xmlFiles) {\n      ContentStreamUpdateRequest req = new ContentStreamUpdateRequest(\"/update\");\n      req.addFile(xml, \"application/xml\");\n      log.info(\"POSTing \"+xml.getAbsolutePath());\n      cloudClient.request(req);\n    }\n    cloudClient.commit();\n\n    int numFound = 0;\n\n    // give the update a chance to take effect.\n    for (int idx = 0; idx < 100; ++idx) {\n      QueryResponse qr = cloudClient.query(new SolrQuery(\"*:*\"));\n      numFound = (int) qr.getResults().getNumFound();\n      if (numFound == expectedXmlDocCount) break;\n      Thread.sleep(100);\n    }\n    assertEquals(\"*:* found unexpected number of documents\", expectedXmlDocCount, numFound);\n\n    log.info(\"Updating Config for \" + testCollectionName);\n    doTestConfigUpdate(testCollectionName, solrUrl);\n\n    log.info(\"Running healthcheck for \" + testCollectionName);\n    doTestHealthcheck(testCollectionName, cloudClient.getZkHost());\n\n    // verify the delete action works too\n    log.info(\"Running delete for \"+testCollectionName);\n    doTestDeleteAction(testCollectionName, solrUrl);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection succeeded ... shutting down now!\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a1c374690db69470f6aa4bffc43dcacf1f4e3e49","date":1529007399,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/SolrCloudExampleTest#testLoadDocsIntoGettingStartedCollection().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/SolrCloudExampleTest#testLoadDocsIntoGettingStartedCollection().mjava","sourceNew":"  @Test\n  // 12-Jun-2018 @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 04-May-2018\n  public void testLoadDocsIntoGettingStartedCollection() throws Exception {\n    waitForThingsToLevelOut(30000);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection initialized OK ... running test logic\");\n\n    String testCollectionName = \"gettingstarted\";\n    File defaultConfigs = new File(ExternalPaths.DEFAULT_CONFIGSET);\n    assertTrue(defaultConfigs.getAbsolutePath()+\" not found!\", defaultConfigs.isDirectory());\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    if (liveNodes.isEmpty())\n      fail(\"No live nodes found! Cannot create a collection until there is at least 1 live node in the cluster.\");\n    String firstLiveNode = liveNodes.iterator().next();\n    String solrUrl = cloudClient.getZkStateReader().getBaseUrlForNodeName(firstLiveNode);\n\n    // create the gettingstarted collection just like the bin/solr script would do\n    String[] args = new String[] {\n        \"-name\", testCollectionName,\n        \"-shards\", \"2\",\n        \"-replicationFactor\", \"2\",\n        \"-confname\", testCollectionName,\n        \"-confdir\", \"_default\",\n        \"-configsetsDir\", defaultConfigs.getParentFile().getParentFile().getAbsolutePath(),\n        \"-solrUrl\", solrUrl\n    };\n\n    // NOTE: not calling SolrCLI.main as the script does because it calls System.exit which is a no-no in a JUnit test\n\n    SolrCLI.CreateCollectionTool tool = new SolrCLI.CreateCollectionTool();\n    CommandLine cli = SolrCLI.processCommandLineArgs(SolrCLI.joinCommonAndToolOptions(tool.getOptions()), args);\n    log.info(\"Creating the '\"+testCollectionName+\"' collection using SolrCLI with: \"+solrUrl);\n    tool.runTool(cli);\n    assertTrue(\"Collection '\" + testCollectionName + \"' doesn't exist after trying to create it!\",\n        cloudClient.getZkStateReader().getClusterState().hasCollection(testCollectionName));\n\n    // verify the collection is usable ...\n    ensureAllReplicasAreActive(testCollectionName, \"shard1\", 2, 2, 20);\n    ensureAllReplicasAreActive(testCollectionName, \"shard2\", 2, 2, 10);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    int invalidToolExitStatus = 1;\n    assertEquals(\"Collection '\" + testCollectionName + \"' created even though it already existed\",\n        invalidToolExitStatus, tool.runTool(cli));\n\n    // now index docs like bin/post would do but we can't use SimplePostTool because it uses System.exit when\n    // it encounters an error, which JUnit doesn't like ...\n    log.info(\"Created collection, now posting example docs!\");\n    File exampleDocsDir = new File(ExternalPaths.SOURCE_HOME, \"example/exampledocs\");\n    assertTrue(exampleDocsDir.getAbsolutePath()+\" not found!\", exampleDocsDir.isDirectory());\n\n    List<File> xmlFiles = Arrays.asList(exampleDocsDir.listFiles(new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return name.endsWith(\".xml\");\n      }\n    }));\n\n    // force a deterministic random ordering of the files so seeds reproduce regardless of platform/filesystem\n    Collections.sort(xmlFiles, (o1, o2) -> {\n      // don't rely on File.compareTo, it's behavior varies by OS\n      return o1.getName().compareTo(o2.getName());\n    });\n    Collections.shuffle(xmlFiles, new Random(random().nextLong()));\n\n    // if you add/remove example XML docs, you'll have to fix these expected values\n    int expectedXmlFileCount = 14;\n    int expectedXmlDocCount = 32;\n\n    assertEquals(\"Unexpected # of example XML files in \"+exampleDocsDir.getAbsolutePath(),\n                 expectedXmlFileCount, xmlFiles.size());\n    \n    for (File xml : xmlFiles) {\n      log.info(\"POSTing \"+xml.getAbsolutePath());\n      cloudClient.request(new StreamingUpdateRequest(\"/update\",xml,\"application/xml\"));\n    }\n    cloudClient.commit();\n\n    int numFound = 0;\n\n    // give the update a chance to take effect.\n    for (int idx = 0; idx < 100; ++idx) {\n      QueryResponse qr = cloudClient.query(new SolrQuery(\"*:*\"));\n      numFound = (int) qr.getResults().getNumFound();\n      if (numFound == expectedXmlDocCount) break;\n      Thread.sleep(100);\n    }\n    assertEquals(\"*:* found unexpected number of documents\", expectedXmlDocCount, numFound);\n\n    log.info(\"Updating Config for \" + testCollectionName);\n    doTestConfigUpdate(testCollectionName, solrUrl);\n\n    log.info(\"Running healthcheck for \" + testCollectionName);\n    doTestHealthcheck(testCollectionName, cloudClient.getZkHost());\n\n    // verify the delete action works too\n    log.info(\"Running delete for \"+testCollectionName);\n    doTestDeleteAction(testCollectionName, solrUrl);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection succeeded ... shutting down now!\");\n  }\n\n","sourceOld":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 04-May-2018\n  public void testLoadDocsIntoGettingStartedCollection() throws Exception {\n    waitForThingsToLevelOut(30000);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection initialized OK ... running test logic\");\n\n    String testCollectionName = \"gettingstarted\";\n    File defaultConfigs = new File(ExternalPaths.DEFAULT_CONFIGSET);\n    assertTrue(defaultConfigs.getAbsolutePath()+\" not found!\", defaultConfigs.isDirectory());\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    if (liveNodes.isEmpty())\n      fail(\"No live nodes found! Cannot create a collection until there is at least 1 live node in the cluster.\");\n    String firstLiveNode = liveNodes.iterator().next();\n    String solrUrl = cloudClient.getZkStateReader().getBaseUrlForNodeName(firstLiveNode);\n\n    // create the gettingstarted collection just like the bin/solr script would do\n    String[] args = new String[] {\n        \"-name\", testCollectionName,\n        \"-shards\", \"2\",\n        \"-replicationFactor\", \"2\",\n        \"-confname\", testCollectionName,\n        \"-confdir\", \"_default\",\n        \"-configsetsDir\", defaultConfigs.getParentFile().getParentFile().getAbsolutePath(),\n        \"-solrUrl\", solrUrl\n    };\n\n    // NOTE: not calling SolrCLI.main as the script does because it calls System.exit which is a no-no in a JUnit test\n\n    SolrCLI.CreateCollectionTool tool = new SolrCLI.CreateCollectionTool();\n    CommandLine cli = SolrCLI.processCommandLineArgs(SolrCLI.joinCommonAndToolOptions(tool.getOptions()), args);\n    log.info(\"Creating the '\"+testCollectionName+\"' collection using SolrCLI with: \"+solrUrl);\n    tool.runTool(cli);\n    assertTrue(\"Collection '\" + testCollectionName + \"' doesn't exist after trying to create it!\",\n        cloudClient.getZkStateReader().getClusterState().hasCollection(testCollectionName));\n\n    // verify the collection is usable ...\n    ensureAllReplicasAreActive(testCollectionName, \"shard1\", 2, 2, 20);\n    ensureAllReplicasAreActive(testCollectionName, \"shard2\", 2, 2, 10);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    int invalidToolExitStatus = 1;\n    assertEquals(\"Collection '\" + testCollectionName + \"' created even though it already existed\",\n        invalidToolExitStatus, tool.runTool(cli));\n\n    // now index docs like bin/post would do but we can't use SimplePostTool because it uses System.exit when\n    // it encounters an error, which JUnit doesn't like ...\n    log.info(\"Created collection, now posting example docs!\");\n    File exampleDocsDir = new File(ExternalPaths.SOURCE_HOME, \"example/exampledocs\");\n    assertTrue(exampleDocsDir.getAbsolutePath()+\" not found!\", exampleDocsDir.isDirectory());\n\n    List<File> xmlFiles = Arrays.asList(exampleDocsDir.listFiles(new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return name.endsWith(\".xml\");\n      }\n    }));\n\n    // force a deterministic random ordering of the files so seeds reproduce regardless of platform/filesystem\n    Collections.sort(xmlFiles, (o1, o2) -> {\n      // don't rely on File.compareTo, it's behavior varies by OS\n      return o1.getName().compareTo(o2.getName());\n    });\n    Collections.shuffle(xmlFiles, new Random(random().nextLong()));\n\n    // if you add/remove example XML docs, you'll have to fix these expected values\n    int expectedXmlFileCount = 14;\n    int expectedXmlDocCount = 32;\n\n    assertEquals(\"Unexpected # of example XML files in \"+exampleDocsDir.getAbsolutePath(),\n                 expectedXmlFileCount, xmlFiles.size());\n    \n    for (File xml : xmlFiles) {\n      log.info(\"POSTing \"+xml.getAbsolutePath());\n      cloudClient.request(new StreamingUpdateRequest(\"/update\",xml,\"application/xml\"));\n    }\n    cloudClient.commit();\n\n    int numFound = 0;\n\n    // give the update a chance to take effect.\n    for (int idx = 0; idx < 100; ++idx) {\n      QueryResponse qr = cloudClient.query(new SolrQuery(\"*:*\"));\n      numFound = (int) qr.getResults().getNumFound();\n      if (numFound == expectedXmlDocCount) break;\n      Thread.sleep(100);\n    }\n    assertEquals(\"*:* found unexpected number of documents\", expectedXmlDocCount, numFound);\n\n    log.info(\"Updating Config for \" + testCollectionName);\n    doTestConfigUpdate(testCollectionName, solrUrl);\n\n    log.info(\"Running healthcheck for \" + testCollectionName);\n    doTestHealthcheck(testCollectionName, cloudClient.getZkHost());\n\n    // verify the delete action works too\n    log.info(\"Running delete for \"+testCollectionName);\n    doTestDeleteAction(testCollectionName, solrUrl);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection succeeded ... shutting down now!\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26","date":1531589977,"type":3,"author":"Michael Braun","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/SolrCloudExampleTest#testLoadDocsIntoGettingStartedCollection().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/SolrCloudExampleTest#testLoadDocsIntoGettingStartedCollection().mjava","sourceNew":"  @Test\n  // 12-Jun-2018 @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 04-May-2018\n  public void testLoadDocsIntoGettingStartedCollection() throws Exception {\n    waitForThingsToLevelOut(30000);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection initialized OK ... running test logic\");\n\n    String testCollectionName = \"gettingstarted\";\n    File defaultConfigs = new File(ExternalPaths.DEFAULT_CONFIGSET);\n    assertTrue(defaultConfigs.getAbsolutePath()+\" not found!\", defaultConfigs.isDirectory());\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    if (liveNodes.isEmpty())\n      fail(\"No live nodes found! Cannot create a collection until there is at least 1 live node in the cluster.\");\n    String firstLiveNode = liveNodes.iterator().next();\n    String solrUrl = cloudClient.getZkStateReader().getBaseUrlForNodeName(firstLiveNode);\n\n    // create the gettingstarted collection just like the bin/solr script would do\n    String[] args = new String[] {\n        \"-name\", testCollectionName,\n        \"-shards\", \"2\",\n        \"-replicationFactor\", \"2\",\n        \"-confname\", testCollectionName,\n        \"-confdir\", \"_default\",\n        \"-configsetsDir\", defaultConfigs.getParentFile().getParentFile().getAbsolutePath(),\n        \"-solrUrl\", solrUrl\n    };\n\n    // NOTE: not calling SolrCLI.main as the script does because it calls System.exit which is a no-no in a JUnit test\n\n    SolrCLI.CreateCollectionTool tool = new SolrCLI.CreateCollectionTool();\n    CommandLine cli = SolrCLI.processCommandLineArgs(SolrCLI.joinCommonAndToolOptions(tool.getOptions()), args);\n    log.info(\"Creating the '\"+testCollectionName+\"' collection using SolrCLI with: \"+solrUrl);\n    tool.runTool(cli);\n    assertTrue(\"Collection '\" + testCollectionName + \"' doesn't exist after trying to create it!\",\n        cloudClient.getZkStateReader().getClusterState().hasCollection(testCollectionName));\n\n    // verify the collection is usable ...\n    ensureAllReplicasAreActive(testCollectionName, \"shard1\", 2, 2, 20);\n    ensureAllReplicasAreActive(testCollectionName, \"shard2\", 2, 2, 10);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    int invalidToolExitStatus = 1;\n    assertEquals(\"Collection '\" + testCollectionName + \"' created even though it already existed\",\n        invalidToolExitStatus, tool.runTool(cli));\n\n    // now index docs like bin/post would do but we can't use SimplePostTool because it uses System.exit when\n    // it encounters an error, which JUnit doesn't like ...\n    log.info(\"Created collection, now posting example docs!\");\n    File exampleDocsDir = new File(ExternalPaths.SOURCE_HOME, \"example/exampledocs\");\n    assertTrue(exampleDocsDir.getAbsolutePath()+\" not found!\", exampleDocsDir.isDirectory());\n\n    List<File> xmlFiles = Arrays.asList(exampleDocsDir.listFiles(new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return name.endsWith(\".xml\");\n      }\n    }));\n\n    // force a deterministic random ordering of the files so seeds reproduce regardless of platform/filesystem\n    Collections.sort(xmlFiles, (o1, o2) -> {\n      // don't rely on File.compareTo, it's behavior varies by OS\n      return o1.getName().compareTo(o2.getName());\n    });\n    Collections.shuffle(xmlFiles, new Random(random().nextLong()));\n\n    // if you add/remove example XML docs, you'll have to fix these expected values\n    int expectedXmlFileCount = 14;\n    int expectedXmlDocCount = 32;\n\n    assertEquals(\"Unexpected # of example XML files in \"+exampleDocsDir.getAbsolutePath(),\n                 expectedXmlFileCount, xmlFiles.size());\n    \n    for (File xml : xmlFiles) {\n      log.info(\"POSTing \"+xml.getAbsolutePath());\n      cloudClient.request(new StreamingUpdateRequest(\"/update\",xml,\"application/xml\"));\n    }\n    cloudClient.commit();\n\n    int numFound = 0;\n\n    // give the update a chance to take effect.\n    for (int idx = 0; idx < 100; ++idx) {\n      QueryResponse qr = cloudClient.query(new SolrQuery(\"*:*\"));\n      numFound = (int) qr.getResults().getNumFound();\n      if (numFound == expectedXmlDocCount) break;\n      Thread.sleep(100);\n    }\n    assertEquals(\"*:* found unexpected number of documents\", expectedXmlDocCount, numFound);\n\n    log.info(\"Updating Config for \" + testCollectionName);\n    doTestConfigUpdate(testCollectionName, solrUrl);\n\n    log.info(\"Running healthcheck for \" + testCollectionName);\n    doTestHealthcheck(testCollectionName, cloudClient.getZkHost());\n\n    // verify the delete action works too\n    log.info(\"Running delete for \"+testCollectionName);\n    doTestDeleteAction(testCollectionName, solrUrl);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection succeeded ... shutting down now!\");\n  }\n\n","sourceOld":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 04-May-2018\n  public void testLoadDocsIntoGettingStartedCollection() throws Exception {\n    waitForThingsToLevelOut(30000);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection initialized OK ... running test logic\");\n\n    String testCollectionName = \"gettingstarted\";\n    File defaultConfigs = new File(ExternalPaths.DEFAULT_CONFIGSET);\n    assertTrue(defaultConfigs.getAbsolutePath()+\" not found!\", defaultConfigs.isDirectory());\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    if (liveNodes.isEmpty())\n      fail(\"No live nodes found! Cannot create a collection until there is at least 1 live node in the cluster.\");\n    String firstLiveNode = liveNodes.iterator().next();\n    String solrUrl = cloudClient.getZkStateReader().getBaseUrlForNodeName(firstLiveNode);\n\n    // create the gettingstarted collection just like the bin/solr script would do\n    String[] args = new String[] {\n        \"-name\", testCollectionName,\n        \"-shards\", \"2\",\n        \"-replicationFactor\", \"2\",\n        \"-confname\", testCollectionName,\n        \"-confdir\", \"_default\",\n        \"-configsetsDir\", defaultConfigs.getParentFile().getParentFile().getAbsolutePath(),\n        \"-solrUrl\", solrUrl\n    };\n\n    // NOTE: not calling SolrCLI.main as the script does because it calls System.exit which is a no-no in a JUnit test\n\n    SolrCLI.CreateCollectionTool tool = new SolrCLI.CreateCollectionTool();\n    CommandLine cli = SolrCLI.processCommandLineArgs(SolrCLI.joinCommonAndToolOptions(tool.getOptions()), args);\n    log.info(\"Creating the '\"+testCollectionName+\"' collection using SolrCLI with: \"+solrUrl);\n    tool.runTool(cli);\n    assertTrue(\"Collection '\" + testCollectionName + \"' doesn't exist after trying to create it!\",\n        cloudClient.getZkStateReader().getClusterState().hasCollection(testCollectionName));\n\n    // verify the collection is usable ...\n    ensureAllReplicasAreActive(testCollectionName, \"shard1\", 2, 2, 20);\n    ensureAllReplicasAreActive(testCollectionName, \"shard2\", 2, 2, 10);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    int invalidToolExitStatus = 1;\n    assertEquals(\"Collection '\" + testCollectionName + \"' created even though it already existed\",\n        invalidToolExitStatus, tool.runTool(cli));\n\n    // now index docs like bin/post would do but we can't use SimplePostTool because it uses System.exit when\n    // it encounters an error, which JUnit doesn't like ...\n    log.info(\"Created collection, now posting example docs!\");\n    File exampleDocsDir = new File(ExternalPaths.SOURCE_HOME, \"example/exampledocs\");\n    assertTrue(exampleDocsDir.getAbsolutePath()+\" not found!\", exampleDocsDir.isDirectory());\n\n    List<File> xmlFiles = Arrays.asList(exampleDocsDir.listFiles(new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return name.endsWith(\".xml\");\n      }\n    }));\n\n    // force a deterministic random ordering of the files so seeds reproduce regardless of platform/filesystem\n    Collections.sort(xmlFiles, (o1, o2) -> {\n      // don't rely on File.compareTo, it's behavior varies by OS\n      return o1.getName().compareTo(o2.getName());\n    });\n    Collections.shuffle(xmlFiles, new Random(random().nextLong()));\n\n    // if you add/remove example XML docs, you'll have to fix these expected values\n    int expectedXmlFileCount = 14;\n    int expectedXmlDocCount = 32;\n\n    assertEquals(\"Unexpected # of example XML files in \"+exampleDocsDir.getAbsolutePath(),\n                 expectedXmlFileCount, xmlFiles.size());\n    \n    for (File xml : xmlFiles) {\n      ContentStreamUpdateRequest req = new ContentStreamUpdateRequest(\"/update\");\n      req.addFile(xml, \"application/xml\");\n      log.info(\"POSTing \"+xml.getAbsolutePath());\n      cloudClient.request(req);\n    }\n    cloudClient.commit();\n\n    int numFound = 0;\n\n    // give the update a chance to take effect.\n    for (int idx = 0; idx < 100; ++idx) {\n      QueryResponse qr = cloudClient.query(new SolrQuery(\"*:*\"));\n      numFound = (int) qr.getResults().getNumFound();\n      if (numFound == expectedXmlDocCount) break;\n      Thread.sleep(100);\n    }\n    assertEquals(\"*:* found unexpected number of documents\", expectedXmlDocCount, numFound);\n\n    log.info(\"Updating Config for \" + testCollectionName);\n    doTestConfigUpdate(testCollectionName, solrUrl);\n\n    log.info(\"Running healthcheck for \" + testCollectionName);\n    doTestHealthcheck(testCollectionName, cloudClient.getZkHost());\n\n    // verify the delete action works too\n    log.info(\"Running delete for \"+testCollectionName);\n    doTestDeleteAction(testCollectionName, solrUrl);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection succeeded ... shutting down now!\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","date":1531905561,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/SolrCloudExampleTest#testLoadDocsIntoGettingStartedCollection().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/SolrCloudExampleTest#testLoadDocsIntoGettingStartedCollection().mjava","sourceNew":"  @Test\n  // 12-Jun-2018 @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 04-May-2018\n  public void testLoadDocsIntoGettingStartedCollection() throws Exception {\n    waitForThingsToLevelOut(30000);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection initialized OK ... running test logic\");\n\n    String testCollectionName = \"gettingstarted\";\n    File defaultConfigs = new File(ExternalPaths.DEFAULT_CONFIGSET);\n    assertTrue(defaultConfigs.getAbsolutePath()+\" not found!\", defaultConfigs.isDirectory());\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    if (liveNodes.isEmpty())\n      fail(\"No live nodes found! Cannot create a collection until there is at least 1 live node in the cluster.\");\n    String firstLiveNode = liveNodes.iterator().next();\n    String solrUrl = cloudClient.getZkStateReader().getBaseUrlForNodeName(firstLiveNode);\n\n    // create the gettingstarted collection just like the bin/solr script would do\n    String[] args = new String[] {\n        \"-name\", testCollectionName,\n        \"-shards\", \"2\",\n        \"-replicationFactor\", \"2\",\n        \"-confname\", testCollectionName,\n        \"-confdir\", \"_default\",\n        \"-configsetsDir\", defaultConfigs.getParentFile().getParentFile().getAbsolutePath(),\n        \"-solrUrl\", solrUrl\n    };\n\n    // NOTE: not calling SolrCLI.main as the script does because it calls System.exit which is a no-no in a JUnit test\n\n    SolrCLI.CreateCollectionTool tool = new SolrCLI.CreateCollectionTool();\n    CommandLine cli = SolrCLI.processCommandLineArgs(SolrCLI.joinCommonAndToolOptions(tool.getOptions()), args);\n    log.info(\"Creating the '\"+testCollectionName+\"' collection using SolrCLI with: \"+solrUrl);\n    tool.runTool(cli);\n    assertTrue(\"Collection '\" + testCollectionName + \"' doesn't exist after trying to create it!\",\n        cloudClient.getZkStateReader().getClusterState().hasCollection(testCollectionName));\n\n    // verify the collection is usable ...\n    ensureAllReplicasAreActive(testCollectionName, \"shard1\", 2, 2, 20);\n    ensureAllReplicasAreActive(testCollectionName, \"shard2\", 2, 2, 10);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    int invalidToolExitStatus = 1;\n    assertEquals(\"Collection '\" + testCollectionName + \"' created even though it already existed\",\n        invalidToolExitStatus, tool.runTool(cli));\n\n    // now index docs like bin/post would do but we can't use SimplePostTool because it uses System.exit when\n    // it encounters an error, which JUnit doesn't like ...\n    log.info(\"Created collection, now posting example docs!\");\n    File exampleDocsDir = new File(ExternalPaths.SOURCE_HOME, \"example/exampledocs\");\n    assertTrue(exampleDocsDir.getAbsolutePath()+\" not found!\", exampleDocsDir.isDirectory());\n\n    List<File> xmlFiles = Arrays.asList(exampleDocsDir.listFiles(new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return name.endsWith(\".xml\");\n      }\n    }));\n\n    // force a deterministic random ordering of the files so seeds reproduce regardless of platform/filesystem\n    Collections.sort(xmlFiles, (o1, o2) -> {\n      // don't rely on File.compareTo, it's behavior varies by OS\n      return o1.getName().compareTo(o2.getName());\n    });\n    Collections.shuffle(xmlFiles, new Random(random().nextLong()));\n\n    // if you add/remove example XML docs, you'll have to fix these expected values\n    int expectedXmlFileCount = 14;\n    int expectedXmlDocCount = 32;\n\n    assertEquals(\"Unexpected # of example XML files in \"+exampleDocsDir.getAbsolutePath(),\n                 expectedXmlFileCount, xmlFiles.size());\n    \n    for (File xml : xmlFiles) {\n      log.info(\"POSTing \"+xml.getAbsolutePath());\n      cloudClient.request(new StreamingUpdateRequest(\"/update\",xml,\"application/xml\"));\n    }\n    cloudClient.commit();\n\n    int numFound = 0;\n\n    // give the update a chance to take effect.\n    for (int idx = 0; idx < 100; ++idx) {\n      QueryResponse qr = cloudClient.query(new SolrQuery(\"*:*\"));\n      numFound = (int) qr.getResults().getNumFound();\n      if (numFound == expectedXmlDocCount) break;\n      Thread.sleep(100);\n    }\n    assertEquals(\"*:* found unexpected number of documents\", expectedXmlDocCount, numFound);\n\n    log.info(\"Updating Config for \" + testCollectionName);\n    doTestConfigUpdate(testCollectionName, solrUrl);\n\n    log.info(\"Running healthcheck for \" + testCollectionName);\n    doTestHealthcheck(testCollectionName, cloudClient.getZkHost());\n\n    // verify the delete action works too\n    log.info(\"Running delete for \"+testCollectionName);\n    doTestDeleteAction(testCollectionName, solrUrl);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection succeeded ... shutting down now!\");\n  }\n\n","sourceOld":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 04-May-2018\n  public void testLoadDocsIntoGettingStartedCollection() throws Exception {\n    waitForThingsToLevelOut(30000);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection initialized OK ... running test logic\");\n\n    String testCollectionName = \"gettingstarted\";\n    File defaultConfigs = new File(ExternalPaths.DEFAULT_CONFIGSET);\n    assertTrue(defaultConfigs.getAbsolutePath()+\" not found!\", defaultConfigs.isDirectory());\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    if (liveNodes.isEmpty())\n      fail(\"No live nodes found! Cannot create a collection until there is at least 1 live node in the cluster.\");\n    String firstLiveNode = liveNodes.iterator().next();\n    String solrUrl = cloudClient.getZkStateReader().getBaseUrlForNodeName(firstLiveNode);\n\n    // create the gettingstarted collection just like the bin/solr script would do\n    String[] args = new String[] {\n        \"-name\", testCollectionName,\n        \"-shards\", \"2\",\n        \"-replicationFactor\", \"2\",\n        \"-confname\", testCollectionName,\n        \"-confdir\", \"_default\",\n        \"-configsetsDir\", defaultConfigs.getParentFile().getParentFile().getAbsolutePath(),\n        \"-solrUrl\", solrUrl\n    };\n\n    // NOTE: not calling SolrCLI.main as the script does because it calls System.exit which is a no-no in a JUnit test\n\n    SolrCLI.CreateCollectionTool tool = new SolrCLI.CreateCollectionTool();\n    CommandLine cli = SolrCLI.processCommandLineArgs(SolrCLI.joinCommonAndToolOptions(tool.getOptions()), args);\n    log.info(\"Creating the '\"+testCollectionName+\"' collection using SolrCLI with: \"+solrUrl);\n    tool.runTool(cli);\n    assertTrue(\"Collection '\" + testCollectionName + \"' doesn't exist after trying to create it!\",\n        cloudClient.getZkStateReader().getClusterState().hasCollection(testCollectionName));\n\n    // verify the collection is usable ...\n    ensureAllReplicasAreActive(testCollectionName, \"shard1\", 2, 2, 20);\n    ensureAllReplicasAreActive(testCollectionName, \"shard2\", 2, 2, 10);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    int invalidToolExitStatus = 1;\n    assertEquals(\"Collection '\" + testCollectionName + \"' created even though it already existed\",\n        invalidToolExitStatus, tool.runTool(cli));\n\n    // now index docs like bin/post would do but we can't use SimplePostTool because it uses System.exit when\n    // it encounters an error, which JUnit doesn't like ...\n    log.info(\"Created collection, now posting example docs!\");\n    File exampleDocsDir = new File(ExternalPaths.SOURCE_HOME, \"example/exampledocs\");\n    assertTrue(exampleDocsDir.getAbsolutePath()+\" not found!\", exampleDocsDir.isDirectory());\n\n    List<File> xmlFiles = Arrays.asList(exampleDocsDir.listFiles(new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return name.endsWith(\".xml\");\n      }\n    }));\n\n    // force a deterministic random ordering of the files so seeds reproduce regardless of platform/filesystem\n    Collections.sort(xmlFiles, (o1, o2) -> {\n      // don't rely on File.compareTo, it's behavior varies by OS\n      return o1.getName().compareTo(o2.getName());\n    });\n    Collections.shuffle(xmlFiles, new Random(random().nextLong()));\n\n    // if you add/remove example XML docs, you'll have to fix these expected values\n    int expectedXmlFileCount = 14;\n    int expectedXmlDocCount = 32;\n\n    assertEquals(\"Unexpected # of example XML files in \"+exampleDocsDir.getAbsolutePath(),\n                 expectedXmlFileCount, xmlFiles.size());\n    \n    for (File xml : xmlFiles) {\n      ContentStreamUpdateRequest req = new ContentStreamUpdateRequest(\"/update\");\n      req.addFile(xml, \"application/xml\");\n      log.info(\"POSTing \"+xml.getAbsolutePath());\n      cloudClient.request(req);\n    }\n    cloudClient.commit();\n\n    int numFound = 0;\n\n    // give the update a chance to take effect.\n    for (int idx = 0; idx < 100; ++idx) {\n      QueryResponse qr = cloudClient.query(new SolrQuery(\"*:*\"));\n      numFound = (int) qr.getResults().getNumFound();\n      if (numFound == expectedXmlDocCount) break;\n      Thread.sleep(100);\n    }\n    assertEquals(\"*:* found unexpected number of documents\", expectedXmlDocCount, numFound);\n\n    log.info(\"Updating Config for \" + testCollectionName);\n    doTestConfigUpdate(testCollectionName, solrUrl);\n\n    log.info(\"Running healthcheck for \" + testCollectionName);\n    doTestHealthcheck(testCollectionName, cloudClient.getZkHost());\n\n    // verify the delete action works too\n    log.info(\"Running delete for \"+testCollectionName);\n    doTestDeleteAction(testCollectionName, solrUrl);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection succeeded ... shutting down now!\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"add1e7dd742ea533ff4318cea83ca0a1f669f662","date":1585262285,"type":3,"author":"Mike Drob","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/SolrCloudExampleTest#testLoadDocsIntoGettingStartedCollection().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/SolrCloudExampleTest#testLoadDocsIntoGettingStartedCollection().mjava","sourceNew":"  @Test\n  // 12-Jun-2018 @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 04-May-2018\n  public void testLoadDocsIntoGettingStartedCollection() throws Exception {\n    waitForThingsToLevelOut(30, TimeUnit.SECONDS);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection initialized OK ... running test logic\");\n\n    String testCollectionName = \"gettingstarted\";\n    File defaultConfigs = new File(ExternalPaths.DEFAULT_CONFIGSET);\n    assertTrue(defaultConfigs.getAbsolutePath()+\" not found!\", defaultConfigs.isDirectory());\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    if (liveNodes.isEmpty())\n      fail(\"No live nodes found! Cannot create a collection until there is at least 1 live node in the cluster.\");\n    String firstLiveNode = liveNodes.iterator().next();\n    String solrUrl = cloudClient.getZkStateReader().getBaseUrlForNodeName(firstLiveNode);\n\n    // create the gettingstarted collection just like the bin/solr script would do\n    String[] args = new String[] {\n        \"-name\", testCollectionName,\n        \"-shards\", \"2\",\n        \"-replicationFactor\", \"2\",\n        \"-confname\", testCollectionName,\n        \"-confdir\", \"_default\",\n        \"-configsetsDir\", defaultConfigs.getParentFile().getParentFile().getAbsolutePath(),\n        \"-solrUrl\", solrUrl\n    };\n\n    // NOTE: not calling SolrCLI.main as the script does because it calls System.exit which is a no-no in a JUnit test\n\n    SolrCLI.CreateCollectionTool tool = new SolrCLI.CreateCollectionTool();\n    CommandLine cli = SolrCLI.processCommandLineArgs(SolrCLI.joinCommonAndToolOptions(tool.getOptions()), args);\n    log.info(\"Creating the '\"+testCollectionName+\"' collection using SolrCLI with: \"+solrUrl);\n    tool.runTool(cli);\n    assertTrue(\"Collection '\" + testCollectionName + \"' doesn't exist after trying to create it!\",\n        cloudClient.getZkStateReader().getClusterState().hasCollection(testCollectionName));\n\n    // verify the collection is usable ...\n    ensureAllReplicasAreActive(testCollectionName, \"shard1\", 2, 2, 20);\n    ensureAllReplicasAreActive(testCollectionName, \"shard2\", 2, 2, 10);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    int invalidToolExitStatus = 1;\n    assertEquals(\"Collection '\" + testCollectionName + \"' created even though it already existed\",\n        invalidToolExitStatus, tool.runTool(cli));\n\n    // now index docs like bin/post would do but we can't use SimplePostTool because it uses System.exit when\n    // it encounters an error, which JUnit doesn't like ...\n    log.info(\"Created collection, now posting example docs!\");\n    File exampleDocsDir = new File(ExternalPaths.SOURCE_HOME, \"example/exampledocs\");\n    assertTrue(exampleDocsDir.getAbsolutePath()+\" not found!\", exampleDocsDir.isDirectory());\n\n    List<File> xmlFiles = Arrays.asList(exampleDocsDir.listFiles(new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return name.endsWith(\".xml\");\n      }\n    }));\n\n    // force a deterministic random ordering of the files so seeds reproduce regardless of platform/filesystem\n    Collections.sort(xmlFiles, (o1, o2) -> {\n      // don't rely on File.compareTo, it's behavior varies by OS\n      return o1.getName().compareTo(o2.getName());\n    });\n    Collections.shuffle(xmlFiles, new Random(random().nextLong()));\n\n    // if you add/remove example XML docs, you'll have to fix these expected values\n    int expectedXmlFileCount = 14;\n    int expectedXmlDocCount = 32;\n\n    assertEquals(\"Unexpected # of example XML files in \"+exampleDocsDir.getAbsolutePath(),\n                 expectedXmlFileCount, xmlFiles.size());\n    \n    for (File xml : xmlFiles) {\n      log.info(\"POSTing \"+xml.getAbsolutePath());\n      cloudClient.request(new StreamingUpdateRequest(\"/update\",xml,\"application/xml\"));\n    }\n    cloudClient.commit();\n\n    int numFound = 0;\n\n    // give the update a chance to take effect.\n    for (int idx = 0; idx < 100; ++idx) {\n      QueryResponse qr = cloudClient.query(new SolrQuery(\"*:*\"));\n      numFound = (int) qr.getResults().getNumFound();\n      if (numFound == expectedXmlDocCount) break;\n      Thread.sleep(100);\n    }\n    assertEquals(\"*:* found unexpected number of documents\", expectedXmlDocCount, numFound);\n\n    log.info(\"Updating Config for \" + testCollectionName);\n    doTestConfigUpdate(testCollectionName, solrUrl);\n\n    log.info(\"Running healthcheck for \" + testCollectionName);\n    doTestHealthcheck(testCollectionName, cloudClient.getZkHost());\n\n    // verify the delete action works too\n    log.info(\"Running delete for \"+testCollectionName);\n    doTestDeleteAction(testCollectionName, solrUrl);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection succeeded ... shutting down now!\");\n  }\n\n","sourceOld":"  @Test\n  // 12-Jun-2018 @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 04-May-2018\n  public void testLoadDocsIntoGettingStartedCollection() throws Exception {\n    waitForThingsToLevelOut(30000);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection initialized OK ... running test logic\");\n\n    String testCollectionName = \"gettingstarted\";\n    File defaultConfigs = new File(ExternalPaths.DEFAULT_CONFIGSET);\n    assertTrue(defaultConfigs.getAbsolutePath()+\" not found!\", defaultConfigs.isDirectory());\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    if (liveNodes.isEmpty())\n      fail(\"No live nodes found! Cannot create a collection until there is at least 1 live node in the cluster.\");\n    String firstLiveNode = liveNodes.iterator().next();\n    String solrUrl = cloudClient.getZkStateReader().getBaseUrlForNodeName(firstLiveNode);\n\n    // create the gettingstarted collection just like the bin/solr script would do\n    String[] args = new String[] {\n        \"-name\", testCollectionName,\n        \"-shards\", \"2\",\n        \"-replicationFactor\", \"2\",\n        \"-confname\", testCollectionName,\n        \"-confdir\", \"_default\",\n        \"-configsetsDir\", defaultConfigs.getParentFile().getParentFile().getAbsolutePath(),\n        \"-solrUrl\", solrUrl\n    };\n\n    // NOTE: not calling SolrCLI.main as the script does because it calls System.exit which is a no-no in a JUnit test\n\n    SolrCLI.CreateCollectionTool tool = new SolrCLI.CreateCollectionTool();\n    CommandLine cli = SolrCLI.processCommandLineArgs(SolrCLI.joinCommonAndToolOptions(tool.getOptions()), args);\n    log.info(\"Creating the '\"+testCollectionName+\"' collection using SolrCLI with: \"+solrUrl);\n    tool.runTool(cli);\n    assertTrue(\"Collection '\" + testCollectionName + \"' doesn't exist after trying to create it!\",\n        cloudClient.getZkStateReader().getClusterState().hasCollection(testCollectionName));\n\n    // verify the collection is usable ...\n    ensureAllReplicasAreActive(testCollectionName, \"shard1\", 2, 2, 20);\n    ensureAllReplicasAreActive(testCollectionName, \"shard2\", 2, 2, 10);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    int invalidToolExitStatus = 1;\n    assertEquals(\"Collection '\" + testCollectionName + \"' created even though it already existed\",\n        invalidToolExitStatus, tool.runTool(cli));\n\n    // now index docs like bin/post would do but we can't use SimplePostTool because it uses System.exit when\n    // it encounters an error, which JUnit doesn't like ...\n    log.info(\"Created collection, now posting example docs!\");\n    File exampleDocsDir = new File(ExternalPaths.SOURCE_HOME, \"example/exampledocs\");\n    assertTrue(exampleDocsDir.getAbsolutePath()+\" not found!\", exampleDocsDir.isDirectory());\n\n    List<File> xmlFiles = Arrays.asList(exampleDocsDir.listFiles(new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return name.endsWith(\".xml\");\n      }\n    }));\n\n    // force a deterministic random ordering of the files so seeds reproduce regardless of platform/filesystem\n    Collections.sort(xmlFiles, (o1, o2) -> {\n      // don't rely on File.compareTo, it's behavior varies by OS\n      return o1.getName().compareTo(o2.getName());\n    });\n    Collections.shuffle(xmlFiles, new Random(random().nextLong()));\n\n    // if you add/remove example XML docs, you'll have to fix these expected values\n    int expectedXmlFileCount = 14;\n    int expectedXmlDocCount = 32;\n\n    assertEquals(\"Unexpected # of example XML files in \"+exampleDocsDir.getAbsolutePath(),\n                 expectedXmlFileCount, xmlFiles.size());\n    \n    for (File xml : xmlFiles) {\n      log.info(\"POSTing \"+xml.getAbsolutePath());\n      cloudClient.request(new StreamingUpdateRequest(\"/update\",xml,\"application/xml\"));\n    }\n    cloudClient.commit();\n\n    int numFound = 0;\n\n    // give the update a chance to take effect.\n    for (int idx = 0; idx < 100; ++idx) {\n      QueryResponse qr = cloudClient.query(new SolrQuery(\"*:*\"));\n      numFound = (int) qr.getResults().getNumFound();\n      if (numFound == expectedXmlDocCount) break;\n      Thread.sleep(100);\n    }\n    assertEquals(\"*:* found unexpected number of documents\", expectedXmlDocCount, numFound);\n\n    log.info(\"Updating Config for \" + testCollectionName);\n    doTestConfigUpdate(testCollectionName, solrUrl);\n\n    log.info(\"Running healthcheck for \" + testCollectionName);\n    doTestHealthcheck(testCollectionName, cloudClient.getZkHost());\n\n    // verify the delete action works too\n    log.info(\"Running delete for \"+testCollectionName);\n    doTestDeleteAction(testCollectionName, solrUrl);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection succeeded ... shutting down now!\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a966532d92cf9ba2856f15a8140151bb6b518e4b","date":1588290631,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/SolrCloudExampleTest#testLoadDocsIntoGettingStartedCollection().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/SolrCloudExampleTest#testLoadDocsIntoGettingStartedCollection().mjava","sourceNew":"  @Test\n  // 12-Jun-2018 @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 04-May-2018\n  public void testLoadDocsIntoGettingStartedCollection() throws Exception {\n    waitForThingsToLevelOut(30, TimeUnit.SECONDS);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection initialized OK ... running test logic\");\n\n    String testCollectionName = \"gettingstarted\";\n    File defaultConfigs = new File(ExternalPaths.DEFAULT_CONFIGSET);\n    assertTrue(defaultConfigs.getAbsolutePath()+\" not found!\", defaultConfigs.isDirectory());\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    if (liveNodes.isEmpty())\n      fail(\"No live nodes found! Cannot create a collection until there is at least 1 live node in the cluster.\");\n    String firstLiveNode = liveNodes.iterator().next();\n    String solrUrl = cloudClient.getZkStateReader().getBaseUrlForNodeName(firstLiveNode);\n\n    // create the gettingstarted collection just like the bin/solr script would do\n    String[] args = new String[] {\n        \"-name\", testCollectionName,\n        \"-shards\", \"2\",\n        \"-replicationFactor\", \"2\",\n        \"-confname\", testCollectionName,\n        \"-confdir\", \"_default\",\n        \"-configsetsDir\", defaultConfigs.getParentFile().getParentFile().getAbsolutePath(),\n        \"-solrUrl\", solrUrl\n    };\n\n    // NOTE: not calling SolrCLI.main as the script does because it calls System.exit which is a no-no in a JUnit test\n\n    SolrCLI.CreateCollectionTool tool = new SolrCLI.CreateCollectionTool();\n    CommandLine cli = SolrCLI.processCommandLineArgs(SolrCLI.joinCommonAndToolOptions(tool.getOptions()), args);\n    log.info(\"Creating the '{}' collection using SolrCLI with: {}\", testCollectionName, solrUrl);\n    tool.runTool(cli);\n    assertTrue(\"Collection '\" + testCollectionName + \"' doesn't exist after trying to create it!\",\n        cloudClient.getZkStateReader().getClusterState().hasCollection(testCollectionName));\n\n    // verify the collection is usable ...\n    ensureAllReplicasAreActive(testCollectionName, \"shard1\", 2, 2, 20);\n    ensureAllReplicasAreActive(testCollectionName, \"shard2\", 2, 2, 10);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    int invalidToolExitStatus = 1;\n    assertEquals(\"Collection '\" + testCollectionName + \"' created even though it already existed\",\n        invalidToolExitStatus, tool.runTool(cli));\n\n    // now index docs like bin/post would do but we can't use SimplePostTool because it uses System.exit when\n    // it encounters an error, which JUnit doesn't like ...\n    log.info(\"Created collection, now posting example docs!\");\n    File exampleDocsDir = new File(ExternalPaths.SOURCE_HOME, \"example/exampledocs\");\n    assertTrue(exampleDocsDir.getAbsolutePath()+\" not found!\", exampleDocsDir.isDirectory());\n\n    List<File> xmlFiles = Arrays.asList(exampleDocsDir.listFiles(new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return name.endsWith(\".xml\");\n      }\n    }));\n\n    // force a deterministic random ordering of the files so seeds reproduce regardless of platform/filesystem\n    Collections.sort(xmlFiles, (o1, o2) -> {\n      // don't rely on File.compareTo, it's behavior varies by OS\n      return o1.getName().compareTo(o2.getName());\n    });\n    Collections.shuffle(xmlFiles, new Random(random().nextLong()));\n\n    // if you add/remove example XML docs, you'll have to fix these expected values\n    int expectedXmlFileCount = 14;\n    int expectedXmlDocCount = 32;\n\n    assertEquals(\"Unexpected # of example XML files in \"+exampleDocsDir.getAbsolutePath(),\n                 expectedXmlFileCount, xmlFiles.size());\n    \n    for (File xml : xmlFiles) {\n      if (log.isInfoEnabled()) {\n        log.info(\"POSTing {}\", xml.getAbsolutePath());\n      }\n      cloudClient.request(new StreamingUpdateRequest(\"/update\",xml,\"application/xml\"));\n    }\n    cloudClient.commit();\n\n    int numFound = 0;\n\n    // give the update a chance to take effect.\n    for (int idx = 0; idx < 100; ++idx) {\n      QueryResponse qr = cloudClient.query(new SolrQuery(\"*:*\"));\n      numFound = (int) qr.getResults().getNumFound();\n      if (numFound == expectedXmlDocCount) break;\n      Thread.sleep(100);\n    }\n    assertEquals(\"*:* found unexpected number of documents\", expectedXmlDocCount, numFound);\n\n    log.info(\"Updating Config for {}\", testCollectionName);\n    doTestConfigUpdate(testCollectionName, solrUrl);\n\n    log.info(\"Running healthcheck for {}\", testCollectionName);\n    doTestHealthcheck(testCollectionName, cloudClient.getZkHost());\n\n    // verify the delete action works too\n    log.info(\"Running delete for {}\", testCollectionName);\n    doTestDeleteAction(testCollectionName, solrUrl);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection succeeded ... shutting down now!\");\n  }\n\n","sourceOld":"  @Test\n  // 12-Jun-2018 @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 04-May-2018\n  public void testLoadDocsIntoGettingStartedCollection() throws Exception {\n    waitForThingsToLevelOut(30, TimeUnit.SECONDS);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection initialized OK ... running test logic\");\n\n    String testCollectionName = \"gettingstarted\";\n    File defaultConfigs = new File(ExternalPaths.DEFAULT_CONFIGSET);\n    assertTrue(defaultConfigs.getAbsolutePath()+\" not found!\", defaultConfigs.isDirectory());\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    if (liveNodes.isEmpty())\n      fail(\"No live nodes found! Cannot create a collection until there is at least 1 live node in the cluster.\");\n    String firstLiveNode = liveNodes.iterator().next();\n    String solrUrl = cloudClient.getZkStateReader().getBaseUrlForNodeName(firstLiveNode);\n\n    // create the gettingstarted collection just like the bin/solr script would do\n    String[] args = new String[] {\n        \"-name\", testCollectionName,\n        \"-shards\", \"2\",\n        \"-replicationFactor\", \"2\",\n        \"-confname\", testCollectionName,\n        \"-confdir\", \"_default\",\n        \"-configsetsDir\", defaultConfigs.getParentFile().getParentFile().getAbsolutePath(),\n        \"-solrUrl\", solrUrl\n    };\n\n    // NOTE: not calling SolrCLI.main as the script does because it calls System.exit which is a no-no in a JUnit test\n\n    SolrCLI.CreateCollectionTool tool = new SolrCLI.CreateCollectionTool();\n    CommandLine cli = SolrCLI.processCommandLineArgs(SolrCLI.joinCommonAndToolOptions(tool.getOptions()), args);\n    log.info(\"Creating the '\"+testCollectionName+\"' collection using SolrCLI with: \"+solrUrl);\n    tool.runTool(cli);\n    assertTrue(\"Collection '\" + testCollectionName + \"' doesn't exist after trying to create it!\",\n        cloudClient.getZkStateReader().getClusterState().hasCollection(testCollectionName));\n\n    // verify the collection is usable ...\n    ensureAllReplicasAreActive(testCollectionName, \"shard1\", 2, 2, 20);\n    ensureAllReplicasAreActive(testCollectionName, \"shard2\", 2, 2, 10);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    int invalidToolExitStatus = 1;\n    assertEquals(\"Collection '\" + testCollectionName + \"' created even though it already existed\",\n        invalidToolExitStatus, tool.runTool(cli));\n\n    // now index docs like bin/post would do but we can't use SimplePostTool because it uses System.exit when\n    // it encounters an error, which JUnit doesn't like ...\n    log.info(\"Created collection, now posting example docs!\");\n    File exampleDocsDir = new File(ExternalPaths.SOURCE_HOME, \"example/exampledocs\");\n    assertTrue(exampleDocsDir.getAbsolutePath()+\" not found!\", exampleDocsDir.isDirectory());\n\n    List<File> xmlFiles = Arrays.asList(exampleDocsDir.listFiles(new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return name.endsWith(\".xml\");\n      }\n    }));\n\n    // force a deterministic random ordering of the files so seeds reproduce regardless of platform/filesystem\n    Collections.sort(xmlFiles, (o1, o2) -> {\n      // don't rely on File.compareTo, it's behavior varies by OS\n      return o1.getName().compareTo(o2.getName());\n    });\n    Collections.shuffle(xmlFiles, new Random(random().nextLong()));\n\n    // if you add/remove example XML docs, you'll have to fix these expected values\n    int expectedXmlFileCount = 14;\n    int expectedXmlDocCount = 32;\n\n    assertEquals(\"Unexpected # of example XML files in \"+exampleDocsDir.getAbsolutePath(),\n                 expectedXmlFileCount, xmlFiles.size());\n    \n    for (File xml : xmlFiles) {\n      log.info(\"POSTing \"+xml.getAbsolutePath());\n      cloudClient.request(new StreamingUpdateRequest(\"/update\",xml,\"application/xml\"));\n    }\n    cloudClient.commit();\n\n    int numFound = 0;\n\n    // give the update a chance to take effect.\n    for (int idx = 0; idx < 100; ++idx) {\n      QueryResponse qr = cloudClient.query(new SolrQuery(\"*:*\"));\n      numFound = (int) qr.getResults().getNumFound();\n      if (numFound == expectedXmlDocCount) break;\n      Thread.sleep(100);\n    }\n    assertEquals(\"*:* found unexpected number of documents\", expectedXmlDocCount, numFound);\n\n    log.info(\"Updating Config for \" + testCollectionName);\n    doTestConfigUpdate(testCollectionName, solrUrl);\n\n    log.info(\"Running healthcheck for \" + testCollectionName);\n    doTestHealthcheck(testCollectionName, cloudClient.getZkHost());\n\n    // verify the delete action works too\n    log.info(\"Running delete for \"+testCollectionName);\n    doTestDeleteAction(testCollectionName, solrUrl);\n\n    log.info(\"testLoadDocsIntoGettingStartedCollection succeeded ... shutting down now!\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"547b9bdc942b65ebcd943738bb12c2a222fcf566":["fa584ccfc18d85d3efa8a95d58762f54c68fa6bf"],"a966532d92cf9ba2856f15a8140151bb6b518e4b":["add1e7dd742ea533ff4318cea83ca0a1f669f662"],"3a0c04b71951333291abc7f317109a6a5957bd28":["4ca20be81c9284c840498143264e583ccbb8525a"],"28288370235ed02234a64753cdbf0c6ec096304a":["fb239ff148d77d2846f7c73b4b1f0ecb0827c0d5","6dac22e2c68188d3e5c96ca60febedc05a96f44f"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["3a0c04b71951333291abc7f317109a6a5957bd28","d470c8182e92b264680e34081b75e70a9f2b3c89"],"d470c8182e92b264680e34081b75e70a9f2b3c89":["3a0c04b71951333291abc7f317109a6a5957bd28","6b7179395314ddf699861fdd8c18857152660e84"],"4ca20be81c9284c840498143264e583ccbb8525a":["919a9ff0212f46eb240b8716a6d189b06659d3f2"],"fa584ccfc18d85d3efa8a95d58762f54c68fa6bf":["9d62f72d1c60d2be239222de52d5e7b516da5f6f"],"e9017cf144952056066919f1ebc7897ff9bd71b1":["d470c8182e92b264680e34081b75e70a9f2b3c89","fb239ff148d77d2846f7c73b4b1f0ecb0827c0d5"],"9d62f72d1c60d2be239222de52d5e7b516da5f6f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":["4bab9eeea60eefbea2957be27b8d1923095df771","a1c374690db69470f6aa4bffc43dcacf1f4e3e49"],"4bab9eeea60eefbea2957be27b8d1923095df771":["28288370235ed02234a64753cdbf0c6ec096304a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"6b7179395314ddf699861fdd8c18857152660e84":["3a0c04b71951333291abc7f317109a6a5957bd28"],"add1e7dd742ea533ff4318cea83ca0a1f669f662":["a1c374690db69470f6aa4bffc43dcacf1f4e3e49"],"fbedfa79ef95dc2b5b49f7d54d80e0b47867f9b4":["e9017cf144952056066919f1ebc7897ff9bd71b1","6dac22e2c68188d3e5c96ca60febedc05a96f44f"],"ebe8b79da5c80c6f5588d8dbd750a5f3865019a6":["4bab9eeea60eefbea2957be27b8d1923095df771"],"919a9ff0212f46eb240b8716a6d189b06659d3f2":["b3e2df0ef4d31d965ccc4afc2ec6349c06c3cccf"],"6dac22e2c68188d3e5c96ca60febedc05a96f44f":["fb239ff148d77d2846f7c73b4b1f0ecb0827c0d5"],"fb239ff148d77d2846f7c73b4b1f0ecb0827c0d5":["d470c8182e92b264680e34081b75e70a9f2b3c89"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a966532d92cf9ba2856f15a8140151bb6b518e4b"],"a1c374690db69470f6aa4bffc43dcacf1f4e3e49":["ebe8b79da5c80c6f5588d8dbd750a5f3865019a6"],"b3e2df0ef4d31d965ccc4afc2ec6349c06c3cccf":["547b9bdc942b65ebcd943738bb12c2a222fcf566"],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":["4bab9eeea60eefbea2957be27b8d1923095df771","a1c374690db69470f6aa4bffc43dcacf1f4e3e49"]},"commit2Childs":{"547b9bdc942b65ebcd943738bb12c2a222fcf566":["b3e2df0ef4d31d965ccc4afc2ec6349c06c3cccf"],"a966532d92cf9ba2856f15a8140151bb6b518e4b":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3a0c04b71951333291abc7f317109a6a5957bd28":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","d470c8182e92b264680e34081b75e70a9f2b3c89","6b7179395314ddf699861fdd8c18857152660e84"],"28288370235ed02234a64753cdbf0c6ec096304a":["4bab9eeea60eefbea2957be27b8d1923095df771"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"d470c8182e92b264680e34081b75e70a9f2b3c89":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","e9017cf144952056066919f1ebc7897ff9bd71b1","fb239ff148d77d2846f7c73b4b1f0ecb0827c0d5"],"fa584ccfc18d85d3efa8a95d58762f54c68fa6bf":["547b9bdc942b65ebcd943738bb12c2a222fcf566"],"4ca20be81c9284c840498143264e583ccbb8525a":["3a0c04b71951333291abc7f317109a6a5957bd28"],"e9017cf144952056066919f1ebc7897ff9bd71b1":["fbedfa79ef95dc2b5b49f7d54d80e0b47867f9b4"],"9d62f72d1c60d2be239222de52d5e7b516da5f6f":["fa584ccfc18d85d3efa8a95d58762f54c68fa6bf"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":[],"4bab9eeea60eefbea2957be27b8d1923095df771":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","ebe8b79da5c80c6f5588d8dbd750a5f3865019a6","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"6b7179395314ddf699861fdd8c18857152660e84":["d470c8182e92b264680e34081b75e70a9f2b3c89"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9d62f72d1c60d2be239222de52d5e7b516da5f6f"],"add1e7dd742ea533ff4318cea83ca0a1f669f662":["a966532d92cf9ba2856f15a8140151bb6b518e4b"],"fbedfa79ef95dc2b5b49f7d54d80e0b47867f9b4":[],"ebe8b79da5c80c6f5588d8dbd750a5f3865019a6":["a1c374690db69470f6aa4bffc43dcacf1f4e3e49"],"6dac22e2c68188d3e5c96ca60febedc05a96f44f":["28288370235ed02234a64753cdbf0c6ec096304a","fbedfa79ef95dc2b5b49f7d54d80e0b47867f9b4"],"919a9ff0212f46eb240b8716a6d189b06659d3f2":["4ca20be81c9284c840498143264e583ccbb8525a"],"fb239ff148d77d2846f7c73b4b1f0ecb0827c0d5":["28288370235ed02234a64753cdbf0c6ec096304a","e9017cf144952056066919f1ebc7897ff9bd71b1","6dac22e2c68188d3e5c96ca60febedc05a96f44f"],"a1c374690db69470f6aa4bffc43dcacf1f4e3e49":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","add1e7dd742ea533ff4318cea83ca0a1f669f662","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"b3e2df0ef4d31d965ccc4afc2ec6349c06c3cccf":["919a9ff0212f46eb240b8716a6d189b06659d3f2"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":[]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","fbedfa79ef95dc2b5b49f7d54d80e0b47867f9b4","cd5edd1f2b162a5cfa08efd17851a07373a96817","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}