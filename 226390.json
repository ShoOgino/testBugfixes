{"path":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testLeaderZkSessionLoss().mjava","commits":[{"id":"6e36353d7461af8d2329a78a71457cf8e3c1e88f","date":1411572107,"type":0,"author":"Timothy Potter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testLeaderZkSessionLoss().mjava","pathOld":"/dev/null","sourceNew":"  // test inspired by SOLR-6511\n  protected void testLeaderZkSessionLoss() throws Exception {\n\n    String testCollectionName = \"c8n_1x2_leader_session_loss\";\n    createCollection(testCollectionName, 1, 2, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    sendDoc(1);\n\n    List<Replica> notLeaders =\n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 2, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 1 replicas for collection \" + testCollectionName\n            + \" but found \" + notLeaders.size() + \"; clusterState: \"\n            + printClusterStateInfo(testCollectionName),\n        notLeaders.size() == 1);\n\n    Replica leader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n        testCollectionName+\"; clusterState: \"+printClusterStateInfo(testCollectionName), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n\n    HttpSolrServer leaderSolr = getHttpSolrServer(leader, testCollectionName);\n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(id, String.valueOf(2));\n    doc.addField(\"a_t\", \"hello\" + 2);\n\n    // cause leader migration by expiring the current leader's zk session\n    chaosMonkey.expireSession(leaderJetty);\n\n    String expectedNewLeaderCoreNodeName = notLeaders.get(0).getName();\n    long timeout = System.nanoTime() + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    while (System.nanoTime() < timeout) {\n      String currentLeaderName = null;\n      try {\n        Replica currentLeader =\n            cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n        currentLeaderName = currentLeader.getName();\n      } catch (Exception exc) {}\n\n      if (expectedNewLeaderCoreNodeName.equals(currentLeaderName))\n        break; // new leader was elected after zk session expiration\n\n      Thread.sleep(500);\n    }\n\n    Replica currentLeader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    assertEquals(expectedNewLeaderCoreNodeName, currentLeader.getName());\n\n    log.info(\"Sending doc 2 to old leader \"+leader.getName());\n    try {\n      leaderSolr.add(doc);\n      leaderSolr.shutdown();\n\n      Replica oldLeaderInRecovery = null;\n      for (Replica next : getActiveOrRecoveringReplicas(testCollectionName, \"shard1\")) {\n        if (next.getName().equals(leader.getName()) &&\n            ZkStateReader.RECOVERING.equals(next.getStr(ZkStateReader.STATE_PROP)))\n        {\n          oldLeaderInRecovery = next;\n          break;\n        }\n      }\n\n      // if the old leader is not active or recovering, the add should have failed\n      if (oldLeaderInRecovery != null) {\n        HttpSolrServer oldLeaderSolr = getHttpSolrServer(oldLeaderInRecovery, testCollectionName);\n        try {\n          assertDocExists(oldLeaderSolr, testCollectionName, \"2\");\n        } finally {\n          oldLeaderSolr.shutdown();\n        }\n      } else {\n        fail(\"Send doc 2 to old leader \" + leader.getName() +\n            \" should have failed! ClusterState: \" + printClusterStateInfo(testCollectionName));\n      }\n\n    } catch (SolrException exc) {\n      // this is expected ..\n      leaderSolr = getHttpSolrServer(currentLeader, testCollectionName);\n      try {\n        leaderSolr.add(doc); // this should work\n      } finally {\n        leaderSolr.shutdown();\n      }\n    }\n\n    List<Replica> participatingReplicas = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    Set<String> replicasToCheck = new HashSet<>();\n    for (Replica stillUp : participatingReplicas)\n      replicasToCheck.add(stillUp.getName());\n    waitToSeeReplicasActive(testCollectionName, \"shard1\", replicasToCheck, 20);\n    assertDocsExistInAllReplicas(participatingReplicas, testCollectionName, 1, 2);\n\n    // try to clean up\n    try {\n      CollectionAdminRequest req = new CollectionAdminRequest.Delete();\n      req.setCollectionName(testCollectionName);\n      req.process(cloudClient);\n    } catch (Exception e) {\n      // don't fail the test\n      log.warn(\"Could not delete collection {} after test completed\", testCollectionName);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ecdef415cd9c28cee0b395ac99e65c45a3efc4ff","date":1412003953,"type":3,"author":"Timothy Potter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testLeaderZkSessionLoss().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testLeaderZkSessionLoss().mjava","sourceNew":"  // test inspired by SOLR-6511\n  protected void testLeaderZkSessionLoss() throws Exception {\n\n    String testCollectionName = \"c8n_1x2_leader_session_loss\";\n    createCollection(testCollectionName, 1, 2, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    sendDoc(1);\n\n    List<Replica> notLeaders =\n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 2, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 1 replicas for collection \" + testCollectionName\n            + \" but found \" + notLeaders.size() + \"; clusterState: \"\n            + printClusterStateInfo(testCollectionName),\n        notLeaders.size() == 1);\n\n    Replica leader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n        testCollectionName+\"; clusterState: \"+printClusterStateInfo(testCollectionName), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n\n    HttpSolrServer leaderSolr = getHttpSolrServer(leader, testCollectionName);\n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(id, String.valueOf(2));\n    doc.addField(\"a_t\", \"hello\" + 2);\n\n    // cause leader migration by expiring the current leader's zk session\n    chaosMonkey.expireSession(leaderJetty);\n\n    String expectedNewLeaderCoreNodeName = notLeaders.get(0).getName();\n    long timeout = System.nanoTime() + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    while (System.nanoTime() < timeout) {\n      String currentLeaderName = null;\n      try {\n        Replica currentLeader =\n            cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n        currentLeaderName = currentLeader.getName();\n      } catch (Exception exc) {}\n\n      if (expectedNewLeaderCoreNodeName.equals(currentLeaderName))\n        break; // new leader was elected after zk session expiration\n\n      Thread.sleep(500);\n    }\n\n    Replica currentLeader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    assertEquals(expectedNewLeaderCoreNodeName, currentLeader.getName());\n\n    // TODO: This test logic seems to be timing dependent and fails on Jenkins\n    // need to come up with a better approach\n    log.info(\"Sending doc 2 to old leader \"+leader.getName());\n    try {\n      leaderSolr.add(doc);\n      leaderSolr.shutdown();\n\n      // if the add worked, then the doc must exist on the new leader\n      HttpSolrServer newLeaderSolr = getHttpSolrServer(currentLeader, testCollectionName);\n      try {\n        assertDocExists(newLeaderSolr, testCollectionName, \"2\");\n      } finally {\n        newLeaderSolr.shutdown();\n      }\n\n    } catch (SolrException exc) {\n      // this is ok provided the doc doesn't exist on the current leader\n      leaderSolr = getHttpSolrServer(currentLeader, testCollectionName);\n      try {\n        leaderSolr.add(doc); // this should work\n      } finally {\n        leaderSolr.shutdown();\n      }\n    }\n\n    List<Replica> participatingReplicas = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    Set<String> replicasToCheck = new HashSet<>();\n    for (Replica stillUp : participatingReplicas)\n      replicasToCheck.add(stillUp.getName());\n    waitToSeeReplicasActive(testCollectionName, \"shard1\", replicasToCheck, 20);\n    assertDocsExistInAllReplicas(participatingReplicas, testCollectionName, 1, 2);\n\n    // try to clean up\n    try {\n      CollectionAdminRequest req = new CollectionAdminRequest.Delete();\n      req.setCollectionName(testCollectionName);\n      req.process(cloudClient);\n    } catch (Exception e) {\n      // don't fail the test\n      log.warn(\"Could not delete collection {} after test completed\", testCollectionName);\n    }\n  }\n\n","sourceOld":"  // test inspired by SOLR-6511\n  protected void testLeaderZkSessionLoss() throws Exception {\n\n    String testCollectionName = \"c8n_1x2_leader_session_loss\";\n    createCollection(testCollectionName, 1, 2, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    sendDoc(1);\n\n    List<Replica> notLeaders =\n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 2, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 1 replicas for collection \" + testCollectionName\n            + \" but found \" + notLeaders.size() + \"; clusterState: \"\n            + printClusterStateInfo(testCollectionName),\n        notLeaders.size() == 1);\n\n    Replica leader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n        testCollectionName+\"; clusterState: \"+printClusterStateInfo(testCollectionName), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n\n    HttpSolrServer leaderSolr = getHttpSolrServer(leader, testCollectionName);\n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(id, String.valueOf(2));\n    doc.addField(\"a_t\", \"hello\" + 2);\n\n    // cause leader migration by expiring the current leader's zk session\n    chaosMonkey.expireSession(leaderJetty);\n\n    String expectedNewLeaderCoreNodeName = notLeaders.get(0).getName();\n    long timeout = System.nanoTime() + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    while (System.nanoTime() < timeout) {\n      String currentLeaderName = null;\n      try {\n        Replica currentLeader =\n            cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n        currentLeaderName = currentLeader.getName();\n      } catch (Exception exc) {}\n\n      if (expectedNewLeaderCoreNodeName.equals(currentLeaderName))\n        break; // new leader was elected after zk session expiration\n\n      Thread.sleep(500);\n    }\n\n    Replica currentLeader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    assertEquals(expectedNewLeaderCoreNodeName, currentLeader.getName());\n\n    log.info(\"Sending doc 2 to old leader \"+leader.getName());\n    try {\n      leaderSolr.add(doc);\n      leaderSolr.shutdown();\n\n      Replica oldLeaderInRecovery = null;\n      for (Replica next : getActiveOrRecoveringReplicas(testCollectionName, \"shard1\")) {\n        if (next.getName().equals(leader.getName()) &&\n            ZkStateReader.RECOVERING.equals(next.getStr(ZkStateReader.STATE_PROP)))\n        {\n          oldLeaderInRecovery = next;\n          break;\n        }\n      }\n\n      // if the old leader is not active or recovering, the add should have failed\n      if (oldLeaderInRecovery != null) {\n        HttpSolrServer oldLeaderSolr = getHttpSolrServer(oldLeaderInRecovery, testCollectionName);\n        try {\n          assertDocExists(oldLeaderSolr, testCollectionName, \"2\");\n        } finally {\n          oldLeaderSolr.shutdown();\n        }\n      } else {\n        fail(\"Send doc 2 to old leader \" + leader.getName() +\n            \" should have failed! ClusterState: \" + printClusterStateInfo(testCollectionName));\n      }\n\n    } catch (SolrException exc) {\n      // this is expected ..\n      leaderSolr = getHttpSolrServer(currentLeader, testCollectionName);\n      try {\n        leaderSolr.add(doc); // this should work\n      } finally {\n        leaderSolr.shutdown();\n      }\n    }\n\n    List<Replica> participatingReplicas = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    Set<String> replicasToCheck = new HashSet<>();\n    for (Replica stillUp : participatingReplicas)\n      replicasToCheck.add(stillUp.getName());\n    waitToSeeReplicasActive(testCollectionName, \"shard1\", replicasToCheck, 20);\n    assertDocsExistInAllReplicas(participatingReplicas, testCollectionName, 1, 2);\n\n    // try to clean up\n    try {\n      CollectionAdminRequest req = new CollectionAdminRequest.Delete();\n      req.setCollectionName(testCollectionName);\n      req.process(cloudClient);\n    } catch (Exception e) {\n      // don't fail the test\n      log.warn(\"Could not delete collection {} after test completed\", testCollectionName);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d9a47902d6207303f5ed3e7aaca62ca33433af66","date":1412435312,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testLeaderZkSessionLoss().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testLeaderZkSessionLoss().mjava","sourceNew":"  // test inspired by SOLR-6511\n  protected void testLeaderZkSessionLoss() throws Exception {\n\n    String testCollectionName = \"c8n_1x2_leader_session_loss\";\n    createCollection(testCollectionName, 1, 2, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    sendDoc(1);\n\n    List<Replica> notLeaders =\n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 2, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 1 replicas for collection \" + testCollectionName\n            + \" but found \" + notLeaders.size() + \"; clusterState: \"\n            + printClusterStateInfo(testCollectionName),\n        notLeaders.size() == 1);\n\n    Replica leader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n        testCollectionName+\"; clusterState: \"+printClusterStateInfo(testCollectionName), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n\n    HttpSolrServer leaderSolr = getHttpSolrServer(leader, testCollectionName);\n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(id, String.valueOf(2));\n    doc.addField(\"a_t\", \"hello\" + 2);\n\n    // cause leader migration by expiring the current leader's zk session\n    chaosMonkey.expireSession(leaderJetty);\n\n    String expectedNewLeaderCoreNodeName = notLeaders.get(0).getName();\n    long timeout = System.nanoTime() + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    while (System.nanoTime() < timeout) {\n      String currentLeaderName = null;\n      try {\n        Replica currentLeader =\n            cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n        currentLeaderName = currentLeader.getName();\n      } catch (Exception exc) {}\n\n      if (expectedNewLeaderCoreNodeName.equals(currentLeaderName))\n        break; // new leader was elected after zk session expiration\n\n      Thread.sleep(500);\n    }\n\n    Replica currentLeader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    assertEquals(expectedNewLeaderCoreNodeName, currentLeader.getName());\n\n    // TODO: This test logic seems to be timing dependent and fails on Jenkins\n    // need to come up with a better approach\n    log.info(\"Sending doc 2 to old leader \"+leader.getName());\n    try {\n      leaderSolr.add(doc);\n      leaderSolr.shutdown();\n\n      // if the add worked, then the doc must exist on the new leader\n      HttpSolrServer newLeaderSolr = getHttpSolrServer(currentLeader, testCollectionName);\n      try {\n        assertDocExists(newLeaderSolr, testCollectionName, \"2\");\n      } finally {\n        newLeaderSolr.shutdown();\n      }\n\n    } catch (SolrException exc) {\n      // this is ok provided the doc doesn't exist on the current leader\n      leaderSolr = getHttpSolrServer(currentLeader, testCollectionName);\n      try {\n        leaderSolr.add(doc); // this should work\n      } finally {\n        leaderSolr.shutdown();\n      }\n    }\n\n    List<Replica> participatingReplicas = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    Set<String> replicasToCheck = new HashSet<>();\n    for (Replica stillUp : participatingReplicas)\n      replicasToCheck.add(stillUp.getName());\n    waitToSeeReplicasActive(testCollectionName, \"shard1\", replicasToCheck, 20);\n    assertDocsExistInAllReplicas(participatingReplicas, testCollectionName, 1, 2);\n\n    // try to clean up\n    try {\n      CollectionAdminRequest req = new CollectionAdminRequest.Delete();\n      req.setCollectionName(testCollectionName);\n      req.process(cloudClient);\n    } catch (Exception e) {\n      // don't fail the test\n      log.warn(\"Could not delete collection {} after test completed\", testCollectionName);\n    }\n  }\n\n","sourceOld":"  // test inspired by SOLR-6511\n  protected void testLeaderZkSessionLoss() throws Exception {\n\n    String testCollectionName = \"c8n_1x2_leader_session_loss\";\n    createCollection(testCollectionName, 1, 2, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    sendDoc(1);\n\n    List<Replica> notLeaders =\n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 2, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 1 replicas for collection \" + testCollectionName\n            + \" but found \" + notLeaders.size() + \"; clusterState: \"\n            + printClusterStateInfo(testCollectionName),\n        notLeaders.size() == 1);\n\n    Replica leader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n        testCollectionName+\"; clusterState: \"+printClusterStateInfo(testCollectionName), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n\n    HttpSolrServer leaderSolr = getHttpSolrServer(leader, testCollectionName);\n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(id, String.valueOf(2));\n    doc.addField(\"a_t\", \"hello\" + 2);\n\n    // cause leader migration by expiring the current leader's zk session\n    chaosMonkey.expireSession(leaderJetty);\n\n    String expectedNewLeaderCoreNodeName = notLeaders.get(0).getName();\n    long timeout = System.nanoTime() + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    while (System.nanoTime() < timeout) {\n      String currentLeaderName = null;\n      try {\n        Replica currentLeader =\n            cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n        currentLeaderName = currentLeader.getName();\n      } catch (Exception exc) {}\n\n      if (expectedNewLeaderCoreNodeName.equals(currentLeaderName))\n        break; // new leader was elected after zk session expiration\n\n      Thread.sleep(500);\n    }\n\n    Replica currentLeader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    assertEquals(expectedNewLeaderCoreNodeName, currentLeader.getName());\n\n    log.info(\"Sending doc 2 to old leader \"+leader.getName());\n    try {\n      leaderSolr.add(doc);\n      leaderSolr.shutdown();\n\n      Replica oldLeaderInRecovery = null;\n      for (Replica next : getActiveOrRecoveringReplicas(testCollectionName, \"shard1\")) {\n        if (next.getName().equals(leader.getName()) &&\n            ZkStateReader.RECOVERING.equals(next.getStr(ZkStateReader.STATE_PROP)))\n        {\n          oldLeaderInRecovery = next;\n          break;\n        }\n      }\n\n      // if the old leader is not active or recovering, the add should have failed\n      if (oldLeaderInRecovery != null) {\n        HttpSolrServer oldLeaderSolr = getHttpSolrServer(oldLeaderInRecovery, testCollectionName);\n        try {\n          assertDocExists(oldLeaderSolr, testCollectionName, \"2\");\n        } finally {\n          oldLeaderSolr.shutdown();\n        }\n      } else {\n        fail(\"Send doc 2 to old leader \" + leader.getName() +\n            \" should have failed! ClusterState: \" + printClusterStateInfo(testCollectionName));\n      }\n\n    } catch (SolrException exc) {\n      // this is expected ..\n      leaderSolr = getHttpSolrServer(currentLeader, testCollectionName);\n      try {\n        leaderSolr.add(doc); // this should work\n      } finally {\n        leaderSolr.shutdown();\n      }\n    }\n\n    List<Replica> participatingReplicas = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    Set<String> replicasToCheck = new HashSet<>();\n    for (Replica stillUp : participatingReplicas)\n      replicasToCheck.add(stillUp.getName());\n    waitToSeeReplicasActive(testCollectionName, \"shard1\", replicasToCheck, 20);\n    assertDocsExistInAllReplicas(participatingReplicas, testCollectionName, 1, 2);\n\n    // try to clean up\n    try {\n      CollectionAdminRequest req = new CollectionAdminRequest.Delete();\n      req.setCollectionName(testCollectionName);\n      req.process(cloudClient);\n    } catch (Exception e) {\n      // don't fail the test\n      log.warn(\"Could not delete collection {} after test completed\", testCollectionName);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2d14328dee83c3ec0478e7d711f7af48560ad5ef","date":1412617800,"type":3,"author":"Timothy Potter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testLeaderZkSessionLoss().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testLeaderZkSessionLoss().mjava","sourceNew":"  // test inspired by SOLR-6511\n  protected void testLeaderZkSessionLoss() throws Exception {\n\n    String testCollectionName = \"c8n_1x2_leader_session_loss\";\n    createCollection(testCollectionName, 1, 2, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    sendDoc(1);\n\n    List<Replica> notLeaders =\n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 2, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 1 replicas for collection \" + testCollectionName\n            + \" but found \" + notLeaders.size() + \"; clusterState: \"\n            + printClusterStateInfo(testCollectionName),\n        notLeaders.size() == 1);\n\n    Replica leader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n        testCollectionName+\"; clusterState: \"+printClusterStateInfo(testCollectionName), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n\n    HttpSolrServer leaderSolr = getHttpSolrServer(leader, testCollectionName);\n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(id, String.valueOf(2));\n    doc.addField(\"a_t\", \"hello\" + 2);\n\n    // cause leader migration by expiring the current leader's zk session\n    chaosMonkey.expireSession(leaderJetty);\n\n    String expectedNewLeaderCoreNodeName = notLeaders.get(0).getName();\n    long timeout = System.nanoTime() + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    while (System.nanoTime() < timeout) {\n      String currentLeaderName = null;\n      try {\n        Replica currentLeader =\n            cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n        currentLeaderName = currentLeader.getName();\n      } catch (Exception exc) {}\n\n      if (expectedNewLeaderCoreNodeName.equals(currentLeaderName))\n        break; // new leader was elected after zk session expiration\n\n      Thread.sleep(500);\n    }\n\n    Replica currentLeader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    assertEquals(expectedNewLeaderCoreNodeName, currentLeader.getName());\n\n    // TODO: This test logic seems to be timing dependent and fails on Jenkins\n    // need to come up with a better approach\n    log.info(\"Sending doc 2 to old leader \"+leader.getName());\n    try {\n      leaderSolr.add(doc);\n      leaderSolr.shutdown();\n\n      // if the add worked, then the doc must exist on the new leader\n      HttpSolrServer newLeaderSolr = getHttpSolrServer(currentLeader, testCollectionName);\n      try {\n        assertDocExists(newLeaderSolr, testCollectionName, \"2\");\n      } finally {\n        newLeaderSolr.shutdown();\n      }\n\n    } catch (SolrException exc) {\n      // this is ok provided the doc doesn't exist on the current leader\n      leaderSolr = getHttpSolrServer(currentLeader, testCollectionName);\n      try {\n        leaderSolr.add(doc); // this should work\n      } finally {\n        leaderSolr.shutdown();\n      }\n    }\n\n    List<Replica> participatingReplicas = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    Set<String> replicasToCheck = new HashSet<>();\n    for (Replica stillUp : participatingReplicas)\n      replicasToCheck.add(stillUp.getName());\n    waitToSeeReplicasActive(testCollectionName, \"shard1\", replicasToCheck, 20);\n    assertDocsExistInAllReplicas(participatingReplicas, testCollectionName, 1, 2);\n\n    log.info(\"testLeaderZkSessionLoss succeeded ... deleting the \"+testCollectionName+\" collection\");\n\n    // try to clean up\n    try {\n      CollectionAdminRequest req = new CollectionAdminRequest.Delete();\n      req.setCollectionName(testCollectionName);\n      req.process(cloudClient);\n    } catch (Exception e) {\n      // don't fail the test\n      log.warn(\"Could not delete collection {} after test completed\", testCollectionName);\n    }\n  }\n\n","sourceOld":"  // test inspired by SOLR-6511\n  protected void testLeaderZkSessionLoss() throws Exception {\n\n    String testCollectionName = \"c8n_1x2_leader_session_loss\";\n    createCollection(testCollectionName, 1, 2, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    sendDoc(1);\n\n    List<Replica> notLeaders =\n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 2, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 1 replicas for collection \" + testCollectionName\n            + \" but found \" + notLeaders.size() + \"; clusterState: \"\n            + printClusterStateInfo(testCollectionName),\n        notLeaders.size() == 1);\n\n    Replica leader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n        testCollectionName+\"; clusterState: \"+printClusterStateInfo(testCollectionName), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n\n    HttpSolrServer leaderSolr = getHttpSolrServer(leader, testCollectionName);\n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(id, String.valueOf(2));\n    doc.addField(\"a_t\", \"hello\" + 2);\n\n    // cause leader migration by expiring the current leader's zk session\n    chaosMonkey.expireSession(leaderJetty);\n\n    String expectedNewLeaderCoreNodeName = notLeaders.get(0).getName();\n    long timeout = System.nanoTime() + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    while (System.nanoTime() < timeout) {\n      String currentLeaderName = null;\n      try {\n        Replica currentLeader =\n            cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n        currentLeaderName = currentLeader.getName();\n      } catch (Exception exc) {}\n\n      if (expectedNewLeaderCoreNodeName.equals(currentLeaderName))\n        break; // new leader was elected after zk session expiration\n\n      Thread.sleep(500);\n    }\n\n    Replica currentLeader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    assertEquals(expectedNewLeaderCoreNodeName, currentLeader.getName());\n\n    // TODO: This test logic seems to be timing dependent and fails on Jenkins\n    // need to come up with a better approach\n    log.info(\"Sending doc 2 to old leader \"+leader.getName());\n    try {\n      leaderSolr.add(doc);\n      leaderSolr.shutdown();\n\n      // if the add worked, then the doc must exist on the new leader\n      HttpSolrServer newLeaderSolr = getHttpSolrServer(currentLeader, testCollectionName);\n      try {\n        assertDocExists(newLeaderSolr, testCollectionName, \"2\");\n      } finally {\n        newLeaderSolr.shutdown();\n      }\n\n    } catch (SolrException exc) {\n      // this is ok provided the doc doesn't exist on the current leader\n      leaderSolr = getHttpSolrServer(currentLeader, testCollectionName);\n      try {\n        leaderSolr.add(doc); // this should work\n      } finally {\n        leaderSolr.shutdown();\n      }\n    }\n\n    List<Replica> participatingReplicas = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    Set<String> replicasToCheck = new HashSet<>();\n    for (Replica stillUp : participatingReplicas)\n      replicasToCheck.add(stillUp.getName());\n    waitToSeeReplicasActive(testCollectionName, \"shard1\", replicasToCheck, 20);\n    assertDocsExistInAllReplicas(participatingReplicas, testCollectionName, 1, 2);\n\n    // try to clean up\n    try {\n      CollectionAdminRequest req = new CollectionAdminRequest.Delete();\n      req.setCollectionName(testCollectionName);\n      req.process(cloudClient);\n    } catch (Exception e) {\n      // don't fail the test\n      log.warn(\"Could not delete collection {} after test completed\", testCollectionName);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"55980207f1977bd1463465de1659b821347e2fa8","date":1413336386,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testLeaderZkSessionLoss().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testLeaderZkSessionLoss().mjava","sourceNew":"  // test inspired by SOLR-6511\n  protected void testLeaderZkSessionLoss() throws Exception {\n\n    String testCollectionName = \"c8n_1x2_leader_session_loss\";\n    createCollection(testCollectionName, 1, 2, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    sendDoc(1);\n\n    List<Replica> notLeaders =\n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 2, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 1 replicas for collection \" + testCollectionName\n            + \" but found \" + notLeaders.size() + \"; clusterState: \"\n            + printClusterStateInfo(testCollectionName),\n        notLeaders.size() == 1);\n\n    Replica leader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n        testCollectionName+\"; clusterState: \"+printClusterStateInfo(testCollectionName), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n\n    HttpSolrServer leaderSolr = getHttpSolrServer(leader, testCollectionName);\n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(id, String.valueOf(2));\n    doc.addField(\"a_t\", \"hello\" + 2);\n\n    // cause leader migration by expiring the current leader's zk session\n    chaosMonkey.expireSession(leaderJetty);\n\n    String expectedNewLeaderCoreNodeName = notLeaders.get(0).getName();\n    long timeout = System.nanoTime() + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    while (System.nanoTime() < timeout) {\n      String currentLeaderName = null;\n      try {\n        Replica currentLeader =\n            cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n        currentLeaderName = currentLeader.getName();\n      } catch (Exception exc) {}\n\n      if (expectedNewLeaderCoreNodeName.equals(currentLeaderName))\n        break; // new leader was elected after zk session expiration\n\n      Thread.sleep(500);\n    }\n\n    Replica currentLeader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    assertEquals(expectedNewLeaderCoreNodeName, currentLeader.getName());\n\n    // TODO: This test logic seems to be timing dependent and fails on Jenkins\n    // need to come up with a better approach\n    log.info(\"Sending doc 2 to old leader \"+leader.getName());\n    try {\n      leaderSolr.add(doc);\n      leaderSolr.shutdown();\n\n      // if the add worked, then the doc must exist on the new leader\n      HttpSolrServer newLeaderSolr = getHttpSolrServer(currentLeader, testCollectionName);\n      try {\n        assertDocExists(newLeaderSolr, testCollectionName, \"2\");\n      } finally {\n        newLeaderSolr.shutdown();\n      }\n\n    } catch (SolrException exc) {\n      // this is ok provided the doc doesn't exist on the current leader\n      leaderSolr = getHttpSolrServer(currentLeader, testCollectionName);\n      try {\n        leaderSolr.add(doc); // this should work\n      } finally {\n        leaderSolr.shutdown();\n      }\n    }\n\n    List<Replica> participatingReplicas = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    Set<String> replicasToCheck = new HashSet<>();\n    for (Replica stillUp : participatingReplicas)\n      replicasToCheck.add(stillUp.getName());\n    waitToSeeReplicasActive(testCollectionName, \"shard1\", replicasToCheck, 20);\n    assertDocsExistInAllReplicas(participatingReplicas, testCollectionName, 1, 2);\n\n    log.info(\"testLeaderZkSessionLoss succeeded ... deleting the \"+testCollectionName+\" collection\");\n\n    // try to clean up\n    try {\n      CollectionAdminRequest req = new CollectionAdminRequest.Delete();\n      req.setCollectionName(testCollectionName);\n      req.process(cloudClient);\n    } catch (Exception e) {\n      // don't fail the test\n      log.warn(\"Could not delete collection {} after test completed\", testCollectionName);\n    }\n  }\n\n","sourceOld":"  // test inspired by SOLR-6511\n  protected void testLeaderZkSessionLoss() throws Exception {\n\n    String testCollectionName = \"c8n_1x2_leader_session_loss\";\n    createCollection(testCollectionName, 1, 2, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    sendDoc(1);\n\n    List<Replica> notLeaders =\n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 2, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 1 replicas for collection \" + testCollectionName\n            + \" but found \" + notLeaders.size() + \"; clusterState: \"\n            + printClusterStateInfo(testCollectionName),\n        notLeaders.size() == 1);\n\n    Replica leader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n        testCollectionName+\"; clusterState: \"+printClusterStateInfo(testCollectionName), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n\n    HttpSolrServer leaderSolr = getHttpSolrServer(leader, testCollectionName);\n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(id, String.valueOf(2));\n    doc.addField(\"a_t\", \"hello\" + 2);\n\n    // cause leader migration by expiring the current leader's zk session\n    chaosMonkey.expireSession(leaderJetty);\n\n    String expectedNewLeaderCoreNodeName = notLeaders.get(0).getName();\n    long timeout = System.nanoTime() + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    while (System.nanoTime() < timeout) {\n      String currentLeaderName = null;\n      try {\n        Replica currentLeader =\n            cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n        currentLeaderName = currentLeader.getName();\n      } catch (Exception exc) {}\n\n      if (expectedNewLeaderCoreNodeName.equals(currentLeaderName))\n        break; // new leader was elected after zk session expiration\n\n      Thread.sleep(500);\n    }\n\n    Replica currentLeader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    assertEquals(expectedNewLeaderCoreNodeName, currentLeader.getName());\n\n    // TODO: This test logic seems to be timing dependent and fails on Jenkins\n    // need to come up with a better approach\n    log.info(\"Sending doc 2 to old leader \"+leader.getName());\n    try {\n      leaderSolr.add(doc);\n      leaderSolr.shutdown();\n\n      // if the add worked, then the doc must exist on the new leader\n      HttpSolrServer newLeaderSolr = getHttpSolrServer(currentLeader, testCollectionName);\n      try {\n        assertDocExists(newLeaderSolr, testCollectionName, \"2\");\n      } finally {\n        newLeaderSolr.shutdown();\n      }\n\n    } catch (SolrException exc) {\n      // this is ok provided the doc doesn't exist on the current leader\n      leaderSolr = getHttpSolrServer(currentLeader, testCollectionName);\n      try {\n        leaderSolr.add(doc); // this should work\n      } finally {\n        leaderSolr.shutdown();\n      }\n    }\n\n    List<Replica> participatingReplicas = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    Set<String> replicasToCheck = new HashSet<>();\n    for (Replica stillUp : participatingReplicas)\n      replicasToCheck.add(stillUp.getName());\n    waitToSeeReplicasActive(testCollectionName, \"shard1\", replicasToCheck, 20);\n    assertDocsExistInAllReplicas(participatingReplicas, testCollectionName, 1, 2);\n\n    // try to clean up\n    try {\n      CollectionAdminRequest req = new CollectionAdminRequest.Delete();\n      req.setCollectionName(testCollectionName);\n      req.process(cloudClient);\n    } catch (Exception e) {\n      // don't fail the test\n      log.warn(\"Could not delete collection {} after test completed\", testCollectionName);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ec3dbdc850ca18bf4aef9acb85f2ea0554306d","date":1419896224,"type":3,"author":"Anshum Gupta","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testLeaderZkSessionLoss().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testLeaderZkSessionLoss().mjava","sourceNew":"  // test inspired by SOLR-6511\n  protected void testLeaderZkSessionLoss() throws Exception {\n\n    String testCollectionName = \"c8n_1x2_leader_session_loss\";\n    createCollection(testCollectionName, 1, 2, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    sendDoc(1);\n\n    List<Replica> notLeaders =\n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 2, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 1 replicas for collection \" + testCollectionName\n            + \" but found \" + notLeaders.size() + \"; clusterState: \"\n            + printClusterStateInfo(testCollectionName),\n        notLeaders.size() == 1);\n\n    Replica leader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n        testCollectionName+\"; clusterState: \"+printClusterStateInfo(testCollectionName), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n\n    HttpSolrServer leaderSolr = getHttpSolrServer(leader, testCollectionName);\n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(id, String.valueOf(2));\n    doc.addField(\"a_t\", \"hello\" + 2);\n\n    // cause leader migration by expiring the current leader's zk session\n    chaosMonkey.expireSession(leaderJetty);\n\n    String expectedNewLeaderCoreNodeName = notLeaders.get(0).getName();\n    long timeout = System.nanoTime() + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    while (System.nanoTime() < timeout) {\n      String currentLeaderName = null;\n      try {\n        Replica currentLeader =\n            cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n        currentLeaderName = currentLeader.getName();\n      } catch (Exception exc) {}\n\n      if (expectedNewLeaderCoreNodeName.equals(currentLeaderName))\n        break; // new leader was elected after zk session expiration\n\n      Thread.sleep(500);\n    }\n\n    Replica currentLeader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    assertEquals(expectedNewLeaderCoreNodeName, currentLeader.getName());\n\n    // TODO: This test logic seems to be timing dependent and fails on Jenkins\n    // need to come up with a better approach\n    log.info(\"Sending doc 2 to old leader \"+leader.getName());\n    try {\n      leaderSolr.add(doc);\n      leaderSolr.shutdown();\n\n      // if the add worked, then the doc must exist on the new leader\n      HttpSolrServer newLeaderSolr = getHttpSolrServer(currentLeader, testCollectionName);\n      try {\n        assertDocExists(newLeaderSolr, testCollectionName, \"2\");\n      } finally {\n        newLeaderSolr.shutdown();\n      }\n\n    } catch (SolrException exc) {\n      // this is ok provided the doc doesn't exist on the current leader\n      leaderSolr = getHttpSolrServer(currentLeader, testCollectionName);\n      try {\n        leaderSolr.add(doc); // this should work\n      } finally {\n        leaderSolr.shutdown();\n      }\n    }\n\n    List<Replica> participatingReplicas = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    Set<String> replicasToCheck = new HashSet<>();\n    for (Replica stillUp : participatingReplicas)\n      replicasToCheck.add(stillUp.getName());\n    waitToSeeReplicasActive(testCollectionName, \"shard1\", replicasToCheck, 20);\n    assertDocsExistInAllReplicas(participatingReplicas, testCollectionName, 1, 2);\n\n    log.info(\"testLeaderZkSessionLoss succeeded ... deleting the \"+testCollectionName+\" collection\");\n\n    // try to clean up\n    try {\n      CollectionAdminRequest.Delete req = new CollectionAdminRequest.Delete();\n      req.setCollectionName(testCollectionName);\n      req.process(cloudClient);\n    } catch (Exception e) {\n      // don't fail the test\n      log.warn(\"Could not delete collection {} after test completed\", testCollectionName);\n    }\n  }\n\n","sourceOld":"  // test inspired by SOLR-6511\n  protected void testLeaderZkSessionLoss() throws Exception {\n\n    String testCollectionName = \"c8n_1x2_leader_session_loss\";\n    createCollection(testCollectionName, 1, 2, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    sendDoc(1);\n\n    List<Replica> notLeaders =\n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 2, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 1 replicas for collection \" + testCollectionName\n            + \" but found \" + notLeaders.size() + \"; clusterState: \"\n            + printClusterStateInfo(testCollectionName),\n        notLeaders.size() == 1);\n\n    Replica leader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n        testCollectionName+\"; clusterState: \"+printClusterStateInfo(testCollectionName), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n\n    HttpSolrServer leaderSolr = getHttpSolrServer(leader, testCollectionName);\n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(id, String.valueOf(2));\n    doc.addField(\"a_t\", \"hello\" + 2);\n\n    // cause leader migration by expiring the current leader's zk session\n    chaosMonkey.expireSession(leaderJetty);\n\n    String expectedNewLeaderCoreNodeName = notLeaders.get(0).getName();\n    long timeout = System.nanoTime() + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    while (System.nanoTime() < timeout) {\n      String currentLeaderName = null;\n      try {\n        Replica currentLeader =\n            cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n        currentLeaderName = currentLeader.getName();\n      } catch (Exception exc) {}\n\n      if (expectedNewLeaderCoreNodeName.equals(currentLeaderName))\n        break; // new leader was elected after zk session expiration\n\n      Thread.sleep(500);\n    }\n\n    Replica currentLeader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    assertEquals(expectedNewLeaderCoreNodeName, currentLeader.getName());\n\n    // TODO: This test logic seems to be timing dependent and fails on Jenkins\n    // need to come up with a better approach\n    log.info(\"Sending doc 2 to old leader \"+leader.getName());\n    try {\n      leaderSolr.add(doc);\n      leaderSolr.shutdown();\n\n      // if the add worked, then the doc must exist on the new leader\n      HttpSolrServer newLeaderSolr = getHttpSolrServer(currentLeader, testCollectionName);\n      try {\n        assertDocExists(newLeaderSolr, testCollectionName, \"2\");\n      } finally {\n        newLeaderSolr.shutdown();\n      }\n\n    } catch (SolrException exc) {\n      // this is ok provided the doc doesn't exist on the current leader\n      leaderSolr = getHttpSolrServer(currentLeader, testCollectionName);\n      try {\n        leaderSolr.add(doc); // this should work\n      } finally {\n        leaderSolr.shutdown();\n      }\n    }\n\n    List<Replica> participatingReplicas = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    Set<String> replicasToCheck = new HashSet<>();\n    for (Replica stillUp : participatingReplicas)\n      replicasToCheck.add(stillUp.getName());\n    waitToSeeReplicasActive(testCollectionName, \"shard1\", replicasToCheck, 20);\n    assertDocsExistInAllReplicas(participatingReplicas, testCollectionName, 1, 2);\n\n    log.info(\"testLeaderZkSessionLoss succeeded ... deleting the \"+testCollectionName+\" collection\");\n\n    // try to clean up\n    try {\n      CollectionAdminRequest req = new CollectionAdminRequest.Delete();\n      req.setCollectionName(testCollectionName);\n      req.process(cloudClient);\n    } catch (Exception e) {\n      // don't fail the test\n      log.warn(\"Could not delete collection {} after test completed\", testCollectionName);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bafca15d8e408346a67f4282ad1143b88023893b","date":1420034748,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testLeaderZkSessionLoss().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testLeaderZkSessionLoss().mjava","sourceNew":"  // test inspired by SOLR-6511\n  protected void testLeaderZkSessionLoss() throws Exception {\n\n    String testCollectionName = \"c8n_1x2_leader_session_loss\";\n    createCollection(testCollectionName, 1, 2, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    sendDoc(1);\n\n    List<Replica> notLeaders =\n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 2, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 1 replicas for collection \" + testCollectionName\n            + \" but found \" + notLeaders.size() + \"; clusterState: \"\n            + printClusterStateInfo(testCollectionName),\n        notLeaders.size() == 1);\n\n    Replica leader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n        testCollectionName+\"; clusterState: \"+printClusterStateInfo(testCollectionName), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n\n    HttpSolrClient leaderSolr = getHttpSolrClient(leader, testCollectionName);\n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(id, String.valueOf(2));\n    doc.addField(\"a_t\", \"hello\" + 2);\n\n    // cause leader migration by expiring the current leader's zk session\n    chaosMonkey.expireSession(leaderJetty);\n\n    String expectedNewLeaderCoreNodeName = notLeaders.get(0).getName();\n    long timeout = System.nanoTime() + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    while (System.nanoTime() < timeout) {\n      String currentLeaderName = null;\n      try {\n        Replica currentLeader =\n            cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n        currentLeaderName = currentLeader.getName();\n      } catch (Exception exc) {}\n\n      if (expectedNewLeaderCoreNodeName.equals(currentLeaderName))\n        break; // new leader was elected after zk session expiration\n\n      Thread.sleep(500);\n    }\n\n    Replica currentLeader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    assertEquals(expectedNewLeaderCoreNodeName, currentLeader.getName());\n\n    // TODO: This test logic seems to be timing dependent and fails on Jenkins\n    // need to come up with a better approach\n    log.info(\"Sending doc 2 to old leader \"+leader.getName());\n    try {\n      leaderSolr.add(doc);\n      leaderSolr.shutdown();\n\n      // if the add worked, then the doc must exist on the new leader\n      HttpSolrClient newLeaderSolr = getHttpSolrClient(currentLeader, testCollectionName);\n      try {\n        assertDocExists(newLeaderSolr, testCollectionName, \"2\");\n      } finally {\n        newLeaderSolr.shutdown();\n      }\n\n    } catch (SolrException exc) {\n      // this is ok provided the doc doesn't exist on the current leader\n      leaderSolr = getHttpSolrClient(currentLeader, testCollectionName);\n      try {\n        leaderSolr.add(doc); // this should work\n      } finally {\n        leaderSolr.shutdown();\n      }\n    }\n\n    List<Replica> participatingReplicas = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    Set<String> replicasToCheck = new HashSet<>();\n    for (Replica stillUp : participatingReplicas)\n      replicasToCheck.add(stillUp.getName());\n    waitToSeeReplicasActive(testCollectionName, \"shard1\", replicasToCheck, 20);\n    assertDocsExistInAllReplicas(participatingReplicas, testCollectionName, 1, 2);\n\n    log.info(\"testLeaderZkSessionLoss succeeded ... deleting the \"+testCollectionName+\" collection\");\n\n    // try to clean up\n    try {\n      CollectionAdminRequest.Delete req = new CollectionAdminRequest.Delete();\n      req.setCollectionName(testCollectionName);\n      req.process(cloudClient);\n    } catch (Exception e) {\n      // don't fail the test\n      log.warn(\"Could not delete collection {} after test completed\", testCollectionName);\n    }\n  }\n\n","sourceOld":"  // test inspired by SOLR-6511\n  protected void testLeaderZkSessionLoss() throws Exception {\n\n    String testCollectionName = \"c8n_1x2_leader_session_loss\";\n    createCollection(testCollectionName, 1, 2, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    sendDoc(1);\n\n    List<Replica> notLeaders =\n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 2, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 1 replicas for collection \" + testCollectionName\n            + \" but found \" + notLeaders.size() + \"; clusterState: \"\n            + printClusterStateInfo(testCollectionName),\n        notLeaders.size() == 1);\n\n    Replica leader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n        testCollectionName+\"; clusterState: \"+printClusterStateInfo(testCollectionName), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n\n    HttpSolrServer leaderSolr = getHttpSolrServer(leader, testCollectionName);\n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(id, String.valueOf(2));\n    doc.addField(\"a_t\", \"hello\" + 2);\n\n    // cause leader migration by expiring the current leader's zk session\n    chaosMonkey.expireSession(leaderJetty);\n\n    String expectedNewLeaderCoreNodeName = notLeaders.get(0).getName();\n    long timeout = System.nanoTime() + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    while (System.nanoTime() < timeout) {\n      String currentLeaderName = null;\n      try {\n        Replica currentLeader =\n            cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n        currentLeaderName = currentLeader.getName();\n      } catch (Exception exc) {}\n\n      if (expectedNewLeaderCoreNodeName.equals(currentLeaderName))\n        break; // new leader was elected after zk session expiration\n\n      Thread.sleep(500);\n    }\n\n    Replica currentLeader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    assertEquals(expectedNewLeaderCoreNodeName, currentLeader.getName());\n\n    // TODO: This test logic seems to be timing dependent and fails on Jenkins\n    // need to come up with a better approach\n    log.info(\"Sending doc 2 to old leader \"+leader.getName());\n    try {\n      leaderSolr.add(doc);\n      leaderSolr.shutdown();\n\n      // if the add worked, then the doc must exist on the new leader\n      HttpSolrServer newLeaderSolr = getHttpSolrServer(currentLeader, testCollectionName);\n      try {\n        assertDocExists(newLeaderSolr, testCollectionName, \"2\");\n      } finally {\n        newLeaderSolr.shutdown();\n      }\n\n    } catch (SolrException exc) {\n      // this is ok provided the doc doesn't exist on the current leader\n      leaderSolr = getHttpSolrServer(currentLeader, testCollectionName);\n      try {\n        leaderSolr.add(doc); // this should work\n      } finally {\n        leaderSolr.shutdown();\n      }\n    }\n\n    List<Replica> participatingReplicas = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    Set<String> replicasToCheck = new HashSet<>();\n    for (Replica stillUp : participatingReplicas)\n      replicasToCheck.add(stillUp.getName());\n    waitToSeeReplicasActive(testCollectionName, \"shard1\", replicasToCheck, 20);\n    assertDocsExistInAllReplicas(participatingReplicas, testCollectionName, 1, 2);\n\n    log.info(\"testLeaderZkSessionLoss succeeded ... deleting the \"+testCollectionName+\" collection\");\n\n    // try to clean up\n    try {\n      CollectionAdminRequest.Delete req = new CollectionAdminRequest.Delete();\n      req.setCollectionName(testCollectionName);\n      req.process(cloudClient);\n    } catch (Exception e) {\n      // don't fail the test\n      log.warn(\"Could not delete collection {} after test completed\", testCollectionName);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"cc3b13b430571c2e169f98fe38e1e7666f88522d","date":1422446157,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testLeaderZkSessionLoss().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testLeaderZkSessionLoss().mjava","sourceNew":"  // test inspired by SOLR-6511\n  protected void testLeaderZkSessionLoss() throws Exception {\n\n    String testCollectionName = \"c8n_1x2_leader_session_loss\";\n    createCollection(testCollectionName, 1, 2, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    sendDoc(1);\n\n    List<Replica> notLeaders =\n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 2, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 1 replicas for collection \" + testCollectionName\n            + \" but found \" + notLeaders.size() + \"; clusterState: \"\n            + printClusterStateInfo(testCollectionName),\n        notLeaders.size() == 1);\n\n    Replica leader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n        testCollectionName+\"; clusterState: \"+printClusterStateInfo(testCollectionName), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n\n    HttpSolrClient leaderSolr = getHttpSolrClient(leader, testCollectionName);\n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(id, String.valueOf(2));\n    doc.addField(\"a_t\", \"hello\" + 2);\n\n    // cause leader migration by expiring the current leader's zk session\n    chaosMonkey.expireSession(leaderJetty);\n\n    String expectedNewLeaderCoreNodeName = notLeaders.get(0).getName();\n    long timeout = System.nanoTime() + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    while (System.nanoTime() < timeout) {\n      String currentLeaderName = null;\n      try {\n        Replica currentLeader =\n            cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n        currentLeaderName = currentLeader.getName();\n      } catch (Exception exc) {}\n\n      if (expectedNewLeaderCoreNodeName.equals(currentLeaderName))\n        break; // new leader was elected after zk session expiration\n\n      Thread.sleep(500);\n    }\n\n    Replica currentLeader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    assertEquals(expectedNewLeaderCoreNodeName, currentLeader.getName());\n\n    // TODO: This test logic seems to be timing dependent and fails on Jenkins\n    // need to come up with a better approach\n    log.info(\"Sending doc 2 to old leader \"+leader.getName());\n    try {\n      leaderSolr.add(doc);\n      leaderSolr.close();\n\n      // if the add worked, then the doc must exist on the new leader\n      try (HttpSolrClient newLeaderSolr = getHttpSolrClient(currentLeader, testCollectionName)) {\n        assertDocExists(newLeaderSolr, testCollectionName, \"2\");\n      }\n\n    } catch (SolrException exc) {\n      // this is ok provided the doc doesn't exist on the current leader\n      try (HttpSolrClient client = getHttpSolrClient(currentLeader, testCollectionName)) {\n        client.add(doc); // this should work\n      }\n    }\n\n    List<Replica> participatingReplicas = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    Set<String> replicasToCheck = new HashSet<>();\n    for (Replica stillUp : participatingReplicas)\n      replicasToCheck.add(stillUp.getName());\n    waitToSeeReplicasActive(testCollectionName, \"shard1\", replicasToCheck, 20);\n    assertDocsExistInAllReplicas(participatingReplicas, testCollectionName, 1, 2);\n\n    log.info(\"testLeaderZkSessionLoss succeeded ... deleting the \"+testCollectionName+\" collection\");\n\n    // try to clean up\n    try {\n      CollectionAdminRequest.Delete req = new CollectionAdminRequest.Delete();\n      req.setCollectionName(testCollectionName);\n      req.process(cloudClient);\n    } catch (Exception e) {\n      // don't fail the test\n      log.warn(\"Could not delete collection {} after test completed\", testCollectionName);\n    }\n  }\n\n","sourceOld":"  // test inspired by SOLR-6511\n  protected void testLeaderZkSessionLoss() throws Exception {\n\n    String testCollectionName = \"c8n_1x2_leader_session_loss\";\n    createCollection(testCollectionName, 1, 2, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    sendDoc(1);\n\n    List<Replica> notLeaders =\n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 2, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 1 replicas for collection \" + testCollectionName\n            + \" but found \" + notLeaders.size() + \"; clusterState: \"\n            + printClusterStateInfo(testCollectionName),\n        notLeaders.size() == 1);\n\n    Replica leader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n        testCollectionName+\"; clusterState: \"+printClusterStateInfo(testCollectionName), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n\n    HttpSolrClient leaderSolr = getHttpSolrClient(leader, testCollectionName);\n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(id, String.valueOf(2));\n    doc.addField(\"a_t\", \"hello\" + 2);\n\n    // cause leader migration by expiring the current leader's zk session\n    chaosMonkey.expireSession(leaderJetty);\n\n    String expectedNewLeaderCoreNodeName = notLeaders.get(0).getName();\n    long timeout = System.nanoTime() + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    while (System.nanoTime() < timeout) {\n      String currentLeaderName = null;\n      try {\n        Replica currentLeader =\n            cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n        currentLeaderName = currentLeader.getName();\n      } catch (Exception exc) {}\n\n      if (expectedNewLeaderCoreNodeName.equals(currentLeaderName))\n        break; // new leader was elected after zk session expiration\n\n      Thread.sleep(500);\n    }\n\n    Replica currentLeader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    assertEquals(expectedNewLeaderCoreNodeName, currentLeader.getName());\n\n    // TODO: This test logic seems to be timing dependent and fails on Jenkins\n    // need to come up with a better approach\n    log.info(\"Sending doc 2 to old leader \"+leader.getName());\n    try {\n      leaderSolr.add(doc);\n      leaderSolr.shutdown();\n\n      // if the add worked, then the doc must exist on the new leader\n      HttpSolrClient newLeaderSolr = getHttpSolrClient(currentLeader, testCollectionName);\n      try {\n        assertDocExists(newLeaderSolr, testCollectionName, \"2\");\n      } finally {\n        newLeaderSolr.shutdown();\n      }\n\n    } catch (SolrException exc) {\n      // this is ok provided the doc doesn't exist on the current leader\n      leaderSolr = getHttpSolrClient(currentLeader, testCollectionName);\n      try {\n        leaderSolr.add(doc); // this should work\n      } finally {\n        leaderSolr.shutdown();\n      }\n    }\n\n    List<Replica> participatingReplicas = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    Set<String> replicasToCheck = new HashSet<>();\n    for (Replica stillUp : participatingReplicas)\n      replicasToCheck.add(stillUp.getName());\n    waitToSeeReplicasActive(testCollectionName, \"shard1\", replicasToCheck, 20);\n    assertDocsExistInAllReplicas(participatingReplicas, testCollectionName, 1, 2);\n\n    log.info(\"testLeaderZkSessionLoss succeeded ... deleting the \"+testCollectionName+\" collection\");\n\n    // try to clean up\n    try {\n      CollectionAdminRequest.Delete req = new CollectionAdminRequest.Delete();\n      req.setCollectionName(testCollectionName);\n      req.process(cloudClient);\n    } catch (Exception e) {\n      // don't fail the test\n      log.warn(\"Could not delete collection {} after test completed\", testCollectionName);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"37e7502644cd23597431d66e301299b1ead2fb9b","date":1422636984,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testLeaderZkSessionLoss().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testLeaderZkSessionLoss().mjava","sourceNew":"  // test inspired by SOLR-6511\n  protected void testLeaderZkSessionLoss() throws Exception {\n\n    String testCollectionName = \"c8n_1x2_leader_session_loss\";\n    createCollectionRetry(testCollectionName, 1, 2, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    sendDoc(1);\n\n    List<Replica> notLeaders =\n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 2, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 1 replicas for collection \" + testCollectionName\n            + \" but found \" + notLeaders.size() + \"; clusterState: \"\n            + printClusterStateInfo(testCollectionName),\n        notLeaders.size() == 1);\n\n    Replica leader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n        testCollectionName+\"; clusterState: \"+printClusterStateInfo(testCollectionName), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n\n\n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(id, String.valueOf(2));\n    doc.addField(\"a_t\", \"hello\" + 2);\n\n    // cause leader migration by expiring the current leader's zk session\n    chaosMonkey.expireSession(leaderJetty);\n\n    String expectedNewLeaderCoreNodeName = notLeaders.get(0).getName();\n    long timeout = System.nanoTime() + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    while (System.nanoTime() < timeout) {\n      String currentLeaderName = null;\n      try {\n        Replica currentLeader =\n            cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n        currentLeaderName = currentLeader.getName();\n      } catch (Exception exc) {}\n\n      if (expectedNewLeaderCoreNodeName.equals(currentLeaderName))\n        break; // new leader was elected after zk session expiration\n\n      Thread.sleep(500);\n    }\n\n    Replica currentLeader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    assertEquals(expectedNewLeaderCoreNodeName, currentLeader.getName());\n\n    // TODO: This test logic seems to be timing dependent and fails on Jenkins\n    // need to come up with a better approach\n    log.info(\"Sending doc 2 to old leader \"+leader.getName());\n    try ( HttpSolrClient leaderSolr = getHttpSolrClient(leader, testCollectionName)) {\n    \n      leaderSolr.add(doc);\n      leaderSolr.close();\n\n      // if the add worked, then the doc must exist on the new leader\n      try (HttpSolrClient newLeaderSolr = getHttpSolrClient(currentLeader, testCollectionName)) {\n        assertDocExists(newLeaderSolr, testCollectionName, \"2\");\n      }\n\n    } catch (SolrException exc) {\n      // this is ok provided the doc doesn't exist on the current leader\n      try (HttpSolrClient client = getHttpSolrClient(currentLeader, testCollectionName)) {\n        client.add(doc); // this should work\n      }\n    } \n\n    List<Replica> participatingReplicas = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    Set<String> replicasToCheck = new HashSet<>();\n    for (Replica stillUp : participatingReplicas)\n      replicasToCheck.add(stillUp.getName());\n    waitToSeeReplicasActive(testCollectionName, \"shard1\", replicasToCheck, 20);\n    assertDocsExistInAllReplicas(participatingReplicas, testCollectionName, 1, 2);\n\n    log.info(\"testLeaderZkSessionLoss succeeded ... deleting the \"+testCollectionName+\" collection\");\n\n    // try to clean up\n    try {\n      CollectionAdminRequest.Delete req = new CollectionAdminRequest.Delete();\n      req.setCollectionName(testCollectionName);\n      req.process(cloudClient);\n    } catch (Exception e) {\n      // don't fail the test\n      log.warn(\"Could not delete collection {} after test completed\", testCollectionName);\n    }\n  }\n\n","sourceOld":"  // test inspired by SOLR-6511\n  protected void testLeaderZkSessionLoss() throws Exception {\n\n    String testCollectionName = \"c8n_1x2_leader_session_loss\";\n    createCollection(testCollectionName, 1, 2, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    sendDoc(1);\n\n    List<Replica> notLeaders =\n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 2, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 1 replicas for collection \" + testCollectionName\n            + \" but found \" + notLeaders.size() + \"; clusterState: \"\n            + printClusterStateInfo(testCollectionName),\n        notLeaders.size() == 1);\n\n    Replica leader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n        testCollectionName+\"; clusterState: \"+printClusterStateInfo(testCollectionName), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n\n    HttpSolrClient leaderSolr = getHttpSolrClient(leader, testCollectionName);\n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(id, String.valueOf(2));\n    doc.addField(\"a_t\", \"hello\" + 2);\n\n    // cause leader migration by expiring the current leader's zk session\n    chaosMonkey.expireSession(leaderJetty);\n\n    String expectedNewLeaderCoreNodeName = notLeaders.get(0).getName();\n    long timeout = System.nanoTime() + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    while (System.nanoTime() < timeout) {\n      String currentLeaderName = null;\n      try {\n        Replica currentLeader =\n            cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n        currentLeaderName = currentLeader.getName();\n      } catch (Exception exc) {}\n\n      if (expectedNewLeaderCoreNodeName.equals(currentLeaderName))\n        break; // new leader was elected after zk session expiration\n\n      Thread.sleep(500);\n    }\n\n    Replica currentLeader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    assertEquals(expectedNewLeaderCoreNodeName, currentLeader.getName());\n\n    // TODO: This test logic seems to be timing dependent and fails on Jenkins\n    // need to come up with a better approach\n    log.info(\"Sending doc 2 to old leader \"+leader.getName());\n    try {\n      leaderSolr.add(doc);\n      leaderSolr.close();\n\n      // if the add worked, then the doc must exist on the new leader\n      try (HttpSolrClient newLeaderSolr = getHttpSolrClient(currentLeader, testCollectionName)) {\n        assertDocExists(newLeaderSolr, testCollectionName, \"2\");\n      }\n\n    } catch (SolrException exc) {\n      // this is ok provided the doc doesn't exist on the current leader\n      try (HttpSolrClient client = getHttpSolrClient(currentLeader, testCollectionName)) {\n        client.add(doc); // this should work\n      }\n    }\n\n    List<Replica> participatingReplicas = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    Set<String> replicasToCheck = new HashSet<>();\n    for (Replica stillUp : participatingReplicas)\n      replicasToCheck.add(stillUp.getName());\n    waitToSeeReplicasActive(testCollectionName, \"shard1\", replicasToCheck, 20);\n    assertDocsExistInAllReplicas(participatingReplicas, testCollectionName, 1, 2);\n\n    log.info(\"testLeaderZkSessionLoss succeeded ... deleting the \"+testCollectionName+\" collection\");\n\n    // try to clean up\n    try {\n      CollectionAdminRequest.Delete req = new CollectionAdminRequest.Delete();\n      req.setCollectionName(testCollectionName);\n      req.process(cloudClient);\n    } catch (Exception e) {\n      // don't fail the test\n      log.warn(\"Could not delete collection {} after test completed\", testCollectionName);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ac97ea104d893f16aab430d9904473bc1f233f3c","date":1496249396,"type":3,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testLeaderZkSessionLoss().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testLeaderZkSessionLoss().mjava","sourceNew":"  // test inspired by SOLR-6511\n  protected void testLeaderZkSessionLoss() throws Exception {\n\n    String testCollectionName = \"c8n_1x2_leader_session_loss\";\n    createCollectionRetry(testCollectionName, 1, 2, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    sendDoc(1);\n\n    List<Replica> notLeaders =\n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 2, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 1 replicas for collection \" + testCollectionName\n            + \" but found \" + notLeaders.size() + \"; clusterState: \"\n            + printClusterStateInfo(testCollectionName),\n        notLeaders.size() == 1);\n\n    Replica leader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n        testCollectionName+\"; clusterState: \"+printClusterStateInfo(testCollectionName), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n\n\n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(id, String.valueOf(2));\n    doc.addField(\"a_t\", \"hello\" + 2);\n\n    // cause leader migration by expiring the current leader's zk session\n    chaosMonkey.expireSession(leaderJetty);\n\n    String expectedNewLeaderCoreNodeName = notLeaders.get(0).getName();\n    long timeout = System.nanoTime() + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    while (System.nanoTime() < timeout) {\n      String currentLeaderName = null;\n      try {\n        Replica currentLeader =\n            cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n        currentLeaderName = currentLeader.getName();\n      } catch (Exception exc) {}\n\n      if (expectedNewLeaderCoreNodeName.equals(currentLeaderName))\n        break; // new leader was elected after zk session expiration\n\n      Thread.sleep(500);\n    }\n\n    Replica currentLeader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    assertEquals(expectedNewLeaderCoreNodeName, currentLeader.getName());\n\n    // TODO: This test logic seems to be timing dependent and fails on Jenkins\n    // need to come up with a better approach\n    log.info(\"Sending doc 2 to old leader \"+leader.getName());\n    try ( HttpSolrClient leaderSolr = getHttpSolrClient(leader, testCollectionName)) {\n    \n      leaderSolr.add(doc);\n      leaderSolr.close();\n\n      // if the add worked, then the doc must exist on the new leader\n      try (HttpSolrClient newLeaderSolr = getHttpSolrClient(currentLeader, testCollectionName)) {\n        assertDocExists(newLeaderSolr, testCollectionName, \"2\");\n      }\n\n    } catch (SolrException exc) {\n      // this is ok provided the doc doesn't exist on the current leader\n      try (HttpSolrClient client = getHttpSolrClient(currentLeader, testCollectionName)) {\n        client.add(doc); // this should work\n      }\n    } \n\n    List<Replica> participatingReplicas = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    Set<String> replicasToCheck = new HashSet<>();\n    for (Replica stillUp : participatingReplicas)\n      replicasToCheck.add(stillUp.getName());\n    waitToSeeReplicasActive(testCollectionName, \"shard1\", replicasToCheck, 20);\n    assertDocsExistInAllReplicas(participatingReplicas, testCollectionName, 1, 2);\n\n    log.info(\"testLeaderZkSessionLoss succeeded ... deleting the \"+testCollectionName+\" collection\");\n\n    // try to clean up\n    attemptCollectionDelete(cloudClient, testCollectionName);\n  }\n\n","sourceOld":"  // test inspired by SOLR-6511\n  protected void testLeaderZkSessionLoss() throws Exception {\n\n    String testCollectionName = \"c8n_1x2_leader_session_loss\";\n    createCollectionRetry(testCollectionName, 1, 2, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    sendDoc(1);\n\n    List<Replica> notLeaders =\n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 2, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 1 replicas for collection \" + testCollectionName\n            + \" but found \" + notLeaders.size() + \"; clusterState: \"\n            + printClusterStateInfo(testCollectionName),\n        notLeaders.size() == 1);\n\n    Replica leader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n        testCollectionName+\"; clusterState: \"+printClusterStateInfo(testCollectionName), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n\n\n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(id, String.valueOf(2));\n    doc.addField(\"a_t\", \"hello\" + 2);\n\n    // cause leader migration by expiring the current leader's zk session\n    chaosMonkey.expireSession(leaderJetty);\n\n    String expectedNewLeaderCoreNodeName = notLeaders.get(0).getName();\n    long timeout = System.nanoTime() + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    while (System.nanoTime() < timeout) {\n      String currentLeaderName = null;\n      try {\n        Replica currentLeader =\n            cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n        currentLeaderName = currentLeader.getName();\n      } catch (Exception exc) {}\n\n      if (expectedNewLeaderCoreNodeName.equals(currentLeaderName))\n        break; // new leader was elected after zk session expiration\n\n      Thread.sleep(500);\n    }\n\n    Replica currentLeader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    assertEquals(expectedNewLeaderCoreNodeName, currentLeader.getName());\n\n    // TODO: This test logic seems to be timing dependent and fails on Jenkins\n    // need to come up with a better approach\n    log.info(\"Sending doc 2 to old leader \"+leader.getName());\n    try ( HttpSolrClient leaderSolr = getHttpSolrClient(leader, testCollectionName)) {\n    \n      leaderSolr.add(doc);\n      leaderSolr.close();\n\n      // if the add worked, then the doc must exist on the new leader\n      try (HttpSolrClient newLeaderSolr = getHttpSolrClient(currentLeader, testCollectionName)) {\n        assertDocExists(newLeaderSolr, testCollectionName, \"2\");\n      }\n\n    } catch (SolrException exc) {\n      // this is ok provided the doc doesn't exist on the current leader\n      try (HttpSolrClient client = getHttpSolrClient(currentLeader, testCollectionName)) {\n        client.add(doc); // this should work\n      }\n    } \n\n    List<Replica> participatingReplicas = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    Set<String> replicasToCheck = new HashSet<>();\n    for (Replica stillUp : participatingReplicas)\n      replicasToCheck.add(stillUp.getName());\n    waitToSeeReplicasActive(testCollectionName, \"shard1\", replicasToCheck, 20);\n    assertDocsExistInAllReplicas(participatingReplicas, testCollectionName, 1, 2);\n\n    log.info(\"testLeaderZkSessionLoss succeeded ... deleting the \"+testCollectionName+\" collection\");\n\n    // try to clean up\n    try {\n      CollectionAdminRequest.Delete req = new CollectionAdminRequest.Delete();\n      req.setCollectionName(testCollectionName);\n      req.process(cloudClient);\n    } catch (Exception e) {\n      // don't fail the test\n      log.warn(\"Could not delete collection {} after test completed\", testCollectionName);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3217321f3e1d7922898c6c633d17acfa840d6875","date":1496257480,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testLeaderZkSessionLoss().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testLeaderZkSessionLoss().mjava","sourceNew":"  // test inspired by SOLR-6511\n  protected void testLeaderZkSessionLoss() throws Exception {\n\n    String testCollectionName = \"c8n_1x2_leader_session_loss\";\n    createCollectionRetry(testCollectionName, 1, 2, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    sendDoc(1);\n\n    List<Replica> notLeaders =\n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 2, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 1 replicas for collection \" + testCollectionName\n            + \" but found \" + notLeaders.size() + \"; clusterState: \"\n            + printClusterStateInfo(testCollectionName),\n        notLeaders.size() == 1);\n\n    Replica leader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n        testCollectionName+\"; clusterState: \"+printClusterStateInfo(testCollectionName), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n\n\n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(id, String.valueOf(2));\n    doc.addField(\"a_t\", \"hello\" + 2);\n\n    // cause leader migration by expiring the current leader's zk session\n    chaosMonkey.expireSession(leaderJetty);\n\n    String expectedNewLeaderCoreNodeName = notLeaders.get(0).getName();\n    long timeout = System.nanoTime() + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    while (System.nanoTime() < timeout) {\n      String currentLeaderName = null;\n      try {\n        Replica currentLeader =\n            cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n        currentLeaderName = currentLeader.getName();\n      } catch (Exception exc) {}\n\n      if (expectedNewLeaderCoreNodeName.equals(currentLeaderName))\n        break; // new leader was elected after zk session expiration\n\n      Thread.sleep(500);\n    }\n\n    Replica currentLeader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    assertEquals(expectedNewLeaderCoreNodeName, currentLeader.getName());\n\n    // TODO: This test logic seems to be timing dependent and fails on Jenkins\n    // need to come up with a better approach\n    log.info(\"Sending doc 2 to old leader \"+leader.getName());\n    try ( HttpSolrClient leaderSolr = getHttpSolrClient(leader, testCollectionName)) {\n    \n      leaderSolr.add(doc);\n      leaderSolr.close();\n\n      // if the add worked, then the doc must exist on the new leader\n      try (HttpSolrClient newLeaderSolr = getHttpSolrClient(currentLeader, testCollectionName)) {\n        assertDocExists(newLeaderSolr, testCollectionName, \"2\");\n      }\n\n    } catch (SolrException exc) {\n      // this is ok provided the doc doesn't exist on the current leader\n      try (HttpSolrClient client = getHttpSolrClient(currentLeader, testCollectionName)) {\n        client.add(doc); // this should work\n      }\n    } \n\n    List<Replica> participatingReplicas = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    Set<String> replicasToCheck = new HashSet<>();\n    for (Replica stillUp : participatingReplicas)\n      replicasToCheck.add(stillUp.getName());\n    waitToSeeReplicasActive(testCollectionName, \"shard1\", replicasToCheck, 20);\n    assertDocsExistInAllReplicas(participatingReplicas, testCollectionName, 1, 2);\n\n    log.info(\"testLeaderZkSessionLoss succeeded ... deleting the \"+testCollectionName+\" collection\");\n\n    // try to clean up\n    attemptCollectionDelete(cloudClient, testCollectionName);\n  }\n\n","sourceOld":"  // test inspired by SOLR-6511\n  protected void testLeaderZkSessionLoss() throws Exception {\n\n    String testCollectionName = \"c8n_1x2_leader_session_loss\";\n    createCollectionRetry(testCollectionName, 1, 2, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    sendDoc(1);\n\n    List<Replica> notLeaders =\n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 2, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 1 replicas for collection \" + testCollectionName\n            + \" but found \" + notLeaders.size() + \"; clusterState: \"\n            + printClusterStateInfo(testCollectionName),\n        notLeaders.size() == 1);\n\n    Replica leader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n        testCollectionName+\"; clusterState: \"+printClusterStateInfo(testCollectionName), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n\n\n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(id, String.valueOf(2));\n    doc.addField(\"a_t\", \"hello\" + 2);\n\n    // cause leader migration by expiring the current leader's zk session\n    chaosMonkey.expireSession(leaderJetty);\n\n    String expectedNewLeaderCoreNodeName = notLeaders.get(0).getName();\n    long timeout = System.nanoTime() + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    while (System.nanoTime() < timeout) {\n      String currentLeaderName = null;\n      try {\n        Replica currentLeader =\n            cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n        currentLeaderName = currentLeader.getName();\n      } catch (Exception exc) {}\n\n      if (expectedNewLeaderCoreNodeName.equals(currentLeaderName))\n        break; // new leader was elected after zk session expiration\n\n      Thread.sleep(500);\n    }\n\n    Replica currentLeader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    assertEquals(expectedNewLeaderCoreNodeName, currentLeader.getName());\n\n    // TODO: This test logic seems to be timing dependent and fails on Jenkins\n    // need to come up with a better approach\n    log.info(\"Sending doc 2 to old leader \"+leader.getName());\n    try ( HttpSolrClient leaderSolr = getHttpSolrClient(leader, testCollectionName)) {\n    \n      leaderSolr.add(doc);\n      leaderSolr.close();\n\n      // if the add worked, then the doc must exist on the new leader\n      try (HttpSolrClient newLeaderSolr = getHttpSolrClient(currentLeader, testCollectionName)) {\n        assertDocExists(newLeaderSolr, testCollectionName, \"2\");\n      }\n\n    } catch (SolrException exc) {\n      // this is ok provided the doc doesn't exist on the current leader\n      try (HttpSolrClient client = getHttpSolrClient(currentLeader, testCollectionName)) {\n        client.add(doc); // this should work\n      }\n    } \n\n    List<Replica> participatingReplicas = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    Set<String> replicasToCheck = new HashSet<>();\n    for (Replica stillUp : participatingReplicas)\n      replicasToCheck.add(stillUp.getName());\n    waitToSeeReplicasActive(testCollectionName, \"shard1\", replicasToCheck, 20);\n    assertDocsExistInAllReplicas(participatingReplicas, testCollectionName, 1, 2);\n\n    log.info(\"testLeaderZkSessionLoss succeeded ... deleting the \"+testCollectionName+\" collection\");\n\n    // try to clean up\n    try {\n      CollectionAdminRequest.Delete req = new CollectionAdminRequest.Delete();\n      req.setCollectionName(testCollectionName);\n      req.process(cloudClient);\n    } catch (Exception e) {\n      // don't fail the test\n      log.warn(\"Could not delete collection {} after test completed\", testCollectionName);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"42dc7f2d60851668d9efa2d12baa1d4ebe54b12f","date":1496281877,"type":3,"author":"Cao Manh Dat","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testLeaderZkSessionLoss().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testLeaderZkSessionLoss().mjava","sourceNew":"  // test inspired by SOLR-6511\n  protected void testLeaderZkSessionLoss() throws Exception {\n\n    String testCollectionName = \"c8n_1x2_leader_session_loss\";\n    createCollectionRetry(testCollectionName, 1, 2, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    sendDoc(1);\n\n    List<Replica> notLeaders =\n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 2, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 1 replicas for collection \" + testCollectionName\n            + \" but found \" + notLeaders.size() + \"; clusterState: \"\n            + printClusterStateInfo(testCollectionName),\n        notLeaders.size() == 1);\n\n    Replica leader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n        testCollectionName+\"; clusterState: \"+printClusterStateInfo(testCollectionName), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n\n\n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(id, String.valueOf(2));\n    doc.addField(\"a_t\", \"hello\" + 2);\n\n    // cause leader migration by expiring the current leader's zk session\n    chaosMonkey.expireSession(leaderJetty);\n\n    String expectedNewLeaderCoreNodeName = notLeaders.get(0).getName();\n    long timeout = System.nanoTime() + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    while (System.nanoTime() < timeout) {\n      String currentLeaderName = null;\n      try {\n        Replica currentLeader =\n            cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n        currentLeaderName = currentLeader.getName();\n      } catch (Exception exc) {}\n\n      if (expectedNewLeaderCoreNodeName.equals(currentLeaderName))\n        break; // new leader was elected after zk session expiration\n\n      Thread.sleep(500);\n    }\n\n    Replica currentLeader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    assertEquals(expectedNewLeaderCoreNodeName, currentLeader.getName());\n\n    // TODO: This test logic seems to be timing dependent and fails on Jenkins\n    // need to come up with a better approach\n    log.info(\"Sending doc 2 to old leader \"+leader.getName());\n    try ( HttpSolrClient leaderSolr = getHttpSolrClient(leader, testCollectionName)) {\n    \n      leaderSolr.add(doc);\n      leaderSolr.close();\n\n      // if the add worked, then the doc must exist on the new leader\n      try (HttpSolrClient newLeaderSolr = getHttpSolrClient(currentLeader, testCollectionName)) {\n        assertDocExists(newLeaderSolr, testCollectionName, \"2\");\n      }\n\n    } catch (SolrException exc) {\n      // this is ok provided the doc doesn't exist on the current leader\n      try (HttpSolrClient client = getHttpSolrClient(currentLeader, testCollectionName)) {\n        client.add(doc); // this should work\n      }\n    } \n\n    List<Replica> participatingReplicas = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    Set<String> replicasToCheck = new HashSet<>();\n    for (Replica stillUp : participatingReplicas)\n      replicasToCheck.add(stillUp.getName());\n    waitToSeeReplicasActive(testCollectionName, \"shard1\", replicasToCheck, 20);\n    assertDocsExistInAllReplicas(participatingReplicas, testCollectionName, 1, 2);\n\n    log.info(\"testLeaderZkSessionLoss succeeded ... deleting the \"+testCollectionName+\" collection\");\n\n    // try to clean up\n    attemptCollectionDelete(cloudClient, testCollectionName);\n  }\n\n","sourceOld":"  // test inspired by SOLR-6511\n  protected void testLeaderZkSessionLoss() throws Exception {\n\n    String testCollectionName = \"c8n_1x2_leader_session_loss\";\n    createCollectionRetry(testCollectionName, 1, 2, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    sendDoc(1);\n\n    List<Replica> notLeaders =\n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 2, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 1 replicas for collection \" + testCollectionName\n            + \" but found \" + notLeaders.size() + \"; clusterState: \"\n            + printClusterStateInfo(testCollectionName),\n        notLeaders.size() == 1);\n\n    Replica leader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n        testCollectionName+\"; clusterState: \"+printClusterStateInfo(testCollectionName), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n\n\n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(id, String.valueOf(2));\n    doc.addField(\"a_t\", \"hello\" + 2);\n\n    // cause leader migration by expiring the current leader's zk session\n    chaosMonkey.expireSession(leaderJetty);\n\n    String expectedNewLeaderCoreNodeName = notLeaders.get(0).getName();\n    long timeout = System.nanoTime() + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    while (System.nanoTime() < timeout) {\n      String currentLeaderName = null;\n      try {\n        Replica currentLeader =\n            cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n        currentLeaderName = currentLeader.getName();\n      } catch (Exception exc) {}\n\n      if (expectedNewLeaderCoreNodeName.equals(currentLeaderName))\n        break; // new leader was elected after zk session expiration\n\n      Thread.sleep(500);\n    }\n\n    Replica currentLeader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    assertEquals(expectedNewLeaderCoreNodeName, currentLeader.getName());\n\n    // TODO: This test logic seems to be timing dependent and fails on Jenkins\n    // need to come up with a better approach\n    log.info(\"Sending doc 2 to old leader \"+leader.getName());\n    try ( HttpSolrClient leaderSolr = getHttpSolrClient(leader, testCollectionName)) {\n    \n      leaderSolr.add(doc);\n      leaderSolr.close();\n\n      // if the add worked, then the doc must exist on the new leader\n      try (HttpSolrClient newLeaderSolr = getHttpSolrClient(currentLeader, testCollectionName)) {\n        assertDocExists(newLeaderSolr, testCollectionName, \"2\");\n      }\n\n    } catch (SolrException exc) {\n      // this is ok provided the doc doesn't exist on the current leader\n      try (HttpSolrClient client = getHttpSolrClient(currentLeader, testCollectionName)) {\n        client.add(doc); // this should work\n      }\n    } \n\n    List<Replica> participatingReplicas = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    Set<String> replicasToCheck = new HashSet<>();\n    for (Replica stillUp : participatingReplicas)\n      replicasToCheck.add(stillUp.getName());\n    waitToSeeReplicasActive(testCollectionName, \"shard1\", replicasToCheck, 20);\n    assertDocsExistInAllReplicas(participatingReplicas, testCollectionName, 1, 2);\n\n    log.info(\"testLeaderZkSessionLoss succeeded ... deleting the \"+testCollectionName+\" collection\");\n\n    // try to clean up\n    try {\n      CollectionAdminRequest.Delete req = new CollectionAdminRequest.Delete();\n      req.setCollectionName(testCollectionName);\n      req.process(cloudClient);\n    } catch (Exception e) {\n      // don't fail the test\n      log.warn(\"Could not delete collection {} after test completed\", testCollectionName);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e9017cf144952056066919f1ebc7897ff9bd71b1","date":1496757600,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testLeaderZkSessionLoss().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testLeaderZkSessionLoss().mjava","sourceNew":"  // test inspired by SOLR-6511\n  protected void testLeaderZkSessionLoss() throws Exception {\n\n    String testCollectionName = \"c8n_1x2_leader_session_loss\";\n    createCollectionRetry(testCollectionName, 1, 2, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    sendDoc(1);\n\n    List<Replica> notLeaders =\n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 2, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 1 replicas for collection \" + testCollectionName\n            + \" but found \" + notLeaders.size() + \"; clusterState: \"\n            + printClusterStateInfo(testCollectionName),\n        notLeaders.size() == 1);\n\n    Replica leader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n        testCollectionName+\"; clusterState: \"+printClusterStateInfo(testCollectionName), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n\n\n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(id, String.valueOf(2));\n    doc.addField(\"a_t\", \"hello\" + 2);\n\n    // cause leader migration by expiring the current leader's zk session\n    chaosMonkey.expireSession(leaderJetty);\n\n    String expectedNewLeaderCoreNodeName = notLeaders.get(0).getName();\n    long timeout = System.nanoTime() + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    while (System.nanoTime() < timeout) {\n      String currentLeaderName = null;\n      try {\n        Replica currentLeader =\n            cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n        currentLeaderName = currentLeader.getName();\n      } catch (Exception exc) {}\n\n      if (expectedNewLeaderCoreNodeName.equals(currentLeaderName))\n        break; // new leader was elected after zk session expiration\n\n      Thread.sleep(500);\n    }\n\n    Replica currentLeader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    assertEquals(expectedNewLeaderCoreNodeName, currentLeader.getName());\n\n    // TODO: This test logic seems to be timing dependent and fails on Jenkins\n    // need to come up with a better approach\n    log.info(\"Sending doc 2 to old leader \"+leader.getName());\n    try ( HttpSolrClient leaderSolr = getHttpSolrClient(leader, testCollectionName)) {\n    \n      leaderSolr.add(doc);\n      leaderSolr.close();\n\n      // if the add worked, then the doc must exist on the new leader\n      try (HttpSolrClient newLeaderSolr = getHttpSolrClient(currentLeader, testCollectionName)) {\n        assertDocExists(newLeaderSolr, testCollectionName, \"2\");\n      }\n\n    } catch (SolrException exc) {\n      // this is ok provided the doc doesn't exist on the current leader\n      try (HttpSolrClient client = getHttpSolrClient(currentLeader, testCollectionName)) {\n        client.add(doc); // this should work\n      }\n    } \n\n    List<Replica> participatingReplicas = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    Set<String> replicasToCheck = new HashSet<>();\n    for (Replica stillUp : participatingReplicas)\n      replicasToCheck.add(stillUp.getName());\n    waitToSeeReplicasActive(testCollectionName, \"shard1\", replicasToCheck, 20);\n    assertDocsExistInAllReplicas(participatingReplicas, testCollectionName, 1, 2);\n\n    log.info(\"testLeaderZkSessionLoss succeeded ... deleting the \"+testCollectionName+\" collection\");\n\n    // try to clean up\n    attemptCollectionDelete(cloudClient, testCollectionName);\n  }\n\n","sourceOld":"  // test inspired by SOLR-6511\n  protected void testLeaderZkSessionLoss() throws Exception {\n\n    String testCollectionName = \"c8n_1x2_leader_session_loss\";\n    createCollectionRetry(testCollectionName, 1, 2, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    sendDoc(1);\n\n    List<Replica> notLeaders =\n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 2, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 1 replicas for collection \" + testCollectionName\n            + \" but found \" + notLeaders.size() + \"; clusterState: \"\n            + printClusterStateInfo(testCollectionName),\n        notLeaders.size() == 1);\n\n    Replica leader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n        testCollectionName+\"; clusterState: \"+printClusterStateInfo(testCollectionName), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n\n\n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(id, String.valueOf(2));\n    doc.addField(\"a_t\", \"hello\" + 2);\n\n    // cause leader migration by expiring the current leader's zk session\n    chaosMonkey.expireSession(leaderJetty);\n\n    String expectedNewLeaderCoreNodeName = notLeaders.get(0).getName();\n    long timeout = System.nanoTime() + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    while (System.nanoTime() < timeout) {\n      String currentLeaderName = null;\n      try {\n        Replica currentLeader =\n            cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n        currentLeaderName = currentLeader.getName();\n      } catch (Exception exc) {}\n\n      if (expectedNewLeaderCoreNodeName.equals(currentLeaderName))\n        break; // new leader was elected after zk session expiration\n\n      Thread.sleep(500);\n    }\n\n    Replica currentLeader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    assertEquals(expectedNewLeaderCoreNodeName, currentLeader.getName());\n\n    // TODO: This test logic seems to be timing dependent and fails on Jenkins\n    // need to come up with a better approach\n    log.info(\"Sending doc 2 to old leader \"+leader.getName());\n    try ( HttpSolrClient leaderSolr = getHttpSolrClient(leader, testCollectionName)) {\n    \n      leaderSolr.add(doc);\n      leaderSolr.close();\n\n      // if the add worked, then the doc must exist on the new leader\n      try (HttpSolrClient newLeaderSolr = getHttpSolrClient(currentLeader, testCollectionName)) {\n        assertDocExists(newLeaderSolr, testCollectionName, \"2\");\n      }\n\n    } catch (SolrException exc) {\n      // this is ok provided the doc doesn't exist on the current leader\n      try (HttpSolrClient client = getHttpSolrClient(currentLeader, testCollectionName)) {\n        client.add(doc); // this should work\n      }\n    } \n\n    List<Replica> participatingReplicas = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    Set<String> replicasToCheck = new HashSet<>();\n    for (Replica stillUp : participatingReplicas)\n      replicasToCheck.add(stillUp.getName());\n    waitToSeeReplicasActive(testCollectionName, \"shard1\", replicasToCheck, 20);\n    assertDocsExistInAllReplicas(participatingReplicas, testCollectionName, 1, 2);\n\n    log.info(\"testLeaderZkSessionLoss succeeded ... deleting the \"+testCollectionName+\" collection\");\n\n    // try to clean up\n    try {\n      CollectionAdminRequest.Delete req = new CollectionAdminRequest.Delete();\n      req.setCollectionName(testCollectionName);\n      req.process(cloudClient);\n    } catch (Exception e) {\n      // don't fail the test\n      log.warn(\"Could not delete collection {} after test completed\", testCollectionName);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"197bbedf08450ade98a11f4a0001448059666bec","date":1498534625,"type":3,"author":"Ishan Chattopadhyaya","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testLeaderZkSessionLoss().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testLeaderZkSessionLoss().mjava","sourceNew":"  // test inspired by SOLR-6511\n  protected void testLeaderZkSessionLoss() throws Exception {\n\n    String testCollectionName = \"c8n_1x2_leader_session_loss\";\n    createCollectionRetry(testCollectionName, \"conf1\", 1, 2, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    sendDoc(1);\n\n    List<Replica> notLeaders =\n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 2, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 1 replicas for collection \" + testCollectionName\n            + \" but found \" + notLeaders.size() + \"; clusterState: \"\n            + printClusterStateInfo(testCollectionName),\n        notLeaders.size() == 1);\n\n    Replica leader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n        testCollectionName+\"; clusterState: \"+printClusterStateInfo(testCollectionName), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n\n\n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(id, String.valueOf(2));\n    doc.addField(\"a_t\", \"hello\" + 2);\n\n    // cause leader migration by expiring the current leader's zk session\n    chaosMonkey.expireSession(leaderJetty);\n\n    String expectedNewLeaderCoreNodeName = notLeaders.get(0).getName();\n    long timeout = System.nanoTime() + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    while (System.nanoTime() < timeout) {\n      String currentLeaderName = null;\n      try {\n        Replica currentLeader =\n            cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n        currentLeaderName = currentLeader.getName();\n      } catch (Exception exc) {}\n\n      if (expectedNewLeaderCoreNodeName.equals(currentLeaderName))\n        break; // new leader was elected after zk session expiration\n\n      Thread.sleep(500);\n    }\n\n    Replica currentLeader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    assertEquals(expectedNewLeaderCoreNodeName, currentLeader.getName());\n\n    // TODO: This test logic seems to be timing dependent and fails on Jenkins\n    // need to come up with a better approach\n    log.info(\"Sending doc 2 to old leader \"+leader.getName());\n    try ( HttpSolrClient leaderSolr = getHttpSolrClient(leader, testCollectionName)) {\n    \n      leaderSolr.add(doc);\n      leaderSolr.close();\n\n      // if the add worked, then the doc must exist on the new leader\n      try (HttpSolrClient newLeaderSolr = getHttpSolrClient(currentLeader, testCollectionName)) {\n        assertDocExists(newLeaderSolr, testCollectionName, \"2\");\n      }\n\n    } catch (SolrException exc) {\n      // this is ok provided the doc doesn't exist on the current leader\n      try (HttpSolrClient client = getHttpSolrClient(currentLeader, testCollectionName)) {\n        client.add(doc); // this should work\n      }\n    } \n\n    List<Replica> participatingReplicas = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    Set<String> replicasToCheck = new HashSet<>();\n    for (Replica stillUp : participatingReplicas)\n      replicasToCheck.add(stillUp.getName());\n    waitToSeeReplicasActive(testCollectionName, \"shard1\", replicasToCheck, 20);\n    assertDocsExistInAllReplicas(participatingReplicas, testCollectionName, 1, 2);\n\n    log.info(\"testLeaderZkSessionLoss succeeded ... deleting the \"+testCollectionName+\" collection\");\n\n    // try to clean up\n    attemptCollectionDelete(cloudClient, testCollectionName);\n  }\n\n","sourceOld":"  // test inspired by SOLR-6511\n  protected void testLeaderZkSessionLoss() throws Exception {\n\n    String testCollectionName = \"c8n_1x2_leader_session_loss\";\n    createCollectionRetry(testCollectionName, 1, 2, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    sendDoc(1);\n\n    List<Replica> notLeaders =\n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 2, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 1 replicas for collection \" + testCollectionName\n            + \" but found \" + notLeaders.size() + \"; clusterState: \"\n            + printClusterStateInfo(testCollectionName),\n        notLeaders.size() == 1);\n\n    Replica leader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n        testCollectionName+\"; clusterState: \"+printClusterStateInfo(testCollectionName), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n\n\n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(id, String.valueOf(2));\n    doc.addField(\"a_t\", \"hello\" + 2);\n\n    // cause leader migration by expiring the current leader's zk session\n    chaosMonkey.expireSession(leaderJetty);\n\n    String expectedNewLeaderCoreNodeName = notLeaders.get(0).getName();\n    long timeout = System.nanoTime() + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    while (System.nanoTime() < timeout) {\n      String currentLeaderName = null;\n      try {\n        Replica currentLeader =\n            cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n        currentLeaderName = currentLeader.getName();\n      } catch (Exception exc) {}\n\n      if (expectedNewLeaderCoreNodeName.equals(currentLeaderName))\n        break; // new leader was elected after zk session expiration\n\n      Thread.sleep(500);\n    }\n\n    Replica currentLeader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    assertEquals(expectedNewLeaderCoreNodeName, currentLeader.getName());\n\n    // TODO: This test logic seems to be timing dependent and fails on Jenkins\n    // need to come up with a better approach\n    log.info(\"Sending doc 2 to old leader \"+leader.getName());\n    try ( HttpSolrClient leaderSolr = getHttpSolrClient(leader, testCollectionName)) {\n    \n      leaderSolr.add(doc);\n      leaderSolr.close();\n\n      // if the add worked, then the doc must exist on the new leader\n      try (HttpSolrClient newLeaderSolr = getHttpSolrClient(currentLeader, testCollectionName)) {\n        assertDocExists(newLeaderSolr, testCollectionName, \"2\");\n      }\n\n    } catch (SolrException exc) {\n      // this is ok provided the doc doesn't exist on the current leader\n      try (HttpSolrClient client = getHttpSolrClient(currentLeader, testCollectionName)) {\n        client.add(doc); // this should work\n      }\n    } \n\n    List<Replica> participatingReplicas = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    Set<String> replicasToCheck = new HashSet<>();\n    for (Replica stillUp : participatingReplicas)\n      replicasToCheck.add(stillUp.getName());\n    waitToSeeReplicasActive(testCollectionName, \"shard1\", replicasToCheck, 20);\n    assertDocsExistInAllReplicas(participatingReplicas, testCollectionName, 1, 2);\n\n    log.info(\"testLeaderZkSessionLoss succeeded ... deleting the \"+testCollectionName+\" collection\");\n\n    // try to clean up\n    attemptCollectionDelete(cloudClient, testCollectionName);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fbedfa79ef95dc2b5b49f7d54d80e0b47867f9b4","date":1498540685,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testLeaderZkSessionLoss().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testLeaderZkSessionLoss().mjava","sourceNew":"  // test inspired by SOLR-6511\n  protected void testLeaderZkSessionLoss() throws Exception {\n\n    String testCollectionName = \"c8n_1x2_leader_session_loss\";\n    createCollectionRetry(testCollectionName, \"conf1\", 1, 2, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    sendDoc(1);\n\n    List<Replica> notLeaders =\n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 2, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 1 replicas for collection \" + testCollectionName\n            + \" but found \" + notLeaders.size() + \"; clusterState: \"\n            + printClusterStateInfo(testCollectionName),\n        notLeaders.size() == 1);\n\n    Replica leader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n        testCollectionName+\"; clusterState: \"+printClusterStateInfo(testCollectionName), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n\n\n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(id, String.valueOf(2));\n    doc.addField(\"a_t\", \"hello\" + 2);\n\n    // cause leader migration by expiring the current leader's zk session\n    chaosMonkey.expireSession(leaderJetty);\n\n    String expectedNewLeaderCoreNodeName = notLeaders.get(0).getName();\n    long timeout = System.nanoTime() + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    while (System.nanoTime() < timeout) {\n      String currentLeaderName = null;\n      try {\n        Replica currentLeader =\n            cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n        currentLeaderName = currentLeader.getName();\n      } catch (Exception exc) {}\n\n      if (expectedNewLeaderCoreNodeName.equals(currentLeaderName))\n        break; // new leader was elected after zk session expiration\n\n      Thread.sleep(500);\n    }\n\n    Replica currentLeader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    assertEquals(expectedNewLeaderCoreNodeName, currentLeader.getName());\n\n    // TODO: This test logic seems to be timing dependent and fails on Jenkins\n    // need to come up with a better approach\n    log.info(\"Sending doc 2 to old leader \"+leader.getName());\n    try ( HttpSolrClient leaderSolr = getHttpSolrClient(leader, testCollectionName)) {\n    \n      leaderSolr.add(doc);\n      leaderSolr.close();\n\n      // if the add worked, then the doc must exist on the new leader\n      try (HttpSolrClient newLeaderSolr = getHttpSolrClient(currentLeader, testCollectionName)) {\n        assertDocExists(newLeaderSolr, testCollectionName, \"2\");\n      }\n\n    } catch (SolrException exc) {\n      // this is ok provided the doc doesn't exist on the current leader\n      try (HttpSolrClient client = getHttpSolrClient(currentLeader, testCollectionName)) {\n        client.add(doc); // this should work\n      }\n    } \n\n    List<Replica> participatingReplicas = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    Set<String> replicasToCheck = new HashSet<>();\n    for (Replica stillUp : participatingReplicas)\n      replicasToCheck.add(stillUp.getName());\n    waitToSeeReplicasActive(testCollectionName, \"shard1\", replicasToCheck, 20);\n    assertDocsExistInAllReplicas(participatingReplicas, testCollectionName, 1, 2);\n\n    log.info(\"testLeaderZkSessionLoss succeeded ... deleting the \"+testCollectionName+\" collection\");\n\n    // try to clean up\n    attemptCollectionDelete(cloudClient, testCollectionName);\n  }\n\n","sourceOld":"  // test inspired by SOLR-6511\n  protected void testLeaderZkSessionLoss() throws Exception {\n\n    String testCollectionName = \"c8n_1x2_leader_session_loss\";\n    createCollectionRetry(testCollectionName, 1, 2, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    sendDoc(1);\n\n    List<Replica> notLeaders =\n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 2, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 1 replicas for collection \" + testCollectionName\n            + \" but found \" + notLeaders.size() + \"; clusterState: \"\n            + printClusterStateInfo(testCollectionName),\n        notLeaders.size() == 1);\n\n    Replica leader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n        testCollectionName+\"; clusterState: \"+printClusterStateInfo(testCollectionName), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n\n\n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(id, String.valueOf(2));\n    doc.addField(\"a_t\", \"hello\" + 2);\n\n    // cause leader migration by expiring the current leader's zk session\n    chaosMonkey.expireSession(leaderJetty);\n\n    String expectedNewLeaderCoreNodeName = notLeaders.get(0).getName();\n    long timeout = System.nanoTime() + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    while (System.nanoTime() < timeout) {\n      String currentLeaderName = null;\n      try {\n        Replica currentLeader =\n            cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n        currentLeaderName = currentLeader.getName();\n      } catch (Exception exc) {}\n\n      if (expectedNewLeaderCoreNodeName.equals(currentLeaderName))\n        break; // new leader was elected after zk session expiration\n\n      Thread.sleep(500);\n    }\n\n    Replica currentLeader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    assertEquals(expectedNewLeaderCoreNodeName, currentLeader.getName());\n\n    // TODO: This test logic seems to be timing dependent and fails on Jenkins\n    // need to come up with a better approach\n    log.info(\"Sending doc 2 to old leader \"+leader.getName());\n    try ( HttpSolrClient leaderSolr = getHttpSolrClient(leader, testCollectionName)) {\n    \n      leaderSolr.add(doc);\n      leaderSolr.close();\n\n      // if the add worked, then the doc must exist on the new leader\n      try (HttpSolrClient newLeaderSolr = getHttpSolrClient(currentLeader, testCollectionName)) {\n        assertDocExists(newLeaderSolr, testCollectionName, \"2\");\n      }\n\n    } catch (SolrException exc) {\n      // this is ok provided the doc doesn't exist on the current leader\n      try (HttpSolrClient client = getHttpSolrClient(currentLeader, testCollectionName)) {\n        client.add(doc); // this should work\n      }\n    } \n\n    List<Replica> participatingReplicas = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    Set<String> replicasToCheck = new HashSet<>();\n    for (Replica stillUp : participatingReplicas)\n      replicasToCheck.add(stillUp.getName());\n    waitToSeeReplicasActive(testCollectionName, \"shard1\", replicasToCheck, 20);\n    assertDocsExistInAllReplicas(participatingReplicas, testCollectionName, 1, 2);\n\n    log.info(\"testLeaderZkSessionLoss succeeded ... deleting the \"+testCollectionName+\" collection\");\n\n    // try to clean up\n    attemptCollectionDelete(cloudClient, testCollectionName);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"28288370235ed02234a64753cdbf0c6ec096304a","date":1498726817,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testLeaderZkSessionLoss().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testLeaderZkSessionLoss().mjava","sourceNew":"  // test inspired by SOLR-6511\n  protected void testLeaderZkSessionLoss() throws Exception {\n\n    String testCollectionName = \"c8n_1x2_leader_session_loss\";\n    createCollectionRetry(testCollectionName, \"conf1\", 1, 2, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    sendDoc(1);\n\n    List<Replica> notLeaders =\n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 2, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 1 replicas for collection \" + testCollectionName\n            + \" but found \" + notLeaders.size() + \"; clusterState: \"\n            + printClusterStateInfo(testCollectionName),\n        notLeaders.size() == 1);\n\n    Replica leader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n        testCollectionName+\"; clusterState: \"+printClusterStateInfo(testCollectionName), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n\n\n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(id, String.valueOf(2));\n    doc.addField(\"a_t\", \"hello\" + 2);\n\n    // cause leader migration by expiring the current leader's zk session\n    chaosMonkey.expireSession(leaderJetty);\n\n    String expectedNewLeaderCoreNodeName = notLeaders.get(0).getName();\n    long timeout = System.nanoTime() + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    while (System.nanoTime() < timeout) {\n      String currentLeaderName = null;\n      try {\n        Replica currentLeader =\n            cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n        currentLeaderName = currentLeader.getName();\n      } catch (Exception exc) {}\n\n      if (expectedNewLeaderCoreNodeName.equals(currentLeaderName))\n        break; // new leader was elected after zk session expiration\n\n      Thread.sleep(500);\n    }\n\n    Replica currentLeader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    assertEquals(expectedNewLeaderCoreNodeName, currentLeader.getName());\n\n    // TODO: This test logic seems to be timing dependent and fails on Jenkins\n    // need to come up with a better approach\n    log.info(\"Sending doc 2 to old leader \"+leader.getName());\n    try ( HttpSolrClient leaderSolr = getHttpSolrClient(leader, testCollectionName)) {\n    \n      leaderSolr.add(doc);\n      leaderSolr.close();\n\n      // if the add worked, then the doc must exist on the new leader\n      try (HttpSolrClient newLeaderSolr = getHttpSolrClient(currentLeader, testCollectionName)) {\n        assertDocExists(newLeaderSolr, testCollectionName, \"2\");\n      }\n\n    } catch (SolrException exc) {\n      // this is ok provided the doc doesn't exist on the current leader\n      try (HttpSolrClient client = getHttpSolrClient(currentLeader, testCollectionName)) {\n        client.add(doc); // this should work\n      }\n    } \n\n    List<Replica> participatingReplicas = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    Set<String> replicasToCheck = new HashSet<>();\n    for (Replica stillUp : participatingReplicas)\n      replicasToCheck.add(stillUp.getName());\n    waitToSeeReplicasActive(testCollectionName, \"shard1\", replicasToCheck, 20);\n    assertDocsExistInAllReplicas(participatingReplicas, testCollectionName, 1, 2);\n\n    log.info(\"testLeaderZkSessionLoss succeeded ... deleting the \"+testCollectionName+\" collection\");\n\n    // try to clean up\n    attemptCollectionDelete(cloudClient, testCollectionName);\n  }\n\n","sourceOld":"  // test inspired by SOLR-6511\n  protected void testLeaderZkSessionLoss() throws Exception {\n\n    String testCollectionName = \"c8n_1x2_leader_session_loss\";\n    createCollectionRetry(testCollectionName, 1, 2, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    sendDoc(1);\n\n    List<Replica> notLeaders =\n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 2, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 1 replicas for collection \" + testCollectionName\n            + \" but found \" + notLeaders.size() + \"; clusterState: \"\n            + printClusterStateInfo(testCollectionName),\n        notLeaders.size() == 1);\n\n    Replica leader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n        testCollectionName+\"; clusterState: \"+printClusterStateInfo(testCollectionName), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n\n\n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(id, String.valueOf(2));\n    doc.addField(\"a_t\", \"hello\" + 2);\n\n    // cause leader migration by expiring the current leader's zk session\n    chaosMonkey.expireSession(leaderJetty);\n\n    String expectedNewLeaderCoreNodeName = notLeaders.get(0).getName();\n    long timeout = System.nanoTime() + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    while (System.nanoTime() < timeout) {\n      String currentLeaderName = null;\n      try {\n        Replica currentLeader =\n            cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n        currentLeaderName = currentLeader.getName();\n      } catch (Exception exc) {}\n\n      if (expectedNewLeaderCoreNodeName.equals(currentLeaderName))\n        break; // new leader was elected after zk session expiration\n\n      Thread.sleep(500);\n    }\n\n    Replica currentLeader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    assertEquals(expectedNewLeaderCoreNodeName, currentLeader.getName());\n\n    // TODO: This test logic seems to be timing dependent and fails on Jenkins\n    // need to come up with a better approach\n    log.info(\"Sending doc 2 to old leader \"+leader.getName());\n    try ( HttpSolrClient leaderSolr = getHttpSolrClient(leader, testCollectionName)) {\n    \n      leaderSolr.add(doc);\n      leaderSolr.close();\n\n      // if the add worked, then the doc must exist on the new leader\n      try (HttpSolrClient newLeaderSolr = getHttpSolrClient(currentLeader, testCollectionName)) {\n        assertDocExists(newLeaderSolr, testCollectionName, \"2\");\n      }\n\n    } catch (SolrException exc) {\n      // this is ok provided the doc doesn't exist on the current leader\n      try (HttpSolrClient client = getHttpSolrClient(currentLeader, testCollectionName)) {\n        client.add(doc); // this should work\n      }\n    } \n\n    List<Replica> participatingReplicas = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    Set<String> replicasToCheck = new HashSet<>();\n    for (Replica stillUp : participatingReplicas)\n      replicasToCheck.add(stillUp.getName());\n    waitToSeeReplicasActive(testCollectionName, \"shard1\", replicasToCheck, 20);\n    assertDocsExistInAllReplicas(participatingReplicas, testCollectionName, 1, 2);\n\n    log.info(\"testLeaderZkSessionLoss succeeded ... deleting the \"+testCollectionName+\" collection\");\n\n    // try to clean up\n    attemptCollectionDelete(cloudClient, testCollectionName);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bb222a3f9d9421d5c95afce73013fbd8de07ea1f","date":1543514331,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testLeaderZkSessionLoss().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testLeaderZkSessionLoss().mjava","sourceNew":"  // test inspired by SOLR-6511\n  protected void testLeaderZkSessionLoss() throws Exception {\n\n    String testCollectionName = \"c8n_1x2_leader_session_loss\";\n    createCollectionRetry(testCollectionName, \"conf1\", 1, 2, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    sendDoc(1);\n\n    List<Replica> notLeaders =\n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 2, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 1 replicas for collection \" + testCollectionName\n            + \" but found \" + notLeaders.size() + \"; clusterState: \"\n            + printClusterStateInfo(testCollectionName),\n        notLeaders.size() == 1);\n\n    Replica leader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n        testCollectionName+\"; clusterState: \"+printClusterStateInfo(testCollectionName), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n\n\n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(id, String.valueOf(2));\n    doc.addField(\"a_t\", \"hello\" + 2);\n\n    // cause leader migration by expiring the current leader's zk session\n    chaosMonkey.expireSession(leaderJetty);\n\n    String expectedNewLeaderCoreNodeName = notLeaders.get(0).getName();\n    long timeout = System.nanoTime() + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    while (System.nanoTime() < timeout) {\n      String currentLeaderName = null;\n      try {\n        Replica currentLeader =\n            cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n        currentLeaderName = currentLeader.getName();\n      } catch (Exception exc) {}\n\n      if (expectedNewLeaderCoreNodeName.equals(currentLeaderName))\n        break; // new leader was elected after zk session expiration\n\n      Thread.sleep(500);\n    }\n\n    Replica currentLeader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    assertEquals(expectedNewLeaderCoreNodeName, currentLeader.getName());\n\n    // TODO: This test logic seems to be timing dependent and fails on Jenkins\n    // need to come up with a better approach\n    log.info(\"Sending doc 2 to old leader \"+leader.getName());\n    try ( HttpSolrClient leaderSolr = getHttpSolrClient(leader, testCollectionName)) {\n    \n      leaderSolr.add(doc);\n      leaderSolr.close();\n\n      // if the add worked, then the doc must exist on the new leader\n      try (HttpSolrClient newLeaderSolr = getHttpSolrClient(currentLeader, testCollectionName)) {\n        assertDocExists(newLeaderSolr, testCollectionName, \"2\");\n      }\n\n    } catch (SolrException exc) {\n      // this is ok provided the doc doesn't exist on the current leader\n      try (HttpSolrClient client = getHttpSolrClient(currentLeader, testCollectionName)) {\n        client.add(doc); // this should work\n      }\n    } \n\n    List<Replica> participatingReplicas = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    Set<String> replicasToCheck = new HashSet<>();\n    for (Replica stillUp : participatingReplicas)\n      replicasToCheck.add(stillUp.getName());\n    waitToSeeReplicasActive(testCollectionName, \"shard1\", replicasToCheck, 30);\n    assertDocsExistInAllReplicas(participatingReplicas, testCollectionName, 1, 2);\n\n    log.info(\"testLeaderZkSessionLoss succeeded ... deleting the \"+testCollectionName+\" collection\");\n\n    // try to clean up\n    attemptCollectionDelete(cloudClient, testCollectionName);\n  }\n\n","sourceOld":"  // test inspired by SOLR-6511\n  protected void testLeaderZkSessionLoss() throws Exception {\n\n    String testCollectionName = \"c8n_1x2_leader_session_loss\";\n    createCollectionRetry(testCollectionName, \"conf1\", 1, 2, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    sendDoc(1);\n\n    List<Replica> notLeaders =\n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 2, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 1 replicas for collection \" + testCollectionName\n            + \" but found \" + notLeaders.size() + \"; clusterState: \"\n            + printClusterStateInfo(testCollectionName),\n        notLeaders.size() == 1);\n\n    Replica leader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n        testCollectionName+\"; clusterState: \"+printClusterStateInfo(testCollectionName), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n\n\n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(id, String.valueOf(2));\n    doc.addField(\"a_t\", \"hello\" + 2);\n\n    // cause leader migration by expiring the current leader's zk session\n    chaosMonkey.expireSession(leaderJetty);\n\n    String expectedNewLeaderCoreNodeName = notLeaders.get(0).getName();\n    long timeout = System.nanoTime() + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    while (System.nanoTime() < timeout) {\n      String currentLeaderName = null;\n      try {\n        Replica currentLeader =\n            cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n        currentLeaderName = currentLeader.getName();\n      } catch (Exception exc) {}\n\n      if (expectedNewLeaderCoreNodeName.equals(currentLeaderName))\n        break; // new leader was elected after zk session expiration\n\n      Thread.sleep(500);\n    }\n\n    Replica currentLeader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    assertEquals(expectedNewLeaderCoreNodeName, currentLeader.getName());\n\n    // TODO: This test logic seems to be timing dependent and fails on Jenkins\n    // need to come up with a better approach\n    log.info(\"Sending doc 2 to old leader \"+leader.getName());\n    try ( HttpSolrClient leaderSolr = getHttpSolrClient(leader, testCollectionName)) {\n    \n      leaderSolr.add(doc);\n      leaderSolr.close();\n\n      // if the add worked, then the doc must exist on the new leader\n      try (HttpSolrClient newLeaderSolr = getHttpSolrClient(currentLeader, testCollectionName)) {\n        assertDocExists(newLeaderSolr, testCollectionName, \"2\");\n      }\n\n    } catch (SolrException exc) {\n      // this is ok provided the doc doesn't exist on the current leader\n      try (HttpSolrClient client = getHttpSolrClient(currentLeader, testCollectionName)) {\n        client.add(doc); // this should work\n      }\n    } \n\n    List<Replica> participatingReplicas = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    Set<String> replicasToCheck = new HashSet<>();\n    for (Replica stillUp : participatingReplicas)\n      replicasToCheck.add(stillUp.getName());\n    waitToSeeReplicasActive(testCollectionName, \"shard1\", replicasToCheck, 20);\n    assertDocsExistInAllReplicas(participatingReplicas, testCollectionName, 1, 2);\n\n    log.info(\"testLeaderZkSessionLoss succeeded ... deleting the \"+testCollectionName+\" collection\");\n\n    // try to clean up\n    attemptCollectionDelete(cloudClient, testCollectionName);\n  }\n\n","bugFix":["6e36353d7461af8d2329a78a71457cf8e3c1e88f"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a966532d92cf9ba2856f15a8140151bb6b518e4b","date":1588290631,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testLeaderZkSessionLoss().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testLeaderZkSessionLoss().mjava","sourceNew":"  // test inspired by SOLR-6511\n  protected void testLeaderZkSessionLoss() throws Exception {\n\n    String testCollectionName = \"c8n_1x2_leader_session_loss\";\n    createCollectionRetry(testCollectionName, \"conf1\", 1, 2, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    sendDoc(1);\n\n    List<Replica> notLeaders =\n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 2, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 1 replicas for collection \" + testCollectionName\n            + \" but found \" + notLeaders.size() + \"; clusterState: \"\n            + printClusterStateInfo(testCollectionName),\n        notLeaders.size() == 1);\n\n    Replica leader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n        testCollectionName+\"; clusterState: \"+printClusterStateInfo(testCollectionName), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n\n\n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(id, String.valueOf(2));\n    doc.addField(\"a_t\", \"hello\" + 2);\n\n    // cause leader migration by expiring the current leader's zk session\n    chaosMonkey.expireSession(leaderJetty);\n\n    String expectedNewLeaderCoreNodeName = notLeaders.get(0).getName();\n    long timeout = System.nanoTime() + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    while (System.nanoTime() < timeout) {\n      String currentLeaderName = null;\n      try {\n        Replica currentLeader =\n            cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n        currentLeaderName = currentLeader.getName();\n      } catch (Exception exc) {}\n\n      if (expectedNewLeaderCoreNodeName.equals(currentLeaderName))\n        break; // new leader was elected after zk session expiration\n\n      Thread.sleep(500);\n    }\n\n    Replica currentLeader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    assertEquals(expectedNewLeaderCoreNodeName, currentLeader.getName());\n\n    // TODO: This test logic seems to be timing dependent and fails on Jenkins\n    // need to come up with a better approach\n    if (log.isInfoEnabled()) {\n      log.info(\"Sending doc 2 to old leader {}\", leader.getName());\n    }\n    try ( HttpSolrClient leaderSolr = getHttpSolrClient(leader, testCollectionName)) {\n    \n      leaderSolr.add(doc);\n      leaderSolr.close();\n\n      // if the add worked, then the doc must exist on the new leader\n      try (HttpSolrClient newLeaderSolr = getHttpSolrClient(currentLeader, testCollectionName)) {\n        assertDocExists(newLeaderSolr, testCollectionName, \"2\");\n      }\n\n    } catch (SolrException exc) {\n      // this is ok provided the doc doesn't exist on the current leader\n      try (HttpSolrClient client = getHttpSolrClient(currentLeader, testCollectionName)) {\n        client.add(doc); // this should work\n      }\n    } \n\n    List<Replica> participatingReplicas = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    Set<String> replicasToCheck = new HashSet<>();\n    for (Replica stillUp : participatingReplicas)\n      replicasToCheck.add(stillUp.getName());\n    waitToSeeReplicasActive(testCollectionName, \"shard1\", replicasToCheck, 30);\n    assertDocsExistInAllReplicas(participatingReplicas, testCollectionName, 1, 2);\n\n    log.info(\"testLeaderZkSessionLoss succeeded ... deleting the {} collection\", testCollectionName);\n\n    // try to clean up\n    attemptCollectionDelete(cloudClient, testCollectionName);\n  }\n\n","sourceOld":"  // test inspired by SOLR-6511\n  protected void testLeaderZkSessionLoss() throws Exception {\n\n    String testCollectionName = \"c8n_1x2_leader_session_loss\";\n    createCollectionRetry(testCollectionName, \"conf1\", 1, 2, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    sendDoc(1);\n\n    List<Replica> notLeaders =\n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 2, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 1 replicas for collection \" + testCollectionName\n            + \" but found \" + notLeaders.size() + \"; clusterState: \"\n            + printClusterStateInfo(testCollectionName),\n        notLeaders.size() == 1);\n\n    Replica leader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n        testCollectionName+\"; clusterState: \"+printClusterStateInfo(testCollectionName), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n\n\n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(id, String.valueOf(2));\n    doc.addField(\"a_t\", \"hello\" + 2);\n\n    // cause leader migration by expiring the current leader's zk session\n    chaosMonkey.expireSession(leaderJetty);\n\n    String expectedNewLeaderCoreNodeName = notLeaders.get(0).getName();\n    long timeout = System.nanoTime() + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    while (System.nanoTime() < timeout) {\n      String currentLeaderName = null;\n      try {\n        Replica currentLeader =\n            cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n        currentLeaderName = currentLeader.getName();\n      } catch (Exception exc) {}\n\n      if (expectedNewLeaderCoreNodeName.equals(currentLeaderName))\n        break; // new leader was elected after zk session expiration\n\n      Thread.sleep(500);\n    }\n\n    Replica currentLeader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    assertEquals(expectedNewLeaderCoreNodeName, currentLeader.getName());\n\n    // TODO: This test logic seems to be timing dependent and fails on Jenkins\n    // need to come up with a better approach\n    log.info(\"Sending doc 2 to old leader \"+leader.getName());\n    try ( HttpSolrClient leaderSolr = getHttpSolrClient(leader, testCollectionName)) {\n    \n      leaderSolr.add(doc);\n      leaderSolr.close();\n\n      // if the add worked, then the doc must exist on the new leader\n      try (HttpSolrClient newLeaderSolr = getHttpSolrClient(currentLeader, testCollectionName)) {\n        assertDocExists(newLeaderSolr, testCollectionName, \"2\");\n      }\n\n    } catch (SolrException exc) {\n      // this is ok provided the doc doesn't exist on the current leader\n      try (HttpSolrClient client = getHttpSolrClient(currentLeader, testCollectionName)) {\n        client.add(doc); // this should work\n      }\n    } \n\n    List<Replica> participatingReplicas = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    Set<String> replicasToCheck = new HashSet<>();\n    for (Replica stillUp : participatingReplicas)\n      replicasToCheck.add(stillUp.getName());\n    waitToSeeReplicasActive(testCollectionName, \"shard1\", replicasToCheck, 30);\n    assertDocsExistInAllReplicas(participatingReplicas, testCollectionName, 1, 2);\n\n    log.info(\"testLeaderZkSessionLoss succeeded ... deleting the \"+testCollectionName+\" collection\");\n\n    // try to clean up\n    attemptCollectionDelete(cloudClient, testCollectionName);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e98520789adb1d5ad05afb4956eca0944a929688","date":1592430701,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testLeaderZkSessionLoss().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testLeaderZkSessionLoss().mjava","sourceNew":"  // test inspired by SOLR-6511\n  @SuppressWarnings({\"try\"})\n  protected void testLeaderZkSessionLoss() throws Exception {\n\n    String testCollectionName = \"c8n_1x2_leader_session_loss\";\n    createCollectionRetry(testCollectionName, \"conf1\", 1, 2, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    sendDoc(1);\n\n    List<Replica> notLeaders =\n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 2, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 1 replicas for collection \" + testCollectionName\n            + \" but found \" + notLeaders.size() + \"; clusterState: \"\n            + printClusterStateInfo(testCollectionName),\n        notLeaders.size() == 1);\n\n    Replica leader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n        testCollectionName+\"; clusterState: \"+printClusterStateInfo(testCollectionName), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n\n\n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(id, String.valueOf(2));\n    doc.addField(\"a_t\", \"hello\" + 2);\n\n    // cause leader migration by expiring the current leader's zk session\n    chaosMonkey.expireSession(leaderJetty);\n\n    String expectedNewLeaderCoreNodeName = notLeaders.get(0).getName();\n    long timeout = System.nanoTime() + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    while (System.nanoTime() < timeout) {\n      String currentLeaderName = null;\n      try {\n        Replica currentLeader =\n            cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n        currentLeaderName = currentLeader.getName();\n      } catch (Exception exc) {}\n\n      if (expectedNewLeaderCoreNodeName.equals(currentLeaderName))\n        break; // new leader was elected after zk session expiration\n\n      Thread.sleep(500);\n    }\n\n    Replica currentLeader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    assertEquals(expectedNewLeaderCoreNodeName, currentLeader.getName());\n\n    // TODO: This test logic seems to be timing dependent and fails on Jenkins\n    // need to come up with a better approach\n    if (log.isInfoEnabled()) {\n      log.info(\"Sending doc 2 to old leader {}\", leader.getName());\n    }\n    try ( HttpSolrClient leaderSolr = getHttpSolrClient(leader, testCollectionName)) {\n    \n      leaderSolr.add(doc);\n      leaderSolr.close();\n\n      // if the add worked, then the doc must exist on the new leader\n      try (HttpSolrClient newLeaderSolr = getHttpSolrClient(currentLeader, testCollectionName)) {\n        assertDocExists(newLeaderSolr, testCollectionName, \"2\");\n      }\n\n    } catch (SolrException exc) {\n      // this is ok provided the doc doesn't exist on the current leader\n      try (HttpSolrClient client = getHttpSolrClient(currentLeader, testCollectionName)) {\n        client.add(doc); // this should work\n      }\n    } \n\n    List<Replica> participatingReplicas = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    Set<String> replicasToCheck = new HashSet<>();\n    for (Replica stillUp : participatingReplicas)\n      replicasToCheck.add(stillUp.getName());\n    waitToSeeReplicasActive(testCollectionName, \"shard1\", replicasToCheck, 30);\n    assertDocsExistInAllReplicas(participatingReplicas, testCollectionName, 1, 2);\n\n    log.info(\"testLeaderZkSessionLoss succeeded ... deleting the {} collection\", testCollectionName);\n\n    // try to clean up\n    attemptCollectionDelete(cloudClient, testCollectionName);\n  }\n\n","sourceOld":"  // test inspired by SOLR-6511\n  protected void testLeaderZkSessionLoss() throws Exception {\n\n    String testCollectionName = \"c8n_1x2_leader_session_loss\";\n    createCollectionRetry(testCollectionName, \"conf1\", 1, 2, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    sendDoc(1);\n\n    List<Replica> notLeaders =\n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 2, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 1 replicas for collection \" + testCollectionName\n            + \" but found \" + notLeaders.size() + \"; clusterState: \"\n            + printClusterStateInfo(testCollectionName),\n        notLeaders.size() == 1);\n\n    Replica leader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n        testCollectionName+\"; clusterState: \"+printClusterStateInfo(testCollectionName), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n\n\n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(id, String.valueOf(2));\n    doc.addField(\"a_t\", \"hello\" + 2);\n\n    // cause leader migration by expiring the current leader's zk session\n    chaosMonkey.expireSession(leaderJetty);\n\n    String expectedNewLeaderCoreNodeName = notLeaders.get(0).getName();\n    long timeout = System.nanoTime() + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    while (System.nanoTime() < timeout) {\n      String currentLeaderName = null;\n      try {\n        Replica currentLeader =\n            cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n        currentLeaderName = currentLeader.getName();\n      } catch (Exception exc) {}\n\n      if (expectedNewLeaderCoreNodeName.equals(currentLeaderName))\n        break; // new leader was elected after zk session expiration\n\n      Thread.sleep(500);\n    }\n\n    Replica currentLeader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    assertEquals(expectedNewLeaderCoreNodeName, currentLeader.getName());\n\n    // TODO: This test logic seems to be timing dependent and fails on Jenkins\n    // need to come up with a better approach\n    if (log.isInfoEnabled()) {\n      log.info(\"Sending doc 2 to old leader {}\", leader.getName());\n    }\n    try ( HttpSolrClient leaderSolr = getHttpSolrClient(leader, testCollectionName)) {\n    \n      leaderSolr.add(doc);\n      leaderSolr.close();\n\n      // if the add worked, then the doc must exist on the new leader\n      try (HttpSolrClient newLeaderSolr = getHttpSolrClient(currentLeader, testCollectionName)) {\n        assertDocExists(newLeaderSolr, testCollectionName, \"2\");\n      }\n\n    } catch (SolrException exc) {\n      // this is ok provided the doc doesn't exist on the current leader\n      try (HttpSolrClient client = getHttpSolrClient(currentLeader, testCollectionName)) {\n        client.add(doc); // this should work\n      }\n    } \n\n    List<Replica> participatingReplicas = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    Set<String> replicasToCheck = new HashSet<>();\n    for (Replica stillUp : participatingReplicas)\n      replicasToCheck.add(stillUp.getName());\n    waitToSeeReplicasActive(testCollectionName, \"shard1\", replicasToCheck, 30);\n    assertDocsExistInAllReplicas(participatingReplicas, testCollectionName, 1, 2);\n\n    log.info(\"testLeaderZkSessionLoss succeeded ... deleting the {} collection\", testCollectionName);\n\n    // try to clean up\n    attemptCollectionDelete(cloudClient, testCollectionName);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e","date":1594223844,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testLeaderZkSessionLoss().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testLeaderZkSessionLoss().mjava","sourceNew":"  // test inspired by SOLR-6511\n  @SuppressWarnings({\"try\"})\n  protected void testLeaderZkSessionLoss() throws Exception {\n\n    String testCollectionName = \"c8n_1x2_leader_session_loss\";\n    createCollectionRetry(testCollectionName, \"conf1\", 1, 2);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    sendDoc(1);\n\n    List<Replica> notLeaders =\n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 2, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 1 replicas for collection \" + testCollectionName\n            + \" but found \" + notLeaders.size() + \"; clusterState: \"\n            + printClusterStateInfo(testCollectionName),\n        notLeaders.size() == 1);\n\n    Replica leader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n        testCollectionName+\"; clusterState: \"+printClusterStateInfo(testCollectionName), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n\n\n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(id, String.valueOf(2));\n    doc.addField(\"a_t\", \"hello\" + 2);\n\n    // cause leader migration by expiring the current leader's zk session\n    chaosMonkey.expireSession(leaderJetty);\n\n    String expectedNewLeaderCoreNodeName = notLeaders.get(0).getName();\n    long timeout = System.nanoTime() + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    while (System.nanoTime() < timeout) {\n      String currentLeaderName = null;\n      try {\n        Replica currentLeader =\n            cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n        currentLeaderName = currentLeader.getName();\n      } catch (Exception exc) {}\n\n      if (expectedNewLeaderCoreNodeName.equals(currentLeaderName))\n        break; // new leader was elected after zk session expiration\n\n      Thread.sleep(500);\n    }\n\n    Replica currentLeader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    assertEquals(expectedNewLeaderCoreNodeName, currentLeader.getName());\n\n    // TODO: This test logic seems to be timing dependent and fails on Jenkins\n    // need to come up with a better approach\n    if (log.isInfoEnabled()) {\n      log.info(\"Sending doc 2 to old leader {}\", leader.getName());\n    }\n    try ( HttpSolrClient leaderSolr = getHttpSolrClient(leader, testCollectionName)) {\n    \n      leaderSolr.add(doc);\n      leaderSolr.close();\n\n      // if the add worked, then the doc must exist on the new leader\n      try (HttpSolrClient newLeaderSolr = getHttpSolrClient(currentLeader, testCollectionName)) {\n        assertDocExists(newLeaderSolr, testCollectionName, \"2\");\n      }\n\n    } catch (SolrException exc) {\n      // this is ok provided the doc doesn't exist on the current leader\n      try (HttpSolrClient client = getHttpSolrClient(currentLeader, testCollectionName)) {\n        client.add(doc); // this should work\n      }\n    } \n\n    List<Replica> participatingReplicas = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    Set<String> replicasToCheck = new HashSet<>();\n    for (Replica stillUp : participatingReplicas)\n      replicasToCheck.add(stillUp.getName());\n    waitToSeeReplicasActive(testCollectionName, \"shard1\", replicasToCheck, 30);\n    assertDocsExistInAllReplicas(participatingReplicas, testCollectionName, 1, 2);\n\n    log.info(\"testLeaderZkSessionLoss succeeded ... deleting the {} collection\", testCollectionName);\n\n    // try to clean up\n    attemptCollectionDelete(cloudClient, testCollectionName);\n  }\n\n","sourceOld":"  // test inspired by SOLR-6511\n  @SuppressWarnings({\"try\"})\n  protected void testLeaderZkSessionLoss() throws Exception {\n\n    String testCollectionName = \"c8n_1x2_leader_session_loss\";\n    createCollectionRetry(testCollectionName, \"conf1\", 1, 2, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    sendDoc(1);\n\n    List<Replica> notLeaders =\n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 2, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 1 replicas for collection \" + testCollectionName\n            + \" but found \" + notLeaders.size() + \"; clusterState: \"\n            + printClusterStateInfo(testCollectionName),\n        notLeaders.size() == 1);\n\n    Replica leader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n        testCollectionName+\"; clusterState: \"+printClusterStateInfo(testCollectionName), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n\n\n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(id, String.valueOf(2));\n    doc.addField(\"a_t\", \"hello\" + 2);\n\n    // cause leader migration by expiring the current leader's zk session\n    chaosMonkey.expireSession(leaderJetty);\n\n    String expectedNewLeaderCoreNodeName = notLeaders.get(0).getName();\n    long timeout = System.nanoTime() + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    while (System.nanoTime() < timeout) {\n      String currentLeaderName = null;\n      try {\n        Replica currentLeader =\n            cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n        currentLeaderName = currentLeader.getName();\n      } catch (Exception exc) {}\n\n      if (expectedNewLeaderCoreNodeName.equals(currentLeaderName))\n        break; // new leader was elected after zk session expiration\n\n      Thread.sleep(500);\n    }\n\n    Replica currentLeader =\n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    assertEquals(expectedNewLeaderCoreNodeName, currentLeader.getName());\n\n    // TODO: This test logic seems to be timing dependent and fails on Jenkins\n    // need to come up with a better approach\n    if (log.isInfoEnabled()) {\n      log.info(\"Sending doc 2 to old leader {}\", leader.getName());\n    }\n    try ( HttpSolrClient leaderSolr = getHttpSolrClient(leader, testCollectionName)) {\n    \n      leaderSolr.add(doc);\n      leaderSolr.close();\n\n      // if the add worked, then the doc must exist on the new leader\n      try (HttpSolrClient newLeaderSolr = getHttpSolrClient(currentLeader, testCollectionName)) {\n        assertDocExists(newLeaderSolr, testCollectionName, \"2\");\n      }\n\n    } catch (SolrException exc) {\n      // this is ok provided the doc doesn't exist on the current leader\n      try (HttpSolrClient client = getHttpSolrClient(currentLeader, testCollectionName)) {\n        client.add(doc); // this should work\n      }\n    } \n\n    List<Replica> participatingReplicas = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    Set<String> replicasToCheck = new HashSet<>();\n    for (Replica stillUp : participatingReplicas)\n      replicasToCheck.add(stillUp.getName());\n    waitToSeeReplicasActive(testCollectionName, \"shard1\", replicasToCheck, 30);\n    assertDocsExistInAllReplicas(participatingReplicas, testCollectionName, 1, 2);\n\n    log.info(\"testLeaderZkSessionLoss succeeded ... deleting the {} collection\", testCollectionName);\n\n    // try to clean up\n    attemptCollectionDelete(cloudClient, testCollectionName);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"55980207f1977bd1463465de1659b821347e2fa8":["d9a47902d6207303f5ed3e7aaca62ca33433af66","2d14328dee83c3ec0478e7d711f7af48560ad5ef"],"197bbedf08450ade98a11f4a0001448059666bec":["42dc7f2d60851668d9efa2d12baa1d4ebe54b12f"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["28288370235ed02234a64753cdbf0c6ec096304a"],"ac97ea104d893f16aab430d9904473bc1f233f3c":["37e7502644cd23597431d66e301299b1ead2fb9b"],"d9a47902d6207303f5ed3e7aaca62ca33433af66":["6e36353d7461af8d2329a78a71457cf8e3c1e88f","ecdef415cd9c28cee0b395ac99e65c45a3efc4ff"],"bafca15d8e408346a67f4282ad1143b88023893b":["d0ec3dbdc850ca18bf4aef9acb85f2ea0554306d"],"2d14328dee83c3ec0478e7d711f7af48560ad5ef":["ecdef415cd9c28cee0b395ac99e65c45a3efc4ff"],"3217321f3e1d7922898c6c633d17acfa840d6875":["37e7502644cd23597431d66e301299b1ead2fb9b","ac97ea104d893f16aab430d9904473bc1f233f3c"],"d0ec3dbdc850ca18bf4aef9acb85f2ea0554306d":["2d14328dee83c3ec0478e7d711f7af48560ad5ef"],"ecdef415cd9c28cee0b395ac99e65c45a3efc4ff":["6e36353d7461af8d2329a78a71457cf8e3c1e88f"],"a966532d92cf9ba2856f15a8140151bb6b518e4b":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e":["e98520789adb1d5ad05afb4956eca0944a929688"],"28288370235ed02234a64753cdbf0c6ec096304a":["3217321f3e1d7922898c6c633d17acfa840d6875","197bbedf08450ade98a11f4a0001448059666bec"],"42dc7f2d60851668d9efa2d12baa1d4ebe54b12f":["37e7502644cd23597431d66e301299b1ead2fb9b","3217321f3e1d7922898c6c633d17acfa840d6875"],"e98520789adb1d5ad05afb4956eca0944a929688":["a966532d92cf9ba2856f15a8140151bb6b518e4b"],"e9017cf144952056066919f1ebc7897ff9bd71b1":["37e7502644cd23597431d66e301299b1ead2fb9b","42dc7f2d60851668d9efa2d12baa1d4ebe54b12f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"fbedfa79ef95dc2b5b49f7d54d80e0b47867f9b4":["e9017cf144952056066919f1ebc7897ff9bd71b1","197bbedf08450ade98a11f4a0001448059666bec"],"37e7502644cd23597431d66e301299b1ead2fb9b":["cc3b13b430571c2e169f98fe38e1e7666f88522d"],"cc3b13b430571c2e169f98fe38e1e7666f88522d":["bafca15d8e408346a67f4282ad1143b88023893b"],"6e36353d7461af8d2329a78a71457cf8e3c1e88f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["e46a76bb135597b8bf35930cfdb3702bdd1cbe6e"]},"commit2Childs":{"55980207f1977bd1463465de1659b821347e2fa8":[],"197bbedf08450ade98a11f4a0001448059666bec":["28288370235ed02234a64753cdbf0c6ec096304a","fbedfa79ef95dc2b5b49f7d54d80e0b47867f9b4"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["a966532d92cf9ba2856f15a8140151bb6b518e4b"],"ac97ea104d893f16aab430d9904473bc1f233f3c":["3217321f3e1d7922898c6c633d17acfa840d6875"],"d9a47902d6207303f5ed3e7aaca62ca33433af66":["55980207f1977bd1463465de1659b821347e2fa8"],"2d14328dee83c3ec0478e7d711f7af48560ad5ef":["55980207f1977bd1463465de1659b821347e2fa8","d0ec3dbdc850ca18bf4aef9acb85f2ea0554306d"],"bafca15d8e408346a67f4282ad1143b88023893b":["cc3b13b430571c2e169f98fe38e1e7666f88522d"],"3217321f3e1d7922898c6c633d17acfa840d6875":["28288370235ed02234a64753cdbf0c6ec096304a","42dc7f2d60851668d9efa2d12baa1d4ebe54b12f"],"d0ec3dbdc850ca18bf4aef9acb85f2ea0554306d":["bafca15d8e408346a67f4282ad1143b88023893b"],"ecdef415cd9c28cee0b395ac99e65c45a3efc4ff":["d9a47902d6207303f5ed3e7aaca62ca33433af66","2d14328dee83c3ec0478e7d711f7af48560ad5ef"],"a966532d92cf9ba2856f15a8140151bb6b518e4b":["e98520789adb1d5ad05afb4956eca0944a929688"],"42dc7f2d60851668d9efa2d12baa1d4ebe54b12f":["197bbedf08450ade98a11f4a0001448059666bec","e9017cf144952056066919f1ebc7897ff9bd71b1"],"28288370235ed02234a64753cdbf0c6ec096304a":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"e98520789adb1d5ad05afb4956eca0944a929688":["e46a76bb135597b8bf35930cfdb3702bdd1cbe6e"],"e9017cf144952056066919f1ebc7897ff9bd71b1":["fbedfa79ef95dc2b5b49f7d54d80e0b47867f9b4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["6e36353d7461af8d2329a78a71457cf8e3c1e88f"],"fbedfa79ef95dc2b5b49f7d54d80e0b47867f9b4":[],"37e7502644cd23597431d66e301299b1ead2fb9b":["ac97ea104d893f16aab430d9904473bc1f233f3c","3217321f3e1d7922898c6c633d17acfa840d6875","42dc7f2d60851668d9efa2d12baa1d4ebe54b12f","e9017cf144952056066919f1ebc7897ff9bd71b1"],"cc3b13b430571c2e169f98fe38e1e7666f88522d":["37e7502644cd23597431d66e301299b1ead2fb9b"],"6e36353d7461af8d2329a78a71457cf8e3c1e88f":["d9a47902d6207303f5ed3e7aaca62ca33433af66","ecdef415cd9c28cee0b395ac99e65c45a3efc4ff"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["55980207f1977bd1463465de1659b821347e2fa8","fbedfa79ef95dc2b5b49f7d54d80e0b47867f9b4","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}