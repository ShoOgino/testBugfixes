{"path":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Builder#add(CharsRef,int,CharsRef,int,boolean).mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Builder#add(CharsRef,int,CharsRef,int,boolean).mjava","pathOld":"modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Builder#add(CharsRef,int,CharsRef,int,boolean).mjava","sourceNew":"    // NOTE: while it's tempting to make this public, since\n    // caller's parser likely knows the\n    // numInput/numOutputWords, sneaky exceptions, much later\n    // on, will result if these values are wrong; so we always\n    // recompute ourselves to be safe:\n    private void add(CharsRef input, int numInputWords, CharsRef output, int numOutputWords, boolean includeOrig) {\n      // first convert to UTF-8\n      if (numInputWords <= 0) {\n        throw new IllegalArgumentException(\"numInputWords must be > 0 (got \" + numInputWords + \")\");\n      }\n      if (input.length <= 0) {\n        throw new IllegalArgumentException(\"input.length must be > 0 (got \" + input.length + \")\");\n      }\n      if (numOutputWords <= 0) {\n        throw new IllegalArgumentException(\"numOutputWords must be > 0 (got \" + numOutputWords + \")\");\n      }\n      if (output.length <= 0) {\n        throw new IllegalArgumentException(\"output.length must be > 0 (got \" + output.length + \")\");\n      }\n\n      assert !hasHoles(input): \"input has holes: \" + input;\n      assert !hasHoles(output): \"output has holes: \" + output;\n\n      //System.out.println(\"fmap.add input=\" + input + \" numInputWords=\" + numInputWords + \" output=\" + output + \" numOutputWords=\" + numOutputWords);\n      final int hashCode = UnicodeUtil.UTF16toUTF8WithHash(output.chars, output.offset, output.length, utf8Scratch);\n      // lookup in hash\n      int ord = words.add(utf8Scratch, hashCode);\n      if (ord < 0) {\n        // already exists in our hash\n        ord = (-ord)-1;\n        //System.out.println(\"  output=\" + output + \" old ord=\" + ord);\n      } else {\n        //System.out.println(\"  output=\" + output + \" new ord=\" + ord);\n      }\n      \n      MapEntry e = workingSet.get(input);\n      if (e == null) {\n        e = new MapEntry();\n        workingSet.put(CharsRef.deepCopyOf(input), e); // make a copy, since we will keep around in our map    \n      }\n      \n      e.ords.add(ord);\n      e.includeOrig |= includeOrig;\n      maxHorizontalContext = Math.max(maxHorizontalContext, numInputWords);\n      maxHorizontalContext = Math.max(maxHorizontalContext, numOutputWords);\n    }\n\n","sourceOld":"    // NOTE: while it's tempting to make this public, since\n    // caller's parser likely knows the\n    // numInput/numOutputWords, sneaky exceptions, much later\n    // on, will result if these values are wrong; so we always\n    // recompute ourselves to be safe:\n    private void add(CharsRef input, int numInputWords, CharsRef output, int numOutputWords, boolean includeOrig) {\n      // first convert to UTF-8\n      if (numInputWords <= 0) {\n        throw new IllegalArgumentException(\"numInputWords must be > 0 (got \" + numInputWords + \")\");\n      }\n      if (input.length <= 0) {\n        throw new IllegalArgumentException(\"input.length must be > 0 (got \" + input.length + \")\");\n      }\n      if (numOutputWords <= 0) {\n        throw new IllegalArgumentException(\"numOutputWords must be > 0 (got \" + numOutputWords + \")\");\n      }\n      if (output.length <= 0) {\n        throw new IllegalArgumentException(\"output.length must be > 0 (got \" + output.length + \")\");\n      }\n\n      assert !hasHoles(input): \"input has holes: \" + input;\n      assert !hasHoles(output): \"output has holes: \" + output;\n\n      //System.out.println(\"fmap.add input=\" + input + \" numInputWords=\" + numInputWords + \" output=\" + output + \" numOutputWords=\" + numOutputWords);\n      final int hashCode = UnicodeUtil.UTF16toUTF8WithHash(output.chars, output.offset, output.length, utf8Scratch);\n      // lookup in hash\n      int ord = words.add(utf8Scratch, hashCode);\n      if (ord < 0) {\n        // already exists in our hash\n        ord = (-ord)-1;\n        //System.out.println(\"  output=\" + output + \" old ord=\" + ord);\n      } else {\n        //System.out.println(\"  output=\" + output + \" new ord=\" + ord);\n      }\n      \n      MapEntry e = workingSet.get(input);\n      if (e == null) {\n        e = new MapEntry();\n        workingSet.put(CharsRef.deepCopyOf(input), e); // make a copy, since we will keep around in our map    \n      }\n      \n      e.ords.add(ord);\n      e.includeOrig |= includeOrig;\n      maxHorizontalContext = Math.max(maxHorizontalContext, numInputWords);\n      maxHorizontalContext = Math.max(maxHorizontalContext, numOutputWords);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"30fe9fa09df804ce770f1b667401a7a7647301ed","date":1397554534,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Builder#add(CharsRef,int,CharsRef,int,boolean).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Builder#add(CharsRef,int,CharsRef,int,boolean).mjava","sourceNew":"    // NOTE: while it's tempting to make this public, since\n    // caller's parser likely knows the\n    // numInput/numOutputWords, sneaky exceptions, much later\n    // on, will result if these values are wrong; so we always\n    // recompute ourselves to be safe:\n    private void add(CharsRef input, int numInputWords, CharsRef output, int numOutputWords, boolean includeOrig) {\n      // first convert to UTF-8\n      if (numInputWords <= 0) {\n        throw new IllegalArgumentException(\"numInputWords must be > 0 (got \" + numInputWords + \")\");\n      }\n      if (input.length <= 0) {\n        throw new IllegalArgumentException(\"input.length must be > 0 (got \" + input.length + \")\");\n      }\n      if (numOutputWords <= 0) {\n        throw new IllegalArgumentException(\"numOutputWords must be > 0 (got \" + numOutputWords + \")\");\n      }\n      if (output.length <= 0) {\n        throw new IllegalArgumentException(\"output.length must be > 0 (got \" + output.length + \")\");\n      }\n\n      assert !hasHoles(input): \"input has holes: \" + input;\n      assert !hasHoles(output): \"output has holes: \" + output;\n\n      //System.out.println(\"fmap.add input=\" + input + \" numInputWords=\" + numInputWords + \" output=\" + output + \" numOutputWords=\" + numOutputWords);\n      UnicodeUtil.UTF16toUTF8(output.chars, output.offset, output.length, utf8Scratch);\n      // lookup in hash\n      int ord = words.add(utf8Scratch);\n      if (ord < 0) {\n        // already exists in our hash\n        ord = (-ord)-1;\n        //System.out.println(\"  output=\" + output + \" old ord=\" + ord);\n      } else {\n        //System.out.println(\"  output=\" + output + \" new ord=\" + ord);\n      }\n      \n      MapEntry e = workingSet.get(input);\n      if (e == null) {\n        e = new MapEntry();\n        workingSet.put(CharsRef.deepCopyOf(input), e); // make a copy, since we will keep around in our map    \n      }\n      \n      e.ords.add(ord);\n      e.includeOrig |= includeOrig;\n      maxHorizontalContext = Math.max(maxHorizontalContext, numInputWords);\n      maxHorizontalContext = Math.max(maxHorizontalContext, numOutputWords);\n    }\n\n","sourceOld":"    // NOTE: while it's tempting to make this public, since\n    // caller's parser likely knows the\n    // numInput/numOutputWords, sneaky exceptions, much later\n    // on, will result if these values are wrong; so we always\n    // recompute ourselves to be safe:\n    private void add(CharsRef input, int numInputWords, CharsRef output, int numOutputWords, boolean includeOrig) {\n      // first convert to UTF-8\n      if (numInputWords <= 0) {\n        throw new IllegalArgumentException(\"numInputWords must be > 0 (got \" + numInputWords + \")\");\n      }\n      if (input.length <= 0) {\n        throw new IllegalArgumentException(\"input.length must be > 0 (got \" + input.length + \")\");\n      }\n      if (numOutputWords <= 0) {\n        throw new IllegalArgumentException(\"numOutputWords must be > 0 (got \" + numOutputWords + \")\");\n      }\n      if (output.length <= 0) {\n        throw new IllegalArgumentException(\"output.length must be > 0 (got \" + output.length + \")\");\n      }\n\n      assert !hasHoles(input): \"input has holes: \" + input;\n      assert !hasHoles(output): \"output has holes: \" + output;\n\n      //System.out.println(\"fmap.add input=\" + input + \" numInputWords=\" + numInputWords + \" output=\" + output + \" numOutputWords=\" + numOutputWords);\n      final int hashCode = UnicodeUtil.UTF16toUTF8WithHash(output.chars, output.offset, output.length, utf8Scratch);\n      // lookup in hash\n      int ord = words.add(utf8Scratch, hashCode);\n      if (ord < 0) {\n        // already exists in our hash\n        ord = (-ord)-1;\n        //System.out.println(\"  output=\" + output + \" old ord=\" + ord);\n      } else {\n        //System.out.println(\"  output=\" + output + \" new ord=\" + ord);\n      }\n      \n      MapEntry e = workingSet.get(input);\n      if (e == null) {\n        e = new MapEntry();\n        workingSet.put(CharsRef.deepCopyOf(input), e); // make a copy, since we will keep around in our map    \n      }\n      \n      e.ords.add(ord);\n      e.includeOrig |= includeOrig;\n      maxHorizontalContext = Math.max(maxHorizontalContext, numInputWords);\n      maxHorizontalContext = Math.max(maxHorizontalContext, numOutputWords);\n    }\n\n","bugFix":null,"bugIntro":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50","date":1407854805,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Builder#add(CharsRef,int,CharsRef,int,boolean).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Builder#add(CharsRef,int,CharsRef,int,boolean).mjava","sourceNew":"    // NOTE: while it's tempting to make this public, since\n    // caller's parser likely knows the\n    // numInput/numOutputWords, sneaky exceptions, much later\n    // on, will result if these values are wrong; so we always\n    // recompute ourselves to be safe:\n    private void add(CharsRef input, int numInputWords, CharsRef output, int numOutputWords, boolean includeOrig) {\n      // first convert to UTF-8\n      if (numInputWords <= 0) {\n        throw new IllegalArgumentException(\"numInputWords must be > 0 (got \" + numInputWords + \")\");\n      }\n      if (input.length <= 0) {\n        throw new IllegalArgumentException(\"input.length must be > 0 (got \" + input.length + \")\");\n      }\n      if (numOutputWords <= 0) {\n        throw new IllegalArgumentException(\"numOutputWords must be > 0 (got \" + numOutputWords + \")\");\n      }\n      if (output.length <= 0) {\n        throw new IllegalArgumentException(\"output.length must be > 0 (got \" + output.length + \")\");\n      }\n\n      assert !hasHoles(input): \"input has holes: \" + input;\n      assert !hasHoles(output): \"output has holes: \" + output;\n\n      //System.out.println(\"fmap.add input=\" + input + \" numInputWords=\" + numInputWords + \" output=\" + output + \" numOutputWords=\" + numOutputWords);\n      utf8Scratch.copyChars(output.chars, output.offset, output.length);\n      // lookup in hash\n      int ord = words.add(utf8Scratch.get());\n      if (ord < 0) {\n        // already exists in our hash\n        ord = (-ord)-1;\n        //System.out.println(\"  output=\" + output + \" old ord=\" + ord);\n      } else {\n        //System.out.println(\"  output=\" + output + \" new ord=\" + ord);\n      }\n      \n      MapEntry e = workingSet.get(input);\n      if (e == null) {\n        e = new MapEntry();\n        workingSet.put(CharsRef.deepCopyOf(input), e); // make a copy, since we will keep around in our map    \n      }\n      \n      e.ords.add(ord);\n      e.includeOrig |= includeOrig;\n      maxHorizontalContext = Math.max(maxHorizontalContext, numInputWords);\n      maxHorizontalContext = Math.max(maxHorizontalContext, numOutputWords);\n    }\n\n","sourceOld":"    // NOTE: while it's tempting to make this public, since\n    // caller's parser likely knows the\n    // numInput/numOutputWords, sneaky exceptions, much later\n    // on, will result if these values are wrong; so we always\n    // recompute ourselves to be safe:\n    private void add(CharsRef input, int numInputWords, CharsRef output, int numOutputWords, boolean includeOrig) {\n      // first convert to UTF-8\n      if (numInputWords <= 0) {\n        throw new IllegalArgumentException(\"numInputWords must be > 0 (got \" + numInputWords + \")\");\n      }\n      if (input.length <= 0) {\n        throw new IllegalArgumentException(\"input.length must be > 0 (got \" + input.length + \")\");\n      }\n      if (numOutputWords <= 0) {\n        throw new IllegalArgumentException(\"numOutputWords must be > 0 (got \" + numOutputWords + \")\");\n      }\n      if (output.length <= 0) {\n        throw new IllegalArgumentException(\"output.length must be > 0 (got \" + output.length + \")\");\n      }\n\n      assert !hasHoles(input): \"input has holes: \" + input;\n      assert !hasHoles(output): \"output has holes: \" + output;\n\n      //System.out.println(\"fmap.add input=\" + input + \" numInputWords=\" + numInputWords + \" output=\" + output + \" numOutputWords=\" + numOutputWords);\n      UnicodeUtil.UTF16toUTF8(output.chars, output.offset, output.length, utf8Scratch);\n      // lookup in hash\n      int ord = words.add(utf8Scratch);\n      if (ord < 0) {\n        // already exists in our hash\n        ord = (-ord)-1;\n        //System.out.println(\"  output=\" + output + \" old ord=\" + ord);\n      } else {\n        //System.out.println(\"  output=\" + output + \" new ord=\" + ord);\n      }\n      \n      MapEntry e = workingSet.get(input);\n      if (e == null) {\n        e = new MapEntry();\n        workingSet.put(CharsRef.deepCopyOf(input), e); // make a copy, since we will keep around in our map    \n      }\n      \n      e.ords.add(ord);\n      e.includeOrig |= includeOrig;\n      maxHorizontalContext = Math.max(maxHorizontalContext, numInputWords);\n      maxHorizontalContext = Math.max(maxHorizontalContext, numOutputWords);\n    }\n\n","bugFix":["30fe9fa09df804ce770f1b667401a7a7647301ed"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"30fe9fa09df804ce770f1b667401a7a7647301ed":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50":["30fe9fa09df804ce770f1b667401a7a7647301ed"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"]},"commit2Childs":{"30fe9fa09df804ce770f1b667401a7a7647301ed":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["30fe9fa09df804ce770f1b667401a7a7647301ed"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}