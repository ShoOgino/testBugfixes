{"path":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpanFirstQuery#testStartPositions().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpanFirstQuery#testStartPositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/spans/TestSpanFirstQuery#testStartPositions().mjava","sourceNew":"  public void testStartPositions() throws Exception {\n    Directory dir = newDirectory();\n    \n    // mimic StopAnalyzer\n    CharacterRunAutomaton stopSet = new CharacterRunAutomaton(new RegExp(\"the|a|of\").toAutomaton());\n    Analyzer analyzer = new MockAnalyzer(random, MockTokenizer.SIMPLE, true, stopSet, true);\n    \n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, analyzer);\n    Document doc = new Document();\n    doc.add(newField(\"field\", \"the quick brown fox\", TextField.TYPE_UNSTORED));\n    writer.addDocument(doc);\n    Document doc2 = new Document();\n    doc2.add(newField(\"field\", \"quick brown fox\", TextField.TYPE_UNSTORED));\n    writer.addDocument(doc2);\n    \n    IndexReader reader = writer.getReader();\n    IndexSearcher searcher = newSearcher(reader);\n    \n    // user queries on \"starts-with quick\"\n    SpanQuery sfq = new SpanFirstQuery(new SpanTermQuery(new Term(\"field\", \"quick\")), 1);\n    assertEquals(1, searcher.search(sfq, 10).totalHits);\n    \n    // user queries on \"starts-with the quick\"\n    SpanQuery include = new SpanFirstQuery(new SpanTermQuery(new Term(\"field\", \"quick\")), 2);\n    sfq = new SpanNotQuery(include, sfq);\n    assertEquals(1, searcher.search(sfq, 10).totalHits);\n    \n    writer.close();\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testStartPositions() throws Exception {\n    Directory dir = newDirectory();\n    \n    // mimic StopAnalyzer\n    CharacterRunAutomaton stopSet = new CharacterRunAutomaton(new RegExp(\"the|a|of\").toAutomaton());\n    Analyzer analyzer = new MockAnalyzer(random, MockTokenizer.SIMPLE, true, stopSet, true);\n    \n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, analyzer);\n    Document doc = new Document();\n    doc.add(newField(\"field\", \"the quick brown fox\", TextField.TYPE_UNSTORED));\n    writer.addDocument(doc);\n    Document doc2 = new Document();\n    doc2.add(newField(\"field\", \"quick brown fox\", TextField.TYPE_UNSTORED));\n    writer.addDocument(doc2);\n    \n    IndexReader reader = writer.getReader();\n    IndexSearcher searcher = newSearcher(reader);\n    \n    // user queries on \"starts-with quick\"\n    SpanQuery sfq = new SpanFirstQuery(new SpanTermQuery(new Term(\"field\", \"quick\")), 1);\n    assertEquals(1, searcher.search(sfq, 10).totalHits);\n    \n    // user queries on \"starts-with the quick\"\n    SpanQuery include = new SpanFirstQuery(new SpanTermQuery(new Term(\"field\", \"quick\")), 2);\n    sfq = new SpanNotQuery(include, sfq);\n    assertEquals(1, searcher.search(sfq, 10).totalHits);\n    \n    writer.close();\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpanFirstQuery#testStartPositions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpanFirstQuery#testStartPositions().mjava","sourceNew":"  public void testStartPositions() throws Exception {\n    Directory dir = newDirectory();\n    \n    // mimic StopAnalyzer\n    CharacterRunAutomaton stopSet = new CharacterRunAutomaton(new RegExp(\"the|a|of\").toAutomaton());\n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, stopSet, true);\n    \n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, analyzer);\n    Document doc = new Document();\n    doc.add(newField(\"field\", \"the quick brown fox\", TextField.TYPE_UNSTORED));\n    writer.addDocument(doc);\n    Document doc2 = new Document();\n    doc2.add(newField(\"field\", \"quick brown fox\", TextField.TYPE_UNSTORED));\n    writer.addDocument(doc2);\n    \n    IndexReader reader = writer.getReader();\n    IndexSearcher searcher = newSearcher(reader);\n    \n    // user queries on \"starts-with quick\"\n    SpanQuery sfq = new SpanFirstQuery(new SpanTermQuery(new Term(\"field\", \"quick\")), 1);\n    assertEquals(1, searcher.search(sfq, 10).totalHits);\n    \n    // user queries on \"starts-with the quick\"\n    SpanQuery include = new SpanFirstQuery(new SpanTermQuery(new Term(\"field\", \"quick\")), 2);\n    sfq = new SpanNotQuery(include, sfq);\n    assertEquals(1, searcher.search(sfq, 10).totalHits);\n    \n    writer.close();\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testStartPositions() throws Exception {\n    Directory dir = newDirectory();\n    \n    // mimic StopAnalyzer\n    CharacterRunAutomaton stopSet = new CharacterRunAutomaton(new RegExp(\"the|a|of\").toAutomaton());\n    Analyzer analyzer = new MockAnalyzer(random, MockTokenizer.SIMPLE, true, stopSet, true);\n    \n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, analyzer);\n    Document doc = new Document();\n    doc.add(newField(\"field\", \"the quick brown fox\", TextField.TYPE_UNSTORED));\n    writer.addDocument(doc);\n    Document doc2 = new Document();\n    doc2.add(newField(\"field\", \"quick brown fox\", TextField.TYPE_UNSTORED));\n    writer.addDocument(doc2);\n    \n    IndexReader reader = writer.getReader();\n    IndexSearcher searcher = newSearcher(reader);\n    \n    // user queries on \"starts-with quick\"\n    SpanQuery sfq = new SpanFirstQuery(new SpanTermQuery(new Term(\"field\", \"quick\")), 1);\n    assertEquals(1, searcher.search(sfq, 10).totalHits);\n    \n    // user queries on \"starts-with the quick\"\n    SpanQuery include = new SpanFirstQuery(new SpanTermQuery(new Term(\"field\", \"quick\")), 2);\n    sfq = new SpanNotQuery(include, sfq);\n    assertEquals(1, searcher.search(sfq, 10).totalHits);\n    \n    writer.close();\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"04f07771a2a7dd3a395700665ed839c3dae2def2","date":1339350139,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpanFirstQuery#testStartPositions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpanFirstQuery#testStartPositions().mjava","sourceNew":"  public void testStartPositions() throws Exception {\n    Directory dir = newDirectory();\n    \n    // mimic StopAnalyzer\n    CharacterRunAutomaton stopSet = new CharacterRunAutomaton(new RegExp(\"the|a|of\").toAutomaton());\n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, stopSet, true);\n    \n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, analyzer);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"the quick brown fox\", Field.Store.NO));\n    writer.addDocument(doc);\n    Document doc2 = new Document();\n    doc2.add(newTextField(\"field\", \"quick brown fox\", Field.Store.NO));\n    writer.addDocument(doc2);\n    \n    IndexReader reader = writer.getReader();\n    IndexSearcher searcher = newSearcher(reader);\n    \n    // user queries on \"starts-with quick\"\n    SpanQuery sfq = new SpanFirstQuery(new SpanTermQuery(new Term(\"field\", \"quick\")), 1);\n    assertEquals(1, searcher.search(sfq, 10).totalHits);\n    \n    // user queries on \"starts-with the quick\"\n    SpanQuery include = new SpanFirstQuery(new SpanTermQuery(new Term(\"field\", \"quick\")), 2);\n    sfq = new SpanNotQuery(include, sfq);\n    assertEquals(1, searcher.search(sfq, 10).totalHits);\n    \n    writer.close();\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testStartPositions() throws Exception {\n    Directory dir = newDirectory();\n    \n    // mimic StopAnalyzer\n    CharacterRunAutomaton stopSet = new CharacterRunAutomaton(new RegExp(\"the|a|of\").toAutomaton());\n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, stopSet, true);\n    \n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, analyzer);\n    Document doc = new Document();\n    doc.add(newField(\"field\", \"the quick brown fox\", TextField.TYPE_UNSTORED));\n    writer.addDocument(doc);\n    Document doc2 = new Document();\n    doc2.add(newField(\"field\", \"quick brown fox\", TextField.TYPE_UNSTORED));\n    writer.addDocument(doc2);\n    \n    IndexReader reader = writer.getReader();\n    IndexSearcher searcher = newSearcher(reader);\n    \n    // user queries on \"starts-with quick\"\n    SpanQuery sfq = new SpanFirstQuery(new SpanTermQuery(new Term(\"field\", \"quick\")), 1);\n    assertEquals(1, searcher.search(sfq, 10).totalHits);\n    \n    // user queries on \"starts-with the quick\"\n    SpanQuery include = new SpanFirstQuery(new SpanTermQuery(new Term(\"field\", \"quick\")), 2);\n    sfq = new SpanNotQuery(include, sfq);\n    assertEquals(1, searcher.search(sfq, 10).totalHits);\n    \n    writer.close();\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"eafa8c5eabc3dacd34680054e6a33bda024080ac","date":1367691488,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpanFirstQuery#testStartPositions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpanFirstQuery#testStartPositions().mjava","sourceNew":"  public void testStartPositions() throws Exception {\n    Directory dir = newDirectory();\n    \n    // mimic StopAnalyzer\n    CharacterRunAutomaton stopSet = new CharacterRunAutomaton(new RegExp(\"the|a|of\").toAutomaton());\n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, stopSet);\n    \n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, analyzer);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"the quick brown fox\", Field.Store.NO));\n    writer.addDocument(doc);\n    Document doc2 = new Document();\n    doc2.add(newTextField(\"field\", \"quick brown fox\", Field.Store.NO));\n    writer.addDocument(doc2);\n    \n    IndexReader reader = writer.getReader();\n    IndexSearcher searcher = newSearcher(reader);\n    \n    // user queries on \"starts-with quick\"\n    SpanQuery sfq = new SpanFirstQuery(new SpanTermQuery(new Term(\"field\", \"quick\")), 1);\n    assertEquals(1, searcher.search(sfq, 10).totalHits);\n    \n    // user queries on \"starts-with the quick\"\n    SpanQuery include = new SpanFirstQuery(new SpanTermQuery(new Term(\"field\", \"quick\")), 2);\n    sfq = new SpanNotQuery(include, sfq);\n    assertEquals(1, searcher.search(sfq, 10).totalHits);\n    \n    writer.close();\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testStartPositions() throws Exception {\n    Directory dir = newDirectory();\n    \n    // mimic StopAnalyzer\n    CharacterRunAutomaton stopSet = new CharacterRunAutomaton(new RegExp(\"the|a|of\").toAutomaton());\n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, stopSet, true);\n    \n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, analyzer);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"the quick brown fox\", Field.Store.NO));\n    writer.addDocument(doc);\n    Document doc2 = new Document();\n    doc2.add(newTextField(\"field\", \"quick brown fox\", Field.Store.NO));\n    writer.addDocument(doc2);\n    \n    IndexReader reader = writer.getReader();\n    IndexSearcher searcher = newSearcher(reader);\n    \n    // user queries on \"starts-with quick\"\n    SpanQuery sfq = new SpanFirstQuery(new SpanTermQuery(new Term(\"field\", \"quick\")), 1);\n    assertEquals(1, searcher.search(sfq, 10).totalHits);\n    \n    // user queries on \"starts-with the quick\"\n    SpanQuery include = new SpanFirstQuery(new SpanTermQuery(new Term(\"field\", \"quick\")), 2);\n    sfq = new SpanNotQuery(include, sfq);\n    assertEquals(1, searcher.search(sfq, 10).totalHits);\n    \n    writer.close();\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpanFirstQuery#testStartPositions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpanFirstQuery#testStartPositions().mjava","sourceNew":"  public void testStartPositions() throws Exception {\n    Directory dir = newDirectory();\n    \n    // mimic StopAnalyzer\n    CharacterRunAutomaton stopSet = new CharacterRunAutomaton(new RegExp(\"the|a|of\").toAutomaton());\n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, stopSet);\n    \n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, analyzer);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"the quick brown fox\", Field.Store.NO));\n    writer.addDocument(doc);\n    Document doc2 = new Document();\n    doc2.add(newTextField(\"field\", \"quick brown fox\", Field.Store.NO));\n    writer.addDocument(doc2);\n    \n    IndexReader reader = writer.getReader();\n    IndexSearcher searcher = newSearcher(reader);\n    \n    // user queries on \"starts-with quick\"\n    SpanQuery sfq = new SpanFirstQuery(new SpanTermQuery(new Term(\"field\", \"quick\")), 1);\n    assertEquals(1, searcher.search(sfq, 10).totalHits);\n    \n    // user queries on \"starts-with the quick\"\n    SpanQuery include = new SpanFirstQuery(new SpanTermQuery(new Term(\"field\", \"quick\")), 2);\n    sfq = new SpanNotQuery(include, sfq);\n    assertEquals(1, searcher.search(sfq, 10).totalHits);\n    \n    writer.shutdown();\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testStartPositions() throws Exception {\n    Directory dir = newDirectory();\n    \n    // mimic StopAnalyzer\n    CharacterRunAutomaton stopSet = new CharacterRunAutomaton(new RegExp(\"the|a|of\").toAutomaton());\n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, stopSet);\n    \n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, analyzer);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"the quick brown fox\", Field.Store.NO));\n    writer.addDocument(doc);\n    Document doc2 = new Document();\n    doc2.add(newTextField(\"field\", \"quick brown fox\", Field.Store.NO));\n    writer.addDocument(doc2);\n    \n    IndexReader reader = writer.getReader();\n    IndexSearcher searcher = newSearcher(reader);\n    \n    // user queries on \"starts-with quick\"\n    SpanQuery sfq = new SpanFirstQuery(new SpanTermQuery(new Term(\"field\", \"quick\")), 1);\n    assertEquals(1, searcher.search(sfq, 10).totalHits);\n    \n    // user queries on \"starts-with the quick\"\n    SpanQuery include = new SpanFirstQuery(new SpanTermQuery(new Term(\"field\", \"quick\")), 2);\n    sfq = new SpanNotQuery(include, sfq);\n    assertEquals(1, searcher.search(sfq, 10).totalHits);\n    \n    writer.close();\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ac34f0c5bb9274821fb0cb18075234e02002e9bf","date":1402508126,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpanFirstQuery#testStartPositions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpanFirstQuery#testStartPositions().mjava","sourceNew":"  public void testStartPositions() throws Exception {\n    Directory dir = newDirectory();\n    \n    // mimic StopAnalyzer\n    CharacterRunAutomaton stopSet = new CharacterRunAutomaton(new RegExp(\"the|a|of\").toLightAutomaton());\n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, stopSet);\n    \n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, analyzer);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"the quick brown fox\", Field.Store.NO));\n    writer.addDocument(doc);\n    Document doc2 = new Document();\n    doc2.add(newTextField(\"field\", \"quick brown fox\", Field.Store.NO));\n    writer.addDocument(doc2);\n    \n    IndexReader reader = writer.getReader();\n    IndexSearcher searcher = newSearcher(reader);\n    \n    // user queries on \"starts-with quick\"\n    SpanQuery sfq = new SpanFirstQuery(new SpanTermQuery(new Term(\"field\", \"quick\")), 1);\n    assertEquals(1, searcher.search(sfq, 10).totalHits);\n    \n    // user queries on \"starts-with the quick\"\n    SpanQuery include = new SpanFirstQuery(new SpanTermQuery(new Term(\"field\", \"quick\")), 2);\n    sfq = new SpanNotQuery(include, sfq);\n    assertEquals(1, searcher.search(sfq, 10).totalHits);\n    \n    writer.shutdown();\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testStartPositions() throws Exception {\n    Directory dir = newDirectory();\n    \n    // mimic StopAnalyzer\n    CharacterRunAutomaton stopSet = new CharacterRunAutomaton(new RegExp(\"the|a|of\").toAutomaton());\n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, stopSet);\n    \n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, analyzer);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"the quick brown fox\", Field.Store.NO));\n    writer.addDocument(doc);\n    Document doc2 = new Document();\n    doc2.add(newTextField(\"field\", \"quick brown fox\", Field.Store.NO));\n    writer.addDocument(doc2);\n    \n    IndexReader reader = writer.getReader();\n    IndexSearcher searcher = newSearcher(reader);\n    \n    // user queries on \"starts-with quick\"\n    SpanQuery sfq = new SpanFirstQuery(new SpanTermQuery(new Term(\"field\", \"quick\")), 1);\n    assertEquals(1, searcher.search(sfq, 10).totalHits);\n    \n    // user queries on \"starts-with the quick\"\n    SpanQuery include = new SpanFirstQuery(new SpanTermQuery(new Term(\"field\", \"quick\")), 2);\n    sfq = new SpanNotQuery(include, sfq);\n    assertEquals(1, searcher.search(sfq, 10).totalHits);\n    \n    writer.shutdown();\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4ca1c732df8923f5624f6c06b1dcca9e69d98c96","date":1402957391,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpanFirstQuery#testStartPositions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpanFirstQuery#testStartPositions().mjava","sourceNew":"  public void testStartPositions() throws Exception {\n    Directory dir = newDirectory();\n    \n    // mimic StopAnalyzer\n    CharacterRunAutomaton stopSet = new CharacterRunAutomaton(new RegExp(\"the|a|of\").toAutomaton());\n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, stopSet);\n    \n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, analyzer);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"the quick brown fox\", Field.Store.NO));\n    writer.addDocument(doc);\n    Document doc2 = new Document();\n    doc2.add(newTextField(\"field\", \"quick brown fox\", Field.Store.NO));\n    writer.addDocument(doc2);\n    \n    IndexReader reader = writer.getReader();\n    IndexSearcher searcher = newSearcher(reader);\n    \n    // user queries on \"starts-with quick\"\n    SpanQuery sfq = new SpanFirstQuery(new SpanTermQuery(new Term(\"field\", \"quick\")), 1);\n    assertEquals(1, searcher.search(sfq, 10).totalHits);\n    \n    // user queries on \"starts-with the quick\"\n    SpanQuery include = new SpanFirstQuery(new SpanTermQuery(new Term(\"field\", \"quick\")), 2);\n    sfq = new SpanNotQuery(include, sfq);\n    assertEquals(1, searcher.search(sfq, 10).totalHits);\n    \n    writer.shutdown();\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testStartPositions() throws Exception {\n    Directory dir = newDirectory();\n    \n    // mimic StopAnalyzer\n    CharacterRunAutomaton stopSet = new CharacterRunAutomaton(new RegExp(\"the|a|of\").toLightAutomaton());\n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, stopSet);\n    \n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, analyzer);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"the quick brown fox\", Field.Store.NO));\n    writer.addDocument(doc);\n    Document doc2 = new Document();\n    doc2.add(newTextField(\"field\", \"quick brown fox\", Field.Store.NO));\n    writer.addDocument(doc2);\n    \n    IndexReader reader = writer.getReader();\n    IndexSearcher searcher = newSearcher(reader);\n    \n    // user queries on \"starts-with quick\"\n    SpanQuery sfq = new SpanFirstQuery(new SpanTermQuery(new Term(\"field\", \"quick\")), 1);\n    assertEquals(1, searcher.search(sfq, 10).totalHits);\n    \n    // user queries on \"starts-with the quick\"\n    SpanQuery include = new SpanFirstQuery(new SpanTermQuery(new Term(\"field\", \"quick\")), 2);\n    sfq = new SpanNotQuery(include, sfq);\n    assertEquals(1, searcher.search(sfq, 10).totalHits);\n    \n    writer.shutdown();\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpanFirstQuery#testStartPositions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpanFirstQuery#testStartPositions().mjava","sourceNew":"  public void testStartPositions() throws Exception {\n    Directory dir = newDirectory();\n    \n    // mimic StopAnalyzer\n    CharacterRunAutomaton stopSet = new CharacterRunAutomaton(new RegExp(\"the|a|of\").toAutomaton());\n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, stopSet);\n    \n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, analyzer);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"the quick brown fox\", Field.Store.NO));\n    writer.addDocument(doc);\n    Document doc2 = new Document();\n    doc2.add(newTextField(\"field\", \"quick brown fox\", Field.Store.NO));\n    writer.addDocument(doc2);\n    \n    IndexReader reader = writer.getReader();\n    IndexSearcher searcher = newSearcher(reader);\n    \n    // user queries on \"starts-with quick\"\n    SpanQuery sfq = new SpanFirstQuery(new SpanTermQuery(new Term(\"field\", \"quick\")), 1);\n    assertEquals(1, searcher.search(sfq, 10).totalHits);\n    \n    // user queries on \"starts-with the quick\"\n    SpanQuery include = new SpanFirstQuery(new SpanTermQuery(new Term(\"field\", \"quick\")), 2);\n    sfq = new SpanNotQuery(include, sfq);\n    assertEquals(1, searcher.search(sfq, 10).totalHits);\n    \n    writer.close();\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testStartPositions() throws Exception {\n    Directory dir = newDirectory();\n    \n    // mimic StopAnalyzer\n    CharacterRunAutomaton stopSet = new CharacterRunAutomaton(new RegExp(\"the|a|of\").toAutomaton());\n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, stopSet);\n    \n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, analyzer);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"the quick brown fox\", Field.Store.NO));\n    writer.addDocument(doc);\n    Document doc2 = new Document();\n    doc2.add(newTextField(\"field\", \"quick brown fox\", Field.Store.NO));\n    writer.addDocument(doc2);\n    \n    IndexReader reader = writer.getReader();\n    IndexSearcher searcher = newSearcher(reader);\n    \n    // user queries on \"starts-with quick\"\n    SpanQuery sfq = new SpanFirstQuery(new SpanTermQuery(new Term(\"field\", \"quick\")), 1);\n    assertEquals(1, searcher.search(sfq, 10).totalHits);\n    \n    // user queries on \"starts-with the quick\"\n    SpanQuery include = new SpanFirstQuery(new SpanTermQuery(new Term(\"field\", \"quick\")), 2);\n    sfq = new SpanNotQuery(include, sfq);\n    assertEquals(1, searcher.search(sfq, 10).totalHits);\n    \n    writer.shutdown();\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c4f600f812447b5512daeaf8e5c9df5dbcc4a254","date":1428874774,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpanFirstQuery#testStartPositions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpanFirstQuery#testStartPositions().mjava","sourceNew":"  public void testStartPositions() throws Exception {\n    Directory dir = newDirectory();\n    \n    // mimic StopAnalyzer\n    CharacterRunAutomaton stopSet = new CharacterRunAutomaton(new RegExp(\"the|a|of\").toAutomaton());\n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, stopSet);\n    \n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, analyzer);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"the quick brown fox\", Field.Store.NO));\n    writer.addDocument(doc);\n    Document doc2 = new Document();\n    doc2.add(newTextField(\"field\", \"quick brown fox\", Field.Store.NO));\n    writer.addDocument(doc2);\n    \n    IndexReader reader = writer.getReader();\n    IndexSearcher searcher = newSearcher(reader);\n    \n    // user queries on \"starts-with quick\"\n    SpanQuery sfq = spanFirstQuery(spanTermQuery(\"field\", \"quick\"), 1);\n    assertEquals(1, searcher.search(sfq, 10).totalHits);\n    \n    // user queries on \"starts-with the quick\"\n    SpanQuery include = spanFirstQuery(spanTermQuery(\"field\", \"quick\"), 2);\n    sfq = spanNotQuery(include, sfq);\n    assertEquals(1, searcher.search(sfq, 10).totalHits);\n    \n    writer.close();\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testStartPositions() throws Exception {\n    Directory dir = newDirectory();\n    \n    // mimic StopAnalyzer\n    CharacterRunAutomaton stopSet = new CharacterRunAutomaton(new RegExp(\"the|a|of\").toAutomaton());\n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, stopSet);\n    \n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, analyzer);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"the quick brown fox\", Field.Store.NO));\n    writer.addDocument(doc);\n    Document doc2 = new Document();\n    doc2.add(newTextField(\"field\", \"quick brown fox\", Field.Store.NO));\n    writer.addDocument(doc2);\n    \n    IndexReader reader = writer.getReader();\n    IndexSearcher searcher = newSearcher(reader);\n    \n    // user queries on \"starts-with quick\"\n    SpanQuery sfq = new SpanFirstQuery(new SpanTermQuery(new Term(\"field\", \"quick\")), 1);\n    assertEquals(1, searcher.search(sfq, 10).totalHits);\n    \n    // user queries on \"starts-with the quick\"\n    SpanQuery include = new SpanFirstQuery(new SpanTermQuery(new Term(\"field\", \"quick\")), 2);\n    sfq = new SpanNotQuery(include, sfq);\n    assertEquals(1, searcher.search(sfq, 10).totalHits);\n    \n    writer.close();\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"83788ad129a5154d5c6562c4e8ce3db48793aada","date":1532961485,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpanFirstQuery#testStartPositions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpanFirstQuery#testStartPositions().mjava","sourceNew":"  public void testStartPositions() throws Exception {\n    Directory dir = newDirectory();\n    \n    // mimic StopAnalyzer\n    CharacterRunAutomaton stopSet = new CharacterRunAutomaton(new RegExp(\"the|a|of\").toAutomaton());\n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, stopSet);\n    \n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, analyzer);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"the quick brown fox\", Field.Store.NO));\n    writer.addDocument(doc);\n    Document doc2 = new Document();\n    doc2.add(newTextField(\"field\", \"quick brown fox\", Field.Store.NO));\n    writer.addDocument(doc2);\n    \n    IndexReader reader = writer.getReader();\n    IndexSearcher searcher = newSearcher(reader);\n    \n    // user queries on \"starts-with quick\"\n    SpanQuery sfq = spanFirstQuery(spanTermQuery(\"field\", \"quick\"), 1);\n    assertEquals(1, searcher.search(sfq, 10).totalHits.value);\n    \n    // user queries on \"starts-with the quick\"\n    SpanQuery include = spanFirstQuery(spanTermQuery(\"field\", \"quick\"), 2);\n    sfq = spanNotQuery(include, sfq);\n    assertEquals(1, searcher.search(sfq, 10).totalHits.value);\n    \n    writer.close();\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testStartPositions() throws Exception {\n    Directory dir = newDirectory();\n    \n    // mimic StopAnalyzer\n    CharacterRunAutomaton stopSet = new CharacterRunAutomaton(new RegExp(\"the|a|of\").toAutomaton());\n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, stopSet);\n    \n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, analyzer);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"the quick brown fox\", Field.Store.NO));\n    writer.addDocument(doc);\n    Document doc2 = new Document();\n    doc2.add(newTextField(\"field\", \"quick brown fox\", Field.Store.NO));\n    writer.addDocument(doc2);\n    \n    IndexReader reader = writer.getReader();\n    IndexSearcher searcher = newSearcher(reader);\n    \n    // user queries on \"starts-with quick\"\n    SpanQuery sfq = spanFirstQuery(spanTermQuery(\"field\", \"quick\"), 1);\n    assertEquals(1, searcher.search(sfq, 10).totalHits);\n    \n    // user queries on \"starts-with the quick\"\n    SpanQuery include = spanFirstQuery(spanTermQuery(\"field\", \"quick\"), 2);\n    sfq = spanNotQuery(include, sfq);\n    assertEquals(1, searcher.search(sfq, 10).totalHits);\n    \n    writer.close();\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"04f07771a2a7dd3a395700665ed839c3dae2def2":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"c4f600f812447b5512daeaf8e5c9df5dbcc4a254":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4ca1c732df8923f5624f6c06b1dcca9e69d98c96":["ac34f0c5bb9274821fb0cb18075234e02002e9bf"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"eafa8c5eabc3dacd34680054e6a33bda024080ac":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["eafa8c5eabc3dacd34680054e6a33bda024080ac"],"83788ad129a5154d5c6562c4e8ce3db48793aada":["c4f600f812447b5512daeaf8e5c9df5dbcc4a254"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"ac34f0c5bb9274821fb0cb18075234e02002e9bf":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["83788ad129a5154d5c6562c4e8ce3db48793aada"]},"commit2Childs":{"04f07771a2a7dd3a395700665ed839c3dae2def2":["eafa8c5eabc3dacd34680054e6a33bda024080ac"],"c4f600f812447b5512daeaf8e5c9df5dbcc4a254":["83788ad129a5154d5c6562c4e8ce3db48793aada"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"4ca1c732df8923f5624f6c06b1dcca9e69d98c96":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["c4f600f812447b5512daeaf8e5c9df5dbcc4a254"],"eafa8c5eabc3dacd34680054e6a33bda024080ac":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["d0ef034a4f10871667ae75181537775ddcf8ade4","ac34f0c5bb9274821fb0cb18075234e02002e9bf"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"83788ad129a5154d5c6562c4e8ce3db48793aada":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"ac34f0c5bb9274821fb0cb18075234e02002e9bf":["4ca1c732df8923f5624f6c06b1dcca9e69d98c96"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4ca1c732df8923f5624f6c06b1dcca9e69d98c96","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}