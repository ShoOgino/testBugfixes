{"path":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getFirstLiveDoc(AtomicReader,String,Terms).mjava","commits":[{"id":"b6912d3e0a9ef2865124c6822bc9e4cfd3581c6c","date":1329188942,"type":0,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getFirstLiveDoc(AtomicReader,String,Terms).mjava","pathOld":"/dev/null","sourceNew":"  // Just get a document with the term in it, the first one will do!\n  // Is there a better way to do this? Shouldn't actually be very costly\n  // to do it this way.\n  private static Document getFirstLiveDoc(AtomicReader reader, String fieldName, Terms terms) throws IOException {\n    DocsEnum docsEnum = null;\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef text;\n    // Deal with the chance that the first bunch of terms are in deleted documents. Is there a better way?\n    for (int idx = 0; idx < 1000 && docsEnum == null; ++idx) {\n      text = termsEnum.next();\n      if (text == null) { // Ran off the end of the terms enum without finding any live docs with that field in them.\n        return null;\n      }\n      Term term = new Term(fieldName, text);\n      docsEnum = reader.termDocsEnum(reader.getLiveDocs(),\n          term.field(),\n          new BytesRef(term.text()),\n          false);\n      if (docsEnum != null) {\n        int docId;\n        if ((docId = docsEnum.nextDoc()) != DocsEnum.NO_MORE_DOCS) {\n          return reader.document(docId);\n        }\n      }\n    }\n    return null;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["02331260bb246364779cb6f04919ca47900d01bb"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f08557cdb6c60ac7b88a9342c983a20cd236e74f","date":1330954480,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getFirstLiveDoc(AtomicReader,String,Terms).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getFirstLiveDoc(AtomicReader,String,Terms).mjava","sourceNew":"  // Just get a document with the term in it, the first one will do!\n  // Is there a better way to do this? Shouldn't actually be very costly\n  // to do it this way.\n  private static Document getFirstLiveDoc(AtomicReader reader, String fieldName, Terms terms) throws IOException {\n    DocsEnum docsEnum = null;\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef text;\n    // Deal with the chance that the first bunch of terms are in deleted documents. Is there a better way?\n    for (int idx = 0; idx < 1000 && docsEnum == null; ++idx) {\n      text = termsEnum.next();\n      if (text == null) { // Ran off the end of the terms enum without finding any live docs with that field in them.\n        return null;\n      }\n      Term term = new Term(fieldName, text);\n      docsEnum = reader.termDocsEnum(reader.getLiveDocs(),\n          term.field(),\n          new BytesRef(term.text()),\n          false);\n      if (docsEnum != null) {\n        int docId;\n        if ((docId = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          return reader.document(docId);\n        }\n      }\n    }\n    return null;\n  }\n\n","sourceOld":"  // Just get a document with the term in it, the first one will do!\n  // Is there a better way to do this? Shouldn't actually be very costly\n  // to do it this way.\n  private static Document getFirstLiveDoc(AtomicReader reader, String fieldName, Terms terms) throws IOException {\n    DocsEnum docsEnum = null;\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef text;\n    // Deal with the chance that the first bunch of terms are in deleted documents. Is there a better way?\n    for (int idx = 0; idx < 1000 && docsEnum == null; ++idx) {\n      text = termsEnum.next();\n      if (text == null) { // Ran off the end of the terms enum without finding any live docs with that field in them.\n        return null;\n      }\n      Term term = new Term(fieldName, text);\n      docsEnum = reader.termDocsEnum(reader.getLiveDocs(),\n          term.field(),\n          new BytesRef(term.text()),\n          false);\n      if (docsEnum != null) {\n        int docId;\n        if ((docId = docsEnum.nextDoc()) != DocsEnum.NO_MORE_DOCS) {\n          return reader.document(docId);\n        }\n      }\n    }\n    return null;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","date":1331075828,"type":3,"author":"Ryan McKinley","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getFirstLiveDoc(AtomicReader,String,Terms).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getFirstLiveDoc(AtomicReader,String,Terms).mjava","sourceNew":"  // Just get a document with the term in it, the first one will do!\n  // Is there a better way to do this? Shouldn't actually be very costly\n  // to do it this way.\n  private static Document getFirstLiveDoc(AtomicReader reader, String fieldName, Terms terms) throws IOException {\n    DocsEnum docsEnum = null;\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef text;\n    // Deal with the chance that the first bunch of terms are in deleted documents. Is there a better way?\n    for (int idx = 0; idx < 1000 && docsEnum == null; ++idx) {\n      text = termsEnum.next();\n      if (text == null) { // Ran off the end of the terms enum without finding any live docs with that field in them.\n        return null;\n      }\n      Term term = new Term(fieldName, text);\n      docsEnum = reader.termDocsEnum(reader.getLiveDocs(),\n          term.field(),\n          new BytesRef(term.text()),\n          false);\n      if (docsEnum != null) {\n        int docId;\n        if ((docId = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          return reader.document(docId);\n        }\n      }\n    }\n    return null;\n  }\n\n","sourceOld":"  // Just get a document with the term in it, the first one will do!\n  // Is there a better way to do this? Shouldn't actually be very costly\n  // to do it this way.\n  private static Document getFirstLiveDoc(AtomicReader reader, String fieldName, Terms terms) throws IOException {\n    DocsEnum docsEnum = null;\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef text;\n    // Deal with the chance that the first bunch of terms are in deleted documents. Is there a better way?\n    for (int idx = 0; idx < 1000 && docsEnum == null; ++idx) {\n      text = termsEnum.next();\n      if (text == null) { // Ran off the end of the terms enum without finding any live docs with that field in them.\n        return null;\n      }\n      Term term = new Term(fieldName, text);\n      docsEnum = reader.termDocsEnum(reader.getLiveDocs(),\n          term.field(),\n          new BytesRef(term.text()),\n          false);\n      if (docsEnum != null) {\n        int docId;\n        if ((docId = docsEnum.nextDoc()) != DocsEnum.NO_MORE_DOCS) {\n          return reader.document(docId);\n        }\n      }\n    }\n    return null;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a7e4907084808af8fdb14b9809e6dceaccf6867b","date":1343473006,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getFirstLiveDoc(AtomicReader,String,Terms).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getFirstLiveDoc(AtomicReader,String,Terms).mjava","sourceNew":"  // Just get a document with the term in it, the first one will do!\n  // Is there a better way to do this? Shouldn't actually be very costly\n  // to do it this way.\n  private static StoredDocument getFirstLiveDoc(AtomicReader reader, String fieldName, Terms terms) throws IOException {\n    DocsEnum docsEnum = null;\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef text;\n    // Deal with the chance that the first bunch of terms are in deleted documents. Is there a better way?\n    for (int idx = 0; idx < 1000 && docsEnum == null; ++idx) {\n      text = termsEnum.next();\n      if (text == null) { // Ran off the end of the terms enum without finding any live docs with that field in them.\n        return null;\n      }\n      Term term = new Term(fieldName, text);\n      docsEnum = reader.termDocsEnum(reader.getLiveDocs(),\n          term.field(),\n          new BytesRef(term.text()),\n          false);\n      if (docsEnum != null) {\n        int docId;\n        if ((docId = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          return reader.document(docId);\n        }\n      }\n    }\n    return null;\n  }\n\n","sourceOld":"  // Just get a document with the term in it, the first one will do!\n  // Is there a better way to do this? Shouldn't actually be very costly\n  // to do it this way.\n  private static Document getFirstLiveDoc(AtomicReader reader, String fieldName, Terms terms) throws IOException {\n    DocsEnum docsEnum = null;\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef text;\n    // Deal with the chance that the first bunch of terms are in deleted documents. Is there a better way?\n    for (int idx = 0; idx < 1000 && docsEnum == null; ++idx) {\n      text = termsEnum.next();\n      if (text == null) { // Ran off the end of the terms enum without finding any live docs with that field in them.\n        return null;\n      }\n      Term term = new Term(fieldName, text);\n      docsEnum = reader.termDocsEnum(reader.getLiveDocs(),\n          term.field(),\n          new BytesRef(term.text()),\n          false);\n      if (docsEnum != null) {\n        int docId;\n        if ((docId = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          return reader.document(docId);\n        }\n      }\n    }\n    return null;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"02331260bb246364779cb6f04919ca47900d01bb","date":1343749884,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getFirstLiveDoc(AtomicReader,String,Terms).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getFirstLiveDoc(AtomicReader,String,Terms).mjava","sourceNew":"  // Just get a document with the term in it, the first one will do!\n  // Is there a better way to do this? Shouldn't actually be very costly\n  // to do it this way.\n  private static Document getFirstLiveDoc(AtomicReader reader, String fieldName, Terms terms) throws IOException {\n    DocsEnum docsEnum = null;\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef text;\n    // Deal with the chance that the first bunch of terms are in deleted documents. Is there a better way?\n    for (int idx = 0; idx < 1000 && docsEnum == null; ++idx) {\n      text = termsEnum.next();\n      if (text == null) { // Ran off the end of the terms enum without finding any live docs with that field in them.\n        return null;\n      }\n      Term term = new Term(fieldName, text);\n      docsEnum = reader.termDocsEnum(reader.getLiveDocs(),\n          term.field(),\n          new BytesRef(term.text()),\n          0);\n      if (docsEnum != null) {\n        int docId;\n        if ((docId = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          return reader.document(docId);\n        }\n      }\n    }\n    return null;\n  }\n\n","sourceOld":"  // Just get a document with the term in it, the first one will do!\n  // Is there a better way to do this? Shouldn't actually be very costly\n  // to do it this way.\n  private static Document getFirstLiveDoc(AtomicReader reader, String fieldName, Terms terms) throws IOException {\n    DocsEnum docsEnum = null;\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef text;\n    // Deal with the chance that the first bunch of terms are in deleted documents. Is there a better way?\n    for (int idx = 0; idx < 1000 && docsEnum == null; ++idx) {\n      text = termsEnum.next();\n      if (text == null) { // Ran off the end of the terms enum without finding any live docs with that field in them.\n        return null;\n      }\n      Term term = new Term(fieldName, text);\n      docsEnum = reader.termDocsEnum(reader.getLiveDocs(),\n          term.field(),\n          new BytesRef(term.text()),\n          false);\n      if (docsEnum != null) {\n        int docId;\n        if ((docId = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          return reader.document(docId);\n        }\n      }\n    }\n    return null;\n  }\n\n","bugFix":["b6912d3e0a9ef2865124c6822bc9e4cfd3581c6c"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","date":1343768312,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getFirstLiveDoc(AtomicReader,String,Terms).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getFirstLiveDoc(AtomicReader,String,Terms).mjava","sourceNew":"  // Just get a document with the term in it, the first one will do!\n  // Is there a better way to do this? Shouldn't actually be very costly\n  // to do it this way.\n  private static Document getFirstLiveDoc(AtomicReader reader, String fieldName, Terms terms) throws IOException {\n    DocsEnum docsEnum = null;\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef text;\n    // Deal with the chance that the first bunch of terms are in deleted documents. Is there a better way?\n    for (int idx = 0; idx < 1000 && docsEnum == null; ++idx) {\n      text = termsEnum.next();\n      if (text == null) { // Ran off the end of the terms enum without finding any live docs with that field in them.\n        return null;\n      }\n      Term term = new Term(fieldName, text);\n      docsEnum = reader.termDocsEnum(reader.getLiveDocs(),\n          term.field(),\n          new BytesRef(term.text()),\n          0);\n      if (docsEnum != null) {\n        int docId;\n        if ((docId = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          return reader.document(docId);\n        }\n      }\n    }\n    return null;\n  }\n\n","sourceOld":"  // Just get a document with the term in it, the first one will do!\n  // Is there a better way to do this? Shouldn't actually be very costly\n  // to do it this way.\n  private static Document getFirstLiveDoc(AtomicReader reader, String fieldName, Terms terms) throws IOException {\n    DocsEnum docsEnum = null;\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef text;\n    // Deal with the chance that the first bunch of terms are in deleted documents. Is there a better way?\n    for (int idx = 0; idx < 1000 && docsEnum == null; ++idx) {\n      text = termsEnum.next();\n      if (text == null) { // Ran off the end of the terms enum without finding any live docs with that field in them.\n        return null;\n      }\n      Term term = new Term(fieldName, text);\n      docsEnum = reader.termDocsEnum(reader.getLiveDocs(),\n          term.field(),\n          new BytesRef(term.text()),\n          false);\n      if (docsEnum != null) {\n        int docId;\n        if ((docId = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          return reader.document(docId);\n        }\n      }\n    }\n    return null;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d6f074e73200c07d54f242d3880a8da5a35ff97b","date":1344507653,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getFirstLiveDoc(AtomicReader,String,Terms).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getFirstLiveDoc(AtomicReader,String,Terms).mjava","sourceNew":"  // Just get a document with the term in it, the first one will do!\n  // Is there a better way to do this? Shouldn't actually be very costly\n  // to do it this way.\n  private static StoredDocument getFirstLiveDoc(AtomicReader reader, String fieldName, Terms terms) throws IOException {\n    DocsEnum docsEnum = null;\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef text;\n    // Deal with the chance that the first bunch of terms are in deleted documents. Is there a better way?\n    for (int idx = 0; idx < 1000 && docsEnum == null; ++idx) {\n      text = termsEnum.next();\n      if (text == null) { // Ran off the end of the terms enum without finding any live docs with that field in them.\n        return null;\n      }\n      Term term = new Term(fieldName, text);\n      docsEnum = reader.termDocsEnum(reader.getLiveDocs(),\n          term.field(),\n          new BytesRef(term.text()),\n          0);\n      if (docsEnum != null) {\n        int docId;\n        if ((docId = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          return reader.document(docId);\n        }\n      }\n    }\n    return null;\n  }\n\n","sourceOld":"  // Just get a document with the term in it, the first one will do!\n  // Is there a better way to do this? Shouldn't actually be very costly\n  // to do it this way.\n  private static StoredDocument getFirstLiveDoc(AtomicReader reader, String fieldName, Terms terms) throws IOException {\n    DocsEnum docsEnum = null;\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef text;\n    // Deal with the chance that the first bunch of terms are in deleted documents. Is there a better way?\n    for (int idx = 0; idx < 1000 && docsEnum == null; ++idx) {\n      text = termsEnum.next();\n      if (text == null) { // Ran off the end of the terms enum without finding any live docs with that field in them.\n        return null;\n      }\n      Term term = new Term(fieldName, text);\n      docsEnum = reader.termDocsEnum(reader.getLiveDocs(),\n          term.field(),\n          new BytesRef(term.text()),\n          false);\n      if (docsEnum != null) {\n        int docId;\n        if ((docId = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          return reader.document(docId);\n        }\n      }\n    }\n    return null;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1d028314cced5858683a1bb4741423d0f934257b","date":1346596535,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getFirstLiveDoc(AtomicReader,String,Terms).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getFirstLiveDoc(AtomicReader,String,Terms).mjava","sourceNew":"  // Just get a document with the term in it, the first one will do!\n  // Is there a better way to do this? Shouldn't actually be very costly\n  // to do it this way.\n  private static StoredDocument getFirstLiveDoc(AtomicReader reader, String fieldName, Terms terms) throws IOException {\n    DocsEnum docsEnum = null;\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef text;\n    // Deal with the chance that the first bunch of terms are in deleted documents. Is there a better way?\n    for (int idx = 0; idx < 1000 && docsEnum == null; ++idx) {\n      text = termsEnum.next();\n      if (text == null) { // Ran off the end of the terms enum without finding any live docs with that field in them.\n        return null;\n      }\n      Term term = new Term(fieldName, text);\n      docsEnum = reader.termDocsEnum(reader.getLiveDocs(),\n          term.field(),\n          new BytesRef(term.text()),\n          0);\n      if (docsEnum != null) {\n        int docId;\n        if ((docId = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          return reader.document(docId);\n        }\n      }\n    }\n    return null;\n  }\n\n","sourceOld":"  // Just get a document with the term in it, the first one will do!\n  // Is there a better way to do this? Shouldn't actually be very costly\n  // to do it this way.\n  private static Document getFirstLiveDoc(AtomicReader reader, String fieldName, Terms terms) throws IOException {\n    DocsEnum docsEnum = null;\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef text;\n    // Deal with the chance that the first bunch of terms are in deleted documents. Is there a better way?\n    for (int idx = 0; idx < 1000 && docsEnum == null; ++idx) {\n      text = termsEnum.next();\n      if (text == null) { // Ran off the end of the terms enum without finding any live docs with that field in them.\n        return null;\n      }\n      Term term = new Term(fieldName, text);\n      docsEnum = reader.termDocsEnum(reader.getLiveDocs(),\n          term.field(),\n          new BytesRef(term.text()),\n          0);\n      if (docsEnum != null) {\n        int docId;\n        if ((docId = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          return reader.document(docId);\n        }\n      }\n    }\n    return null;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b6a0e3c1c21aac8ecf75706605133012833585c7","date":1347535263,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getFirstLiveDoc(Terms,AtomicReader).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getFirstLiveDoc(AtomicReader,String,Terms).mjava","sourceNew":"  // Just get a document with the term in it, the first one will do!\n  // Is there a better way to do this? Shouldn't actually be very costly\n  // to do it this way.\n  private static StoredDocument getFirstLiveDoc(Terms terms, AtomicReader reader) throws IOException {\n    DocsEnum docsEnum = null;\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef text;\n    // Deal with the chance that the first bunch of terms are in deleted documents. Is there a better way?\n    for (int idx = 0; idx < 1000 && docsEnum == null; ++idx) {\n      text = termsEnum.next();\n      if (text == null) { // Ran off the end of the terms enum without finding any live docs with that field in them.\n        return null;\n      }\n      docsEnum = termsEnum.docs(reader.getLiveDocs(), docsEnum, 0);\n      if (docsEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n        return reader.document(docsEnum.docID());\n      }\n    }\n    return null;\n  }\n\n","sourceOld":"  // Just get a document with the term in it, the first one will do!\n  // Is there a better way to do this? Shouldn't actually be very costly\n  // to do it this way.\n  private static StoredDocument getFirstLiveDoc(AtomicReader reader, String fieldName, Terms terms) throws IOException {\n    DocsEnum docsEnum = null;\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef text;\n    // Deal with the chance that the first bunch of terms are in deleted documents. Is there a better way?\n    for (int idx = 0; idx < 1000 && docsEnum == null; ++idx) {\n      text = termsEnum.next();\n      if (text == null) { // Ran off the end of the terms enum without finding any live docs with that field in them.\n        return null;\n      }\n      Term term = new Term(fieldName, text);\n      docsEnum = reader.termDocsEnum(reader.getLiveDocs(),\n          term.field(),\n          new BytesRef(term.text()),\n          0);\n      if (docsEnum != null) {\n        int docId;\n        if ((docId = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          return reader.document(docId);\n        }\n      }\n    }\n    return null;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"1d028314cced5858683a1bb4741423d0f934257b":["02331260bb246364779cb6f04919ca47900d01bb","d6f074e73200c07d54f242d3880a8da5a35ff97b"],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":["b6912d3e0a9ef2865124c6822bc9e4cfd3581c6c","f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"f08557cdb6c60ac7b88a9342c983a20cd236e74f":["b6912d3e0a9ef2865124c6822bc9e4cfd3581c6c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":["f08557cdb6c60ac7b88a9342c983a20cd236e74f","02331260bb246364779cb6f04919ca47900d01bb"],"b6a0e3c1c21aac8ecf75706605133012833585c7":["1d028314cced5858683a1bb4741423d0f934257b"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["a7e4907084808af8fdb14b9809e6dceaccf6867b","02331260bb246364779cb6f04919ca47900d01bb"],"b6912d3e0a9ef2865124c6822bc9e4cfd3581c6c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a7e4907084808af8fdb14b9809e6dceaccf6867b":["f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b6a0e3c1c21aac8ecf75706605133012833585c7"],"02331260bb246364779cb6f04919ca47900d01bb":["f08557cdb6c60ac7b88a9342c983a20cd236e74f"]},"commit2Childs":{"1d028314cced5858683a1bb4741423d0f934257b":["b6a0e3c1c21aac8ecf75706605133012833585c7"],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":[],"f08557cdb6c60ac7b88a9342c983a20cd236e74f":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","a7e4907084808af8fdb14b9809e6dceaccf6867b","02331260bb246364779cb6f04919ca47900d01bb"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b6912d3e0a9ef2865124c6822bc9e4cfd3581c6c"],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":[],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["1d028314cced5858683a1bb4741423d0f934257b"],"b6a0e3c1c21aac8ecf75706605133012833585c7":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"b6912d3e0a9ef2865124c6822bc9e4cfd3581c6c":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"a7e4907084808af8fdb14b9809e6dceaccf6867b":["d6f074e73200c07d54f242d3880a8da5a35ff97b"],"02331260bb246364779cb6f04919ca47900d01bb":["1d028314cced5858683a1bb4741423d0f934257b","b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}