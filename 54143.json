{"path":"solr/core/src/java/org/apache/solr/handler/sql/SolrTable#query(Properties,List[Map.Entry[String,Class]],String,List[Pair[String,String]],List[String],List[Pair[String,String]],String).mjava","commits":[{"id":"fa4a466195c69a11a113b33adc90f9069031e54e","date":1477605536,"type":1,"author":"Kevin Risden","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/sql/SolrTable#query(Properties,List[Map.Entry[String,Class]],String,List[Pair[String,String]],List[String],List[Pair[String,String]],String).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/sql/SolrTable#query(Properties,List[String],String,List[String],List[String],List[Pair[String,String]],String).mjava","sourceNew":"  /** Executes a Solr query on the underlying table.\n   *\n   * @param properties Connections properties\n   * @param fields List of fields to project\n   * @param query A string for the query\n   * @return Enumerator of results\n   */\n  private Enumerable<Object> query(final Properties properties, final List<Map.Entry<String, Class>> fields,\n                                   final String query, final List<Pair<String, String>> orders, final List<String> buckets,\n                                   final List<Pair<String, String>> metricPairs, final String limit) {\n    // SolrParams should be a ModifiableParams instead of a map\n    ModifiableSolrParams solrParams = new ModifiableSolrParams();\n    solrParams.add(CommonParams.OMIT_HEADER, \"true\");\n\n    if (query == null) {\n      solrParams.add(CommonParams.Q, DEFAULT_QUERY);\n    } else {\n      solrParams.add(CommonParams.Q, DEFAULT_QUERY + \" AND \" + query);\n    }\n\n    // List<String> doesn't have add so must make a new ArrayList\n    List<String> fieldsList = new ArrayList<>(fields.size());\n    fieldsList.addAll(fields.stream().map(Map.Entry::getKey).collect(Collectors.toList()));\n    List<Pair<String, String>> ordersList = new ArrayList<>(orders);\n    List<Metric> metrics = buildMetrics(metricPairs);\n    List<Bucket> bucketsList = buckets.stream().map(Bucket::new).collect(Collectors.toList());\n\n    for(int i = buckets.size()-1; i >= 0; i--) {\n      ordersList.add(0, new Pair<>(buckets.get(i), \"asc\"));\n    }\n\n    for(Metric metric : metrics) {\n      String metricIdentifier = metric.getIdentifier();\n\n      List<Pair<String, String>> newOrders= new ArrayList<>();\n      for(Pair<String, String> order : ordersList) {\n        String column = order.getKey();\n        if(!column.startsWith(metricIdentifier)) {\n          newOrders.add(order);\n        }\n      }\n      ordersList = newOrders;\n\n      if(fieldsList.contains(metricIdentifier)) {\n        fieldsList.remove(metricIdentifier);\n      }\n\n      for(String column : metric.getColumns()) {\n        if (!fieldsList.contains(column)) {\n          fieldsList.add(column);\n        }\n\n        Pair<String, String> order = new Pair<>(column, \"asc\");\n        if(!ordersList.contains(order)) {\n          ordersList.add(order);\n        }\n      }\n    }\n\n    ordersList.add(new Pair<>(DEFAULT_VERSION_FIELD, \"desc\"));\n\n    // Make sure the default sort field is in the field list\n    if (!fieldsList.contains(DEFAULT_VERSION_FIELD)) {\n      fieldsList.add(DEFAULT_VERSION_FIELD);\n    }\n\n    if(!ordersList.isEmpty()) {\n      List<String> orderList = new ArrayList<>(ordersList.size());\n      for(Pair<String, String> order : ordersList) {\n        String column = order.getKey();\n        if(!fieldsList.contains(column)) {\n          fieldsList.add(column);\n        }\n        orderList.add(column + \" \" + order.getValue());\n      }\n      solrParams.add(CommonParams.SORT, String.join(\",\", orderList));\n    }\n\n    if (fieldsList.isEmpty()) {\n      solrParams.add(CommonParams.FL, \"*\");\n    } else {\n      solrParams.add(CommonParams.FL, String.join(\",\", fieldsList));\n    }\n\n    TupleStream tupleStream;\n    String zk = properties.getProperty(\"zk\");\n    try {\n      if (metrics.isEmpty()) {\n        if (limit == null) {\n          solrParams.add(CommonParams.QT, \"/export\");\n          tupleStream = new CloudSolrStream(zk, collection, solrParams);\n        } else {\n          solrParams.add(CommonParams.ROWS, limit);\n          tupleStream = new LimitStream(new CloudSolrStream(zk, collection, solrParams), Integer.parseInt(limit));\n        }\n      } else {\n        Metric[] metricsArray = metrics.toArray(new Metric[metrics.size()]);\n        if(bucketsList.isEmpty()) {\n          solrParams.remove(CommonParams.FL);\n          solrParams.remove(CommonParams.SORT);\n          tupleStream = new StatsStream(zk, collection, solrParams, metricsArray);\n        } else {\n          solrParams.add(CommonParams.QT, \"/export\");\n          tupleStream = new CloudSolrStream(zk, collection, solrParams);\n          tupleStream = new RollupStream(tupleStream, bucketsList.toArray(new Bucket[bucketsList.size()]), metricsArray);\n\n          String sortDirection = getSortDirection(ordersList);\n\n          int numWorkers = Integer.parseInt(properties.getProperty(\"numWorkers\", \"1\"));\n          if(numWorkers > 1) {\n            String workerZkHost = properties.getProperty(\"workerZkhost\");\n            String workerCollection = properties.getProperty(\"workerCollection\");\n            // Do the rollups in parallel\n            // Maintain the sort of the Tuples coming from the workers.\n            StreamComparator comp = bucketSortComp(bucketsList, sortDirection);\n            ParallelStream parallelStream = new ParallelStream(workerZkHost, workerCollection, tupleStream, numWorkers, comp);\n\n            StreamFactory factory = new StreamFactory()\n                .withFunctionName(\"search\", CloudSolrStream.class)\n                .withFunctionName(\"parallel\", ParallelStream.class)\n                .withFunctionName(\"rollup\", RollupStream.class)\n                .withFunctionName(\"sum\", SumMetric.class)\n                .withFunctionName(\"min\", MinMetric.class)\n                .withFunctionName(\"max\", MaxMetric.class)\n                .withFunctionName(\"avg\", MeanMetric.class)\n                .withFunctionName(\"count\", CountMetric.class);\n\n            parallelStream.setStreamFactory(factory);\n            tupleStream = parallelStream;\n          }\n\n          if (!sortsEqual(bucketsList, sortDirection, ordersList)) {\n            int limitVal = limit == null ? 100 : Integer.parseInt(limit);\n            StreamComparator comp = getComp(ordersList);\n            //Rank the Tuples\n            //If parallel stream is used ALL the Rolled up tuples from the workers will be ranked\n            //Providing a true Top or Bottom.\n            tupleStream = new RankStream(tupleStream, limitVal, comp);\n          } else {\n            // Sort is the same as the same as the underlying stream\n            // Only need to limit the result, not Rank the result\n            if (limit != null) {\n              solrParams.add(CommonParams.ROWS, limit);\n              tupleStream = new LimitStream(new CloudSolrStream(zk, collection, solrParams), Integer.parseInt(limit));\n            }\n          }\n        }\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n\n    final TupleStream finalStream = tupleStream;\n\n    return new AbstractEnumerable<Object>() {\n      // Use original fields list to make sure only the fields specified are enumerated\n      public Enumerator<Object> enumerator() {\n        return new SolrEnumerator(finalStream, fields);\n      }\n    };\n  }\n\n","sourceOld":"  /** Executes a Solr query on the underlying table.\n   *\n   * @param properties Connections properties\n   * @param fields List of fields to project\n   * @param query A string for the query\n   * @return Enumerator of results\n   */\n  private Enumerable<Object> query(final Properties properties, final List<String> fields,\n                                   final String query, final List<String> order, final List<String> buckets,\n                                   final List<Pair<String, String>> metricPairs, final String limit) {\n    // SolrParams should be a ModifiableParams instead of a map\n    Map<String, String> solrParams = new HashMap<>();\n    solrParams.put(CommonParams.OMIT_HEADER, \"true\");\n\n    if (query == null) {\n      solrParams.put(CommonParams.Q, DEFAULT_QUERY);\n    } else {\n      solrParams.put(CommonParams.Q, DEFAULT_QUERY + \" AND \" + query);\n    }\n\n    // List<String> doesn't have add so must make a new ArrayList\n    List<String> fieldsList = new ArrayList<>(fields);\n    List<String> orderList = new ArrayList<>(order);\n\n    List<Metric> metrics = buildMetrics(metricPairs);\n\n    if (!metrics.isEmpty()) {\n      for(String bucket : buckets) {\n        orderList.add(bucket + \" desc\");\n      }\n\n      for(Metric metric : metrics) {\n        List<String> newOrderList = new ArrayList<>();\n        for(String orderItem : orderList) {\n          if(!orderItem.startsWith(metric.getIdentifier())) {\n            newOrderList.add(orderItem);\n          }\n        }\n        orderList = newOrderList;\n\n        for(String column : metric.getColumns()) {\n          if (!fieldsList.contains(column)) {\n            fieldsList.add(column);\n          }\n        }\n      }\n    }\n\n    if (orderList.isEmpty()) {\n      orderList.add(DEFAULT_VERSION_FIELD + \" desc\");\n\n      // Make sure the default sort field is in the field list\n      if (!fieldsList.contains(DEFAULT_VERSION_FIELD)) {\n        fieldsList.add(DEFAULT_VERSION_FIELD);\n      }\n    }\n\n    if(!orderList.isEmpty()) {\n      solrParams.put(CommonParams.SORT, String.join(\",\", orderList));\n    }\n\n    if (fieldsList.isEmpty()) {\n      solrParams.put(CommonParams.FL, \"*\");\n    } else {\n      solrParams.put(CommonParams.FL, String.join(\",\", fieldsList));\n    }\n\n    TupleStream tupleStream;\n    String zk = properties.getProperty(\"zk\");\n    try {\n      if (metrics.isEmpty()) {\n        if (limit == null) {\n          solrParams.put(CommonParams.QT, \"/export\");\n          tupleStream = new CloudSolrStream(zk, collection, solrParams);\n        } else {\n          solrParams.put(CommonParams.ROWS, limit);\n          tupleStream = new LimitStream(new CloudSolrStream(zk, collection, solrParams), Integer.parseInt(limit));\n        }\n      } else {\n        Metric[] metricsArray = metrics.toArray(new Metric[metrics.size()]);\n        if(buckets.isEmpty()) {\n          solrParams.remove(CommonParams.FL);\n          solrParams.remove(CommonParams.SORT);\n          tupleStream = new StatsStream(zk, collection, solrParams, metricsArray);\n        } else {\n          List<Bucket> bucketsList = new ArrayList<>();\n          for(String bucket : buckets) {\n            bucketsList.add(new Bucket(bucket));\n          }\n\n          solrParams.put(CommonParams.QT, \"/export\");\n          for(Metric metric : metrics) {\n            fieldsList.remove(metric.getIdentifier());\n          }\n          solrParams.put(CommonParams.FL, String.join(\",\", fieldsList));\n          tupleStream = new CloudSolrStream(zk, collection, solrParams);\n          tupleStream = new RollupStream(tupleStream, bucketsList.toArray(new Bucket[bucketsList.size()]), metricsArray);\n\n          String sortDirection = getSortDirection(orderList);\n\n          int numWorkers = Integer.parseInt(properties.getProperty(\"numWorkers\", \"1\"));\n          if(numWorkers > 1) {\n            String workerZkHost = properties.getProperty(\"workerZkhost\");\n            String workerCollection = properties.getProperty(\"workerCollection\");\n            // Do the rollups in parallel\n            // Maintain the sort of the Tuples coming from the workers.\n            StreamComparator comp = bucketSortComp(bucketsList, sortDirection);\n            ParallelStream parallelStream = new ParallelStream(workerZkHost, workerCollection, tupleStream, numWorkers, comp);\n\n            StreamFactory factory = new StreamFactory()\n                .withFunctionName(\"search\", CloudSolrStream.class)\n                .withFunctionName(\"parallel\", ParallelStream.class)\n                .withFunctionName(\"rollup\", RollupStream.class)\n                .withFunctionName(\"sum\", SumMetric.class)\n                .withFunctionName(\"min\", MinMetric.class)\n                .withFunctionName(\"max\", MaxMetric.class)\n                .withFunctionName(\"avg\", MeanMetric.class)\n                .withFunctionName(\"count\", CountMetric.class);\n\n            parallelStream.setStreamFactory(factory);\n            tupleStream = parallelStream;\n          }\n\n          if (!sortsEqual(bucketsList, sortDirection, orderList)) {\n            int limitVal = limit == null ? 100 : Integer.parseInt(limit);\n            StreamComparator comp = getComp(orderList);\n            //Rank the Tuples\n            //If parallel stream is used ALL the Rolled up tuples from the workers will be ranked\n            //Providing a true Top or Bottom.\n            tupleStream = new RankStream(tupleStream, limitVal, comp);\n          } else {\n            // Sort is the same as the same as the underlying stream\n            // Only need to limit the result, not Rank the result\n            if (limit != null) {\n              solrParams.put(CommonParams.ROWS, limit);\n              tupleStream = new LimitStream(new CloudSolrStream(zk, collection, solrParams), Integer.parseInt(limit));\n            }\n          }\n        }\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n\n    final TupleStream finalStream = tupleStream;\n\n    return new AbstractEnumerable<Object>() {\n      // Use original fields list to make sure only the fields specified are enumerated\n      public Enumerator<Object> enumerator() {\n        return new SolrEnumerator(finalStream, fields);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"612da0a0a2d5f4409da55729b9833e799f905ac5","date":1479142562,"type":3,"author":"Kevin Risden","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/sql/SolrTable#query(Properties,List[Map.Entry[String,Class]],String,List[Pair[String,String]],List[String],List[Pair[String,String]],String).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/sql/SolrTable#query(Properties,List[Map.Entry[String,Class]],String,List[Pair[String,String]],List[String],List[Pair[String,String]],String).mjava","sourceNew":"  /** Executes a Solr query on the underlying table.\n   *\n   * @param properties Connections properties\n   * @param fields List of fields to project\n   * @param query A string for the query\n   * @return Enumerator of results\n   */\n  private Enumerable<Object> query(final Properties properties, final List<Map.Entry<String, Class>> fields,\n                                   final String query, final List<Pair<String, String>> orders, final List<String> buckets,\n                                   final List<Pair<String, String>> metricPairs, final String limit) {\n    // SolrParams should be a ModifiableParams instead of a map\n    ModifiableSolrParams solrParams = new ModifiableSolrParams();\n    solrParams.add(CommonParams.OMIT_HEADER, \"true\");\n\n    if (query == null) {\n      solrParams.add(CommonParams.Q, DEFAULT_QUERY);\n    } else {\n      solrParams.add(CommonParams.Q, DEFAULT_QUERY + \" AND \" + query);\n    }\n\n    // List<String> doesn't have add so must make a new ArrayList\n    List<String> fieldsList = new ArrayList<>(fields.size());\n    fieldsList.addAll(fields.stream().map(Map.Entry::getKey).collect(Collectors.toList()));\n    LinkedHashMap<String,String> ordersMap = new LinkedHashMap<>();\n    for (Pair<String,String> order : orders) {\n      ordersMap.put(order.getKey(), order.getValue());\n    }\n    List<Metric> metrics = buildMetrics(metricPairs);\n    List<Bucket> bucketsList = buckets.stream().map(Bucket::new).collect(Collectors.toList());\n\n    for(int i = buckets.size()-1; i >= 0; i--) {\n      if (!ordersMap.containsKey(buckets.get(i))) {\n        ordersMap.put(buckets.get(i), \"asc\");\n      }\n    }\n\n    boolean isReOrder = false;\n\n    for(Metric metric : metrics) {\n      String metricIdentifier = metric.getIdentifier();\n\n      ordersMap.remove(metricIdentifier);\n\n      if(fieldsList.contains(metricIdentifier)) {\n        fieldsList.remove(metricIdentifier);\n        isReOrder = true;\n      }\n\n      for(String column : metric.getColumns()) {\n        if (!fieldsList.contains(column)) {\n          fieldsList.add(column);\n        }\n\n        if (!ordersMap.containsKey(column)) {\n          ordersMap.put(column, \"asc\");\n        }\n      }\n    }\n\n    if (ordersMap.size() < 4) {\n      ordersMap.put(DEFAULT_VERSION_FIELD, \"desc\");\n\n      // Make sure the default sort field is in the field list\n      if (!fieldsList.contains(DEFAULT_VERSION_FIELD)) {\n        fieldsList.add(DEFAULT_VERSION_FIELD);\n      }\n    }\n\n    if(!ordersMap.isEmpty()) {\n      List<String> orderList = new ArrayList<>(ordersMap.size());\n      for(Map.Entry<String, String> order : ordersMap.entrySet()) {\n        String column = order.getKey();\n        if(!fieldsList.contains(column)) {\n          fieldsList.add(column);\n        }\n        orderList.add(column + \" \" + order.getValue());\n      }\n      solrParams.add(CommonParams.SORT, String.join(\",\", orderList));\n    }\n\n    if (fieldsList.isEmpty()) {\n      solrParams.add(CommonParams.FL, \"*\");\n    } else {\n      solrParams.add(CommonParams.FL, String.join(\",\", fieldsList));\n    }\n\n    TupleStream tupleStream;\n    String zk = properties.getProperty(\"zk\");\n    try {\n      if (metrics.isEmpty() && bucketsList.isEmpty()) {\n        solrParams.add(CommonParams.QT, \"/export\");\n        if (limit != null) {\n          solrParams.add(CommonParams.ROWS, limit);\n          tupleStream = new LimitStream(new CloudSolrStream(zk, collection, solrParams), Integer.parseInt(limit));\n        } else {\n          tupleStream = new CloudSolrStream(zk, collection, solrParams);\n        }\n      } else {\n        Metric[] metricsArray = metrics.toArray(new Metric[metrics.size()]);\n        if(bucketsList.isEmpty()) {\n          solrParams.remove(CommonParams.FL);\n          solrParams.remove(CommonParams.SORT);\n          tupleStream = new StatsStream(zk, collection, solrParams, metricsArray);\n        } else {\n          solrParams.add(CommonParams.QT, \"/export\");\n\n          int numWorkers = Integer.parseInt(properties.getProperty(\"numWorkers\", \"1\"));\n          if (numWorkers > 1) solrParams.add(\"partitionKeys\",String.join(\",\", buckets));\n\n          tupleStream = new CloudSolrStream(zk, collection, solrParams);\n          tupleStream = new RollupStream(tupleStream, bucketsList.toArray(new Bucket[bucketsList.size()]), metricsArray);\n\n          if(numWorkers > 1) {\n            String workerZkHost = properties.getProperty(\"workerZkhost\");\n            String workerCollection = properties.getProperty(\"workerCollection\");\n            // Do the rollups in parallel\n            // Maintain the sort of the Tuples coming from the workers.\n            StreamComparator comp = bucketSortComp(bucketsList, ordersMap);\n\n            ParallelStream parallelStream = new ParallelStream(workerZkHost, workerCollection, tupleStream, numWorkers, comp);\n\n            StreamFactory factory = new StreamFactory()\n                .withFunctionName(\"search\", CloudSolrStream.class)\n                .withFunctionName(\"parallel\", ParallelStream.class)\n                .withFunctionName(\"rollup\", RollupStream.class)\n                .withFunctionName(\"sum\", SumMetric.class)\n                .withFunctionName(\"min\", MinMetric.class)\n                .withFunctionName(\"max\", MaxMetric.class)\n                .withFunctionName(\"avg\", MeanMetric.class)\n                .withFunctionName(\"count\", CountMetric.class);\n\n            parallelStream.setStreamFactory(factory);\n            tupleStream = parallelStream;\n            isReOrder = true;\n          }\n\n          if (isReOrder) {\n            int limitVal = limit == null ? 100 : Integer.parseInt(limit);\n            StreamComparator comp = getComp(orders);\n            if (orders.isEmpty() && !ordersMap.isEmpty()) {\n              // default order\n              comp = getComp(new ArrayList<>(ordersMap.entrySet()));\n            }\n            tupleStream = new RankStream(tupleStream, limitVal, comp);\n          } else {\n            // Sort is the same as the same as the underlying stream\n            // Only need to limit the result, not Rank the result\n            if (limit != null) {\n              solrParams.add(CommonParams.ROWS, limit);\n              tupleStream = new LimitStream(new CloudSolrStream(zk, collection, solrParams), Integer.parseInt(limit));\n            }\n          }\n        }\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n\n    final TupleStream finalStream = tupleStream;\n\n    return new AbstractEnumerable<Object>() {\n      // Use original fields list to make sure only the fields specified are enumerated\n      public Enumerator<Object> enumerator() {\n        return new SolrEnumerator(finalStream, fields);\n      }\n    };\n  }\n\n","sourceOld":"  /** Executes a Solr query on the underlying table.\n   *\n   * @param properties Connections properties\n   * @param fields List of fields to project\n   * @param query A string for the query\n   * @return Enumerator of results\n   */\n  private Enumerable<Object> query(final Properties properties, final List<Map.Entry<String, Class>> fields,\n                                   final String query, final List<Pair<String, String>> orders, final List<String> buckets,\n                                   final List<Pair<String, String>> metricPairs, final String limit) {\n    // SolrParams should be a ModifiableParams instead of a map\n    ModifiableSolrParams solrParams = new ModifiableSolrParams();\n    solrParams.add(CommonParams.OMIT_HEADER, \"true\");\n\n    if (query == null) {\n      solrParams.add(CommonParams.Q, DEFAULT_QUERY);\n    } else {\n      solrParams.add(CommonParams.Q, DEFAULT_QUERY + \" AND \" + query);\n    }\n\n    // List<String> doesn't have add so must make a new ArrayList\n    List<String> fieldsList = new ArrayList<>(fields.size());\n    fieldsList.addAll(fields.stream().map(Map.Entry::getKey).collect(Collectors.toList()));\n    List<Pair<String, String>> ordersList = new ArrayList<>(orders);\n    List<Metric> metrics = buildMetrics(metricPairs);\n    List<Bucket> bucketsList = buckets.stream().map(Bucket::new).collect(Collectors.toList());\n\n    for(int i = buckets.size()-1; i >= 0; i--) {\n      ordersList.add(0, new Pair<>(buckets.get(i), \"asc\"));\n    }\n\n    for(Metric metric : metrics) {\n      String metricIdentifier = metric.getIdentifier();\n\n      List<Pair<String, String>> newOrders= new ArrayList<>();\n      for(Pair<String, String> order : ordersList) {\n        String column = order.getKey();\n        if(!column.startsWith(metricIdentifier)) {\n          newOrders.add(order);\n        }\n      }\n      ordersList = newOrders;\n\n      if(fieldsList.contains(metricIdentifier)) {\n        fieldsList.remove(metricIdentifier);\n      }\n\n      for(String column : metric.getColumns()) {\n        if (!fieldsList.contains(column)) {\n          fieldsList.add(column);\n        }\n\n        Pair<String, String> order = new Pair<>(column, \"asc\");\n        if(!ordersList.contains(order)) {\n          ordersList.add(order);\n        }\n      }\n    }\n\n    ordersList.add(new Pair<>(DEFAULT_VERSION_FIELD, \"desc\"));\n\n    // Make sure the default sort field is in the field list\n    if (!fieldsList.contains(DEFAULT_VERSION_FIELD)) {\n      fieldsList.add(DEFAULT_VERSION_FIELD);\n    }\n\n    if(!ordersList.isEmpty()) {\n      List<String> orderList = new ArrayList<>(ordersList.size());\n      for(Pair<String, String> order : ordersList) {\n        String column = order.getKey();\n        if(!fieldsList.contains(column)) {\n          fieldsList.add(column);\n        }\n        orderList.add(column + \" \" + order.getValue());\n      }\n      solrParams.add(CommonParams.SORT, String.join(\",\", orderList));\n    }\n\n    if (fieldsList.isEmpty()) {\n      solrParams.add(CommonParams.FL, \"*\");\n    } else {\n      solrParams.add(CommonParams.FL, String.join(\",\", fieldsList));\n    }\n\n    TupleStream tupleStream;\n    String zk = properties.getProperty(\"zk\");\n    try {\n      if (metrics.isEmpty()) {\n        if (limit == null) {\n          solrParams.add(CommonParams.QT, \"/export\");\n          tupleStream = new CloudSolrStream(zk, collection, solrParams);\n        } else {\n          solrParams.add(CommonParams.ROWS, limit);\n          tupleStream = new LimitStream(new CloudSolrStream(zk, collection, solrParams), Integer.parseInt(limit));\n        }\n      } else {\n        Metric[] metricsArray = metrics.toArray(new Metric[metrics.size()]);\n        if(bucketsList.isEmpty()) {\n          solrParams.remove(CommonParams.FL);\n          solrParams.remove(CommonParams.SORT);\n          tupleStream = new StatsStream(zk, collection, solrParams, metricsArray);\n        } else {\n          solrParams.add(CommonParams.QT, \"/export\");\n          tupleStream = new CloudSolrStream(zk, collection, solrParams);\n          tupleStream = new RollupStream(tupleStream, bucketsList.toArray(new Bucket[bucketsList.size()]), metricsArray);\n\n          String sortDirection = getSortDirection(ordersList);\n\n          int numWorkers = Integer.parseInt(properties.getProperty(\"numWorkers\", \"1\"));\n          if(numWorkers > 1) {\n            String workerZkHost = properties.getProperty(\"workerZkhost\");\n            String workerCollection = properties.getProperty(\"workerCollection\");\n            // Do the rollups in parallel\n            // Maintain the sort of the Tuples coming from the workers.\n            StreamComparator comp = bucketSortComp(bucketsList, sortDirection);\n            ParallelStream parallelStream = new ParallelStream(workerZkHost, workerCollection, tupleStream, numWorkers, comp);\n\n            StreamFactory factory = new StreamFactory()\n                .withFunctionName(\"search\", CloudSolrStream.class)\n                .withFunctionName(\"parallel\", ParallelStream.class)\n                .withFunctionName(\"rollup\", RollupStream.class)\n                .withFunctionName(\"sum\", SumMetric.class)\n                .withFunctionName(\"min\", MinMetric.class)\n                .withFunctionName(\"max\", MaxMetric.class)\n                .withFunctionName(\"avg\", MeanMetric.class)\n                .withFunctionName(\"count\", CountMetric.class);\n\n            parallelStream.setStreamFactory(factory);\n            tupleStream = parallelStream;\n          }\n\n          if (!sortsEqual(bucketsList, sortDirection, ordersList)) {\n            int limitVal = limit == null ? 100 : Integer.parseInt(limit);\n            StreamComparator comp = getComp(ordersList);\n            //Rank the Tuples\n            //If parallel stream is used ALL the Rolled up tuples from the workers will be ranked\n            //Providing a true Top or Bottom.\n            tupleStream = new RankStream(tupleStream, limitVal, comp);\n          } else {\n            // Sort is the same as the same as the underlying stream\n            // Only need to limit the result, not Rank the result\n            if (limit != null) {\n              solrParams.add(CommonParams.ROWS, limit);\n              tupleStream = new LimitStream(new CloudSolrStream(zk, collection, solrParams), Integer.parseInt(limit));\n            }\n          }\n        }\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n\n    final TupleStream finalStream = tupleStream;\n\n    return new AbstractEnumerable<Object>() {\n      // Use original fields list to make sure only the fields specified are enumerated\n      public Enumerator<Object> enumerator() {\n        return new SolrEnumerator(finalStream, fields);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"36b1ce25b5b465615c00f409ce694664abbe7bd2","date":1481836328,"type":4,"author":"Joel Bernstein","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/core/src/java/org/apache/solr/handler/sql/SolrTable#query(Properties,List[Map.Entry[String,Class]],String,List[Pair[String,String]],List[String],List[Pair[String,String]],String).mjava","sourceNew":null,"sourceOld":"  /** Executes a Solr query on the underlying table.\n   *\n   * @param properties Connections properties\n   * @param fields List of fields to project\n   * @param query A string for the query\n   * @return Enumerator of results\n   */\n  private Enumerable<Object> query(final Properties properties, final List<Map.Entry<String, Class>> fields,\n                                   final String query, final List<Pair<String, String>> orders, final List<String> buckets,\n                                   final List<Pair<String, String>> metricPairs, final String limit) {\n    // SolrParams should be a ModifiableParams instead of a map\n    ModifiableSolrParams solrParams = new ModifiableSolrParams();\n    solrParams.add(CommonParams.OMIT_HEADER, \"true\");\n\n    if (query == null) {\n      solrParams.add(CommonParams.Q, DEFAULT_QUERY);\n    } else {\n      solrParams.add(CommonParams.Q, DEFAULT_QUERY + \" AND \" + query);\n    }\n\n    // List<String> doesn't have add so must make a new ArrayList\n    List<String> fieldsList = new ArrayList<>(fields.size());\n    fieldsList.addAll(fields.stream().map(Map.Entry::getKey).collect(Collectors.toList()));\n    LinkedHashMap<String,String> ordersMap = new LinkedHashMap<>();\n    for (Pair<String,String> order : orders) {\n      ordersMap.put(order.getKey(), order.getValue());\n    }\n    List<Metric> metrics = buildMetrics(metricPairs);\n    List<Bucket> bucketsList = buckets.stream().map(Bucket::new).collect(Collectors.toList());\n\n    for(int i = buckets.size()-1; i >= 0; i--) {\n      if (!ordersMap.containsKey(buckets.get(i))) {\n        ordersMap.put(buckets.get(i), \"asc\");\n      }\n    }\n\n    boolean isReOrder = false;\n\n    for(Metric metric : metrics) {\n      String metricIdentifier = metric.getIdentifier();\n\n      ordersMap.remove(metricIdentifier);\n\n      if(fieldsList.contains(metricIdentifier)) {\n        fieldsList.remove(metricIdentifier);\n        isReOrder = true;\n      }\n\n      for(String column : metric.getColumns()) {\n        if (!fieldsList.contains(column)) {\n          fieldsList.add(column);\n        }\n\n        if (!ordersMap.containsKey(column)) {\n          ordersMap.put(column, \"asc\");\n        }\n      }\n    }\n\n    if (ordersMap.size() < 4) {\n      ordersMap.put(DEFAULT_VERSION_FIELD, \"desc\");\n\n      // Make sure the default sort field is in the field list\n      if (!fieldsList.contains(DEFAULT_VERSION_FIELD)) {\n        fieldsList.add(DEFAULT_VERSION_FIELD);\n      }\n    }\n\n    if(!ordersMap.isEmpty()) {\n      List<String> orderList = new ArrayList<>(ordersMap.size());\n      for(Map.Entry<String, String> order : ordersMap.entrySet()) {\n        String column = order.getKey();\n        if(!fieldsList.contains(column)) {\n          fieldsList.add(column);\n        }\n        orderList.add(column + \" \" + order.getValue());\n      }\n      solrParams.add(CommonParams.SORT, String.join(\",\", orderList));\n    }\n\n    if (fieldsList.isEmpty()) {\n      solrParams.add(CommonParams.FL, \"*\");\n    } else {\n      solrParams.add(CommonParams.FL, String.join(\",\", fieldsList));\n    }\n\n    TupleStream tupleStream;\n    String zk = properties.getProperty(\"zk\");\n    try {\n      if (metrics.isEmpty() && bucketsList.isEmpty()) {\n        solrParams.add(CommonParams.QT, \"/export\");\n        if (limit != null) {\n          solrParams.add(CommonParams.ROWS, limit);\n          tupleStream = new LimitStream(new CloudSolrStream(zk, collection, solrParams), Integer.parseInt(limit));\n        } else {\n          tupleStream = new CloudSolrStream(zk, collection, solrParams);\n        }\n      } else {\n        Metric[] metricsArray = metrics.toArray(new Metric[metrics.size()]);\n        if(bucketsList.isEmpty()) {\n          solrParams.remove(CommonParams.FL);\n          solrParams.remove(CommonParams.SORT);\n          tupleStream = new StatsStream(zk, collection, solrParams, metricsArray);\n        } else {\n          solrParams.add(CommonParams.QT, \"/export\");\n\n          int numWorkers = Integer.parseInt(properties.getProperty(\"numWorkers\", \"1\"));\n          if (numWorkers > 1) solrParams.add(\"partitionKeys\",String.join(\",\", buckets));\n\n          tupleStream = new CloudSolrStream(zk, collection, solrParams);\n          tupleStream = new RollupStream(tupleStream, bucketsList.toArray(new Bucket[bucketsList.size()]), metricsArray);\n\n          if(numWorkers > 1) {\n            String workerZkHost = properties.getProperty(\"workerZkhost\");\n            String workerCollection = properties.getProperty(\"workerCollection\");\n            // Do the rollups in parallel\n            // Maintain the sort of the Tuples coming from the workers.\n            StreamComparator comp = bucketSortComp(bucketsList, ordersMap);\n\n            ParallelStream parallelStream = new ParallelStream(workerZkHost, workerCollection, tupleStream, numWorkers, comp);\n\n            StreamFactory factory = new StreamFactory()\n                .withFunctionName(\"search\", CloudSolrStream.class)\n                .withFunctionName(\"parallel\", ParallelStream.class)\n                .withFunctionName(\"rollup\", RollupStream.class)\n                .withFunctionName(\"sum\", SumMetric.class)\n                .withFunctionName(\"min\", MinMetric.class)\n                .withFunctionName(\"max\", MaxMetric.class)\n                .withFunctionName(\"avg\", MeanMetric.class)\n                .withFunctionName(\"count\", CountMetric.class);\n\n            parallelStream.setStreamFactory(factory);\n            tupleStream = parallelStream;\n            isReOrder = true;\n          }\n\n          if (isReOrder) {\n            int limitVal = limit == null ? 100 : Integer.parseInt(limit);\n            StreamComparator comp = getComp(orders);\n            if (orders.isEmpty() && !ordersMap.isEmpty()) {\n              // default order\n              comp = getComp(new ArrayList<>(ordersMap.entrySet()));\n            }\n            tupleStream = new RankStream(tupleStream, limitVal, comp);\n          } else {\n            // Sort is the same as the same as the underlying stream\n            // Only need to limit the result, not Rank the result\n            if (limit != null) {\n              solrParams.add(CommonParams.ROWS, limit);\n              tupleStream = new LimitStream(new CloudSolrStream(zk, collection, solrParams), Integer.parseInt(limit));\n            }\n          }\n        }\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n\n    final TupleStream finalStream = tupleStream;\n\n    return new AbstractEnumerable<Object>() {\n      // Use original fields list to make sure only the fields specified are enumerated\n      public Enumerator<Object> enumerator() {\n        return new SolrEnumerator(finalStream, fields);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"612da0a0a2d5f4409da55729b9833e799f905ac5":["fa4a466195c69a11a113b33adc90f9069031e54e"],"fa4a466195c69a11a113b33adc90f9069031e54e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"36b1ce25b5b465615c00f409ce694664abbe7bd2":["612da0a0a2d5f4409da55729b9833e799f905ac5"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"612da0a0a2d5f4409da55729b9833e799f905ac5":["36b1ce25b5b465615c00f409ce694664abbe7bd2"],"fa4a466195c69a11a113b33adc90f9069031e54e":["612da0a0a2d5f4409da55729b9833e799f905ac5"],"36b1ce25b5b465615c00f409ce694664abbe7bd2":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["fa4a466195c69a11a113b33adc90f9069031e54e","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["36b1ce25b5b465615c00f409ce694664abbe7bd2","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}