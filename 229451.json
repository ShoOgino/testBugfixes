{"path":"solr/core/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","commits":[{"id":"c903c3d15906a3da96b8c0c2fb704491005fdbdb","date":1453508227,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","pathOld":"solr/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","sourceNew":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    Collection<Token> result = new HashSet<Token>();\n    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer(Version.LUCENE_40);\n    TokenStream ts = analyzer.tokenStream(\"\", new StringReader(origQuery));\n    // TODO: support custom attributes\n    CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n    OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n    TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n    FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n    PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n    PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n    \n    try {\n      ts.reset();\n      while (ts.incrementToken()){\n        Token tok = new Token();\n        tok.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    return result;\n  }\n\n","sourceOld":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    Collection<Token> result = new HashSet<Token>();\n    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer(Version.LUCENE_40);\n    TokenStream ts = analyzer.tokenStream(\"\", new StringReader(origQuery));\n    // TODO: support custom attributes\n    CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n    OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n    TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n    FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n    PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n    PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n    \n    try {\n      ts.reset();\n      while (ts.incrementToken()){\n        Token tok = new Token();\n        tok.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a258fbb26824fd104ed795e5d9033d2d040049ee","date":1453508252,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","pathOld":"solr/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","sourceNew":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    Collection<Token> result = new HashSet<Token>();\n    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer(Version.LUCENE_40);\n    TokenStream ts = analyzer.tokenStream(\"\", new StringReader(origQuery));\n    // TODO: support custom attributes\n    CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n    OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n    TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n    FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n    PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n    PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n    \n    try {\n      ts.reset();\n      while (ts.incrementToken()){\n        Token tok = new Token();\n        tok.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    return result;\n  }\n\n","sourceOld":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    Collection<Token> result = new HashSet<Token>();\n    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer(Version.LUCENE_40);\n    TokenStream ts = analyzer.tokenStream(\"\", new StringReader(origQuery));\n    // TODO: support custom attributes\n    CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n    OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n    TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n    FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n    PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n    PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n    \n    try {\n      ts.reset();\n      while (ts.incrementToken()){\n        Token tok = new Token();\n        tok.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":1,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","pathOld":"solr/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","sourceNew":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    Collection<Token> result = new HashSet<Token>();\n    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer(Version.LUCENE_40);\n    TokenStream ts = analyzer.tokenStream(\"\", new StringReader(origQuery));\n    // TODO: support custom attributes\n    CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n    OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n    TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n    FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n    PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n    PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n    \n    try {\n      ts.reset();\n      while (ts.incrementToken()){\n        Token tok = new Token();\n        tok.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    return result;\n  }\n\n","sourceOld":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    Collection<Token> result = new HashSet<Token>();\n    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer(Version.LUCENE_40);\n    TokenStream ts = analyzer.tokenStream(\"\", new StringReader(origQuery));\n    // TODO: support custom attributes\n    CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n    OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n    TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n    FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n    PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n    PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n    \n    try {\n      ts.reset();\n      while (ts.incrementToken()){\n        Token tok = new Token();\n        tok.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"60c9885566d6f83ba835be67d76ecbf214685052","date":1317096458,"type":3,"author":"Christopher John Male","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","pathOld":"solr/core/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","sourceNew":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    try {\n      Collection<Token> result = new HashSet<Token>();\n      WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer(Version.LUCENE_40);\n      TokenStream ts = analyzer.reusableTokenStream(\"\", new StringReader(origQuery));\n      // TODO: support custom attributes\n      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n      FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n      PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n      PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n\n      ts.reset();\n\n      while (ts.incrementToken()) {\n        Token tok = new Token();\n        tok.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n      ts.end();\n      ts.close();\n      \n      return result;\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    Collection<Token> result = new HashSet<Token>();\n    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer(Version.LUCENE_40);\n    TokenStream ts = analyzer.tokenStream(\"\", new StringReader(origQuery));\n    // TODO: support custom attributes\n    CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n    OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n    TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n    FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n    PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n    PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n    \n    try {\n      ts.reset();\n      while (ts.incrementToken()){\n        Token tok = new Token();\n        tok.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":["782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"69e043c521d4e8db770cc140c63f5ef51f03426a","date":1317187614,"type":3,"author":"Christopher John Male","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","pathOld":"solr/core/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","sourceNew":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    try {\n      Collection<Token> result = new HashSet<Token>();\n      WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer(Version.LUCENE_40);\n      TokenStream ts = analyzer.tokenStream(\"\", new StringReader(origQuery));\n      // TODO: support custom attributes\n      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n      FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n      PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n      PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n\n      ts.reset();\n\n      while (ts.incrementToken()) {\n        Token tok = new Token();\n        tok.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n      ts.end();\n      ts.close();\n      \n      return result;\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    try {\n      Collection<Token> result = new HashSet<Token>();\n      WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer(Version.LUCENE_40);\n      TokenStream ts = analyzer.reusableTokenStream(\"\", new StringReader(origQuery));\n      // TODO: support custom attributes\n      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n      FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n      PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n      PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n\n      ts.reset();\n\n      while (ts.incrementToken()) {\n        Token tok = new Token();\n        tok.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n      ts.end();\n      ts.close();\n      \n      return result;\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }\n\n","bugFix":null,"bugIntro":["c83d6c4335f31cae14f625a222bc842f20073dcd"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c83d6c4335f31cae14f625a222bc842f20073dcd","date":1373306148,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","pathOld":"solr/core/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","sourceNew":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    try {\n      Collection<Token> result = new HashSet<Token>();\n      WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer(Version.LUCENE_40);\n      TokenStream ts = analyzer.tokenStream(\"\", origQuery);\n      // TODO: support custom attributes\n      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n      FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n      PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n      PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n\n      ts.reset();\n\n      while (ts.incrementToken()) {\n        Token tok = new Token();\n        tok.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n      ts.end();\n      ts.close();\n      \n      return result;\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    try {\n      Collection<Token> result = new HashSet<Token>();\n      WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer(Version.LUCENE_40);\n      TokenStream ts = analyzer.tokenStream(\"\", new StringReader(origQuery));\n      // TODO: support custom attributes\n      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n      FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n      PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n      PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n\n      ts.reset();\n\n      while (ts.incrementToken()) {\n        Token tok = new Token();\n        tok.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n      ts.end();\n      ts.close();\n      \n      return result;\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }\n\n","bugFix":["69e043c521d4e8db770cc140c63f5ef51f03426a"],"bugIntro":["782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"37a0f60745e53927c4c876cfe5b5a58170f0646c","date":1373994005,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","pathOld":"solr/core/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","sourceNew":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    try {\n      Collection<Token> result = new HashSet<Token>();\n      WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer(Version.LUCENE_40);\n      TokenStream ts = analyzer.tokenStream(\"\", origQuery);\n      // TODO: support custom attributes\n      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n      FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n      PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n      PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n\n      ts.reset();\n\n      while (ts.incrementToken()) {\n        Token tok = new Token();\n        tok.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n      ts.end();\n      ts.close();\n      \n      return result;\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    try {\n      Collection<Token> result = new HashSet<Token>();\n      WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer(Version.LUCENE_40);\n      TokenStream ts = analyzer.tokenStream(\"\", new StringReader(origQuery));\n      // TODO: support custom attributes\n      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n      FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n      PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n      PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n\n      ts.reset();\n\n      while (ts.incrementToken()) {\n        Token tok = new Token();\n        tok.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n      ts.end();\n      ts.close();\n      \n      return result;\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"782ed6a4b4ba50ec19734fc8db4e570ee193d627","date":1381127065,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","pathOld":"solr/core/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","sourceNew":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    Collection<Token> result = new HashSet<Token>();\n    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer(Version.LUCENE_40);\n    \n    try (TokenStream ts = analyzer.tokenStream(\"\", origQuery)) {\n      // TODO: support custom attributes\n      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n      FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n      PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n      PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n\n      ts.reset();\n\n      while (ts.incrementToken()) {\n        Token tok = new Token();\n        tok.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n      ts.end();      \n      return result;\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    try {\n      Collection<Token> result = new HashSet<Token>();\n      WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer(Version.LUCENE_40);\n      TokenStream ts = analyzer.tokenStream(\"\", origQuery);\n      // TODO: support custom attributes\n      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n      FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n      PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n      PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n\n      ts.reset();\n\n      while (ts.incrementToken()) {\n        Token tok = new Token();\n        tok.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n      ts.end();\n      ts.close();\n      \n      return result;\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }\n\n","bugFix":["84b6c001c19319635b53dd80ee9fc1ba9a5b4574","60c9885566d6f83ba835be67d76ecbf214685052","c83d6c4335f31cae14f625a222bc842f20073dcd"],"bugIntro":["0bf41419d452997826ec5f17684993377be77f49"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0bf41419d452997826ec5f17684993377be77f49","date":1386629618,"type":3,"author":"Steven Rowe","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","pathOld":"solr/core/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","sourceNew":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    Collection<Token> result = new HashSet<Token>();\n    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer(LuceneTestCase.TEST_VERSION_CURRENT);\n    \n    try (TokenStream ts = analyzer.tokenStream(\"\", origQuery)) {\n      // TODO: support custom attributes\n      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n      FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n      PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n      PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n\n      ts.reset();\n\n      while (ts.incrementToken()) {\n        Token tok = new Token();\n        tok.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n      ts.end();      \n      return result;\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    Collection<Token> result = new HashSet<Token>();\n    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer(Version.LUCENE_40);\n    \n    try (TokenStream ts = analyzer.tokenStream(\"\", origQuery)) {\n      // TODO: support custom attributes\n      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n      FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n      PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n      PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n\n      ts.reset();\n\n      while (ts.incrementToken()) {\n        Token tok = new Token();\n        tok.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n      ts.end();      \n      return result;\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }\n\n","bugFix":["782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"74f45af4339b0daf7a95c820ab88c1aea74fbce0","date":1387475327,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","pathOld":"solr/core/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","sourceNew":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    Collection<Token> result = new HashSet<Token>();\n    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer(LuceneTestCase.TEST_VERSION_CURRENT);\n    \n    try (TokenStream ts = analyzer.tokenStream(\"\", origQuery)) {\n      // TODO: support custom attributes\n      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n      FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n      PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n      PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n\n      ts.reset();\n\n      while (ts.incrementToken()) {\n        Token tok = new Token();\n        tok.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n      ts.end();      \n      return result;\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    Collection<Token> result = new HashSet<Token>();\n    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer(Version.LUCENE_40);\n    \n    try (TokenStream ts = analyzer.tokenStream(\"\", origQuery)) {\n      // TODO: support custom attributes\n      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n      FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n      PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n      PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n\n      ts.reset();\n\n      while (ts.incrementToken()) {\n        Token tok = new Token();\n        tok.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n      ts.end();      \n      return result;\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","pathOld":"solr/core/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","sourceNew":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    Collection<Token> result = new HashSet<>();\n    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer(LuceneTestCase.TEST_VERSION_CURRENT);\n    \n    try (TokenStream ts = analyzer.tokenStream(\"\", origQuery)) {\n      // TODO: support custom attributes\n      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n      FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n      PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n      PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n\n      ts.reset();\n\n      while (ts.incrementToken()) {\n        Token tok = new Token();\n        tok.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n      ts.end();      \n      return result;\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    Collection<Token> result = new HashSet<Token>();\n    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer(LuceneTestCase.TEST_VERSION_CURRENT);\n    \n    try (TokenStream ts = analyzer.tokenStream(\"\", origQuery)) {\n      // TODO: support custom attributes\n      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n      FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n      PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n      PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n\n      ts.reset();\n\n      while (ts.incrementToken()) {\n        Token tok = new Token();\n        tok.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n      ts.end();      \n      return result;\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ff4227bb146f97aabae888091c19e48c88dbb0db","date":1406758576,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","pathOld":"solr/core/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","sourceNew":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    Collection<Token> result = new HashSet<>();\n    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer();\n    \n    try (TokenStream ts = analyzer.tokenStream(\"\", origQuery)) {\n      // TODO: support custom attributes\n      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n      FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n      PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n      PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n\n      ts.reset();\n\n      while (ts.incrementToken()) {\n        Token tok = new Token();\n        tok.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n      ts.end();      \n      return result;\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    Collection<Token> result = new HashSet<>();\n    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer(LuceneTestCase.TEST_VERSION_CURRENT);\n    \n    try (TokenStream ts = analyzer.tokenStream(\"\", origQuery)) {\n      // TODO: support custom attributes\n      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n      FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n      PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n      PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n\n      ts.reset();\n\n      while (ts.incrementToken()) {\n        Token tok = new Token();\n        tok.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n      ts.end();      \n      return result;\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5cdab62f058ea765dd33deb05b4f19b7d626c801","date":1406803479,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","pathOld":"solr/core/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","sourceNew":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    Collection<Token> result = new HashSet<>();\n    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer(LuceneTestCase.TEST_VERSION_CURRENT);\n    \n    try (TokenStream ts = analyzer.tokenStream(\"\", origQuery)) {\n      // TODO: support custom attributes\n      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n      FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n      PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n      PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n\n      ts.reset();\n\n      while (ts.incrementToken()) {\n        Token tok = new Token();\n        tok.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n      ts.end();      \n      return result;\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    Collection<Token> result = new HashSet<>();\n    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer();\n    \n    try (TokenStream ts = analyzer.tokenStream(\"\", origQuery)) {\n      // TODO: support custom attributes\n      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n      FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n      PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n      PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n\n      ts.reset();\n\n      while (ts.incrementToken()) {\n        Token tok = new Token();\n        tok.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n      ts.end();      \n      return result;\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"379db3ad24c4f0214f30a122265a6d6be003a99d","date":1407537768,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","pathOld":"solr/core/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","sourceNew":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    Collection<Token> result = new HashSet<>();\n    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer();\n    \n    try (TokenStream ts = analyzer.tokenStream(\"\", origQuery)) {\n      // TODO: support custom attributes\n      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n      FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n      PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n      PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n\n      ts.reset();\n\n      while (ts.incrementToken()) {\n        Token tok = new Token();\n        tok.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n      ts.end();      \n      return result;\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    Collection<Token> result = new HashSet<>();\n    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer(LuceneTestCase.TEST_VERSION_CURRENT);\n    \n    try (TokenStream ts = analyzer.tokenStream(\"\", origQuery)) {\n      // TODO: support custom attributes\n      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n      FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n      PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n      PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n\n      ts.reset();\n\n      while (ts.incrementToken()) {\n        Token tok = new Token();\n        tok.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n      ts.end();      \n      return result;\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f15af35d55d70c34451f9df5edeaeff6b31f8cbe","date":1519625627,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","pathOld":"solr/core/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","sourceNew":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    Collection<Token> result = new HashSet<>();\n\n    try (WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer(); TokenStream ts = analyzer.tokenStream(\"\", origQuery)) {\n      // TODO: support custom attributes\n      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n      FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n      PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n      PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n\n      ts.reset();\n\n      while (ts.incrementToken()) {\n        Token tok = new Token();\n        tok.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n      ts.end();      \n      return result;\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    Collection<Token> result = new HashSet<>();\n    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer();\n    \n    try (TokenStream ts = analyzer.tokenStream(\"\", origQuery)) {\n      // TODO: support custom attributes\n      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n      FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n      PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n      PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n\n      ts.reset();\n\n      while (ts.incrementToken()) {\n        Token tok = new Token();\n        tok.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n      ts.end();      \n      return result;\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"ff4227bb146f97aabae888091c19e48c88dbb0db":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["0bf41419d452997826ec5f17684993377be77f49"],"60c9885566d6f83ba835be67d76ecbf214685052":["c26f00b574427b55127e869b935845554afde1fa"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":["69e043c521d4e8db770cc140c63f5ef51f03426a","c83d6c4335f31cae14f625a222bc842f20073dcd"],"c26f00b574427b55127e869b935845554afde1fa":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"782ed6a4b4ba50ec19734fc8db4e570ee193d627":["c83d6c4335f31cae14f625a222bc842f20073dcd"],"0bf41419d452997826ec5f17684993377be77f49":["782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"c83d6c4335f31cae14f625a222bc842f20073dcd":["69e043c521d4e8db770cc140c63f5ef51f03426a"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"379db3ad24c4f0214f30a122265a6d6be003a99d":["5cdab62f058ea765dd33deb05b4f19b7d626c801"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"74f45af4339b0daf7a95c820ab88c1aea74fbce0":["782ed6a4b4ba50ec19734fc8db4e570ee193d627","0bf41419d452997826ec5f17684993377be77f49"],"a258fbb26824fd104ed795e5d9033d2d040049ee":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"f15af35d55d70c34451f9df5edeaeff6b31f8cbe":["379db3ad24c4f0214f30a122265a6d6be003a99d"],"5cdab62f058ea765dd33deb05b4f19b7d626c801":["ff4227bb146f97aabae888091c19e48c88dbb0db"],"69e043c521d4e8db770cc140c63f5ef51f03426a":["60c9885566d6f83ba835be67d76ecbf214685052"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["f15af35d55d70c34451f9df5edeaeff6b31f8cbe"]},"commit2Childs":{"ff4227bb146f97aabae888091c19e48c88dbb0db":["5cdab62f058ea765dd33deb05b4f19b7d626c801"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["ff4227bb146f97aabae888091c19e48c88dbb0db"],"60c9885566d6f83ba835be67d76ecbf214685052":["69e043c521d4e8db770cc140c63f5ef51f03426a"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":[],"c26f00b574427b55127e869b935845554afde1fa":["60c9885566d6f83ba835be67d76ecbf214685052"],"782ed6a4b4ba50ec19734fc8db4e570ee193d627":["0bf41419d452997826ec5f17684993377be77f49","74f45af4339b0daf7a95c820ab88c1aea74fbce0"],"0bf41419d452997826ec5f17684993377be77f49":["634f330c54fd3f9f491d52036dc3f40b4f4d8934","74f45af4339b0daf7a95c820ab88c1aea74fbce0"],"c83d6c4335f31cae14f625a222bc842f20073dcd":["37a0f60745e53927c4c876cfe5b5a58170f0646c","782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["c26f00b574427b55127e869b935845554afde1fa"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c26f00b574427b55127e869b935845554afde1fa","c903c3d15906a3da96b8c0c2fb704491005fdbdb","a258fbb26824fd104ed795e5d9033d2d040049ee"],"379db3ad24c4f0214f30a122265a6d6be003a99d":["f15af35d55d70c34451f9df5edeaeff6b31f8cbe"],"74f45af4339b0daf7a95c820ab88c1aea74fbce0":[],"a258fbb26824fd104ed795e5d9033d2d040049ee":[],"f15af35d55d70c34451f9df5edeaeff6b31f8cbe":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"5cdab62f058ea765dd33deb05b4f19b7d626c801":["379db3ad24c4f0214f30a122265a6d6be003a99d"],"69e043c521d4e8db770cc140c63f5ef51f03426a":["37a0f60745e53927c4c876cfe5b5a58170f0646c","c83d6c4335f31cae14f625a222bc842f20073dcd"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["37a0f60745e53927c4c876cfe5b5a58170f0646c","74f45af4339b0daf7a95c820ab88c1aea74fbce0","a258fbb26824fd104ed795e5d9033d2d040049ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}