{"path":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","commits":[{"id":"e31e6ce5848e5040d4c9ecbb25bc6ccf5d0894ac","date":1438841252,"type":1,"author":"Gregory Chanan","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    final String collectionName = message.getStr(NAME);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n        \n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.info(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<Position, String> e : positionVsNodes.entrySet()) {\n        Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getInQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        params.set(\"qt\", adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    final String collectionName = message.getStr(NAME);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n        \n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we do see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.info(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<Position, String> e : positionVsNodes.entrySet()) {\n        Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getInQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        params.set(\"qt\", adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bcf9886c8ff537aafde14de48ebf744f5673f08b","date":1439041198,"type":3,"author":"Ramkumar Aiyengar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    final String collectionName = message.getStr(NAME);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n        \n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.info(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<Position, String> e : positionVsNodes.entrySet()) {\n        Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getInQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        params.set(\"qt\", adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    final String collectionName = message.getStr(NAME);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n        \n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.info(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<Position, String> e : positionVsNodes.entrySet()) {\n        Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getInQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        params.set(\"qt\", adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8bf04c3f77a2936f29948b9c0dd215d82d43f5cf","date":1440482195,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    final String collectionName = message.getStr(NAME);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n        \n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.info(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<Position, String> e : positionVsNodes.entrySet()) {\n        Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getInQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        params.set(\"qt\", adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    final String collectionName = message.getStr(NAME);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n        \n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.info(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<Position, String> e : positionVsNodes.entrySet()) {\n        Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getInQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        params.set(\"qt\", adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3bbb741690cdafda7f1f7549c26351c912917a69","date":1453203134,"type":3,"author":"Varun Thacker","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    final String collectionName = message.getStr(NAME);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n        \n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.info(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<Position, String> e : positionVsNodes.entrySet()) {\n        Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getInQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        params.set(\"qt\", adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler, false, null, async, requestMap);\n\n      log.debug(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    final String collectionName = message.getStr(NAME);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n        \n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.info(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<Position, String> e : positionVsNodes.entrySet()) {\n        Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getInQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        params.set(\"qt\", adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":["69e6520a21709190413a63084ed135271aab1a7c","69e6520a21709190413a63084ed135271aab1a7c","69e6520a21709190413a63084ed135271aab1a7c","69e6520a21709190413a63084ed135271aab1a7c","69e6520a21709190413a63084ed135271aab1a7c","69e6520a21709190413a63084ed135271aab1a7c","69e6520a21709190413a63084ed135271aab1a7c","69e6520a21709190413a63084ed135271aab1a7c","efefd19367eebaa6d911ba8f441a30b7b7564e26"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f9362075f92dff89425ca488b480f70d565d66e7","date":1454985541,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    final String collectionName = message.getStr(NAME);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n        \n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.info(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<Position, String> e : positionVsNodes.entrySet()) {\n        Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getInQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        params.set(\"qt\", adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n\n      log.debug(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    final String collectionName = message.getStr(NAME);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n        \n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.info(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<Position, String> e : positionVsNodes.entrySet()) {\n        Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getInQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        params.set(\"qt\", adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler, false, null, async, requestMap);\n\n      log.debug(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b1197d6f54676973038ad402280d80a139dfd27b","date":1455734228,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n        \n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.info(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<Position, String> e : positionVsNodes.entrySet()) {\n        Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getInQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n\n      log.debug(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    final String collectionName = message.getStr(NAME);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n        \n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.info(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<Position, String> e : positionVsNodes.entrySet()) {\n        Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getInQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        params.set(\"qt\", adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n\n      log.debug(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"19498030e0adab22f604f935cae3c03dcf0952a6","date":1456558851,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n        \n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.info(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<Position, String> e : positionVsNodes.entrySet()) {\n        Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n\n      log.debug(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n        \n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.info(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<Position, String> e : positionVsNodes.entrySet()) {\n        Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getInQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n\n      log.debug(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f","bb222a3f9d9421d5c95afce73013fbd8de07ea1f","bb222a3f9d9421d5c95afce73013fbd8de07ea1f","bb222a3f9d9421d5c95afce73013fbd8de07ea1f","bb222a3f9d9421d5c95afce73013fbd8de07ea1f","bb222a3f9d9421d5c95afce73013fbd8de07ea1f","bb222a3f9d9421d5c95afce73013fbd8de07ea1f","bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"af2638813028b254a88b418ebeafb541afb49653","date":1456804822,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n        \n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.info(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<Position, String> e : positionVsNodes.entrySet()) {\n        Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n\n      log.debug(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n        \n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.info(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<Position, String> e : positionVsNodes.entrySet()) {\n        Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getInQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n\n      log.debug(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"efefd19367eebaa6d911ba8f441a30b7b7564e26","date":1461003590,"type":3,"author":"anshum","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n        \n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.info(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<Position, String> e : positionVsNodes.entrySet()) {\n        Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up  artifacts for failed create collection for [\" + collectionName + \"]\");\n      } else {\n        log.debug(\"Finished create command on all shards for collection: \"\n            + collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n        \n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.info(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<Position, String> e : positionVsNodes.entrySet()) {\n        Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n\n      log.debug(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":["058f5a3debcfa0ea477da3eabb4cbe2ec0fac211","3bbb741690cdafda7f1f7549c26351c912917a69","c215736a9e29403edd2132d9f0829a287b428df4","fe999fc2d95d6fea71f960bf9556858387ba21f5"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0e15955b4980562a0c1c81d08654904f3fadb83b","date":1461068916,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n        \n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.info(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<Position, String> e : positionVsNodes.entrySet()) {\n        Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up  artifacts for failed create collection for [\" + collectionName + \"]\");\n      } else {\n        log.debug(\"Finished create command on all shards for collection: \"\n            + collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n        \n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.info(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<Position, String> e : positionVsNodes.entrySet()) {\n        Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n\n      log.debug(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"115923bc88e5b1dc4bef049b1ded8486723052ed","date":1463216796,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n        \n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader);\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.info(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<Position, String> e : positionVsNodes.entrySet()) {\n        Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up  artifacts for failed create collection for [\" + collectionName + \"]\");\n      } else {\n        log.debug(\"Finished create command on all shards for collection: \"\n            + collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n        \n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.info(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<Position, String> e : positionVsNodes.entrySet()) {\n        Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up  artifacts for failed create collection for [\" + collectionName + \"]\");\n      } else {\n        log.debug(\"Finished create command on all shards for collection: \"\n            + collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":["f291d2d430e8149d24fdd06b0bcdab0941ec9144","f291d2d430e8149d24fdd06b0bcdab0941ec9144"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0ad30c6a479e764150a3316e57263319775f1df2","date":1463395403,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n        \n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader);\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.info(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<Position, String> e : positionVsNodes.entrySet()) {\n        Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up  artifacts for failed create collection for [\" + collectionName + \"]\");\n      } else {\n        log.debug(\"Finished create command on all shards for collection: \"\n            + collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n        \n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.info(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<Position, String> e : positionVsNodes.entrySet()) {\n        Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up  artifacts for failed create collection for [\" + collectionName + \"]\");\n      } else {\n        log.debug(\"Finished create command on all shards for collection: \"\n            + collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d470c8182e92b264680e34081b75e70a9f2b3c89","date":1463985353,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n        \n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader);\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.info(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<Position, String> e : positionVsNodes.entrySet()) {\n        Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up  artifacts for failed create collection for [\" + collectionName + \"]\");\n      } else {\n        log.debug(\"Finished create command on all shards for collection: \"\n            + collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n        \n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.info(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<Position, String> e : positionVsNodes.entrySet()) {\n        Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up  artifacts for failed create collection for [\" + collectionName + \"]\");\n      } else {\n        log.debug(\"Finished create command on all shards for collection: \"\n            + collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4425aa1103f1abe8e39d220f12e82b94c4f8272a","date":1467268836,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n    \n    validateConfigOrThrowSolrException(configName);\n    \n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n        \n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader);\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.info(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<Position, String> e : positionVsNodes.entrySet()) {\n        Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up  artifacts for failed create collection for [\" + collectionName + \"]\");\n      } else {\n        log.debug(\"Finished create command on all shards for collection: \"\n            + collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n        \n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader);\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.info(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<Position, String> e : positionVsNodes.entrySet()) {\n        Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up  artifacts for failed create collection for [\" + collectionName + \"]\");\n      } else {\n        log.debug(\"Finished create command on all shards for collection: \"\n            + collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"66e0b82bd39567aa2bf534e5282d05fb4a4a2c76","date":1471585465,"type":5,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<ReplicaAssigner.Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = ocmh.identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.info(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<ReplicaAssigner.Position, String> e : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up  artifacts for failed create collection for [\" + collectionName + \"]\");\n      } else {\n        log.debug(\"Finished create command on all shards for collection: \"\n            + collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n    \n    validateConfigOrThrowSolrException(configName);\n    \n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n        \n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader);\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.info(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<Position, String> e : positionVsNodes.entrySet()) {\n        Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up  artifacts for failed create collection for [\" + collectionName + \"]\");\n      } else {\n        log.debug(\"Finished create command on all shards for collection: \"\n            + collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":["ab6131420a270c49b653c969cc1dbbaf7d1b36e7","ab6131420a270c49b653c969cc1dbbaf7d1b36e7","ab6131420a270c49b653c969cc1dbbaf7d1b36e7","ab6131420a270c49b653c969cc1dbbaf7d1b36e7","ab6131420a270c49b653c969cc1dbbaf7d1b36e7","ab6131420a270c49b653c969cc1dbbaf7d1b36e7","ab6131420a270c49b653c969cc1dbbaf7d1b36e7","ab6131420a270c49b653c969cc1dbbaf7d1b36e7","5ad9c35f926b4bf8da0336d1300efc709c8d5a56","5ad9c35f926b4bf8da0336d1300efc709c8d5a56","5ad9c35f926b4bf8da0336d1300efc709c8d5a56","5ad9c35f926b4bf8da0336d1300efc709c8d5a56","5ad9c35f926b4bf8da0336d1300efc709c8d5a56","5ad9c35f926b4bf8da0336d1300efc709c8d5a56","5ad9c35f926b4bf8da0336d1300efc709c8d5a56","5ad9c35f926b4bf8da0336d1300efc709c8d5a56","69e6520a21709190413a63084ed135271aab1a7c","69e6520a21709190413a63084ed135271aab1a7c","69e6520a21709190413a63084ed135271aab1a7c","69e6520a21709190413a63084ed135271aab1a7c","69e6520a21709190413a63084ed135271aab1a7c","69e6520a21709190413a63084ed135271aab1a7c","69e6520a21709190413a63084ed135271aab1a7c","69e6520a21709190413a63084ed135271aab1a7c"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"403d05f7f8d69b65659157eff1bc1d2717f04c66","date":1471692961,"type":5,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<ReplicaAssigner.Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = ocmh.identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.info(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<ReplicaAssigner.Position, String> e : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up  artifacts for failed create collection for [\" + collectionName + \"]\");\n      } else {\n        log.debug(\"Finished create command on all shards for collection: \"\n            + collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n    \n    validateConfigOrThrowSolrException(configName);\n    \n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n        \n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader);\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.info(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<Position, String> e : positionVsNodes.entrySet()) {\n        Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up  artifacts for failed create collection for [\" + collectionName + \"]\");\n      } else {\n        log.debug(\"Finished create command on all shards for collection: \"\n            + collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":4,"author":"Kevin Risden","isMerge":true,"pathNew":"/dev/null","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":null,"sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n        \n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.info(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<Position, String> e : positionVsNodes.entrySet()) {\n        Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up  artifacts for failed create collection for [\" + collectionName + \"]\");\n      } else {\n        log.debug(\"Finished create command on all shards for collection: \"\n            + collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"af2638813028b254a88b418ebeafb541afb49653":["b1197d6f54676973038ad402280d80a139dfd27b","19498030e0adab22f604f935cae3c03dcf0952a6"],"3bbb741690cdafda7f1f7549c26351c912917a69":["8bf04c3f77a2936f29948b9c0dd215d82d43f5cf"],"efefd19367eebaa6d911ba8f441a30b7b7564e26":["af2638813028b254a88b418ebeafb541afb49653"],"403d05f7f8d69b65659157eff1bc1d2717f04c66":["4425aa1103f1abe8e39d220f12e82b94c4f8272a","66e0b82bd39567aa2bf534e5282d05fb4a4a2c76"],"0ad30c6a479e764150a3316e57263319775f1df2":["0e15955b4980562a0c1c81d08654904f3fadb83b","115923bc88e5b1dc4bef049b1ded8486723052ed"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["0e15955b4980562a0c1c81d08654904f3fadb83b","403d05f7f8d69b65659157eff1bc1d2717f04c66"],"d470c8182e92b264680e34081b75e70a9f2b3c89":["0e15955b4980562a0c1c81d08654904f3fadb83b","0ad30c6a479e764150a3316e57263319775f1df2"],"b1197d6f54676973038ad402280d80a139dfd27b":["f9362075f92dff89425ca488b480f70d565d66e7"],"e31e6ce5848e5040d4c9ecbb25bc6ccf5d0894ac":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"19498030e0adab22f604f935cae3c03dcf0952a6":["b1197d6f54676973038ad402280d80a139dfd27b"],"4425aa1103f1abe8e39d220f12e82b94c4f8272a":["d470c8182e92b264680e34081b75e70a9f2b3c89"],"115923bc88e5b1dc4bef049b1ded8486723052ed":["0e15955b4980562a0c1c81d08654904f3fadb83b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"8bf04c3f77a2936f29948b9c0dd215d82d43f5cf":["bcf9886c8ff537aafde14de48ebf744f5673f08b"],"66e0b82bd39567aa2bf534e5282d05fb4a4a2c76":["4425aa1103f1abe8e39d220f12e82b94c4f8272a"],"bcf9886c8ff537aafde14de48ebf744f5673f08b":["e31e6ce5848e5040d4c9ecbb25bc6ccf5d0894ac"],"f9362075f92dff89425ca488b480f70d565d66e7":["3bbb741690cdafda7f1f7549c26351c912917a69"],"0e15955b4980562a0c1c81d08654904f3fadb83b":["af2638813028b254a88b418ebeafb541afb49653","efefd19367eebaa6d911ba8f441a30b7b7564e26"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["403d05f7f8d69b65659157eff1bc1d2717f04c66"]},"commit2Childs":{"af2638813028b254a88b418ebeafb541afb49653":["efefd19367eebaa6d911ba8f441a30b7b7564e26","0e15955b4980562a0c1c81d08654904f3fadb83b"],"3bbb741690cdafda7f1f7549c26351c912917a69":["f9362075f92dff89425ca488b480f70d565d66e7"],"efefd19367eebaa6d911ba8f441a30b7b7564e26":["0e15955b4980562a0c1c81d08654904f3fadb83b"],"403d05f7f8d69b65659157eff1bc1d2717f04c66":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"0ad30c6a479e764150a3316e57263319775f1df2":["d470c8182e92b264680e34081b75e70a9f2b3c89"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"d470c8182e92b264680e34081b75e70a9f2b3c89":["4425aa1103f1abe8e39d220f12e82b94c4f8272a"],"b1197d6f54676973038ad402280d80a139dfd27b":["af2638813028b254a88b418ebeafb541afb49653","19498030e0adab22f604f935cae3c03dcf0952a6"],"19498030e0adab22f604f935cae3c03dcf0952a6":["af2638813028b254a88b418ebeafb541afb49653"],"e31e6ce5848e5040d4c9ecbb25bc6ccf5d0894ac":["bcf9886c8ff537aafde14de48ebf744f5673f08b"],"4425aa1103f1abe8e39d220f12e82b94c4f8272a":["403d05f7f8d69b65659157eff1bc1d2717f04c66","66e0b82bd39567aa2bf534e5282d05fb4a4a2c76"],"115923bc88e5b1dc4bef049b1ded8486723052ed":["0ad30c6a479e764150a3316e57263319775f1df2"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["e31e6ce5848e5040d4c9ecbb25bc6ccf5d0894ac"],"8bf04c3f77a2936f29948b9c0dd215d82d43f5cf":["3bbb741690cdafda7f1f7549c26351c912917a69"],"66e0b82bd39567aa2bf534e5282d05fb4a4a2c76":["403d05f7f8d69b65659157eff1bc1d2717f04c66"],"bcf9886c8ff537aafde14de48ebf744f5673f08b":["8bf04c3f77a2936f29948b9c0dd215d82d43f5cf"],"0e15955b4980562a0c1c81d08654904f3fadb83b":["0ad30c6a479e764150a3316e57263319775f1df2","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","d470c8182e92b264680e34081b75e70a9f2b3c89","115923bc88e5b1dc4bef049b1ded8486723052ed"],"f9362075f92dff89425ca488b480f70d565d66e7":["b1197d6f54676973038ad402280d80a139dfd27b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}