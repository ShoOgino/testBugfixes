{"path":"modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter#incrementToken().mjava","commits":[{"id":"b59603a30f81d2af70cd2033270521dc7c8ec626","date":1273513065,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter#incrementToken().mjava","pathOld":"solr/src/java/org/apache/solr/analysis/SynonymFilter#incrementToken().mjava","sourceNew":"  /*\n   * Need to worry about multiple scenarios:\n   *  - need to go for the longest match\n   *    a b => foo      #shouldn't match if \"a b\" is followed by \"c d\"\n   *    a b c d => bar\n   *  - need to backtrack - retry matches for tokens already read\n   *     a b c d => foo\n   *       b c => bar\n   *     If the input stream is \"a b c x\", one will consume \"a b c d\"\n   *     trying to match the first rule... all but \"a\" should be\n   *     pushed back so a match may be made on \"b c\".\n   *  - don't try and match generated tokens (thus need separate queue)\n   *    matching is not recursive.\n   *  - handle optional generation of original tokens in all these cases,\n   *    merging token streams to preserve token positions.\n   *  - preserve original positionIncrement of first matched token\n   */\n  @Override\n  public boolean incrementToken() throws IOException {\n    while (true) {\n      // if there are any generated tokens, return them... don't try any\n      // matches against them, as we specifically don't want recursion.\n      if (replacement!=null && replacement.hasNext()) {\n        copy(this, replacement.next());\n        return true;\n      }\n\n      // common case fast-path of first token not matching anything\n      AttributeSource firstTok = nextTok();\n      if (firstTok == null) return false;\n      CharTermAttribute termAtt = firstTok.addAttribute(CharTermAttribute.class);\n      SynonymMap result = map.submap!=null ? map.submap.get(termAtt.buffer(), 0, termAtt.length()) : null;\n      if (result == null) {\n        copy(this, firstTok);\n        return true;\n      }\n\n      // fast-path failed, clone ourselves if needed\n      if (firstTok == this)\n        firstTok = cloneAttributes();\n      // OK, we matched a token, so find the longest match.\n\n      matched = new LinkedList<AttributeSource>();\n\n      result = match(result);\n\n      if (result==null) {\n        // no match, simply return the first token read.\n        copy(this, firstTok);\n        return true;\n      }\n\n      // reuse, or create new one each time?\n      ArrayList<AttributeSource> generated = new ArrayList<AttributeSource>(result.synonyms.length + matched.size() + 1);\n\n      //\n      // there was a match... let's generate the new tokens, merging\n      // in the matched tokens (position increments need adjusting)\n      //\n      AttributeSource lastTok = matched.isEmpty() ? firstTok : matched.getLast();\n      boolean includeOrig = result.includeOrig();\n\n      AttributeSource origTok = includeOrig ? firstTok : null;\n      PositionIncrementAttribute firstPosIncAtt = firstTok.addAttribute(PositionIncrementAttribute.class);\n      int origPos = firstPosIncAtt.getPositionIncrement();  // position of origTok in the original stream\n      int repPos=0; // curr position in replacement token stream\n      int pos=0;  // current position in merged token stream\n\n      for (int i=0; i<result.synonyms.length; i++) {\n        Token repTok = result.synonyms[i];\n        AttributeSource newTok = firstTok.cloneAttributes();\n        CharTermAttribute newTermAtt = newTok.addAttribute(CharTermAttribute.class);\n        OffsetAttribute newOffsetAtt = newTok.addAttribute(OffsetAttribute.class);\n        PositionIncrementAttribute newPosIncAtt = newTok.addAttribute(PositionIncrementAttribute.class);\n\n        OffsetAttribute lastOffsetAtt = lastTok.addAttribute(OffsetAttribute.class);\n\n        newOffsetAtt.setOffset(newOffsetAtt.startOffset(), lastOffsetAtt.endOffset());\n        newTermAtt.copyBuffer(repTok.termBuffer(), 0, repTok.termLength());\n        repPos += repTok.getPositionIncrement();\n        if (i==0) repPos=origPos;  // make position of first token equal to original\n\n        // if necessary, insert original tokens and adjust position increment\n        while (origTok != null && origPos <= repPos) {\n          PositionIncrementAttribute origPosInc = origTok.addAttribute(PositionIncrementAttribute.class);\n          origPosInc.setPositionIncrement(origPos-pos);\n          generated.add(origTok);\n          pos += origPosInc.getPositionIncrement();\n          origTok = matched.isEmpty() ? null : matched.removeFirst();\n          if (origTok != null) {\n            origPosInc = origTok.addAttribute(PositionIncrementAttribute.class);\n            origPos += origPosInc.getPositionIncrement();\n          }\n        }\n\n        newPosIncAtt.setPositionIncrement(repPos - pos);\n        generated.add(newTok);\n        pos += newPosIncAtt.getPositionIncrement();\n      }\n\n      // finish up any leftover original tokens\n      while (origTok!=null) {\n        PositionIncrementAttribute origPosInc = origTok.addAttribute(PositionIncrementAttribute.class);\n        origPosInc.setPositionIncrement(origPos-pos);\n        generated.add(origTok);\n        pos += origPosInc.getPositionIncrement();\n        origTok = matched.isEmpty() ? null : matched.removeFirst();\n        if (origTok != null) {\n          origPosInc = origTok.addAttribute(PositionIncrementAttribute.class);\n          origPos += origPosInc.getPositionIncrement();\n        }\n      }\n\n      // what if we replaced a longer sequence with a shorter one?\n      // a/0 b/5 =>  foo/0\n      // should I re-create the gap on the next buffered token?\n\n      replacement = generated.iterator();\n      // Now return to the top of the loop to read and return the first\n      // generated token.. The reason this is done is that we may have generated\n      // nothing at all, and may need to continue with more matching logic.\n    }\n  }\n\n","sourceOld":"  /*\n   * Need to worry about multiple scenarios:\n   *  - need to go for the longest match\n   *    a b => foo      #shouldn't match if \"a b\" is followed by \"c d\"\n   *    a b c d => bar\n   *  - need to backtrack - retry matches for tokens already read\n   *     a b c d => foo\n   *       b c => bar\n   *     If the input stream is \"a b c x\", one will consume \"a b c d\"\n   *     trying to match the first rule... all but \"a\" should be\n   *     pushed back so a match may be made on \"b c\".\n   *  - don't try and match generated tokens (thus need separate queue)\n   *    matching is not recursive.\n   *  - handle optional generation of original tokens in all these cases,\n   *    merging token streams to preserve token positions.\n   *  - preserve original positionIncrement of first matched token\n   */\n  @Override\n  public boolean incrementToken() throws IOException {\n    while (true) {\n      // if there are any generated tokens, return them... don't try any\n      // matches against them, as we specifically don't want recursion.\n      if (replacement!=null && replacement.hasNext()) {\n        copy(this, replacement.next());\n        return true;\n      }\n\n      // common case fast-path of first token not matching anything\n      AttributeSource firstTok = nextTok();\n      if (firstTok == null) return false;\n      CharTermAttribute termAtt = firstTok.addAttribute(CharTermAttribute.class);\n      SynonymMap result = map.submap!=null ? map.submap.get(termAtt.buffer(), 0, termAtt.length()) : null;\n      if (result == null) {\n        copy(this, firstTok);\n        return true;\n      }\n\n      // fast-path failed, clone ourselves if needed\n      if (firstTok == this)\n        firstTok = cloneAttributes();\n      // OK, we matched a token, so find the longest match.\n\n      matched = new LinkedList<AttributeSource>();\n\n      result = match(result);\n\n      if (result==null) {\n        // no match, simply return the first token read.\n        copy(this, firstTok);\n        return true;\n      }\n\n      // reuse, or create new one each time?\n      ArrayList<AttributeSource> generated = new ArrayList<AttributeSource>(result.synonyms.length + matched.size() + 1);\n\n      //\n      // there was a match... let's generate the new tokens, merging\n      // in the matched tokens (position increments need adjusting)\n      //\n      AttributeSource lastTok = matched.isEmpty() ? firstTok : matched.getLast();\n      boolean includeOrig = result.includeOrig();\n\n      AttributeSource origTok = includeOrig ? firstTok : null;\n      PositionIncrementAttribute firstPosIncAtt = firstTok.addAttribute(PositionIncrementAttribute.class);\n      int origPos = firstPosIncAtt.getPositionIncrement();  // position of origTok in the original stream\n      int repPos=0; // curr position in replacement token stream\n      int pos=0;  // current position in merged token stream\n\n      for (int i=0; i<result.synonyms.length; i++) {\n        Token repTok = result.synonyms[i];\n        AttributeSource newTok = firstTok.cloneAttributes();\n        CharTermAttribute newTermAtt = newTok.addAttribute(CharTermAttribute.class);\n        OffsetAttribute newOffsetAtt = newTok.addAttribute(OffsetAttribute.class);\n        PositionIncrementAttribute newPosIncAtt = newTok.addAttribute(PositionIncrementAttribute.class);\n\n        OffsetAttribute lastOffsetAtt = lastTok.addAttribute(OffsetAttribute.class);\n\n        newOffsetAtt.setOffset(newOffsetAtt.startOffset(), lastOffsetAtt.endOffset());\n        newTermAtt.copyBuffer(repTok.termBuffer(), 0, repTok.termLength());\n        repPos += repTok.getPositionIncrement();\n        if (i==0) repPos=origPos;  // make position of first token equal to original\n\n        // if necessary, insert original tokens and adjust position increment\n        while (origTok != null && origPos <= repPos) {\n          PositionIncrementAttribute origPosInc = origTok.addAttribute(PositionIncrementAttribute.class);\n          origPosInc.setPositionIncrement(origPos-pos);\n          generated.add(origTok);\n          pos += origPosInc.getPositionIncrement();\n          origTok = matched.isEmpty() ? null : matched.removeFirst();\n          if (origTok != null) {\n            origPosInc = origTok.addAttribute(PositionIncrementAttribute.class);\n            origPos += origPosInc.getPositionIncrement();\n          }\n        }\n\n        newPosIncAtt.setPositionIncrement(repPos - pos);\n        generated.add(newTok);\n        pos += newPosIncAtt.getPositionIncrement();\n      }\n\n      // finish up any leftover original tokens\n      while (origTok!=null) {\n        PositionIncrementAttribute origPosInc = origTok.addAttribute(PositionIncrementAttribute.class);\n        origPosInc.setPositionIncrement(origPos-pos);\n        generated.add(origTok);\n        pos += origPosInc.getPositionIncrement();\n        origTok = matched.isEmpty() ? null : matched.removeFirst();\n        if (origTok != null) {\n          origPosInc = origTok.addAttribute(PositionIncrementAttribute.class);\n          origPos += origPosInc.getPositionIncrement();\n        }\n      }\n\n      // what if we replaced a longer sequence with a shorter one?\n      // a/0 b/5 =>  foo/0\n      // should I re-create the gap on the next buffered token?\n\n      replacement = generated.iterator();\n      // Now return to the top of the loop to read and return the first\n      // generated token.. The reason this is done is that we may have generated\n      // nothing at all, and may need to continue with more matching logic.\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a7347509fad0711ac30cb15a746e9a3830a38ebd","date":1275388513,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter#incrementToken().mjava","pathOld":"modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter#incrementToken().mjava","sourceNew":"  /*\n   * Need to worry about multiple scenarios:\n   *  - need to go for the longest match\n   *    a b => foo      #shouldn't match if \"a b\" is followed by \"c d\"\n   *    a b c d => bar\n   *  - need to backtrack - retry matches for tokens already read\n   *     a b c d => foo\n   *       b c => bar\n   *     If the input stream is \"a b c x\", one will consume \"a b c d\"\n   *     trying to match the first rule... all but \"a\" should be\n   *     pushed back so a match may be made on \"b c\".\n   *  - don't try and match generated tokens (thus need separate queue)\n   *    matching is not recursive.\n   *  - handle optional generation of original tokens in all these cases,\n   *    merging token streams to preserve token positions.\n   *  - preserve original positionIncrement of first matched token\n   */\n  @Override\n  public boolean incrementToken() throws IOException {\n    while (true) {\n      // if there are any generated tokens, return them... don't try any\n      // matches against them, as we specifically don't want recursion.\n      if (replacement!=null && replacement.hasNext()) {\n        copy(this, replacement.next());\n        return true;\n      }\n\n      // common case fast-path of first token not matching anything\n      AttributeSource firstTok = nextTok();\n      if (firstTok == null) return false;\n      CharTermAttribute termAtt = firstTok.addAttribute(CharTermAttribute.class);\n      SynonymMap result = map.submap!=null ? map.submap.get(termAtt.buffer(), 0, termAtt.length()) : null;\n      if (result == null) {\n        copy(this, firstTok);\n        return true;\n      }\n\n      // fast-path failed, clone ourselves if needed\n      if (firstTok == this)\n        firstTok = cloneAttributes();\n      // OK, we matched a token, so find the longest match.\n\n      matched = new LinkedList<AttributeSource>();\n\n      result = match(result);\n\n      if (result==null) {\n        // no match, simply return the first token read.\n        copy(this, firstTok);\n        return true;\n      }\n\n      // reuse, or create new one each time?\n      ArrayList<AttributeSource> generated = new ArrayList<AttributeSource>(result.synonyms.length + matched.size() + 1);\n\n      //\n      // there was a match... let's generate the new tokens, merging\n      // in the matched tokens (position increments need adjusting)\n      //\n      AttributeSource lastTok = matched.isEmpty() ? firstTok : matched.getLast();\n      boolean includeOrig = result.includeOrig();\n\n      AttributeSource origTok = includeOrig ? firstTok : null;\n      PositionIncrementAttribute firstPosIncAtt = firstTok.addAttribute(PositionIncrementAttribute.class);\n      int origPos = firstPosIncAtt.getPositionIncrement();  // position of origTok in the original stream\n      int repPos=0; // curr position in replacement token stream\n      int pos=0;  // current position in merged token stream\n\n      for (int i=0; i<result.synonyms.length; i++) {\n        Token repTok = result.synonyms[i];\n        AttributeSource newTok = firstTok.cloneAttributes();\n        CharTermAttribute newTermAtt = newTok.addAttribute(CharTermAttribute.class);\n        OffsetAttribute newOffsetAtt = newTok.addAttribute(OffsetAttribute.class);\n        PositionIncrementAttribute newPosIncAtt = newTok.addAttribute(PositionIncrementAttribute.class);\n\n        OffsetAttribute lastOffsetAtt = lastTok.addAttribute(OffsetAttribute.class);\n\n        newOffsetAtt.setOffset(newOffsetAtt.startOffset(), lastOffsetAtt.endOffset());\n        newTermAtt.copyBuffer(repTok.buffer(), 0, repTok.length());\n        repPos += repTok.getPositionIncrement();\n        if (i==0) repPos=origPos;  // make position of first token equal to original\n\n        // if necessary, insert original tokens and adjust position increment\n        while (origTok != null && origPos <= repPos) {\n          PositionIncrementAttribute origPosInc = origTok.addAttribute(PositionIncrementAttribute.class);\n          origPosInc.setPositionIncrement(origPos-pos);\n          generated.add(origTok);\n          pos += origPosInc.getPositionIncrement();\n          origTok = matched.isEmpty() ? null : matched.removeFirst();\n          if (origTok != null) {\n            origPosInc = origTok.addAttribute(PositionIncrementAttribute.class);\n            origPos += origPosInc.getPositionIncrement();\n          }\n        }\n\n        newPosIncAtt.setPositionIncrement(repPos - pos);\n        generated.add(newTok);\n        pos += newPosIncAtt.getPositionIncrement();\n      }\n\n      // finish up any leftover original tokens\n      while (origTok!=null) {\n        PositionIncrementAttribute origPosInc = origTok.addAttribute(PositionIncrementAttribute.class);\n        origPosInc.setPositionIncrement(origPos-pos);\n        generated.add(origTok);\n        pos += origPosInc.getPositionIncrement();\n        origTok = matched.isEmpty() ? null : matched.removeFirst();\n        if (origTok != null) {\n          origPosInc = origTok.addAttribute(PositionIncrementAttribute.class);\n          origPos += origPosInc.getPositionIncrement();\n        }\n      }\n\n      // what if we replaced a longer sequence with a shorter one?\n      // a/0 b/5 =>  foo/0\n      // should I re-create the gap on the next buffered token?\n\n      replacement = generated.iterator();\n      // Now return to the top of the loop to read and return the first\n      // generated token.. The reason this is done is that we may have generated\n      // nothing at all, and may need to continue with more matching logic.\n    }\n  }\n\n","sourceOld":"  /*\n   * Need to worry about multiple scenarios:\n   *  - need to go for the longest match\n   *    a b => foo      #shouldn't match if \"a b\" is followed by \"c d\"\n   *    a b c d => bar\n   *  - need to backtrack - retry matches for tokens already read\n   *     a b c d => foo\n   *       b c => bar\n   *     If the input stream is \"a b c x\", one will consume \"a b c d\"\n   *     trying to match the first rule... all but \"a\" should be\n   *     pushed back so a match may be made on \"b c\".\n   *  - don't try and match generated tokens (thus need separate queue)\n   *    matching is not recursive.\n   *  - handle optional generation of original tokens in all these cases,\n   *    merging token streams to preserve token positions.\n   *  - preserve original positionIncrement of first matched token\n   */\n  @Override\n  public boolean incrementToken() throws IOException {\n    while (true) {\n      // if there are any generated tokens, return them... don't try any\n      // matches against them, as we specifically don't want recursion.\n      if (replacement!=null && replacement.hasNext()) {\n        copy(this, replacement.next());\n        return true;\n      }\n\n      // common case fast-path of first token not matching anything\n      AttributeSource firstTok = nextTok();\n      if (firstTok == null) return false;\n      CharTermAttribute termAtt = firstTok.addAttribute(CharTermAttribute.class);\n      SynonymMap result = map.submap!=null ? map.submap.get(termAtt.buffer(), 0, termAtt.length()) : null;\n      if (result == null) {\n        copy(this, firstTok);\n        return true;\n      }\n\n      // fast-path failed, clone ourselves if needed\n      if (firstTok == this)\n        firstTok = cloneAttributes();\n      // OK, we matched a token, so find the longest match.\n\n      matched = new LinkedList<AttributeSource>();\n\n      result = match(result);\n\n      if (result==null) {\n        // no match, simply return the first token read.\n        copy(this, firstTok);\n        return true;\n      }\n\n      // reuse, or create new one each time?\n      ArrayList<AttributeSource> generated = new ArrayList<AttributeSource>(result.synonyms.length + matched.size() + 1);\n\n      //\n      // there was a match... let's generate the new tokens, merging\n      // in the matched tokens (position increments need adjusting)\n      //\n      AttributeSource lastTok = matched.isEmpty() ? firstTok : matched.getLast();\n      boolean includeOrig = result.includeOrig();\n\n      AttributeSource origTok = includeOrig ? firstTok : null;\n      PositionIncrementAttribute firstPosIncAtt = firstTok.addAttribute(PositionIncrementAttribute.class);\n      int origPos = firstPosIncAtt.getPositionIncrement();  // position of origTok in the original stream\n      int repPos=0; // curr position in replacement token stream\n      int pos=0;  // current position in merged token stream\n\n      for (int i=0; i<result.synonyms.length; i++) {\n        Token repTok = result.synonyms[i];\n        AttributeSource newTok = firstTok.cloneAttributes();\n        CharTermAttribute newTermAtt = newTok.addAttribute(CharTermAttribute.class);\n        OffsetAttribute newOffsetAtt = newTok.addAttribute(OffsetAttribute.class);\n        PositionIncrementAttribute newPosIncAtt = newTok.addAttribute(PositionIncrementAttribute.class);\n\n        OffsetAttribute lastOffsetAtt = lastTok.addAttribute(OffsetAttribute.class);\n\n        newOffsetAtt.setOffset(newOffsetAtt.startOffset(), lastOffsetAtt.endOffset());\n        newTermAtt.copyBuffer(repTok.termBuffer(), 0, repTok.termLength());\n        repPos += repTok.getPositionIncrement();\n        if (i==0) repPos=origPos;  // make position of first token equal to original\n\n        // if necessary, insert original tokens and adjust position increment\n        while (origTok != null && origPos <= repPos) {\n          PositionIncrementAttribute origPosInc = origTok.addAttribute(PositionIncrementAttribute.class);\n          origPosInc.setPositionIncrement(origPos-pos);\n          generated.add(origTok);\n          pos += origPosInc.getPositionIncrement();\n          origTok = matched.isEmpty() ? null : matched.removeFirst();\n          if (origTok != null) {\n            origPosInc = origTok.addAttribute(PositionIncrementAttribute.class);\n            origPos += origPosInc.getPositionIncrement();\n          }\n        }\n\n        newPosIncAtt.setPositionIncrement(repPos - pos);\n        generated.add(newTok);\n        pos += newPosIncAtt.getPositionIncrement();\n      }\n\n      // finish up any leftover original tokens\n      while (origTok!=null) {\n        PositionIncrementAttribute origPosInc = origTok.addAttribute(PositionIncrementAttribute.class);\n        origPosInc.setPositionIncrement(origPos-pos);\n        generated.add(origTok);\n        pos += origPosInc.getPositionIncrement();\n        origTok = matched.isEmpty() ? null : matched.removeFirst();\n        if (origTok != null) {\n          origPosInc = origTok.addAttribute(PositionIncrementAttribute.class);\n          origPos += origPosInc.getPositionIncrement();\n        }\n      }\n\n      // what if we replaced a longer sequence with a shorter one?\n      // a/0 b/5 =>  foo/0\n      // should I re-create the gap on the next buffered token?\n\n      replacement = generated.iterator();\n      // Now return to the top of the loop to read and return the first\n      // generated token.. The reason this is done is that we may have generated\n      // nothing at all, and may need to continue with more matching logic.\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"44d6f0ab53c1962856b9f48dedb7a2a6cc18905c","date":1310389132,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter#incrementToken().mjava","pathOld":"modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter#incrementToken().mjava","sourceNew":"  @Override\n  public boolean incrementToken() throws IOException {\n\n    //System.out.println(\"\\nS: incrToken inputSkipCount=\" + inputSkipCount + \" nextRead=\" + nextRead + \" nextWrite=\" + nextWrite);\n\n    while(true) {\n\n      // First play back any buffered future inputs/outputs\n      // w/o running parsing again:\n      while (inputSkipCount != 0) {\n        \n        // At each position, we first output the original\n        // token\n\n        // TODO: maybe just a PendingState class, holding\n        // both input & outputs?\n        final PendingInput input = futureInputs[nextRead];\n        final PendingOutputs outputs = futureOutputs[nextRead];\n        \n        //System.out.println(\"  cycle nextRead=\" + nextRead + \" nextWrite=\" + nextWrite + \" inputSkipCount=\"+ inputSkipCount + \" input.keepOrig=\" + input.keepOrig + \" input.consumed=\" + input.consumed + \" input.state=\" + input.state);\n\n        if (!input.consumed && (input.keepOrig || outputs.count == 0)) {\n          if (input.state != null) {\n            // Return a previously saved token (because we\n            // had to lookahead):\n            restoreState(input.state);\n          } else {\n            // Pass-through case: return token we just pulled\n            // but didn't capture:\n            assert inputSkipCount == 1: \"inputSkipCount=\" + inputSkipCount + \" nextRead=\" + nextRead;\n          }\n          input.reset();\n          if (outputs.count > 0) {\n            outputs.posIncr = 0;\n          } else {\n            nextRead = rollIncr(nextRead);\n            inputSkipCount--;\n          }\n          //System.out.println(\"  return token=\" + termAtt.toString());\n          return true;\n        } else if (outputs.upto < outputs.count) {\n          // Still have pending outputs to replay at this\n          // position\n          input.reset();\n          final int posIncr = outputs.posIncr;\n          final CharsRef output = outputs.pullNext();\n          clearAttributes();\n          termAtt.copyBuffer(output.chars, output.offset, output.length);\n          typeAtt.setType(TYPE_SYNONYM);\n          offsetAtt.setOffset(input.startOffset, input.endOffset);\n          posIncrAtt.setPositionIncrement(posIncr);\n          if (outputs.count == 0) {\n            // Done with the buffered input and all outputs at\n            // this position\n            nextRead = rollIncr(nextRead);\n            inputSkipCount--;\n          }\n          //System.out.println(\"  return token=\" + termAtt.toString());\n          return true;\n        } else {\n          // Done with the buffered input and all outputs at\n          // this position\n          input.reset();\n          nextRead = rollIncr(nextRead);\n          inputSkipCount--;\n        }\n      }\n\n      if (finished && nextRead == nextWrite) {\n        // End case: if any output syns went beyond end of\n        // input stream, enumerate them now:\n        final PendingOutputs outputs = futureOutputs[nextRead];\n        if (outputs.upto < outputs.count) {\n          final int posIncr = outputs.posIncr;\n          final CharsRef output = outputs.pullNext();\n          futureInputs[nextRead].reset();\n          if (outputs.count == 0) {\n            nextWrite = nextRead = rollIncr(nextRead);\n          }\n          clearAttributes();\n          termAtt.copyBuffer(output.chars, output.offset, output.length);\n          typeAtt.setType(TYPE_SYNONYM);\n          //System.out.println(\"  set posIncr=\" + outputs.posIncr + \" outputs=\" + outputs);\n          posIncrAtt.setPositionIncrement(posIncr);\n          //System.out.println(\"  return token=\" + termAtt.toString());\n          return true;\n        } else {\n          return false;\n        }\n      }\n\n      // Find new synonym matches:\n      parse();\n    }\n  }\n\n","sourceOld":"  /*\n   * Need to worry about multiple scenarios:\n   *  - need to go for the longest match\n   *    a b => foo      #shouldn't match if \"a b\" is followed by \"c d\"\n   *    a b c d => bar\n   *  - need to backtrack - retry matches for tokens already read\n   *     a b c d => foo\n   *       b c => bar\n   *     If the input stream is \"a b c x\", one will consume \"a b c d\"\n   *     trying to match the first rule... all but \"a\" should be\n   *     pushed back so a match may be made on \"b c\".\n   *  - don't try and match generated tokens (thus need separate queue)\n   *    matching is not recursive.\n   *  - handle optional generation of original tokens in all these cases,\n   *    merging token streams to preserve token positions.\n   *  - preserve original positionIncrement of first matched token\n   */\n  @Override\n  public boolean incrementToken() throws IOException {\n    while (true) {\n      // if there are any generated tokens, return them... don't try any\n      // matches against them, as we specifically don't want recursion.\n      if (replacement!=null && replacement.hasNext()) {\n        copy(this, replacement.next());\n        return true;\n      }\n\n      // common case fast-path of first token not matching anything\n      AttributeSource firstTok = nextTok();\n      if (firstTok == null) return false;\n      CharTermAttribute termAtt = firstTok.addAttribute(CharTermAttribute.class);\n      SynonymMap result = map.submap!=null ? map.submap.get(termAtt.buffer(), 0, termAtt.length()) : null;\n      if (result == null) {\n        copy(this, firstTok);\n        return true;\n      }\n\n      // fast-path failed, clone ourselves if needed\n      if (firstTok == this)\n        firstTok = cloneAttributes();\n      // OK, we matched a token, so find the longest match.\n\n      matched = new LinkedList<AttributeSource>();\n\n      result = match(result);\n\n      if (result==null) {\n        // no match, simply return the first token read.\n        copy(this, firstTok);\n        return true;\n      }\n\n      // reuse, or create new one each time?\n      ArrayList<AttributeSource> generated = new ArrayList<AttributeSource>(result.synonyms.length + matched.size() + 1);\n\n      //\n      // there was a match... let's generate the new tokens, merging\n      // in the matched tokens (position increments need adjusting)\n      //\n      AttributeSource lastTok = matched.isEmpty() ? firstTok : matched.getLast();\n      boolean includeOrig = result.includeOrig();\n\n      AttributeSource origTok = includeOrig ? firstTok : null;\n      PositionIncrementAttribute firstPosIncAtt = firstTok.addAttribute(PositionIncrementAttribute.class);\n      int origPos = firstPosIncAtt.getPositionIncrement();  // position of origTok in the original stream\n      int repPos=0; // curr position in replacement token stream\n      int pos=0;  // current position in merged token stream\n\n      for (int i=0; i<result.synonyms.length; i++) {\n        Token repTok = result.synonyms[i];\n        AttributeSource newTok = firstTok.cloneAttributes();\n        CharTermAttribute newTermAtt = newTok.addAttribute(CharTermAttribute.class);\n        OffsetAttribute newOffsetAtt = newTok.addAttribute(OffsetAttribute.class);\n        PositionIncrementAttribute newPosIncAtt = newTok.addAttribute(PositionIncrementAttribute.class);\n\n        OffsetAttribute lastOffsetAtt = lastTok.addAttribute(OffsetAttribute.class);\n\n        newOffsetAtt.setOffset(newOffsetAtt.startOffset(), lastOffsetAtt.endOffset());\n        newTermAtt.copyBuffer(repTok.buffer(), 0, repTok.length());\n        repPos += repTok.getPositionIncrement();\n        if (i==0) repPos=origPos;  // make position of first token equal to original\n\n        // if necessary, insert original tokens and adjust position increment\n        while (origTok != null && origPos <= repPos) {\n          PositionIncrementAttribute origPosInc = origTok.addAttribute(PositionIncrementAttribute.class);\n          origPosInc.setPositionIncrement(origPos-pos);\n          generated.add(origTok);\n          pos += origPosInc.getPositionIncrement();\n          origTok = matched.isEmpty() ? null : matched.removeFirst();\n          if (origTok != null) {\n            origPosInc = origTok.addAttribute(PositionIncrementAttribute.class);\n            origPos += origPosInc.getPositionIncrement();\n          }\n        }\n\n        newPosIncAtt.setPositionIncrement(repPos - pos);\n        generated.add(newTok);\n        pos += newPosIncAtt.getPositionIncrement();\n      }\n\n      // finish up any leftover original tokens\n      while (origTok!=null) {\n        PositionIncrementAttribute origPosInc = origTok.addAttribute(PositionIncrementAttribute.class);\n        origPosInc.setPositionIncrement(origPos-pos);\n        generated.add(origTok);\n        pos += origPosInc.getPositionIncrement();\n        origTok = matched.isEmpty() ? null : matched.removeFirst();\n        if (origTok != null) {\n          origPosInc = origTok.addAttribute(PositionIncrementAttribute.class);\n          origPos += origPosInc.getPositionIncrement();\n        }\n      }\n\n      // what if we replaced a longer sequence with a shorter one?\n      // a/0 b/5 =>  foo/0\n      // should I re-create the gap on the next buffered token?\n\n      replacement = generated.iterator();\n      // Now return to the top of the loop to read and return the first\n      // generated token.. The reason this is done is that we may have generated\n      // nothing at all, and may need to continue with more matching logic.\n    }\n  }\n\n","bugFix":null,"bugIntro":["865b7d0f8430a08d385370b6b87a89a737aa6145","de11853c992f764e52d4164cc9afdebb989dba8a"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"de11853c992f764e52d4164cc9afdebb989dba8a","date":1313510465,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter#incrementToken().mjava","pathOld":"modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter#incrementToken().mjava","sourceNew":"  @Override\n  public boolean incrementToken() throws IOException {\n\n    //System.out.println(\"\\nS: incrToken inputSkipCount=\" + inputSkipCount + \" nextRead=\" + nextRead + \" nextWrite=\" + nextWrite);\n\n    while(true) {\n\n      // First play back any buffered future inputs/outputs\n      // w/o running parsing again:\n      while (inputSkipCount != 0) {\n        \n        // At each position, we first output the original\n        // token\n\n        // TODO: maybe just a PendingState class, holding\n        // both input & outputs?\n        final PendingInput input = futureInputs[nextRead];\n        final PendingOutputs outputs = futureOutputs[nextRead];\n        \n        //System.out.println(\"  cycle nextRead=\" + nextRead + \" nextWrite=\" + nextWrite + \" inputSkipCount=\"+ inputSkipCount + \" input.keepOrig=\" + input.keepOrig + \" input.consumed=\" + input.consumed + \" input.state=\" + input.state);\n\n        if (!input.consumed && (input.keepOrig || !input.matched)) {\n          if (input.state != null) {\n            // Return a previously saved token (because we\n            // had to lookahead):\n            restoreState(input.state);\n          } else {\n            // Pass-through case: return token we just pulled\n            // but didn't capture:\n            assert inputSkipCount == 1: \"inputSkipCount=\" + inputSkipCount + \" nextRead=\" + nextRead;\n          }\n          input.reset();\n          if (outputs.count > 0) {\n            outputs.posIncr = 0;\n          } else {\n            nextRead = rollIncr(nextRead);\n            inputSkipCount--;\n          }\n          //System.out.println(\"  return token=\" + termAtt.toString());\n          return true;\n        } else if (outputs.upto < outputs.count) {\n          // Still have pending outputs to replay at this\n          // position\n          input.reset();\n          final int posIncr = outputs.posIncr;\n          final CharsRef output = outputs.pullNext();\n          clearAttributes();\n          termAtt.copyBuffer(output.chars, output.offset, output.length);\n          typeAtt.setType(TYPE_SYNONYM);\n          offsetAtt.setOffset(input.startOffset, input.endOffset);\n          posIncrAtt.setPositionIncrement(posIncr);\n          if (outputs.count == 0) {\n            // Done with the buffered input and all outputs at\n            // this position\n            nextRead = rollIncr(nextRead);\n            inputSkipCount--;\n          }\n          //System.out.println(\"  return token=\" + termAtt.toString());\n          return true;\n        } else {\n          // Done with the buffered input and all outputs at\n          // this position\n          input.reset();\n          nextRead = rollIncr(nextRead);\n          inputSkipCount--;\n        }\n      }\n\n      if (finished && nextRead == nextWrite) {\n        // End case: if any output syns went beyond end of\n        // input stream, enumerate them now:\n        final PendingOutputs outputs = futureOutputs[nextRead];\n        if (outputs.upto < outputs.count) {\n          final int posIncr = outputs.posIncr;\n          final CharsRef output = outputs.pullNext();\n          futureInputs[nextRead].reset();\n          if (outputs.count == 0) {\n            nextWrite = nextRead = rollIncr(nextRead);\n          }\n          clearAttributes();\n          termAtt.copyBuffer(output.chars, output.offset, output.length);\n          typeAtt.setType(TYPE_SYNONYM);\n          //System.out.println(\"  set posIncr=\" + outputs.posIncr + \" outputs=\" + outputs);\n          posIncrAtt.setPositionIncrement(posIncr);\n          //System.out.println(\"  return token=\" + termAtt.toString());\n          return true;\n        } else {\n          return false;\n        }\n      }\n\n      // Find new synonym matches:\n      parse();\n    }\n  }\n\n","sourceOld":"  @Override\n  public boolean incrementToken() throws IOException {\n\n    //System.out.println(\"\\nS: incrToken inputSkipCount=\" + inputSkipCount + \" nextRead=\" + nextRead + \" nextWrite=\" + nextWrite);\n\n    while(true) {\n\n      // First play back any buffered future inputs/outputs\n      // w/o running parsing again:\n      while (inputSkipCount != 0) {\n        \n        // At each position, we first output the original\n        // token\n\n        // TODO: maybe just a PendingState class, holding\n        // both input & outputs?\n        final PendingInput input = futureInputs[nextRead];\n        final PendingOutputs outputs = futureOutputs[nextRead];\n        \n        //System.out.println(\"  cycle nextRead=\" + nextRead + \" nextWrite=\" + nextWrite + \" inputSkipCount=\"+ inputSkipCount + \" input.keepOrig=\" + input.keepOrig + \" input.consumed=\" + input.consumed + \" input.state=\" + input.state);\n\n        if (!input.consumed && (input.keepOrig || outputs.count == 0)) {\n          if (input.state != null) {\n            // Return a previously saved token (because we\n            // had to lookahead):\n            restoreState(input.state);\n          } else {\n            // Pass-through case: return token we just pulled\n            // but didn't capture:\n            assert inputSkipCount == 1: \"inputSkipCount=\" + inputSkipCount + \" nextRead=\" + nextRead;\n          }\n          input.reset();\n          if (outputs.count > 0) {\n            outputs.posIncr = 0;\n          } else {\n            nextRead = rollIncr(nextRead);\n            inputSkipCount--;\n          }\n          //System.out.println(\"  return token=\" + termAtt.toString());\n          return true;\n        } else if (outputs.upto < outputs.count) {\n          // Still have pending outputs to replay at this\n          // position\n          input.reset();\n          final int posIncr = outputs.posIncr;\n          final CharsRef output = outputs.pullNext();\n          clearAttributes();\n          termAtt.copyBuffer(output.chars, output.offset, output.length);\n          typeAtt.setType(TYPE_SYNONYM);\n          offsetAtt.setOffset(input.startOffset, input.endOffset);\n          posIncrAtt.setPositionIncrement(posIncr);\n          if (outputs.count == 0) {\n            // Done with the buffered input and all outputs at\n            // this position\n            nextRead = rollIncr(nextRead);\n            inputSkipCount--;\n          }\n          //System.out.println(\"  return token=\" + termAtt.toString());\n          return true;\n        } else {\n          // Done with the buffered input and all outputs at\n          // this position\n          input.reset();\n          nextRead = rollIncr(nextRead);\n          inputSkipCount--;\n        }\n      }\n\n      if (finished && nextRead == nextWrite) {\n        // End case: if any output syns went beyond end of\n        // input stream, enumerate them now:\n        final PendingOutputs outputs = futureOutputs[nextRead];\n        if (outputs.upto < outputs.count) {\n          final int posIncr = outputs.posIncr;\n          final CharsRef output = outputs.pullNext();\n          futureInputs[nextRead].reset();\n          if (outputs.count == 0) {\n            nextWrite = nextRead = rollIncr(nextRead);\n          }\n          clearAttributes();\n          termAtt.copyBuffer(output.chars, output.offset, output.length);\n          typeAtt.setType(TYPE_SYNONYM);\n          //System.out.println(\"  set posIncr=\" + outputs.posIncr + \" outputs=\" + outputs);\n          posIncrAtt.setPositionIncrement(posIncr);\n          //System.out.println(\"  return token=\" + termAtt.toString());\n          return true;\n        } else {\n          return false;\n        }\n      }\n\n      // Find new synonym matches:\n      parse();\n    }\n  }\n\n","bugFix":["44d6f0ab53c1962856b9f48dedb7a2a6cc18905c"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"865b7d0f8430a08d385370b6b87a89a737aa6145","date":1325953575,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter#incrementToken().mjava","pathOld":"modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter#incrementToken().mjava","sourceNew":"  @Override\n  public boolean incrementToken() throws IOException {\n\n    //System.out.println(\"\\nS: incrToken inputSkipCount=\" + inputSkipCount + \" nextRead=\" + nextRead + \" nextWrite=\" + nextWrite);\n\n    while(true) {\n\n      // First play back any buffered future inputs/outputs\n      // w/o running parsing again:\n      while (inputSkipCount != 0) {\n        \n        // At each position, we first output the original\n        // token\n\n        // TODO: maybe just a PendingState class, holding\n        // both input & outputs?\n        final PendingInput input = futureInputs[nextRead];\n        final PendingOutputs outputs = futureOutputs[nextRead];\n        \n        //System.out.println(\"  cycle nextRead=\" + nextRead + \" nextWrite=\" + nextWrite + \" inputSkipCount=\"+ inputSkipCount + \" input.keepOrig=\" + input.keepOrig + \" input.consumed=\" + input.consumed + \" input.state=\" + input.state);\n\n        if (!input.consumed && (input.keepOrig || !input.matched)) {\n          if (input.state != null) {\n            // Return a previously saved token (because we\n            // had to lookahead):\n            restoreState(input.state);\n          } else {\n            // Pass-through case: return token we just pulled\n            // but didn't capture:\n            assert inputSkipCount == 1: \"inputSkipCount=\" + inputSkipCount + \" nextRead=\" + nextRead;\n          }\n          input.reset();\n          if (outputs.count > 0) {\n            outputs.posIncr = 0;\n          } else {\n            nextRead = rollIncr(nextRead);\n            inputSkipCount--;\n          }\n          //System.out.println(\"  return token=\" + termAtt.toString());\n          return true;\n        } else if (outputs.upto < outputs.count) {\n          // Still have pending outputs to replay at this\n          // position\n          input.reset();\n          final int posIncr = outputs.posIncr;\n          final CharsRef output = outputs.pullNext();\n          clearAttributes();\n          termAtt.copyBuffer(output.chars, output.offset, output.length);\n          typeAtt.setType(TYPE_SYNONYM);\n          int endOffset = outputs.getLastEndOffset();\n          if (endOffset == -1) {\n            endOffset = input.endOffset;\n          }\n          offsetAtt.setOffset(input.startOffset, endOffset);\n          posIncrAtt.setPositionIncrement(posIncr);\n          if (outputs.count == 0) {\n            // Done with the buffered input and all outputs at\n            // this position\n            nextRead = rollIncr(nextRead);\n            inputSkipCount--;\n          }\n          //System.out.println(\"  return token=\" + termAtt.toString());\n          return true;\n        } else {\n          // Done with the buffered input and all outputs at\n          // this position\n          input.reset();\n          nextRead = rollIncr(nextRead);\n          inputSkipCount--;\n        }\n      }\n\n      if (finished && nextRead == nextWrite) {\n        // End case: if any output syns went beyond end of\n        // input stream, enumerate them now:\n        final PendingOutputs outputs = futureOutputs[nextRead];\n        if (outputs.upto < outputs.count) {\n          final int posIncr = outputs.posIncr;\n          final CharsRef output = outputs.pullNext();\n          futureInputs[nextRead].reset();\n          if (outputs.count == 0) {\n            nextWrite = nextRead = rollIncr(nextRead);\n          }\n          clearAttributes();\n          termAtt.copyBuffer(output.chars, output.offset, output.length);\n          typeAtt.setType(TYPE_SYNONYM);\n          //System.out.println(\"  set posIncr=\" + outputs.posIncr + \" outputs=\" + outputs);\n          posIncrAtt.setPositionIncrement(posIncr);\n          //System.out.println(\"  return token=\" + termAtt.toString());\n          return true;\n        } else {\n          return false;\n        }\n      }\n\n      // Find new synonym matches:\n      parse();\n    }\n  }\n\n","sourceOld":"  @Override\n  public boolean incrementToken() throws IOException {\n\n    //System.out.println(\"\\nS: incrToken inputSkipCount=\" + inputSkipCount + \" nextRead=\" + nextRead + \" nextWrite=\" + nextWrite);\n\n    while(true) {\n\n      // First play back any buffered future inputs/outputs\n      // w/o running parsing again:\n      while (inputSkipCount != 0) {\n        \n        // At each position, we first output the original\n        // token\n\n        // TODO: maybe just a PendingState class, holding\n        // both input & outputs?\n        final PendingInput input = futureInputs[nextRead];\n        final PendingOutputs outputs = futureOutputs[nextRead];\n        \n        //System.out.println(\"  cycle nextRead=\" + nextRead + \" nextWrite=\" + nextWrite + \" inputSkipCount=\"+ inputSkipCount + \" input.keepOrig=\" + input.keepOrig + \" input.consumed=\" + input.consumed + \" input.state=\" + input.state);\n\n        if (!input.consumed && (input.keepOrig || !input.matched)) {\n          if (input.state != null) {\n            // Return a previously saved token (because we\n            // had to lookahead):\n            restoreState(input.state);\n          } else {\n            // Pass-through case: return token we just pulled\n            // but didn't capture:\n            assert inputSkipCount == 1: \"inputSkipCount=\" + inputSkipCount + \" nextRead=\" + nextRead;\n          }\n          input.reset();\n          if (outputs.count > 0) {\n            outputs.posIncr = 0;\n          } else {\n            nextRead = rollIncr(nextRead);\n            inputSkipCount--;\n          }\n          //System.out.println(\"  return token=\" + termAtt.toString());\n          return true;\n        } else if (outputs.upto < outputs.count) {\n          // Still have pending outputs to replay at this\n          // position\n          input.reset();\n          final int posIncr = outputs.posIncr;\n          final CharsRef output = outputs.pullNext();\n          clearAttributes();\n          termAtt.copyBuffer(output.chars, output.offset, output.length);\n          typeAtt.setType(TYPE_SYNONYM);\n          offsetAtt.setOffset(input.startOffset, input.endOffset);\n          posIncrAtt.setPositionIncrement(posIncr);\n          if (outputs.count == 0) {\n            // Done with the buffered input and all outputs at\n            // this position\n            nextRead = rollIncr(nextRead);\n            inputSkipCount--;\n          }\n          //System.out.println(\"  return token=\" + termAtt.toString());\n          return true;\n        } else {\n          // Done with the buffered input and all outputs at\n          // this position\n          input.reset();\n          nextRead = rollIncr(nextRead);\n          inputSkipCount--;\n        }\n      }\n\n      if (finished && nextRead == nextWrite) {\n        // End case: if any output syns went beyond end of\n        // input stream, enumerate them now:\n        final PendingOutputs outputs = futureOutputs[nextRead];\n        if (outputs.upto < outputs.count) {\n          final int posIncr = outputs.posIncr;\n          final CharsRef output = outputs.pullNext();\n          futureInputs[nextRead].reset();\n          if (outputs.count == 0) {\n            nextWrite = nextRead = rollIncr(nextRead);\n          }\n          clearAttributes();\n          termAtt.copyBuffer(output.chars, output.offset, output.length);\n          typeAtt.setType(TYPE_SYNONYM);\n          //System.out.println(\"  set posIncr=\" + outputs.posIncr + \" outputs=\" + outputs);\n          posIncrAtt.setPositionIncrement(posIncr);\n          //System.out.println(\"  return token=\" + termAtt.toString());\n          return true;\n        } else {\n          return false;\n        }\n      }\n\n      // Find new synonym matches:\n      parse();\n    }\n  }\n\n","bugFix":["44d6f0ab53c1962856b9f48dedb7a2a6cc18905c"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7c49a1b0f95bf8ecc502e6d44d79e4809dbf8ee","date":1328050915,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter#incrementToken().mjava","pathOld":"modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter#incrementToken().mjava","sourceNew":"  @Override\n  public boolean incrementToken() throws IOException {\n\n    //System.out.println(\"\\nS: incrToken inputSkipCount=\" + inputSkipCount + \" nextRead=\" + nextRead + \" nextWrite=\" + nextWrite);\n\n    while(true) {\n\n      // First play back any buffered future inputs/outputs\n      // w/o running parsing again:\n      while (inputSkipCount != 0) {\n        \n        // At each position, we first output the original\n        // token\n\n        // TODO: maybe just a PendingState class, holding\n        // both input & outputs?\n        final PendingInput input = futureInputs[nextRead];\n        final PendingOutputs outputs = futureOutputs[nextRead];\n        \n        //System.out.println(\"  cycle nextRead=\" + nextRead + \" nextWrite=\" + nextWrite + \" inputSkipCount=\"+ inputSkipCount + \" input.keepOrig=\" + input.keepOrig + \" input.consumed=\" + input.consumed + \" input.state=\" + input.state);\n\n        if (!input.consumed && (input.keepOrig || !input.matched)) {\n          if (input.state != null) {\n            // Return a previously saved token (because we\n            // had to lookahead):\n            restoreState(input.state);\n          } else {\n            // Pass-through case: return token we just pulled\n            // but didn't capture:\n            assert inputSkipCount == 1: \"inputSkipCount=\" + inputSkipCount + \" nextRead=\" + nextRead;\n          }\n          input.reset();\n          if (outputs.count > 0) {\n            outputs.posIncr = 0;\n          } else {\n            nextRead = rollIncr(nextRead);\n            inputSkipCount--;\n          }\n          //System.out.println(\"  return token=\" + termAtt.toString());\n          return true;\n        } else if (outputs.upto < outputs.count) {\n          // Still have pending outputs to replay at this\n          // position\n          input.reset();\n          final int posIncr = outputs.posIncr;\n          final CharsRef output = outputs.pullNext();\n          clearAttributes();\n          termAtt.copyBuffer(output.chars, output.offset, output.length);\n          typeAtt.setType(TYPE_SYNONYM);\n          int endOffset = outputs.getLastEndOffset();\n          if (endOffset == -1) {\n            endOffset = input.endOffset;\n          }\n          offsetAtt.setOffset(input.startOffset, endOffset);\n          posIncrAtt.setPositionIncrement(posIncr);\n          if (outputs.count == 0) {\n            // Done with the buffered input and all outputs at\n            // this position\n            nextRead = rollIncr(nextRead);\n            inputSkipCount--;\n          }\n          //System.out.println(\"  return token=\" + termAtt.toString());\n          return true;\n        } else {\n          // Done with the buffered input and all outputs at\n          // this position\n          input.reset();\n          nextRead = rollIncr(nextRead);\n          inputSkipCount--;\n        }\n      }\n\n      if (finished && nextRead == nextWrite) {\n        // End case: if any output syns went beyond end of\n        // input stream, enumerate them now:\n        final PendingOutputs outputs = futureOutputs[nextRead];\n        if (outputs.upto < outputs.count) {\n          final int posIncr = outputs.posIncr;\n          final CharsRef output = outputs.pullNext();\n          futureInputs[nextRead].reset();\n          if (outputs.count == 0) {\n            nextWrite = nextRead = rollIncr(nextRead);\n          }\n          clearAttributes();\n          // Keep offset from last input token:\n          offsetAtt.setOffset(lastStartOffset, lastEndOffset);\n          termAtt.copyBuffer(output.chars, output.offset, output.length);\n          typeAtt.setType(TYPE_SYNONYM);\n          //System.out.println(\"  set posIncr=\" + outputs.posIncr + \" outputs=\" + outputs);\n          posIncrAtt.setPositionIncrement(posIncr);\n          //System.out.println(\"  return token=\" + termAtt.toString());\n          return true;\n        } else {\n          return false;\n        }\n      }\n\n      // Find new synonym matches:\n      parse();\n    }\n  }\n\n","sourceOld":"  @Override\n  public boolean incrementToken() throws IOException {\n\n    //System.out.println(\"\\nS: incrToken inputSkipCount=\" + inputSkipCount + \" nextRead=\" + nextRead + \" nextWrite=\" + nextWrite);\n\n    while(true) {\n\n      // First play back any buffered future inputs/outputs\n      // w/o running parsing again:\n      while (inputSkipCount != 0) {\n        \n        // At each position, we first output the original\n        // token\n\n        // TODO: maybe just a PendingState class, holding\n        // both input & outputs?\n        final PendingInput input = futureInputs[nextRead];\n        final PendingOutputs outputs = futureOutputs[nextRead];\n        \n        //System.out.println(\"  cycle nextRead=\" + nextRead + \" nextWrite=\" + nextWrite + \" inputSkipCount=\"+ inputSkipCount + \" input.keepOrig=\" + input.keepOrig + \" input.consumed=\" + input.consumed + \" input.state=\" + input.state);\n\n        if (!input.consumed && (input.keepOrig || !input.matched)) {\n          if (input.state != null) {\n            // Return a previously saved token (because we\n            // had to lookahead):\n            restoreState(input.state);\n          } else {\n            // Pass-through case: return token we just pulled\n            // but didn't capture:\n            assert inputSkipCount == 1: \"inputSkipCount=\" + inputSkipCount + \" nextRead=\" + nextRead;\n          }\n          input.reset();\n          if (outputs.count > 0) {\n            outputs.posIncr = 0;\n          } else {\n            nextRead = rollIncr(nextRead);\n            inputSkipCount--;\n          }\n          //System.out.println(\"  return token=\" + termAtt.toString());\n          return true;\n        } else if (outputs.upto < outputs.count) {\n          // Still have pending outputs to replay at this\n          // position\n          input.reset();\n          final int posIncr = outputs.posIncr;\n          final CharsRef output = outputs.pullNext();\n          clearAttributes();\n          termAtt.copyBuffer(output.chars, output.offset, output.length);\n          typeAtt.setType(TYPE_SYNONYM);\n          int endOffset = outputs.getLastEndOffset();\n          if (endOffset == -1) {\n            endOffset = input.endOffset;\n          }\n          offsetAtt.setOffset(input.startOffset, endOffset);\n          posIncrAtt.setPositionIncrement(posIncr);\n          if (outputs.count == 0) {\n            // Done with the buffered input and all outputs at\n            // this position\n            nextRead = rollIncr(nextRead);\n            inputSkipCount--;\n          }\n          //System.out.println(\"  return token=\" + termAtt.toString());\n          return true;\n        } else {\n          // Done with the buffered input and all outputs at\n          // this position\n          input.reset();\n          nextRead = rollIncr(nextRead);\n          inputSkipCount--;\n        }\n      }\n\n      if (finished && nextRead == nextWrite) {\n        // End case: if any output syns went beyond end of\n        // input stream, enumerate them now:\n        final PendingOutputs outputs = futureOutputs[nextRead];\n        if (outputs.upto < outputs.count) {\n          final int posIncr = outputs.posIncr;\n          final CharsRef output = outputs.pullNext();\n          futureInputs[nextRead].reset();\n          if (outputs.count == 0) {\n            nextWrite = nextRead = rollIncr(nextRead);\n          }\n          clearAttributes();\n          termAtt.copyBuffer(output.chars, output.offset, output.length);\n          typeAtt.setType(TYPE_SYNONYM);\n          //System.out.println(\"  set posIncr=\" + outputs.posIncr + \" outputs=\" + outputs);\n          posIncrAtt.setPositionIncrement(posIncr);\n          //System.out.println(\"  return token=\" + termAtt.toString());\n          return true;\n        } else {\n          return false;\n        }\n      }\n\n      // Find new synonym matches:\n      parse();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ffbcd36aff3bb411177ed61f02fb3d3aa9588d27","date":1333918532,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter#incrementToken().mjava","pathOld":"modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter#incrementToken().mjava","sourceNew":"  @Override\n  public boolean incrementToken() throws IOException {\n\n    //System.out.println(\"\\nS: incrToken inputSkipCount=\" + inputSkipCount + \" nextRead=\" + nextRead + \" nextWrite=\" + nextWrite);\n\n    while(true) {\n\n      // First play back any buffered future inputs/outputs\n      // w/o running parsing again:\n      while (inputSkipCount != 0) {\n        \n        // At each position, we first output the original\n        // token\n\n        // TODO: maybe just a PendingState class, holding\n        // both input & outputs?\n        final PendingInput input = futureInputs[nextRead];\n        final PendingOutputs outputs = futureOutputs[nextRead];\n        \n        //System.out.println(\"  cycle nextRead=\" + nextRead + \" nextWrite=\" + nextWrite + \" inputSkipCount=\"+ inputSkipCount + \" input.keepOrig=\" + input.keepOrig + \" input.consumed=\" + input.consumed + \" input.state=\" + input.state);\n\n        if (!input.consumed && (input.keepOrig || !input.matched)) {\n          if (input.state != null) {\n            // Return a previously saved token (because we\n            // had to lookahead):\n            restoreState(input.state);\n          } else {\n            // Pass-through case: return token we just pulled\n            // but didn't capture:\n            assert inputSkipCount == 1: \"inputSkipCount=\" + inputSkipCount + \" nextRead=\" + nextRead;\n          }\n          input.reset();\n          if (outputs.count > 0) {\n            outputs.posIncr = 0;\n          } else {\n            nextRead = rollIncr(nextRead);\n            inputSkipCount--;\n          }\n          //System.out.println(\"  return token=\" + termAtt.toString());\n          return true;\n        } else if (outputs.upto < outputs.count) {\n          // Still have pending outputs to replay at this\n          // position\n          input.reset();\n          final int posIncr = outputs.posIncr;\n          final CharsRef output = outputs.pullNext();\n          clearAttributes();\n          termAtt.copyBuffer(output.chars, output.offset, output.length);\n          typeAtt.setType(TYPE_SYNONYM);\n          int endOffset = outputs.getLastEndOffset();\n          if (endOffset == -1) {\n            endOffset = input.endOffset;\n          }\n          offsetAtt.setOffset(input.startOffset, endOffset);\n          posIncrAtt.setPositionIncrement(posIncr);\n          posLenAtt.setPositionLength(outputs.getLastPosLength());\n          if (outputs.count == 0) {\n            // Done with the buffered input and all outputs at\n            // this position\n            nextRead = rollIncr(nextRead);\n            inputSkipCount--;\n          }\n          //System.out.println(\"  return token=\" + termAtt.toString());\n          return true;\n        } else {\n          // Done with the buffered input and all outputs at\n          // this position\n          input.reset();\n          nextRead = rollIncr(nextRead);\n          inputSkipCount--;\n        }\n      }\n\n      if (finished && nextRead == nextWrite) {\n        // End case: if any output syns went beyond end of\n        // input stream, enumerate them now:\n        final PendingOutputs outputs = futureOutputs[nextRead];\n        if (outputs.upto < outputs.count) {\n          final int posIncr = outputs.posIncr;\n          final CharsRef output = outputs.pullNext();\n          futureInputs[nextRead].reset();\n          if (outputs.count == 0) {\n            nextWrite = nextRead = rollIncr(nextRead);\n          }\n          clearAttributes();\n          // Keep offset from last input token:\n          offsetAtt.setOffset(lastStartOffset, lastEndOffset);\n          termAtt.copyBuffer(output.chars, output.offset, output.length);\n          typeAtt.setType(TYPE_SYNONYM);\n          //System.out.println(\"  set posIncr=\" + outputs.posIncr + \" outputs=\" + outputs);\n          posIncrAtt.setPositionIncrement(posIncr);\n          //System.out.println(\"  return token=\" + termAtt.toString());\n          return true;\n        } else {\n          return false;\n        }\n      }\n\n      // Find new synonym matches:\n      parse();\n    }\n  }\n\n","sourceOld":"  @Override\n  public boolean incrementToken() throws IOException {\n\n    //System.out.println(\"\\nS: incrToken inputSkipCount=\" + inputSkipCount + \" nextRead=\" + nextRead + \" nextWrite=\" + nextWrite);\n\n    while(true) {\n\n      // First play back any buffered future inputs/outputs\n      // w/o running parsing again:\n      while (inputSkipCount != 0) {\n        \n        // At each position, we first output the original\n        // token\n\n        // TODO: maybe just a PendingState class, holding\n        // both input & outputs?\n        final PendingInput input = futureInputs[nextRead];\n        final PendingOutputs outputs = futureOutputs[nextRead];\n        \n        //System.out.println(\"  cycle nextRead=\" + nextRead + \" nextWrite=\" + nextWrite + \" inputSkipCount=\"+ inputSkipCount + \" input.keepOrig=\" + input.keepOrig + \" input.consumed=\" + input.consumed + \" input.state=\" + input.state);\n\n        if (!input.consumed && (input.keepOrig || !input.matched)) {\n          if (input.state != null) {\n            // Return a previously saved token (because we\n            // had to lookahead):\n            restoreState(input.state);\n          } else {\n            // Pass-through case: return token we just pulled\n            // but didn't capture:\n            assert inputSkipCount == 1: \"inputSkipCount=\" + inputSkipCount + \" nextRead=\" + nextRead;\n          }\n          input.reset();\n          if (outputs.count > 0) {\n            outputs.posIncr = 0;\n          } else {\n            nextRead = rollIncr(nextRead);\n            inputSkipCount--;\n          }\n          //System.out.println(\"  return token=\" + termAtt.toString());\n          return true;\n        } else if (outputs.upto < outputs.count) {\n          // Still have pending outputs to replay at this\n          // position\n          input.reset();\n          final int posIncr = outputs.posIncr;\n          final CharsRef output = outputs.pullNext();\n          clearAttributes();\n          termAtt.copyBuffer(output.chars, output.offset, output.length);\n          typeAtt.setType(TYPE_SYNONYM);\n          int endOffset = outputs.getLastEndOffset();\n          if (endOffset == -1) {\n            endOffset = input.endOffset;\n          }\n          offsetAtt.setOffset(input.startOffset, endOffset);\n          posIncrAtt.setPositionIncrement(posIncr);\n          if (outputs.count == 0) {\n            // Done with the buffered input and all outputs at\n            // this position\n            nextRead = rollIncr(nextRead);\n            inputSkipCount--;\n          }\n          //System.out.println(\"  return token=\" + termAtt.toString());\n          return true;\n        } else {\n          // Done with the buffered input and all outputs at\n          // this position\n          input.reset();\n          nextRead = rollIncr(nextRead);\n          inputSkipCount--;\n        }\n      }\n\n      if (finished && nextRead == nextWrite) {\n        // End case: if any output syns went beyond end of\n        // input stream, enumerate them now:\n        final PendingOutputs outputs = futureOutputs[nextRead];\n        if (outputs.upto < outputs.count) {\n          final int posIncr = outputs.posIncr;\n          final CharsRef output = outputs.pullNext();\n          futureInputs[nextRead].reset();\n          if (outputs.count == 0) {\n            nextWrite = nextRead = rollIncr(nextRead);\n          }\n          clearAttributes();\n          // Keep offset from last input token:\n          offsetAtt.setOffset(lastStartOffset, lastEndOffset);\n          termAtt.copyBuffer(output.chars, output.offset, output.length);\n          typeAtt.setType(TYPE_SYNONYM);\n          //System.out.println(\"  set posIncr=\" + outputs.posIncr + \" outputs=\" + outputs);\n          posIncrAtt.setPositionIncrement(posIncr);\n          //System.out.println(\"  return token=\" + termAtt.toString());\n          return true;\n        } else {\n          return false;\n        }\n      }\n\n      // Find new synonym matches:\n      parse();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter#incrementToken().mjava","pathOld":"modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter#incrementToken().mjava","sourceNew":"  @Override\n  public boolean incrementToken() throws IOException {\n\n    //System.out.println(\"\\nS: incrToken inputSkipCount=\" + inputSkipCount + \" nextRead=\" + nextRead + \" nextWrite=\" + nextWrite);\n\n    while(true) {\n\n      // First play back any buffered future inputs/outputs\n      // w/o running parsing again:\n      while (inputSkipCount != 0) {\n        \n        // At each position, we first output the original\n        // token\n\n        // TODO: maybe just a PendingState class, holding\n        // both input & outputs?\n        final PendingInput input = futureInputs[nextRead];\n        final PendingOutputs outputs = futureOutputs[nextRead];\n        \n        //System.out.println(\"  cycle nextRead=\" + nextRead + \" nextWrite=\" + nextWrite + \" inputSkipCount=\"+ inputSkipCount + \" input.keepOrig=\" + input.keepOrig + \" input.consumed=\" + input.consumed + \" input.state=\" + input.state);\n\n        if (!input.consumed && (input.keepOrig || !input.matched)) {\n          if (input.state != null) {\n            // Return a previously saved token (because we\n            // had to lookahead):\n            restoreState(input.state);\n          } else {\n            // Pass-through case: return token we just pulled\n            // but didn't capture:\n            assert inputSkipCount == 1: \"inputSkipCount=\" + inputSkipCount + \" nextRead=\" + nextRead;\n          }\n          input.reset();\n          if (outputs.count > 0) {\n            outputs.posIncr = 0;\n          } else {\n            nextRead = rollIncr(nextRead);\n            inputSkipCount--;\n          }\n          //System.out.println(\"  return token=\" + termAtt.toString());\n          return true;\n        } else if (outputs.upto < outputs.count) {\n          // Still have pending outputs to replay at this\n          // position\n          input.reset();\n          final int posIncr = outputs.posIncr;\n          final CharsRef output = outputs.pullNext();\n          clearAttributes();\n          termAtt.copyBuffer(output.chars, output.offset, output.length);\n          typeAtt.setType(TYPE_SYNONYM);\n          int endOffset = outputs.getLastEndOffset();\n          if (endOffset == -1) {\n            endOffset = input.endOffset;\n          }\n          offsetAtt.setOffset(input.startOffset, endOffset);\n          posIncrAtt.setPositionIncrement(posIncr);\n          posLenAtt.setPositionLength(outputs.getLastPosLength());\n          if (outputs.count == 0) {\n            // Done with the buffered input and all outputs at\n            // this position\n            nextRead = rollIncr(nextRead);\n            inputSkipCount--;\n          }\n          //System.out.println(\"  return token=\" + termAtt.toString());\n          return true;\n        } else {\n          // Done with the buffered input and all outputs at\n          // this position\n          input.reset();\n          nextRead = rollIncr(nextRead);\n          inputSkipCount--;\n        }\n      }\n\n      if (finished && nextRead == nextWrite) {\n        // End case: if any output syns went beyond end of\n        // input stream, enumerate them now:\n        final PendingOutputs outputs = futureOutputs[nextRead];\n        if (outputs.upto < outputs.count) {\n          final int posIncr = outputs.posIncr;\n          final CharsRef output = outputs.pullNext();\n          futureInputs[nextRead].reset();\n          if (outputs.count == 0) {\n            nextWrite = nextRead = rollIncr(nextRead);\n          }\n          clearAttributes();\n          // Keep offset from last input token:\n          offsetAtt.setOffset(lastStartOffset, lastEndOffset);\n          termAtt.copyBuffer(output.chars, output.offset, output.length);\n          typeAtt.setType(TYPE_SYNONYM);\n          //System.out.println(\"  set posIncr=\" + outputs.posIncr + \" outputs=\" + outputs);\n          posIncrAtt.setPositionIncrement(posIncr);\n          //System.out.println(\"  return token=\" + termAtt.toString());\n          return true;\n        } else {\n          return false;\n        }\n      }\n\n      // Find new synonym matches:\n      parse();\n    }\n  }\n\n","sourceOld":"  @Override\n  public boolean incrementToken() throws IOException {\n\n    //System.out.println(\"\\nS: incrToken inputSkipCount=\" + inputSkipCount + \" nextRead=\" + nextRead + \" nextWrite=\" + nextWrite);\n\n    while(true) {\n\n      // First play back any buffered future inputs/outputs\n      // w/o running parsing again:\n      while (inputSkipCount != 0) {\n        \n        // At each position, we first output the original\n        // token\n\n        // TODO: maybe just a PendingState class, holding\n        // both input & outputs?\n        final PendingInput input = futureInputs[nextRead];\n        final PendingOutputs outputs = futureOutputs[nextRead];\n        \n        //System.out.println(\"  cycle nextRead=\" + nextRead + \" nextWrite=\" + nextWrite + \" inputSkipCount=\"+ inputSkipCount + \" input.keepOrig=\" + input.keepOrig + \" input.consumed=\" + input.consumed + \" input.state=\" + input.state);\n\n        if (!input.consumed && (input.keepOrig || !input.matched)) {\n          if (input.state != null) {\n            // Return a previously saved token (because we\n            // had to lookahead):\n            restoreState(input.state);\n          } else {\n            // Pass-through case: return token we just pulled\n            // but didn't capture:\n            assert inputSkipCount == 1: \"inputSkipCount=\" + inputSkipCount + \" nextRead=\" + nextRead;\n          }\n          input.reset();\n          if (outputs.count > 0) {\n            outputs.posIncr = 0;\n          } else {\n            nextRead = rollIncr(nextRead);\n            inputSkipCount--;\n          }\n          //System.out.println(\"  return token=\" + termAtt.toString());\n          return true;\n        } else if (outputs.upto < outputs.count) {\n          // Still have pending outputs to replay at this\n          // position\n          input.reset();\n          final int posIncr = outputs.posIncr;\n          final CharsRef output = outputs.pullNext();\n          clearAttributes();\n          termAtt.copyBuffer(output.chars, output.offset, output.length);\n          typeAtt.setType(TYPE_SYNONYM);\n          int endOffset = outputs.getLastEndOffset();\n          if (endOffset == -1) {\n            endOffset = input.endOffset;\n          }\n          offsetAtt.setOffset(input.startOffset, endOffset);\n          posIncrAtt.setPositionIncrement(posIncr);\n          posLenAtt.setPositionLength(outputs.getLastPosLength());\n          if (outputs.count == 0) {\n            // Done with the buffered input and all outputs at\n            // this position\n            nextRead = rollIncr(nextRead);\n            inputSkipCount--;\n          }\n          //System.out.println(\"  return token=\" + termAtt.toString());\n          return true;\n        } else {\n          // Done with the buffered input and all outputs at\n          // this position\n          input.reset();\n          nextRead = rollIncr(nextRead);\n          inputSkipCount--;\n        }\n      }\n\n      if (finished && nextRead == nextWrite) {\n        // End case: if any output syns went beyond end of\n        // input stream, enumerate them now:\n        final PendingOutputs outputs = futureOutputs[nextRead];\n        if (outputs.upto < outputs.count) {\n          final int posIncr = outputs.posIncr;\n          final CharsRef output = outputs.pullNext();\n          futureInputs[nextRead].reset();\n          if (outputs.count == 0) {\n            nextWrite = nextRead = rollIncr(nextRead);\n          }\n          clearAttributes();\n          // Keep offset from last input token:\n          offsetAtt.setOffset(lastStartOffset, lastEndOffset);\n          termAtt.copyBuffer(output.chars, output.offset, output.length);\n          typeAtt.setType(TYPE_SYNONYM);\n          //System.out.println(\"  set posIncr=\" + outputs.posIncr + \" outputs=\" + outputs);\n          posIncrAtt.setPositionIncrement(posIncr);\n          //System.out.println(\"  return token=\" + termAtt.toString());\n          return true;\n        } else {\n          return false;\n        }\n      }\n\n      // Find new synonym matches:\n      parse();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["ffbcd36aff3bb411177ed61f02fb3d3aa9588d27"],"865b7d0f8430a08d385370b6b87a89a737aa6145":["de11853c992f764e52d4164cc9afdebb989dba8a"],"de11853c992f764e52d4164cc9afdebb989dba8a":["44d6f0ab53c1962856b9f48dedb7a2a6cc18905c"],"b7c49a1b0f95bf8ecc502e6d44d79e4809dbf8ee":["865b7d0f8430a08d385370b6b87a89a737aa6145"],"ffbcd36aff3bb411177ed61f02fb3d3aa9588d27":["b7c49a1b0f95bf8ecc502e6d44d79e4809dbf8ee"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b59603a30f81d2af70cd2033270521dc7c8ec626":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"44d6f0ab53c1962856b9f48dedb7a2a6cc18905c":["a7347509fad0711ac30cb15a746e9a3830a38ebd"],"a7347509fad0711ac30cb15a746e9a3830a38ebd":["b59603a30f81d2af70cd2033270521dc7c8ec626"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b89678825b68eccaf09e6ab71675fc0b0af1e099"]},"commit2Childs":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"865b7d0f8430a08d385370b6b87a89a737aa6145":["b7c49a1b0f95bf8ecc502e6d44d79e4809dbf8ee"],"de11853c992f764e52d4164cc9afdebb989dba8a":["865b7d0f8430a08d385370b6b87a89a737aa6145"],"b7c49a1b0f95bf8ecc502e6d44d79e4809dbf8ee":["ffbcd36aff3bb411177ed61f02fb3d3aa9588d27"],"ffbcd36aff3bb411177ed61f02fb3d3aa9588d27":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b59603a30f81d2af70cd2033270521dc7c8ec626"],"b59603a30f81d2af70cd2033270521dc7c8ec626":["a7347509fad0711ac30cb15a746e9a3830a38ebd"],"44d6f0ab53c1962856b9f48dedb7a2a6cc18905c":["de11853c992f764e52d4164cc9afdebb989dba8a"],"a7347509fad0711ac30cb15a746e9a3830a38ebd":["44d6f0ab53c1962856b9f48dedb7a2a6cc18905c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}