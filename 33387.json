{"path":"solr/core/src/java/org/apache/solr/handler/admin/MetricsHistoryHandler#collectGlobalMetrics().mjava","commits":[{"id":"4181b4cf0450ea3c6d1aff8dc3ad4ed9cd3eeb6a","date":1527582939,"type":0,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/admin/MetricsHistoryHandler#collectGlobalMetrics().mjava","pathOld":"/dev/null","sourceNew":"  private void collectGlobalMetrics() {\n    if (!isOverseerLeader()) {\n      return;\n    }\n    Set<String> nodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n    NodeStateProvider nodeStateProvider = cloudManager.getNodeStateProvider();\n    Set<String> collTags = new HashSet<>();\n    collTags.addAll(counters.get(Group.core.toString()));\n    collTags.addAll(gauges.get(Group.core.toString()));\n\n    Set<String> nodeTags = new HashSet<>();\n    String nodePrefix = \"metrics:\" + SolrMetricManager.getRegistryName(Group.node) + \":\";\n    counters.get(Group.node.toString()).forEach(name -> {\n      nodeTags.add(nodePrefix + name);\n    });\n    gauges.get(Group.node.toString()).forEach(name -> {\n      nodeTags.add(nodePrefix + name);\n    });\n    String jvmPrefix = \"metrics:\" + SolrMetricManager.getRegistryName(Group.jvm) + \":\";\n    counters.get(Group.jvm.toString()).forEach(name -> {\n      nodeTags.add(jvmPrefix + name);\n    });\n    gauges.get(Group.jvm.toString()).forEach(name -> {\n      nodeTags.add(jvmPrefix + name);\n    });\n\n    // per-registry totals\n    // XXX at the moment the type of metrics that we collect allows\n    // adding all partial values. At some point it may be necessary to implement\n    // other aggregation functions.\n    // group : registry : name : value\n    Map<Group, Map<String, Map<String, Number>>> totals = new HashMap<>();\n\n    // collect and aggregate per-collection totals\n    for (String node : nodes) {\n      if (cloudManager.isClosed() || Thread.interrupted()) {\n        return;\n      }\n      // add core-level stats\n      Map<String, Map<String, List<ReplicaInfo>>> infos = nodeStateProvider.getReplicaInfo(node, collTags);\n      infos.forEach((coll, shards) -> {\n        shards.forEach((sh, replicas) -> {\n          String registry = SolrMetricManager.getRegistryName(Group.collection, coll);\n          Map<String, Number> perReg = totals\n              .computeIfAbsent(Group.collection, g -> new HashMap<>())\n              .computeIfAbsent(registry, r -> new HashMap<>());\n          replicas.forEach(ri -> {\n            collTags.forEach(tag -> {\n              double value = ((Number)ri.getVariable(tag, 0.0)).doubleValue();\n              // TODO: fix this when Suggestion.Condition.DISK_IDX uses proper conversion\n              if (tag.contains(Suggestion.coreidxsize)) {\n                value = value * 1024.0 * 1024.0 * 1024.0;\n              }\n              DoubleAdder adder = (DoubleAdder)perReg.computeIfAbsent(tag, t -> new DoubleAdder());\n              adder.add(value);\n            });\n          });\n        });\n      });\n      // add node-level stats\n      Map<String, Object> nodeValues = nodeStateProvider.getNodeValues(node, nodeTags);\n      for (Group g : Arrays.asList(Group.node, Group.jvm)) {\n        String registry = SolrMetricManager.getRegistryName(g);\n        Map<String, Number> perReg = totals\n            .computeIfAbsent(g, gr -> new HashMap<>())\n            .computeIfAbsent(registry, r -> new HashMap<>());\n        Set<String> names = new HashSet<>();\n        names.addAll(counters.get(g.toString()));\n        names.addAll(gauges.get(g.toString()));\n        names.forEach(name -> {\n          String tag = \"metrics:\" + registry + \":\" + name;\n          double value = ((Number)nodeValues.getOrDefault(tag, 0.0)).doubleValue();\n          DoubleAdder adder = (DoubleAdder)perReg.computeIfAbsent(name, t -> new DoubleAdder());\n          adder.add(value);\n        });\n      }\n    }\n\n    // add numNodes\n    String nodeReg = SolrMetricManager.getRegistryName(Group.node);\n    Map<String, Number> perNodeReg = totals\n        .computeIfAbsent(Group.node, gr -> new HashMap<>())\n        .computeIfAbsent(nodeReg, r -> new HashMap<>());\n    perNodeReg.put(NUM_NODES_KEY, nodes.size());\n\n    // add some global collection-level stats\n    try {\n      ClusterState state = cloudManager.getClusterStateProvider().getClusterState();\n      state.forEachCollection(coll -> {\n        String registry = SolrMetricManager.getRegistryName(Group.collection, coll.getName());\n        Map<String, Number> perReg = totals\n            .computeIfAbsent(Group.collection, g -> new HashMap<>())\n            .computeIfAbsent(registry, r -> new HashMap<>());\n        Collection<Slice> slices = coll.getActiveSlices();\n        perReg.put(NUM_SHARDS_KEY, slices.size());\n        DoubleAdder numActiveReplicas = new DoubleAdder();\n        slices.forEach(s -> {\n          s.forEach(r -> {\n            if (r.isActive(state.getLiveNodes())) {\n              numActiveReplicas.add(1.0);\n            }\n          });\n        });\n        perReg.put(NUM_REPLICAS_KEY, numActiveReplicas);\n      });\n    } catch (IOException e) {\n      log.warn(\"Exception getting cluster state\", e);\n    }\n\n    // now update the db-s\n    totals.forEach((group, perGroup) -> {\n      perGroup.forEach((reg, perReg) -> {\n        RrdDb db = getOrCreateDb(reg, group);\n        if (db == null) {\n          return;\n        }\n        try {\n          // set the timestamp\n          Sample s = db.createSample(TimeUnit.SECONDS.convert(timeSource.getEpochTimeNs(), TimeUnit.NANOSECONDS));\n          AtomicBoolean dirty = new AtomicBoolean(false);\n          List<Group> groups = new ArrayList<>();\n          groups.add(group);\n          if (group == Group.collection) {\n            groups.add(Group.core);\n          }\n          for (Group g : groups) {\n            counters.get(g.toString()).forEach(c -> {\n              Number val = perReg.get(c);\n              if (val != null) {\n                dirty.set(true);\n                s.setValue(c, val.doubleValue());\n              }\n            });\n            gauges.get(g.toString()).forEach(c -> {\n              Number val = perReg.get(c);\n              if (val != null) {\n                dirty.set(true);\n                s.setValue(c, val.doubleValue());\n              }\n            });\n          }\n          if (dirty.get()) {\n            s.update();\n          }\n        } catch (Exception e) {\n        }\n      });\n    });\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["f8f0f2472d437d44ec2144932e1d13fb494e82a3"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f8f0f2472d437d44ec2144932e1d13fb494e82a3","date":1528403207,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/admin/MetricsHistoryHandler#collectGlobalMetrics().mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/admin/MetricsHistoryHandler#collectGlobalMetrics().mjava","sourceNew":"  private void collectGlobalMetrics() {\n    if (!amIOverseerLeader()) {\n      return;\n    }\n    Set<String> nodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n    NodeStateProvider nodeStateProvider = cloudManager.getNodeStateProvider();\n    Set<String> collTags = new HashSet<>();\n    collTags.addAll(counters.get(Group.core.toString()));\n    collTags.addAll(gauges.get(Group.core.toString()));\n\n    Set<String> nodeTags = new HashSet<>();\n    String nodePrefix = \"metrics:\" + SolrMetricManager.getRegistryName(Group.node) + \":\";\n    counters.get(Group.node.toString()).forEach(name -> {\n      nodeTags.add(nodePrefix + name);\n    });\n    gauges.get(Group.node.toString()).forEach(name -> {\n      nodeTags.add(nodePrefix + name);\n    });\n    String jvmPrefix = \"metrics:\" + SolrMetricManager.getRegistryName(Group.jvm) + \":\";\n    counters.get(Group.jvm.toString()).forEach(name -> {\n      nodeTags.add(jvmPrefix + name);\n    });\n    gauges.get(Group.jvm.toString()).forEach(name -> {\n      nodeTags.add(jvmPrefix + name);\n    });\n\n    // per-registry totals\n    // XXX at the moment the type of metrics that we collect allows\n    // adding all partial values. At some point it may be necessary to implement\n    // other aggregation functions.\n    // group : registry : name : value\n    Map<Group, Map<String, Map<String, Number>>> totals = new HashMap<>();\n\n    // collect and aggregate per-collection totals\n    for (String node : nodes) {\n      if (cloudManager.isClosed() || Thread.interrupted()) {\n        return;\n      }\n      // add core-level stats\n      Map<String, Map<String, List<ReplicaInfo>>> infos = nodeStateProvider.getReplicaInfo(node, collTags);\n      infos.forEach((coll, shards) -> {\n        shards.forEach((sh, replicas) -> {\n          String registry = SolrMetricManager.getRegistryName(Group.collection, coll);\n          Map<String, Number> perReg = totals\n              .computeIfAbsent(Group.collection, g -> new HashMap<>())\n              .computeIfAbsent(registry, r -> new HashMap<>());\n          replicas.forEach(ri -> {\n            collTags.forEach(tag -> {\n              double value = ((Number)ri.getVariable(tag, 0.0)).doubleValue();\n              // TODO: fix this when Suggestion.Condition.DISK_IDX uses proper conversion\n              if (tag.contains(Suggestion.coreidxsize)) {\n                value = value * 1024.0 * 1024.0 * 1024.0;\n              }\n              DoubleAdder adder = (DoubleAdder)perReg.computeIfAbsent(tag, t -> new DoubleAdder());\n              adder.add(value);\n            });\n          });\n        });\n      });\n      // add node-level stats\n      Map<String, Object> nodeValues = nodeStateProvider.getNodeValues(node, nodeTags);\n      for (Group g : Arrays.asList(Group.node, Group.jvm)) {\n        String registry = SolrMetricManager.getRegistryName(g);\n        Map<String, Number> perReg = totals\n            .computeIfAbsent(g, gr -> new HashMap<>())\n            .computeIfAbsent(registry, r -> new HashMap<>());\n        Set<String> names = new HashSet<>();\n        names.addAll(counters.get(g.toString()));\n        names.addAll(gauges.get(g.toString()));\n        names.forEach(name -> {\n          String tag = \"metrics:\" + registry + \":\" + name;\n          double value = ((Number)nodeValues.getOrDefault(tag, 0.0)).doubleValue();\n          DoubleAdder adder = (DoubleAdder)perReg.computeIfAbsent(name, t -> new DoubleAdder());\n          adder.add(value);\n        });\n      }\n    }\n\n    // add numNodes\n    String nodeReg = SolrMetricManager.getRegistryName(Group.node);\n    Map<String, Number> perNodeReg = totals\n        .computeIfAbsent(Group.node, gr -> new HashMap<>())\n        .computeIfAbsent(nodeReg, r -> new HashMap<>());\n    perNodeReg.put(NUM_NODES_KEY, nodes.size());\n\n    // add some global collection-level stats\n    try {\n      ClusterState state = cloudManager.getClusterStateProvider().getClusterState();\n      state.forEachCollection(coll -> {\n        String registry = SolrMetricManager.getRegistryName(Group.collection, coll.getName());\n        Map<String, Number> perReg = totals\n            .computeIfAbsent(Group.collection, g -> new HashMap<>())\n            .computeIfAbsent(registry, r -> new HashMap<>());\n        Collection<Slice> slices = coll.getActiveSlices();\n        perReg.put(NUM_SHARDS_KEY, slices.size());\n        DoubleAdder numActiveReplicas = new DoubleAdder();\n        slices.forEach(s -> {\n          s.forEach(r -> {\n            if (r.isActive(state.getLiveNodes())) {\n              numActiveReplicas.add(1.0);\n            }\n          });\n        });\n        perReg.put(NUM_REPLICAS_KEY, numActiveReplicas);\n      });\n    } catch (IOException e) {\n      log.warn(\"Exception getting cluster state\", e);\n    }\n\n    // now update the db-s\n    totals.forEach((group, perGroup) -> {\n      perGroup.forEach((reg, perReg) -> {\n        RrdDb db = getOrCreateDb(reg, group);\n        if (db == null) {\n          return;\n        }\n        try {\n          // set the timestamp\n          Sample s = db.createSample(TimeUnit.SECONDS.convert(timeSource.getEpochTimeNs(), TimeUnit.NANOSECONDS));\n          AtomicBoolean dirty = new AtomicBoolean(false);\n          List<Group> groups = new ArrayList<>();\n          groups.add(group);\n          if (group == Group.collection) {\n            groups.add(Group.core);\n          }\n          for (Group g : groups) {\n            counters.get(g.toString()).forEach(c -> {\n              Number val = perReg.get(c);\n              if (val != null) {\n                dirty.set(true);\n                s.setValue(c, val.doubleValue());\n              }\n            });\n            gauges.get(g.toString()).forEach(c -> {\n              Number val = perReg.get(c);\n              if (val != null) {\n                dirty.set(true);\n                s.setValue(c, val.doubleValue());\n              }\n            });\n          }\n          if (dirty.get()) {\n            s.update();\n          }\n        } catch (Exception e) {\n        }\n      });\n    });\n  }\n\n","sourceOld":"  private void collectGlobalMetrics() {\n    if (!isOverseerLeader()) {\n      return;\n    }\n    Set<String> nodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n    NodeStateProvider nodeStateProvider = cloudManager.getNodeStateProvider();\n    Set<String> collTags = new HashSet<>();\n    collTags.addAll(counters.get(Group.core.toString()));\n    collTags.addAll(gauges.get(Group.core.toString()));\n\n    Set<String> nodeTags = new HashSet<>();\n    String nodePrefix = \"metrics:\" + SolrMetricManager.getRegistryName(Group.node) + \":\";\n    counters.get(Group.node.toString()).forEach(name -> {\n      nodeTags.add(nodePrefix + name);\n    });\n    gauges.get(Group.node.toString()).forEach(name -> {\n      nodeTags.add(nodePrefix + name);\n    });\n    String jvmPrefix = \"metrics:\" + SolrMetricManager.getRegistryName(Group.jvm) + \":\";\n    counters.get(Group.jvm.toString()).forEach(name -> {\n      nodeTags.add(jvmPrefix + name);\n    });\n    gauges.get(Group.jvm.toString()).forEach(name -> {\n      nodeTags.add(jvmPrefix + name);\n    });\n\n    // per-registry totals\n    // XXX at the moment the type of metrics that we collect allows\n    // adding all partial values. At some point it may be necessary to implement\n    // other aggregation functions.\n    // group : registry : name : value\n    Map<Group, Map<String, Map<String, Number>>> totals = new HashMap<>();\n\n    // collect and aggregate per-collection totals\n    for (String node : nodes) {\n      if (cloudManager.isClosed() || Thread.interrupted()) {\n        return;\n      }\n      // add core-level stats\n      Map<String, Map<String, List<ReplicaInfo>>> infos = nodeStateProvider.getReplicaInfo(node, collTags);\n      infos.forEach((coll, shards) -> {\n        shards.forEach((sh, replicas) -> {\n          String registry = SolrMetricManager.getRegistryName(Group.collection, coll);\n          Map<String, Number> perReg = totals\n              .computeIfAbsent(Group.collection, g -> new HashMap<>())\n              .computeIfAbsent(registry, r -> new HashMap<>());\n          replicas.forEach(ri -> {\n            collTags.forEach(tag -> {\n              double value = ((Number)ri.getVariable(tag, 0.0)).doubleValue();\n              // TODO: fix this when Suggestion.Condition.DISK_IDX uses proper conversion\n              if (tag.contains(Suggestion.coreidxsize)) {\n                value = value * 1024.0 * 1024.0 * 1024.0;\n              }\n              DoubleAdder adder = (DoubleAdder)perReg.computeIfAbsent(tag, t -> new DoubleAdder());\n              adder.add(value);\n            });\n          });\n        });\n      });\n      // add node-level stats\n      Map<String, Object> nodeValues = nodeStateProvider.getNodeValues(node, nodeTags);\n      for (Group g : Arrays.asList(Group.node, Group.jvm)) {\n        String registry = SolrMetricManager.getRegistryName(g);\n        Map<String, Number> perReg = totals\n            .computeIfAbsent(g, gr -> new HashMap<>())\n            .computeIfAbsent(registry, r -> new HashMap<>());\n        Set<String> names = new HashSet<>();\n        names.addAll(counters.get(g.toString()));\n        names.addAll(gauges.get(g.toString()));\n        names.forEach(name -> {\n          String tag = \"metrics:\" + registry + \":\" + name;\n          double value = ((Number)nodeValues.getOrDefault(tag, 0.0)).doubleValue();\n          DoubleAdder adder = (DoubleAdder)perReg.computeIfAbsent(name, t -> new DoubleAdder());\n          adder.add(value);\n        });\n      }\n    }\n\n    // add numNodes\n    String nodeReg = SolrMetricManager.getRegistryName(Group.node);\n    Map<String, Number> perNodeReg = totals\n        .computeIfAbsent(Group.node, gr -> new HashMap<>())\n        .computeIfAbsent(nodeReg, r -> new HashMap<>());\n    perNodeReg.put(NUM_NODES_KEY, nodes.size());\n\n    // add some global collection-level stats\n    try {\n      ClusterState state = cloudManager.getClusterStateProvider().getClusterState();\n      state.forEachCollection(coll -> {\n        String registry = SolrMetricManager.getRegistryName(Group.collection, coll.getName());\n        Map<String, Number> perReg = totals\n            .computeIfAbsent(Group.collection, g -> new HashMap<>())\n            .computeIfAbsent(registry, r -> new HashMap<>());\n        Collection<Slice> slices = coll.getActiveSlices();\n        perReg.put(NUM_SHARDS_KEY, slices.size());\n        DoubleAdder numActiveReplicas = new DoubleAdder();\n        slices.forEach(s -> {\n          s.forEach(r -> {\n            if (r.isActive(state.getLiveNodes())) {\n              numActiveReplicas.add(1.0);\n            }\n          });\n        });\n        perReg.put(NUM_REPLICAS_KEY, numActiveReplicas);\n      });\n    } catch (IOException e) {\n      log.warn(\"Exception getting cluster state\", e);\n    }\n\n    // now update the db-s\n    totals.forEach((group, perGroup) -> {\n      perGroup.forEach((reg, perReg) -> {\n        RrdDb db = getOrCreateDb(reg, group);\n        if (db == null) {\n          return;\n        }\n        try {\n          // set the timestamp\n          Sample s = db.createSample(TimeUnit.SECONDS.convert(timeSource.getEpochTimeNs(), TimeUnit.NANOSECONDS));\n          AtomicBoolean dirty = new AtomicBoolean(false);\n          List<Group> groups = new ArrayList<>();\n          groups.add(group);\n          if (group == Group.collection) {\n            groups.add(Group.core);\n          }\n          for (Group g : groups) {\n            counters.get(g.toString()).forEach(c -> {\n              Number val = perReg.get(c);\n              if (val != null) {\n                dirty.set(true);\n                s.setValue(c, val.doubleValue());\n              }\n            });\n            gauges.get(g.toString()).forEach(c -> {\n              Number val = perReg.get(c);\n              if (val != null) {\n                dirty.set(true);\n                s.setValue(c, val.doubleValue());\n              }\n            });\n          }\n          if (dirty.get()) {\n            s.update();\n          }\n        } catch (Exception e) {\n        }\n      });\n    });\n  }\n\n","bugFix":["4181b4cf0450ea3c6d1aff8dc3ad4ed9cd3eeb6a"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"dcfa8a1a5da4cfdac38e256c38e4b631637aa157","date":1528911895,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/admin/MetricsHistoryHandler#collectGlobalMetrics().mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/admin/MetricsHistoryHandler#collectGlobalMetrics().mjava","sourceNew":"  private void collectGlobalMetrics() {\n    if (!amIOverseerLeader()) {\n      return;\n    }\n    Set<String> nodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n    NodeStateProvider nodeStateProvider = cloudManager.getNodeStateProvider();\n    Set<String> collTags = new HashSet<>();\n    collTags.addAll(counters.get(Group.core.toString()));\n    collTags.addAll(gauges.get(Group.core.toString()));\n\n    Set<String> nodeTags = new HashSet<>();\n    String nodePrefix = \"metrics:\" + SolrMetricManager.getRegistryName(Group.node) + \":\";\n    counters.get(Group.node.toString()).forEach(name -> {\n      nodeTags.add(nodePrefix + name);\n    });\n    gauges.get(Group.node.toString()).forEach(name -> {\n      nodeTags.add(nodePrefix + name);\n    });\n    String jvmPrefix = \"metrics:\" + SolrMetricManager.getRegistryName(Group.jvm) + \":\";\n    counters.get(Group.jvm.toString()).forEach(name -> {\n      nodeTags.add(jvmPrefix + name);\n    });\n    gauges.get(Group.jvm.toString()).forEach(name -> {\n      nodeTags.add(jvmPrefix + name);\n    });\n\n    // per-registry totals\n    // XXX at the moment the type of metrics that we collect allows\n    // adding all partial values. At some point it may be necessary to implement\n    // other aggregation functions.\n    // group : registry : name : value\n    Map<Group, Map<String, Map<String, Number>>> totals = new HashMap<>();\n\n    // collect and aggregate per-collection totals\n    for (String node : nodes) {\n      if (cloudManager.isClosed() || Thread.interrupted()) {\n        return;\n      }\n      // add core-level stats\n      Map<String, Map<String, List<ReplicaInfo>>> infos = nodeStateProvider.getReplicaInfo(node, collTags);\n      infos.forEach((coll, shards) -> {\n        shards.forEach((sh, replicas) -> {\n          String registry = SolrMetricManager.getRegistryName(Group.collection, coll);\n          Map<String, Number> perReg = totals\n              .computeIfAbsent(Group.collection, g -> new HashMap<>())\n              .computeIfAbsent(registry, r -> new HashMap<>());\n          replicas.forEach(ri -> {\n            collTags.forEach(tag -> {\n              double value = ((Number)ri.getVariable(tag, 0.0)).doubleValue();\n              DoubleAdder adder = (DoubleAdder)perReg.computeIfAbsent(tag, t -> new DoubleAdder());\n              adder.add(value);\n            });\n          });\n        });\n      });\n      // add node-level stats\n      Map<String, Object> nodeValues = nodeStateProvider.getNodeValues(node, nodeTags);\n      for (Group g : Arrays.asList(Group.node, Group.jvm)) {\n        String registry = SolrMetricManager.getRegistryName(g);\n        Map<String, Number> perReg = totals\n            .computeIfAbsent(g, gr -> new HashMap<>())\n            .computeIfAbsent(registry, r -> new HashMap<>());\n        Set<String> names = new HashSet<>();\n        names.addAll(counters.get(g.toString()));\n        names.addAll(gauges.get(g.toString()));\n        names.forEach(name -> {\n          String tag = \"metrics:\" + registry + \":\" + name;\n          double value = ((Number)nodeValues.getOrDefault(tag, 0.0)).doubleValue();\n          DoubleAdder adder = (DoubleAdder)perReg.computeIfAbsent(name, t -> new DoubleAdder());\n          adder.add(value);\n        });\n      }\n    }\n\n    // add numNodes\n    String nodeReg = SolrMetricManager.getRegistryName(Group.node);\n    Map<String, Number> perNodeReg = totals\n        .computeIfAbsent(Group.node, gr -> new HashMap<>())\n        .computeIfAbsent(nodeReg, r -> new HashMap<>());\n    perNodeReg.put(NUM_NODES_KEY, nodes.size());\n\n    // add some global collection-level stats\n    try {\n      ClusterState state = cloudManager.getClusterStateProvider().getClusterState();\n      state.forEachCollection(coll -> {\n        String registry = SolrMetricManager.getRegistryName(Group.collection, coll.getName());\n        Map<String, Number> perReg = totals\n            .computeIfAbsent(Group.collection, g -> new HashMap<>())\n            .computeIfAbsent(registry, r -> new HashMap<>());\n        Collection<Slice> slices = coll.getActiveSlices();\n        perReg.put(NUM_SHARDS_KEY, slices.size());\n        DoubleAdder numActiveReplicas = new DoubleAdder();\n        slices.forEach(s -> {\n          s.forEach(r -> {\n            if (r.isActive(state.getLiveNodes())) {\n              numActiveReplicas.add(1.0);\n            }\n          });\n        });\n        perReg.put(NUM_REPLICAS_KEY, numActiveReplicas);\n      });\n    } catch (IOException e) {\n      log.warn(\"Exception getting cluster state\", e);\n    }\n\n    // now update the db-s\n    totals.forEach((group, perGroup) -> {\n      perGroup.forEach((reg, perReg) -> {\n        RrdDb db = getOrCreateDb(reg, group);\n        if (db == null) {\n          return;\n        }\n        try {\n          // set the timestamp\n          Sample s = db.createSample(TimeUnit.SECONDS.convert(timeSource.getEpochTimeNs(), TimeUnit.NANOSECONDS));\n          AtomicBoolean dirty = new AtomicBoolean(false);\n          List<Group> groups = new ArrayList<>();\n          groups.add(group);\n          if (group == Group.collection) {\n            groups.add(Group.core);\n          }\n          for (Group g : groups) {\n            counters.get(g.toString()).forEach(c -> {\n              Number val = perReg.get(c);\n              if (val != null) {\n                dirty.set(true);\n                s.setValue(c, val.doubleValue());\n              }\n            });\n            gauges.get(g.toString()).forEach(c -> {\n              Number val = perReg.get(c);\n              if (val != null) {\n                dirty.set(true);\n                s.setValue(c, val.doubleValue());\n              }\n            });\n          }\n          if (dirty.get()) {\n            s.update();\n          }\n        } catch (Exception e) {\n        }\n      });\n    });\n  }\n\n","sourceOld":"  private void collectGlobalMetrics() {\n    if (!amIOverseerLeader()) {\n      return;\n    }\n    Set<String> nodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n    NodeStateProvider nodeStateProvider = cloudManager.getNodeStateProvider();\n    Set<String> collTags = new HashSet<>();\n    collTags.addAll(counters.get(Group.core.toString()));\n    collTags.addAll(gauges.get(Group.core.toString()));\n\n    Set<String> nodeTags = new HashSet<>();\n    String nodePrefix = \"metrics:\" + SolrMetricManager.getRegistryName(Group.node) + \":\";\n    counters.get(Group.node.toString()).forEach(name -> {\n      nodeTags.add(nodePrefix + name);\n    });\n    gauges.get(Group.node.toString()).forEach(name -> {\n      nodeTags.add(nodePrefix + name);\n    });\n    String jvmPrefix = \"metrics:\" + SolrMetricManager.getRegistryName(Group.jvm) + \":\";\n    counters.get(Group.jvm.toString()).forEach(name -> {\n      nodeTags.add(jvmPrefix + name);\n    });\n    gauges.get(Group.jvm.toString()).forEach(name -> {\n      nodeTags.add(jvmPrefix + name);\n    });\n\n    // per-registry totals\n    // XXX at the moment the type of metrics that we collect allows\n    // adding all partial values. At some point it may be necessary to implement\n    // other aggregation functions.\n    // group : registry : name : value\n    Map<Group, Map<String, Map<String, Number>>> totals = new HashMap<>();\n\n    // collect and aggregate per-collection totals\n    for (String node : nodes) {\n      if (cloudManager.isClosed() || Thread.interrupted()) {\n        return;\n      }\n      // add core-level stats\n      Map<String, Map<String, List<ReplicaInfo>>> infos = nodeStateProvider.getReplicaInfo(node, collTags);\n      infos.forEach((coll, shards) -> {\n        shards.forEach((sh, replicas) -> {\n          String registry = SolrMetricManager.getRegistryName(Group.collection, coll);\n          Map<String, Number> perReg = totals\n              .computeIfAbsent(Group.collection, g -> new HashMap<>())\n              .computeIfAbsent(registry, r -> new HashMap<>());\n          replicas.forEach(ri -> {\n            collTags.forEach(tag -> {\n              double value = ((Number)ri.getVariable(tag, 0.0)).doubleValue();\n              // TODO: fix this when Suggestion.Condition.DISK_IDX uses proper conversion\n              if (tag.contains(Suggestion.coreidxsize)) {\n                value = value * 1024.0 * 1024.0 * 1024.0;\n              }\n              DoubleAdder adder = (DoubleAdder)perReg.computeIfAbsent(tag, t -> new DoubleAdder());\n              adder.add(value);\n            });\n          });\n        });\n      });\n      // add node-level stats\n      Map<String, Object> nodeValues = nodeStateProvider.getNodeValues(node, nodeTags);\n      for (Group g : Arrays.asList(Group.node, Group.jvm)) {\n        String registry = SolrMetricManager.getRegistryName(g);\n        Map<String, Number> perReg = totals\n            .computeIfAbsent(g, gr -> new HashMap<>())\n            .computeIfAbsent(registry, r -> new HashMap<>());\n        Set<String> names = new HashSet<>();\n        names.addAll(counters.get(g.toString()));\n        names.addAll(gauges.get(g.toString()));\n        names.forEach(name -> {\n          String tag = \"metrics:\" + registry + \":\" + name;\n          double value = ((Number)nodeValues.getOrDefault(tag, 0.0)).doubleValue();\n          DoubleAdder adder = (DoubleAdder)perReg.computeIfAbsent(name, t -> new DoubleAdder());\n          adder.add(value);\n        });\n      }\n    }\n\n    // add numNodes\n    String nodeReg = SolrMetricManager.getRegistryName(Group.node);\n    Map<String, Number> perNodeReg = totals\n        .computeIfAbsent(Group.node, gr -> new HashMap<>())\n        .computeIfAbsent(nodeReg, r -> new HashMap<>());\n    perNodeReg.put(NUM_NODES_KEY, nodes.size());\n\n    // add some global collection-level stats\n    try {\n      ClusterState state = cloudManager.getClusterStateProvider().getClusterState();\n      state.forEachCollection(coll -> {\n        String registry = SolrMetricManager.getRegistryName(Group.collection, coll.getName());\n        Map<String, Number> perReg = totals\n            .computeIfAbsent(Group.collection, g -> new HashMap<>())\n            .computeIfAbsent(registry, r -> new HashMap<>());\n        Collection<Slice> slices = coll.getActiveSlices();\n        perReg.put(NUM_SHARDS_KEY, slices.size());\n        DoubleAdder numActiveReplicas = new DoubleAdder();\n        slices.forEach(s -> {\n          s.forEach(r -> {\n            if (r.isActive(state.getLiveNodes())) {\n              numActiveReplicas.add(1.0);\n            }\n          });\n        });\n        perReg.put(NUM_REPLICAS_KEY, numActiveReplicas);\n      });\n    } catch (IOException e) {\n      log.warn(\"Exception getting cluster state\", e);\n    }\n\n    // now update the db-s\n    totals.forEach((group, perGroup) -> {\n      perGroup.forEach((reg, perReg) -> {\n        RrdDb db = getOrCreateDb(reg, group);\n        if (db == null) {\n          return;\n        }\n        try {\n          // set the timestamp\n          Sample s = db.createSample(TimeUnit.SECONDS.convert(timeSource.getEpochTimeNs(), TimeUnit.NANOSECONDS));\n          AtomicBoolean dirty = new AtomicBoolean(false);\n          List<Group> groups = new ArrayList<>();\n          groups.add(group);\n          if (group == Group.collection) {\n            groups.add(Group.core);\n          }\n          for (Group g : groups) {\n            counters.get(g.toString()).forEach(c -> {\n              Number val = perReg.get(c);\n              if (val != null) {\n                dirty.set(true);\n                s.setValue(c, val.doubleValue());\n              }\n            });\n            gauges.get(g.toString()).forEach(c -> {\n              Number val = perReg.get(c);\n              if (val != null) {\n                dirty.set(true);\n                s.setValue(c, val.doubleValue());\n              }\n            });\n          }\n          if (dirty.get()) {\n            s.update();\n          }\n        } catch (Exception e) {\n        }\n      });\n    });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26","date":1531589977,"type":3,"author":"Michael Braun","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/admin/MetricsHistoryHandler#collectGlobalMetrics().mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/admin/MetricsHistoryHandler#collectGlobalMetrics().mjava","sourceNew":"  private void collectGlobalMetrics() {\n    if (!amIOverseerLeader()) {\n      return;\n    }\n    Set<String> nodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n    NodeStateProvider nodeStateProvider = cloudManager.getNodeStateProvider();\n    Set<String> collTags = new HashSet<>();\n    collTags.addAll(counters.get(Group.core.toString()));\n    collTags.addAll(gauges.get(Group.core.toString()));\n\n    Set<String> nodeTags = new HashSet<>();\n    String nodePrefix = \"metrics:\" + SolrMetricManager.getRegistryName(Group.node) + \":\";\n    counters.get(Group.node.toString()).forEach(name -> {\n      nodeTags.add(nodePrefix + name);\n    });\n    gauges.get(Group.node.toString()).forEach(name -> {\n      nodeTags.add(nodePrefix + name);\n    });\n    String jvmPrefix = \"metrics:\" + SolrMetricManager.getRegistryName(Group.jvm) + \":\";\n    counters.get(Group.jvm.toString()).forEach(name -> {\n      nodeTags.add(jvmPrefix + name);\n    });\n    gauges.get(Group.jvm.toString()).forEach(name -> {\n      nodeTags.add(jvmPrefix + name);\n    });\n\n    // per-registry totals\n    // XXX at the moment the type of metrics that we collect allows\n    // adding all partial values. At some point it may be necessary to implement\n    // other aggregation functions.\n    // group : registry : name : value\n    Map<Group, Map<String, Map<String, Number>>> totals = new HashMap<>();\n\n    // collect and aggregate per-collection totals\n    for (String node : nodes) {\n      if (cloudManager.isClosed() || Thread.interrupted()) {\n        return;\n      }\n      // add core-level stats\n      Map<String, Map<String, List<ReplicaInfo>>> infos = nodeStateProvider.getReplicaInfo(node, collTags);\n      infos.forEach((coll, shards) -> {\n        shards.forEach((sh, replicas) -> {\n          String registry = SolrMetricManager.getRegistryName(Group.collection, coll);\n          Map<String, Number> perReg = totals\n              .computeIfAbsent(Group.collection, g -> new HashMap<>())\n              .computeIfAbsent(registry, r -> new HashMap<>());\n          replicas.forEach(ri -> {\n            collTags.forEach(tag -> {\n              double value = ((Number)ri.getVariable(tag, 0.0)).doubleValue();\n              DoubleAdder adder = (DoubleAdder)perReg.computeIfAbsent(tag, t -> new DoubleAdder());\n              adder.add(value);\n            });\n          });\n        });\n      });\n      // add node-level stats\n      Map<String, Object> nodeValues = nodeStateProvider.getNodeValues(node, nodeTags);\n      for (Group g : Arrays.asList(Group.node, Group.jvm)) {\n        String registry = SolrMetricManager.getRegistryName(g);\n        Map<String, Number> perReg = totals\n            .computeIfAbsent(g, gr -> new HashMap<>())\n            .computeIfAbsent(registry, r -> new HashMap<>());\n        Set<String> names = new HashSet<>();\n        names.addAll(counters.get(g.toString()));\n        names.addAll(gauges.get(g.toString()));\n        names.forEach(name -> {\n          String tag = \"metrics:\" + registry + \":\" + name;\n          double value = ((Number)nodeValues.getOrDefault(tag, 0.0)).doubleValue();\n          DoubleAdder adder = (DoubleAdder)perReg.computeIfAbsent(name, t -> new DoubleAdder());\n          adder.add(value);\n        });\n      }\n    }\n\n    // add numNodes\n    String nodeReg = SolrMetricManager.getRegistryName(Group.node);\n    Map<String, Number> perNodeReg = totals\n        .computeIfAbsent(Group.node, gr -> new HashMap<>())\n        .computeIfAbsent(nodeReg, r -> new HashMap<>());\n    perNodeReg.put(NUM_NODES_KEY, nodes.size());\n\n    // add some global collection-level stats\n    try {\n      ClusterState state = cloudManager.getClusterStateProvider().getClusterState();\n      state.forEachCollection(coll -> {\n        String registry = SolrMetricManager.getRegistryName(Group.collection, coll.getName());\n        Map<String, Number> perReg = totals\n            .computeIfAbsent(Group.collection, g -> new HashMap<>())\n            .computeIfAbsent(registry, r -> new HashMap<>());\n        Collection<Slice> slices = coll.getActiveSlices();\n        perReg.put(NUM_SHARDS_KEY, slices.size());\n        DoubleAdder numActiveReplicas = new DoubleAdder();\n        slices.forEach(s -> {\n          s.forEach(r -> {\n            if (r.isActive(state.getLiveNodes())) {\n              numActiveReplicas.add(1.0);\n            }\n          });\n        });\n        perReg.put(NUM_REPLICAS_KEY, numActiveReplicas);\n      });\n    } catch (IOException e) {\n      log.warn(\"Exception getting cluster state\", e);\n    }\n\n    // now update the db-s\n    totals.forEach((group, perGroup) -> {\n      perGroup.forEach((reg, perReg) -> {\n        RrdDb db = getOrCreateDb(reg, group);\n        if (db == null) {\n          return;\n        }\n        try {\n          // set the timestamp\n          Sample s = db.createSample(TimeUnit.SECONDS.convert(timeSource.getEpochTimeNs(), TimeUnit.NANOSECONDS));\n          AtomicBoolean dirty = new AtomicBoolean(false);\n          List<Group> groups = new ArrayList<>();\n          groups.add(group);\n          if (group == Group.collection) {\n            groups.add(Group.core);\n          }\n          for (Group g : groups) {\n            counters.get(g.toString()).forEach(c -> {\n              Number val = perReg.get(c);\n              if (val != null) {\n                dirty.set(true);\n                s.setValue(c, val.doubleValue());\n              }\n            });\n            gauges.get(g.toString()).forEach(c -> {\n              Number val = perReg.get(c);\n              if (val != null) {\n                dirty.set(true);\n                s.setValue(c, val.doubleValue());\n              }\n            });\n          }\n          if (dirty.get()) {\n            s.update();\n          }\n        } catch (Exception e) {\n        }\n      });\n    });\n  }\n\n","sourceOld":"  private void collectGlobalMetrics() {\n    if (!isOverseerLeader()) {\n      return;\n    }\n    Set<String> nodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n    NodeStateProvider nodeStateProvider = cloudManager.getNodeStateProvider();\n    Set<String> collTags = new HashSet<>();\n    collTags.addAll(counters.get(Group.core.toString()));\n    collTags.addAll(gauges.get(Group.core.toString()));\n\n    Set<String> nodeTags = new HashSet<>();\n    String nodePrefix = \"metrics:\" + SolrMetricManager.getRegistryName(Group.node) + \":\";\n    counters.get(Group.node.toString()).forEach(name -> {\n      nodeTags.add(nodePrefix + name);\n    });\n    gauges.get(Group.node.toString()).forEach(name -> {\n      nodeTags.add(nodePrefix + name);\n    });\n    String jvmPrefix = \"metrics:\" + SolrMetricManager.getRegistryName(Group.jvm) + \":\";\n    counters.get(Group.jvm.toString()).forEach(name -> {\n      nodeTags.add(jvmPrefix + name);\n    });\n    gauges.get(Group.jvm.toString()).forEach(name -> {\n      nodeTags.add(jvmPrefix + name);\n    });\n\n    // per-registry totals\n    // XXX at the moment the type of metrics that we collect allows\n    // adding all partial values. At some point it may be necessary to implement\n    // other aggregation functions.\n    // group : registry : name : value\n    Map<Group, Map<String, Map<String, Number>>> totals = new HashMap<>();\n\n    // collect and aggregate per-collection totals\n    for (String node : nodes) {\n      if (cloudManager.isClosed() || Thread.interrupted()) {\n        return;\n      }\n      // add core-level stats\n      Map<String, Map<String, List<ReplicaInfo>>> infos = nodeStateProvider.getReplicaInfo(node, collTags);\n      infos.forEach((coll, shards) -> {\n        shards.forEach((sh, replicas) -> {\n          String registry = SolrMetricManager.getRegistryName(Group.collection, coll);\n          Map<String, Number> perReg = totals\n              .computeIfAbsent(Group.collection, g -> new HashMap<>())\n              .computeIfAbsent(registry, r -> new HashMap<>());\n          replicas.forEach(ri -> {\n            collTags.forEach(tag -> {\n              double value = ((Number)ri.getVariable(tag, 0.0)).doubleValue();\n              // TODO: fix this when Suggestion.Condition.DISK_IDX uses proper conversion\n              if (tag.contains(Suggestion.coreidxsize)) {\n                value = value * 1024.0 * 1024.0 * 1024.0;\n              }\n              DoubleAdder adder = (DoubleAdder)perReg.computeIfAbsent(tag, t -> new DoubleAdder());\n              adder.add(value);\n            });\n          });\n        });\n      });\n      // add node-level stats\n      Map<String, Object> nodeValues = nodeStateProvider.getNodeValues(node, nodeTags);\n      for (Group g : Arrays.asList(Group.node, Group.jvm)) {\n        String registry = SolrMetricManager.getRegistryName(g);\n        Map<String, Number> perReg = totals\n            .computeIfAbsent(g, gr -> new HashMap<>())\n            .computeIfAbsent(registry, r -> new HashMap<>());\n        Set<String> names = new HashSet<>();\n        names.addAll(counters.get(g.toString()));\n        names.addAll(gauges.get(g.toString()));\n        names.forEach(name -> {\n          String tag = \"metrics:\" + registry + \":\" + name;\n          double value = ((Number)nodeValues.getOrDefault(tag, 0.0)).doubleValue();\n          DoubleAdder adder = (DoubleAdder)perReg.computeIfAbsent(name, t -> new DoubleAdder());\n          adder.add(value);\n        });\n      }\n    }\n\n    // add numNodes\n    String nodeReg = SolrMetricManager.getRegistryName(Group.node);\n    Map<String, Number> perNodeReg = totals\n        .computeIfAbsent(Group.node, gr -> new HashMap<>())\n        .computeIfAbsent(nodeReg, r -> new HashMap<>());\n    perNodeReg.put(NUM_NODES_KEY, nodes.size());\n\n    // add some global collection-level stats\n    try {\n      ClusterState state = cloudManager.getClusterStateProvider().getClusterState();\n      state.forEachCollection(coll -> {\n        String registry = SolrMetricManager.getRegistryName(Group.collection, coll.getName());\n        Map<String, Number> perReg = totals\n            .computeIfAbsent(Group.collection, g -> new HashMap<>())\n            .computeIfAbsent(registry, r -> new HashMap<>());\n        Collection<Slice> slices = coll.getActiveSlices();\n        perReg.put(NUM_SHARDS_KEY, slices.size());\n        DoubleAdder numActiveReplicas = new DoubleAdder();\n        slices.forEach(s -> {\n          s.forEach(r -> {\n            if (r.isActive(state.getLiveNodes())) {\n              numActiveReplicas.add(1.0);\n            }\n          });\n        });\n        perReg.put(NUM_REPLICAS_KEY, numActiveReplicas);\n      });\n    } catch (IOException e) {\n      log.warn(\"Exception getting cluster state\", e);\n    }\n\n    // now update the db-s\n    totals.forEach((group, perGroup) -> {\n      perGroup.forEach((reg, perReg) -> {\n        RrdDb db = getOrCreateDb(reg, group);\n        if (db == null) {\n          return;\n        }\n        try {\n          // set the timestamp\n          Sample s = db.createSample(TimeUnit.SECONDS.convert(timeSource.getEpochTimeNs(), TimeUnit.NANOSECONDS));\n          AtomicBoolean dirty = new AtomicBoolean(false);\n          List<Group> groups = new ArrayList<>();\n          groups.add(group);\n          if (group == Group.collection) {\n            groups.add(Group.core);\n          }\n          for (Group g : groups) {\n            counters.get(g.toString()).forEach(c -> {\n              Number val = perReg.get(c);\n              if (val != null) {\n                dirty.set(true);\n                s.setValue(c, val.doubleValue());\n              }\n            });\n            gauges.get(g.toString()).forEach(c -> {\n              Number val = perReg.get(c);\n              if (val != null) {\n                dirty.set(true);\n                s.setValue(c, val.doubleValue());\n              }\n            });\n          }\n          if (dirty.get()) {\n            s.update();\n          }\n        } catch (Exception e) {\n        }\n      });\n    });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","date":1531905561,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/admin/MetricsHistoryHandler#collectGlobalMetrics().mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/admin/MetricsHistoryHandler#collectGlobalMetrics().mjava","sourceNew":"  private void collectGlobalMetrics() {\n    if (!amIOverseerLeader()) {\n      return;\n    }\n    Set<String> nodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n    NodeStateProvider nodeStateProvider = cloudManager.getNodeStateProvider();\n    Set<String> collTags = new HashSet<>();\n    collTags.addAll(counters.get(Group.core.toString()));\n    collTags.addAll(gauges.get(Group.core.toString()));\n\n    Set<String> nodeTags = new HashSet<>();\n    String nodePrefix = \"metrics:\" + SolrMetricManager.getRegistryName(Group.node) + \":\";\n    counters.get(Group.node.toString()).forEach(name -> {\n      nodeTags.add(nodePrefix + name);\n    });\n    gauges.get(Group.node.toString()).forEach(name -> {\n      nodeTags.add(nodePrefix + name);\n    });\n    String jvmPrefix = \"metrics:\" + SolrMetricManager.getRegistryName(Group.jvm) + \":\";\n    counters.get(Group.jvm.toString()).forEach(name -> {\n      nodeTags.add(jvmPrefix + name);\n    });\n    gauges.get(Group.jvm.toString()).forEach(name -> {\n      nodeTags.add(jvmPrefix + name);\n    });\n\n    // per-registry totals\n    // XXX at the moment the type of metrics that we collect allows\n    // adding all partial values. At some point it may be necessary to implement\n    // other aggregation functions.\n    // group : registry : name : value\n    Map<Group, Map<String, Map<String, Number>>> totals = new HashMap<>();\n\n    // collect and aggregate per-collection totals\n    for (String node : nodes) {\n      if (cloudManager.isClosed() || Thread.interrupted()) {\n        return;\n      }\n      // add core-level stats\n      Map<String, Map<String, List<ReplicaInfo>>> infos = nodeStateProvider.getReplicaInfo(node, collTags);\n      infos.forEach((coll, shards) -> {\n        shards.forEach((sh, replicas) -> {\n          String registry = SolrMetricManager.getRegistryName(Group.collection, coll);\n          Map<String, Number> perReg = totals\n              .computeIfAbsent(Group.collection, g -> new HashMap<>())\n              .computeIfAbsent(registry, r -> new HashMap<>());\n          replicas.forEach(ri -> {\n            collTags.forEach(tag -> {\n              double value = ((Number)ri.getVariable(tag, 0.0)).doubleValue();\n              DoubleAdder adder = (DoubleAdder)perReg.computeIfAbsent(tag, t -> new DoubleAdder());\n              adder.add(value);\n            });\n          });\n        });\n      });\n      // add node-level stats\n      Map<String, Object> nodeValues = nodeStateProvider.getNodeValues(node, nodeTags);\n      for (Group g : Arrays.asList(Group.node, Group.jvm)) {\n        String registry = SolrMetricManager.getRegistryName(g);\n        Map<String, Number> perReg = totals\n            .computeIfAbsent(g, gr -> new HashMap<>())\n            .computeIfAbsent(registry, r -> new HashMap<>());\n        Set<String> names = new HashSet<>();\n        names.addAll(counters.get(g.toString()));\n        names.addAll(gauges.get(g.toString()));\n        names.forEach(name -> {\n          String tag = \"metrics:\" + registry + \":\" + name;\n          double value = ((Number)nodeValues.getOrDefault(tag, 0.0)).doubleValue();\n          DoubleAdder adder = (DoubleAdder)perReg.computeIfAbsent(name, t -> new DoubleAdder());\n          adder.add(value);\n        });\n      }\n    }\n\n    // add numNodes\n    String nodeReg = SolrMetricManager.getRegistryName(Group.node);\n    Map<String, Number> perNodeReg = totals\n        .computeIfAbsent(Group.node, gr -> new HashMap<>())\n        .computeIfAbsent(nodeReg, r -> new HashMap<>());\n    perNodeReg.put(NUM_NODES_KEY, nodes.size());\n\n    // add some global collection-level stats\n    try {\n      ClusterState state = cloudManager.getClusterStateProvider().getClusterState();\n      state.forEachCollection(coll -> {\n        String registry = SolrMetricManager.getRegistryName(Group.collection, coll.getName());\n        Map<String, Number> perReg = totals\n            .computeIfAbsent(Group.collection, g -> new HashMap<>())\n            .computeIfAbsent(registry, r -> new HashMap<>());\n        Collection<Slice> slices = coll.getActiveSlices();\n        perReg.put(NUM_SHARDS_KEY, slices.size());\n        DoubleAdder numActiveReplicas = new DoubleAdder();\n        slices.forEach(s -> {\n          s.forEach(r -> {\n            if (r.isActive(state.getLiveNodes())) {\n              numActiveReplicas.add(1.0);\n            }\n          });\n        });\n        perReg.put(NUM_REPLICAS_KEY, numActiveReplicas);\n      });\n    } catch (IOException e) {\n      log.warn(\"Exception getting cluster state\", e);\n    }\n\n    // now update the db-s\n    totals.forEach((group, perGroup) -> {\n      perGroup.forEach((reg, perReg) -> {\n        RrdDb db = getOrCreateDb(reg, group);\n        if (db == null) {\n          return;\n        }\n        try {\n          // set the timestamp\n          Sample s = db.createSample(TimeUnit.SECONDS.convert(timeSource.getEpochTimeNs(), TimeUnit.NANOSECONDS));\n          AtomicBoolean dirty = new AtomicBoolean(false);\n          List<Group> groups = new ArrayList<>();\n          groups.add(group);\n          if (group == Group.collection) {\n            groups.add(Group.core);\n          }\n          for (Group g : groups) {\n            counters.get(g.toString()).forEach(c -> {\n              Number val = perReg.get(c);\n              if (val != null) {\n                dirty.set(true);\n                s.setValue(c, val.doubleValue());\n              }\n            });\n            gauges.get(g.toString()).forEach(c -> {\n              Number val = perReg.get(c);\n              if (val != null) {\n                dirty.set(true);\n                s.setValue(c, val.doubleValue());\n              }\n            });\n          }\n          if (dirty.get()) {\n            s.update();\n          }\n        } catch (Exception e) {\n        }\n      });\n    });\n  }\n\n","sourceOld":"  private void collectGlobalMetrics() {\n    if (!isOverseerLeader()) {\n      return;\n    }\n    Set<String> nodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n    NodeStateProvider nodeStateProvider = cloudManager.getNodeStateProvider();\n    Set<String> collTags = new HashSet<>();\n    collTags.addAll(counters.get(Group.core.toString()));\n    collTags.addAll(gauges.get(Group.core.toString()));\n\n    Set<String> nodeTags = new HashSet<>();\n    String nodePrefix = \"metrics:\" + SolrMetricManager.getRegistryName(Group.node) + \":\";\n    counters.get(Group.node.toString()).forEach(name -> {\n      nodeTags.add(nodePrefix + name);\n    });\n    gauges.get(Group.node.toString()).forEach(name -> {\n      nodeTags.add(nodePrefix + name);\n    });\n    String jvmPrefix = \"metrics:\" + SolrMetricManager.getRegistryName(Group.jvm) + \":\";\n    counters.get(Group.jvm.toString()).forEach(name -> {\n      nodeTags.add(jvmPrefix + name);\n    });\n    gauges.get(Group.jvm.toString()).forEach(name -> {\n      nodeTags.add(jvmPrefix + name);\n    });\n\n    // per-registry totals\n    // XXX at the moment the type of metrics that we collect allows\n    // adding all partial values. At some point it may be necessary to implement\n    // other aggregation functions.\n    // group : registry : name : value\n    Map<Group, Map<String, Map<String, Number>>> totals = new HashMap<>();\n\n    // collect and aggregate per-collection totals\n    for (String node : nodes) {\n      if (cloudManager.isClosed() || Thread.interrupted()) {\n        return;\n      }\n      // add core-level stats\n      Map<String, Map<String, List<ReplicaInfo>>> infos = nodeStateProvider.getReplicaInfo(node, collTags);\n      infos.forEach((coll, shards) -> {\n        shards.forEach((sh, replicas) -> {\n          String registry = SolrMetricManager.getRegistryName(Group.collection, coll);\n          Map<String, Number> perReg = totals\n              .computeIfAbsent(Group.collection, g -> new HashMap<>())\n              .computeIfAbsent(registry, r -> new HashMap<>());\n          replicas.forEach(ri -> {\n            collTags.forEach(tag -> {\n              double value = ((Number)ri.getVariable(tag, 0.0)).doubleValue();\n              // TODO: fix this when Suggestion.Condition.DISK_IDX uses proper conversion\n              if (tag.contains(Suggestion.coreidxsize)) {\n                value = value * 1024.0 * 1024.0 * 1024.0;\n              }\n              DoubleAdder adder = (DoubleAdder)perReg.computeIfAbsent(tag, t -> new DoubleAdder());\n              adder.add(value);\n            });\n          });\n        });\n      });\n      // add node-level stats\n      Map<String, Object> nodeValues = nodeStateProvider.getNodeValues(node, nodeTags);\n      for (Group g : Arrays.asList(Group.node, Group.jvm)) {\n        String registry = SolrMetricManager.getRegistryName(g);\n        Map<String, Number> perReg = totals\n            .computeIfAbsent(g, gr -> new HashMap<>())\n            .computeIfAbsent(registry, r -> new HashMap<>());\n        Set<String> names = new HashSet<>();\n        names.addAll(counters.get(g.toString()));\n        names.addAll(gauges.get(g.toString()));\n        names.forEach(name -> {\n          String tag = \"metrics:\" + registry + \":\" + name;\n          double value = ((Number)nodeValues.getOrDefault(tag, 0.0)).doubleValue();\n          DoubleAdder adder = (DoubleAdder)perReg.computeIfAbsent(name, t -> new DoubleAdder());\n          adder.add(value);\n        });\n      }\n    }\n\n    // add numNodes\n    String nodeReg = SolrMetricManager.getRegistryName(Group.node);\n    Map<String, Number> perNodeReg = totals\n        .computeIfAbsent(Group.node, gr -> new HashMap<>())\n        .computeIfAbsent(nodeReg, r -> new HashMap<>());\n    perNodeReg.put(NUM_NODES_KEY, nodes.size());\n\n    // add some global collection-level stats\n    try {\n      ClusterState state = cloudManager.getClusterStateProvider().getClusterState();\n      state.forEachCollection(coll -> {\n        String registry = SolrMetricManager.getRegistryName(Group.collection, coll.getName());\n        Map<String, Number> perReg = totals\n            .computeIfAbsent(Group.collection, g -> new HashMap<>())\n            .computeIfAbsent(registry, r -> new HashMap<>());\n        Collection<Slice> slices = coll.getActiveSlices();\n        perReg.put(NUM_SHARDS_KEY, slices.size());\n        DoubleAdder numActiveReplicas = new DoubleAdder();\n        slices.forEach(s -> {\n          s.forEach(r -> {\n            if (r.isActive(state.getLiveNodes())) {\n              numActiveReplicas.add(1.0);\n            }\n          });\n        });\n        perReg.put(NUM_REPLICAS_KEY, numActiveReplicas);\n      });\n    } catch (IOException e) {\n      log.warn(\"Exception getting cluster state\", e);\n    }\n\n    // now update the db-s\n    totals.forEach((group, perGroup) -> {\n      perGroup.forEach((reg, perReg) -> {\n        RrdDb db = getOrCreateDb(reg, group);\n        if (db == null) {\n          return;\n        }\n        try {\n          // set the timestamp\n          Sample s = db.createSample(TimeUnit.SECONDS.convert(timeSource.getEpochTimeNs(), TimeUnit.NANOSECONDS));\n          AtomicBoolean dirty = new AtomicBoolean(false);\n          List<Group> groups = new ArrayList<>();\n          groups.add(group);\n          if (group == Group.collection) {\n            groups.add(Group.core);\n          }\n          for (Group g : groups) {\n            counters.get(g.toString()).forEach(c -> {\n              Number val = perReg.get(c);\n              if (val != null) {\n                dirty.set(true);\n                s.setValue(c, val.doubleValue());\n              }\n            });\n            gauges.get(g.toString()).forEach(c -> {\n              Number val = perReg.get(c);\n              if (val != null) {\n                dirty.set(true);\n                s.setValue(c, val.doubleValue());\n              }\n            });\n          }\n          if (dirty.get()) {\n            s.update();\n          }\n        } catch (Exception e) {\n        }\n      });\n    });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c84df91ca6a2e8d6f26f185663112546a27f6b45","date":1536077760,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/admin/MetricsHistoryHandler#collectGlobalMetrics().mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/admin/MetricsHistoryHandler#collectGlobalMetrics().mjava","sourceNew":"  private void collectGlobalMetrics() {\n    if (!amIOverseerLeader()) {\n      return;\n    }\n    Set<String> nodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n    NodeStateProvider nodeStateProvider = cloudManager.getNodeStateProvider();\n    Set<String> collTags = new HashSet<>();\n    collTags.addAll(counters.get(Group.core.toString()));\n    collTags.addAll(gauges.get(Group.core.toString()));\n\n    Set<String> nodeTags = new HashSet<>();\n    String nodePrefix = \"metrics:\" + SolrMetricManager.getRegistryName(Group.node) + \":\";\n    counters.get(Group.node.toString()).forEach(name -> {\n      nodeTags.add(nodePrefix + name);\n    });\n    gauges.get(Group.node.toString()).forEach(name -> {\n      nodeTags.add(nodePrefix + name);\n    });\n    String jvmPrefix = \"metrics:\" + SolrMetricManager.getRegistryName(Group.jvm) + \":\";\n    counters.get(Group.jvm.toString()).forEach(name -> {\n      nodeTags.add(jvmPrefix + name);\n    });\n    gauges.get(Group.jvm.toString()).forEach(name -> {\n      nodeTags.add(jvmPrefix + name);\n    });\n\n    // per-registry totals\n    // XXX at the moment the type of metrics that we collect allows\n    // adding all partial values. At some point it may be necessary to implement\n    // other aggregation functions.\n    // group : registry : name : value\n    Map<Group, Map<String, Map<String, Number>>> totals = new HashMap<>();\n\n    // collect and aggregate per-collection totals\n    for (String node : nodes) {\n      if (cloudManager.isClosed() || Thread.interrupted()) {\n        return;\n      }\n      // add core-level stats\n      Map<String, Map<String, List<ReplicaInfo>>> infos = nodeStateProvider.getReplicaInfo(node, collTags);\n      infos.forEach((coll, shards) -> {\n        shards.forEach((sh, replicas) -> {\n          String registry = SolrMetricManager.getRegistryName(Group.collection, coll);\n          Map<String, Number> perReg = totals\n              .computeIfAbsent(Group.collection, g -> new HashMap<>())\n              .computeIfAbsent(registry, r -> new HashMap<>());\n          replicas.forEach(ri -> {\n            collTags.forEach(tag -> {\n              double value = ((Number)ri.getVariable(tag, 0.0)).doubleValue();\n              DoubleAdder adder = (DoubleAdder)perReg.computeIfAbsent(tag, t -> new DoubleAdder());\n              adder.add(value);\n            });\n          });\n        });\n      });\n      // add node-level stats\n      Map<String, Object> nodeValues = nodeStateProvider.getNodeValues(node, nodeTags);\n      for (Group g : Arrays.asList(Group.node, Group.jvm)) {\n        String registry = SolrMetricManager.getRegistryName(g);\n        Map<String, Number> perReg = totals\n            .computeIfAbsent(g, gr -> new HashMap<>())\n            .computeIfAbsent(registry, r -> new HashMap<>());\n        Set<String> names = new HashSet<>();\n        names.addAll(counters.get(g.toString()));\n        names.addAll(gauges.get(g.toString()));\n        names.forEach(name -> {\n          String tag = \"metrics:\" + registry + \":\" + name;\n          double value = ((Number)nodeValues.getOrDefault(tag, 0.0)).doubleValue();\n          DoubleAdder adder = (DoubleAdder)perReg.computeIfAbsent(name, t -> new DoubleAdder());\n          adder.add(value);\n        });\n      }\n    }\n\n    // add numNodes\n    String nodeReg = SolrMetricManager.getRegistryName(Group.node);\n    Map<String, Number> perNodeReg = totals\n        .computeIfAbsent(Group.node, gr -> new HashMap<>())\n        .computeIfAbsent(nodeReg, r -> new HashMap<>());\n    perNodeReg.put(NUM_NODES_KEY, nodes.size());\n\n    // add some global collection-level stats\n    try {\n      ClusterState state = cloudManager.getClusterStateProvider().getClusterState();\n      state.forEachCollection(coll -> {\n        String registry = SolrMetricManager.getRegistryName(Group.collection, coll.getName());\n        Map<String, Number> perReg = totals\n            .computeIfAbsent(Group.collection, g -> new HashMap<>())\n            .computeIfAbsent(registry, r -> new HashMap<>());\n        Slice[] slices = coll.getActiveSlicesArr();\n        perReg.put(NUM_SHARDS_KEY, slices.length);\n        DoubleAdder numActiveReplicas = new DoubleAdder();\n        for (Slice s : slices) {\n          s.forEach(r -> {\n            if (r.isActive(state.getLiveNodes())) {\n              numActiveReplicas.add(1.0);\n            }\n          });\n        }\n        perReg.put(NUM_REPLICAS_KEY, numActiveReplicas);\n      });\n    } catch (IOException e) {\n      log.warn(\"Exception getting cluster state\", e);\n    }\n\n    // now update the db-s\n    totals.forEach((group, perGroup) -> {\n      perGroup.forEach((reg, perReg) -> {\n        RrdDb db = getOrCreateDb(reg, group);\n        if (db == null) {\n          return;\n        }\n        try {\n          // set the timestamp\n          Sample s = db.createSample(TimeUnit.SECONDS.convert(timeSource.getEpochTimeNs(), TimeUnit.NANOSECONDS));\n          AtomicBoolean dirty = new AtomicBoolean(false);\n          List<Group> groups = new ArrayList<>();\n          groups.add(group);\n          if (group == Group.collection) {\n            groups.add(Group.core);\n          }\n          for (Group g : groups) {\n            counters.get(g.toString()).forEach(c -> {\n              Number val = perReg.get(c);\n              if (val != null) {\n                dirty.set(true);\n                s.setValue(c, val.doubleValue());\n              }\n            });\n            gauges.get(g.toString()).forEach(c -> {\n              Number val = perReg.get(c);\n              if (val != null) {\n                dirty.set(true);\n                s.setValue(c, val.doubleValue());\n              }\n            });\n          }\n          if (dirty.get()) {\n            s.update();\n          }\n        } catch (Exception e) {\n        }\n      });\n    });\n  }\n\n","sourceOld":"  private void collectGlobalMetrics() {\n    if (!amIOverseerLeader()) {\n      return;\n    }\n    Set<String> nodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n    NodeStateProvider nodeStateProvider = cloudManager.getNodeStateProvider();\n    Set<String> collTags = new HashSet<>();\n    collTags.addAll(counters.get(Group.core.toString()));\n    collTags.addAll(gauges.get(Group.core.toString()));\n\n    Set<String> nodeTags = new HashSet<>();\n    String nodePrefix = \"metrics:\" + SolrMetricManager.getRegistryName(Group.node) + \":\";\n    counters.get(Group.node.toString()).forEach(name -> {\n      nodeTags.add(nodePrefix + name);\n    });\n    gauges.get(Group.node.toString()).forEach(name -> {\n      nodeTags.add(nodePrefix + name);\n    });\n    String jvmPrefix = \"metrics:\" + SolrMetricManager.getRegistryName(Group.jvm) + \":\";\n    counters.get(Group.jvm.toString()).forEach(name -> {\n      nodeTags.add(jvmPrefix + name);\n    });\n    gauges.get(Group.jvm.toString()).forEach(name -> {\n      nodeTags.add(jvmPrefix + name);\n    });\n\n    // per-registry totals\n    // XXX at the moment the type of metrics that we collect allows\n    // adding all partial values. At some point it may be necessary to implement\n    // other aggregation functions.\n    // group : registry : name : value\n    Map<Group, Map<String, Map<String, Number>>> totals = new HashMap<>();\n\n    // collect and aggregate per-collection totals\n    for (String node : nodes) {\n      if (cloudManager.isClosed() || Thread.interrupted()) {\n        return;\n      }\n      // add core-level stats\n      Map<String, Map<String, List<ReplicaInfo>>> infos = nodeStateProvider.getReplicaInfo(node, collTags);\n      infos.forEach((coll, shards) -> {\n        shards.forEach((sh, replicas) -> {\n          String registry = SolrMetricManager.getRegistryName(Group.collection, coll);\n          Map<String, Number> perReg = totals\n              .computeIfAbsent(Group.collection, g -> new HashMap<>())\n              .computeIfAbsent(registry, r -> new HashMap<>());\n          replicas.forEach(ri -> {\n            collTags.forEach(tag -> {\n              double value = ((Number)ri.getVariable(tag, 0.0)).doubleValue();\n              DoubleAdder adder = (DoubleAdder)perReg.computeIfAbsent(tag, t -> new DoubleAdder());\n              adder.add(value);\n            });\n          });\n        });\n      });\n      // add node-level stats\n      Map<String, Object> nodeValues = nodeStateProvider.getNodeValues(node, nodeTags);\n      for (Group g : Arrays.asList(Group.node, Group.jvm)) {\n        String registry = SolrMetricManager.getRegistryName(g);\n        Map<String, Number> perReg = totals\n            .computeIfAbsent(g, gr -> new HashMap<>())\n            .computeIfAbsent(registry, r -> new HashMap<>());\n        Set<String> names = new HashSet<>();\n        names.addAll(counters.get(g.toString()));\n        names.addAll(gauges.get(g.toString()));\n        names.forEach(name -> {\n          String tag = \"metrics:\" + registry + \":\" + name;\n          double value = ((Number)nodeValues.getOrDefault(tag, 0.0)).doubleValue();\n          DoubleAdder adder = (DoubleAdder)perReg.computeIfAbsent(name, t -> new DoubleAdder());\n          adder.add(value);\n        });\n      }\n    }\n\n    // add numNodes\n    String nodeReg = SolrMetricManager.getRegistryName(Group.node);\n    Map<String, Number> perNodeReg = totals\n        .computeIfAbsent(Group.node, gr -> new HashMap<>())\n        .computeIfAbsent(nodeReg, r -> new HashMap<>());\n    perNodeReg.put(NUM_NODES_KEY, nodes.size());\n\n    // add some global collection-level stats\n    try {\n      ClusterState state = cloudManager.getClusterStateProvider().getClusterState();\n      state.forEachCollection(coll -> {\n        String registry = SolrMetricManager.getRegistryName(Group.collection, coll.getName());\n        Map<String, Number> perReg = totals\n            .computeIfAbsent(Group.collection, g -> new HashMap<>())\n            .computeIfAbsent(registry, r -> new HashMap<>());\n        Collection<Slice> slices = coll.getActiveSlices();\n        perReg.put(NUM_SHARDS_KEY, slices.size());\n        DoubleAdder numActiveReplicas = new DoubleAdder();\n        slices.forEach(s -> {\n          s.forEach(r -> {\n            if (r.isActive(state.getLiveNodes())) {\n              numActiveReplicas.add(1.0);\n            }\n          });\n        });\n        perReg.put(NUM_REPLICAS_KEY, numActiveReplicas);\n      });\n    } catch (IOException e) {\n      log.warn(\"Exception getting cluster state\", e);\n    }\n\n    // now update the db-s\n    totals.forEach((group, perGroup) -> {\n      perGroup.forEach((reg, perReg) -> {\n        RrdDb db = getOrCreateDb(reg, group);\n        if (db == null) {\n          return;\n        }\n        try {\n          // set the timestamp\n          Sample s = db.createSample(TimeUnit.SECONDS.convert(timeSource.getEpochTimeNs(), TimeUnit.NANOSECONDS));\n          AtomicBoolean dirty = new AtomicBoolean(false);\n          List<Group> groups = new ArrayList<>();\n          groups.add(group);\n          if (group == Group.collection) {\n            groups.add(Group.core);\n          }\n          for (Group g : groups) {\n            counters.get(g.toString()).forEach(c -> {\n              Number val = perReg.get(c);\n              if (val != null) {\n                dirty.set(true);\n                s.setValue(c, val.doubleValue());\n              }\n            });\n            gauges.get(g.toString()).forEach(c -> {\n              Number val = perReg.get(c);\n              if (val != null) {\n                dirty.set(true);\n                s.setValue(c, val.doubleValue());\n              }\n            });\n          }\n          if (dirty.get()) {\n            s.update();\n          }\n        } catch (Exception e) {\n        }\n      });\n    });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"257a6da104932110fa3a53e12d46e146db5d8eb6","date":1553203323,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/admin/MetricsHistoryHandler#collectGlobalMetrics().mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/admin/MetricsHistoryHandler#collectGlobalMetrics().mjava","sourceNew":"  private void collectGlobalMetrics() {\n    if (!amIOverseerLeader()) {\n      return;\n    }\n    Set<String> nodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n    NodeStateProvider nodeStateProvider = cloudManager.getNodeStateProvider();\n    Set<String> collTags = new HashSet<>();\n    collTags.addAll(counters.get(Group.core.toString()));\n    collTags.addAll(gauges.get(Group.core.toString()));\n\n    Set<String> nodeTags = new HashSet<>();\n    String nodePrefix = \"metrics:\" + SolrMetricManager.getRegistryName(Group.node) + \":\";\n    counters.get(Group.node.toString()).forEach(name -> {\n      nodeTags.add(nodePrefix + name);\n    });\n    gauges.get(Group.node.toString()).forEach(name -> {\n      nodeTags.add(nodePrefix + name);\n    });\n    String jvmPrefix = \"metrics:\" + SolrMetricManager.getRegistryName(Group.jvm) + \":\";\n    counters.get(Group.jvm.toString()).forEach(name -> {\n      nodeTags.add(jvmPrefix + name);\n    });\n    gauges.get(Group.jvm.toString()).forEach(name -> {\n      nodeTags.add(jvmPrefix + name);\n    });\n\n    // per-registry totals\n    // XXX at the moment the type of metrics that we collect allows\n    // adding all partial values. At some point it may be necessary to implement\n    // other aggregation functions.\n    // group : registry : name : value\n    Map<Group, Map<String, Map<String, Number>>> totals = new HashMap<>();\n\n    // collect and aggregate per-collection totals\n    for (String node : nodes) {\n      if (cloudManager.isClosed() || Thread.interrupted()) {\n        return;\n      }\n      // add core-level stats\n      Map<String, Map<String, List<ReplicaInfo>>> infos = nodeStateProvider.getReplicaInfo(node, collTags);\n      infos.forEach((coll, shards) -> {\n        shards.forEach((sh, replicas) -> {\n          String registry = SolrMetricManager.getRegistryName(Group.collection, coll);\n          Map<String, Number> perReg = totals\n              .computeIfAbsent(Group.collection, g -> new HashMap<>())\n              .computeIfAbsent(registry, r -> new HashMap<>());\n          replicas.forEach(ri -> {\n            collTags.forEach(tag -> {\n              double value = ((Number)ri.getVariable(tag, 0.0)).doubleValue();\n              DoubleAdder adder = (DoubleAdder)perReg.computeIfAbsent(tag, t -> new DoubleAdder());\n              adder.add(value);\n            });\n          });\n        });\n      });\n      // add node-level stats\n      Map<String, Object> nodeValues = nodeStateProvider.getNodeValues(node, nodeTags);\n      for (Group g : Arrays.asList(Group.node, Group.jvm)) {\n        String registry = SolrMetricManager.getRegistryName(g);\n        Map<String, Number> perReg = totals\n            .computeIfAbsent(g, gr -> new HashMap<>())\n            .computeIfAbsent(registry, r -> new HashMap<>());\n        Set<String> names = new HashSet<>();\n        names.addAll(counters.get(g.toString()));\n        names.addAll(gauges.get(g.toString()));\n        names.forEach(name -> {\n          String tag = \"metrics:\" + registry + \":\" + name;\n          double value = ((Number)nodeValues.getOrDefault(tag, 0.0)).doubleValue();\n          DoubleAdder adder = (DoubleAdder)perReg.computeIfAbsent(name, t -> new DoubleAdder());\n          adder.add(value);\n        });\n      }\n    }\n\n    // add numNodes\n    String nodeReg = SolrMetricManager.getRegistryName(Group.node);\n    Map<String, Number> perNodeReg = totals\n        .computeIfAbsent(Group.node, gr -> new HashMap<>())\n        .computeIfAbsent(nodeReg, r -> new HashMap<>());\n    perNodeReg.put(NUM_NODES_KEY, nodes.size());\n\n    // add some global collection-level stats\n    try {\n      ClusterState state = cloudManager.getClusterStateProvider().getClusterState();\n      state.forEachCollection(coll -> {\n        String registry = SolrMetricManager.getRegistryName(Group.collection, coll.getName());\n        Map<String, Number> perReg = totals\n            .computeIfAbsent(Group.collection, g -> new HashMap<>())\n            .computeIfAbsent(registry, r -> new HashMap<>());\n        Slice[] slices = coll.getActiveSlicesArr();\n        perReg.put(NUM_SHARDS_KEY, slices.length);\n        DoubleAdder numActiveReplicas = new DoubleAdder();\n        for (Slice s : slices) {\n          s.forEach(r -> {\n            if (r.isActive(state.getLiveNodes())) {\n              numActiveReplicas.add(1.0);\n            }\n          });\n        }\n        perReg.put(NUM_REPLICAS_KEY, numActiveReplicas);\n      });\n    } catch (IOException e) {\n      log.warn(\"Exception getting cluster state\", e);\n    }\n\n    // now update the db-s\n    totals.forEach((group, perGroup) -> {\n      perGroup.forEach((reg, perReg) -> {\n        RrdDb db = getOrCreateDb(reg, group);\n        if (db == null) {\n          return;\n        }\n        try {\n          // set the timestamp\n          Sample s = db.createSample(TimeUnit.SECONDS.convert(timeSource.getEpochTimeNs(), TimeUnit.NANOSECONDS));\n          AtomicBoolean dirty = new AtomicBoolean(false);\n          List<Group> groups = new ArrayList<>();\n          groups.add(group);\n          if (group == Group.collection) {\n            groups.add(Group.core);\n          }\n          for (Group g : groups) {\n            counters.get(g.toString()).forEach(c -> {\n              Number val = perReg.get(c);\n              if (val != null) {\n                dirty.set(true);\n                s.setValue(c, val.doubleValue());\n              }\n            });\n            gauges.get(g.toString()).forEach(c -> {\n              Number val = perReg.get(c);\n              if (val != null) {\n                dirty.set(true);\n                s.setValue(c, val.doubleValue());\n              }\n            });\n          }\n          if (dirty.get()) {\n            s.update();\n          }\n        } catch (Exception e) {\n          log.warn(\"Exception storing sample in RrdDb for group {}: {}\", group, e);\n        }\n      });\n    });\n  }\n\n","sourceOld":"  private void collectGlobalMetrics() {\n    if (!amIOverseerLeader()) {\n      return;\n    }\n    Set<String> nodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n    NodeStateProvider nodeStateProvider = cloudManager.getNodeStateProvider();\n    Set<String> collTags = new HashSet<>();\n    collTags.addAll(counters.get(Group.core.toString()));\n    collTags.addAll(gauges.get(Group.core.toString()));\n\n    Set<String> nodeTags = new HashSet<>();\n    String nodePrefix = \"metrics:\" + SolrMetricManager.getRegistryName(Group.node) + \":\";\n    counters.get(Group.node.toString()).forEach(name -> {\n      nodeTags.add(nodePrefix + name);\n    });\n    gauges.get(Group.node.toString()).forEach(name -> {\n      nodeTags.add(nodePrefix + name);\n    });\n    String jvmPrefix = \"metrics:\" + SolrMetricManager.getRegistryName(Group.jvm) + \":\";\n    counters.get(Group.jvm.toString()).forEach(name -> {\n      nodeTags.add(jvmPrefix + name);\n    });\n    gauges.get(Group.jvm.toString()).forEach(name -> {\n      nodeTags.add(jvmPrefix + name);\n    });\n\n    // per-registry totals\n    // XXX at the moment the type of metrics that we collect allows\n    // adding all partial values. At some point it may be necessary to implement\n    // other aggregation functions.\n    // group : registry : name : value\n    Map<Group, Map<String, Map<String, Number>>> totals = new HashMap<>();\n\n    // collect and aggregate per-collection totals\n    for (String node : nodes) {\n      if (cloudManager.isClosed() || Thread.interrupted()) {\n        return;\n      }\n      // add core-level stats\n      Map<String, Map<String, List<ReplicaInfo>>> infos = nodeStateProvider.getReplicaInfo(node, collTags);\n      infos.forEach((coll, shards) -> {\n        shards.forEach((sh, replicas) -> {\n          String registry = SolrMetricManager.getRegistryName(Group.collection, coll);\n          Map<String, Number> perReg = totals\n              .computeIfAbsent(Group.collection, g -> new HashMap<>())\n              .computeIfAbsent(registry, r -> new HashMap<>());\n          replicas.forEach(ri -> {\n            collTags.forEach(tag -> {\n              double value = ((Number)ri.getVariable(tag, 0.0)).doubleValue();\n              DoubleAdder adder = (DoubleAdder)perReg.computeIfAbsent(tag, t -> new DoubleAdder());\n              adder.add(value);\n            });\n          });\n        });\n      });\n      // add node-level stats\n      Map<String, Object> nodeValues = nodeStateProvider.getNodeValues(node, nodeTags);\n      for (Group g : Arrays.asList(Group.node, Group.jvm)) {\n        String registry = SolrMetricManager.getRegistryName(g);\n        Map<String, Number> perReg = totals\n            .computeIfAbsent(g, gr -> new HashMap<>())\n            .computeIfAbsent(registry, r -> new HashMap<>());\n        Set<String> names = new HashSet<>();\n        names.addAll(counters.get(g.toString()));\n        names.addAll(gauges.get(g.toString()));\n        names.forEach(name -> {\n          String tag = \"metrics:\" + registry + \":\" + name;\n          double value = ((Number)nodeValues.getOrDefault(tag, 0.0)).doubleValue();\n          DoubleAdder adder = (DoubleAdder)perReg.computeIfAbsent(name, t -> new DoubleAdder());\n          adder.add(value);\n        });\n      }\n    }\n\n    // add numNodes\n    String nodeReg = SolrMetricManager.getRegistryName(Group.node);\n    Map<String, Number> perNodeReg = totals\n        .computeIfAbsent(Group.node, gr -> new HashMap<>())\n        .computeIfAbsent(nodeReg, r -> new HashMap<>());\n    perNodeReg.put(NUM_NODES_KEY, nodes.size());\n\n    // add some global collection-level stats\n    try {\n      ClusterState state = cloudManager.getClusterStateProvider().getClusterState();\n      state.forEachCollection(coll -> {\n        String registry = SolrMetricManager.getRegistryName(Group.collection, coll.getName());\n        Map<String, Number> perReg = totals\n            .computeIfAbsent(Group.collection, g -> new HashMap<>())\n            .computeIfAbsent(registry, r -> new HashMap<>());\n        Slice[] slices = coll.getActiveSlicesArr();\n        perReg.put(NUM_SHARDS_KEY, slices.length);\n        DoubleAdder numActiveReplicas = new DoubleAdder();\n        for (Slice s : slices) {\n          s.forEach(r -> {\n            if (r.isActive(state.getLiveNodes())) {\n              numActiveReplicas.add(1.0);\n            }\n          });\n        }\n        perReg.put(NUM_REPLICAS_KEY, numActiveReplicas);\n      });\n    } catch (IOException e) {\n      log.warn(\"Exception getting cluster state\", e);\n    }\n\n    // now update the db-s\n    totals.forEach((group, perGroup) -> {\n      perGroup.forEach((reg, perReg) -> {\n        RrdDb db = getOrCreateDb(reg, group);\n        if (db == null) {\n          return;\n        }\n        try {\n          // set the timestamp\n          Sample s = db.createSample(TimeUnit.SECONDS.convert(timeSource.getEpochTimeNs(), TimeUnit.NANOSECONDS));\n          AtomicBoolean dirty = new AtomicBoolean(false);\n          List<Group> groups = new ArrayList<>();\n          groups.add(group);\n          if (group == Group.collection) {\n            groups.add(Group.core);\n          }\n          for (Group g : groups) {\n            counters.get(g.toString()).forEach(c -> {\n              Number val = perReg.get(c);\n              if (val != null) {\n                dirty.set(true);\n                s.setValue(c, val.doubleValue());\n              }\n            });\n            gauges.get(g.toString()).forEach(c -> {\n              Number val = perReg.get(c);\n              if (val != null) {\n                dirty.set(true);\n                s.setValue(c, val.doubleValue());\n              }\n            });\n          }\n          if (dirty.get()) {\n            s.update();\n          }\n        } catch (Exception e) {\n        }\n      });\n    });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7e8ce2f9d2ddfcf5cfa7e73b8b2af287a2a276fd","date":1594731683,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/admin/MetricsHistoryHandler#collectGlobalMetrics().mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/admin/MetricsHistoryHandler#collectGlobalMetrics().mjava","sourceNew":"  private void collectGlobalMetrics() {\n    if (!amIOverseerLeader()) {\n      return;\n    }\n    Set<String> nodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n    NodeStateProvider nodeStateProvider = cloudManager.getNodeStateProvider();\n    Set<String> collTags = new HashSet<>();\n    collTags.addAll(counters.get(Group.core.toString()));\n    collTags.addAll(gauges.get(Group.core.toString()));\n\n    Set<String> nodeTags = new HashSet<>();\n    String nodePrefix = \"metrics:\" + SolrMetricManager.getRegistryName(Group.node) + \":\";\n    counters.get(Group.node.toString()).forEach(name -> {\n      nodeTags.add(nodePrefix + name);\n    });\n    gauges.get(Group.node.toString()).forEach(name -> {\n      nodeTags.add(nodePrefix + name);\n    });\n    String jvmPrefix = \"metrics:\" + SolrMetricManager.getRegistryName(Group.jvm) + \":\";\n    counters.get(Group.jvm.toString()).forEach(name -> {\n      nodeTags.add(jvmPrefix + name);\n    });\n    gauges.get(Group.jvm.toString()).forEach(name -> {\n      nodeTags.add(jvmPrefix + name);\n    });\n\n    // per-registry totals\n    // XXX at the moment the type of metrics that we collect allows\n    // adding all partial values. At some point it may be necessary to implement\n    // other aggregation functions.\n    // group : registry : name : value\n    Map<Group, Map<String, Map<String, Number>>> totals = new HashMap<>();\n\n    // collect and aggregate per-collection totals\n    for (String node : nodes) {\n      if (cloudManager.isClosed() || Thread.interrupted()) {\n        return;\n      }\n      // add core-level stats\n      Map<String, Map<String, List<Replica>>> infos = nodeStateProvider.getReplicaInfo(node, collTags);\n      infos.forEach((coll, shards) -> {\n        shards.forEach((sh, replicas) -> {\n          String registry = SolrMetricManager.getRegistryName(Group.collection, coll);\n          Map<String, Number> perReg = totals\n              .computeIfAbsent(Group.collection, g -> new HashMap<>())\n              .computeIfAbsent(registry, r -> new HashMap<>());\n          replicas.forEach(ri -> {\n            collTags.forEach(tag -> {\n              double value = ((Number)ri.get(tag, 0.0)).doubleValue();\n              DoubleAdder adder = (DoubleAdder)perReg.computeIfAbsent(tag, t -> new DoubleAdder());\n              adder.add(value);\n            });\n          });\n        });\n      });\n      // add node-level stats\n      Map<String, Object> nodeValues = nodeStateProvider.getNodeValues(node, nodeTags);\n      for (Group g : Arrays.asList(Group.node, Group.jvm)) {\n        String registry = SolrMetricManager.getRegistryName(g);\n        Map<String, Number> perReg = totals\n            .computeIfAbsent(g, gr -> new HashMap<>())\n            .computeIfAbsent(registry, r -> new HashMap<>());\n        Set<String> names = new HashSet<>();\n        names.addAll(counters.get(g.toString()));\n        names.addAll(gauges.get(g.toString()));\n        names.forEach(name -> {\n          String tag = \"metrics:\" + registry + \":\" + name;\n          double value = ((Number)nodeValues.getOrDefault(tag, 0.0)).doubleValue();\n          DoubleAdder adder = (DoubleAdder)perReg.computeIfAbsent(name, t -> new DoubleAdder());\n          adder.add(value);\n        });\n      }\n    }\n\n    // add numNodes\n    String nodeReg = SolrMetricManager.getRegistryName(Group.node);\n    Map<String, Number> perNodeReg = totals\n        .computeIfAbsent(Group.node, gr -> new HashMap<>())\n        .computeIfAbsent(nodeReg, r -> new HashMap<>());\n    perNodeReg.put(NUM_NODES_KEY, nodes.size());\n\n    // add some global collection-level stats\n    try {\n      ClusterState state = cloudManager.getClusterStateProvider().getClusterState();\n      state.forEachCollection(coll -> {\n        String registry = SolrMetricManager.getRegistryName(Group.collection, coll.getName());\n        Map<String, Number> perReg = totals\n            .computeIfAbsent(Group.collection, g -> new HashMap<>())\n            .computeIfAbsent(registry, r -> new HashMap<>());\n        Slice[] slices = coll.getActiveSlicesArr();\n        perReg.put(NUM_SHARDS_KEY, slices.length);\n        DoubleAdder numActiveReplicas = new DoubleAdder();\n        for (Slice s : slices) {\n          s.forEach(r -> {\n            if (r.isActive(state.getLiveNodes())) {\n              numActiveReplicas.add(1.0);\n            }\n          });\n        }\n        perReg.put(NUM_REPLICAS_KEY, numActiveReplicas);\n      });\n    } catch (IOException e) {\n      log.warn(\"Exception getting cluster state\", e);\n    }\n\n    // now update the db-s\n    totals.forEach((group, perGroup) -> {\n      perGroup.forEach((reg, perReg) -> {\n        RrdDb db = getOrCreateDb(reg, group);\n        if (db == null) {\n          return;\n        }\n        try {\n          // set the timestamp\n          Sample s = db.createSample(TimeUnit.SECONDS.convert(timeSource.getEpochTimeNs(), TimeUnit.NANOSECONDS));\n          AtomicBoolean dirty = new AtomicBoolean(false);\n          List<Group> groups = new ArrayList<>();\n          groups.add(group);\n          if (group == Group.collection) {\n            groups.add(Group.core);\n          }\n          for (Group g : groups) {\n            counters.get(g.toString()).forEach(c -> {\n              Number val = perReg.get(c);\n              if (val != null) {\n                dirty.set(true);\n                s.setValue(c, val.doubleValue());\n              }\n            });\n            gauges.get(g.toString()).forEach(c -> {\n              Number val = perReg.get(c);\n              if (val != null) {\n                dirty.set(true);\n                s.setValue(c, val.doubleValue());\n              }\n            });\n          }\n          if (dirty.get()) {\n            s.update();\n          }\n        } catch (Exception e) {\n          log.warn(\"Exception storing sample in RrdDb for group {}: {}\", group, e);\n        }\n      });\n    });\n  }\n\n","sourceOld":"  private void collectGlobalMetrics() {\n    if (!amIOverseerLeader()) {\n      return;\n    }\n    Set<String> nodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n    NodeStateProvider nodeStateProvider = cloudManager.getNodeStateProvider();\n    Set<String> collTags = new HashSet<>();\n    collTags.addAll(counters.get(Group.core.toString()));\n    collTags.addAll(gauges.get(Group.core.toString()));\n\n    Set<String> nodeTags = new HashSet<>();\n    String nodePrefix = \"metrics:\" + SolrMetricManager.getRegistryName(Group.node) + \":\";\n    counters.get(Group.node.toString()).forEach(name -> {\n      nodeTags.add(nodePrefix + name);\n    });\n    gauges.get(Group.node.toString()).forEach(name -> {\n      nodeTags.add(nodePrefix + name);\n    });\n    String jvmPrefix = \"metrics:\" + SolrMetricManager.getRegistryName(Group.jvm) + \":\";\n    counters.get(Group.jvm.toString()).forEach(name -> {\n      nodeTags.add(jvmPrefix + name);\n    });\n    gauges.get(Group.jvm.toString()).forEach(name -> {\n      nodeTags.add(jvmPrefix + name);\n    });\n\n    // per-registry totals\n    // XXX at the moment the type of metrics that we collect allows\n    // adding all partial values. At some point it may be necessary to implement\n    // other aggregation functions.\n    // group : registry : name : value\n    Map<Group, Map<String, Map<String, Number>>> totals = new HashMap<>();\n\n    // collect and aggregate per-collection totals\n    for (String node : nodes) {\n      if (cloudManager.isClosed() || Thread.interrupted()) {\n        return;\n      }\n      // add core-level stats\n      Map<String, Map<String, List<ReplicaInfo>>> infos = nodeStateProvider.getReplicaInfo(node, collTags);\n      infos.forEach((coll, shards) -> {\n        shards.forEach((sh, replicas) -> {\n          String registry = SolrMetricManager.getRegistryName(Group.collection, coll);\n          Map<String, Number> perReg = totals\n              .computeIfAbsent(Group.collection, g -> new HashMap<>())\n              .computeIfAbsent(registry, r -> new HashMap<>());\n          replicas.forEach(ri -> {\n            collTags.forEach(tag -> {\n              double value = ((Number)ri.getVariable(tag, 0.0)).doubleValue();\n              DoubleAdder adder = (DoubleAdder)perReg.computeIfAbsent(tag, t -> new DoubleAdder());\n              adder.add(value);\n            });\n          });\n        });\n      });\n      // add node-level stats\n      Map<String, Object> nodeValues = nodeStateProvider.getNodeValues(node, nodeTags);\n      for (Group g : Arrays.asList(Group.node, Group.jvm)) {\n        String registry = SolrMetricManager.getRegistryName(g);\n        Map<String, Number> perReg = totals\n            .computeIfAbsent(g, gr -> new HashMap<>())\n            .computeIfAbsent(registry, r -> new HashMap<>());\n        Set<String> names = new HashSet<>();\n        names.addAll(counters.get(g.toString()));\n        names.addAll(gauges.get(g.toString()));\n        names.forEach(name -> {\n          String tag = \"metrics:\" + registry + \":\" + name;\n          double value = ((Number)nodeValues.getOrDefault(tag, 0.0)).doubleValue();\n          DoubleAdder adder = (DoubleAdder)perReg.computeIfAbsent(name, t -> new DoubleAdder());\n          adder.add(value);\n        });\n      }\n    }\n\n    // add numNodes\n    String nodeReg = SolrMetricManager.getRegistryName(Group.node);\n    Map<String, Number> perNodeReg = totals\n        .computeIfAbsent(Group.node, gr -> new HashMap<>())\n        .computeIfAbsent(nodeReg, r -> new HashMap<>());\n    perNodeReg.put(NUM_NODES_KEY, nodes.size());\n\n    // add some global collection-level stats\n    try {\n      ClusterState state = cloudManager.getClusterStateProvider().getClusterState();\n      state.forEachCollection(coll -> {\n        String registry = SolrMetricManager.getRegistryName(Group.collection, coll.getName());\n        Map<String, Number> perReg = totals\n            .computeIfAbsent(Group.collection, g -> new HashMap<>())\n            .computeIfAbsent(registry, r -> new HashMap<>());\n        Slice[] slices = coll.getActiveSlicesArr();\n        perReg.put(NUM_SHARDS_KEY, slices.length);\n        DoubleAdder numActiveReplicas = new DoubleAdder();\n        for (Slice s : slices) {\n          s.forEach(r -> {\n            if (r.isActive(state.getLiveNodes())) {\n              numActiveReplicas.add(1.0);\n            }\n          });\n        }\n        perReg.put(NUM_REPLICAS_KEY, numActiveReplicas);\n      });\n    } catch (IOException e) {\n      log.warn(\"Exception getting cluster state\", e);\n    }\n\n    // now update the db-s\n    totals.forEach((group, perGroup) -> {\n      perGroup.forEach((reg, perReg) -> {\n        RrdDb db = getOrCreateDb(reg, group);\n        if (db == null) {\n          return;\n        }\n        try {\n          // set the timestamp\n          Sample s = db.createSample(TimeUnit.SECONDS.convert(timeSource.getEpochTimeNs(), TimeUnit.NANOSECONDS));\n          AtomicBoolean dirty = new AtomicBoolean(false);\n          List<Group> groups = new ArrayList<>();\n          groups.add(group);\n          if (group == Group.collection) {\n            groups.add(Group.core);\n          }\n          for (Group g : groups) {\n            counters.get(g.toString()).forEach(c -> {\n              Number val = perReg.get(c);\n              if (val != null) {\n                dirty.set(true);\n                s.setValue(c, val.doubleValue());\n              }\n            });\n            gauges.get(g.toString()).forEach(c -> {\n              Number val = perReg.get(c);\n              if (val != null) {\n                dirty.set(true);\n                s.setValue(c, val.doubleValue());\n              }\n            });\n          }\n          if (dirty.get()) {\n            s.update();\n          }\n        } catch (Exception e) {\n          log.warn(\"Exception storing sample in RrdDb for group {}: {}\", group, e);\n        }\n      });\n    });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"dcfa8a1a5da4cfdac38e256c38e4b631637aa157":["f8f0f2472d437d44ec2144932e1d13fb494e82a3"],"c84df91ca6a2e8d6f26f185663112546a27f6b45":["dcfa8a1a5da4cfdac38e256c38e4b631637aa157"],"f8f0f2472d437d44ec2144932e1d13fb494e82a3":["4181b4cf0450ea3c6d1aff8dc3ad4ed9cd3eeb6a"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":["4181b4cf0450ea3c6d1aff8dc3ad4ed9cd3eeb6a","dcfa8a1a5da4cfdac38e256c38e4b631637aa157"],"7e8ce2f9d2ddfcf5cfa7e73b8b2af287a2a276fd":["257a6da104932110fa3a53e12d46e146db5d8eb6"],"4181b4cf0450ea3c6d1aff8dc3ad4ed9cd3eeb6a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"257a6da104932110fa3a53e12d46e146db5d8eb6":["c84df91ca6a2e8d6f26f185663112546a27f6b45"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["7e8ce2f9d2ddfcf5cfa7e73b8b2af287a2a276fd"],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":["4181b4cf0450ea3c6d1aff8dc3ad4ed9cd3eeb6a","dcfa8a1a5da4cfdac38e256c38e4b631637aa157"]},"commit2Childs":{"dcfa8a1a5da4cfdac38e256c38e4b631637aa157":["c84df91ca6a2e8d6f26f185663112546a27f6b45","0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"f8f0f2472d437d44ec2144932e1d13fb494e82a3":["dcfa8a1a5da4cfdac38e256c38e4b631637aa157"],"c84df91ca6a2e8d6f26f185663112546a27f6b45":["257a6da104932110fa3a53e12d46e146db5d8eb6"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":[],"4181b4cf0450ea3c6d1aff8dc3ad4ed9cd3eeb6a":["f8f0f2472d437d44ec2144932e1d13fb494e82a3","0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"7e8ce2f9d2ddfcf5cfa7e73b8b2af287a2a276fd":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"257a6da104932110fa3a53e12d46e146db5d8eb6":["7e8ce2f9d2ddfcf5cfa7e73b8b2af287a2a276fd"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["4181b4cf0450ea3c6d1aff8dc3ad4ed9cd3eeb6a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":[]},"heads":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","cd5edd1f2b162a5cfa08efd17851a07373a96817","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}