{"path":"lucene/src/test/org/apache/lucene/index/TestMaxTermFrequency#addValue().mjava","commits":[{"id":"5e9ee82a511a2ff4aad3e0bd7a3ab820c03ce6fc","date":1295002842,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestMaxTermFrequency#addValue().mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Makes a bunch of single-char tokens (the max freq will at most be 255).\n   * shuffles them around, and returns the whole list with Arrays.toString().\n   * This works fine because we use lettertokenizer.\n   * puts the max-frequency term into expected, to be checked against the norm.\n   */\n  private String addValue() {\n    List<String> terms = new ArrayList<String>();\n    int maxCeiling = _TestUtil.nextInt(random, 0, 255);\n    int max = 0;\n    for (char ch = 'a'; ch <= 'z'; ch++) {\n      int num = _TestUtil.nextInt(random, 0, maxCeiling);\n      for (int i = 0; i < num; i++)\n        terms.add(Character.toString(ch));\n      max = Math.max(max, num);\n    }\n    expected.add(max);\n    Collections.shuffle(terms, random);\n    return Arrays.toString(terms.toArray(new String[terms.size()]));\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"16843358872ed92ba92888ab99df297550b9a36a","date":1295144724,"type":0,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestMaxTermFrequency#addValue().mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Makes a bunch of single-char tokens (the max freq will at most be 255).\n   * shuffles them around, and returns the whole list with Arrays.toString().\n   * This works fine because we use lettertokenizer.\n   * puts the max-frequency term into expected, to be checked against the norm.\n   */\n  private String addValue() {\n    List<String> terms = new ArrayList<String>();\n    int maxCeiling = _TestUtil.nextInt(random, 0, 255);\n    int max = 0;\n    for (char ch = 'a'; ch <= 'z'; ch++) {\n      int num = _TestUtil.nextInt(random, 0, maxCeiling);\n      for (int i = 0; i < num; i++)\n        terms.add(Character.toString(ch));\n      max = Math.max(max, num);\n    }\n    expected.add(max);\n    Collections.shuffle(terms, random);\n    return Arrays.toString(terms.toArray(new String[terms.size()]));\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestMaxTermFrequency#addValue().mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Makes a bunch of single-char tokens (the max freq will at most be 255).\n   * shuffles them around, and returns the whole list with Arrays.toString().\n   * This works fine because we use lettertokenizer.\n   * puts the max-frequency term into expected, to be checked against the norm.\n   */\n  private String addValue() {\n    List<String> terms = new ArrayList<String>();\n    int maxCeiling = _TestUtil.nextInt(random, 0, 255);\n    int max = 0;\n    for (char ch = 'a'; ch <= 'z'; ch++) {\n      int num = _TestUtil.nextInt(random, 0, maxCeiling);\n      for (int i = 0; i < num; i++)\n        terms.add(Character.toString(ch));\n      max = Math.max(max, num);\n    }\n    expected.add(max);\n    Collections.shuffle(terms, random);\n    return Arrays.toString(terms.toArray(new String[terms.size()]));\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestMaxTermFrequency#addValue().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestMaxTermFrequency#addValue().mjava","sourceNew":"  /**\n   * Makes a bunch of single-char tokens (the max freq will at most be 255).\n   * shuffles them around, and returns the whole list with Arrays.toString().\n   * This works fine because we use lettertokenizer.\n   * puts the max-frequency term into expected, to be checked against the norm.\n   */\n  private String addValue() {\n    List<String> terms = new ArrayList<String>();\n    int maxCeiling = _TestUtil.nextInt(random, 0, 255);\n    int max = 0;\n    for (char ch = 'a'; ch <= 'z'; ch++) {\n      int num = _TestUtil.nextInt(random, 0, maxCeiling);\n      for (int i = 0; i < num; i++)\n        terms.add(Character.toString(ch));\n      max = Math.max(max, num);\n    }\n    expected.add(max);\n    Collections.shuffle(terms, random);\n    return Arrays.toString(terms.toArray(new String[terms.size()]));\n  }\n\n","sourceOld":"  /**\n   * Makes a bunch of single-char tokens (the max freq will at most be 255).\n   * shuffles them around, and returns the whole list with Arrays.toString().\n   * This works fine because we use lettertokenizer.\n   * puts the max-frequency term into expected, to be checked against the norm.\n   */\n  private String addValue() {\n    List<String> terms = new ArrayList<String>();\n    int maxCeiling = _TestUtil.nextInt(random, 0, 255);\n    int max = 0;\n    for (char ch = 'a'; ch <= 'z'; ch++) {\n      int num = _TestUtil.nextInt(random, 0, maxCeiling);\n      for (int i = 0; i < num; i++)\n        terms.add(Character.toString(ch));\n      max = Math.max(max, num);\n    }\n    expected.add(max);\n    Collections.shuffle(terms, random);\n    return Arrays.toString(terms.toArray(new String[terms.size()]));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["5e9ee82a511a2ff4aad3e0bd7a3ab820c03ce6fc"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","5e9ee82a511a2ff4aad3e0bd7a3ab820c03ce6fc"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"16843358872ed92ba92888ab99df297550b9a36a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","5e9ee82a511a2ff4aad3e0bd7a3ab820c03ce6fc"],"5e9ee82a511a2ff4aad3e0bd7a3ab820c03ce6fc":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"29ef99d61cda9641b6250bf9567329a6e65f901d":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["29ef99d61cda9641b6250bf9567329a6e65f901d","16843358872ed92ba92888ab99df297550b9a36a","5e9ee82a511a2ff4aad3e0bd7a3ab820c03ce6fc"],"16843358872ed92ba92888ab99df297550b9a36a":[],"5e9ee82a511a2ff4aad3e0bd7a3ab820c03ce6fc":["3a119bbc8703c10faa329ec201c654b3a35a1e3e","29ef99d61cda9641b6250bf9567329a6e65f901d","16843358872ed92ba92888ab99df297550b9a36a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["29ef99d61cda9641b6250bf9567329a6e65f901d","16843358872ed92ba92888ab99df297550b9a36a","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}