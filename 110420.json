{"path":"contrib/memory/src/java/org/apache/lucene/index/memory/MemoryIndex#addField(String,TokenStream).mjava","commits":[{"id":"50e7972fe4865715af8951d4ba15555e3426fc5d","date":1115024647,"type":0,"author":"Erik Hatcher","isMerge":false,"pathNew":"contrib/memory/src/java/org/apache/lucene/index/memory/MemoryIndex#addField(String,TokenStream).mjava","pathOld":"/dev/null","sourceNew":"\t/**\n\t * Iterates over the given token stream and adds the resulting terms to the index;\n\t * Equivalent to adding a tokenized, indexed, termVectorStored, unstored,\n\t * Lucene {@link org.apache.lucene.document.Field}.\n\t * Finally closes the token stream. Note that untokenized keywords can be added with this method via \n\t * the Lucene contrib <code>KeywordTokenizer</code> or similar utilities.\n\t * \n\t * @param fieldName\n\t *            a name to be associated with the text\n\t * @param stream\n\t *            the token stream to retrieve tokens from.\n\t */\n\tpublic void addField(String fieldName, TokenStream stream) {\n\t\t/*\n\t\t * Note that this method signature avoids having a user call new\n\t\t * o.a.l.d.Field(...) which would be much too expensive due to the\n\t\t * String.intern() usage of that class.\n\t\t * \n\t\t * More often than not, String.intern() leads to serious performance\n\t\t * degradations rather than improvements! If you're curious why, check\n\t\t * out the JDK's native code, see how it oscillates multiple times back\n\t\t * and forth between Java code and native code on each intern() call,\n\t\t * only to end up using a plain vanilla java.util.HashMap on the Java\n\t\t * heap for it's interned strings! String.equals() has a small cost\n\t\t * compared to String.intern(), trust me. Application level interning\n\t\t * (e.g. a HashMap per Directory/Index) typically leads to better\n\t\t * solutions than frequent hidden low-level calls to String.intern().\n\t\t * \n\t\t * Perhaps with some luck, Lucene's Field.java (and Term.java) and\n\t\t * cousins could be fixed to not use String.intern(). Sigh :-(\n\t\t */\n\t\ttry {\n\t\t\tif (fieldName == null)\n\t\t\t\tthrow new IllegalArgumentException(\"fieldName must not be null\");\n\t\t\tif (stream == null)\n\t\t\t\tthrow new IllegalArgumentException(\"token stream must not be null\");\n\t\t\tif (fields.get(fieldName) != null)\n\t\t\t\tthrow new IllegalArgumentException(\"field must not be added more than once\");\n\t\t\t\n\t\t\tHashMap terms = new HashMap();\n\t\t\tint numTokens = 0;\n\t\t\tint pos = -1;\n\t\t\tToken token;\n\t\t\t\n\t\t\twhile ((token = stream.next()) != null) {\n\t\t\t\tnumTokens++;\n\t\t\t\tpos += token.getPositionIncrement();\n\t\t\t\t\n\t\t\t\tString term = token.termText();\n\t\t\t\tif (DEBUG) System.err.println(\"token='\" + term + \"'\");\n\t\t\t\tArrayIntList positions = (ArrayIntList) terms.get(term);\n\t\t\t\tif (positions == null) { // term not seen before\n\t\t\t\t\tpositions = new ArrayIntList(stride);\n\t\t\t\t\tterms.put(term, positions);\n\t\t\t\t}\n\t\t\t\tif (stride == 1)\n\t\t\t\t\tpositions.add(pos);\n\t\t\t\telse\n\t\t\t\t\tpositions.add(pos, token.startOffset(), token.endOffset());\n\t\t\t}\n\t\t\t\n\t\t\t// ensure infos.numTokens > 0 invariant; needed for correct operation of terms()\n\t\t\tif (numTokens > 0) {\n\t\t\t\tfields.put(fieldName, new Info(terms, numTokens));\n\t\t\t\tsortedFields = null; // invalidate sorted view, if any\n\t\t\t}\n\t\t} catch (IOException e) { // can never happen\n\t\t\tthrow new RuntimeException(e);\n\t\t} finally {\n\t\t\ttry {\n\t\t\t\tif (stream != null) stream.close();\n\t\t\t} catch (IOException e2) {\n\t\t\t\tthrow new RuntimeException(e2);\n\t\t\t}\n\t\t}\n\t}\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c8f14489323057ef6de92ba5ea2d0cfe6e34755f","date":1120167605,"type":3,"author":"Mark Harwood","isMerge":false,"pathNew":"contrib/memory/src/java/org/apache/lucene/index/memory/MemoryIndex#addField(String,TokenStream).mjava","pathOld":"contrib/memory/src/java/org/apache/lucene/index/memory/MemoryIndex#addField(String,TokenStream).mjava","sourceNew":"\t/**\r\n\t * Iterates over the given token stream and adds the resulting terms to the index;\r\n\t * Equivalent to adding a tokenized, indexed, termVectorStored, unstored,\r\n\t * Lucene {@link org.apache.lucene.document.Field}.\r\n\t * Finally closes the token stream. Note that untokenized keywords can be added with this method via \r\n\t * {@link #keywordTokenStream(Collection)}, the Lucene contrib <code>KeywordTokenizer</code> or similar utilities.\r\n\t * \r\n\t * @param fieldName\r\n\t *            a name to be associated with the text\r\n\t * @param stream\r\n\t *            the token stream to retrieve tokens from.\r\n\t */\r\n\tpublic void addField(String fieldName, TokenStream stream) {\r\n\t\t/*\r\n\t\t * Note that this method signature avoids having a user call new\r\n\t\t * o.a.l.d.Field(...) which would be much too expensive due to the\r\n\t\t * String.intern() usage of that class.\r\n\t\t * \r\n\t\t * More often than not, String.intern() leads to serious performance\r\n\t\t * degradations rather than improvements! If you're curious why, check\r\n\t\t * out the JDK's native code, see how it oscillates multiple times back\r\n\t\t * and forth between Java code and native code on each intern() call,\r\n\t\t * only to end up using a plain vanilla java.util.HashMap on the Java\r\n\t\t * heap for it's interned strings! String.equals() has a small cost\r\n\t\t * compared to String.intern(), trust me. Application level interning\r\n\t\t * (e.g. a HashMap per Directory/Index) typically leads to better\r\n\t\t * solutions than frequent hidden low-level calls to String.intern().\r\n\t\t * \r\n\t\t * Perhaps with some luck, Lucene's Field.java (and Term.java) and\r\n\t\t * cousins could be fixed to not use String.intern(). Sigh :-(\r\n\t\t */\r\n\t\ttry {\r\n\t\t\tif (fieldName == null)\r\n\t\t\t\tthrow new IllegalArgumentException(\"fieldName must not be null\");\r\n\t\t\tif (stream == null)\r\n\t\t\t\tthrow new IllegalArgumentException(\"token stream must not be null\");\r\n\t\t\tif (fields.get(fieldName) != null)\r\n\t\t\t\tthrow new IllegalArgumentException(\"field must not be added more than once\");\r\n\t\t\t\r\n\t\t\tHashMap terms = new HashMap();\r\n\t\t\tint numTokens = 0;\r\n\t\t\tint pos = -1;\r\n\t\t\tToken token;\r\n\t\t\t\r\n\t\t\twhile ((token = stream.next()) != null) {\r\n\t\t\t\tnumTokens++;\r\n\t\t\t\tpos += token.getPositionIncrement();\r\n\t\t\t\t\r\n\t\t\t\tString term = token.termText();\r\n//\t\t\t\tif (DEBUG) System.err.println(\"token='\" + term + \"'\");\r\n\t\t\t\tArrayIntList positions = (ArrayIntList) terms.get(term);\r\n\t\t\t\tif (positions == null) { // term not seen before\r\n\t\t\t\t\tpositions = new ArrayIntList(stride);\r\n\t\t\t\t\tterms.put(term, positions);\r\n\t\t\t\t}\r\n\t\t\t\tif (stride == 1)\r\n\t\t\t\t\tpositions.add(pos);\r\n\t\t\t\telse\r\n\t\t\t\t\tpositions.add(pos, token.startOffset(), token.endOffset());\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\t// ensure infos.numTokens > 0 invariant; needed for correct operation of terms()\r\n\t\t\tif (numTokens > 0) {\r\n\t\t\t\tfields.put(fieldName, new Info(terms, numTokens));\r\n\t\t\t\tsortedFields = null;    // invalidate sorted view, if any\r\n\t\t\t\tsortedTemplates = null; // invalidate sorted view, if any\r\n\t\t\t}\r\n\t\t} catch (IOException e) { // can never happen\r\n\t\t\tthrow new RuntimeException(e);\r\n\t\t} finally {\r\n\t\t\ttry {\r\n\t\t\t\tif (stream != null) stream.close();\r\n\t\t\t} catch (IOException e2) {\r\n\t\t\t\tthrow new RuntimeException(e2);\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\n","sourceOld":"\t/**\n\t * Iterates over the given token stream and adds the resulting terms to the index;\n\t * Equivalent to adding a tokenized, indexed, termVectorStored, unstored,\n\t * Lucene {@link org.apache.lucene.document.Field}.\n\t * Finally closes the token stream. Note that untokenized keywords can be added with this method via \n\t * the Lucene contrib <code>KeywordTokenizer</code> or similar utilities.\n\t * \n\t * @param fieldName\n\t *            a name to be associated with the text\n\t * @param stream\n\t *            the token stream to retrieve tokens from.\n\t */\n\tpublic void addField(String fieldName, TokenStream stream) {\n\t\t/*\n\t\t * Note that this method signature avoids having a user call new\n\t\t * o.a.l.d.Field(...) which would be much too expensive due to the\n\t\t * String.intern() usage of that class.\n\t\t * \n\t\t * More often than not, String.intern() leads to serious performance\n\t\t * degradations rather than improvements! If you're curious why, check\n\t\t * out the JDK's native code, see how it oscillates multiple times back\n\t\t * and forth between Java code and native code on each intern() call,\n\t\t * only to end up using a plain vanilla java.util.HashMap on the Java\n\t\t * heap for it's interned strings! String.equals() has a small cost\n\t\t * compared to String.intern(), trust me. Application level interning\n\t\t * (e.g. a HashMap per Directory/Index) typically leads to better\n\t\t * solutions than frequent hidden low-level calls to String.intern().\n\t\t * \n\t\t * Perhaps with some luck, Lucene's Field.java (and Term.java) and\n\t\t * cousins could be fixed to not use String.intern(). Sigh :-(\n\t\t */\n\t\ttry {\n\t\t\tif (fieldName == null)\n\t\t\t\tthrow new IllegalArgumentException(\"fieldName must not be null\");\n\t\t\tif (stream == null)\n\t\t\t\tthrow new IllegalArgumentException(\"token stream must not be null\");\n\t\t\tif (fields.get(fieldName) != null)\n\t\t\t\tthrow new IllegalArgumentException(\"field must not be added more than once\");\n\t\t\t\n\t\t\tHashMap terms = new HashMap();\n\t\t\tint numTokens = 0;\n\t\t\tint pos = -1;\n\t\t\tToken token;\n\t\t\t\n\t\t\twhile ((token = stream.next()) != null) {\n\t\t\t\tnumTokens++;\n\t\t\t\tpos += token.getPositionIncrement();\n\t\t\t\t\n\t\t\t\tString term = token.termText();\n\t\t\t\tif (DEBUG) System.err.println(\"token='\" + term + \"'\");\n\t\t\t\tArrayIntList positions = (ArrayIntList) terms.get(term);\n\t\t\t\tif (positions == null) { // term not seen before\n\t\t\t\t\tpositions = new ArrayIntList(stride);\n\t\t\t\t\tterms.put(term, positions);\n\t\t\t\t}\n\t\t\t\tif (stride == 1)\n\t\t\t\t\tpositions.add(pos);\n\t\t\t\telse\n\t\t\t\t\tpositions.add(pos, token.startOffset(), token.endOffset());\n\t\t\t}\n\t\t\t\n\t\t\t// ensure infos.numTokens > 0 invariant; needed for correct operation of terms()\n\t\t\tif (numTokens > 0) {\n\t\t\t\tfields.put(fieldName, new Info(terms, numTokens));\n\t\t\t\tsortedFields = null; // invalidate sorted view, if any\n\t\t\t}\n\t\t} catch (IOException e) { // can never happen\n\t\t\tthrow new RuntimeException(e);\n\t\t} finally {\n\t\t\ttry {\n\t\t\t\tif (stream != null) stream.close();\n\t\t\t} catch (IOException e2) {\n\t\t\t\tthrow new RuntimeException(e2);\n\t\t\t}\n\t\t}\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"35dd40ede4dd66fa47506858c4a073d295c5a76e","date":1133587328,"type":4,"author":"Wolfgang Hoschek","isMerge":false,"pathNew":"/dev/null","pathOld":"contrib/memory/src/java/org/apache/lucene/index/memory/MemoryIndex#addField(String,TokenStream).mjava","sourceNew":null,"sourceOld":"\t/**\r\n\t * Iterates over the given token stream and adds the resulting terms to the index;\r\n\t * Equivalent to adding a tokenized, indexed, termVectorStored, unstored,\r\n\t * Lucene {@link org.apache.lucene.document.Field}.\r\n\t * Finally closes the token stream. Note that untokenized keywords can be added with this method via \r\n\t * {@link #keywordTokenStream(Collection)}, the Lucene contrib <code>KeywordTokenizer</code> or similar utilities.\r\n\t * \r\n\t * @param fieldName\r\n\t *            a name to be associated with the text\r\n\t * @param stream\r\n\t *            the token stream to retrieve tokens from.\r\n\t */\r\n\tpublic void addField(String fieldName, TokenStream stream) {\r\n\t\t/*\r\n\t\t * Note that this method signature avoids having a user call new\r\n\t\t * o.a.l.d.Field(...) which would be much too expensive due to the\r\n\t\t * String.intern() usage of that class.\r\n\t\t * \r\n\t\t * More often than not, String.intern() leads to serious performance\r\n\t\t * degradations rather than improvements! If you're curious why, check\r\n\t\t * out the JDK's native code, see how it oscillates multiple times back\r\n\t\t * and forth between Java code and native code on each intern() call,\r\n\t\t * only to end up using a plain vanilla java.util.HashMap on the Java\r\n\t\t * heap for it's interned strings! String.equals() has a small cost\r\n\t\t * compared to String.intern(), trust me. Application level interning\r\n\t\t * (e.g. a HashMap per Directory/Index) typically leads to better\r\n\t\t * solutions than frequent hidden low-level calls to String.intern().\r\n\t\t * \r\n\t\t * Perhaps with some luck, Lucene's Field.java (and Term.java) and\r\n\t\t * cousins could be fixed to not use String.intern(). Sigh :-(\r\n\t\t */\r\n\t\ttry {\r\n\t\t\tif (fieldName == null)\r\n\t\t\t\tthrow new IllegalArgumentException(\"fieldName must not be null\");\r\n\t\t\tif (stream == null)\r\n\t\t\t\tthrow new IllegalArgumentException(\"token stream must not be null\");\r\n\t\t\tif (fields.get(fieldName) != null)\r\n\t\t\t\tthrow new IllegalArgumentException(\"field must not be added more than once\");\r\n\t\t\t\r\n\t\t\tHashMap terms = new HashMap();\r\n\t\t\tint numTokens = 0;\r\n\t\t\tint pos = -1;\r\n\t\t\tToken token;\r\n\t\t\t\r\n\t\t\twhile ((token = stream.next()) != null) {\r\n\t\t\t\tnumTokens++;\r\n\t\t\t\tpos += token.getPositionIncrement();\r\n\t\t\t\t\r\n\t\t\t\tString term = token.termText();\r\n//\t\t\t\tif (DEBUG) System.err.println(\"token='\" + term + \"'\");\r\n\t\t\t\tArrayIntList positions = (ArrayIntList) terms.get(term);\r\n\t\t\t\tif (positions == null) { // term not seen before\r\n\t\t\t\t\tpositions = new ArrayIntList(stride);\r\n\t\t\t\t\tterms.put(term, positions);\r\n\t\t\t\t}\r\n\t\t\t\tif (stride == 1)\r\n\t\t\t\t\tpositions.add(pos);\r\n\t\t\t\telse\r\n\t\t\t\t\tpositions.add(pos, token.startOffset(), token.endOffset());\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\t// ensure infos.numTokens > 0 invariant; needed for correct operation of terms()\r\n\t\t\tif (numTokens > 0) {\r\n\t\t\t\tfields.put(fieldName, new Info(terms, numTokens));\r\n\t\t\t\tsortedFields = null;    // invalidate sorted view, if any\r\n\t\t\t\tsortedTemplates = null; // invalidate sorted view, if any\r\n\t\t\t}\r\n\t\t} catch (IOException e) { // can never happen\r\n\t\t\tthrow new RuntimeException(e);\r\n\t\t} finally {\r\n\t\t\ttry {\r\n\t\t\t\tif (stream != null) stream.close();\r\n\t\t\t} catch (IOException e2) {\r\n\t\t\t\tthrow new RuntimeException(e2);\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a93e1e4a21be8ebb98e53e6933412a363931faa1","date":1133587471,"type":0,"author":"Wolfgang Hoschek","isMerge":false,"pathNew":"contrib/memory/src/java/org/apache/lucene/index/memory/MemoryIndex#addField(String,TokenStream).mjava","pathOld":"/dev/null","sourceNew":"\t/**\n\t * Iterates over the given token stream and adds the resulting terms to the index;\n\t * Equivalent to adding a tokenized, indexed, termVectorStored, unstored,\n\t * Lucene {@link org.apache.lucene.document.Field}.\n\t * Finally closes the token stream. Note that untokenized keywords can be added with this method via \n\t * {@link #keywordTokenStream(Collection)}, the Lucene contrib <code>KeywordTokenizer</code> or similar utilities.\n\t * \n\t * @param fieldName\n\t *            a name to be associated with the text\n\t * @param stream\n\t *            the token stream to retrieve tokens from.\n\t */\n\tpublic void addField(String fieldName, TokenStream stream) {\n\t\t/*\n\t\t * Note that this method signature avoids having a user call new\n\t\t * o.a.l.d.Field(...) which would be much too expensive due to the\n\t\t * String.intern() usage of that class.\n\t\t * \n\t\t * More often than not, String.intern() leads to serious performance\n\t\t * degradations rather than improvements! If you're curious why, check\n\t\t * out the JDK's native code, see how it oscillates multiple times back\n\t\t * and forth between Java code and native code on each intern() call,\n\t\t * only to end up using a plain vanilla java.util.HashMap on the Java\n\t\t * heap for it's interned strings! String.equals() has a small cost\n\t\t * compared to String.intern(), trust me. Application level interning\n\t\t * (e.g. a HashMap per Directory/Index) typically leads to better\n\t\t * solutions than frequent hidden low-level calls to String.intern().\n\t\t * \n\t\t * Perhaps with some luck, Lucene's Field.java (and Term.java) and\n\t\t * cousins could be fixed to not use String.intern(). Sigh :-(\n\t\t */\n\t\ttry {\n\t\t\tif (fieldName == null)\n\t\t\t\tthrow new IllegalArgumentException(\"fieldName must not be null\");\n\t\t\tif (stream == null)\n\t\t\t\tthrow new IllegalArgumentException(\"token stream must not be null\");\n\t\t\tif (fields.get(fieldName) != null)\n\t\t\t\tthrow new IllegalArgumentException(\"field must not be added more than once\");\n\t\t\t\n\t\t\tHashMap terms = new HashMap();\n\t\t\tint numTokens = 0;\n\t\t\tint pos = -1;\n\t\t\tToken token;\n\t\t\t\n\t\t\twhile ((token = stream.next()) != null) {\n\t\t\t\tString term = token.termText();\n\t\t\t\tif (term.length() == 0) continue; // nothing to do\n//\t\t\t\tif (DEBUG) System.err.println(\"token='\" + term + \"'\");\n\t\t\t\tnumTokens++;\n\t\t\t\tpos += token.getPositionIncrement();\n\t\t\t\t\n\t\t\t\tArrayIntList positions = (ArrayIntList) terms.get(term);\n\t\t\t\tif (positions == null) { // term not seen before\n\t\t\t\t\tpositions = new ArrayIntList(stride);\n\t\t\t\t\tterms.put(term, positions);\n\t\t\t\t}\n\t\t\t\tif (stride == 1) {\n\t\t\t\t\tpositions.add(pos);\n\t\t\t\t} else {\n\t\t\t\t\tpositions.add(pos, token.startOffset(), token.endOffset());\n\t\t\t\t}\n\t\t\t}\n\t\t\t\n\t\t\t// ensure infos.numTokens > 0 invariant; needed for correct operation of terms()\n\t\t\tif (numTokens > 0) {\n\t\t\t\tfields.put(fieldName, new Info(terms, numTokens));\n\t\t\t\tsortedFields = null;    // invalidate sorted view, if any\n\t\t\t}\n\t\t} catch (IOException e) { // can never happen\n\t\t\tthrow new RuntimeException(e);\n\t\t} finally {\n\t\t\ttry {\n\t\t\t\tif (stream != null) stream.close();\n\t\t\t} catch (IOException e2) {\n\t\t\t\tthrow new RuntimeException(e2);\n\t\t\t}\n\t\t}\n\t}\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7f68e24227d5556d33ee6d586fd9010cd9ff8bec","date":1150091176,"type":3,"author":"Otis Gospodnetic","isMerge":false,"pathNew":"contrib/memory/src/java/org/apache/lucene/index/memory/MemoryIndex#addField(String,TokenStream).mjava","pathOld":"contrib/memory/src/java/org/apache/lucene/index/memory/MemoryIndex#addField(String,TokenStream).mjava","sourceNew":"  /**\n   * Iterates over the given token stream and adds the resulting terms to the index;\n   * Equivalent to adding a tokenized, indexed, termVectorStored, unstored,\n   * Lucene {@link org.apache.lucene.document.Field}.\n   * Finally closes the token stream. Note that untokenized keywords can be added with this method via \n   * {@link #keywordTokenStream(Collection)}, the Lucene contrib <code>KeywordTokenizer</code> or similar utilities.\n   * \n   * @param fieldName\n   *            a name to be associated with the text\n   * @param stream\n   *            the token stream to retrieve tokens from.\n   */\n  public void addField(String fieldName, TokenStream stream) {\n    /*\n     * Note that this method signature avoids having a user call new\n     * o.a.l.d.Field(...) which would be much too expensive due to the\n     * String.intern() usage of that class.\n     * \n     * More often than not, String.intern() leads to serious performance\n     * degradations rather than improvements! If you're curious why, check\n     * out the JDK's native code, see how it oscillates multiple times back\n     * and forth between Java code and native code on each intern() call,\n     * only to end up using a plain vanilla java.util.HashMap on the Java\n     * heap for it's interned strings! String.equals() has a small cost\n     * compared to String.intern(), trust me. Application level interning\n     * (e.g. a HashMap per Directory/Index) typically leads to better\n     * solutions than frequent hidden low-level calls to String.intern().\n     * \n     * Perhaps with some luck, Lucene's Field.java (and Term.java) and\n     * cousins could be fixed to not use String.intern(). Sigh :-(\n     */\n    try {\n      if (fieldName == null)\n        throw new IllegalArgumentException(\"fieldName must not be null\");\n      if (stream == null)\n        throw new IllegalArgumentException(\"token stream must not be null\");\n      if (fields.get(fieldName) != null)\n        throw new IllegalArgumentException(\"field must not be added more than once\");\n      \n      HashMap terms = new HashMap();\n      int numTokens = 0;\n      int pos = -1;\n      Token token;\n      \n      while ((token = stream.next()) != null) {\n        String term = token.termText();\n        if (term.length() == 0) continue; // nothing to do\n//        if (DEBUG) System.err.println(\"token='\" + term + \"'\");\n        numTokens++;\n        pos += token.getPositionIncrement();\n        \n        ArrayIntList positions = (ArrayIntList) terms.get(term);\n        if (positions == null) { // term not seen before\n          positions = new ArrayIntList(stride);\n          terms.put(term, positions);\n        }\n        if (stride == 1) {\n          positions.add(pos);\n        } else {\n          positions.add(pos, token.startOffset(), token.endOffset());\n        }\n      }\n      \n      // ensure infos.numTokens > 0 invariant; needed for correct operation of terms()\n      if (numTokens > 0) {\n        fields.put(fieldName, new Info(terms, numTokens));\n        sortedFields = null;    // invalidate sorted view, if any\n      }\n    } catch (IOException e) { // can never happen\n      throw new RuntimeException(e);\n    } finally {\n      try {\n        if (stream != null) stream.close();\n      } catch (IOException e2) {\n        throw new RuntimeException(e2);\n      }\n    }\n  }\n\n","sourceOld":"\t/**\n\t * Iterates over the given token stream and adds the resulting terms to the index;\n\t * Equivalent to adding a tokenized, indexed, termVectorStored, unstored,\n\t * Lucene {@link org.apache.lucene.document.Field}.\n\t * Finally closes the token stream. Note that untokenized keywords can be added with this method via \n\t * {@link #keywordTokenStream(Collection)}, the Lucene contrib <code>KeywordTokenizer</code> or similar utilities.\n\t * \n\t * @param fieldName\n\t *            a name to be associated with the text\n\t * @param stream\n\t *            the token stream to retrieve tokens from.\n\t */\n\tpublic void addField(String fieldName, TokenStream stream) {\n\t\t/*\n\t\t * Note that this method signature avoids having a user call new\n\t\t * o.a.l.d.Field(...) which would be much too expensive due to the\n\t\t * String.intern() usage of that class.\n\t\t * \n\t\t * More often than not, String.intern() leads to serious performance\n\t\t * degradations rather than improvements! If you're curious why, check\n\t\t * out the JDK's native code, see how it oscillates multiple times back\n\t\t * and forth between Java code and native code on each intern() call,\n\t\t * only to end up using a plain vanilla java.util.HashMap on the Java\n\t\t * heap for it's interned strings! String.equals() has a small cost\n\t\t * compared to String.intern(), trust me. Application level interning\n\t\t * (e.g. a HashMap per Directory/Index) typically leads to better\n\t\t * solutions than frequent hidden low-level calls to String.intern().\n\t\t * \n\t\t * Perhaps with some luck, Lucene's Field.java (and Term.java) and\n\t\t * cousins could be fixed to not use String.intern(). Sigh :-(\n\t\t */\n\t\ttry {\n\t\t\tif (fieldName == null)\n\t\t\t\tthrow new IllegalArgumentException(\"fieldName must not be null\");\n\t\t\tif (stream == null)\n\t\t\t\tthrow new IllegalArgumentException(\"token stream must not be null\");\n\t\t\tif (fields.get(fieldName) != null)\n\t\t\t\tthrow new IllegalArgumentException(\"field must not be added more than once\");\n\t\t\t\n\t\t\tHashMap terms = new HashMap();\n\t\t\tint numTokens = 0;\n\t\t\tint pos = -1;\n\t\t\tToken token;\n\t\t\t\n\t\t\twhile ((token = stream.next()) != null) {\n\t\t\t\tString term = token.termText();\n\t\t\t\tif (term.length() == 0) continue; // nothing to do\n//\t\t\t\tif (DEBUG) System.err.println(\"token='\" + term + \"'\");\n\t\t\t\tnumTokens++;\n\t\t\t\tpos += token.getPositionIncrement();\n\t\t\t\t\n\t\t\t\tArrayIntList positions = (ArrayIntList) terms.get(term);\n\t\t\t\tif (positions == null) { // term not seen before\n\t\t\t\t\tpositions = new ArrayIntList(stride);\n\t\t\t\t\tterms.put(term, positions);\n\t\t\t\t}\n\t\t\t\tif (stride == 1) {\n\t\t\t\t\tpositions.add(pos);\n\t\t\t\t} else {\n\t\t\t\t\tpositions.add(pos, token.startOffset(), token.endOffset());\n\t\t\t\t}\n\t\t\t}\n\t\t\t\n\t\t\t// ensure infos.numTokens > 0 invariant; needed for correct operation of terms()\n\t\t\tif (numTokens > 0) {\n\t\t\t\tfields.put(fieldName, new Info(terms, numTokens));\n\t\t\t\tsortedFields = null;    // invalidate sorted view, if any\n\t\t\t}\n\t\t} catch (IOException e) { // can never happen\n\t\t\tthrow new RuntimeException(e);\n\t\t} finally {\n\t\t\ttry {\n\t\t\t\tif (stream != null) stream.close();\n\t\t\t} catch (IOException e2) {\n\t\t\t\tthrow new RuntimeException(e2);\n\t\t\t}\n\t\t}\n\t}\n\n","bugFix":null,"bugIntro":["2eceb3be6e29e3ad7ee08d5025a431c3812aa0d9"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3a2dfe27dcd813920f9df8dbd28079c6e6b9e93e","date":1159427430,"type":3,"author":"Wolfgang Hoschek","isMerge":false,"pathNew":"contrib/memory/src/java/org/apache/lucene/index/memory/MemoryIndex#addField(String,TokenStream).mjava","pathOld":"contrib/memory/src/java/org/apache/lucene/index/memory/MemoryIndex#addField(String,TokenStream).mjava","sourceNew":"  /**\n   * Equivalent to <code>addField(fieldName, stream, 1.0f)</code>.\n   * \n   * @param fieldName\n   *            a name to be associated with the text\n   * @param stream\n   *            the token stream to retrieve tokens from\n   */\n  public void addField(String fieldName, TokenStream stream) {\n\taddField(fieldName, stream, 1.0f);\n  }\n\n","sourceOld":"  /**\n   * Iterates over the given token stream and adds the resulting terms to the index;\n   * Equivalent to adding a tokenized, indexed, termVectorStored, unstored,\n   * Lucene {@link org.apache.lucene.document.Field}.\n   * Finally closes the token stream. Note that untokenized keywords can be added with this method via \n   * {@link #keywordTokenStream(Collection)}, the Lucene contrib <code>KeywordTokenizer</code> or similar utilities.\n   * \n   * @param fieldName\n   *            a name to be associated with the text\n   * @param stream\n   *            the token stream to retrieve tokens from.\n   */\n  public void addField(String fieldName, TokenStream stream) {\n    /*\n     * Note that this method signature avoids having a user call new\n     * o.a.l.d.Field(...) which would be much too expensive due to the\n     * String.intern() usage of that class.\n     * \n     * More often than not, String.intern() leads to serious performance\n     * degradations rather than improvements! If you're curious why, check\n     * out the JDK's native code, see how it oscillates multiple times back\n     * and forth between Java code and native code on each intern() call,\n     * only to end up using a plain vanilla java.util.HashMap on the Java\n     * heap for it's interned strings! String.equals() has a small cost\n     * compared to String.intern(), trust me. Application level interning\n     * (e.g. a HashMap per Directory/Index) typically leads to better\n     * solutions than frequent hidden low-level calls to String.intern().\n     * \n     * Perhaps with some luck, Lucene's Field.java (and Term.java) and\n     * cousins could be fixed to not use String.intern(). Sigh :-(\n     */\n    try {\n      if (fieldName == null)\n        throw new IllegalArgumentException(\"fieldName must not be null\");\n      if (stream == null)\n        throw new IllegalArgumentException(\"token stream must not be null\");\n      if (fields.get(fieldName) != null)\n        throw new IllegalArgumentException(\"field must not be added more than once\");\n      \n      HashMap terms = new HashMap();\n      int numTokens = 0;\n      int pos = -1;\n      Token token;\n      \n      while ((token = stream.next()) != null) {\n        String term = token.termText();\n        if (term.length() == 0) continue; // nothing to do\n//        if (DEBUG) System.err.println(\"token='\" + term + \"'\");\n        numTokens++;\n        pos += token.getPositionIncrement();\n        \n        ArrayIntList positions = (ArrayIntList) terms.get(term);\n        if (positions == null) { // term not seen before\n          positions = new ArrayIntList(stride);\n          terms.put(term, positions);\n        }\n        if (stride == 1) {\n          positions.add(pos);\n        } else {\n          positions.add(pos, token.startOffset(), token.endOffset());\n        }\n      }\n      \n      // ensure infos.numTokens > 0 invariant; needed for correct operation of terms()\n      if (numTokens > 0) {\n        fields.put(fieldName, new Info(terms, numTokens));\n        sortedFields = null;    // invalidate sorted view, if any\n      }\n    } catch (IOException e) { // can never happen\n      throw new RuntimeException(e);\n    } finally {\n      try {\n        if (stream != null) stream.close();\n      } catch (IOException e2) {\n        throw new RuntimeException(e2);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3152c5a8024c769c20b6eeec4fcb04097d750874","date":1163744279,"type":3,"author":"Wolfgang Hoschek","isMerge":false,"pathNew":"contrib/memory/src/java/org/apache/lucene/index/memory/MemoryIndex#addField(String,TokenStream).mjava","pathOld":"contrib/memory/src/java/org/apache/lucene/index/memory/MemoryIndex#addField(String,TokenStream).mjava","sourceNew":"  /**\n   * Equivalent to <code>addField(fieldName, stream, 1.0f)</code>.\n   * \n   * @param fieldName\n   *            a name to be associated with the text\n   * @param stream\n   *            the token stream to retrieve tokens from\n   */\n  public void addField(String fieldName, TokenStream stream) {\n    addField(fieldName, stream, 1.0f);\n  }\n\n","sourceOld":"  /**\n   * Equivalent to <code>addField(fieldName, stream, 1.0f)</code>.\n   * \n   * @param fieldName\n   *            a name to be associated with the text\n   * @param stream\n   *            the token stream to retrieve tokens from\n   */\n  public void addField(String fieldName, TokenStream stream) {\n\taddField(fieldName, stream, 1.0f);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/memory/src/java/org/apache/lucene/index/memory/MemoryIndex#addField(String,TokenStream).mjava","pathOld":"contrib/memory/src/java/org/apache/lucene/index/memory/MemoryIndex#addField(String,TokenStream).mjava","sourceNew":"  /**\n   * Equivalent to <code>addField(fieldName, stream, 1.0f)</code>.\n   * \n   * @param fieldName\n   *            a name to be associated with the text\n   * @param stream\n   *            the token stream to retrieve tokens from\n   */\n  public void addField(String fieldName, TokenStream stream) {\n    addField(fieldName, stream, 1.0f);\n  }\n\n","sourceOld":"  /**\n   * Equivalent to <code>addField(fieldName, stream, 1.0f)</code>.\n   * \n   * @param fieldName\n   *            a name to be associated with the text\n   * @param stream\n   *            the token stream to retrieve tokens from\n   */\n  public void addField(String fieldName, TokenStream stream) {\n    addField(fieldName, stream, 1.0f);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"35dd40ede4dd66fa47506858c4a073d295c5a76e":["c8f14489323057ef6de92ba5ea2d0cfe6e34755f"],"c8f14489323057ef6de92ba5ea2d0cfe6e34755f":["50e7972fe4865715af8951d4ba15555e3426fc5d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"7f68e24227d5556d33ee6d586fd9010cd9ff8bec":["a93e1e4a21be8ebb98e53e6933412a363931faa1"],"50e7972fe4865715af8951d4ba15555e3426fc5d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"3152c5a8024c769c20b6eeec4fcb04097d750874":["3a2dfe27dcd813920f9df8dbd28079c6e6b9e93e"],"a93e1e4a21be8ebb98e53e6933412a363931faa1":["35dd40ede4dd66fa47506858c4a073d295c5a76e"],"3a2dfe27dcd813920f9df8dbd28079c6e6b9e93e":["7f68e24227d5556d33ee6d586fd9010cd9ff8bec"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["3152c5a8024c769c20b6eeec4fcb04097d750874"]},"commit2Childs":{"35dd40ede4dd66fa47506858c4a073d295c5a76e":["a93e1e4a21be8ebb98e53e6933412a363931faa1"],"c8f14489323057ef6de92ba5ea2d0cfe6e34755f":["35dd40ede4dd66fa47506858c4a073d295c5a76e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["50e7972fe4865715af8951d4ba15555e3426fc5d"],"7f68e24227d5556d33ee6d586fd9010cd9ff8bec":["3a2dfe27dcd813920f9df8dbd28079c6e6b9e93e"],"50e7972fe4865715af8951d4ba15555e3426fc5d":["c8f14489323057ef6de92ba5ea2d0cfe6e34755f"],"3152c5a8024c769c20b6eeec4fcb04097d750874":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"a93e1e4a21be8ebb98e53e6933412a363931faa1":["7f68e24227d5556d33ee6d586fd9010cd9ff8bec"],"3a2dfe27dcd813920f9df8dbd28079c6e6b9e93e":["3152c5a8024c769c20b6eeec4fcb04097d750874"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}