{"path":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","pathOld":"src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","sourceNew":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = new MockRAMDirectory();\n    final IndexWriter writer = new IndexWriter(dir1, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));\n    writer.setInfoStream(infoStream);\n    ((LogMergePolicy) writer.getMergePolicy()).setMergeFactor(2);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final int NUM_THREAD = 5;\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[NUM_THREAD];\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            int count = 0;\n            final Random r = new Random();\n            do {\n              try {\n                for(int i=0;i<10;i++) {\n                  writer.addDocument(createDocument(10*count+i, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int i=0;i<5;i++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      sum += new IndexSearcher(r).search(q, 10).totalHits;\n    }\n\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    sum += new IndexSearcher(r).search(q, 10).totalHits;\n\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    _TestUtil.checkIndex(dir1);\n    r.close();\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = new MockRAMDirectory();\n    final IndexWriter writer = new IndexWriter(dir1, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));\n    writer.setInfoStream(infoStream);\n    ((LogMergePolicy) writer.getMergePolicy()).setMergeFactor(2);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final int NUM_THREAD = 5;\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[NUM_THREAD];\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            int count = 0;\n            final Random r = new Random();\n            do {\n              try {\n                for(int i=0;i<10;i++) {\n                  writer.addDocument(createDocument(10*count+i, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int i=0;i<5;i++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      sum += new IndexSearcher(r).search(q, 10).totalHits;\n    }\n\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    sum += new IndexSearcher(r).search(q, 10).totalHits;\n\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    _TestUtil.checkIndex(dir1);\n    r.close();\n    dir1.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7ab99e8c71442b92c320e218141dee04a9b91ce8","date":1269203801,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","sourceNew":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = new MockRAMDirectory();\n    final IndexWriter writer = new IndexWriter(dir1, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));\n    writer.setInfoStream(infoStream);\n    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(2);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final int NUM_THREAD = 5;\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[NUM_THREAD];\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            int count = 0;\n            final Random r = new Random();\n            do {\n              try {\n                for(int i=0;i<10;i++) {\n                  writer.addDocument(createDocument(10*count+i, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int i=0;i<5;i++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      sum += new IndexSearcher(r).search(q, 10).totalHits;\n    }\n\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    sum += new IndexSearcher(r).search(q, 10).totalHits;\n\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    _TestUtil.checkIndex(dir1);\n    r.close();\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = new MockRAMDirectory();\n    final IndexWriter writer = new IndexWriter(dir1, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));\n    writer.setInfoStream(infoStream);\n    ((LogMergePolicy) writer.getMergePolicy()).setMergeFactor(2);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final int NUM_THREAD = 5;\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[NUM_THREAD];\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            int count = 0;\n            final Random r = new Random();\n            do {\n              try {\n                for(int i=0;i<10;i++) {\n                  writer.addDocument(createDocument(10*count+i, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int i=0;i<5;i++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      sum += new IndexSearcher(r).search(q, 10).totalHits;\n    }\n\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    sum += new IndexSearcher(r).search(q, 10).totalHits;\n\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    _TestUtil.checkIndex(dir1);\n    r.close();\n    dir1.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d572389229127c297dd1fa5ce4758e1cec41e799","date":1273610938,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","sourceNew":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = new MockRAMDirectory();\n    final IndexWriter writer = new IndexWriter(dir1, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    writer.setInfoStream(infoStream);\n    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(2);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final int NUM_THREAD = 5;\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[NUM_THREAD];\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            int count = 0;\n            final Random r = new Random();\n            do {\n              try {\n                for(int i=0;i<10;i++) {\n                  writer.addDocument(createDocument(10*count+i, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int i=0;i<5;i++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      sum += new IndexSearcher(r).search(q, 10).totalHits;\n    }\n\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    sum += new IndexSearcher(r).search(q, 10).totalHits;\n\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    _TestUtil.checkIndex(dir1);\n    r.close();\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = new MockRAMDirectory();\n    final IndexWriter writer = new IndexWriter(dir1, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));\n    writer.setInfoStream(infoStream);\n    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(2);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final int NUM_THREAD = 5;\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[NUM_THREAD];\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            int count = 0;\n            final Random r = new Random();\n            do {\n              try {\n                for(int i=0;i<10;i++) {\n                  writer.addDocument(createDocument(10*count+i, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int i=0;i<5;i++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      sum += new IndexSearcher(r).search(q, 10).totalHits;\n    }\n\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    sum += new IndexSearcher(r).search(q, 10).totalHits;\n\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    _TestUtil.checkIndex(dir1);\n    r.close();\n    dir1.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b21422ff1d1d56499dec481f193b402e5e8def5b","date":1281472367,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","sourceNew":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = new MockRAMDirectory();\n    final IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));\n    writer.setInfoStream(infoStream);\n    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(2);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final int NUM_THREAD = 5;\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[NUM_THREAD];\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            int count = 0;\n            final Random r = new Random();\n            do {\n              try {\n                for(int i=0;i<10;i++) {\n                  writer.addDocument(createDocument(10*count+i, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int i=0;i<5;i++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      sum += new IndexSearcher(r).search(q, 10).totalHits;\n    }\n\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    sum += new IndexSearcher(r).search(q, 10).totalHits;\n\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    _TestUtil.checkIndex(dir1);\n    r.close();\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = new MockRAMDirectory();\n    final IndexWriter writer = new IndexWriter(dir1, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    writer.setInfoStream(infoStream);\n    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(2);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final int NUM_THREAD = 5;\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[NUM_THREAD];\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            int count = 0;\n            final Random r = new Random();\n            do {\n              try {\n                for(int i=0;i<10;i++) {\n                  writer.addDocument(createDocument(10*count+i, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int i=0;i<5;i++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      sum += new IndexSearcher(r).search(q, 10).totalHits;\n    }\n\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    sum += new IndexSearcher(r).search(q, 10).totalHits;\n\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    _TestUtil.checkIndex(dir1);\n    r.close();\n    dir1.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c","date":1281646583,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","sourceNew":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory(random);\n    final IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));\n    writer.setInfoStream(infoStream);\n    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(2);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final int NUM_THREAD = 5;\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[NUM_THREAD];\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            int count = 0;\n            final Random r = new Random();\n            do {\n              try {\n                for(int i=0;i<10;i++) {\n                  writer.addDocument(createDocument(10*count+i, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int i=0;i<5;i++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      sum += new IndexSearcher(r).search(q, 10).totalHits;\n    }\n\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    sum += new IndexSearcher(r).search(q, 10).totalHits;\n\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    _TestUtil.checkIndex(dir1);\n    r.close();\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = new MockRAMDirectory();\n    final IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));\n    writer.setInfoStream(infoStream);\n    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(2);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final int NUM_THREAD = 5;\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[NUM_THREAD];\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            int count = 0;\n            final Random r = new Random();\n            do {\n              try {\n                for(int i=0;i<10;i++) {\n                  writer.addDocument(createDocument(10*count+i, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int i=0;i<5;i++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      sum += new IndexSearcher(r).search(q, 10).totalHits;\n    }\n\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    sum += new IndexSearcher(r).search(q, 10).totalHits;\n\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    _TestUtil.checkIndex(dir1);\n    r.close();\n    dir1.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"300334dcd665e74e45788a3884e5989d4b4bab15","date":1283942659,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","sourceNew":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory(random);\n    final IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));\n    writer.setInfoStream(infoStream);\n    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(2);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final int NUM_THREAD = 5;\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[NUM_THREAD];\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            int count = 0;\n            final Random r = new Random();\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      sum += new IndexSearcher(r).search(q, 10).totalHits;\n    }\n\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    sum += new IndexSearcher(r).search(q, 10).totalHits;\n\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    _TestUtil.checkIndex(dir1);\n    r.close();\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory(random);\n    final IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));\n    writer.setInfoStream(infoStream);\n    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(2);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final int NUM_THREAD = 5;\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[NUM_THREAD];\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            int count = 0;\n            final Random r = new Random();\n            do {\n              try {\n                for(int i=0;i<10;i++) {\n                  writer.addDocument(createDocument(10*count+i, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int i=0;i<5;i++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      sum += new IndexSearcher(r).search(q, 10).totalHits;\n    }\n\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    sum += new IndexSearcher(r).search(q, 10).totalHits;\n\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    _TestUtil.checkIndex(dir1);\n    r.close();\n    dir1.close();\n  }\n\n","bugFix":["c4ff8864209d2e972cb4393600c26082f9a6533d"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1f653cfcf159baeaafe5d01682a911e95bba4012","date":1284122058,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","sourceNew":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n    writer.setInfoStream(infoStream);\n    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(2);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final int NUM_THREAD = 5;\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[NUM_THREAD];\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            int count = 0;\n            final Random r = new Random();\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      sum += new IndexSearcher(r).search(q, 10).totalHits;\n    }\n\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    sum += new IndexSearcher(r).search(q, 10).totalHits;\n\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    _TestUtil.checkIndex(dir1);\n    r.close();\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory(random);\n    final IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));\n    writer.setInfoStream(infoStream);\n    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(2);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final int NUM_THREAD = 5;\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[NUM_THREAD];\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            int count = 0;\n            final Random r = new Random();\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      sum += new IndexSearcher(r).search(q, 10).totalHits;\n    }\n\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    sum += new IndexSearcher(r).search(q, 10).totalHits;\n\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    _TestUtil.checkIndex(dir1);\n    r.close();\n    dir1.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4e8cc373c801e54cec75daf9f52792cb4b17f536","date":1291116159,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","sourceNew":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    writer.setInfoStream(infoStream);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final int NUM_THREAD = 5;\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[NUM_THREAD];\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            int count = 0;\n            final Random r = new Random();\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      sum += new IndexSearcher(r).search(q, 10).totalHits;\n    }\n\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    sum += new IndexSearcher(r).search(q, 10).totalHits;\n\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    _TestUtil.checkIndex(dir1);\n    r.close();\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n    writer.setInfoStream(infoStream);\n    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(2);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final int NUM_THREAD = 5;\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[NUM_THREAD];\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            int count = 0;\n            final Random r = new Random();\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      sum += new IndexSearcher(r).search(q, 10).totalHits;\n    }\n\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    sum += new IndexSearcher(r).search(q, 10).totalHits;\n\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    _TestUtil.checkIndex(dir1);\n    r.close();\n    dir1.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3bb13258feba31ab676502787ab2e1779f129b7a","date":1291596436,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","sourceNew":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    writer.setInfoStream(infoStream);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final int NUM_THREAD = 5;\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[NUM_THREAD];\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            int count = 0;\n            final Random r = new Random();\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      sum += new IndexSearcher(r).search(q, 10).totalHits;\n    }\n\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    sum += new IndexSearcher(r).search(q, 10).totalHits;\n\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    _TestUtil.checkIndex(dir1);\n    r.close();\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n    writer.setInfoStream(infoStream);\n    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(2);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final int NUM_THREAD = 5;\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[NUM_THREAD];\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            int count = 0;\n            final Random r = new Random();\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      sum += new IndexSearcher(r).search(q, 10).totalHits;\n    }\n\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    sum += new IndexSearcher(r).search(q, 10).totalHits;\n\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    _TestUtil.checkIndex(dir1);\n    r.close();\n    dir1.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ad1eb108f4291bd5b4672bac446eb48bf97d321f","date":1292343856,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","sourceNew":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    writer.setInfoStream(infoStream);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final int NUM_THREAD = 5;\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[NUM_THREAD];\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i] = new Thread() {\n          final Random r = new Random(random.nextLong());\n\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      sum += new IndexSearcher(r).search(q, 10).totalHits;\n    }\n\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    sum += new IndexSearcher(r).search(q, 10).totalHits;\n\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    _TestUtil.checkIndex(dir1);\n    r.close();\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    writer.setInfoStream(infoStream);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final int NUM_THREAD = 5;\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[NUM_THREAD];\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            int count = 0;\n            final Random r = new Random();\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      sum += new IndexSearcher(r).search(q, 10).totalHits;\n    }\n\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    sum += new IndexSearcher(r).search(q, 10).totalHits;\n\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    _TestUtil.checkIndex(dir1);\n    r.close();\n    dir1.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab5cb6a74aefb78aa0569857970b9151dfe2e787","date":1292842407,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","sourceNew":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    writer.setInfoStream(infoStream);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final int NUM_THREAD = 5;\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[NUM_THREAD];\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i] = new Thread() {\n          final Random r = new Random(random.nextLong());\n\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      sum += new IndexSearcher(r).search(q, 10).totalHits;\n    }\n\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    sum += new IndexSearcher(r).search(q, 10).totalHits;\n\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    _TestUtil.checkIndex(dir1);\n    r.close();\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    writer.setInfoStream(infoStream);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final int NUM_THREAD = 5;\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[NUM_THREAD];\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            int count = 0;\n            final Random r = new Random();\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      sum += new IndexSearcher(r).search(q, 10).totalHits;\n    }\n\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    sum += new IndexSearcher(r).search(q, 10).totalHits;\n\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    _TestUtil.checkIndex(dir1);\n    r.close();\n    dir1.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","sourceNew":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    writer.setInfoStream(infoStream);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final int NUM_THREAD = 5;\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[NUM_THREAD];\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i] = new Thread() {\n          final Random r = new Random(random.nextLong());\n\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      sum += new IndexSearcher(r).search(q, 10).totalHits;\n    }\n\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    sum += new IndexSearcher(r).search(q, 10).totalHits;\n\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    _TestUtil.checkIndex(dir1);\n    r.close();\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = new MockRAMDirectory();\n    final IndexWriter writer = new IndexWriter(dir1, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    writer.setInfoStream(infoStream);\n    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(2);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final int NUM_THREAD = 5;\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[NUM_THREAD];\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            int count = 0;\n            final Random r = new Random();\n            do {\n              try {\n                for(int i=0;i<10;i++) {\n                  writer.addDocument(createDocument(10*count+i, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int i=0;i<5;i++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      sum += new IndexSearcher(r).search(q, 10).totalHits;\n    }\n\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    sum += new IndexSearcher(r).search(q, 10).totalHits;\n\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    _TestUtil.checkIndex(dir1);\n    r.close();\n    dir1.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"790e1fde4caa765b3faaad3fbcd25c6973450336","date":1296689245,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","sourceNew":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    writer.setInfoStream(infoStream);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final int NUM_THREAD = 5;\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[NUM_THREAD];\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i] = new Thread() {\n          final Random r = new Random(random.nextLong());\n\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      sum += searcher.search(q, 10).totalHits;\n      searcher.close();\n    }\n\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    sum += searcher.search(q, 10).totalHits;\n    searcher.close();\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    _TestUtil.checkIndex(dir1);\n    r.close();\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    writer.setInfoStream(infoStream);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final int NUM_THREAD = 5;\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[NUM_THREAD];\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i] = new Thread() {\n          final Random r = new Random(random.nextLong());\n\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      sum += new IndexSearcher(r).search(q, 10).totalHits;\n    }\n\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    sum += new IndexSearcher(r).search(q, 10).totalHits;\n\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    _TestUtil.checkIndex(dir1);\n    r.close();\n    dir1.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","sourceNew":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    writer.setInfoStream(infoStream);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final int NUM_THREAD = 5;\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[NUM_THREAD];\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i] = new Thread() {\n          final Random r = new Random(random.nextLong());\n\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      sum += searcher.search(q, 10).totalHits;\n      searcher.close();\n    }\n\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    sum += searcher.search(q, 10).totalHits;\n    searcher.close();\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    _TestUtil.checkIndex(dir1);\n    r.close();\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    writer.setInfoStream(infoStream);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final int NUM_THREAD = 5;\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[NUM_THREAD];\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i] = new Thread() {\n          final Random r = new Random(random.nextLong());\n\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      sum += new IndexSearcher(r).search(q, 10).totalHits;\n    }\n\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    sum += new IndexSearcher(r).search(q, 10).totalHits;\n\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    _TestUtil.checkIndex(dir1);\n    r.close();\n    dir1.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bde51b089eb7f86171eb3406e38a274743f9b7ac","date":1298336439,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","sourceNew":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    writer.setInfoStream(infoStream);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final int NUM_THREAD = 5;\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[NUM_THREAD];\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i] = new Thread() {\n          final Random r = new Random(random.nextLong());\n\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      sum += searcher.search(q, 10).totalHits;\n      searcher.close();\n    }\n\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    sum += searcher.search(q, 10).totalHits;\n    searcher.close();\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    _TestUtil.checkIndex(dir1);\n    r.close();\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    writer.setInfoStream(infoStream);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final int NUM_THREAD = 5;\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[NUM_THREAD];\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i] = new Thread() {\n          final Random r = new Random(random.nextLong());\n\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      sum += new IndexSearcher(r).search(q, 10).totalHits;\n    }\n\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    sum += new IndexSearcher(r).search(q, 10).totalHits;\n\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    _TestUtil.checkIndex(dir1);\n    r.close();\n    dir1.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f2c5f0cb44df114db4228c8f77861714b5cabaea","date":1302542431,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","sourceNew":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    writer.setInfoStream(infoStream);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final int NUM_THREAD = 5;\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[NUM_THREAD];\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i] = new Thread() {\n          final Random r = new Random(random.nextLong());\n\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      sum += searcher.search(q, 10).totalHits;\n      searcher.close();\n    }\n\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    sum += searcher.search(q, 10).totalHits;\n    searcher.close();\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    _TestUtil.checkIndex(dir1);\n    r.close();\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    writer.setInfoStream(infoStream);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final int NUM_THREAD = 5;\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[NUM_THREAD];\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i] = new Thread() {\n          final Random r = new Random(random.nextLong());\n\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      sum += searcher.search(q, 10).totalHits;\n      searcher.close();\n    }\n\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    sum += searcher.search(q, 10).totalHits;\n    searcher.close();\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    _TestUtil.checkIndex(dir1);\n    r.close();\n    dir1.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"962d04139994fce5193143ef35615499a9a96d78","date":1302693744,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","sourceNew":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    writer.setInfoStream(infoStream);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final int NUM_THREAD = 5;\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[NUM_THREAD];\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i] = new Thread() {\n          final Random r = new Random(random.nextLong());\n\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      sum += searcher.search(q, 10).totalHits;\n      searcher.close();\n    }\n\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    sum += searcher.search(q, 10).totalHits;\n    searcher.close();\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    _TestUtil.checkIndex(dir1);\n    r.close();\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    writer.setInfoStream(infoStream);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final int NUM_THREAD = 5;\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[NUM_THREAD];\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i] = new Thread() {\n          final Random r = new Random(random.nextLong());\n\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      sum += searcher.search(q, 10).totalHits;\n      searcher.close();\n    }\n\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    sum += searcher.search(q, 10).totalHits;\n    searcher.close();\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    _TestUtil.checkIndex(dir1);\n    r.close();\n    dir1.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","sourceNew":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    writer.setInfoStream(infoStream);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final int NUM_THREAD = 5;\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[NUM_THREAD];\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i] = new Thread() {\n          final Random r = new Random(random.nextLong());\n\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      sum += searcher.search(q, 10).totalHits;\n      searcher.close();\n    }\n\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    sum += searcher.search(q, 10).totalHits;\n    searcher.close();\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    _TestUtil.checkIndex(dir1);\n    r.close();\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    writer.setInfoStream(infoStream);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final int NUM_THREAD = 5;\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[NUM_THREAD];\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i] = new Thread() {\n          final Random r = new Random(random.nextLong());\n\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      sum += searcher.search(q, 10).totalHits;\n      searcher.close();\n    }\n\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    sum += searcher.search(q, 10).totalHits;\n    searcher.close();\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    _TestUtil.checkIndex(dir1);\n    r.close();\n    dir1.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","sourceNew":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    writer.setInfoStream(infoStream);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final int NUM_THREAD = 5;\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[NUM_THREAD];\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i] = new Thread() {\n          final Random r = new Random(random.nextLong());\n\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      sum += searcher.search(q, 10).totalHits;\n      searcher.close();\n    }\n\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    sum += searcher.search(q, 10).totalHits;\n    searcher.close();\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    _TestUtil.checkIndex(dir1);\n    r.close();\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    writer.setInfoStream(infoStream);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final int NUM_THREAD = 5;\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[NUM_THREAD];\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i] = new Thread() {\n          final Random r = new Random(random.nextLong());\n\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      sum += searcher.search(q, 10).totalHits;\n      searcher.close();\n    }\n\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    sum += searcher.search(q, 10).totalHits;\n    searcher.close();\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    _TestUtil.checkIndex(dir1);\n    r.close();\n    dir1.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ff6fd241dc6610f7f81b62e3ba4cedf105939623","date":1307331653,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","sourceNew":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    writer.setInfoStream(infoStream);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final int NUM_THREAD = 5;\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[NUM_THREAD];\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i] = new Thread() {\n          final Random r = new Random(random.nextLong());\n\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      sum += searcher.search(q, 10).totalHits;\n      searcher.close();\n    }\n\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    sum += searcher.search(q, 10).totalHits;\n    searcher.close();\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    r.close();\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    writer.setInfoStream(infoStream);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final int NUM_THREAD = 5;\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[NUM_THREAD];\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i] = new Thread() {\n          final Random r = new Random(random.nextLong());\n\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      sum += searcher.search(q, 10).totalHits;\n      searcher.close();\n    }\n\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    sum += searcher.search(q, 10).totalHits;\n    searcher.close();\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    _TestUtil.checkIndex(dir1);\n    r.close();\n    dir1.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"79c2cb24929f2649a8875fb629086171f914d5ce","date":1307332717,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","sourceNew":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    writer.setInfoStream(infoStream);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final int NUM_THREAD = 5;\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[NUM_THREAD];\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i] = new Thread() {\n          final Random r = new Random(random.nextLong());\n\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      sum += searcher.search(q, 10).totalHits;\n      searcher.close();\n    }\n\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    sum += searcher.search(q, 10).totalHits;\n    searcher.close();\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    r.close();\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    writer.setInfoStream(infoStream);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final int NUM_THREAD = 5;\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[NUM_THREAD];\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i] = new Thread() {\n          final Random r = new Random(random.nextLong());\n\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      sum += searcher.search(q, 10).totalHits;\n      searcher.close();\n    }\n\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    sum += searcher.search(q, 10).totalHits;\n    searcher.close();\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    _TestUtil.checkIndex(dir1);\n    r.close();\n    dir1.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"77cf4379b2824f6ea34b091c495d6e95c38ff9e2","date":1307610475,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","sourceNew":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    writer.setInfoStream(infoStream);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final int NUM_THREAD = 5;\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[NUM_THREAD];\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i] = new Thread() {\n          final Random r = new Random(random.nextLong());\n\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      sum += searcher.search(q, 10).totalHits;\n      searcher.close();\n    }\n\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    sum += searcher.search(q, 10).totalHits;\n    searcher.close();\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    r.close();\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    writer.setInfoStream(infoStream);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final int NUM_THREAD = 5;\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[NUM_THREAD];\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i] = new Thread() {\n          final Random r = new Random(random.nextLong());\n\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      sum += searcher.search(q, 10).totalHits;\n      searcher.close();\n    }\n\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    sum += searcher.search(q, 10).totalHits;\n    searcher.close();\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    _TestUtil.checkIndex(dir1);\n    r.close();\n    dir1.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a37d7952ff54064a735708748444570f9963683e","date":1309331473,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","sourceNew":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    writer.setInfoStream(infoStream);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[numThreads];\n    for(int i=0;i<numThreads;i++) {\n      threads[i] = new Thread() {\n          final Random r = new Random(random.nextLong());\n\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      sum += searcher.search(q, 10).totalHits;\n      searcher.close();\n    }\n\n    for(int i=0;i<numThreads;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    sum += searcher.search(q, 10).totalHits;\n    searcher.close();\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    r.close();\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    writer.setInfoStream(infoStream);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final int NUM_THREAD = 5;\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[NUM_THREAD];\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i] = new Thread() {\n          final Random r = new Random(random.nextLong());\n\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      sum += searcher.search(q, 10).totalHits;\n      searcher.close();\n    }\n\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    sum += searcher.search(q, 10).totalHits;\n    searcher.close();\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    r.close();\n    dir1.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"817d8435e9135b756f08ce6710ab0baac51bdf88","date":1309986993,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","sourceNew":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    writer.setInfoStream(infoStream);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[numThreads];\n    for(int i=0;i<numThreads;i++) {\n      threads[i] = new Thread() {\n          final Random r = new Random(random.nextLong());\n\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      sum += searcher.search(q, 10).totalHits;\n      searcher.close();\n    }\n\n    for(int i=0;i<numThreads;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    sum += searcher.search(q, 10).totalHits;\n    searcher.close();\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    r.close();\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    writer.setInfoStream(infoStream);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final int NUM_THREAD = 5;\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[NUM_THREAD];\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i] = new Thread() {\n          final Random r = new Random(random.nextLong());\n\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      sum += searcher.search(q, 10).totalHits;\n      searcher.close();\n    }\n\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    sum += searcher.search(q, 10).totalHits;\n    searcher.close();\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    r.close();\n    dir1.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d083e83f225b11e5fdd900e83d26ddb385b6955c","date":1310029438,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","sourceNew":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    writer.setInfoStream(infoStream);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[numThreads];\n    for(int i=0;i<numThreads;i++) {\n      threads[i] = new Thread() {\n          final Random r = new Random(random.nextLong());\n\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      sum += searcher.search(q, 10).totalHits;\n      searcher.close();\n    }\n\n    for(int i=0;i<numThreads;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    sum += searcher.search(q, 10).totalHits;\n    searcher.close();\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    r.close();\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    writer.setInfoStream(infoStream);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final int NUM_THREAD = 5;\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[NUM_THREAD];\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i] = new Thread() {\n          final Random r = new Random(random.nextLong());\n\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      sum += searcher.search(q, 10).totalHits;\n      searcher.close();\n    }\n\n    for(int i=0;i<NUM_THREAD;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    sum += searcher.search(q, 10).totalHits;\n    searcher.close();\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    r.close();\n    dir1.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"00743482822ec0841b0344a37944b666e6a0228d","date":1313588663,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","sourceNew":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    writer.setInfoStream(infoStream);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[numThreads];\n    for(int i=0;i<numThreads;i++) {\n      threads[i] = new Thread() {\n          final Random r = new Random(random.nextLong());\n\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(DocHelper.createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      sum += searcher.search(q, 10).totalHits;\n      searcher.close();\n    }\n\n    for(int i=0;i<numThreads;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    sum += searcher.search(q, 10).totalHits;\n    searcher.close();\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    r.close();\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    writer.setInfoStream(infoStream);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[numThreads];\n    for(int i=0;i<numThreads;i++) {\n      threads[i] = new Thread() {\n          final Random r = new Random(random.nextLong());\n\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      sum += searcher.search(q, 10).totalHits;\n      searcher.close();\n    }\n\n    for(int i=0;i<numThreads;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    sum += searcher.search(q, 10).totalHits;\n    searcher.close();\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    r.close();\n    dir1.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8a8259c922a83abc544609227a60d48e5ee93e7e","date":1317679620,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","sourceNew":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    writer.setInfoStream(infoStream);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[numThreads];\n    for(int i=0;i<numThreads;i++) {\n      threads[i] = new Thread() {\n          final Random r = new Random(random.nextLong());\n\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(DocHelper.createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = IndexReader.openIfChanged(r);\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      sum += searcher.search(q, 10).totalHits;\n      searcher.close();\n    }\n\n    for(int i=0;i<numThreads;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = IndexReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    sum += searcher.search(q, 10).totalHits;\n    searcher.close();\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    r.close();\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    writer.setInfoStream(infoStream);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[numThreads];\n    for(int i=0;i<numThreads;i++) {\n      threads[i] = new Thread() {\n          final Random r = new Random(random.nextLong());\n\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(DocHelper.createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = r.reopen();\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      sum += searcher.search(q, 10).totalHits;\n      searcher.close();\n    }\n\n    for(int i=0;i<numThreads;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = r.reopen();\n    if (r2 != r) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    sum += searcher.search(q, 10).totalHits;\n    searcher.close();\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    r.close();\n    dir1.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"43369d257d14f61a881aa609962ef95e8a334d3a","date":1318786064,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","sourceNew":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    writer.setInfoStream(infoStream);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[numThreads];\n    for(int i=0;i<numThreads;i++) {\n      threads[i] = new Thread() {\n          final Random r = new Random(random.nextLong());\n\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(DocHelper.createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = IndexReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      sum += searcher.search(q, 10).totalHits;\n      searcher.close();\n    }\n\n    for(int i=0;i<numThreads;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = IndexReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    sum += searcher.search(q, 10).totalHits;\n    searcher.close();\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    r.close();\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    writer.setInfoStream(infoStream);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[numThreads];\n    for(int i=0;i<numThreads;i++) {\n      threads[i] = new Thread() {\n          final Random r = new Random(random.nextLong());\n\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(DocHelper.createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = IndexReader.openIfChanged(r);\n      if (r2 != r) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      sum += searcher.search(q, 10).totalHits;\n      searcher.close();\n    }\n\n    for(int i=0;i<numThreads;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = IndexReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    sum += searcher.search(q, 10).totalHits;\n    searcher.close();\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    r.close();\n    dir1.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"06584e6e98d592b34e1329b384182f368d2025e8","date":1320850353,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","sourceNew":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[numThreads];\n    for(int i=0;i<numThreads;i++) {\n      threads[i] = new Thread() {\n          final Random r = new Random(random.nextLong());\n\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(DocHelper.createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = IndexReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      sum += searcher.search(q, 10).totalHits;\n      searcher.close();\n    }\n\n    for(int i=0;i<numThreads;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = IndexReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    sum += searcher.search(q, 10).totalHits;\n    searcher.close();\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    r.close();\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    writer.setInfoStream(infoStream);\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[numThreads];\n    for(int i=0;i<numThreads;i++) {\n      threads[i] = new Thread() {\n          final Random r = new Random(random.nextLong());\n\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(DocHelper.createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = IndexReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      sum += searcher.search(q, 10).totalHits;\n      searcher.close();\n    }\n\n    for(int i=0;i<numThreads;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = IndexReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    sum += searcher.search(q, 10).totalHits;\n    searcher.close();\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    r.close();\n    dir1.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0e7c2454a6a8237bfd0e953f5b940838408c9055","date":1323649300,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","sourceNew":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[numThreads];\n    for(int i=0;i<numThreads;i++) {\n      threads[i] = new Thread() {\n          final Random r = new Random(random.nextLong());\n\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(DocHelper.createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = IndexReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      sum += searcher.search(q, 10).totalHits;\n    }\n\n    for(int i=0;i<numThreads;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = IndexReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    sum += searcher.search(q, 10).totalHits;\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    r.close();\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[numThreads];\n    for(int i=0;i<numThreads;i++) {\n      threads[i] = new Thread() {\n          final Random r = new Random(random.nextLong());\n\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(DocHelper.createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = IndexReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      sum += searcher.search(q, 10).totalHits;\n      searcher.close();\n    }\n\n    for(int i=0;i<numThreads;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = IndexReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    sum += searcher.search(q, 10).totalHits;\n    searcher.close();\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    r.close();\n    dir1.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","date":1323720782,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","sourceNew":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[numThreads];\n    for(int i=0;i<numThreads;i++) {\n      threads[i] = new Thread() {\n          final Random r = new Random(random.nextLong());\n\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(DocHelper.createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = IndexReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      sum += searcher.search(q, 10).totalHits;\n    }\n\n    for(int i=0;i<numThreads;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = IndexReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    sum += searcher.search(q, 10).totalHits;\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    r.close();\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[numThreads];\n    for(int i=0;i<numThreads;i++) {\n      threads[i] = new Thread() {\n          final Random r = new Random(random.nextLong());\n\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(DocHelper.createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = IndexReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      sum += searcher.search(q, 10).totalHits;\n      searcher.close();\n    }\n\n    for(int i=0;i<numThreads;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = IndexReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    sum += searcher.search(q, 10).totalHits;\n    searcher.close();\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    r.close();\n    dir1.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"55c2bb1bcc0edd142e63b9230976dfc3e500dbe8","date":1327857288,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","sourceNew":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    DirectoryReader r = writer.getReader();\n\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[numThreads];\n    for(int i=0;i<numThreads;i++) {\n      threads[i] = new Thread() {\n          final Random r = new Random(random.nextLong());\n\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(DocHelper.createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      sum += searcher.search(q, 10).totalHits;\n    }\n\n    for(int i=0;i<numThreads;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    sum += searcher.search(q, 10).totalHits;\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    r.close();\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[numThreads];\n    for(int i=0;i<numThreads;i++) {\n      threads[i] = new Thread() {\n          final Random r = new Random(random.nextLong());\n\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(DocHelper.createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = IndexReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      sum += searcher.search(q, 10).totalHits;\n    }\n\n    for(int i=0;i<numThreads;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = IndexReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    sum += searcher.search(q, 10).totalHits;\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    r.close();\n    dir1.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5cab9a86bd67202d20b6adc463008c8e982b070a","date":1327966443,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","sourceNew":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    DirectoryReader r = writer.getReader();\n\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[numThreads];\n    for(int i=0;i<numThreads;i++) {\n      threads[i] = new Thread() {\n          final Random r = new Random(random.nextLong());\n\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(DocHelper.createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      sum += searcher.search(q, 10).totalHits;\n    }\n\n    for(int i=0;i<numThreads;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    sum += searcher.search(q, 10).totalHits;\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    r.close();\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    IndexReader r = writer.getReader();\n\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[numThreads];\n    for(int i=0;i<numThreads;i++) {\n      threads[i] = new Thread() {\n          final Random r = new Random(random.nextLong());\n\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(DocHelper.createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      IndexReader r2 = IndexReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      sum += searcher.search(q, 10).totalHits;\n    }\n\n    for(int i=0;i<numThreads;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    IndexReader r2 = IndexReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    sum += searcher.search(q, 10).totalHits;\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    r.close();\n    dir1.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddDelete().mjava","sourceNew":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    DirectoryReader r = writer.getReader();\n\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[numThreads];\n    for(int i=0;i<numThreads;i++) {\n      threads[i] = new Thread() {\n          final Random r = new Random(random.nextLong());\n\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(DocHelper.createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      sum += searcher.search(q, 10).totalHits;\n    }\n\n    for(int i=0;i<numThreads;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    sum += searcher.search(q, 10).totalHits;\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    r.close();\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during add/delete\n  public void testDuringAddDelete() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    DirectoryReader r = writer.getReader();\n\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[numThreads];\n    for(int i=0;i<numThreads;i++) {\n      threads[i] = new Thread() {\n          final Random r = new Random(random.nextLong());\n\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              try {\n                for(int docUpto=0;docUpto<10;docUpto++) {\n                  writer.addDocument(DocHelper.createDocument(10*count+docUpto, \"test\", 4));\n                }\n                count++;\n                final int limit = count*10;\n                for(int delUpto=0;delUpto<5;delUpto++) {\n                  int x = r.nextInt(limit);\n                  writer.deleteDocuments(new Term(\"field3\", \"b\"+x));\n                }\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int sum = 0;\n    while(System.currentTimeMillis() < endTime) {\n      DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      sum += searcher.search(q, 10).totalHits;\n    }\n\n    for(int i=0;i<numThreads;i++) {\n      threads[i].join();\n    }\n    // at least search once\n    DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    sum += searcher.search(q, 10).totalHits;\n    assertTrue(\"no documents found at all\", sum > 0);\n\n    assertEquals(0, excs.size());\n    writer.close();\n\n    r.close();\n    dir1.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"ad1eb108f4291bd5b4672bac446eb48bf97d321f":["4e8cc373c801e54cec75daf9f52792cb4b17f536"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["5cab9a86bd67202d20b6adc463008c8e982b070a"],"93ccd971aca7fb61b7f1b946e44714cfc80bfc7c":["06584e6e98d592b34e1329b384182f368d2025e8","0e7c2454a6a8237bfd0e953f5b940838408c9055"],"55c2bb1bcc0edd142e63b9230976dfc3e500dbe8":["0e7c2454a6a8237bfd0e953f5b940838408c9055"],"00743482822ec0841b0344a37944b666e6a0228d":["a37d7952ff54064a735708748444570f9963683e"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["d572389229127c297dd1fa5ce4758e1cec41e799","ad1eb108f4291bd5b4672bac446eb48bf97d321f"],"8a8259c922a83abc544609227a60d48e5ee93e7e":["00743482822ec0841b0344a37944b666e6a0228d"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["790e1fde4caa765b3faaad3fbcd25c6973450336"],"0e7c2454a6a8237bfd0e953f5b940838408c9055":["06584e6e98d592b34e1329b384182f368d2025e8"],"79c2cb24929f2649a8875fb629086171f914d5ce":["a3776dccca01c11e7046323cfad46a3b4a471233","ff6fd241dc6610f7f81b62e3ba4cedf105939623"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["300334dcd665e74e45788a3884e5989d4b4bab15"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["ab5cb6a74aefb78aa0569857970b9151dfe2e787","790e1fde4caa765b3faaad3fbcd25c6973450336"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b21422ff1d1d56499dec481f193b402e5e8def5b":["d572389229127c297dd1fa5ce4758e1cec41e799"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","790e1fde4caa765b3faaad3fbcd25c6973450336"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"ff6fd241dc6610f7f81b62e3ba4cedf105939623":["f2c5f0cb44df114db4228c8f77861714b5cabaea"],"a37d7952ff54064a735708748444570f9963683e":["ff6fd241dc6610f7f81b62e3ba4cedf105939623"],"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["b21422ff1d1d56499dec481f193b402e5e8def5b"],"7ab99e8c71442b92c320e218141dee04a9b91ce8":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"06584e6e98d592b34e1329b384182f368d2025e8":["43369d257d14f61a881aa609962ef95e8a334d3a"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["29ef99d61cda9641b6250bf9567329a6e65f901d","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"d572389229127c297dd1fa5ce4758e1cec41e799":["7ab99e8c71442b92c320e218141dee04a9b91ce8"],"ab5cb6a74aefb78aa0569857970b9151dfe2e787":["3bb13258feba31ab676502787ab2e1779f129b7a","ad1eb108f4291bd5b4672bac446eb48bf97d321f"],"962d04139994fce5193143ef35615499a9a96d78":["bde51b089eb7f86171eb3406e38a274743f9b7ac","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"43369d257d14f61a881aa609962ef95e8a334d3a":["8a8259c922a83abc544609227a60d48e5ee93e7e"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["ff6fd241dc6610f7f81b62e3ba4cedf105939623","a37d7952ff54064a735708748444570f9963683e"],"5cab9a86bd67202d20b6adc463008c8e982b070a":["0e7c2454a6a8237bfd0e953f5b940838408c9055","55c2bb1bcc0edd142e63b9230976dfc3e500dbe8"],"817d8435e9135b756f08ce6710ab0baac51bdf88":["79c2cb24929f2649a8875fb629086171f914d5ce","a37d7952ff54064a735708748444570f9963683e"],"790e1fde4caa765b3faaad3fbcd25c6973450336":["ad1eb108f4291bd5b4672bac446eb48bf97d321f"],"300334dcd665e74e45788a3884e5989d4b4bab15":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"a3776dccca01c11e7046323cfad46a3b4a471233":["790e1fde4caa765b3faaad3fbcd25c6973450336","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"77cf4379b2824f6ea34b091c495d6e95c38ff9e2":["135621f3a0670a9394eb563224a3b76cc4dddc0f","ff6fd241dc6610f7f81b62e3ba4cedf105939623"],"3bb13258feba31ab676502787ab2e1779f129b7a":["1f653cfcf159baeaafe5d01682a911e95bba4012","4e8cc373c801e54cec75daf9f52792cb4b17f536"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"4e8cc373c801e54cec75daf9f52792cb4b17f536":["1f653cfcf159baeaafe5d01682a911e95bba4012"]},"commit2Childs":{"ad1eb108f4291bd5b4672bac446eb48bf97d321f":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","ab5cb6a74aefb78aa0569857970b9151dfe2e787","790e1fde4caa765b3faaad3fbcd25c6973450336"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"93ccd971aca7fb61b7f1b946e44714cfc80bfc7c":[],"55c2bb1bcc0edd142e63b9230976dfc3e500dbe8":["5cab9a86bd67202d20b6adc463008c8e982b070a"],"00743482822ec0841b0344a37944b666e6a0228d":["8a8259c922a83abc544609227a60d48e5ee93e7e"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["bde51b089eb7f86171eb3406e38a274743f9b7ac"],"8a8259c922a83abc544609227a60d48e5ee93e7e":["43369d257d14f61a881aa609962ef95e8a334d3a"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["ff6fd241dc6610f7f81b62e3ba4cedf105939623","135621f3a0670a9394eb563224a3b76cc4dddc0f","962d04139994fce5193143ef35615499a9a96d78","a3776dccca01c11e7046323cfad46a3b4a471233"],"0e7c2454a6a8237bfd0e953f5b940838408c9055":["93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","55c2bb1bcc0edd142e63b9230976dfc3e500dbe8","5cab9a86bd67202d20b6adc463008c8e982b070a"],"79c2cb24929f2649a8875fb629086171f914d5ce":["817d8435e9135b756f08ce6710ab0baac51bdf88"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["3bb13258feba31ab676502787ab2e1779f129b7a","4e8cc373c801e54cec75daf9f52792cb4b17f536"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["135621f3a0670a9394eb563224a3b76cc4dddc0f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"b21422ff1d1d56499dec481f193b402e5e8def5b":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["962d04139994fce5193143ef35615499a9a96d78"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["7ab99e8c71442b92c320e218141dee04a9b91ce8"],"ff6fd241dc6610f7f81b62e3ba4cedf105939623":["79c2cb24929f2649a8875fb629086171f914d5ce","a37d7952ff54064a735708748444570f9963683e","d083e83f225b11e5fdd900e83d26ddb385b6955c","77cf4379b2824f6ea34b091c495d6e95c38ff9e2"],"a37d7952ff54064a735708748444570f9963683e":["00743482822ec0841b0344a37944b666e6a0228d","d083e83f225b11e5fdd900e83d26ddb385b6955c","817d8435e9135b756f08ce6710ab0baac51bdf88"],"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["300334dcd665e74e45788a3884e5989d4b4bab15"],"7ab99e8c71442b92c320e218141dee04a9b91ce8":["d572389229127c297dd1fa5ce4758e1cec41e799"],"06584e6e98d592b34e1329b384182f368d2025e8":["93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","0e7c2454a6a8237bfd0e953f5b940838408c9055"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["77cf4379b2824f6ea34b091c495d6e95c38ff9e2"],"d572389229127c297dd1fa5ce4758e1cec41e799":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","b21422ff1d1d56499dec481f193b402e5e8def5b"],"ab5cb6a74aefb78aa0569857970b9151dfe2e787":["29ef99d61cda9641b6250bf9567329a6e65f901d"],"962d04139994fce5193143ef35615499a9a96d78":[],"43369d257d14f61a881aa609962ef95e8a334d3a":["06584e6e98d592b34e1329b384182f368d2025e8"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":[],"5cab9a86bd67202d20b6adc463008c8e982b070a":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"817d8435e9135b756f08ce6710ab0baac51bdf88":[],"790e1fde4caa765b3faaad3fbcd25c6973450336":["f2c5f0cb44df114db4228c8f77861714b5cabaea","29ef99d61cda9641b6250bf9567329a6e65f901d","bde51b089eb7f86171eb3406e38a274743f9b7ac","a3776dccca01c11e7046323cfad46a3b4a471233"],"300334dcd665e74e45788a3884e5989d4b4bab15":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"a3776dccca01c11e7046323cfad46a3b4a471233":["79c2cb24929f2649a8875fb629086171f914d5ce"],"77cf4379b2824f6ea34b091c495d6e95c38ff9e2":[],"3bb13258feba31ab676502787ab2e1779f129b7a":["ab5cb6a74aefb78aa0569857970b9151dfe2e787"],"4e8cc373c801e54cec75daf9f52792cb4b17f536":["ad1eb108f4291bd5b4672bac446eb48bf97d321f","3bb13258feba31ab676502787ab2e1779f129b7a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","962d04139994fce5193143ef35615499a9a96d78","d083e83f225b11e5fdd900e83d26ddb385b6955c","817d8435e9135b756f08ce6710ab0baac51bdf88","77cf4379b2824f6ea34b091c495d6e95c38ff9e2","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}