{"path":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher,boolean).mjava","commits":[{"id":"fb17639909a369c1e64866842e5c213440acc17e","date":1423238093,"type":1,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher,boolean).mjava","pathOld":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher, needsScores);\n    return new Weight(TermsIncludingScoreQuery.this) {\n\n      private TermsEnum segmentTermsEnum;\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms != null) {\n          segmentTermsEnum = terms.iterator(segmentTermsEnum);\n          BytesRef spare = new BytesRef();\n          PostingsEnum postingsEnum = null;\n          for (int i = 0; i < TermsIncludingScoreQuery.this.terms.size(); i++) {\n            if (segmentTermsEnum.seekExact(TermsIncludingScoreQuery.this.terms.get(ords[i], spare))) {\n              postingsEnum = segmentTermsEnum.postings(null, postingsEnum, PostingsEnum.FLAG_NONE);\n              if (postingsEnum.advance(doc) == doc) {\n                final float score = TermsIncludingScoreQuery.this.scores[ords[i]];\n                return new ComplexExplanation(true, score, \"Score based on join value \" + segmentTermsEnum.term().utf8ToString());\n              }\n            }\n          }\n        }\n        return new ComplexExplanation(false, 0.0f, \"Not a match\");\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n        \n        // what is the runtime...seems ok?\n        final long cost = context.reader().maxDoc() * terms.size();\n\n        segmentTermsEnum = terms.iterator(segmentTermsEnum);\n        if (multipleValuesPerDocument) {\n          return new MVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        } else {\n          return new SVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        }\n      }\n\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher);\n    return new Weight() {\n\n      private TermsEnum segmentTermsEnum;\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms != null) {\n          segmentTermsEnum = terms.iterator(segmentTermsEnum);\n          BytesRef spare = new BytesRef();\n          PostingsEnum postingsEnum = null;\n          for (int i = 0; i < TermsIncludingScoreQuery.this.terms.size(); i++) {\n            if (segmentTermsEnum.seekExact(TermsIncludingScoreQuery.this.terms.get(ords[i], spare))) {\n              postingsEnum = segmentTermsEnum.postings(null, postingsEnum, PostingsEnum.FLAG_NONE);\n              if (postingsEnum.advance(doc) == doc) {\n                final float score = TermsIncludingScoreQuery.this.scores[ords[i]];\n                return new ComplexExplanation(true, score, \"Score based on join value \" + segmentTermsEnum.term().utf8ToString());\n              }\n            }\n          }\n        }\n        return new ComplexExplanation(false, 0.0f, \"Not a match\");\n      }\n\n      @Override\n      public Query getQuery() {\n        return TermsIncludingScoreQuery.this;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs, boolean needsScores) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n        \n        // what is the runtime...seems ok?\n        final long cost = context.reader().maxDoc() * terms.size();\n\n        segmentTermsEnum = terms.iterator(segmentTermsEnum);\n        if (multipleValuesPerDocument) {\n          return new MVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        } else {\n          return new SVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        }\n      }\n\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"954e59be3da8dc1b046646ad7af4b466852009d3","date":1423482367,"type":5,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher,int).mjava","pathOld":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher,boolean).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, int postingsFlags) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher, postingsFlags);\n    return new Weight(TermsIncludingScoreQuery.this) {\n\n      private TermsEnum segmentTermsEnum;\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms != null) {\n          segmentTermsEnum = terms.iterator(segmentTermsEnum);\n          BytesRef spare = new BytesRef();\n          PostingsEnum postingsEnum = null;\n          for (int i = 0; i < TermsIncludingScoreQuery.this.terms.size(); i++) {\n            if (segmentTermsEnum.seekExact(TermsIncludingScoreQuery.this.terms.get(ords[i], spare))) {\n              postingsEnum = segmentTermsEnum.postings(null, postingsEnum, PostingsEnum.FLAG_NONE);\n              if (postingsEnum.advance(doc) == doc) {\n                final float score = TermsIncludingScoreQuery.this.scores[ords[i]];\n                return new ComplexExplanation(true, score, \"Score based on join value \" + segmentTermsEnum.term().utf8ToString());\n              }\n            }\n          }\n        }\n        return new ComplexExplanation(false, 0.0f, \"Not a match\");\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n        \n        // what is the runtime...seems ok?\n        final long cost = context.reader().maxDoc() * terms.size();\n\n        segmentTermsEnum = terms.iterator(segmentTermsEnum);\n        if (multipleValuesPerDocument) {\n          return new MVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        } else {\n          return new SVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        }\n      }\n\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher, needsScores);\n    return new Weight(TermsIncludingScoreQuery.this) {\n\n      private TermsEnum segmentTermsEnum;\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms != null) {\n          segmentTermsEnum = terms.iterator(segmentTermsEnum);\n          BytesRef spare = new BytesRef();\n          PostingsEnum postingsEnum = null;\n          for (int i = 0; i < TermsIncludingScoreQuery.this.terms.size(); i++) {\n            if (segmentTermsEnum.seekExact(TermsIncludingScoreQuery.this.terms.get(ords[i], spare))) {\n              postingsEnum = segmentTermsEnum.postings(null, postingsEnum, PostingsEnum.FLAG_NONE);\n              if (postingsEnum.advance(doc) == doc) {\n                final float score = TermsIncludingScoreQuery.this.scores[ords[i]];\n                return new ComplexExplanation(true, score, \"Score based on join value \" + segmentTermsEnum.term().utf8ToString());\n              }\n            }\n          }\n        }\n        return new ComplexExplanation(false, 0.0f, \"Not a match\");\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n        \n        // what is the runtime...seems ok?\n        final long cost = context.reader().maxDoc() * terms.size();\n\n        segmentTermsEnum = terms.iterator(segmentTermsEnum);\n        if (multipleValuesPerDocument) {\n          return new MVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        } else {\n          return new SVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        }\n      }\n\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6a47d642ab24da1a811adce4bda9cc52c520ca13","date":1423483323,"type":1,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher,boolean).mjava","pathOld":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher,int).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher, needsScores);\n    return new Weight(TermsIncludingScoreQuery.this) {\n\n      private TermsEnum segmentTermsEnum;\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms != null) {\n          segmentTermsEnum = terms.iterator(segmentTermsEnum);\n          BytesRef spare = new BytesRef();\n          PostingsEnum postingsEnum = null;\n          for (int i = 0; i < TermsIncludingScoreQuery.this.terms.size(); i++) {\n            if (segmentTermsEnum.seekExact(TermsIncludingScoreQuery.this.terms.get(ords[i], spare))) {\n              postingsEnum = segmentTermsEnum.postings(null, postingsEnum, PostingsEnum.FLAG_NONE);\n              if (postingsEnum.advance(doc) == doc) {\n                final float score = TermsIncludingScoreQuery.this.scores[ords[i]];\n                return new ComplexExplanation(true, score, \"Score based on join value \" + segmentTermsEnum.term().utf8ToString());\n              }\n            }\n          }\n        }\n        return new ComplexExplanation(false, 0.0f, \"Not a match\");\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n        \n        // what is the runtime...seems ok?\n        final long cost = context.reader().maxDoc() * terms.size();\n\n        segmentTermsEnum = terms.iterator(segmentTermsEnum);\n        if (multipleValuesPerDocument) {\n          return new MVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        } else {\n          return new SVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        }\n      }\n\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, int postingsFlags) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher, postingsFlags);\n    return new Weight(TermsIncludingScoreQuery.this) {\n\n      private TermsEnum segmentTermsEnum;\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms != null) {\n          segmentTermsEnum = terms.iterator(segmentTermsEnum);\n          BytesRef spare = new BytesRef();\n          PostingsEnum postingsEnum = null;\n          for (int i = 0; i < TermsIncludingScoreQuery.this.terms.size(); i++) {\n            if (segmentTermsEnum.seekExact(TermsIncludingScoreQuery.this.terms.get(ords[i], spare))) {\n              postingsEnum = segmentTermsEnum.postings(null, postingsEnum, PostingsEnum.FLAG_NONE);\n              if (postingsEnum.advance(doc) == doc) {\n                final float score = TermsIncludingScoreQuery.this.scores[ords[i]];\n                return new ComplexExplanation(true, score, \"Score based on join value \" + segmentTermsEnum.term().utf8ToString());\n              }\n            }\n          }\n        }\n        return new ComplexExplanation(false, 0.0f, \"Not a match\");\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n        \n        // what is the runtime...seems ok?\n        final long cost = context.reader().maxDoc() * terms.size();\n\n        segmentTermsEnum = terms.iterator(segmentTermsEnum);\n        if (multipleValuesPerDocument) {\n          return new MVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        } else {\n          return new SVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        }\n      }\n\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e73063b92d958076ef4ae8beb5f493e8ccdcecb4","date":1424177215,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher,boolean).mjava","pathOld":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher,boolean).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher, needsScores);\n    return new Weight(TermsIncludingScoreQuery.this) {\n\n      private TermsEnum segmentTermsEnum;\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms != null) {\n          segmentTermsEnum = terms.iterator(segmentTermsEnum);\n          BytesRef spare = new BytesRef();\n          PostingsEnum postingsEnum = null;\n          for (int i = 0; i < TermsIncludingScoreQuery.this.terms.size(); i++) {\n            if (segmentTermsEnum.seekExact(TermsIncludingScoreQuery.this.terms.get(ords[i], spare))) {\n              postingsEnum = segmentTermsEnum.postings(null, postingsEnum, PostingsEnum.NONE);\n              if (postingsEnum.advance(doc) == doc) {\n                final float score = TermsIncludingScoreQuery.this.scores[ords[i]];\n                return new ComplexExplanation(true, score, \"Score based on join value \" + segmentTermsEnum.term().utf8ToString());\n              }\n            }\n          }\n        }\n        return new ComplexExplanation(false, 0.0f, \"Not a match\");\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n        \n        // what is the runtime...seems ok?\n        final long cost = context.reader().maxDoc() * terms.size();\n\n        segmentTermsEnum = terms.iterator(segmentTermsEnum);\n        if (multipleValuesPerDocument) {\n          return new MVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        } else {\n          return new SVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        }\n      }\n\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher, needsScores);\n    return new Weight(TermsIncludingScoreQuery.this) {\n\n      private TermsEnum segmentTermsEnum;\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms != null) {\n          segmentTermsEnum = terms.iterator(segmentTermsEnum);\n          BytesRef spare = new BytesRef();\n          PostingsEnum postingsEnum = null;\n          for (int i = 0; i < TermsIncludingScoreQuery.this.terms.size(); i++) {\n            if (segmentTermsEnum.seekExact(TermsIncludingScoreQuery.this.terms.get(ords[i], spare))) {\n              postingsEnum = segmentTermsEnum.postings(null, postingsEnum, PostingsEnum.FLAG_NONE);\n              if (postingsEnum.advance(doc) == doc) {\n                final float score = TermsIncludingScoreQuery.this.scores[ords[i]];\n                return new ComplexExplanation(true, score, \"Score based on join value \" + segmentTermsEnum.term().utf8ToString());\n              }\n            }\n          }\n        }\n        return new ComplexExplanation(false, 0.0f, \"Not a match\");\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n        \n        // what is the runtime...seems ok?\n        final long cost = context.reader().maxDoc() * terms.size();\n\n        segmentTermsEnum = terms.iterator(segmentTermsEnum);\n        if (multipleValuesPerDocument) {\n          return new MVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        } else {\n          return new SVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        }\n      }\n\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82","date":1428522487,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher,boolean).mjava","pathOld":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher,boolean).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher, needsScores);\n    return new Weight(TermsIncludingScoreQuery.this) {\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms != null) {\n          TermsEnum segmentTermsEnum = terms.iterator();\n          BytesRef spare = new BytesRef();\n          PostingsEnum postingsEnum = null;\n          for (int i = 0; i < TermsIncludingScoreQuery.this.terms.size(); i++) {\n            if (segmentTermsEnum.seekExact(TermsIncludingScoreQuery.this.terms.get(ords[i], spare))) {\n              postingsEnum = segmentTermsEnum.postings(null, postingsEnum, PostingsEnum.NONE);\n              if (postingsEnum.advance(doc) == doc) {\n                final float score = TermsIncludingScoreQuery.this.scores[ords[i]];\n                return new ComplexExplanation(true, score, \"Score based on join value \" + segmentTermsEnum.term().utf8ToString());\n              }\n            }\n          }\n        }\n        return new ComplexExplanation(false, 0.0f, \"Not a match\");\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n        \n        // what is the runtime...seems ok?\n        final long cost = context.reader().maxDoc() * terms.size();\n\n        TermsEnum segmentTermsEnum = terms.iterator();\n        if (multipleValuesPerDocument) {\n          return new MVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        } else {\n          return new SVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        }\n      }\n\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher, needsScores);\n    return new Weight(TermsIncludingScoreQuery.this) {\n\n      private TermsEnum segmentTermsEnum;\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms != null) {\n          segmentTermsEnum = terms.iterator(segmentTermsEnum);\n          BytesRef spare = new BytesRef();\n          PostingsEnum postingsEnum = null;\n          for (int i = 0; i < TermsIncludingScoreQuery.this.terms.size(); i++) {\n            if (segmentTermsEnum.seekExact(TermsIncludingScoreQuery.this.terms.get(ords[i], spare))) {\n              postingsEnum = segmentTermsEnum.postings(null, postingsEnum, PostingsEnum.NONE);\n              if (postingsEnum.advance(doc) == doc) {\n                final float score = TermsIncludingScoreQuery.this.scores[ords[i]];\n                return new ComplexExplanation(true, score, \"Score based on join value \" + segmentTermsEnum.term().utf8ToString());\n              }\n            }\n          }\n        }\n        return new ComplexExplanation(false, 0.0f, \"Not a match\");\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n        \n        // what is the runtime...seems ok?\n        final long cost = context.reader().maxDoc() * terms.size();\n\n        segmentTermsEnum = terms.iterator(segmentTermsEnum);\n        if (multipleValuesPerDocument) {\n          return new MVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        } else {\n          return new SVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        }\n      }\n\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"05c52ac194342b760b830342ee8423fcf00e54d0","date":1429197275,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher,boolean).mjava","pathOld":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher,boolean).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher, needsScores);\n    return new Weight(TermsIncludingScoreQuery.this) {\n\n      @Override\n      public void extractTerms(Set<Term> terms) {}\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms != null) {\n          TermsEnum segmentTermsEnum = terms.iterator();\n          BytesRef spare = new BytesRef();\n          PostingsEnum postingsEnum = null;\n          for (int i = 0; i < TermsIncludingScoreQuery.this.terms.size(); i++) {\n            if (segmentTermsEnum.seekExact(TermsIncludingScoreQuery.this.terms.get(ords[i], spare))) {\n              postingsEnum = segmentTermsEnum.postings(null, postingsEnum, PostingsEnum.NONE);\n              if (postingsEnum.advance(doc) == doc) {\n                final float score = TermsIncludingScoreQuery.this.scores[ords[i]];\n                return new ComplexExplanation(true, score, \"Score based on join value \" + segmentTermsEnum.term().utf8ToString());\n              }\n            }\n          }\n        }\n        return new ComplexExplanation(false, 0.0f, \"Not a match\");\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n        \n        // what is the runtime...seems ok?\n        final long cost = context.reader().maxDoc() * terms.size();\n\n        TermsEnum segmentTermsEnum = terms.iterator();\n        if (multipleValuesPerDocument) {\n          return new MVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        } else {\n          return new SVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        }\n      }\n\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher, needsScores);\n    return new Weight(TermsIncludingScoreQuery.this) {\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms != null) {\n          TermsEnum segmentTermsEnum = terms.iterator();\n          BytesRef spare = new BytesRef();\n          PostingsEnum postingsEnum = null;\n          for (int i = 0; i < TermsIncludingScoreQuery.this.terms.size(); i++) {\n            if (segmentTermsEnum.seekExact(TermsIncludingScoreQuery.this.terms.get(ords[i], spare))) {\n              postingsEnum = segmentTermsEnum.postings(null, postingsEnum, PostingsEnum.NONE);\n              if (postingsEnum.advance(doc) == doc) {\n                final float score = TermsIncludingScoreQuery.this.scores[ords[i]];\n                return new ComplexExplanation(true, score, \"Score based on join value \" + segmentTermsEnum.term().utf8ToString());\n              }\n            }\n          }\n        }\n        return new ComplexExplanation(false, 0.0f, \"Not a match\");\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n        \n        // what is the runtime...seems ok?\n        final long cost = context.reader().maxDoc() * terms.size();\n\n        TermsEnum segmentTermsEnum = terms.iterator();\n        if (multipleValuesPerDocument) {\n          return new MVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        } else {\n          return new SVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        }\n      }\n\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ff3285c7b2387faedef0ffb24db20c4cbbd9fd91","date":1429620941,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher,boolean).mjava","pathOld":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher,boolean).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher, needsScores);\n    return new Weight(TermsIncludingScoreQuery.this) {\n\n      @Override\n      public void extractTerms(Set<Term> terms) {}\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms != null) {\n          TermsEnum segmentTermsEnum = terms.iterator();\n          BytesRef spare = new BytesRef();\n          PostingsEnum postingsEnum = null;\n          for (int i = 0; i < TermsIncludingScoreQuery.this.terms.size(); i++) {\n            if (segmentTermsEnum.seekExact(TermsIncludingScoreQuery.this.terms.get(ords[i], spare))) {\n              postingsEnum = segmentTermsEnum.postings(null, postingsEnum, PostingsEnum.NONE);\n              if (postingsEnum.advance(doc) == doc) {\n                final float score = TermsIncludingScoreQuery.this.scores[ords[i]];\n                return Explanation.match(score, \"Score based on join value \" + segmentTermsEnum.term().utf8ToString());\n              }\n            }\n          }\n        }\n        return Explanation.noMatch(\"Not a match\");\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n        \n        // what is the runtime...seems ok?\n        final long cost = context.reader().maxDoc() * terms.size();\n\n        TermsEnum segmentTermsEnum = terms.iterator();\n        if (multipleValuesPerDocument) {\n          return new MVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        } else {\n          return new SVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        }\n      }\n\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher, needsScores);\n    return new Weight(TermsIncludingScoreQuery.this) {\n\n      @Override\n      public void extractTerms(Set<Term> terms) {}\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms != null) {\n          TermsEnum segmentTermsEnum = terms.iterator();\n          BytesRef spare = new BytesRef();\n          PostingsEnum postingsEnum = null;\n          for (int i = 0; i < TermsIncludingScoreQuery.this.terms.size(); i++) {\n            if (segmentTermsEnum.seekExact(TermsIncludingScoreQuery.this.terms.get(ords[i], spare))) {\n              postingsEnum = segmentTermsEnum.postings(null, postingsEnum, PostingsEnum.NONE);\n              if (postingsEnum.advance(doc) == doc) {\n                final float score = TermsIncludingScoreQuery.this.scores[ords[i]];\n                return new ComplexExplanation(true, score, \"Score based on join value \" + segmentTermsEnum.term().utf8ToString());\n              }\n            }\n          }\n        }\n        return new ComplexExplanation(false, 0.0f, \"Not a match\");\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n        \n        // what is the runtime...seems ok?\n        final long cost = context.reader().maxDoc() * terms.size();\n\n        TermsEnum segmentTermsEnum = terms.iterator();\n        if (multipleValuesPerDocument) {\n          return new MVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        } else {\n          return new SVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        }\n      }\n\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0f4464508ee83288c8c4585b533f9faaa93aa314","date":1435240759,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher,boolean).mjava","pathOld":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher,boolean).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher, needsScores);\n    return new Weight(TermsIncludingScoreQuery.this) {\n\n      @Override\n      public void extractTerms(Set<Term> terms) {}\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms != null) {\n          TermsEnum segmentTermsEnum = terms.iterator();\n          BytesRef spare = new BytesRef();\n          PostingsEnum postingsEnum = null;\n          for (int i = 0; i < TermsIncludingScoreQuery.this.terms.size(); i++) {\n            if (segmentTermsEnum.seekExact(TermsIncludingScoreQuery.this.terms.get(ords[i], spare))) {\n              postingsEnum = segmentTermsEnum.postings(postingsEnum, PostingsEnum.NONE);\n              if (postingsEnum.advance(doc) == doc) {\n                final float score = TermsIncludingScoreQuery.this.scores[ords[i]];\n                return Explanation.match(score, \"Score based on join value \" + segmentTermsEnum.term().utf8ToString());\n              }\n            }\n          }\n        }\n        return Explanation.noMatch(\"Not a match\");\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n        \n        // what is the runtime...seems ok?\n        final long cost = context.reader().maxDoc() * terms.size();\n\n        TermsEnum segmentTermsEnum = terms.iterator();\n        if (multipleValuesPerDocument) {\n          return new MVInOrderScorer(this, segmentTermsEnum, context.reader().maxDoc(), cost);\n        } else {\n          return new SVInOrderScorer(this, segmentTermsEnum, context.reader().maxDoc(), cost);\n        }\n      }\n\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher, needsScores);\n    return new Weight(TermsIncludingScoreQuery.this) {\n\n      @Override\n      public void extractTerms(Set<Term> terms) {}\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms != null) {\n          TermsEnum segmentTermsEnum = terms.iterator();\n          BytesRef spare = new BytesRef();\n          PostingsEnum postingsEnum = null;\n          for (int i = 0; i < TermsIncludingScoreQuery.this.terms.size(); i++) {\n            if (segmentTermsEnum.seekExact(TermsIncludingScoreQuery.this.terms.get(ords[i], spare))) {\n              postingsEnum = segmentTermsEnum.postings(null, postingsEnum, PostingsEnum.NONE);\n              if (postingsEnum.advance(doc) == doc) {\n                final float score = TermsIncludingScoreQuery.this.scores[ords[i]];\n                return Explanation.match(score, \"Score based on join value \" + segmentTermsEnum.term().utf8ToString());\n              }\n            }\n          }\n        }\n        return Explanation.noMatch(\"Not a match\");\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n        \n        // what is the runtime...seems ok?\n        final long cost = context.reader().maxDoc() * terms.size();\n\n        TermsEnum segmentTermsEnum = terms.iterator();\n        if (multipleValuesPerDocument) {\n          return new MVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        } else {\n          return new SVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        }\n      }\n\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2dfdf766e55e943d942055d7de53c7ad6bc45283","date":1441632886,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher,boolean).mjava","pathOld":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher,boolean).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher, needsScores);\n    return new Weight(TermsIncludingScoreQuery.this) {\n\n      @Override\n      public void extractTerms(Set<Term> terms) {}\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms != null) {\n          TermsEnum segmentTermsEnum = terms.iterator();\n          BytesRef spare = new BytesRef();\n          PostingsEnum postingsEnum = null;\n          for (int i = 0; i < TermsIncludingScoreQuery.this.terms.size(); i++) {\n            if (segmentTermsEnum.seekExact(TermsIncludingScoreQuery.this.terms.get(ords[i], spare))) {\n              postingsEnum = segmentTermsEnum.postings(postingsEnum, PostingsEnum.NONE);\n              if (postingsEnum.advance(doc) == doc) {\n                final float score = TermsIncludingScoreQuery.this.scores[ords[i]];\n                return Explanation.match(score, \"Score based on join value \" + segmentTermsEnum.term().utf8ToString());\n              }\n            }\n          }\n        }\n        return Explanation.noMatch(\"Not a match\");\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization();\n      }\n\n      @Override\n      public void normalize(float norm, float boost) {\n        originalWeight.normalize(norm, boost);\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n        \n        // what is the runtime...seems ok?\n        final long cost = context.reader().maxDoc() * terms.size();\n\n        TermsEnum segmentTermsEnum = terms.iterator();\n        if (multipleValuesPerDocument) {\n          return new MVInOrderScorer(this, segmentTermsEnum, context.reader().maxDoc(), cost);\n        } else {\n          return new SVInOrderScorer(this, segmentTermsEnum, context.reader().maxDoc(), cost);\n        }\n      }\n\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher, needsScores);\n    return new Weight(TermsIncludingScoreQuery.this) {\n\n      @Override\n      public void extractTerms(Set<Term> terms) {}\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms != null) {\n          TermsEnum segmentTermsEnum = terms.iterator();\n          BytesRef spare = new BytesRef();\n          PostingsEnum postingsEnum = null;\n          for (int i = 0; i < TermsIncludingScoreQuery.this.terms.size(); i++) {\n            if (segmentTermsEnum.seekExact(TermsIncludingScoreQuery.this.terms.get(ords[i], spare))) {\n              postingsEnum = segmentTermsEnum.postings(postingsEnum, PostingsEnum.NONE);\n              if (postingsEnum.advance(doc) == doc) {\n                final float score = TermsIncludingScoreQuery.this.scores[ords[i]];\n                return Explanation.match(score, \"Score based on join value \" + segmentTermsEnum.term().utf8ToString());\n              }\n            }\n          }\n        }\n        return Explanation.noMatch(\"Not a match\");\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n        \n        // what is the runtime...seems ok?\n        final long cost = context.reader().maxDoc() * terms.size();\n\n        TermsEnum segmentTermsEnum = terms.iterator();\n        if (multipleValuesPerDocument) {\n          return new MVInOrderScorer(this, segmentTermsEnum, context.reader().maxDoc(), cost);\n        } else {\n          return new SVInOrderScorer(this, segmentTermsEnum, context.reader().maxDoc(), cost);\n        }\n      }\n\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"02e175abd2c4c1611c5a9647486ae8ba249a94c1","date":1468327116,"type":5,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher,boolean,float).mjava","pathOld":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher,boolean).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, boolean needsScores, float boost) throws IOException {\n    return new Weight(TermsIncludingScoreQuery.this) {\n\n      @Override\n      public void extractTerms(Set<Term> terms) {}\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms != null) {\n          TermsEnum segmentTermsEnum = terms.iterator();\n          BytesRef spare = new BytesRef();\n          PostingsEnum postingsEnum = null;\n          for (int i = 0; i < TermsIncludingScoreQuery.this.terms.size(); i++) {\n            if (segmentTermsEnum.seekExact(TermsIncludingScoreQuery.this.terms.get(ords[i], spare))) {\n              postingsEnum = segmentTermsEnum.postings(postingsEnum, PostingsEnum.NONE);\n              if (postingsEnum.advance(doc) == doc) {\n                final float score = TermsIncludingScoreQuery.this.scores[ords[i]];\n                return Explanation.match(score, \"Score based on join value \" + segmentTermsEnum.term().utf8ToString());\n              }\n            }\n          }\n        }\n        return Explanation.noMatch(\"Not a match\");\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n        \n        // what is the runtime...seems ok?\n        final long cost = context.reader().maxDoc() * terms.size();\n\n        TermsEnum segmentTermsEnum = terms.iterator();\n        if (multipleValuesPerDocument) {\n          return new MVInOrderScorer(this, segmentTermsEnum, context.reader().maxDoc(), cost);\n        } else {\n          return new SVInOrderScorer(this, segmentTermsEnum, context.reader().maxDoc(), cost);\n        }\n      }\n\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher, needsScores);\n    return new Weight(TermsIncludingScoreQuery.this) {\n\n      @Override\n      public void extractTerms(Set<Term> terms) {}\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms != null) {\n          TermsEnum segmentTermsEnum = terms.iterator();\n          BytesRef spare = new BytesRef();\n          PostingsEnum postingsEnum = null;\n          for (int i = 0; i < TermsIncludingScoreQuery.this.terms.size(); i++) {\n            if (segmentTermsEnum.seekExact(TermsIncludingScoreQuery.this.terms.get(ords[i], spare))) {\n              postingsEnum = segmentTermsEnum.postings(postingsEnum, PostingsEnum.NONE);\n              if (postingsEnum.advance(doc) == doc) {\n                final float score = TermsIncludingScoreQuery.this.scores[ords[i]];\n                return Explanation.match(score, \"Score based on join value \" + segmentTermsEnum.term().utf8ToString());\n              }\n            }\n          }\n        }\n        return Explanation.noMatch(\"Not a match\");\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization();\n      }\n\n      @Override\n      public void normalize(float norm, float boost) {\n        originalWeight.normalize(norm, boost);\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n        \n        // what is the runtime...seems ok?\n        final long cost = context.reader().maxDoc() * terms.size();\n\n        TermsEnum segmentTermsEnum = terms.iterator();\n        if (multipleValuesPerDocument) {\n          return new MVInOrderScorer(this, segmentTermsEnum, context.reader().maxDoc(), cost);\n        } else {\n          return new SVInOrderScorer(this, segmentTermsEnum, context.reader().maxDoc(), cost);\n        }\n      }\n\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":4,"author":"Kevin Risden","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher,boolean).mjava","sourceNew":null,"sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher, needsScores);\n    return new Weight(TermsIncludingScoreQuery.this) {\n\n      @Override\n      public void extractTerms(Set<Term> terms) {}\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms != null) {\n          TermsEnum segmentTermsEnum = terms.iterator();\n          BytesRef spare = new BytesRef();\n          PostingsEnum postingsEnum = null;\n          for (int i = 0; i < TermsIncludingScoreQuery.this.terms.size(); i++) {\n            if (segmentTermsEnum.seekExact(TermsIncludingScoreQuery.this.terms.get(ords[i], spare))) {\n              postingsEnum = segmentTermsEnum.postings(postingsEnum, PostingsEnum.NONE);\n              if (postingsEnum.advance(doc) == doc) {\n                final float score = TermsIncludingScoreQuery.this.scores[ords[i]];\n                return Explanation.match(score, \"Score based on join value \" + segmentTermsEnum.term().utf8ToString());\n              }\n            }\n          }\n        }\n        return Explanation.noMatch(\"Not a match\");\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization();\n      }\n\n      @Override\n      public void normalize(float norm, float boost) {\n        originalWeight.normalize(norm, boost);\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n        \n        // what is the runtime...seems ok?\n        final long cost = context.reader().maxDoc() * terms.size();\n\n        TermsEnum segmentTermsEnum = terms.iterator();\n        if (multipleValuesPerDocument) {\n          return new MVInOrderScorer(this, segmentTermsEnum, context.reader().maxDoc(), cost);\n        } else {\n          return new SVInOrderScorer(this, segmentTermsEnum, context.reader().maxDoc(), cost);\n        }\n      }\n\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82":["e73063b92d958076ef4ae8beb5f493e8ccdcecb4"],"6a47d642ab24da1a811adce4bda9cc52c520ca13":["954e59be3da8dc1b046646ad7af4b466852009d3"],"fb17639909a369c1e64866842e5c213440acc17e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"2dfdf766e55e943d942055d7de53c7ad6bc45283":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"05c52ac194342b760b830342ee8423fcf00e54d0":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82"],"954e59be3da8dc1b046646ad7af4b466852009d3":["fb17639909a369c1e64866842e5c213440acc17e"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["2dfdf766e55e943d942055d7de53c7ad6bc45283","02e175abd2c4c1611c5a9647486ae8ba249a94c1"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["ff3285c7b2387faedef0ffb24db20c4cbbd9fd91"],"e73063b92d958076ef4ae8beb5f493e8ccdcecb4":["6a47d642ab24da1a811adce4bda9cc52c520ca13"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"02e175abd2c4c1611c5a9647486ae8ba249a94c1":["2dfdf766e55e943d942055d7de53c7ad6bc45283"],"ff3285c7b2387faedef0ffb24db20c4cbbd9fd91":["05c52ac194342b760b830342ee8423fcf00e54d0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["02e175abd2c4c1611c5a9647486ae8ba249a94c1"]},"commit2Childs":{"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82":["05c52ac194342b760b830342ee8423fcf00e54d0"],"6a47d642ab24da1a811adce4bda9cc52c520ca13":["e73063b92d958076ef4ae8beb5f493e8ccdcecb4"],"fb17639909a369c1e64866842e5c213440acc17e":["954e59be3da8dc1b046646ad7af4b466852009d3"],"2dfdf766e55e943d942055d7de53c7ad6bc45283":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","02e175abd2c4c1611c5a9647486ae8ba249a94c1"],"954e59be3da8dc1b046646ad7af4b466852009d3":["6a47d642ab24da1a811adce4bda9cc52c520ca13"],"05c52ac194342b760b830342ee8423fcf00e54d0":["ff3285c7b2387faedef0ffb24db20c4cbbd9fd91"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"e73063b92d958076ef4ae8beb5f493e8ccdcecb4":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["2dfdf766e55e943d942055d7de53c7ad6bc45283"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["fb17639909a369c1e64866842e5c213440acc17e"],"02e175abd2c4c1611c5a9647486ae8ba249a94c1":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"ff3285c7b2387faedef0ffb24db20c4cbbd9fd91":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}