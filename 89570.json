{"path":"solr/core/src/java/org/apache/solr/cloud/api/collections/SplitShardCmd#cleanupAfterFailure(ZkStateReader,CloudConfig,String,String,List[String],Set[String]).mjava","commits":[{"id":"c526352db87264a72a7a9ad68c1b769b81e54305","date":1598780188,"type":1,"author":"Ilan Ginzburg","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/api/collections/SplitShardCmd#cleanupAfterFailure(ZkStateReader,CloudConfig,String,String,List[String],Set[String]).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/api/collections/SplitShardCmd#cleanupAfterFailure(ZkStateReader,String,String,List[String],Set[String]).mjava","sourceNew":"  private void cleanupAfterFailure(ZkStateReader zkStateReader, CloudConfig cloudConfig, String collectionName, String parentShard,\n                                   List<String> subSlices, Set<String> offlineSlices) {\n    log.info(\"Cleaning up after a failed split of {}/{}\", collectionName, parentShard);\n    // get the latest state\n    try {\n      zkStateReader.forceUpdateCollection(collectionName);\n    } catch (KeeperException | InterruptedException e) {\n      log.warn(\"Cleanup failed after failed split of {}/{} : (force update collection)\", collectionName, parentShard, e);\n      return;\n    }\n    ClusterState clusterState = zkStateReader.getClusterState();\n    DocCollection coll = clusterState.getCollectionOrNull(collectionName);\n\n    if (coll == null) { // may have been deleted\n      return;\n    }\n\n    // If parent is inactive and all sub shards are active, then rolling back\n    // to make the parent active again will cause data loss.\n    if (coll.getSlice(parentShard).getState() == Slice.State.INACTIVE) {\n      boolean allSubSlicesActive = true;\n      for (String sub: subSlices) {\n        if (coll.getSlice(sub).getState() != Slice.State.ACTIVE) {\n          allSubSlicesActive = false;\n          break;\n        }\n      }\n      if (allSubSlicesActive) {\n        return;\n      }\n    }\n\n    // set already created sub shards states to CONSTRUCTION - this prevents them\n    // from entering into RECOVERY or ACTIVE (SOLR-9455)\n    final Map<String, Object> propMap = new HashMap<>();\n    boolean sendUpdateState = false;\n    propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n    propMap.put(ZkStateReader.COLLECTION_PROP, collectionName);\n    for (Slice s : coll.getSlices()) {\n      if (!subSlices.contains(s.getName())) {\n        continue;\n      }\n      propMap.put(s.getName(), Slice.State.CONSTRUCTION.toString());\n      sendUpdateState = true;\n    }\n\n    // if parent is inactive activate it again\n    Slice parentSlice = coll.getSlice(parentShard);\n    if (parentSlice.getState() == Slice.State.INACTIVE) {\n      sendUpdateState = true;\n      propMap.put(parentShard, Slice.State.ACTIVE.toString());\n    }\n    // plus any other previously deactivated slices\n    for (String sliceName : offlineSlices) {\n      propMap.put(sliceName, Slice.State.ACTIVE.toString());\n      sendUpdateState = true;\n    }\n\n    if (sendUpdateState) {\n      try {\n        ZkNodeProps m = new ZkNodeProps(propMap);\n        ocmh.overseer.offerStateUpdate(Utils.toJSON(m));\n      } catch (Exception e) {\n        // don't give up yet - just log the error, we may still be able to clean up\n        log.warn(\"Cleanup failed after failed split of {}/{}: (slice state changes)\", collectionName, parentShard, e);\n      }\n    }\n\n    // delete existing subShards\n    for (String subSlice : subSlices) {\n      Slice s = coll.getSlice(subSlice);\n      if (s == null) {\n        continue;\n      }\n      log.debug(\"- sub-shard: {} exists therefore requesting its deletion\", subSlice);\n      HashMap<String, Object> props = new HashMap<>();\n      props.put(Overseer.QUEUE_OPERATION, \"deleteshard\");\n      props.put(COLLECTION_PROP, collectionName);\n      props.put(SHARD_ID_PROP, subSlice);\n      ZkNodeProps m = new ZkNodeProps(props);\n      try {\n        ocmh.commandMap.get(DELETESHARD).call(clusterState, cloudConfig, m, new NamedList<Object>());\n      } catch (Exception e) {\n        log.warn(\"Cleanup failed after failed split of {}/{} : (deleting existing sub shard{})\", collectionName, parentShard, subSlice, e);\n      }\n    }\n  }\n\n","sourceOld":"  private void cleanupAfterFailure(ZkStateReader zkStateReader, String collectionName, String parentShard,\n                                   List<String> subSlices, Set<String> offlineSlices) {\n    log.info(\"Cleaning up after a failed split of {}/{}\", collectionName, parentShard);\n    // get the latest state\n    try {\n      zkStateReader.forceUpdateCollection(collectionName);\n    } catch (KeeperException | InterruptedException e) {\n      log.warn(\"Cleanup failed after failed split of {}/{} : (force update collection)\", collectionName, parentShard, e);\n      return;\n    }\n    ClusterState clusterState = zkStateReader.getClusterState();\n    DocCollection coll = clusterState.getCollectionOrNull(collectionName);\n\n    if (coll == null) { // may have been deleted\n      return;\n    }\n\n    // If parent is inactive and all sub shards are active, then rolling back\n    // to make the parent active again will cause data loss.\n    if (coll.getSlice(parentShard).getState() == Slice.State.INACTIVE) {\n      boolean allSubSlicesActive = true;\n      for (String sub: subSlices) {\n        if (coll.getSlice(sub).getState() != Slice.State.ACTIVE) {\n          allSubSlicesActive = false;\n          break;\n        }\n      }\n      if (allSubSlicesActive) {\n        return;\n      }\n    }\n\n    // set already created sub shards states to CONSTRUCTION - this prevents them\n    // from entering into RECOVERY or ACTIVE (SOLR-9455)\n    final Map<String, Object> propMap = new HashMap<>();\n    boolean sendUpdateState = false;\n    propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n    propMap.put(ZkStateReader.COLLECTION_PROP, collectionName);\n    for (Slice s : coll.getSlices()) {\n      if (!subSlices.contains(s.getName())) {\n        continue;\n      }\n      propMap.put(s.getName(), Slice.State.CONSTRUCTION.toString());\n      sendUpdateState = true;\n    }\n\n    // if parent is inactive activate it again\n    Slice parentSlice = coll.getSlice(parentShard);\n    if (parentSlice.getState() == Slice.State.INACTIVE) {\n      sendUpdateState = true;\n      propMap.put(parentShard, Slice.State.ACTIVE.toString());\n    }\n    // plus any other previously deactivated slices\n    for (String sliceName : offlineSlices) {\n      propMap.put(sliceName, Slice.State.ACTIVE.toString());\n      sendUpdateState = true;\n    }\n\n    if (sendUpdateState) {\n      try {\n        ZkNodeProps m = new ZkNodeProps(propMap);\n        ocmh.overseer.offerStateUpdate(Utils.toJSON(m));\n      } catch (Exception e) {\n        // don't give up yet - just log the error, we may still be able to clean up\n        log.warn(\"Cleanup failed after failed split of {}/{}: (slice state changes)\", collectionName, parentShard, e);\n      }\n    }\n\n    // delete existing subShards\n    for (String subSlice : subSlices) {\n      Slice s = coll.getSlice(subSlice);\n      if (s == null) {\n        continue;\n      }\n      log.debug(\"- sub-shard: {} exists therefore requesting its deletion\", subSlice);\n      HashMap<String, Object> props = new HashMap<>();\n      props.put(Overseer.QUEUE_OPERATION, \"deleteshard\");\n      props.put(COLLECTION_PROP, collectionName);\n      props.put(SHARD_ID_PROP, subSlice);\n      ZkNodeProps m = new ZkNodeProps(props);\n      try {\n        ocmh.commandMap.get(DELETESHARD).call(clusterState, m, new NamedList<Object>());\n      } catch (Exception e) {\n        log.warn(\"Cleanup failed after failed split of {}/{} : (deleting existing sub shard{})\", collectionName, parentShard, subSlice, e);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e7b17e79a71117668ecbf8d3417c876e41396565","date":1598973672,"type":5,"author":"Ilan Ginzburg","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/api/collections/SplitShardCmd#cleanupAfterFailure(ZkStateReader,String,String,List[String],Set[String]).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/api/collections/SplitShardCmd#cleanupAfterFailure(ZkStateReader,CloudConfig,String,String,List[String],Set[String]).mjava","sourceNew":"  private void cleanupAfterFailure(ZkStateReader zkStateReader, String collectionName, String parentShard,\n                                   List<String> subSlices, Set<String> offlineSlices) {\n    log.info(\"Cleaning up after a failed split of {}/{}\", collectionName, parentShard);\n    // get the latest state\n    try {\n      zkStateReader.forceUpdateCollection(collectionName);\n    } catch (KeeperException | InterruptedException e) {\n      log.warn(\"Cleanup failed after failed split of {}/{} : (force update collection)\", collectionName, parentShard, e);\n      return;\n    }\n    ClusterState clusterState = zkStateReader.getClusterState();\n    DocCollection coll = clusterState.getCollectionOrNull(collectionName);\n\n    if (coll == null) { // may have been deleted\n      return;\n    }\n\n    // If parent is inactive and all sub shards are active, then rolling back\n    // to make the parent active again will cause data loss.\n    if (coll.getSlice(parentShard).getState() == Slice.State.INACTIVE) {\n      boolean allSubSlicesActive = true;\n      for (String sub: subSlices) {\n        if (coll.getSlice(sub).getState() != Slice.State.ACTIVE) {\n          allSubSlicesActive = false;\n          break;\n        }\n      }\n      if (allSubSlicesActive) {\n        return;\n      }\n    }\n\n    // set already created sub shards states to CONSTRUCTION - this prevents them\n    // from entering into RECOVERY or ACTIVE (SOLR-9455)\n    final Map<String, Object> propMap = new HashMap<>();\n    boolean sendUpdateState = false;\n    propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n    propMap.put(ZkStateReader.COLLECTION_PROP, collectionName);\n    for (Slice s : coll.getSlices()) {\n      if (!subSlices.contains(s.getName())) {\n        continue;\n      }\n      propMap.put(s.getName(), Slice.State.CONSTRUCTION.toString());\n      sendUpdateState = true;\n    }\n\n    // if parent is inactive activate it again\n    Slice parentSlice = coll.getSlice(parentShard);\n    if (parentSlice.getState() == Slice.State.INACTIVE) {\n      sendUpdateState = true;\n      propMap.put(parentShard, Slice.State.ACTIVE.toString());\n    }\n    // plus any other previously deactivated slices\n    for (String sliceName : offlineSlices) {\n      propMap.put(sliceName, Slice.State.ACTIVE.toString());\n      sendUpdateState = true;\n    }\n\n    if (sendUpdateState) {\n      try {\n        ZkNodeProps m = new ZkNodeProps(propMap);\n        ocmh.overseer.offerStateUpdate(Utils.toJSON(m));\n      } catch (Exception e) {\n        // don't give up yet - just log the error, we may still be able to clean up\n        log.warn(\"Cleanup failed after failed split of {}/{}: (slice state changes)\", collectionName, parentShard, e);\n      }\n    }\n\n    // delete existing subShards\n    for (String subSlice : subSlices) {\n      Slice s = coll.getSlice(subSlice);\n      if (s == null) {\n        continue;\n      }\n      log.debug(\"- sub-shard: {} exists therefore requesting its deletion\", subSlice);\n      HashMap<String, Object> props = new HashMap<>();\n      props.put(Overseer.QUEUE_OPERATION, \"deleteshard\");\n      props.put(COLLECTION_PROP, collectionName);\n      props.put(SHARD_ID_PROP, subSlice);\n      ZkNodeProps m = new ZkNodeProps(props);\n      try {\n        ocmh.commandMap.get(DELETESHARD).call(clusterState, m, new NamedList<Object>());\n      } catch (Exception e) {\n        log.warn(\"Cleanup failed after failed split of {}/{} : (deleting existing sub shard{})\", collectionName, parentShard, subSlice, e);\n      }\n    }\n  }\n\n","sourceOld":"  private void cleanupAfterFailure(ZkStateReader zkStateReader, CloudConfig cloudConfig, String collectionName, String parentShard,\n                                   List<String> subSlices, Set<String> offlineSlices) {\n    log.info(\"Cleaning up after a failed split of {}/{}\", collectionName, parentShard);\n    // get the latest state\n    try {\n      zkStateReader.forceUpdateCollection(collectionName);\n    } catch (KeeperException | InterruptedException e) {\n      log.warn(\"Cleanup failed after failed split of {}/{} : (force update collection)\", collectionName, parentShard, e);\n      return;\n    }\n    ClusterState clusterState = zkStateReader.getClusterState();\n    DocCollection coll = clusterState.getCollectionOrNull(collectionName);\n\n    if (coll == null) { // may have been deleted\n      return;\n    }\n\n    // If parent is inactive and all sub shards are active, then rolling back\n    // to make the parent active again will cause data loss.\n    if (coll.getSlice(parentShard).getState() == Slice.State.INACTIVE) {\n      boolean allSubSlicesActive = true;\n      for (String sub: subSlices) {\n        if (coll.getSlice(sub).getState() != Slice.State.ACTIVE) {\n          allSubSlicesActive = false;\n          break;\n        }\n      }\n      if (allSubSlicesActive) {\n        return;\n      }\n    }\n\n    // set already created sub shards states to CONSTRUCTION - this prevents them\n    // from entering into RECOVERY or ACTIVE (SOLR-9455)\n    final Map<String, Object> propMap = new HashMap<>();\n    boolean sendUpdateState = false;\n    propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n    propMap.put(ZkStateReader.COLLECTION_PROP, collectionName);\n    for (Slice s : coll.getSlices()) {\n      if (!subSlices.contains(s.getName())) {\n        continue;\n      }\n      propMap.put(s.getName(), Slice.State.CONSTRUCTION.toString());\n      sendUpdateState = true;\n    }\n\n    // if parent is inactive activate it again\n    Slice parentSlice = coll.getSlice(parentShard);\n    if (parentSlice.getState() == Slice.State.INACTIVE) {\n      sendUpdateState = true;\n      propMap.put(parentShard, Slice.State.ACTIVE.toString());\n    }\n    // plus any other previously deactivated slices\n    for (String sliceName : offlineSlices) {\n      propMap.put(sliceName, Slice.State.ACTIVE.toString());\n      sendUpdateState = true;\n    }\n\n    if (sendUpdateState) {\n      try {\n        ZkNodeProps m = new ZkNodeProps(propMap);\n        ocmh.overseer.offerStateUpdate(Utils.toJSON(m));\n      } catch (Exception e) {\n        // don't give up yet - just log the error, we may still be able to clean up\n        log.warn(\"Cleanup failed after failed split of {}/{}: (slice state changes)\", collectionName, parentShard, e);\n      }\n    }\n\n    // delete existing subShards\n    for (String subSlice : subSlices) {\n      Slice s = coll.getSlice(subSlice);\n      if (s == null) {\n        continue;\n      }\n      log.debug(\"- sub-shard: {} exists therefore requesting its deletion\", subSlice);\n      HashMap<String, Object> props = new HashMap<>();\n      props.put(Overseer.QUEUE_OPERATION, \"deleteshard\");\n      props.put(COLLECTION_PROP, collectionName);\n      props.put(SHARD_ID_PROP, subSlice);\n      ZkNodeProps m = new ZkNodeProps(props);\n      try {\n        ocmh.commandMap.get(DELETESHARD).call(clusterState, cloudConfig, m, new NamedList<Object>());\n      } catch (Exception e) {\n        log.warn(\"Cleanup failed after failed split of {}/{} : (deleting existing sub shard{})\", collectionName, parentShard, subSlice, e);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"e7b17e79a71117668ecbf8d3417c876e41396565":["c526352db87264a72a7a9ad68c1b769b81e54305"],"c526352db87264a72a7a9ad68c1b769b81e54305":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["e7b17e79a71117668ecbf8d3417c876e41396565"]},"commit2Childs":{"e7b17e79a71117668ecbf8d3417c876e41396565":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"c526352db87264a72a7a9ad68c1b769b81e54305":["e7b17e79a71117668ecbf8d3417c876e41396565"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c526352db87264a72a7a9ad68c1b769b81e54305"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}