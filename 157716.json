{"path":"lucene/core/src/test/org/apache/lucene/search/TestCachingCollector#testCachedArraysAllocation().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestCachingCollector#testCachedArraysAllocation().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestCachingCollector#testCachedArraysAllocation().mjava","sourceNew":"  public void testCachedArraysAllocation() throws Exception {\n    // tests the cached arrays allocation -- if the 'nextLength' was too high,\n    // caching would terminate even if a smaller length would suffice.\n    \n    // set RAM limit enough for 150 docs + random(10000)\n    int numDocs = random.nextInt(10000) + 150;\n    for (boolean cacheScores : new boolean[] { false, true }) {\n      int bytesPerDoc = cacheScores ? 8 : 4;\n      CachingCollector cc = CachingCollector.create(new NoOpCollector(false),\n          cacheScores, bytesPerDoc * ONE_BYTE * numDocs);\n      cc.setScorer(new MockScorer());\n      for (int i = 0; i < numDocs; i++) cc.collect(i);\n      assertTrue(cc.isCached());\n\n      // The 151's document should terminate caching\n      cc.collect(numDocs);\n      assertFalse(cc.isCached());\n    }\n  }\n\n","sourceOld":"  public void testCachedArraysAllocation() throws Exception {\n    // tests the cached arrays allocation -- if the 'nextLength' was too high,\n    // caching would terminate even if a smaller length would suffice.\n    \n    // set RAM limit enough for 150 docs + random(10000)\n    int numDocs = random.nextInt(10000) + 150;\n    for (boolean cacheScores : new boolean[] { false, true }) {\n      int bytesPerDoc = cacheScores ? 8 : 4;\n      CachingCollector cc = CachingCollector.create(new NoOpCollector(false),\n          cacheScores, bytesPerDoc * ONE_BYTE * numDocs);\n      cc.setScorer(new MockScorer());\n      for (int i = 0; i < numDocs; i++) cc.collect(i);\n      assertTrue(cc.isCached());\n\n      // The 151's document should terminate caching\n      cc.collect(numDocs);\n      assertFalse(cc.isCached());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestCachingCollector#testCachedArraysAllocation().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestCachingCollector#testCachedArraysAllocation().mjava","sourceNew":"  public void testCachedArraysAllocation() throws Exception {\n    // tests the cached arrays allocation -- if the 'nextLength' was too high,\n    // caching would terminate even if a smaller length would suffice.\n    \n    // set RAM limit enough for 150 docs + random(10000)\n    int numDocs = random().nextInt(10000) + 150;\n    for (boolean cacheScores : new boolean[] { false, true }) {\n      int bytesPerDoc = cacheScores ? 8 : 4;\n      CachingCollector cc = CachingCollector.create(new NoOpCollector(false),\n          cacheScores, bytesPerDoc * ONE_BYTE * numDocs);\n      cc.setScorer(new MockScorer());\n      for (int i = 0; i < numDocs; i++) cc.collect(i);\n      assertTrue(cc.isCached());\n\n      // The 151's document should terminate caching\n      cc.collect(numDocs);\n      assertFalse(cc.isCached());\n    }\n  }\n\n","sourceOld":"  public void testCachedArraysAllocation() throws Exception {\n    // tests the cached arrays allocation -- if the 'nextLength' was too high,\n    // caching would terminate even if a smaller length would suffice.\n    \n    // set RAM limit enough for 150 docs + random(10000)\n    int numDocs = random.nextInt(10000) + 150;\n    for (boolean cacheScores : new boolean[] { false, true }) {\n      int bytesPerDoc = cacheScores ? 8 : 4;\n      CachingCollector cc = CachingCollector.create(new NoOpCollector(false),\n          cacheScores, bytesPerDoc * ONE_BYTE * numDocs);\n      cc.setScorer(new MockScorer());\n      for (int i = 0; i < numDocs; i++) cc.collect(i);\n      assertTrue(cc.isCached());\n\n      // The 151's document should terminate caching\n      cc.collect(numDocs);\n      assertFalse(cc.isCached());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"19275ba31e621f6da1b83bf13af75233876fd3d4","date":1374846698,"type":3,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestCachingCollector#testCachedArraysAllocation().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestCachingCollector#testCachedArraysAllocation().mjava","sourceNew":"  public void testCachedArraysAllocation() throws Exception {\n    // tests the cached arrays allocation -- if the 'nextLength' was too high,\n    // caching would terminate even if a smaller length would suffice.\n    \n    // set RAM limit enough for 150 docs + random(10000)\n    int numDocs = random().nextInt(10000) + 150;\n    for (boolean cacheScores : new boolean[] { false, true }) {\n      int bytesPerDoc = cacheScores ? 8 : 4;\n      CachingCollector cc = CachingCollector.create(new NoOpCollector(false),\n          cacheScores, bytesPerDoc * ONE_BYTE * numDocs);\n      cc.setScorer(new MockScorer());\n      for (int i = 0; i < numDocs; i++) cc.collect(i);\n      assertTrue(cc.isCached());\n\n      // The 151's document should terminate caching\n      cc.collect(numDocs);\n      assertFalse(cc.isCached());\n    }\n  }\n\n","sourceOld":"  public void testCachedArraysAllocation() throws Exception {\n    // tests the cached arrays allocation -- if the 'nextLength' was too high,\n    // caching would terminate even if a smaller length would suffice.\n    \n    // set RAM limit enough for 150 docs + random(10000)\n    int numDocs = random().nextInt(10000) + 150;\n    for (boolean cacheScores : new boolean[] { false, true }) {\n      int bytesPerDoc = cacheScores ? 8 : 4;\n      CachingCollector cc = CachingCollector.create(new NoOpCollector(false),\n          cacheScores, bytesPerDoc * ONE_BYTE * numDocs);\n      cc.setScorer(new MockScorer());\n      for (int i = 0; i < numDocs; i++) cc.collect(i);\n      assertTrue(cc.isCached());\n\n      // The 151's document should terminate caching\n      cc.collect(numDocs);\n      assertFalse(cc.isCached());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","date":1376366778,"type":3,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestCachingCollector#testCachedArraysAllocation().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestCachingCollector#testCachedArraysAllocation().mjava","sourceNew":"  public void testCachedArraysAllocation() throws Exception {\n    // tests the cached arrays allocation -- if the 'nextLength' was too high,\n    // caching would terminate even if a smaller length would suffice.\n    \n    // set RAM limit enough for 150 docs + random(10000)\n    int numDocs = random().nextInt(10000) + 150;\n    for (boolean cacheScores : new boolean[] { false, true }) {\n      int bytesPerDoc = cacheScores ? 8 : 4;\n      CachingCollector cc = CachingCollector.create(new NoOpCollector(false),\n          cacheScores, bytesPerDoc * ONE_BYTE * numDocs);\n      cc.setScorer(new MockScorer());\n      for (int i = 0; i < numDocs; i++) cc.collect(i);\n      assertTrue(cc.isCached());\n\n      // The 151's document should terminate caching\n      cc.collect(numDocs);\n      assertFalse(cc.isCached());\n    }\n  }\n\n","sourceOld":"  public void testCachedArraysAllocation() throws Exception {\n    // tests the cached arrays allocation -- if the 'nextLength' was too high,\n    // caching would terminate even if a smaller length would suffice.\n    \n    // set RAM limit enough for 150 docs + random(10000)\n    int numDocs = random().nextInt(10000) + 150;\n    for (boolean cacheScores : new boolean[] { false, true }) {\n      int bytesPerDoc = cacheScores ? 8 : 4;\n      CachingCollector cc = CachingCollector.create(new NoOpCollector(false),\n          cacheScores, bytesPerDoc * ONE_BYTE * numDocs);\n      cc.setScorer(new MockScorer());\n      for (int i = 0; i < numDocs; i++) cc.collect(i);\n      assertTrue(cc.isCached());\n\n      // The 151's document should terminate caching\n      cc.collect(numDocs);\n      assertFalse(cc.isCached());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae73da626f97850c922c42736f808d0378e165f0","date":1396625460,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestCachingCollector#testCachedArraysAllocation().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestCachingCollector#testCachedArraysAllocation().mjava","sourceNew":"  public void testCachedArraysAllocation() throws Exception {\n    // tests the cached arrays allocation -- if the 'nextLength' was too high,\n    // caching would terminate even if a smaller length would suffice.\n    \n    // set RAM limit enough for 150 docs + random(10000)\n    int numDocs = random().nextInt(10000) + 150;\n    for (boolean cacheScores : new boolean[] { false, true }) {\n      int bytesPerDoc = cacheScores ? 8 : 4;\n      CachingCollector cc = CachingCollector.create(new NoOpCollector(false),\n          cacheScores, bytesPerDoc * ONE_BYTE * numDocs);\n      LeafCollector acc = cc.getLeafCollector(null);\n      acc.setScorer(new MockScorer());\n      for (int i = 0; i < numDocs; i++) acc.collect(i);\n      assertTrue(cc.isCached());\n\n      // The 151's document should terminate caching\n      acc.collect(numDocs);\n      assertFalse(cc.isCached());\n    }\n  }\n\n","sourceOld":"  public void testCachedArraysAllocation() throws Exception {\n    // tests the cached arrays allocation -- if the 'nextLength' was too high,\n    // caching would terminate even if a smaller length would suffice.\n    \n    // set RAM limit enough for 150 docs + random(10000)\n    int numDocs = random().nextInt(10000) + 150;\n    for (boolean cacheScores : new boolean[] { false, true }) {\n      int bytesPerDoc = cacheScores ? 8 : 4;\n      CachingCollector cc = CachingCollector.create(new NoOpCollector(false),\n          cacheScores, bytesPerDoc * ONE_BYTE * numDocs);\n      cc.setScorer(new MockScorer());\n      for (int i = 0; i < numDocs; i++) cc.collect(i);\n      assertTrue(cc.isCached());\n\n      // The 151's document should terminate caching\n      cc.collect(numDocs);\n      assertFalse(cc.isCached());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"15e323346eac5e4685c0a9f2df85eb96b4239bbb","date":1396688577,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestCachingCollector#testCachedArraysAllocation().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestCachingCollector#testCachedArraysAllocation().mjava","sourceNew":"  public void testCachedArraysAllocation() throws Exception {\n    // tests the cached arrays allocation -- if the 'nextLength' was too high,\n    // caching would terminate even if a smaller length would suffice.\n    \n    // set RAM limit enough for 150 docs + random(10000)\n    int numDocs = random().nextInt(10000) + 150;\n    for (boolean cacheScores : new boolean[] { false, true }) {\n      int bytesPerDoc = cacheScores ? 8 : 4;\n      CachingCollector cc = CachingCollector.create(new NoOpCollector(false),\n          cacheScores, bytesPerDoc * ONE_BYTE * numDocs);\n      LeafCollector acc = cc.getLeafCollector(null);\n      acc.setScorer(new MockScorer());\n      for (int i = 0; i < numDocs; i++) acc.collect(i);\n      assertTrue(cc.isCached());\n\n      // The 151's document should terminate caching\n      acc.collect(numDocs);\n      assertFalse(cc.isCached());\n    }\n  }\n\n","sourceOld":"  public void testCachedArraysAllocation() throws Exception {\n    // tests the cached arrays allocation -- if the 'nextLength' was too high,\n    // caching would terminate even if a smaller length would suffice.\n    \n    // set RAM limit enough for 150 docs + random(10000)\n    int numDocs = random().nextInt(10000) + 150;\n    for (boolean cacheScores : new boolean[] { false, true }) {\n      int bytesPerDoc = cacheScores ? 8 : 4;\n      CachingCollector cc = CachingCollector.create(new NoOpCollector(false),\n          cacheScores, bytesPerDoc * ONE_BYTE * numDocs);\n      cc.setScorer(new MockScorer());\n      for (int i = 0; i < numDocs; i++) cc.collect(i);\n      assertTrue(cc.isCached());\n\n      // The 151's document should terminate caching\n      cc.collect(numDocs);\n      assertFalse(cc.isCached());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f582f18c13d4852b01d4fe0a0196432c5c6f2b7f","date":1421314520,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestCachingCollector#testCachedArraysAllocation().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestCachingCollector#testCachedArraysAllocation().mjava","sourceNew":"  public void testCachedArraysAllocation() throws Exception {\n    // tests the cached arrays allocation -- if the 'nextLength' was too high,\n    // caching would terminate even if a smaller length would suffice.\n    \n    // set RAM limit enough for 150 docs + random(10000)\n    int numDocs = random().nextInt(10000) + 150;\n    for (boolean cacheScores : new boolean[] { false, true }) {\n      int bytesPerDoc = cacheScores ? 8 : 4;\n      CachingCollector cc = CachingCollector.create(new NoOpCollector(),\n          cacheScores, bytesPerDoc * ONE_BYTE * numDocs);\n      LeafCollector acc = cc.getLeafCollector(null);\n      acc.setScorer(new MockScorer());\n      for (int i = 0; i < numDocs; i++) acc.collect(i);\n      assertTrue(cc.isCached());\n\n      // The 151's document should terminate caching\n      acc.collect(numDocs);\n      assertFalse(cc.isCached());\n    }\n  }\n\n","sourceOld":"  public void testCachedArraysAllocation() throws Exception {\n    // tests the cached arrays allocation -- if the 'nextLength' was too high,\n    // caching would terminate even if a smaller length would suffice.\n    \n    // set RAM limit enough for 150 docs + random(10000)\n    int numDocs = random().nextInt(10000) + 150;\n    for (boolean cacheScores : new boolean[] { false, true }) {\n      int bytesPerDoc = cacheScores ? 8 : 4;\n      CachingCollector cc = CachingCollector.create(new NoOpCollector(false),\n          cacheScores, bytesPerDoc * ONE_BYTE * numDocs);\n      LeafCollector acc = cc.getLeafCollector(null);\n      acc.setScorer(new MockScorer());\n      for (int i = 0; i < numDocs; i++) acc.collect(i);\n      assertTrue(cc.isCached());\n\n      // The 151's document should terminate caching\n      acc.collect(numDocs);\n      assertFalse(cc.isCached());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6dbd758f2776b0129f6b3641b6490ddc68d7b0f3","date":1536316907,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestCachingCollector#testCachedArraysAllocation().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestCachingCollector#testCachedArraysAllocation().mjava","sourceNew":"  public void testCachedArraysAllocation() throws Exception {\n    // tests the cached arrays allocation -- if the 'nextLength' was too high,\n    // caching would terminate even if a smaller length would suffice.\n    \n    // set RAM limit enough for 150 docs + random(10000)\n    int numDocs = random().nextInt(10000) + 150;\n    for (boolean cacheScores : new boolean[] { false, true }) {\n      int bytesPerDoc = cacheScores ? 8 : 4;\n      CachingCollector cc = CachingCollector.create(new NoOpCollector(),\n          cacheScores, bytesPerDoc * ONE_BYTE * numDocs);\n      LeafCollector acc = cc.getLeafCollector(null);\n      acc.setScorer(new MockScorable());\n      for (int i = 0; i < numDocs; i++) acc.collect(i);\n      assertTrue(cc.isCached());\n\n      // The 151's document should terminate caching\n      acc.collect(numDocs);\n      assertFalse(cc.isCached());\n    }\n  }\n\n","sourceOld":"  public void testCachedArraysAllocation() throws Exception {\n    // tests the cached arrays allocation -- if the 'nextLength' was too high,\n    // caching would terminate even if a smaller length would suffice.\n    \n    // set RAM limit enough for 150 docs + random(10000)\n    int numDocs = random().nextInt(10000) + 150;\n    for (boolean cacheScores : new boolean[] { false, true }) {\n      int bytesPerDoc = cacheScores ? 8 : 4;\n      CachingCollector cc = CachingCollector.create(new NoOpCollector(),\n          cacheScores, bytesPerDoc * ONE_BYTE * numDocs);\n      LeafCollector acc = cc.getLeafCollector(null);\n      acc.setScorer(new MockScorer());\n      for (int i = 0; i < numDocs; i++) acc.collect(i);\n      assertTrue(cc.isCached());\n\n      // The 151's document should terminate caching\n      acc.collect(numDocs);\n      assertFalse(cc.isCached());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"f582f18c13d4852b01d4fe0a0196432c5c6f2b7f":["ae73da626f97850c922c42736f808d0378e165f0"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"15e323346eac5e4685c0a9f2df85eb96b4239bbb":["19275ba31e621f6da1b83bf13af75233876fd3d4","ae73da626f97850c922c42736f808d0378e165f0"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"6dbd758f2776b0129f6b3641b6490ddc68d7b0f3":["f582f18c13d4852b01d4fe0a0196432c5c6f2b7f"],"ae73da626f97850c922c42736f808d0378e165f0":["19275ba31e621f6da1b83bf13af75233876fd3d4"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"19275ba31e621f6da1b83bf13af75233876fd3d4":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["6dbd758f2776b0129f6b3641b6490ddc68d7b0f3"]},"commit2Childs":{"f582f18c13d4852b01d4fe0a0196432c5c6f2b7f":["6dbd758f2776b0129f6b3641b6490ddc68d7b0f3"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"15e323346eac5e4685c0a9f2df85eb96b4239bbb":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"ae73da626f97850c922c42736f808d0378e165f0":["f582f18c13d4852b01d4fe0a0196432c5c6f2b7f","15e323346eac5e4685c0a9f2df85eb96b4239bbb"],"6dbd758f2776b0129f6b3641b6490ddc68d7b0f3":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":[],"19275ba31e621f6da1b83bf13af75233876fd3d4":["15e323346eac5e4685c0a9f2df85eb96b4239bbb","ae73da626f97850c922c42736f808d0378e165f0"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","19275ba31e621f6da1b83bf13af75233876fd3d4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["15e323346eac5e4685c0a9f2df85eb96b4239bbb","8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}