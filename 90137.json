{"path":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","commits":[{"id":"84b590669deb3d3a471cec6cb13b104b2ee94418","date":1288889547,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testImmediateDiskFull().mjava","sourceNew":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())\n        .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.close(false);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close(false);\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())\n        .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.close(false);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close(false);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"85a883878c0af761245ab048babc63d099f835f3","date":1289553330,"type":1,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testImmediateDiskFull().mjava","sourceNew":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())\n        .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.close(false);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close(false);\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())\n        .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.close(false);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close(false);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":0,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","pathOld":"/dev/null","sourceNew":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())\n        .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.close(false);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close(false);\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f2c5f0cb44df114db4228c8f77861714b5cabaea","date":1302542431,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","sourceNew":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random))\n        .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.close(false);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close(false);\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())\n        .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.close(false);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close(false);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"962d04139994fce5193143ef35615499a9a96d78","date":1302693744,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","sourceNew":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random))\n        .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.close(false);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close(false);\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())\n        .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.close(false);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close(false);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","sourceNew":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random))\n        .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.close(false);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close(false);\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())\n        .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.close(false);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close(false);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","sourceNew":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random))\n        .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.close(false);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close(false);\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())\n        .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.close(false);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close(false);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1509f151d7692d84fae414b2b799ac06ba60fcb4","date":1314451621,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","sourceNew":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random))\n        .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", customType));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.close(false);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close(false);\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random))\n        .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.close(false);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close(false);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7118b8e5d127b58ad37740f4fa0881259a362090","date":1327618211,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","sourceNew":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n        .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", customType));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.close(false);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close(false);\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random))\n        .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", customType));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.close(false);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close(false);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"78a55f24d9b493c2a1cecf79f1d78279062b545b","date":1327688152,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","sourceNew":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n        .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", customType));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.close(false);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close(false);\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random))\n        .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", customType));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.close(false);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close(false);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fd92b8bcc88e969302510acf77bd6970da3994c4","date":1327839530,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","sourceNew":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n        .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", customType));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.close(false);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close(false);\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random))\n        .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", customType));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.close(false);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close(false);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","sourceNew":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n        .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", customType));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.close(false);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close(false);\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n        .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", customType));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.close(false);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close(false);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"78a55f24d9b493c2a1cecf79f1d78279062b545b":["1509f151d7692d84fae414b2b799ac06ba60fcb4","7118b8e5d127b58ad37740f4fa0881259a362090"],"7118b8e5d127b58ad37740f4fa0881259a362090":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["7118b8e5d127b58ad37740f4fa0881259a362090"],"85a883878c0af761245ab048babc63d099f835f3":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","84b590669deb3d3a471cec6cb13b104b2ee94418"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["85a883878c0af761245ab048babc63d099f835f3","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"fd92b8bcc88e969302510acf77bd6970da3994c4":["1509f151d7692d84fae414b2b799ac06ba60fcb4","7118b8e5d127b58ad37740f4fa0881259a362090"],"962d04139994fce5193143ef35615499a9a96d78":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","84b590669deb3d3a471cec6cb13b104b2ee94418"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["84b590669deb3d3a471cec6cb13b104b2ee94418"],"84b590669deb3d3a471cec6cb13b104b2ee94418":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a3776dccca01c11e7046323cfad46a3b4a471233":["84b590669deb3d3a471cec6cb13b104b2ee94418","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["f2c5f0cb44df114db4228c8f77861714b5cabaea"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"78a55f24d9b493c2a1cecf79f1d78279062b545b":[],"7118b8e5d127b58ad37740f4fa0881259a362090":["78a55f24d9b493c2a1cecf79f1d78279062b545b","3a119bbc8703c10faa329ec201c654b3a35a1e3e","fd92b8bcc88e969302510acf77bd6970da3994c4"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"85a883878c0af761245ab048babc63d099f835f3":["135621f3a0670a9394eb563224a3b76cc4dddc0f"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":[],"fd92b8bcc88e969302510acf77bd6970da3994c4":[],"962d04139994fce5193143ef35615499a9a96d78":[],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["962d04139994fce5193143ef35615499a9a96d78"],"84b590669deb3d3a471cec6cb13b104b2ee94418":["85a883878c0af761245ab048babc63d099f835f3","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","f2c5f0cb44df114db4228c8f77861714b5cabaea","a3776dccca01c11e7046323cfad46a3b4a471233"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["135621f3a0670a9394eb563224a3b76cc4dddc0f","962d04139994fce5193143ef35615499a9a96d78","a3776dccca01c11e7046323cfad46a3b4a471233","1509f151d7692d84fae414b2b799ac06ba60fcb4"],"a3776dccca01c11e7046323cfad46a3b4a471233":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["85a883878c0af761245ab048babc63d099f835f3","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","84b590669deb3d3a471cec6cb13b104b2ee94418"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["78a55f24d9b493c2a1cecf79f1d78279062b545b","7118b8e5d127b58ad37740f4fa0881259a362090","fd92b8bcc88e969302510acf77bd6970da3994c4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["78a55f24d9b493c2a1cecf79f1d78279062b545b","135621f3a0670a9394eb563224a3b76cc4dddc0f","fd92b8bcc88e969302510acf77bd6970da3994c4","962d04139994fce5193143ef35615499a9a96d78","a3776dccca01c11e7046323cfad46a3b4a471233","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}