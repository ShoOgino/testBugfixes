{"path":"modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter#parse().mjava","commits":[{"id":"44d6f0ab53c1962856b9f48dedb7a2a6cc18905c","date":1310389132,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter#parse().mjava","pathOld":"/dev/null","sourceNew":"  private void parse() throws IOException {\n    //System.out.println(\"\\nS: parse\");\n\n    assert inputSkipCount == 0;\n\n    int curNextRead = nextRead;\n\n    // Holds the longest match we've seen so far:\n    BytesRef matchOutput = null;\n    int matchInputLength = 0;\n\n    BytesRef pendingOutput = fst.outputs.getNoOutput();\n    fst.getFirstArc(scratchArc);\n\n    assert scratchArc.output == fst.outputs.getNoOutput();\n\n    int tokenCount = 0;\n\n    byToken:\n    while(true) {\n      \n      // Pull next token's chars:\n      final char[] buffer;\n      final int bufferLen;\n      //System.out.println(\"  cycle nextRead=\" + curNextRead + \" nextWrite=\" + nextWrite);\n\n      if (curNextRead == nextWrite) {\n\n        // We used up our lookahead buffer of input tokens\n        // -- pull next real input token:\n\n        if (finished) {\n          break;\n        } else  {\n          //System.out.println(\"  input.incrToken\");\n          assert futureInputs[nextWrite].consumed;\n          // Not correct: a syn match whose output is longer\n          // than its input can set future inputs keepOrig\n          // to true:\n          //assert !futureInputs[nextWrite].keepOrig;\n          if (input.incrementToken()) {\n            buffer = termAtt.buffer();\n            bufferLen = termAtt.length();\n            final PendingInput input = futureInputs[nextWrite];\n            input.startOffset = offsetAtt.startOffset();\n            input.endOffset = offsetAtt.endOffset();\n            //System.out.println(\"  new token=\" + new String(buffer, 0, bufferLen));\n            if (nextRead != nextWrite) {\n              capture();\n            } else {\n              input.consumed = false;\n            }\n\n          } else {\n            // No more input tokens\n            //System.out.println(\"      set end\");\n            finished = true;\n            break;\n          }\n        }\n      } else {\n        // Still in our lookahead\n        buffer = futureInputs[curNextRead].term.chars;\n        bufferLen = futureInputs[curNextRead].term.length;\n        //System.out.println(\"  old token=\" + new String(buffer, 0, bufferLen));\n      }\n\n      tokenCount++;\n\n      // Run each char in this token through the FST:\n      int bufUpto = 0;\n      while(bufUpto < bufferLen) {\n        final int codePoint = Character.codePointAt(buffer, bufUpto, bufferLen);\n        if (fst.findTargetArc(ignoreCase ? Character.toLowerCase(codePoint) : codePoint, scratchArc, scratchArc) == null) {\n          //System.out.println(\"    stop\");\n          break byToken;\n        }\n\n        // Accum the output\n        pendingOutput = fst.outputs.add(pendingOutput, scratchArc.output);\n        //System.out.println(\"    char=\" + buffer[bufUpto] + \" output=\" + pendingOutput + \" arc.output=\" + scratchArc.output);\n        bufUpto += Character.charCount(codePoint);\n      }\n\n      // OK, entire token matched; now see if this is a final\n      // state:\n      if (scratchArc.isFinal()) {\n        matchOutput = fst.outputs.add(pendingOutput, scratchArc.nextFinalOutput);\n        matchInputLength = tokenCount;\n        //System.out.println(\"  found matchLength=\" + matchInputLength + \" output=\" + matchOutput);\n      }\n\n      // See if the FST wants to continue matching (ie, needs to\n      // see the next input token):\n      if (fst.findTargetArc(SynonymMap.WORD_SEPARATOR, scratchArc, scratchArc) == null) {\n        // No further rules can match here; we're done\n        // searching for matching rules starting at the\n        // current input position.\n        break;\n      } else {\n        // More matching is possible -- accum the output (if\n        // any) of the WORD_SEP arc:\n        pendingOutput = fst.outputs.add(pendingOutput, scratchArc.output);\n        if (nextRead == nextWrite) {\n          capture();\n        }\n      }\n\n      curNextRead = rollIncr(curNextRead);\n    }\n\n    if (nextRead == nextWrite && !finished) {\n      //System.out.println(\"  skip write slot=\" + nextWrite);\n      nextWrite = rollIncr(nextWrite);\n    }\n\n    if (matchOutput != null) {\n      //System.out.println(\"  add matchLength=\" + matchInputLength + \" output=\" + matchOutput);\n      inputSkipCount = matchInputLength;\n      addOutput(matchOutput);\n    } else if (nextRead != nextWrite) {\n      // Even though we had no match here, we set to 1\n      // because we need to skip current input token before\n      // trying to match again:\n      inputSkipCount = 1;\n    } else {\n      assert finished;\n    }\n\n    //System.out.println(\"  parse done inputSkipCount=\" + inputSkipCount + \" nextRead=\" + nextRead + \" nextWrite=\" + nextWrite);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50","de11853c992f764e52d4164cc9afdebb989dba8a","b7c49a1b0f95bf8ecc502e6d44d79e4809dbf8ee"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"de11853c992f764e52d4164cc9afdebb989dba8a","date":1313510465,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter#parse().mjava","pathOld":"modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter#parse().mjava","sourceNew":"  private void parse() throws IOException {\n    //System.out.println(\"\\nS: parse\");\n\n    assert inputSkipCount == 0;\n\n    int curNextRead = nextRead;\n\n    // Holds the longest match we've seen so far:\n    BytesRef matchOutput = null;\n    int matchInputLength = 0;\n\n    BytesRef pendingOutput = fst.outputs.getNoOutput();\n    fst.getFirstArc(scratchArc);\n\n    assert scratchArc.output == fst.outputs.getNoOutput();\n\n    int tokenCount = 0;\n\n    byToken:\n    while(true) {\n      \n      // Pull next token's chars:\n      final char[] buffer;\n      final int bufferLen;\n      //System.out.println(\"  cycle nextRead=\" + curNextRead + \" nextWrite=\" + nextWrite);\n\n      if (curNextRead == nextWrite) {\n\n        // We used up our lookahead buffer of input tokens\n        // -- pull next real input token:\n\n        if (finished) {\n          break;\n        } else  {\n          //System.out.println(\"  input.incrToken\");\n          assert futureInputs[nextWrite].consumed;\n          // Not correct: a syn match whose output is longer\n          // than its input can set future inputs keepOrig\n          // to true:\n          //assert !futureInputs[nextWrite].keepOrig;\n          if (input.incrementToken()) {\n            buffer = termAtt.buffer();\n            bufferLen = termAtt.length();\n            final PendingInput input = futureInputs[nextWrite];\n            input.startOffset = offsetAtt.startOffset();\n            input.endOffset = offsetAtt.endOffset();\n            //System.out.println(\"  new token=\" + new String(buffer, 0, bufferLen));\n            if (nextRead != nextWrite) {\n              capture();\n            } else {\n              input.consumed = false;\n            }\n\n          } else {\n            // No more input tokens\n            //System.out.println(\"      set end\");\n            finished = true;\n            break;\n          }\n        }\n      } else {\n        // Still in our lookahead\n        buffer = futureInputs[curNextRead].term.chars;\n        bufferLen = futureInputs[curNextRead].term.length;\n        //System.out.println(\"  old token=\" + new String(buffer, 0, bufferLen));\n      }\n\n      tokenCount++;\n\n      // Run each char in this token through the FST:\n      int bufUpto = 0;\n      while(bufUpto < bufferLen) {\n        final int codePoint = Character.codePointAt(buffer, bufUpto, bufferLen);\n        if (fst.findTargetArc(ignoreCase ? Character.toLowerCase(codePoint) : codePoint, scratchArc, scratchArc) == null) {\n          //System.out.println(\"    stop\");\n          break byToken;\n        }\n\n        // Accum the output\n        pendingOutput = fst.outputs.add(pendingOutput, scratchArc.output);\n        //System.out.println(\"    char=\" + buffer[bufUpto] + \" output=\" + pendingOutput + \" arc.output=\" + scratchArc.output);\n        bufUpto += Character.charCount(codePoint);\n      }\n\n      // OK, entire token matched; now see if this is a final\n      // state:\n      if (scratchArc.isFinal()) {\n        matchOutput = fst.outputs.add(pendingOutput, scratchArc.nextFinalOutput);\n        matchInputLength = tokenCount;\n        //System.out.println(\"  found matchLength=\" + matchInputLength + \" output=\" + matchOutput);\n      }\n\n      // See if the FST wants to continue matching (ie, needs to\n      // see the next input token):\n      if (fst.findTargetArc(SynonymMap.WORD_SEPARATOR, scratchArc, scratchArc) == null) {\n        // No further rules can match here; we're done\n        // searching for matching rules starting at the\n        // current input position.\n        break;\n      } else {\n        // More matching is possible -- accum the output (if\n        // any) of the WORD_SEP arc:\n        pendingOutput = fst.outputs.add(pendingOutput, scratchArc.output);\n        if (nextRead == nextWrite) {\n          capture();\n        }\n      }\n\n      curNextRead = rollIncr(curNextRead);\n    }\n\n    if (nextRead == nextWrite && !finished) {\n      //System.out.println(\"  skip write slot=\" + nextWrite);\n      nextWrite = rollIncr(nextWrite);\n    }\n\n    if (matchOutput != null) {\n      //System.out.println(\"  add matchLength=\" + matchInputLength + \" output=\" + matchOutput);\n      inputSkipCount = matchInputLength;\n      addOutput(matchOutput, matchInputLength);\n    } else if (nextRead != nextWrite) {\n      // Even though we had no match here, we set to 1\n      // because we need to skip current input token before\n      // trying to match again:\n      inputSkipCount = 1;\n    } else {\n      assert finished;\n    }\n\n    //System.out.println(\"  parse done inputSkipCount=\" + inputSkipCount + \" nextRead=\" + nextRead + \" nextWrite=\" + nextWrite);\n  }\n\n","sourceOld":"  private void parse() throws IOException {\n    //System.out.println(\"\\nS: parse\");\n\n    assert inputSkipCount == 0;\n\n    int curNextRead = nextRead;\n\n    // Holds the longest match we've seen so far:\n    BytesRef matchOutput = null;\n    int matchInputLength = 0;\n\n    BytesRef pendingOutput = fst.outputs.getNoOutput();\n    fst.getFirstArc(scratchArc);\n\n    assert scratchArc.output == fst.outputs.getNoOutput();\n\n    int tokenCount = 0;\n\n    byToken:\n    while(true) {\n      \n      // Pull next token's chars:\n      final char[] buffer;\n      final int bufferLen;\n      //System.out.println(\"  cycle nextRead=\" + curNextRead + \" nextWrite=\" + nextWrite);\n\n      if (curNextRead == nextWrite) {\n\n        // We used up our lookahead buffer of input tokens\n        // -- pull next real input token:\n\n        if (finished) {\n          break;\n        } else  {\n          //System.out.println(\"  input.incrToken\");\n          assert futureInputs[nextWrite].consumed;\n          // Not correct: a syn match whose output is longer\n          // than its input can set future inputs keepOrig\n          // to true:\n          //assert !futureInputs[nextWrite].keepOrig;\n          if (input.incrementToken()) {\n            buffer = termAtt.buffer();\n            bufferLen = termAtt.length();\n            final PendingInput input = futureInputs[nextWrite];\n            input.startOffset = offsetAtt.startOffset();\n            input.endOffset = offsetAtt.endOffset();\n            //System.out.println(\"  new token=\" + new String(buffer, 0, bufferLen));\n            if (nextRead != nextWrite) {\n              capture();\n            } else {\n              input.consumed = false;\n            }\n\n          } else {\n            // No more input tokens\n            //System.out.println(\"      set end\");\n            finished = true;\n            break;\n          }\n        }\n      } else {\n        // Still in our lookahead\n        buffer = futureInputs[curNextRead].term.chars;\n        bufferLen = futureInputs[curNextRead].term.length;\n        //System.out.println(\"  old token=\" + new String(buffer, 0, bufferLen));\n      }\n\n      tokenCount++;\n\n      // Run each char in this token through the FST:\n      int bufUpto = 0;\n      while(bufUpto < bufferLen) {\n        final int codePoint = Character.codePointAt(buffer, bufUpto, bufferLen);\n        if (fst.findTargetArc(ignoreCase ? Character.toLowerCase(codePoint) : codePoint, scratchArc, scratchArc) == null) {\n          //System.out.println(\"    stop\");\n          break byToken;\n        }\n\n        // Accum the output\n        pendingOutput = fst.outputs.add(pendingOutput, scratchArc.output);\n        //System.out.println(\"    char=\" + buffer[bufUpto] + \" output=\" + pendingOutput + \" arc.output=\" + scratchArc.output);\n        bufUpto += Character.charCount(codePoint);\n      }\n\n      // OK, entire token matched; now see if this is a final\n      // state:\n      if (scratchArc.isFinal()) {\n        matchOutput = fst.outputs.add(pendingOutput, scratchArc.nextFinalOutput);\n        matchInputLength = tokenCount;\n        //System.out.println(\"  found matchLength=\" + matchInputLength + \" output=\" + matchOutput);\n      }\n\n      // See if the FST wants to continue matching (ie, needs to\n      // see the next input token):\n      if (fst.findTargetArc(SynonymMap.WORD_SEPARATOR, scratchArc, scratchArc) == null) {\n        // No further rules can match here; we're done\n        // searching for matching rules starting at the\n        // current input position.\n        break;\n      } else {\n        // More matching is possible -- accum the output (if\n        // any) of the WORD_SEP arc:\n        pendingOutput = fst.outputs.add(pendingOutput, scratchArc.output);\n        if (nextRead == nextWrite) {\n          capture();\n        }\n      }\n\n      curNextRead = rollIncr(curNextRead);\n    }\n\n    if (nextRead == nextWrite && !finished) {\n      //System.out.println(\"  skip write slot=\" + nextWrite);\n      nextWrite = rollIncr(nextWrite);\n    }\n\n    if (matchOutput != null) {\n      //System.out.println(\"  add matchLength=\" + matchInputLength + \" output=\" + matchOutput);\n      inputSkipCount = matchInputLength;\n      addOutput(matchOutput);\n    } else if (nextRead != nextWrite) {\n      // Even though we had no match here, we set to 1\n      // because we need to skip current input token before\n      // trying to match again:\n      inputSkipCount = 1;\n    } else {\n      assert finished;\n    }\n\n    //System.out.println(\"  parse done inputSkipCount=\" + inputSkipCount + \" nextRead=\" + nextRead + \" nextWrite=\" + nextWrite);\n  }\n\n","bugFix":["44d6f0ab53c1962856b9f48dedb7a2a6cc18905c"],"bugIntro":["865b7d0f8430a08d385370b6b87a89a737aa6145"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"865b7d0f8430a08d385370b6b87a89a737aa6145","date":1325953575,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter#parse().mjava","pathOld":"modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter#parse().mjava","sourceNew":"  private void parse() throws IOException {\n    //System.out.println(\"\\nS: parse\");\n\n    assert inputSkipCount == 0;\n\n    int curNextRead = nextRead;\n\n    // Holds the longest match we've seen so far:\n    BytesRef matchOutput = null;\n    int matchInputLength = 0;\n    int matchEndOffset = -1;\n\n    BytesRef pendingOutput = fst.outputs.getNoOutput();\n    fst.getFirstArc(scratchArc);\n\n    assert scratchArc.output == fst.outputs.getNoOutput();\n\n    int tokenCount = 0;\n\n    byToken:\n    while(true) {\n      \n      // Pull next token's chars:\n      final char[] buffer;\n      final int bufferLen;\n      //System.out.println(\"  cycle nextRead=\" + curNextRead + \" nextWrite=\" + nextWrite);\n\n      int inputEndOffset = 0;\n\n      if (curNextRead == nextWrite) {\n\n        // We used up our lookahead buffer of input tokens\n        // -- pull next real input token:\n\n        if (finished) {\n          break;\n        } else  {\n          //System.out.println(\"  input.incrToken\");\n          assert futureInputs[nextWrite].consumed;\n          // Not correct: a syn match whose output is longer\n          // than its input can set future inputs keepOrig\n          // to true:\n          //assert !futureInputs[nextWrite].keepOrig;\n          if (input.incrementToken()) {\n            buffer = termAtt.buffer();\n            bufferLen = termAtt.length();\n            final PendingInput input = futureInputs[nextWrite];\n            input.startOffset = offsetAtt.startOffset();\n            input.endOffset = offsetAtt.endOffset();\n            inputEndOffset = input.endOffset;\n            //System.out.println(\"  new token=\" + new String(buffer, 0, bufferLen));\n            if (nextRead != nextWrite) {\n              capture();\n            } else {\n              input.consumed = false;\n            }\n\n          } else {\n            // No more input tokens\n            //System.out.println(\"      set end\");\n            finished = true;\n            break;\n          }\n        }\n      } else {\n        // Still in our lookahead\n        buffer = futureInputs[curNextRead].term.chars;\n        bufferLen = futureInputs[curNextRead].term.length;\n        inputEndOffset = futureInputs[curNextRead].endOffset;\n        //System.out.println(\"  old token=\" + new String(buffer, 0, bufferLen));\n      }\n\n      tokenCount++;\n\n      // Run each char in this token through the FST:\n      int bufUpto = 0;\n      while(bufUpto < bufferLen) {\n        final int codePoint = Character.codePointAt(buffer, bufUpto, bufferLen);\n        if (fst.findTargetArc(ignoreCase ? Character.toLowerCase(codePoint) : codePoint, scratchArc, scratchArc) == null) {\n          //System.out.println(\"    stop\");\n          break byToken;\n        }\n\n        // Accum the output\n        pendingOutput = fst.outputs.add(pendingOutput, scratchArc.output);\n        //System.out.println(\"    char=\" + buffer[bufUpto] + \" output=\" + pendingOutput + \" arc.output=\" + scratchArc.output);\n        bufUpto += Character.charCount(codePoint);\n      }\n\n      // OK, entire token matched; now see if this is a final\n      // state:\n      if (scratchArc.isFinal()) {\n        matchOutput = fst.outputs.add(pendingOutput, scratchArc.nextFinalOutput);\n        matchInputLength = tokenCount;\n        matchEndOffset = inputEndOffset;\n        //System.out.println(\"  found matchLength=\" + matchInputLength + \" output=\" + matchOutput);\n      }\n\n      // See if the FST wants to continue matching (ie, needs to\n      // see the next input token):\n      if (fst.findTargetArc(SynonymMap.WORD_SEPARATOR, scratchArc, scratchArc) == null) {\n        // No further rules can match here; we're done\n        // searching for matching rules starting at the\n        // current input position.\n        break;\n      } else {\n        // More matching is possible -- accum the output (if\n        // any) of the WORD_SEP arc:\n        pendingOutput = fst.outputs.add(pendingOutput, scratchArc.output);\n        if (nextRead == nextWrite) {\n          capture();\n        }\n      }\n\n      curNextRead = rollIncr(curNextRead);\n    }\n\n    if (nextRead == nextWrite && !finished) {\n      //System.out.println(\"  skip write slot=\" + nextWrite);\n      nextWrite = rollIncr(nextWrite);\n    }\n\n    if (matchOutput != null) {\n      //System.out.println(\"  add matchLength=\" + matchInputLength + \" output=\" + matchOutput);\n      inputSkipCount = matchInputLength;\n      addOutput(matchOutput, matchInputLength, matchEndOffset);\n    } else if (nextRead != nextWrite) {\n      // Even though we had no match here, we set to 1\n      // because we need to skip current input token before\n      // trying to match again:\n      inputSkipCount = 1;\n    } else {\n      assert finished;\n    }\n\n    //System.out.println(\"  parse done inputSkipCount=\" + inputSkipCount + \" nextRead=\" + nextRead + \" nextWrite=\" + nextWrite);\n  }\n\n","sourceOld":"  private void parse() throws IOException {\n    //System.out.println(\"\\nS: parse\");\n\n    assert inputSkipCount == 0;\n\n    int curNextRead = nextRead;\n\n    // Holds the longest match we've seen so far:\n    BytesRef matchOutput = null;\n    int matchInputLength = 0;\n\n    BytesRef pendingOutput = fst.outputs.getNoOutput();\n    fst.getFirstArc(scratchArc);\n\n    assert scratchArc.output == fst.outputs.getNoOutput();\n\n    int tokenCount = 0;\n\n    byToken:\n    while(true) {\n      \n      // Pull next token's chars:\n      final char[] buffer;\n      final int bufferLen;\n      //System.out.println(\"  cycle nextRead=\" + curNextRead + \" nextWrite=\" + nextWrite);\n\n      if (curNextRead == nextWrite) {\n\n        // We used up our lookahead buffer of input tokens\n        // -- pull next real input token:\n\n        if (finished) {\n          break;\n        } else  {\n          //System.out.println(\"  input.incrToken\");\n          assert futureInputs[nextWrite].consumed;\n          // Not correct: a syn match whose output is longer\n          // than its input can set future inputs keepOrig\n          // to true:\n          //assert !futureInputs[nextWrite].keepOrig;\n          if (input.incrementToken()) {\n            buffer = termAtt.buffer();\n            bufferLen = termAtt.length();\n            final PendingInput input = futureInputs[nextWrite];\n            input.startOffset = offsetAtt.startOffset();\n            input.endOffset = offsetAtt.endOffset();\n            //System.out.println(\"  new token=\" + new String(buffer, 0, bufferLen));\n            if (nextRead != nextWrite) {\n              capture();\n            } else {\n              input.consumed = false;\n            }\n\n          } else {\n            // No more input tokens\n            //System.out.println(\"      set end\");\n            finished = true;\n            break;\n          }\n        }\n      } else {\n        // Still in our lookahead\n        buffer = futureInputs[curNextRead].term.chars;\n        bufferLen = futureInputs[curNextRead].term.length;\n        //System.out.println(\"  old token=\" + new String(buffer, 0, bufferLen));\n      }\n\n      tokenCount++;\n\n      // Run each char in this token through the FST:\n      int bufUpto = 0;\n      while(bufUpto < bufferLen) {\n        final int codePoint = Character.codePointAt(buffer, bufUpto, bufferLen);\n        if (fst.findTargetArc(ignoreCase ? Character.toLowerCase(codePoint) : codePoint, scratchArc, scratchArc) == null) {\n          //System.out.println(\"    stop\");\n          break byToken;\n        }\n\n        // Accum the output\n        pendingOutput = fst.outputs.add(pendingOutput, scratchArc.output);\n        //System.out.println(\"    char=\" + buffer[bufUpto] + \" output=\" + pendingOutput + \" arc.output=\" + scratchArc.output);\n        bufUpto += Character.charCount(codePoint);\n      }\n\n      // OK, entire token matched; now see if this is a final\n      // state:\n      if (scratchArc.isFinal()) {\n        matchOutput = fst.outputs.add(pendingOutput, scratchArc.nextFinalOutput);\n        matchInputLength = tokenCount;\n        //System.out.println(\"  found matchLength=\" + matchInputLength + \" output=\" + matchOutput);\n      }\n\n      // See if the FST wants to continue matching (ie, needs to\n      // see the next input token):\n      if (fst.findTargetArc(SynonymMap.WORD_SEPARATOR, scratchArc, scratchArc) == null) {\n        // No further rules can match here; we're done\n        // searching for matching rules starting at the\n        // current input position.\n        break;\n      } else {\n        // More matching is possible -- accum the output (if\n        // any) of the WORD_SEP arc:\n        pendingOutput = fst.outputs.add(pendingOutput, scratchArc.output);\n        if (nextRead == nextWrite) {\n          capture();\n        }\n      }\n\n      curNextRead = rollIncr(curNextRead);\n    }\n\n    if (nextRead == nextWrite && !finished) {\n      //System.out.println(\"  skip write slot=\" + nextWrite);\n      nextWrite = rollIncr(nextWrite);\n    }\n\n    if (matchOutput != null) {\n      //System.out.println(\"  add matchLength=\" + matchInputLength + \" output=\" + matchOutput);\n      inputSkipCount = matchInputLength;\n      addOutput(matchOutput, matchInputLength);\n    } else if (nextRead != nextWrite) {\n      // Even though we had no match here, we set to 1\n      // because we need to skip current input token before\n      // trying to match again:\n      inputSkipCount = 1;\n    } else {\n      assert finished;\n    }\n\n    //System.out.println(\"  parse done inputSkipCount=\" + inputSkipCount + \" nextRead=\" + nextRead + \" nextWrite=\" + nextWrite);\n  }\n\n","bugFix":["de11853c992f764e52d4164cc9afdebb989dba8a"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b3be20ca1091c0b7cdb2308b9023606a5e451cec","date":1327877325,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter#parse().mjava","pathOld":"modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter#parse().mjava","sourceNew":"  private void parse() throws IOException {\n    //System.out.println(\"\\nS: parse\");\n\n    assert inputSkipCount == 0;\n\n    int curNextRead = nextRead;\n\n    // Holds the longest match we've seen so far:\n    BytesRef matchOutput = null;\n    int matchInputLength = 0;\n    int matchEndOffset = -1;\n\n    BytesRef pendingOutput = fst.outputs.getNoOutput();\n    fst.getFirstArc(scratchArc);\n\n    assert scratchArc.output == fst.outputs.getNoOutput();\n\n    int tokenCount = 0;\n\n    byToken:\n    while(true) {\n      \n      // Pull next token's chars:\n      final char[] buffer;\n      final int bufferLen;\n      //System.out.println(\"  cycle nextRead=\" + curNextRead + \" nextWrite=\" + nextWrite);\n\n      int inputEndOffset = 0;\n\n      if (curNextRead == nextWrite) {\n\n        // We used up our lookahead buffer of input tokens\n        // -- pull next real input token:\n\n        if (finished) {\n          break;\n        } else  {\n          //System.out.println(\"  input.incrToken\");\n          assert futureInputs[nextWrite].consumed;\n          // Not correct: a syn match whose output is longer\n          // than its input can set future inputs keepOrig\n          // to true:\n          //assert !futureInputs[nextWrite].keepOrig;\n          if (input.incrementToken()) {\n            buffer = termAtt.buffer();\n            bufferLen = termAtt.length();\n            final PendingInput input = futureInputs[nextWrite];\n            input.startOffset = offsetAtt.startOffset();\n            input.endOffset = offsetAtt.endOffset();\n            inputEndOffset = input.endOffset;\n            //System.out.println(\"  new token=\" + new String(buffer, 0, bufferLen));\n            if (nextRead != nextWrite) {\n              capture();\n            } else {\n              input.consumed = false;\n            }\n\n          } else {\n            // No more input tokens\n            //System.out.println(\"      set end\");\n            finished = true;\n            break;\n          }\n        }\n      } else {\n        // Still in our lookahead\n        buffer = futureInputs[curNextRead].term.chars;\n        bufferLen = futureInputs[curNextRead].term.length;\n        inputEndOffset = futureInputs[curNextRead].endOffset;\n        //System.out.println(\"  old token=\" + new String(buffer, 0, bufferLen));\n      }\n\n      tokenCount++;\n\n      // Run each char in this token through the FST:\n      int bufUpto = 0;\n      while(bufUpto < bufferLen) {\n        final int codePoint = Character.codePointAt(buffer, bufUpto, bufferLen);\n        if (fst.findTargetArc(ignoreCase ? Character.toLowerCase(codePoint) : codePoint, scratchArc, scratchArc, fstReader) == null) {\n          //System.out.println(\"    stop\");\n          break byToken;\n        }\n\n        // Accum the output\n        pendingOutput = fst.outputs.add(pendingOutput, scratchArc.output);\n        //System.out.println(\"    char=\" + buffer[bufUpto] + \" output=\" + pendingOutput + \" arc.output=\" + scratchArc.output);\n        bufUpto += Character.charCount(codePoint);\n      }\n\n      // OK, entire token matched; now see if this is a final\n      // state:\n      if (scratchArc.isFinal()) {\n        matchOutput = fst.outputs.add(pendingOutput, scratchArc.nextFinalOutput);\n        matchInputLength = tokenCount;\n        matchEndOffset = inputEndOffset;\n        //System.out.println(\"  found matchLength=\" + matchInputLength + \" output=\" + matchOutput);\n      }\n\n      // See if the FST wants to continue matching (ie, needs to\n      // see the next input token):\n      if (fst.findTargetArc(SynonymMap.WORD_SEPARATOR, scratchArc, scratchArc, fstReader) == null) {\n        // No further rules can match here; we're done\n        // searching for matching rules starting at the\n        // current input position.\n        break;\n      } else {\n        // More matching is possible -- accum the output (if\n        // any) of the WORD_SEP arc:\n        pendingOutput = fst.outputs.add(pendingOutput, scratchArc.output);\n        if (nextRead == nextWrite) {\n          capture();\n        }\n      }\n\n      curNextRead = rollIncr(curNextRead);\n    }\n\n    if (nextRead == nextWrite && !finished) {\n      //System.out.println(\"  skip write slot=\" + nextWrite);\n      nextWrite = rollIncr(nextWrite);\n    }\n\n    if (matchOutput != null) {\n      //System.out.println(\"  add matchLength=\" + matchInputLength + \" output=\" + matchOutput);\n      inputSkipCount = matchInputLength;\n      addOutput(matchOutput, matchInputLength, matchEndOffset);\n    } else if (nextRead != nextWrite) {\n      // Even though we had no match here, we set to 1\n      // because we need to skip current input token before\n      // trying to match again:\n      inputSkipCount = 1;\n    } else {\n      assert finished;\n    }\n\n    //System.out.println(\"  parse done inputSkipCount=\" + inputSkipCount + \" nextRead=\" + nextRead + \" nextWrite=\" + nextWrite);\n  }\n\n","sourceOld":"  private void parse() throws IOException {\n    //System.out.println(\"\\nS: parse\");\n\n    assert inputSkipCount == 0;\n\n    int curNextRead = nextRead;\n\n    // Holds the longest match we've seen so far:\n    BytesRef matchOutput = null;\n    int matchInputLength = 0;\n    int matchEndOffset = -1;\n\n    BytesRef pendingOutput = fst.outputs.getNoOutput();\n    fst.getFirstArc(scratchArc);\n\n    assert scratchArc.output == fst.outputs.getNoOutput();\n\n    int tokenCount = 0;\n\n    byToken:\n    while(true) {\n      \n      // Pull next token's chars:\n      final char[] buffer;\n      final int bufferLen;\n      //System.out.println(\"  cycle nextRead=\" + curNextRead + \" nextWrite=\" + nextWrite);\n\n      int inputEndOffset = 0;\n\n      if (curNextRead == nextWrite) {\n\n        // We used up our lookahead buffer of input tokens\n        // -- pull next real input token:\n\n        if (finished) {\n          break;\n        } else  {\n          //System.out.println(\"  input.incrToken\");\n          assert futureInputs[nextWrite].consumed;\n          // Not correct: a syn match whose output is longer\n          // than its input can set future inputs keepOrig\n          // to true:\n          //assert !futureInputs[nextWrite].keepOrig;\n          if (input.incrementToken()) {\n            buffer = termAtt.buffer();\n            bufferLen = termAtt.length();\n            final PendingInput input = futureInputs[nextWrite];\n            input.startOffset = offsetAtt.startOffset();\n            input.endOffset = offsetAtt.endOffset();\n            inputEndOffset = input.endOffset;\n            //System.out.println(\"  new token=\" + new String(buffer, 0, bufferLen));\n            if (nextRead != nextWrite) {\n              capture();\n            } else {\n              input.consumed = false;\n            }\n\n          } else {\n            // No more input tokens\n            //System.out.println(\"      set end\");\n            finished = true;\n            break;\n          }\n        }\n      } else {\n        // Still in our lookahead\n        buffer = futureInputs[curNextRead].term.chars;\n        bufferLen = futureInputs[curNextRead].term.length;\n        inputEndOffset = futureInputs[curNextRead].endOffset;\n        //System.out.println(\"  old token=\" + new String(buffer, 0, bufferLen));\n      }\n\n      tokenCount++;\n\n      // Run each char in this token through the FST:\n      int bufUpto = 0;\n      while(bufUpto < bufferLen) {\n        final int codePoint = Character.codePointAt(buffer, bufUpto, bufferLen);\n        if (fst.findTargetArc(ignoreCase ? Character.toLowerCase(codePoint) : codePoint, scratchArc, scratchArc) == null) {\n          //System.out.println(\"    stop\");\n          break byToken;\n        }\n\n        // Accum the output\n        pendingOutput = fst.outputs.add(pendingOutput, scratchArc.output);\n        //System.out.println(\"    char=\" + buffer[bufUpto] + \" output=\" + pendingOutput + \" arc.output=\" + scratchArc.output);\n        bufUpto += Character.charCount(codePoint);\n      }\n\n      // OK, entire token matched; now see if this is a final\n      // state:\n      if (scratchArc.isFinal()) {\n        matchOutput = fst.outputs.add(pendingOutput, scratchArc.nextFinalOutput);\n        matchInputLength = tokenCount;\n        matchEndOffset = inputEndOffset;\n        //System.out.println(\"  found matchLength=\" + matchInputLength + \" output=\" + matchOutput);\n      }\n\n      // See if the FST wants to continue matching (ie, needs to\n      // see the next input token):\n      if (fst.findTargetArc(SynonymMap.WORD_SEPARATOR, scratchArc, scratchArc) == null) {\n        // No further rules can match here; we're done\n        // searching for matching rules starting at the\n        // current input position.\n        break;\n      } else {\n        // More matching is possible -- accum the output (if\n        // any) of the WORD_SEP arc:\n        pendingOutput = fst.outputs.add(pendingOutput, scratchArc.output);\n        if (nextRead == nextWrite) {\n          capture();\n        }\n      }\n\n      curNextRead = rollIncr(curNextRead);\n    }\n\n    if (nextRead == nextWrite && !finished) {\n      //System.out.println(\"  skip write slot=\" + nextWrite);\n      nextWrite = rollIncr(nextWrite);\n    }\n\n    if (matchOutput != null) {\n      //System.out.println(\"  add matchLength=\" + matchInputLength + \" output=\" + matchOutput);\n      inputSkipCount = matchInputLength;\n      addOutput(matchOutput, matchInputLength, matchEndOffset);\n    } else if (nextRead != nextWrite) {\n      // Even though we had no match here, we set to 1\n      // because we need to skip current input token before\n      // trying to match again:\n      inputSkipCount = 1;\n    } else {\n      assert finished;\n    }\n\n    //System.out.println(\"  parse done inputSkipCount=\" + inputSkipCount + \" nextRead=\" + nextRead + \" nextWrite=\" + nextWrite);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"817882884229bace7dc5d1b75f6b0e4aa1e47122","date":1327879145,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter#parse().mjava","pathOld":"modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter#parse().mjava","sourceNew":"  private void parse() throws IOException {\n    //System.out.println(\"\\nS: parse\");\n\n    assert inputSkipCount == 0;\n\n    int curNextRead = nextRead;\n\n    // Holds the longest match we've seen so far:\n    BytesRef matchOutput = null;\n    int matchInputLength = 0;\n    int matchEndOffset = -1;\n\n    BytesRef pendingOutput = fst.outputs.getNoOutput();\n    fst.getFirstArc(scratchArc);\n\n    assert scratchArc.output == fst.outputs.getNoOutput();\n\n    int tokenCount = 0;\n\n    byToken:\n    while(true) {\n      \n      // Pull next token's chars:\n      final char[] buffer;\n      final int bufferLen;\n      //System.out.println(\"  cycle nextRead=\" + curNextRead + \" nextWrite=\" + nextWrite);\n\n      int inputEndOffset = 0;\n\n      if (curNextRead == nextWrite) {\n\n        // We used up our lookahead buffer of input tokens\n        // -- pull next real input token:\n\n        if (finished) {\n          break;\n        } else  {\n          //System.out.println(\"  input.incrToken\");\n          assert futureInputs[nextWrite].consumed;\n          // Not correct: a syn match whose output is longer\n          // than its input can set future inputs keepOrig\n          // to true:\n          //assert !futureInputs[nextWrite].keepOrig;\n          if (input.incrementToken()) {\n            buffer = termAtt.buffer();\n            bufferLen = termAtt.length();\n            final PendingInput input = futureInputs[nextWrite];\n            input.startOffset = offsetAtt.startOffset();\n            input.endOffset = offsetAtt.endOffset();\n            inputEndOffset = input.endOffset;\n            //System.out.println(\"  new token=\" + new String(buffer, 0, bufferLen));\n            if (nextRead != nextWrite) {\n              capture();\n            } else {\n              input.consumed = false;\n            }\n\n          } else {\n            // No more input tokens\n            //System.out.println(\"      set end\");\n            finished = true;\n            break;\n          }\n        }\n      } else {\n        // Still in our lookahead\n        buffer = futureInputs[curNextRead].term.chars;\n        bufferLen = futureInputs[curNextRead].term.length;\n        inputEndOffset = futureInputs[curNextRead].endOffset;\n        //System.out.println(\"  old token=\" + new String(buffer, 0, bufferLen));\n      }\n\n      tokenCount++;\n\n      // Run each char in this token through the FST:\n      int bufUpto = 0;\n      while(bufUpto < bufferLen) {\n        final int codePoint = Character.codePointAt(buffer, bufUpto, bufferLen);\n        if (fst.findTargetArc(ignoreCase ? Character.toLowerCase(codePoint) : codePoint, scratchArc, scratchArc, fstReader) == null) {\n          //System.out.println(\"    stop\");\n          break byToken;\n        }\n\n        // Accum the output\n        pendingOutput = fst.outputs.add(pendingOutput, scratchArc.output);\n        //System.out.println(\"    char=\" + buffer[bufUpto] + \" output=\" + pendingOutput + \" arc.output=\" + scratchArc.output);\n        bufUpto += Character.charCount(codePoint);\n      }\n\n      // OK, entire token matched; now see if this is a final\n      // state:\n      if (scratchArc.isFinal()) {\n        matchOutput = fst.outputs.add(pendingOutput, scratchArc.nextFinalOutput);\n        matchInputLength = tokenCount;\n        matchEndOffset = inputEndOffset;\n        //System.out.println(\"  found matchLength=\" + matchInputLength + \" output=\" + matchOutput);\n      }\n\n      // See if the FST wants to continue matching (ie, needs to\n      // see the next input token):\n      if (fst.findTargetArc(SynonymMap.WORD_SEPARATOR, scratchArc, scratchArc, fstReader) == null) {\n        // No further rules can match here; we're done\n        // searching for matching rules starting at the\n        // current input position.\n        break;\n      } else {\n        // More matching is possible -- accum the output (if\n        // any) of the WORD_SEP arc:\n        pendingOutput = fst.outputs.add(pendingOutput, scratchArc.output);\n        if (nextRead == nextWrite) {\n          capture();\n        }\n      }\n\n      curNextRead = rollIncr(curNextRead);\n    }\n\n    if (nextRead == nextWrite && !finished) {\n      //System.out.println(\"  skip write slot=\" + nextWrite);\n      nextWrite = rollIncr(nextWrite);\n    }\n\n    if (matchOutput != null) {\n      //System.out.println(\"  add matchLength=\" + matchInputLength + \" output=\" + matchOutput);\n      inputSkipCount = matchInputLength;\n      addOutput(matchOutput, matchInputLength, matchEndOffset);\n    } else if (nextRead != nextWrite) {\n      // Even though we had no match here, we set to 1\n      // because we need to skip current input token before\n      // trying to match again:\n      inputSkipCount = 1;\n    } else {\n      assert finished;\n    }\n\n    //System.out.println(\"  parse done inputSkipCount=\" + inputSkipCount + \" nextRead=\" + nextRead + \" nextWrite=\" + nextWrite);\n  }\n\n","sourceOld":"  private void parse() throws IOException {\n    //System.out.println(\"\\nS: parse\");\n\n    assert inputSkipCount == 0;\n\n    int curNextRead = nextRead;\n\n    // Holds the longest match we've seen so far:\n    BytesRef matchOutput = null;\n    int matchInputLength = 0;\n    int matchEndOffset = -1;\n\n    BytesRef pendingOutput = fst.outputs.getNoOutput();\n    fst.getFirstArc(scratchArc);\n\n    assert scratchArc.output == fst.outputs.getNoOutput();\n\n    int tokenCount = 0;\n\n    byToken:\n    while(true) {\n      \n      // Pull next token's chars:\n      final char[] buffer;\n      final int bufferLen;\n      //System.out.println(\"  cycle nextRead=\" + curNextRead + \" nextWrite=\" + nextWrite);\n\n      int inputEndOffset = 0;\n\n      if (curNextRead == nextWrite) {\n\n        // We used up our lookahead buffer of input tokens\n        // -- pull next real input token:\n\n        if (finished) {\n          break;\n        } else  {\n          //System.out.println(\"  input.incrToken\");\n          assert futureInputs[nextWrite].consumed;\n          // Not correct: a syn match whose output is longer\n          // than its input can set future inputs keepOrig\n          // to true:\n          //assert !futureInputs[nextWrite].keepOrig;\n          if (input.incrementToken()) {\n            buffer = termAtt.buffer();\n            bufferLen = termAtt.length();\n            final PendingInput input = futureInputs[nextWrite];\n            input.startOffset = offsetAtt.startOffset();\n            input.endOffset = offsetAtt.endOffset();\n            inputEndOffset = input.endOffset;\n            //System.out.println(\"  new token=\" + new String(buffer, 0, bufferLen));\n            if (nextRead != nextWrite) {\n              capture();\n            } else {\n              input.consumed = false;\n            }\n\n          } else {\n            // No more input tokens\n            //System.out.println(\"      set end\");\n            finished = true;\n            break;\n          }\n        }\n      } else {\n        // Still in our lookahead\n        buffer = futureInputs[curNextRead].term.chars;\n        bufferLen = futureInputs[curNextRead].term.length;\n        inputEndOffset = futureInputs[curNextRead].endOffset;\n        //System.out.println(\"  old token=\" + new String(buffer, 0, bufferLen));\n      }\n\n      tokenCount++;\n\n      // Run each char in this token through the FST:\n      int bufUpto = 0;\n      while(bufUpto < bufferLen) {\n        final int codePoint = Character.codePointAt(buffer, bufUpto, bufferLen);\n        if (fst.findTargetArc(ignoreCase ? Character.toLowerCase(codePoint) : codePoint, scratchArc, scratchArc) == null) {\n          //System.out.println(\"    stop\");\n          break byToken;\n        }\n\n        // Accum the output\n        pendingOutput = fst.outputs.add(pendingOutput, scratchArc.output);\n        //System.out.println(\"    char=\" + buffer[bufUpto] + \" output=\" + pendingOutput + \" arc.output=\" + scratchArc.output);\n        bufUpto += Character.charCount(codePoint);\n      }\n\n      // OK, entire token matched; now see if this is a final\n      // state:\n      if (scratchArc.isFinal()) {\n        matchOutput = fst.outputs.add(pendingOutput, scratchArc.nextFinalOutput);\n        matchInputLength = tokenCount;\n        matchEndOffset = inputEndOffset;\n        //System.out.println(\"  found matchLength=\" + matchInputLength + \" output=\" + matchOutput);\n      }\n\n      // See if the FST wants to continue matching (ie, needs to\n      // see the next input token):\n      if (fst.findTargetArc(SynonymMap.WORD_SEPARATOR, scratchArc, scratchArc) == null) {\n        // No further rules can match here; we're done\n        // searching for matching rules starting at the\n        // current input position.\n        break;\n      } else {\n        // More matching is possible -- accum the output (if\n        // any) of the WORD_SEP arc:\n        pendingOutput = fst.outputs.add(pendingOutput, scratchArc.output);\n        if (nextRead == nextWrite) {\n          capture();\n        }\n      }\n\n      curNextRead = rollIncr(curNextRead);\n    }\n\n    if (nextRead == nextWrite && !finished) {\n      //System.out.println(\"  skip write slot=\" + nextWrite);\n      nextWrite = rollIncr(nextWrite);\n    }\n\n    if (matchOutput != null) {\n      //System.out.println(\"  add matchLength=\" + matchInputLength + \" output=\" + matchOutput);\n      inputSkipCount = matchInputLength;\n      addOutput(matchOutput, matchInputLength, matchEndOffset);\n    } else if (nextRead != nextWrite) {\n      // Even though we had no match here, we set to 1\n      // because we need to skip current input token before\n      // trying to match again:\n      inputSkipCount = 1;\n    } else {\n      assert finished;\n    }\n\n    //System.out.println(\"  parse done inputSkipCount=\" + inputSkipCount + \" nextRead=\" + nextRead + \" nextWrite=\" + nextWrite);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5b6fdfce35d0adb18836cf8711abe487a934df33","date":1327946200,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter#parse().mjava","pathOld":"modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter#parse().mjava","sourceNew":"  private void parse() throws IOException {\n    //System.out.println(\"\\nS: parse\");\n\n    assert inputSkipCount == 0;\n\n    int curNextRead = nextRead;\n\n    // Holds the longest match we've seen so far:\n    BytesRef matchOutput = null;\n    int matchInputLength = 0;\n    int matchEndOffset = -1;\n\n    BytesRef pendingOutput = fst.outputs.getNoOutput();\n    fst.getFirstArc(scratchArc);\n\n    assert scratchArc.output == fst.outputs.getNoOutput();\n\n    int tokenCount = 0;\n\n    byToken:\n    while(true) {\n      \n      // Pull next token's chars:\n      final char[] buffer;\n      final int bufferLen;\n      //System.out.println(\"  cycle nextRead=\" + curNextRead + \" nextWrite=\" + nextWrite);\n\n      int inputEndOffset = 0;\n\n      if (curNextRead == nextWrite) {\n\n        // We used up our lookahead buffer of input tokens\n        // -- pull next real input token:\n\n        if (finished) {\n          break;\n        } else  {\n          //System.out.println(\"  input.incrToken\");\n          assert futureInputs[nextWrite].consumed;\n          // Not correct: a syn match whose output is longer\n          // than its input can set future inputs keepOrig\n          // to true:\n          //assert !futureInputs[nextWrite].keepOrig;\n          if (input.incrementToken()) {\n            buffer = termAtt.buffer();\n            bufferLen = termAtt.length();\n            final PendingInput input = futureInputs[nextWrite];\n            input.startOffset = offsetAtt.startOffset();\n            input.endOffset = offsetAtt.endOffset();\n            inputEndOffset = input.endOffset;\n            //System.out.println(\"  new token=\" + new String(buffer, 0, bufferLen));\n            if (nextRead != nextWrite) {\n              capture();\n            } else {\n              input.consumed = false;\n            }\n\n          } else {\n            // No more input tokens\n            //System.out.println(\"      set end\");\n            finished = true;\n            break;\n          }\n        }\n      } else {\n        // Still in our lookahead\n        buffer = futureInputs[curNextRead].term.chars;\n        bufferLen = futureInputs[curNextRead].term.length;\n        inputEndOffset = futureInputs[curNextRead].endOffset;\n        //System.out.println(\"  old token=\" + new String(buffer, 0, bufferLen));\n      }\n\n      tokenCount++;\n\n      // Run each char in this token through the FST:\n      int bufUpto = 0;\n      while(bufUpto < bufferLen) {\n        final int codePoint = Character.codePointAt(buffer, bufUpto, bufferLen);\n        if (fst.findTargetArc(ignoreCase ? Character.toLowerCase(codePoint) : codePoint, scratchArc, scratchArc, fstReader) == null) {\n          //System.out.println(\"    stop\");\n          break byToken;\n        }\n\n        // Accum the output\n        pendingOutput = fst.outputs.add(pendingOutput, scratchArc.output);\n        //System.out.println(\"    char=\" + buffer[bufUpto] + \" output=\" + pendingOutput + \" arc.output=\" + scratchArc.output);\n        bufUpto += Character.charCount(codePoint);\n      }\n\n      // OK, entire token matched; now see if this is a final\n      // state:\n      if (scratchArc.isFinal()) {\n        matchOutput = fst.outputs.add(pendingOutput, scratchArc.nextFinalOutput);\n        matchInputLength = tokenCount;\n        matchEndOffset = inputEndOffset;\n        //System.out.println(\"  found matchLength=\" + matchInputLength + \" output=\" + matchOutput);\n      }\n\n      // See if the FST wants to continue matching (ie, needs to\n      // see the next input token):\n      if (fst.findTargetArc(SynonymMap.WORD_SEPARATOR, scratchArc, scratchArc, fstReader) == null) {\n        // No further rules can match here; we're done\n        // searching for matching rules starting at the\n        // current input position.\n        break;\n      } else {\n        // More matching is possible -- accum the output (if\n        // any) of the WORD_SEP arc:\n        pendingOutput = fst.outputs.add(pendingOutput, scratchArc.output);\n        if (nextRead == nextWrite) {\n          capture();\n        }\n      }\n\n      curNextRead = rollIncr(curNextRead);\n    }\n\n    if (nextRead == nextWrite && !finished) {\n      //System.out.println(\"  skip write slot=\" + nextWrite);\n      nextWrite = rollIncr(nextWrite);\n    }\n\n    if (matchOutput != null) {\n      //System.out.println(\"  add matchLength=\" + matchInputLength + \" output=\" + matchOutput);\n      inputSkipCount = matchInputLength;\n      addOutput(matchOutput, matchInputLength, matchEndOffset);\n    } else if (nextRead != nextWrite) {\n      // Even though we had no match here, we set to 1\n      // because we need to skip current input token before\n      // trying to match again:\n      inputSkipCount = 1;\n    } else {\n      assert finished;\n    }\n\n    //System.out.println(\"  parse done inputSkipCount=\" + inputSkipCount + \" nextRead=\" + nextRead + \" nextWrite=\" + nextWrite);\n  }\n\n","sourceOld":"  private void parse() throws IOException {\n    //System.out.println(\"\\nS: parse\");\n\n    assert inputSkipCount == 0;\n\n    int curNextRead = nextRead;\n\n    // Holds the longest match we've seen so far:\n    BytesRef matchOutput = null;\n    int matchInputLength = 0;\n    int matchEndOffset = -1;\n\n    BytesRef pendingOutput = fst.outputs.getNoOutput();\n    fst.getFirstArc(scratchArc);\n\n    assert scratchArc.output == fst.outputs.getNoOutput();\n\n    int tokenCount = 0;\n\n    byToken:\n    while(true) {\n      \n      // Pull next token's chars:\n      final char[] buffer;\n      final int bufferLen;\n      //System.out.println(\"  cycle nextRead=\" + curNextRead + \" nextWrite=\" + nextWrite);\n\n      int inputEndOffset = 0;\n\n      if (curNextRead == nextWrite) {\n\n        // We used up our lookahead buffer of input tokens\n        // -- pull next real input token:\n\n        if (finished) {\n          break;\n        } else  {\n          //System.out.println(\"  input.incrToken\");\n          assert futureInputs[nextWrite].consumed;\n          // Not correct: a syn match whose output is longer\n          // than its input can set future inputs keepOrig\n          // to true:\n          //assert !futureInputs[nextWrite].keepOrig;\n          if (input.incrementToken()) {\n            buffer = termAtt.buffer();\n            bufferLen = termAtt.length();\n            final PendingInput input = futureInputs[nextWrite];\n            input.startOffset = offsetAtt.startOffset();\n            input.endOffset = offsetAtt.endOffset();\n            inputEndOffset = input.endOffset;\n            //System.out.println(\"  new token=\" + new String(buffer, 0, bufferLen));\n            if (nextRead != nextWrite) {\n              capture();\n            } else {\n              input.consumed = false;\n            }\n\n          } else {\n            // No more input tokens\n            //System.out.println(\"      set end\");\n            finished = true;\n            break;\n          }\n        }\n      } else {\n        // Still in our lookahead\n        buffer = futureInputs[curNextRead].term.chars;\n        bufferLen = futureInputs[curNextRead].term.length;\n        inputEndOffset = futureInputs[curNextRead].endOffset;\n        //System.out.println(\"  old token=\" + new String(buffer, 0, bufferLen));\n      }\n\n      tokenCount++;\n\n      // Run each char in this token through the FST:\n      int bufUpto = 0;\n      while(bufUpto < bufferLen) {\n        final int codePoint = Character.codePointAt(buffer, bufUpto, bufferLen);\n        if (fst.findTargetArc(ignoreCase ? Character.toLowerCase(codePoint) : codePoint, scratchArc, scratchArc) == null) {\n          //System.out.println(\"    stop\");\n          break byToken;\n        }\n\n        // Accum the output\n        pendingOutput = fst.outputs.add(pendingOutput, scratchArc.output);\n        //System.out.println(\"    char=\" + buffer[bufUpto] + \" output=\" + pendingOutput + \" arc.output=\" + scratchArc.output);\n        bufUpto += Character.charCount(codePoint);\n      }\n\n      // OK, entire token matched; now see if this is a final\n      // state:\n      if (scratchArc.isFinal()) {\n        matchOutput = fst.outputs.add(pendingOutput, scratchArc.nextFinalOutput);\n        matchInputLength = tokenCount;\n        matchEndOffset = inputEndOffset;\n        //System.out.println(\"  found matchLength=\" + matchInputLength + \" output=\" + matchOutput);\n      }\n\n      // See if the FST wants to continue matching (ie, needs to\n      // see the next input token):\n      if (fst.findTargetArc(SynonymMap.WORD_SEPARATOR, scratchArc, scratchArc) == null) {\n        // No further rules can match here; we're done\n        // searching for matching rules starting at the\n        // current input position.\n        break;\n      } else {\n        // More matching is possible -- accum the output (if\n        // any) of the WORD_SEP arc:\n        pendingOutput = fst.outputs.add(pendingOutput, scratchArc.output);\n        if (nextRead == nextWrite) {\n          capture();\n        }\n      }\n\n      curNextRead = rollIncr(curNextRead);\n    }\n\n    if (nextRead == nextWrite && !finished) {\n      //System.out.println(\"  skip write slot=\" + nextWrite);\n      nextWrite = rollIncr(nextWrite);\n    }\n\n    if (matchOutput != null) {\n      //System.out.println(\"  add matchLength=\" + matchInputLength + \" output=\" + matchOutput);\n      inputSkipCount = matchInputLength;\n      addOutput(matchOutput, matchInputLength, matchEndOffset);\n    } else if (nextRead != nextWrite) {\n      // Even though we had no match here, we set to 1\n      // because we need to skip current input token before\n      // trying to match again:\n      inputSkipCount = 1;\n    } else {\n      assert finished;\n    }\n\n    //System.out.println(\"  parse done inputSkipCount=\" + inputSkipCount + \" nextRead=\" + nextRead + \" nextWrite=\" + nextWrite);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7c49a1b0f95bf8ecc502e6d44d79e4809dbf8ee","date":1328050915,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter#parse().mjava","pathOld":"modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter#parse().mjava","sourceNew":"  private void parse() throws IOException {\n    //System.out.println(\"\\nS: parse\");\n\n    assert inputSkipCount == 0;\n\n    int curNextRead = nextRead;\n\n    // Holds the longest match we've seen so far:\n    BytesRef matchOutput = null;\n    int matchInputLength = 0;\n    int matchEndOffset = -1;\n\n    BytesRef pendingOutput = fst.outputs.getNoOutput();\n    fst.getFirstArc(scratchArc);\n\n    assert scratchArc.output == fst.outputs.getNoOutput();\n\n    int tokenCount = 0;\n\n    byToken:\n    while(true) {\n      \n      // Pull next token's chars:\n      final char[] buffer;\n      final int bufferLen;\n      //System.out.println(\"  cycle nextRead=\" + curNextRead + \" nextWrite=\" + nextWrite);\n\n      int inputEndOffset = 0;\n\n      if (curNextRead == nextWrite) {\n\n        // We used up our lookahead buffer of input tokens\n        // -- pull next real input token:\n\n        if (finished) {\n          break;\n        } else  {\n          //System.out.println(\"  input.incrToken\");\n          assert futureInputs[nextWrite].consumed;\n          // Not correct: a syn match whose output is longer\n          // than its input can set future inputs keepOrig\n          // to true:\n          //assert !futureInputs[nextWrite].keepOrig;\n          if (input.incrementToken()) {\n            buffer = termAtt.buffer();\n            bufferLen = termAtt.length();\n            final PendingInput input = futureInputs[nextWrite];\n            lastStartOffset = input.startOffset = offsetAtt.startOffset();\n            lastEndOffset = input.endOffset = offsetAtt.endOffset();\n            inputEndOffset = input.endOffset;\n            //System.out.println(\"  new token=\" + new String(buffer, 0, bufferLen));\n            if (nextRead != nextWrite) {\n              capture();\n            } else {\n              input.consumed = false;\n            }\n\n          } else {\n            // No more input tokens\n            //System.out.println(\"      set end\");\n            finished = true;\n            break;\n          }\n        }\n      } else {\n        // Still in our lookahead\n        buffer = futureInputs[curNextRead].term.chars;\n        bufferLen = futureInputs[curNextRead].term.length;\n        inputEndOffset = futureInputs[curNextRead].endOffset;\n        //System.out.println(\"  old token=\" + new String(buffer, 0, bufferLen));\n      }\n\n      tokenCount++;\n\n      // Run each char in this token through the FST:\n      int bufUpto = 0;\n      while(bufUpto < bufferLen) {\n        final int codePoint = Character.codePointAt(buffer, bufUpto, bufferLen);\n        if (fst.findTargetArc(ignoreCase ? Character.toLowerCase(codePoint) : codePoint, scratchArc, scratchArc, fstReader) == null) {\n          //System.out.println(\"    stop\");\n          break byToken;\n        }\n\n        // Accum the output\n        pendingOutput = fst.outputs.add(pendingOutput, scratchArc.output);\n        //System.out.println(\"    char=\" + buffer[bufUpto] + \" output=\" + pendingOutput + \" arc.output=\" + scratchArc.output);\n        bufUpto += Character.charCount(codePoint);\n      }\n\n      // OK, entire token matched; now see if this is a final\n      // state:\n      if (scratchArc.isFinal()) {\n        matchOutput = fst.outputs.add(pendingOutput, scratchArc.nextFinalOutput);\n        matchInputLength = tokenCount;\n        matchEndOffset = inputEndOffset;\n        //System.out.println(\"  found matchLength=\" + matchInputLength + \" output=\" + matchOutput);\n      }\n\n      // See if the FST wants to continue matching (ie, needs to\n      // see the next input token):\n      if (fst.findTargetArc(SynonymMap.WORD_SEPARATOR, scratchArc, scratchArc, fstReader) == null) {\n        // No further rules can match here; we're done\n        // searching for matching rules starting at the\n        // current input position.\n        break;\n      } else {\n        // More matching is possible -- accum the output (if\n        // any) of the WORD_SEP arc:\n        pendingOutput = fst.outputs.add(pendingOutput, scratchArc.output);\n        if (nextRead == nextWrite) {\n          capture();\n        }\n      }\n\n      curNextRead = rollIncr(curNextRead);\n    }\n\n    if (nextRead == nextWrite && !finished) {\n      //System.out.println(\"  skip write slot=\" + nextWrite);\n      nextWrite = rollIncr(nextWrite);\n    }\n\n    if (matchOutput != null) {\n      //System.out.println(\"  add matchLength=\" + matchInputLength + \" output=\" + matchOutput);\n      inputSkipCount = matchInputLength;\n      addOutput(matchOutput, matchInputLength, matchEndOffset);\n    } else if (nextRead != nextWrite) {\n      // Even though we had no match here, we set to 1\n      // because we need to skip current input token before\n      // trying to match again:\n      inputSkipCount = 1;\n    } else {\n      assert finished;\n    }\n\n    //System.out.println(\"  parse done inputSkipCount=\" + inputSkipCount + \" nextRead=\" + nextRead + \" nextWrite=\" + nextWrite);\n  }\n\n","sourceOld":"  private void parse() throws IOException {\n    //System.out.println(\"\\nS: parse\");\n\n    assert inputSkipCount == 0;\n\n    int curNextRead = nextRead;\n\n    // Holds the longest match we've seen so far:\n    BytesRef matchOutput = null;\n    int matchInputLength = 0;\n    int matchEndOffset = -1;\n\n    BytesRef pendingOutput = fst.outputs.getNoOutput();\n    fst.getFirstArc(scratchArc);\n\n    assert scratchArc.output == fst.outputs.getNoOutput();\n\n    int tokenCount = 0;\n\n    byToken:\n    while(true) {\n      \n      // Pull next token's chars:\n      final char[] buffer;\n      final int bufferLen;\n      //System.out.println(\"  cycle nextRead=\" + curNextRead + \" nextWrite=\" + nextWrite);\n\n      int inputEndOffset = 0;\n\n      if (curNextRead == nextWrite) {\n\n        // We used up our lookahead buffer of input tokens\n        // -- pull next real input token:\n\n        if (finished) {\n          break;\n        } else  {\n          //System.out.println(\"  input.incrToken\");\n          assert futureInputs[nextWrite].consumed;\n          // Not correct: a syn match whose output is longer\n          // than its input can set future inputs keepOrig\n          // to true:\n          //assert !futureInputs[nextWrite].keepOrig;\n          if (input.incrementToken()) {\n            buffer = termAtt.buffer();\n            bufferLen = termAtt.length();\n            final PendingInput input = futureInputs[nextWrite];\n            input.startOffset = offsetAtt.startOffset();\n            input.endOffset = offsetAtt.endOffset();\n            inputEndOffset = input.endOffset;\n            //System.out.println(\"  new token=\" + new String(buffer, 0, bufferLen));\n            if (nextRead != nextWrite) {\n              capture();\n            } else {\n              input.consumed = false;\n            }\n\n          } else {\n            // No more input tokens\n            //System.out.println(\"      set end\");\n            finished = true;\n            break;\n          }\n        }\n      } else {\n        // Still in our lookahead\n        buffer = futureInputs[curNextRead].term.chars;\n        bufferLen = futureInputs[curNextRead].term.length;\n        inputEndOffset = futureInputs[curNextRead].endOffset;\n        //System.out.println(\"  old token=\" + new String(buffer, 0, bufferLen));\n      }\n\n      tokenCount++;\n\n      // Run each char in this token through the FST:\n      int bufUpto = 0;\n      while(bufUpto < bufferLen) {\n        final int codePoint = Character.codePointAt(buffer, bufUpto, bufferLen);\n        if (fst.findTargetArc(ignoreCase ? Character.toLowerCase(codePoint) : codePoint, scratchArc, scratchArc, fstReader) == null) {\n          //System.out.println(\"    stop\");\n          break byToken;\n        }\n\n        // Accum the output\n        pendingOutput = fst.outputs.add(pendingOutput, scratchArc.output);\n        //System.out.println(\"    char=\" + buffer[bufUpto] + \" output=\" + pendingOutput + \" arc.output=\" + scratchArc.output);\n        bufUpto += Character.charCount(codePoint);\n      }\n\n      // OK, entire token matched; now see if this is a final\n      // state:\n      if (scratchArc.isFinal()) {\n        matchOutput = fst.outputs.add(pendingOutput, scratchArc.nextFinalOutput);\n        matchInputLength = tokenCount;\n        matchEndOffset = inputEndOffset;\n        //System.out.println(\"  found matchLength=\" + matchInputLength + \" output=\" + matchOutput);\n      }\n\n      // See if the FST wants to continue matching (ie, needs to\n      // see the next input token):\n      if (fst.findTargetArc(SynonymMap.WORD_SEPARATOR, scratchArc, scratchArc, fstReader) == null) {\n        // No further rules can match here; we're done\n        // searching for matching rules starting at the\n        // current input position.\n        break;\n      } else {\n        // More matching is possible -- accum the output (if\n        // any) of the WORD_SEP arc:\n        pendingOutput = fst.outputs.add(pendingOutput, scratchArc.output);\n        if (nextRead == nextWrite) {\n          capture();\n        }\n      }\n\n      curNextRead = rollIncr(curNextRead);\n    }\n\n    if (nextRead == nextWrite && !finished) {\n      //System.out.println(\"  skip write slot=\" + nextWrite);\n      nextWrite = rollIncr(nextWrite);\n    }\n\n    if (matchOutput != null) {\n      //System.out.println(\"  add matchLength=\" + matchInputLength + \" output=\" + matchOutput);\n      inputSkipCount = matchInputLength;\n      addOutput(matchOutput, matchInputLength, matchEndOffset);\n    } else if (nextRead != nextWrite) {\n      // Even though we had no match here, we set to 1\n      // because we need to skip current input token before\n      // trying to match again:\n      inputSkipCount = 1;\n    } else {\n      assert finished;\n    }\n\n    //System.out.println(\"  parse done inputSkipCount=\" + inputSkipCount + \" nextRead=\" + nextRead + \" nextWrite=\" + nextWrite);\n  }\n\n","bugFix":["44d6f0ab53c1962856b9f48dedb7a2a6cc18905c"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter#parse().mjava","pathOld":"modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter#parse().mjava","sourceNew":"  private void parse() throws IOException {\n    //System.out.println(\"\\nS: parse\");\n\n    assert inputSkipCount == 0;\n\n    int curNextRead = nextRead;\n\n    // Holds the longest match we've seen so far:\n    BytesRef matchOutput = null;\n    int matchInputLength = 0;\n    int matchEndOffset = -1;\n\n    BytesRef pendingOutput = fst.outputs.getNoOutput();\n    fst.getFirstArc(scratchArc);\n\n    assert scratchArc.output == fst.outputs.getNoOutput();\n\n    int tokenCount = 0;\n\n    byToken:\n    while(true) {\n      \n      // Pull next token's chars:\n      final char[] buffer;\n      final int bufferLen;\n      //System.out.println(\"  cycle nextRead=\" + curNextRead + \" nextWrite=\" + nextWrite);\n\n      int inputEndOffset = 0;\n\n      if (curNextRead == nextWrite) {\n\n        // We used up our lookahead buffer of input tokens\n        // -- pull next real input token:\n\n        if (finished) {\n          break;\n        } else  {\n          //System.out.println(\"  input.incrToken\");\n          assert futureInputs[nextWrite].consumed;\n          // Not correct: a syn match whose output is longer\n          // than its input can set future inputs keepOrig\n          // to true:\n          //assert !futureInputs[nextWrite].keepOrig;\n          if (input.incrementToken()) {\n            buffer = termAtt.buffer();\n            bufferLen = termAtt.length();\n            final PendingInput input = futureInputs[nextWrite];\n            lastStartOffset = input.startOffset = offsetAtt.startOffset();\n            lastEndOffset = input.endOffset = offsetAtt.endOffset();\n            inputEndOffset = input.endOffset;\n            //System.out.println(\"  new token=\" + new String(buffer, 0, bufferLen));\n            if (nextRead != nextWrite) {\n              capture();\n            } else {\n              input.consumed = false;\n            }\n\n          } else {\n            // No more input tokens\n            //System.out.println(\"      set end\");\n            finished = true;\n            break;\n          }\n        }\n      } else {\n        // Still in our lookahead\n        buffer = futureInputs[curNextRead].term.chars;\n        bufferLen = futureInputs[curNextRead].term.length;\n        inputEndOffset = futureInputs[curNextRead].endOffset;\n        //System.out.println(\"  old token=\" + new String(buffer, 0, bufferLen));\n      }\n\n      tokenCount++;\n\n      // Run each char in this token through the FST:\n      int bufUpto = 0;\n      while(bufUpto < bufferLen) {\n        final int codePoint = Character.codePointAt(buffer, bufUpto, bufferLen);\n        if (fst.findTargetArc(ignoreCase ? Character.toLowerCase(codePoint) : codePoint, scratchArc, scratchArc, fstReader) == null) {\n          //System.out.println(\"    stop\");\n          break byToken;\n        }\n\n        // Accum the output\n        pendingOutput = fst.outputs.add(pendingOutput, scratchArc.output);\n        //System.out.println(\"    char=\" + buffer[bufUpto] + \" output=\" + pendingOutput + \" arc.output=\" + scratchArc.output);\n        bufUpto += Character.charCount(codePoint);\n      }\n\n      // OK, entire token matched; now see if this is a final\n      // state:\n      if (scratchArc.isFinal()) {\n        matchOutput = fst.outputs.add(pendingOutput, scratchArc.nextFinalOutput);\n        matchInputLength = tokenCount;\n        matchEndOffset = inputEndOffset;\n        //System.out.println(\"  found matchLength=\" + matchInputLength + \" output=\" + matchOutput);\n      }\n\n      // See if the FST wants to continue matching (ie, needs to\n      // see the next input token):\n      if (fst.findTargetArc(SynonymMap.WORD_SEPARATOR, scratchArc, scratchArc, fstReader) == null) {\n        // No further rules can match here; we're done\n        // searching for matching rules starting at the\n        // current input position.\n        break;\n      } else {\n        // More matching is possible -- accum the output (if\n        // any) of the WORD_SEP arc:\n        pendingOutput = fst.outputs.add(pendingOutput, scratchArc.output);\n        if (nextRead == nextWrite) {\n          capture();\n        }\n      }\n\n      curNextRead = rollIncr(curNextRead);\n    }\n\n    if (nextRead == nextWrite && !finished) {\n      //System.out.println(\"  skip write slot=\" + nextWrite);\n      nextWrite = rollIncr(nextWrite);\n    }\n\n    if (matchOutput != null) {\n      //System.out.println(\"  add matchLength=\" + matchInputLength + \" output=\" + matchOutput);\n      inputSkipCount = matchInputLength;\n      addOutput(matchOutput, matchInputLength, matchEndOffset);\n    } else if (nextRead != nextWrite) {\n      // Even though we had no match here, we set to 1\n      // because we need to skip current input token before\n      // trying to match again:\n      inputSkipCount = 1;\n    } else {\n      assert finished;\n    }\n\n    //System.out.println(\"  parse done inputSkipCount=\" + inputSkipCount + \" nextRead=\" + nextRead + \" nextWrite=\" + nextWrite);\n  }\n\n","sourceOld":"  private void parse() throws IOException {\n    //System.out.println(\"\\nS: parse\");\n\n    assert inputSkipCount == 0;\n\n    int curNextRead = nextRead;\n\n    // Holds the longest match we've seen so far:\n    BytesRef matchOutput = null;\n    int matchInputLength = 0;\n    int matchEndOffset = -1;\n\n    BytesRef pendingOutput = fst.outputs.getNoOutput();\n    fst.getFirstArc(scratchArc);\n\n    assert scratchArc.output == fst.outputs.getNoOutput();\n\n    int tokenCount = 0;\n\n    byToken:\n    while(true) {\n      \n      // Pull next token's chars:\n      final char[] buffer;\n      final int bufferLen;\n      //System.out.println(\"  cycle nextRead=\" + curNextRead + \" nextWrite=\" + nextWrite);\n\n      int inputEndOffset = 0;\n\n      if (curNextRead == nextWrite) {\n\n        // We used up our lookahead buffer of input tokens\n        // -- pull next real input token:\n\n        if (finished) {\n          break;\n        } else  {\n          //System.out.println(\"  input.incrToken\");\n          assert futureInputs[nextWrite].consumed;\n          // Not correct: a syn match whose output is longer\n          // than its input can set future inputs keepOrig\n          // to true:\n          //assert !futureInputs[nextWrite].keepOrig;\n          if (input.incrementToken()) {\n            buffer = termAtt.buffer();\n            bufferLen = termAtt.length();\n            final PendingInput input = futureInputs[nextWrite];\n            lastStartOffset = input.startOffset = offsetAtt.startOffset();\n            lastEndOffset = input.endOffset = offsetAtt.endOffset();\n            inputEndOffset = input.endOffset;\n            //System.out.println(\"  new token=\" + new String(buffer, 0, bufferLen));\n            if (nextRead != nextWrite) {\n              capture();\n            } else {\n              input.consumed = false;\n            }\n\n          } else {\n            // No more input tokens\n            //System.out.println(\"      set end\");\n            finished = true;\n            break;\n          }\n        }\n      } else {\n        // Still in our lookahead\n        buffer = futureInputs[curNextRead].term.chars;\n        bufferLen = futureInputs[curNextRead].term.length;\n        inputEndOffset = futureInputs[curNextRead].endOffset;\n        //System.out.println(\"  old token=\" + new String(buffer, 0, bufferLen));\n      }\n\n      tokenCount++;\n\n      // Run each char in this token through the FST:\n      int bufUpto = 0;\n      while(bufUpto < bufferLen) {\n        final int codePoint = Character.codePointAt(buffer, bufUpto, bufferLen);\n        if (fst.findTargetArc(ignoreCase ? Character.toLowerCase(codePoint) : codePoint, scratchArc, scratchArc, fstReader) == null) {\n          //System.out.println(\"    stop\");\n          break byToken;\n        }\n\n        // Accum the output\n        pendingOutput = fst.outputs.add(pendingOutput, scratchArc.output);\n        //System.out.println(\"    char=\" + buffer[bufUpto] + \" output=\" + pendingOutput + \" arc.output=\" + scratchArc.output);\n        bufUpto += Character.charCount(codePoint);\n      }\n\n      // OK, entire token matched; now see if this is a final\n      // state:\n      if (scratchArc.isFinal()) {\n        matchOutput = fst.outputs.add(pendingOutput, scratchArc.nextFinalOutput);\n        matchInputLength = tokenCount;\n        matchEndOffset = inputEndOffset;\n        //System.out.println(\"  found matchLength=\" + matchInputLength + \" output=\" + matchOutput);\n      }\n\n      // See if the FST wants to continue matching (ie, needs to\n      // see the next input token):\n      if (fst.findTargetArc(SynonymMap.WORD_SEPARATOR, scratchArc, scratchArc, fstReader) == null) {\n        // No further rules can match here; we're done\n        // searching for matching rules starting at the\n        // current input position.\n        break;\n      } else {\n        // More matching is possible -- accum the output (if\n        // any) of the WORD_SEP arc:\n        pendingOutput = fst.outputs.add(pendingOutput, scratchArc.output);\n        if (nextRead == nextWrite) {\n          capture();\n        }\n      }\n\n      curNextRead = rollIncr(curNextRead);\n    }\n\n    if (nextRead == nextWrite && !finished) {\n      //System.out.println(\"  skip write slot=\" + nextWrite);\n      nextWrite = rollIncr(nextWrite);\n    }\n\n    if (matchOutput != null) {\n      //System.out.println(\"  add matchLength=\" + matchInputLength + \" output=\" + matchOutput);\n      inputSkipCount = matchInputLength;\n      addOutput(matchOutput, matchInputLength, matchEndOffset);\n    } else if (nextRead != nextWrite) {\n      // Even though we had no match here, we set to 1\n      // because we need to skip current input token before\n      // trying to match again:\n      inputSkipCount = 1;\n    } else {\n      assert finished;\n    }\n\n    //System.out.println(\"  parse done inputSkipCount=\" + inputSkipCount + \" nextRead=\" + nextRead + \" nextWrite=\" + nextWrite);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["b7c49a1b0f95bf8ecc502e6d44d79e4809dbf8ee"],"865b7d0f8430a08d385370b6b87a89a737aa6145":["de11853c992f764e52d4164cc9afdebb989dba8a"],"de11853c992f764e52d4164cc9afdebb989dba8a":["44d6f0ab53c1962856b9f48dedb7a2a6cc18905c"],"b3be20ca1091c0b7cdb2308b9023606a5e451cec":["865b7d0f8430a08d385370b6b87a89a737aa6145"],"817882884229bace7dc5d1b75f6b0e4aa1e47122":["865b7d0f8430a08d385370b6b87a89a737aa6145","b3be20ca1091c0b7cdb2308b9023606a5e451cec"],"b7c49a1b0f95bf8ecc502e6d44d79e4809dbf8ee":["b3be20ca1091c0b7cdb2308b9023606a5e451cec"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"5b6fdfce35d0adb18836cf8711abe487a934df33":["865b7d0f8430a08d385370b6b87a89a737aa6145","b3be20ca1091c0b7cdb2308b9023606a5e451cec"],"44d6f0ab53c1962856b9f48dedb7a2a6cc18905c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b89678825b68eccaf09e6ab71675fc0b0af1e099"]},"commit2Childs":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"865b7d0f8430a08d385370b6b87a89a737aa6145":["b3be20ca1091c0b7cdb2308b9023606a5e451cec","817882884229bace7dc5d1b75f6b0e4aa1e47122","5b6fdfce35d0adb18836cf8711abe487a934df33"],"de11853c992f764e52d4164cc9afdebb989dba8a":["865b7d0f8430a08d385370b6b87a89a737aa6145"],"b3be20ca1091c0b7cdb2308b9023606a5e451cec":["817882884229bace7dc5d1b75f6b0e4aa1e47122","b7c49a1b0f95bf8ecc502e6d44d79e4809dbf8ee","5b6fdfce35d0adb18836cf8711abe487a934df33"],"817882884229bace7dc5d1b75f6b0e4aa1e47122":[],"b7c49a1b0f95bf8ecc502e6d44d79e4809dbf8ee":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["44d6f0ab53c1962856b9f48dedb7a2a6cc18905c"],"5b6fdfce35d0adb18836cf8711abe487a934df33":[],"44d6f0ab53c1962856b9f48dedb7a2a6cc18905c":["de11853c992f764e52d4164cc9afdebb989dba8a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["817882884229bace7dc5d1b75f6b0e4aa1e47122","5b6fdfce35d0adb18836cf8711abe487a934df33","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}