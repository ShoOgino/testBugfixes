{"path":"solr/core/src/test/org/apache/solr/cloud/TestTolerantUpdateProcessorRandomCloud#testRandomUpdates().mjava","commits":[{"id":"f57cf082c4d2ee975c6a2034fcf3c13f9514e6ef","date":1458928975,"type":0,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestTolerantUpdateProcessorRandomCloud#testRandomUpdates().mjava","pathOld":"/dev/null","sourceNew":"  public void testRandomUpdates() throws Exception {\n    final int maxDocId = atLeast(10000);\n    final BitSet expectedDocIds = new BitSet(maxDocId+1);\n    \n    final int numIters = atLeast(50);\n    for (int i = 0; i < numIters; i++) {\n\n      log.info(\"BEGIN ITER #{}\", i);\n      \n      final UpdateRequest req = update(params(\"maxErrors\",\"-1\",\n                                              \"update.chain\", \"tolerant-chain-max-errors-10\"));\n      final int numCmds = TestUtil.nextInt(random(), 1, 20);\n      final List<ExpectedErr> expectedErrors = new ArrayList<ExpectedErr>(numCmds);\n      int expectedErrorsCount = 0;\n      // it's ambigious/confusing which order mixed DELQ + ADD  (or ADD and DELI for the same ID)\n      // in the same request wll be processed by various clients, so we keep things simple\n      // and ensure that no single doc Id is affected by more then one command in the same request\n      final BitSet docsAffectedThisRequest = new BitSet(maxDocId+1);\n      for (int cmdIter = 0; cmdIter < numCmds; cmdIter++) {\n        if ((maxDocId / 2) < docsAffectedThisRequest.cardinality()) {\n          // we're already mucking with more then half the docs in the index\n          break;\n        }\n\n        final boolean causeError = random().nextBoolean();\n        if (causeError) {\n          expectedErrorsCount++;\n        }\n        \n        if (random().nextBoolean()) {\n          // add a doc\n          String id = null;\n          SolrInputDocument doc = null;\n          if (causeError && (0 == TestUtil.nextInt(random(), 0, 21))) {\n            doc = doc(f(\"foo_s\",\"no unique key\"));\n            expectedErrors.add(addErr(\"(unknown)\"));\n          } else {\n            final int id_i = randomUnsetBit(random(), docsAffectedThisRequest, maxDocId);\n            docsAffectedThisRequest.set(id_i);\n            id = \"id_\"+id_i;\n            if (causeError) {\n              expectedErrors.add(addErr(id));\n            } else {\n              expectedDocIds.set(id_i);\n            }\n            final String val = causeError ? \"bogus_val\" : (\"\"+TestUtil.nextInt(random(), 42, 666));\n            doc = doc(f(\"id\",id),\n                      f(\"id_i\", id_i),\n                      f(\"foo_i\", val));\n          }\n          req.add(doc);\n          log.info(\"ADD: {} = {}\", id, doc);\n        } else {\n          // delete something\n          if (random().nextBoolean()) {\n            // delete by id\n            final int id_i = randomUnsetBit(random(), docsAffectedThisRequest, maxDocId);\n            final String id = \"id_\"+id_i;\n            final boolean docExists = expectedDocIds.get(id_i);\n            docsAffectedThisRequest.set(id_i);\n            long versionConstraint = docExists ? 1 : -1;\n            if (causeError) {\n              versionConstraint = -1 * versionConstraint;\n              expectedErrors.add(delIErr(id));\n            } else {\n              // if doc exists it will legitimately be deleted\n              expectedDocIds.clear(id_i);\n            }\n            req.deleteById(id, versionConstraint);\n            log.info(\"DEL: {} = {}\", id, causeError ? \"ERR\" : \"OK\" );\n          } else {\n            // delete by query\n            final String q;\n            if (causeError) {\n              // even though our DBQ is gibberish that's going to fail, record a docId as affected\n              // so that we don't generate the same random DBQ and get redundent errors\n              // (problematic because of how DUP forwarded DBQs have to have their errors deduped by TUP)\n              final int id_i = randomUnsetBit(random(), docsAffectedThisRequest, maxDocId);\n              docsAffectedThisRequest.set(id_i);\n              q = \"foo_i:[\"+id_i+\" TO ....giberish\";\n              expectedErrors.add(delQErr(q));\n            } else {\n              // ensure our DBQ is only over a range of docs not already affected\n              // by any other cmds in this request\n              final int rangeAxis = randomUnsetBit(random(), docsAffectedThisRequest, maxDocId);\n              final int loBound = docsAffectedThisRequest.previousSetBit(rangeAxis);\n              final int hiBound = docsAffectedThisRequest.nextSetBit(rangeAxis);\n              final int lo = TestUtil.nextInt(random(), loBound+1, rangeAxis);\n              final int hi = TestUtil.nextInt(random(), rangeAxis,\n                                              // bound might be negative if no set bits above axis\n                                              (hiBound < 0) ? maxDocId : hiBound-1);\n\n              if (lo != hi) {\n                assert lo < hi : \"lo=\"+lo+\" hi=\"+hi;\n                // NOTE: clear & set are exclusive of hi, so we use \"}\" in range query accordingly\n                q = \"id_i:[\" + lo + \" TO \" + hi + \"}\";\n                expectedDocIds.clear(lo, hi);\n                docsAffectedThisRequest.set(lo, hi);\n              } else {\n                // edge case: special case DBQ of one doc\n                assert (lo == rangeAxis && hi == rangeAxis) : \"lo=\"+lo+\" axis=\"+rangeAxis+\" hi=\"+hi;\n                q = \"id_i:[\" + lo + \" TO \" + lo + \"]\"; // have to be inclusive of both ends\n                expectedDocIds.clear(lo);\n                docsAffectedThisRequest.set(lo);\n              }\n            }\n            req.deleteByQuery(q);\n            log.info(\"DEL: {}\", q);\n          }\n        }\n      }\n      assertEquals(\"expected error count sanity check: \" + req.toString(),\n                   expectedErrorsCount, expectedErrors.size());\n        \n      final SolrClient client = random().nextBoolean() ? CLOUD_CLIENT\n        : NODE_CLIENTS.get(TestUtil.nextInt(random(), 0, NODE_CLIENTS.size()-1));\n      \n      final UpdateResponse rsp = req.process(client);\n      assertUpdateTolerantErrors(client.toString() + \" => \" + expectedErrors.toString(), rsp,\n                                 expectedErrors.toArray(new ExpectedErr[expectedErrors.size()]));\n               \n      log.info(\"END ITER #{}, expecting #docs: {}\", i, expectedDocIds.cardinality());\n\n      assertEquals(\"post update commit failed?\", 0, CLOUD_CLIENT.commit().getStatus());\n      \n      for (int j = 0; j < 5; j++) {\n        if (expectedDocIds.cardinality() == countDocs(CLOUD_CLIENT)) {\n          break;\n        }\n        log.info(\"sleeping to give searchers a chance to re-open #\" + j);\n        Thread.sleep(200);\n      }\n\n      // check the index contents against our expecationts\n      final BitSet actualDocIds = allDocs(CLOUD_CLIENT, maxDocId);\n      if ( expectedDocIds.cardinality() != actualDocIds.cardinality() ) {\n        log.error(\"cardinality missmatch: expected {} BUT actual {}\",\n                  expectedDocIds.cardinality(),\n                  actualDocIds.cardinality());\n      }\n      final BitSet x = (BitSet) actualDocIds.clone();\n      x.xor(expectedDocIds);\n      for (int b = x.nextSetBit(0); 0 <= b; b = x.nextSetBit(b+1)) {\n        final boolean expectedBit = expectedDocIds.get(b);\n        final boolean actualBit = actualDocIds.get(b);\n        log.error(\"bit #\"+b+\" mismatch: expected {} BUT actual {}\", expectedBit, actualBit);\n      }\n      assertEquals(x.cardinality() + \" mismatched bits\",\n                   expectedDocIds.cardinality(), actualDocIds.cardinality());\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0158ced21948b6626f733c1c42c1e18d94449789","date":1462994341,"type":3,"author":"Bartosz KrasiÅ„ski","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestTolerantUpdateProcessorRandomCloud#testRandomUpdates().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestTolerantUpdateProcessorRandomCloud#testRandomUpdates().mjava","sourceNew":"  public void testRandomUpdates() throws Exception {\n    final int maxDocId = atLeast(10000);\n    final BitSet expectedDocIds = new BitSet(maxDocId+1);\n    \n    final int numIters = atLeast(50);\n    for (int i = 0; i < numIters; i++) {\n\n      log.info(\"BEGIN ITER #{}\", i);\n      \n      final UpdateRequest req = update(params(\"maxErrors\",\"-1\",\n                                              \"update.chain\", \"tolerant-chain-max-errors-10\"));\n      final int numCmds = TestUtil.nextInt(random(), 1, 20);\n      final List<ExpectedErr> expectedErrors = new ArrayList<ExpectedErr>(numCmds);\n      int expectedErrorsCount = 0;\n      // it's ambigious/confusing which order mixed DELQ + ADD  (or ADD and DELI for the same ID)\n      // in the same request wll be processed by various clients, so we keep things simple\n      // and ensure that no single doc Id is affected by more then one command in the same request\n      final BitSet docsAffectedThisRequest = new BitSet(maxDocId+1);\n      for (int cmdIter = 0; cmdIter < numCmds; cmdIter++) {\n        if ((maxDocId / 2) < docsAffectedThisRequest.cardinality()) {\n          // we're already mucking with more then half the docs in the index\n          break;\n        }\n\n        final boolean causeError = random().nextBoolean();\n        if (causeError) {\n          expectedErrorsCount++;\n        }\n        \n        if (random().nextBoolean()) {\n          // add a doc\n          String id = null;\n          SolrInputDocument doc = null;\n          if (causeError && (0 == TestUtil.nextInt(random(), 0, 21))) {\n            doc = doc(f(\"foo_s\",\"no unique key\"));\n            expectedErrors.add(addErr(\"(unknown)\"));\n          } else {\n            final int id_i = randomUnsetBit(random(), docsAffectedThisRequest, maxDocId);\n            docsAffectedThisRequest.set(id_i);\n            id = \"id_\"+id_i;\n            if (causeError) {\n              expectedErrors.add(addErr(id));\n            } else {\n              expectedDocIds.set(id_i);\n            }\n            final String val = causeError ? \"bogus_val\" : (\"\"+TestUtil.nextInt(random(), 42, 666));\n            doc = doc(f(\"id\",id),\n                      f(\"id_i\", id_i),\n                      f(\"foo_i\", val));\n          }\n          req.add(doc);\n          log.info(\"ADD: {} = {}\", id, doc);\n        } else {\n          // delete something\n          if (random().nextBoolean()) {\n            // delete by id\n            final int id_i = randomUnsetBit(random(), docsAffectedThisRequest, maxDocId);\n            final String id = \"id_\"+id_i;\n            final boolean docExists = expectedDocIds.get(id_i);\n            docsAffectedThisRequest.set(id_i);\n            long versionConstraint = docExists ? 1 : -1;\n            if (causeError) {\n              versionConstraint = -1 * versionConstraint;\n              expectedErrors.add(delIErr(id));\n            } else {\n              // if doc exists it will legitimately be deleted\n              expectedDocIds.clear(id_i);\n            }\n            req.deleteById(id, versionConstraint);\n            log.info(\"DEL: {} = {}\", id, causeError ? \"ERR\" : \"OK\" );\n          } else {\n            // delete by query\n            final String q;\n            if (causeError) {\n              // even though our DBQ is gibberish that's going to fail, record a docId as affected\n              // so that we don't generate the same random DBQ and get redundent errors\n              // (problematic because of how DUP forwarded DBQs have to have their errors deduped by TUP)\n              final int id_i = randomUnsetBit(random(), docsAffectedThisRequest, maxDocId);\n              docsAffectedThisRequest.set(id_i);\n              q = \"foo_i:[\"+id_i+\" TO ....giberish\";\n              expectedErrors.add(delQErr(q));\n            } else {\n              // ensure our DBQ is only over a range of docs not already affected\n              // by any other cmds in this request\n              final int rangeAxis = randomUnsetBit(random(), docsAffectedThisRequest, maxDocId);\n              final int loBound = docsAffectedThisRequest.previousSetBit(rangeAxis);\n              final int hiBound = docsAffectedThisRequest.nextSetBit(rangeAxis);\n              final int lo = TestUtil.nextInt(random(), loBound+1, rangeAxis);\n              final int hi = TestUtil.nextInt(random(), rangeAxis,\n                                              // bound might be negative if no set bits above axis\n                                              (hiBound < 0) ? maxDocId : hiBound-1);\n\n              if (lo != hi) {\n                assert lo < hi : \"lo=\"+lo+\" hi=\"+hi;\n                // NOTE: clear & set are exclusive of hi, so we use \"}\" in range query accordingly\n                q = \"id_i:[\" + lo + \" TO \" + hi + \"}\";\n                expectedDocIds.clear(lo, hi);\n                docsAffectedThisRequest.set(lo, hi);\n              } else {\n                // edge case: special case DBQ of one doc\n                assert (lo == rangeAxis && hi == rangeAxis) : \"lo=\"+lo+\" axis=\"+rangeAxis+\" hi=\"+hi;\n                q = \"id_i:[\" + lo + \" TO \" + lo + \"]\"; // have to be inclusive of both ends\n                expectedDocIds.clear(lo);\n                docsAffectedThisRequest.set(lo);\n              }\n            }\n            req.deleteByQuery(q);\n            log.info(\"DEL: {}\", q);\n          }\n        }\n      }\n      assertEquals(\"expected error count sanity check: \" + req.toString(),\n                   expectedErrorsCount, expectedErrors.size());\n        \n      final SolrClient client = random().nextBoolean() ? CLOUD_CLIENT\n        : NODE_CLIENTS.get(TestUtil.nextInt(random(), 0, NODE_CLIENTS.size()-1));\n      \n      final UpdateResponse rsp = req.process(client);\n      assertUpdateTolerantErrors(client.toString() + \" => \" + expectedErrors.toString(), rsp,\n                                 expectedErrors.toArray(new ExpectedErr[expectedErrors.size()]));\n               \n      log.info(\"END ITER #{}, expecting #docs: {}\", i, expectedDocIds.cardinality());\n\n      assertEquals(\"post update commit failed?\", 0, CLOUD_CLIENT.commit().getStatus());\n      \n      for (int j = 0; j < 5; j++) {\n        if (expectedDocIds.cardinality() == countDocs(CLOUD_CLIENT)) {\n          break;\n        }\n        log.info(\"sleeping to give searchers a chance to re-open #\" + j);\n        Thread.sleep(200);\n      }\n\n      // check the index contents against our expectations\n      final BitSet actualDocIds = allDocs(CLOUD_CLIENT, maxDocId);\n      if ( expectedDocIds.cardinality() != actualDocIds.cardinality() ) {\n        log.error(\"cardinality mismatch: expected {} BUT actual {}\",\n                  expectedDocIds.cardinality(),\n                  actualDocIds.cardinality());\n      }\n      final BitSet x = (BitSet) actualDocIds.clone();\n      x.xor(expectedDocIds);\n      for (int b = x.nextSetBit(0); 0 <= b; b = x.nextSetBit(b+1)) {\n        final boolean expectedBit = expectedDocIds.get(b);\n        final boolean actualBit = actualDocIds.get(b);\n        log.error(\"bit #\"+b+\" mismatch: expected {} BUT actual {}\", expectedBit, actualBit);\n      }\n      assertEquals(x.cardinality() + \" mismatched bits\",\n                   expectedDocIds.cardinality(), actualDocIds.cardinality());\n    }\n  }\n\n","sourceOld":"  public void testRandomUpdates() throws Exception {\n    final int maxDocId = atLeast(10000);\n    final BitSet expectedDocIds = new BitSet(maxDocId+1);\n    \n    final int numIters = atLeast(50);\n    for (int i = 0; i < numIters; i++) {\n\n      log.info(\"BEGIN ITER #{}\", i);\n      \n      final UpdateRequest req = update(params(\"maxErrors\",\"-1\",\n                                              \"update.chain\", \"tolerant-chain-max-errors-10\"));\n      final int numCmds = TestUtil.nextInt(random(), 1, 20);\n      final List<ExpectedErr> expectedErrors = new ArrayList<ExpectedErr>(numCmds);\n      int expectedErrorsCount = 0;\n      // it's ambigious/confusing which order mixed DELQ + ADD  (or ADD and DELI for the same ID)\n      // in the same request wll be processed by various clients, so we keep things simple\n      // and ensure that no single doc Id is affected by more then one command in the same request\n      final BitSet docsAffectedThisRequest = new BitSet(maxDocId+1);\n      for (int cmdIter = 0; cmdIter < numCmds; cmdIter++) {\n        if ((maxDocId / 2) < docsAffectedThisRequest.cardinality()) {\n          // we're already mucking with more then half the docs in the index\n          break;\n        }\n\n        final boolean causeError = random().nextBoolean();\n        if (causeError) {\n          expectedErrorsCount++;\n        }\n        \n        if (random().nextBoolean()) {\n          // add a doc\n          String id = null;\n          SolrInputDocument doc = null;\n          if (causeError && (0 == TestUtil.nextInt(random(), 0, 21))) {\n            doc = doc(f(\"foo_s\",\"no unique key\"));\n            expectedErrors.add(addErr(\"(unknown)\"));\n          } else {\n            final int id_i = randomUnsetBit(random(), docsAffectedThisRequest, maxDocId);\n            docsAffectedThisRequest.set(id_i);\n            id = \"id_\"+id_i;\n            if (causeError) {\n              expectedErrors.add(addErr(id));\n            } else {\n              expectedDocIds.set(id_i);\n            }\n            final String val = causeError ? \"bogus_val\" : (\"\"+TestUtil.nextInt(random(), 42, 666));\n            doc = doc(f(\"id\",id),\n                      f(\"id_i\", id_i),\n                      f(\"foo_i\", val));\n          }\n          req.add(doc);\n          log.info(\"ADD: {} = {}\", id, doc);\n        } else {\n          // delete something\n          if (random().nextBoolean()) {\n            // delete by id\n            final int id_i = randomUnsetBit(random(), docsAffectedThisRequest, maxDocId);\n            final String id = \"id_\"+id_i;\n            final boolean docExists = expectedDocIds.get(id_i);\n            docsAffectedThisRequest.set(id_i);\n            long versionConstraint = docExists ? 1 : -1;\n            if (causeError) {\n              versionConstraint = -1 * versionConstraint;\n              expectedErrors.add(delIErr(id));\n            } else {\n              // if doc exists it will legitimately be deleted\n              expectedDocIds.clear(id_i);\n            }\n            req.deleteById(id, versionConstraint);\n            log.info(\"DEL: {} = {}\", id, causeError ? \"ERR\" : \"OK\" );\n          } else {\n            // delete by query\n            final String q;\n            if (causeError) {\n              // even though our DBQ is gibberish that's going to fail, record a docId as affected\n              // so that we don't generate the same random DBQ and get redundent errors\n              // (problematic because of how DUP forwarded DBQs have to have their errors deduped by TUP)\n              final int id_i = randomUnsetBit(random(), docsAffectedThisRequest, maxDocId);\n              docsAffectedThisRequest.set(id_i);\n              q = \"foo_i:[\"+id_i+\" TO ....giberish\";\n              expectedErrors.add(delQErr(q));\n            } else {\n              // ensure our DBQ is only over a range of docs not already affected\n              // by any other cmds in this request\n              final int rangeAxis = randomUnsetBit(random(), docsAffectedThisRequest, maxDocId);\n              final int loBound = docsAffectedThisRequest.previousSetBit(rangeAxis);\n              final int hiBound = docsAffectedThisRequest.nextSetBit(rangeAxis);\n              final int lo = TestUtil.nextInt(random(), loBound+1, rangeAxis);\n              final int hi = TestUtil.nextInt(random(), rangeAxis,\n                                              // bound might be negative if no set bits above axis\n                                              (hiBound < 0) ? maxDocId : hiBound-1);\n\n              if (lo != hi) {\n                assert lo < hi : \"lo=\"+lo+\" hi=\"+hi;\n                // NOTE: clear & set are exclusive of hi, so we use \"}\" in range query accordingly\n                q = \"id_i:[\" + lo + \" TO \" + hi + \"}\";\n                expectedDocIds.clear(lo, hi);\n                docsAffectedThisRequest.set(lo, hi);\n              } else {\n                // edge case: special case DBQ of one doc\n                assert (lo == rangeAxis && hi == rangeAxis) : \"lo=\"+lo+\" axis=\"+rangeAxis+\" hi=\"+hi;\n                q = \"id_i:[\" + lo + \" TO \" + lo + \"]\"; // have to be inclusive of both ends\n                expectedDocIds.clear(lo);\n                docsAffectedThisRequest.set(lo);\n              }\n            }\n            req.deleteByQuery(q);\n            log.info(\"DEL: {}\", q);\n          }\n        }\n      }\n      assertEquals(\"expected error count sanity check: \" + req.toString(),\n                   expectedErrorsCount, expectedErrors.size());\n        \n      final SolrClient client = random().nextBoolean() ? CLOUD_CLIENT\n        : NODE_CLIENTS.get(TestUtil.nextInt(random(), 0, NODE_CLIENTS.size()-1));\n      \n      final UpdateResponse rsp = req.process(client);\n      assertUpdateTolerantErrors(client.toString() + \" => \" + expectedErrors.toString(), rsp,\n                                 expectedErrors.toArray(new ExpectedErr[expectedErrors.size()]));\n               \n      log.info(\"END ITER #{}, expecting #docs: {}\", i, expectedDocIds.cardinality());\n\n      assertEquals(\"post update commit failed?\", 0, CLOUD_CLIENT.commit().getStatus());\n      \n      for (int j = 0; j < 5; j++) {\n        if (expectedDocIds.cardinality() == countDocs(CLOUD_CLIENT)) {\n          break;\n        }\n        log.info(\"sleeping to give searchers a chance to re-open #\" + j);\n        Thread.sleep(200);\n      }\n\n      // check the index contents against our expecationts\n      final BitSet actualDocIds = allDocs(CLOUD_CLIENT, maxDocId);\n      if ( expectedDocIds.cardinality() != actualDocIds.cardinality() ) {\n        log.error(\"cardinality missmatch: expected {} BUT actual {}\",\n                  expectedDocIds.cardinality(),\n                  actualDocIds.cardinality());\n      }\n      final BitSet x = (BitSet) actualDocIds.clone();\n      x.xor(expectedDocIds);\n      for (int b = x.nextSetBit(0); 0 <= b; b = x.nextSetBit(b+1)) {\n        final boolean expectedBit = expectedDocIds.get(b);\n        final boolean actualBit = actualDocIds.get(b);\n        log.error(\"bit #\"+b+\" mismatch: expected {} BUT actual {}\", expectedBit, actualBit);\n      }\n      assertEquals(x.cardinality() + \" mismatched bits\",\n                   expectedDocIds.cardinality(), actualDocIds.cardinality());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d470c8182e92b264680e34081b75e70a9f2b3c89","date":1463985353,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestTolerantUpdateProcessorRandomCloud#testRandomUpdates().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestTolerantUpdateProcessorRandomCloud#testRandomUpdates().mjava","sourceNew":"  public void testRandomUpdates() throws Exception {\n    final int maxDocId = atLeast(10000);\n    final BitSet expectedDocIds = new BitSet(maxDocId+1);\n    \n    final int numIters = atLeast(50);\n    for (int i = 0; i < numIters; i++) {\n\n      log.info(\"BEGIN ITER #{}\", i);\n      \n      final UpdateRequest req = update(params(\"maxErrors\",\"-1\",\n                                              \"update.chain\", \"tolerant-chain-max-errors-10\"));\n      final int numCmds = TestUtil.nextInt(random(), 1, 20);\n      final List<ExpectedErr> expectedErrors = new ArrayList<ExpectedErr>(numCmds);\n      int expectedErrorsCount = 0;\n      // it's ambigious/confusing which order mixed DELQ + ADD  (or ADD and DELI for the same ID)\n      // in the same request wll be processed by various clients, so we keep things simple\n      // and ensure that no single doc Id is affected by more then one command in the same request\n      final BitSet docsAffectedThisRequest = new BitSet(maxDocId+1);\n      for (int cmdIter = 0; cmdIter < numCmds; cmdIter++) {\n        if ((maxDocId / 2) < docsAffectedThisRequest.cardinality()) {\n          // we're already mucking with more then half the docs in the index\n          break;\n        }\n\n        final boolean causeError = random().nextBoolean();\n        if (causeError) {\n          expectedErrorsCount++;\n        }\n        \n        if (random().nextBoolean()) {\n          // add a doc\n          String id = null;\n          SolrInputDocument doc = null;\n          if (causeError && (0 == TestUtil.nextInt(random(), 0, 21))) {\n            doc = doc(f(\"foo_s\",\"no unique key\"));\n            expectedErrors.add(addErr(\"(unknown)\"));\n          } else {\n            final int id_i = randomUnsetBit(random(), docsAffectedThisRequest, maxDocId);\n            docsAffectedThisRequest.set(id_i);\n            id = \"id_\"+id_i;\n            if (causeError) {\n              expectedErrors.add(addErr(id));\n            } else {\n              expectedDocIds.set(id_i);\n            }\n            final String val = causeError ? \"bogus_val\" : (\"\"+TestUtil.nextInt(random(), 42, 666));\n            doc = doc(f(\"id\",id),\n                      f(\"id_i\", id_i),\n                      f(\"foo_i\", val));\n          }\n          req.add(doc);\n          log.info(\"ADD: {} = {}\", id, doc);\n        } else {\n          // delete something\n          if (random().nextBoolean()) {\n            // delete by id\n            final int id_i = randomUnsetBit(random(), docsAffectedThisRequest, maxDocId);\n            final String id = \"id_\"+id_i;\n            final boolean docExists = expectedDocIds.get(id_i);\n            docsAffectedThisRequest.set(id_i);\n            long versionConstraint = docExists ? 1 : -1;\n            if (causeError) {\n              versionConstraint = -1 * versionConstraint;\n              expectedErrors.add(delIErr(id));\n            } else {\n              // if doc exists it will legitimately be deleted\n              expectedDocIds.clear(id_i);\n            }\n            req.deleteById(id, versionConstraint);\n            log.info(\"DEL: {} = {}\", id, causeError ? \"ERR\" : \"OK\" );\n          } else {\n            // delete by query\n            final String q;\n            if (causeError) {\n              // even though our DBQ is gibberish that's going to fail, record a docId as affected\n              // so that we don't generate the same random DBQ and get redundent errors\n              // (problematic because of how DUP forwarded DBQs have to have their errors deduped by TUP)\n              final int id_i = randomUnsetBit(random(), docsAffectedThisRequest, maxDocId);\n              docsAffectedThisRequest.set(id_i);\n              q = \"foo_i:[\"+id_i+\" TO ....giberish\";\n              expectedErrors.add(delQErr(q));\n            } else {\n              // ensure our DBQ is only over a range of docs not already affected\n              // by any other cmds in this request\n              final int rangeAxis = randomUnsetBit(random(), docsAffectedThisRequest, maxDocId);\n              final int loBound = docsAffectedThisRequest.previousSetBit(rangeAxis);\n              final int hiBound = docsAffectedThisRequest.nextSetBit(rangeAxis);\n              final int lo = TestUtil.nextInt(random(), loBound+1, rangeAxis);\n              final int hi = TestUtil.nextInt(random(), rangeAxis,\n                                              // bound might be negative if no set bits above axis\n                                              (hiBound < 0) ? maxDocId : hiBound-1);\n\n              if (lo != hi) {\n                assert lo < hi : \"lo=\"+lo+\" hi=\"+hi;\n                // NOTE: clear & set are exclusive of hi, so we use \"}\" in range query accordingly\n                q = \"id_i:[\" + lo + \" TO \" + hi + \"}\";\n                expectedDocIds.clear(lo, hi);\n                docsAffectedThisRequest.set(lo, hi);\n              } else {\n                // edge case: special case DBQ of one doc\n                assert (lo == rangeAxis && hi == rangeAxis) : \"lo=\"+lo+\" axis=\"+rangeAxis+\" hi=\"+hi;\n                q = \"id_i:[\" + lo + \" TO \" + lo + \"]\"; // have to be inclusive of both ends\n                expectedDocIds.clear(lo);\n                docsAffectedThisRequest.set(lo);\n              }\n            }\n            req.deleteByQuery(q);\n            log.info(\"DEL: {}\", q);\n          }\n        }\n      }\n      assertEquals(\"expected error count sanity check: \" + req.toString(),\n                   expectedErrorsCount, expectedErrors.size());\n        \n      final SolrClient client = random().nextBoolean() ? CLOUD_CLIENT\n        : NODE_CLIENTS.get(TestUtil.nextInt(random(), 0, NODE_CLIENTS.size()-1));\n      \n      final UpdateResponse rsp = req.process(client);\n      assertUpdateTolerantErrors(client.toString() + \" => \" + expectedErrors.toString(), rsp,\n                                 expectedErrors.toArray(new ExpectedErr[expectedErrors.size()]));\n               \n      log.info(\"END ITER #{}, expecting #docs: {}\", i, expectedDocIds.cardinality());\n\n      assertEquals(\"post update commit failed?\", 0, CLOUD_CLIENT.commit().getStatus());\n      \n      for (int j = 0; j < 5; j++) {\n        if (expectedDocIds.cardinality() == countDocs(CLOUD_CLIENT)) {\n          break;\n        }\n        log.info(\"sleeping to give searchers a chance to re-open #\" + j);\n        Thread.sleep(200);\n      }\n\n      // check the index contents against our expectations\n      final BitSet actualDocIds = allDocs(CLOUD_CLIENT, maxDocId);\n      if ( expectedDocIds.cardinality() != actualDocIds.cardinality() ) {\n        log.error(\"cardinality mismatch: expected {} BUT actual {}\",\n                  expectedDocIds.cardinality(),\n                  actualDocIds.cardinality());\n      }\n      final BitSet x = (BitSet) actualDocIds.clone();\n      x.xor(expectedDocIds);\n      for (int b = x.nextSetBit(0); 0 <= b; b = x.nextSetBit(b+1)) {\n        final boolean expectedBit = expectedDocIds.get(b);\n        final boolean actualBit = actualDocIds.get(b);\n        log.error(\"bit #\"+b+\" mismatch: expected {} BUT actual {}\", expectedBit, actualBit);\n      }\n      assertEquals(x.cardinality() + \" mismatched bits\",\n                   expectedDocIds.cardinality(), actualDocIds.cardinality());\n    }\n  }\n\n","sourceOld":"  public void testRandomUpdates() throws Exception {\n    final int maxDocId = atLeast(10000);\n    final BitSet expectedDocIds = new BitSet(maxDocId+1);\n    \n    final int numIters = atLeast(50);\n    for (int i = 0; i < numIters; i++) {\n\n      log.info(\"BEGIN ITER #{}\", i);\n      \n      final UpdateRequest req = update(params(\"maxErrors\",\"-1\",\n                                              \"update.chain\", \"tolerant-chain-max-errors-10\"));\n      final int numCmds = TestUtil.nextInt(random(), 1, 20);\n      final List<ExpectedErr> expectedErrors = new ArrayList<ExpectedErr>(numCmds);\n      int expectedErrorsCount = 0;\n      // it's ambigious/confusing which order mixed DELQ + ADD  (or ADD and DELI for the same ID)\n      // in the same request wll be processed by various clients, so we keep things simple\n      // and ensure that no single doc Id is affected by more then one command in the same request\n      final BitSet docsAffectedThisRequest = new BitSet(maxDocId+1);\n      for (int cmdIter = 0; cmdIter < numCmds; cmdIter++) {\n        if ((maxDocId / 2) < docsAffectedThisRequest.cardinality()) {\n          // we're already mucking with more then half the docs in the index\n          break;\n        }\n\n        final boolean causeError = random().nextBoolean();\n        if (causeError) {\n          expectedErrorsCount++;\n        }\n        \n        if (random().nextBoolean()) {\n          // add a doc\n          String id = null;\n          SolrInputDocument doc = null;\n          if (causeError && (0 == TestUtil.nextInt(random(), 0, 21))) {\n            doc = doc(f(\"foo_s\",\"no unique key\"));\n            expectedErrors.add(addErr(\"(unknown)\"));\n          } else {\n            final int id_i = randomUnsetBit(random(), docsAffectedThisRequest, maxDocId);\n            docsAffectedThisRequest.set(id_i);\n            id = \"id_\"+id_i;\n            if (causeError) {\n              expectedErrors.add(addErr(id));\n            } else {\n              expectedDocIds.set(id_i);\n            }\n            final String val = causeError ? \"bogus_val\" : (\"\"+TestUtil.nextInt(random(), 42, 666));\n            doc = doc(f(\"id\",id),\n                      f(\"id_i\", id_i),\n                      f(\"foo_i\", val));\n          }\n          req.add(doc);\n          log.info(\"ADD: {} = {}\", id, doc);\n        } else {\n          // delete something\n          if (random().nextBoolean()) {\n            // delete by id\n            final int id_i = randomUnsetBit(random(), docsAffectedThisRequest, maxDocId);\n            final String id = \"id_\"+id_i;\n            final boolean docExists = expectedDocIds.get(id_i);\n            docsAffectedThisRequest.set(id_i);\n            long versionConstraint = docExists ? 1 : -1;\n            if (causeError) {\n              versionConstraint = -1 * versionConstraint;\n              expectedErrors.add(delIErr(id));\n            } else {\n              // if doc exists it will legitimately be deleted\n              expectedDocIds.clear(id_i);\n            }\n            req.deleteById(id, versionConstraint);\n            log.info(\"DEL: {} = {}\", id, causeError ? \"ERR\" : \"OK\" );\n          } else {\n            // delete by query\n            final String q;\n            if (causeError) {\n              // even though our DBQ is gibberish that's going to fail, record a docId as affected\n              // so that we don't generate the same random DBQ and get redundent errors\n              // (problematic because of how DUP forwarded DBQs have to have their errors deduped by TUP)\n              final int id_i = randomUnsetBit(random(), docsAffectedThisRequest, maxDocId);\n              docsAffectedThisRequest.set(id_i);\n              q = \"foo_i:[\"+id_i+\" TO ....giberish\";\n              expectedErrors.add(delQErr(q));\n            } else {\n              // ensure our DBQ is only over a range of docs not already affected\n              // by any other cmds in this request\n              final int rangeAxis = randomUnsetBit(random(), docsAffectedThisRequest, maxDocId);\n              final int loBound = docsAffectedThisRequest.previousSetBit(rangeAxis);\n              final int hiBound = docsAffectedThisRequest.nextSetBit(rangeAxis);\n              final int lo = TestUtil.nextInt(random(), loBound+1, rangeAxis);\n              final int hi = TestUtil.nextInt(random(), rangeAxis,\n                                              // bound might be negative if no set bits above axis\n                                              (hiBound < 0) ? maxDocId : hiBound-1);\n\n              if (lo != hi) {\n                assert lo < hi : \"lo=\"+lo+\" hi=\"+hi;\n                // NOTE: clear & set are exclusive of hi, so we use \"}\" in range query accordingly\n                q = \"id_i:[\" + lo + \" TO \" + hi + \"}\";\n                expectedDocIds.clear(lo, hi);\n                docsAffectedThisRequest.set(lo, hi);\n              } else {\n                // edge case: special case DBQ of one doc\n                assert (lo == rangeAxis && hi == rangeAxis) : \"lo=\"+lo+\" axis=\"+rangeAxis+\" hi=\"+hi;\n                q = \"id_i:[\" + lo + \" TO \" + lo + \"]\"; // have to be inclusive of both ends\n                expectedDocIds.clear(lo);\n                docsAffectedThisRequest.set(lo);\n              }\n            }\n            req.deleteByQuery(q);\n            log.info(\"DEL: {}\", q);\n          }\n        }\n      }\n      assertEquals(\"expected error count sanity check: \" + req.toString(),\n                   expectedErrorsCount, expectedErrors.size());\n        \n      final SolrClient client = random().nextBoolean() ? CLOUD_CLIENT\n        : NODE_CLIENTS.get(TestUtil.nextInt(random(), 0, NODE_CLIENTS.size()-1));\n      \n      final UpdateResponse rsp = req.process(client);\n      assertUpdateTolerantErrors(client.toString() + \" => \" + expectedErrors.toString(), rsp,\n                                 expectedErrors.toArray(new ExpectedErr[expectedErrors.size()]));\n               \n      log.info(\"END ITER #{}, expecting #docs: {}\", i, expectedDocIds.cardinality());\n\n      assertEquals(\"post update commit failed?\", 0, CLOUD_CLIENT.commit().getStatus());\n      \n      for (int j = 0; j < 5; j++) {\n        if (expectedDocIds.cardinality() == countDocs(CLOUD_CLIENT)) {\n          break;\n        }\n        log.info(\"sleeping to give searchers a chance to re-open #\" + j);\n        Thread.sleep(200);\n      }\n\n      // check the index contents against our expecationts\n      final BitSet actualDocIds = allDocs(CLOUD_CLIENT, maxDocId);\n      if ( expectedDocIds.cardinality() != actualDocIds.cardinality() ) {\n        log.error(\"cardinality missmatch: expected {} BUT actual {}\",\n                  expectedDocIds.cardinality(),\n                  actualDocIds.cardinality());\n      }\n      final BitSet x = (BitSet) actualDocIds.clone();\n      x.xor(expectedDocIds);\n      for (int b = x.nextSetBit(0); 0 <= b; b = x.nextSetBit(b+1)) {\n        final boolean expectedBit = expectedDocIds.get(b);\n        final boolean actualBit = actualDocIds.get(b);\n        log.error(\"bit #\"+b+\" mismatch: expected {} BUT actual {}\", expectedBit, actualBit);\n      }\n      assertEquals(x.cardinality() + \" mismatched bits\",\n                   expectedDocIds.cardinality(), actualDocIds.cardinality());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestTolerantUpdateProcessorRandomCloud#testRandomUpdates().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestTolerantUpdateProcessorRandomCloud#testRandomUpdates().mjava","sourceNew":"  public void testRandomUpdates() throws Exception {\n    final int maxDocId = atLeast(10000);\n    final BitSet expectedDocIds = new BitSet(maxDocId+1);\n    \n    final int numIters = atLeast(50);\n    for (int i = 0; i < numIters; i++) {\n\n      log.info(\"BEGIN ITER #{}\", i);\n      \n      final UpdateRequest req = update(params(\"maxErrors\",\"-1\",\n                                              \"update.chain\", \"tolerant-chain-max-errors-10\"));\n      final int numCmds = TestUtil.nextInt(random(), 1, 20);\n      final List<ExpectedErr> expectedErrors = new ArrayList<ExpectedErr>(numCmds);\n      int expectedErrorsCount = 0;\n      // it's ambigious/confusing which order mixed DELQ + ADD  (or ADD and DELI for the same ID)\n      // in the same request wll be processed by various clients, so we keep things simple\n      // and ensure that no single doc Id is affected by more then one command in the same request\n      final BitSet docsAffectedThisRequest = new BitSet(maxDocId+1);\n      for (int cmdIter = 0; cmdIter < numCmds; cmdIter++) {\n        if ((maxDocId / 2) < docsAffectedThisRequest.cardinality()) {\n          // we're already mucking with more then half the docs in the index\n          break;\n        }\n\n        final boolean causeError = random().nextBoolean();\n        if (causeError) {\n          expectedErrorsCount++;\n        }\n        \n        if (random().nextBoolean()) {\n          // add a doc\n          String id = null;\n          SolrInputDocument doc = null;\n          if (causeError && (0 == TestUtil.nextInt(random(), 0, 21))) {\n            doc = doc(f(\"foo_s\",\"no unique key\"));\n            expectedErrors.add(addErr(\"(unknown)\"));\n          } else {\n            final int id_i = randomUnsetBit(random(), docsAffectedThisRequest, maxDocId);\n            docsAffectedThisRequest.set(id_i);\n            id = \"id_\"+id_i;\n            if (causeError) {\n              expectedErrors.add(addErr(id));\n            } else {\n              expectedDocIds.set(id_i);\n            }\n            final String val = causeError ? \"bogus_val\" : (\"\"+TestUtil.nextInt(random(), 42, 666));\n            doc = doc(f(\"id\",id),\n                      f(\"id_i\", id_i),\n                      f(\"foo_i\", val));\n          }\n          req.add(doc);\n          log.info(\"ADD: {} = {}\", id, doc);\n        } else {\n          // delete something\n          if (random().nextBoolean()) {\n            // delete by id\n            final int id_i = randomUnsetBit(random(), docsAffectedThisRequest, maxDocId);\n            final String id = \"id_\"+id_i;\n            final boolean docExists = expectedDocIds.get(id_i);\n            docsAffectedThisRequest.set(id_i);\n            long versionConstraint = docExists ? 1 : -1;\n            if (causeError) {\n              versionConstraint = -1 * versionConstraint;\n              expectedErrors.add(delIErr(id));\n            } else {\n              // if doc exists it will legitimately be deleted\n              expectedDocIds.clear(id_i);\n            }\n            req.deleteById(id, versionConstraint);\n            log.info(\"DEL: {} = {}\", id, causeError ? \"ERR\" : \"OK\" );\n          } else {\n            // delete by query\n            final String q;\n            if (causeError) {\n              // even though our DBQ is gibberish that's going to fail, record a docId as affected\n              // so that we don't generate the same random DBQ and get redundent errors\n              // (problematic because of how DUP forwarded DBQs have to have their errors deduped by TUP)\n              final int id_i = randomUnsetBit(random(), docsAffectedThisRequest, maxDocId);\n              docsAffectedThisRequest.set(id_i);\n              q = \"foo_i:[\"+id_i+\" TO ....giberish\";\n              expectedErrors.add(delQErr(q));\n            } else {\n              // ensure our DBQ is only over a range of docs not already affected\n              // by any other cmds in this request\n              final int rangeAxis = randomUnsetBit(random(), docsAffectedThisRequest, maxDocId);\n              final int loBound = docsAffectedThisRequest.previousSetBit(rangeAxis);\n              final int hiBound = docsAffectedThisRequest.nextSetBit(rangeAxis);\n              final int lo = TestUtil.nextInt(random(), loBound+1, rangeAxis);\n              final int hi = TestUtil.nextInt(random(), rangeAxis,\n                                              // bound might be negative if no set bits above axis\n                                              (hiBound < 0) ? maxDocId : hiBound-1);\n\n              if (lo != hi) {\n                assert lo < hi : \"lo=\"+lo+\" hi=\"+hi;\n                // NOTE: clear & set are exclusive of hi, so we use \"}\" in range query accordingly\n                q = \"id_i:[\" + lo + \" TO \" + hi + \"}\";\n                expectedDocIds.clear(lo, hi);\n                docsAffectedThisRequest.set(lo, hi);\n              } else {\n                // edge case: special case DBQ of one doc\n                assert (lo == rangeAxis && hi == rangeAxis) : \"lo=\"+lo+\" axis=\"+rangeAxis+\" hi=\"+hi;\n                q = \"id_i:[\" + lo + \" TO \" + lo + \"]\"; // have to be inclusive of both ends\n                expectedDocIds.clear(lo);\n                docsAffectedThisRequest.set(lo);\n              }\n            }\n            req.deleteByQuery(q);\n            log.info(\"DEL: {}\", q);\n          }\n        }\n      }\n      assertEquals(\"expected error count sanity check: \" + req.toString(),\n                   expectedErrorsCount, expectedErrors.size());\n        \n      final SolrClient client = random().nextBoolean() ? CLOUD_CLIENT\n        : NODE_CLIENTS.get(TestUtil.nextInt(random(), 0, NODE_CLIENTS.size()-1));\n      \n      final UpdateResponse rsp = req.process(client);\n      assertUpdateTolerantErrors(client.toString() + \" => \" + expectedErrors.toString(), rsp,\n                                 expectedErrors.toArray(new ExpectedErr[expectedErrors.size()]));\n               \n      log.info(\"END ITER #{}, expecting #docs: {}\", i, expectedDocIds.cardinality());\n\n      assertEquals(\"post update commit failed?\", 0, CLOUD_CLIENT.commit().getStatus());\n      \n      for (int j = 0; j < 5; j++) {\n        if (expectedDocIds.cardinality() == countDocs(CLOUD_CLIENT)) {\n          break;\n        }\n        log.info(\"sleeping to give searchers a chance to re-open #\" + j);\n        Thread.sleep(200);\n      }\n\n      // check the index contents against our expectations\n      final BitSet actualDocIds = allDocs(CLOUD_CLIENT, maxDocId);\n      if ( expectedDocIds.cardinality() != actualDocIds.cardinality() ) {\n        log.error(\"cardinality mismatch: expected {} BUT actual {}\",\n                  expectedDocIds.cardinality(),\n                  actualDocIds.cardinality());\n      }\n      final BitSet x = (BitSet) actualDocIds.clone();\n      x.xor(expectedDocIds);\n      for (int b = x.nextSetBit(0); 0 <= b; b = x.nextSetBit(b+1)) {\n        final boolean expectedBit = expectedDocIds.get(b);\n        final boolean actualBit = actualDocIds.get(b);\n        log.error(\"bit #\"+b+\" mismatch: expected {} BUT actual {}\", expectedBit, actualBit);\n      }\n      assertEquals(x.cardinality() + \" mismatched bits\",\n                   expectedDocIds.cardinality(), actualDocIds.cardinality());\n    }\n  }\n\n","sourceOld":"  public void testRandomUpdates() throws Exception {\n    final int maxDocId = atLeast(10000);\n    final BitSet expectedDocIds = new BitSet(maxDocId+1);\n    \n    final int numIters = atLeast(50);\n    for (int i = 0; i < numIters; i++) {\n\n      log.info(\"BEGIN ITER #{}\", i);\n      \n      final UpdateRequest req = update(params(\"maxErrors\",\"-1\",\n                                              \"update.chain\", \"tolerant-chain-max-errors-10\"));\n      final int numCmds = TestUtil.nextInt(random(), 1, 20);\n      final List<ExpectedErr> expectedErrors = new ArrayList<ExpectedErr>(numCmds);\n      int expectedErrorsCount = 0;\n      // it's ambigious/confusing which order mixed DELQ + ADD  (or ADD and DELI for the same ID)\n      // in the same request wll be processed by various clients, so we keep things simple\n      // and ensure that no single doc Id is affected by more then one command in the same request\n      final BitSet docsAffectedThisRequest = new BitSet(maxDocId+1);\n      for (int cmdIter = 0; cmdIter < numCmds; cmdIter++) {\n        if ((maxDocId / 2) < docsAffectedThisRequest.cardinality()) {\n          // we're already mucking with more then half the docs in the index\n          break;\n        }\n\n        final boolean causeError = random().nextBoolean();\n        if (causeError) {\n          expectedErrorsCount++;\n        }\n        \n        if (random().nextBoolean()) {\n          // add a doc\n          String id = null;\n          SolrInputDocument doc = null;\n          if (causeError && (0 == TestUtil.nextInt(random(), 0, 21))) {\n            doc = doc(f(\"foo_s\",\"no unique key\"));\n            expectedErrors.add(addErr(\"(unknown)\"));\n          } else {\n            final int id_i = randomUnsetBit(random(), docsAffectedThisRequest, maxDocId);\n            docsAffectedThisRequest.set(id_i);\n            id = \"id_\"+id_i;\n            if (causeError) {\n              expectedErrors.add(addErr(id));\n            } else {\n              expectedDocIds.set(id_i);\n            }\n            final String val = causeError ? \"bogus_val\" : (\"\"+TestUtil.nextInt(random(), 42, 666));\n            doc = doc(f(\"id\",id),\n                      f(\"id_i\", id_i),\n                      f(\"foo_i\", val));\n          }\n          req.add(doc);\n          log.info(\"ADD: {} = {}\", id, doc);\n        } else {\n          // delete something\n          if (random().nextBoolean()) {\n            // delete by id\n            final int id_i = randomUnsetBit(random(), docsAffectedThisRequest, maxDocId);\n            final String id = \"id_\"+id_i;\n            final boolean docExists = expectedDocIds.get(id_i);\n            docsAffectedThisRequest.set(id_i);\n            long versionConstraint = docExists ? 1 : -1;\n            if (causeError) {\n              versionConstraint = -1 * versionConstraint;\n              expectedErrors.add(delIErr(id));\n            } else {\n              // if doc exists it will legitimately be deleted\n              expectedDocIds.clear(id_i);\n            }\n            req.deleteById(id, versionConstraint);\n            log.info(\"DEL: {} = {}\", id, causeError ? \"ERR\" : \"OK\" );\n          } else {\n            // delete by query\n            final String q;\n            if (causeError) {\n              // even though our DBQ is gibberish that's going to fail, record a docId as affected\n              // so that we don't generate the same random DBQ and get redundent errors\n              // (problematic because of how DUP forwarded DBQs have to have their errors deduped by TUP)\n              final int id_i = randomUnsetBit(random(), docsAffectedThisRequest, maxDocId);\n              docsAffectedThisRequest.set(id_i);\n              q = \"foo_i:[\"+id_i+\" TO ....giberish\";\n              expectedErrors.add(delQErr(q));\n            } else {\n              // ensure our DBQ is only over a range of docs not already affected\n              // by any other cmds in this request\n              final int rangeAxis = randomUnsetBit(random(), docsAffectedThisRequest, maxDocId);\n              final int loBound = docsAffectedThisRequest.previousSetBit(rangeAxis);\n              final int hiBound = docsAffectedThisRequest.nextSetBit(rangeAxis);\n              final int lo = TestUtil.nextInt(random(), loBound+1, rangeAxis);\n              final int hi = TestUtil.nextInt(random(), rangeAxis,\n                                              // bound might be negative if no set bits above axis\n                                              (hiBound < 0) ? maxDocId : hiBound-1);\n\n              if (lo != hi) {\n                assert lo < hi : \"lo=\"+lo+\" hi=\"+hi;\n                // NOTE: clear & set are exclusive of hi, so we use \"}\" in range query accordingly\n                q = \"id_i:[\" + lo + \" TO \" + hi + \"}\";\n                expectedDocIds.clear(lo, hi);\n                docsAffectedThisRequest.set(lo, hi);\n              } else {\n                // edge case: special case DBQ of one doc\n                assert (lo == rangeAxis && hi == rangeAxis) : \"lo=\"+lo+\" axis=\"+rangeAxis+\" hi=\"+hi;\n                q = \"id_i:[\" + lo + \" TO \" + lo + \"]\"; // have to be inclusive of both ends\n                expectedDocIds.clear(lo);\n                docsAffectedThisRequest.set(lo);\n              }\n            }\n            req.deleteByQuery(q);\n            log.info(\"DEL: {}\", q);\n          }\n        }\n      }\n      assertEquals(\"expected error count sanity check: \" + req.toString(),\n                   expectedErrorsCount, expectedErrors.size());\n        \n      final SolrClient client = random().nextBoolean() ? CLOUD_CLIENT\n        : NODE_CLIENTS.get(TestUtil.nextInt(random(), 0, NODE_CLIENTS.size()-1));\n      \n      final UpdateResponse rsp = req.process(client);\n      assertUpdateTolerantErrors(client.toString() + \" => \" + expectedErrors.toString(), rsp,\n                                 expectedErrors.toArray(new ExpectedErr[expectedErrors.size()]));\n               \n      log.info(\"END ITER #{}, expecting #docs: {}\", i, expectedDocIds.cardinality());\n\n      assertEquals(\"post update commit failed?\", 0, CLOUD_CLIENT.commit().getStatus());\n      \n      for (int j = 0; j < 5; j++) {\n        if (expectedDocIds.cardinality() == countDocs(CLOUD_CLIENT)) {\n          break;\n        }\n        log.info(\"sleeping to give searchers a chance to re-open #\" + j);\n        Thread.sleep(200);\n      }\n\n      // check the index contents against our expecationts\n      final BitSet actualDocIds = allDocs(CLOUD_CLIENT, maxDocId);\n      if ( expectedDocIds.cardinality() != actualDocIds.cardinality() ) {\n        log.error(\"cardinality missmatch: expected {} BUT actual {}\",\n                  expectedDocIds.cardinality(),\n                  actualDocIds.cardinality());\n      }\n      final BitSet x = (BitSet) actualDocIds.clone();\n      x.xor(expectedDocIds);\n      for (int b = x.nextSetBit(0); 0 <= b; b = x.nextSetBit(b+1)) {\n        final boolean expectedBit = expectedDocIds.get(b);\n        final boolean actualBit = actualDocIds.get(b);\n        log.error(\"bit #\"+b+\" mismatch: expected {} BUT actual {}\", expectedBit, actualBit);\n      }\n      assertEquals(x.cardinality() + \" mismatched bits\",\n                   expectedDocIds.cardinality(), actualDocIds.cardinality());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a966532d92cf9ba2856f15a8140151bb6b518e4b","date":1588290631,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestTolerantUpdateProcessorRandomCloud#testRandomUpdates().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestTolerantUpdateProcessorRandomCloud#testRandomUpdates().mjava","sourceNew":"  public void testRandomUpdates() throws Exception {\n    final int maxDocId = atLeast(10000);\n    final BitSet expectedDocIds = new BitSet(maxDocId+1);\n    \n    final int numIters = atLeast(50);\n    for (int i = 0; i < numIters; i++) {\n\n      log.info(\"BEGIN ITER #{}\", i);\n      \n      final UpdateRequest req = update(params(\"maxErrors\",\"-1\",\n                                              \"update.chain\", \"tolerant-chain-max-errors-10\"));\n      final int numCmds = TestUtil.nextInt(random(), 1, 20);\n      final List<ExpectedErr> expectedErrors = new ArrayList<ExpectedErr>(numCmds);\n      int expectedErrorsCount = 0;\n      // it's ambigious/confusing which order mixed DELQ + ADD  (or ADD and DELI for the same ID)\n      // in the same request wll be processed by various clients, so we keep things simple\n      // and ensure that no single doc Id is affected by more then one command in the same request\n      final BitSet docsAffectedThisRequest = new BitSet(maxDocId+1);\n      for (int cmdIter = 0; cmdIter < numCmds; cmdIter++) {\n        if ((maxDocId / 2) < docsAffectedThisRequest.cardinality()) {\n          // we're already mucking with more then half the docs in the index\n          break;\n        }\n\n        final boolean causeError = random().nextBoolean();\n        if (causeError) {\n          expectedErrorsCount++;\n        }\n        \n        if (random().nextBoolean()) {\n          // add a doc\n          String id = null;\n          SolrInputDocument doc = null;\n          if (causeError && (0 == TestUtil.nextInt(random(), 0, 21))) {\n            doc = doc(f(\"foo_s\",\"no unique key\"));\n            expectedErrors.add(addErr(\"(unknown)\"));\n          } else {\n            final int id_i = randomUnsetBit(random(), docsAffectedThisRequest, maxDocId);\n            docsAffectedThisRequest.set(id_i);\n            id = \"id_\"+id_i;\n            if (causeError) {\n              expectedErrors.add(addErr(id));\n            } else {\n              expectedDocIds.set(id_i);\n            }\n            final String val = causeError ? \"bogus_val\" : (\"\"+TestUtil.nextInt(random(), 42, 666));\n            doc = doc(f(\"id\",id),\n                      f(\"id_i\", id_i),\n                      f(\"foo_i\", val));\n          }\n          req.add(doc);\n          log.info(\"ADD: {} = {}\", id, doc);\n        } else {\n          // delete something\n          if (random().nextBoolean()) {\n            // delete by id\n            final int id_i = randomUnsetBit(random(), docsAffectedThisRequest, maxDocId);\n            final String id = \"id_\"+id_i;\n            final boolean docExists = expectedDocIds.get(id_i);\n            docsAffectedThisRequest.set(id_i);\n            long versionConstraint = docExists ? 1 : -1;\n            if (causeError) {\n              versionConstraint = -1 * versionConstraint;\n              expectedErrors.add(delIErr(id));\n            } else {\n              // if doc exists it will legitimately be deleted\n              expectedDocIds.clear(id_i);\n            }\n            req.deleteById(id, versionConstraint);\n            log.info(\"DEL: {} = {}\", id, causeError ? \"ERR\" : \"OK\" );\n          } else {\n            // delete by query\n            final String q;\n            if (causeError) {\n              // even though our DBQ is gibberish that's going to fail, record a docId as affected\n              // so that we don't generate the same random DBQ and get redundent errors\n              // (problematic because of how DUP forwarded DBQs have to have their errors deduped by TUP)\n              final int id_i = randomUnsetBit(random(), docsAffectedThisRequest, maxDocId);\n              docsAffectedThisRequest.set(id_i);\n              q = \"foo_i:[\"+id_i+\" TO ....giberish\";\n              expectedErrors.add(delQErr(q));\n            } else {\n              // ensure our DBQ is only over a range of docs not already affected\n              // by any other cmds in this request\n              final int rangeAxis = randomUnsetBit(random(), docsAffectedThisRequest, maxDocId);\n              final int loBound = docsAffectedThisRequest.previousSetBit(rangeAxis);\n              final int hiBound = docsAffectedThisRequest.nextSetBit(rangeAxis);\n              final int lo = TestUtil.nextInt(random(), loBound+1, rangeAxis);\n              final int hi = TestUtil.nextInt(random(), rangeAxis,\n                                              // bound might be negative if no set bits above axis\n                                              (hiBound < 0) ? maxDocId : hiBound-1);\n\n              if (lo != hi) {\n                assert lo < hi : \"lo=\"+lo+\" hi=\"+hi;\n                // NOTE: clear & set are exclusive of hi, so we use \"}\" in range query accordingly\n                q = \"id_i:[\" + lo + \" TO \" + hi + \"}\";\n                expectedDocIds.clear(lo, hi);\n                docsAffectedThisRequest.set(lo, hi);\n              } else {\n                // edge case: special case DBQ of one doc\n                assert (lo == rangeAxis && hi == rangeAxis) : \"lo=\"+lo+\" axis=\"+rangeAxis+\" hi=\"+hi;\n                q = \"id_i:[\" + lo + \" TO \" + lo + \"]\"; // have to be inclusive of both ends\n                expectedDocIds.clear(lo);\n                docsAffectedThisRequest.set(lo);\n              }\n            }\n            req.deleteByQuery(q);\n            log.info(\"DEL: {}\", q);\n          }\n        }\n      }\n      assertEquals(\"expected error count sanity check: \" + req.toString(),\n                   expectedErrorsCount, expectedErrors.size());\n        \n      final SolrClient client = random().nextBoolean() ? CLOUD_CLIENT\n        : NODE_CLIENTS.get(TestUtil.nextInt(random(), 0, NODE_CLIENTS.size()-1));\n      \n      final UpdateResponse rsp = req.process(client);\n      assertUpdateTolerantErrors(client.toString() + \" => \" + expectedErrors.toString(), rsp,\n                                 expectedErrors.toArray(new ExpectedErr[expectedErrors.size()]));\n\n      if (log.isInfoEnabled()) {\n        log.info(\"END ITER #{}, expecting #docs: {}\", i, expectedDocIds.cardinality());\n      }\n\n      assertEquals(\"post update commit failed?\", 0, CLOUD_CLIENT.commit().getStatus());\n      \n      for (int j = 0; j < 5; j++) {\n        if (expectedDocIds.cardinality() == countDocs(CLOUD_CLIENT)) {\n          break;\n        }\n        log.info(\"sleeping to give searchers a chance to re-open #{}\", j);\n        Thread.sleep(200);\n      }\n\n      // check the index contents against our expectations\n      final BitSet actualDocIds = allDocs(CLOUD_CLIENT, maxDocId);\n      if ( expectedDocIds.cardinality() != actualDocIds.cardinality() ) {\n        log.error(\"cardinality mismatch: expected {} BUT actual {}\",\n                  expectedDocIds.cardinality(),\n                  actualDocIds.cardinality());\n      }\n      final BitSet x = (BitSet) actualDocIds.clone();\n      x.xor(expectedDocIds);\n      for (int b = x.nextSetBit(0); 0 <= b; b = x.nextSetBit(b+1)) {\n        final boolean expectedBit = expectedDocIds.get(b);\n        final boolean actualBit = actualDocIds.get(b);\n        log.error(\"bit #{} mismatch: expected {} BUT actual {}\", b, expectedBit, actualBit);\n      }\n      assertEquals(x.cardinality() + \" mismatched bits\",\n                   expectedDocIds.cardinality(), actualDocIds.cardinality());\n    }\n  }\n\n","sourceOld":"  public void testRandomUpdates() throws Exception {\n    final int maxDocId = atLeast(10000);\n    final BitSet expectedDocIds = new BitSet(maxDocId+1);\n    \n    final int numIters = atLeast(50);\n    for (int i = 0; i < numIters; i++) {\n\n      log.info(\"BEGIN ITER #{}\", i);\n      \n      final UpdateRequest req = update(params(\"maxErrors\",\"-1\",\n                                              \"update.chain\", \"tolerant-chain-max-errors-10\"));\n      final int numCmds = TestUtil.nextInt(random(), 1, 20);\n      final List<ExpectedErr> expectedErrors = new ArrayList<ExpectedErr>(numCmds);\n      int expectedErrorsCount = 0;\n      // it's ambigious/confusing which order mixed DELQ + ADD  (or ADD and DELI for the same ID)\n      // in the same request wll be processed by various clients, so we keep things simple\n      // and ensure that no single doc Id is affected by more then one command in the same request\n      final BitSet docsAffectedThisRequest = new BitSet(maxDocId+1);\n      for (int cmdIter = 0; cmdIter < numCmds; cmdIter++) {\n        if ((maxDocId / 2) < docsAffectedThisRequest.cardinality()) {\n          // we're already mucking with more then half the docs in the index\n          break;\n        }\n\n        final boolean causeError = random().nextBoolean();\n        if (causeError) {\n          expectedErrorsCount++;\n        }\n        \n        if (random().nextBoolean()) {\n          // add a doc\n          String id = null;\n          SolrInputDocument doc = null;\n          if (causeError && (0 == TestUtil.nextInt(random(), 0, 21))) {\n            doc = doc(f(\"foo_s\",\"no unique key\"));\n            expectedErrors.add(addErr(\"(unknown)\"));\n          } else {\n            final int id_i = randomUnsetBit(random(), docsAffectedThisRequest, maxDocId);\n            docsAffectedThisRequest.set(id_i);\n            id = \"id_\"+id_i;\n            if (causeError) {\n              expectedErrors.add(addErr(id));\n            } else {\n              expectedDocIds.set(id_i);\n            }\n            final String val = causeError ? \"bogus_val\" : (\"\"+TestUtil.nextInt(random(), 42, 666));\n            doc = doc(f(\"id\",id),\n                      f(\"id_i\", id_i),\n                      f(\"foo_i\", val));\n          }\n          req.add(doc);\n          log.info(\"ADD: {} = {}\", id, doc);\n        } else {\n          // delete something\n          if (random().nextBoolean()) {\n            // delete by id\n            final int id_i = randomUnsetBit(random(), docsAffectedThisRequest, maxDocId);\n            final String id = \"id_\"+id_i;\n            final boolean docExists = expectedDocIds.get(id_i);\n            docsAffectedThisRequest.set(id_i);\n            long versionConstraint = docExists ? 1 : -1;\n            if (causeError) {\n              versionConstraint = -1 * versionConstraint;\n              expectedErrors.add(delIErr(id));\n            } else {\n              // if doc exists it will legitimately be deleted\n              expectedDocIds.clear(id_i);\n            }\n            req.deleteById(id, versionConstraint);\n            log.info(\"DEL: {} = {}\", id, causeError ? \"ERR\" : \"OK\" );\n          } else {\n            // delete by query\n            final String q;\n            if (causeError) {\n              // even though our DBQ is gibberish that's going to fail, record a docId as affected\n              // so that we don't generate the same random DBQ and get redundent errors\n              // (problematic because of how DUP forwarded DBQs have to have their errors deduped by TUP)\n              final int id_i = randomUnsetBit(random(), docsAffectedThisRequest, maxDocId);\n              docsAffectedThisRequest.set(id_i);\n              q = \"foo_i:[\"+id_i+\" TO ....giberish\";\n              expectedErrors.add(delQErr(q));\n            } else {\n              // ensure our DBQ is only over a range of docs not already affected\n              // by any other cmds in this request\n              final int rangeAxis = randomUnsetBit(random(), docsAffectedThisRequest, maxDocId);\n              final int loBound = docsAffectedThisRequest.previousSetBit(rangeAxis);\n              final int hiBound = docsAffectedThisRequest.nextSetBit(rangeAxis);\n              final int lo = TestUtil.nextInt(random(), loBound+1, rangeAxis);\n              final int hi = TestUtil.nextInt(random(), rangeAxis,\n                                              // bound might be negative if no set bits above axis\n                                              (hiBound < 0) ? maxDocId : hiBound-1);\n\n              if (lo != hi) {\n                assert lo < hi : \"lo=\"+lo+\" hi=\"+hi;\n                // NOTE: clear & set are exclusive of hi, so we use \"}\" in range query accordingly\n                q = \"id_i:[\" + lo + \" TO \" + hi + \"}\";\n                expectedDocIds.clear(lo, hi);\n                docsAffectedThisRequest.set(lo, hi);\n              } else {\n                // edge case: special case DBQ of one doc\n                assert (lo == rangeAxis && hi == rangeAxis) : \"lo=\"+lo+\" axis=\"+rangeAxis+\" hi=\"+hi;\n                q = \"id_i:[\" + lo + \" TO \" + lo + \"]\"; // have to be inclusive of both ends\n                expectedDocIds.clear(lo);\n                docsAffectedThisRequest.set(lo);\n              }\n            }\n            req.deleteByQuery(q);\n            log.info(\"DEL: {}\", q);\n          }\n        }\n      }\n      assertEquals(\"expected error count sanity check: \" + req.toString(),\n                   expectedErrorsCount, expectedErrors.size());\n        \n      final SolrClient client = random().nextBoolean() ? CLOUD_CLIENT\n        : NODE_CLIENTS.get(TestUtil.nextInt(random(), 0, NODE_CLIENTS.size()-1));\n      \n      final UpdateResponse rsp = req.process(client);\n      assertUpdateTolerantErrors(client.toString() + \" => \" + expectedErrors.toString(), rsp,\n                                 expectedErrors.toArray(new ExpectedErr[expectedErrors.size()]));\n               \n      log.info(\"END ITER #{}, expecting #docs: {}\", i, expectedDocIds.cardinality());\n\n      assertEquals(\"post update commit failed?\", 0, CLOUD_CLIENT.commit().getStatus());\n      \n      for (int j = 0; j < 5; j++) {\n        if (expectedDocIds.cardinality() == countDocs(CLOUD_CLIENT)) {\n          break;\n        }\n        log.info(\"sleeping to give searchers a chance to re-open #\" + j);\n        Thread.sleep(200);\n      }\n\n      // check the index contents against our expectations\n      final BitSet actualDocIds = allDocs(CLOUD_CLIENT, maxDocId);\n      if ( expectedDocIds.cardinality() != actualDocIds.cardinality() ) {\n        log.error(\"cardinality mismatch: expected {} BUT actual {}\",\n                  expectedDocIds.cardinality(),\n                  actualDocIds.cardinality());\n      }\n      final BitSet x = (BitSet) actualDocIds.clone();\n      x.xor(expectedDocIds);\n      for (int b = x.nextSetBit(0); 0 <= b; b = x.nextSetBit(b+1)) {\n        final boolean expectedBit = expectedDocIds.get(b);\n        final boolean actualBit = actualDocIds.get(b);\n        log.error(\"bit #\"+b+\" mismatch: expected {} BUT actual {}\", expectedBit, actualBit);\n      }\n      assertEquals(x.cardinality() + \" mismatched bits\",\n                   expectedDocIds.cardinality(), actualDocIds.cardinality());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"f57cf082c4d2ee975c6a2034fcf3c13f9514e6ef":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a966532d92cf9ba2856f15a8140151bb6b518e4b":["d470c8182e92b264680e34081b75e70a9f2b3c89"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["f57cf082c4d2ee975c6a2034fcf3c13f9514e6ef","d470c8182e92b264680e34081b75e70a9f2b3c89"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a966532d92cf9ba2856f15a8140151bb6b518e4b"],"d470c8182e92b264680e34081b75e70a9f2b3c89":["f57cf082c4d2ee975c6a2034fcf3c13f9514e6ef","0158ced21948b6626f733c1c42c1e18d94449789"],"0158ced21948b6626f733c1c42c1e18d94449789":["f57cf082c4d2ee975c6a2034fcf3c13f9514e6ef"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["f57cf082c4d2ee975c6a2034fcf3c13f9514e6ef"],"f57cf082c4d2ee975c6a2034fcf3c13f9514e6ef":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","d470c8182e92b264680e34081b75e70a9f2b3c89","0158ced21948b6626f733c1c42c1e18d94449789"],"a966532d92cf9ba2856f15a8140151bb6b518e4b":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"d470c8182e92b264680e34081b75e70a9f2b3c89":["a966532d92cf9ba2856f15a8140151bb6b518e4b","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"0158ced21948b6626f733c1c42c1e18d94449789":["d470c8182e92b264680e34081b75e70a9f2b3c89"]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}