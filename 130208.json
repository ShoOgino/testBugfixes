{"path":"solr/core/src/test/org/apache/solr/handler/TestReplicationHandler#testRateLimitedReplication().mjava","commits":[{"id":"5a2d81cf6955f09cda03ed448bb9bb397d4b9742","date":1411570057,"type":0,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/handler/TestReplicationHandler#testRateLimitedReplication().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testRateLimitedReplication() throws Exception {\n\n    //clean index\n    masterClient.deleteByQuery(\"*:*\");\n    slaveClient.deleteByQuery(\"*:*\");\n    masterClient.commit();\n    slaveClient.commit();\n\n    masterJetty.stop();\n    slaveJetty.stop();\n\n    //Start master with the new solrconfig\n    master.copyConfigFile(CONF_DIR + \"solrconfig-master-throttled.xml\", \"solrconfig.xml\");\n    useFactory(null);\n    masterJetty = createJetty(master);\n    masterClient.shutdown();\n    masterClient = createNewSolrServer(masterJetty.getLocalPort());\n\n    //index docs\n    final int totalDocs = TestUtil.nextInt(random(), 50, 100);\n    for (int i = 0; i < totalDocs; i++)\n      index(masterClient, \"id\", i, \"name\", TestUtil.randomSimpleString(random(), 1000 , 5000));\n\n    masterClient.commit();\n\n    //Check Index Size\n    String dataDir = master.getDataDir();\n    masterClient.shutdown();\n    masterJetty.stop();\n\n    Directory dir = FSDirectory.open(Paths.get(dataDir, \"index\"));\n    String[] files = dir.listAll();\n    long totalBytes = 0;\n    for(String file : files) {\n      totalBytes += dir.fileLength(file);\n    }\n\n    float approximateTimeInSeconds = Math.round( totalBytes/1024/1024/0.1 ); // maxWriteMBPerSec=0.1 in solrconfig\n\n    //Start again and replicate the data\n    useFactory(null);\n    masterJetty = createJetty(master);\n    masterClient = createNewSolrServer(masterJetty.getLocalPort());\n\n    //start slave\n    slave.setTestPort(masterJetty.getLocalPort());\n    slave.copyConfigFile(CONF_DIR + \"solrconfig-slave1.xml\", \"solrconfig.xml\");\n    slaveJetty = createJetty(slave);\n    slaveClient.shutdown();\n    slaveClient = createNewSolrServer(slaveJetty.getLocalPort());\n\n    long startTime = System.nanoTime();\n\n    pullFromMasterToSlave();\n\n    //Add a few more docs in the master. Just to make sure that we are replicating the correct index point\n    //These extra docs should not get replicated\n    new Thread(new AddExtraDocs(masterClient, totalDocs)).start();\n\n    //Wait and make sure that it actually replicated correctly.\n    NamedList slaveQueryRsp = rQuery(totalDocs, \"*:*\", slaveClient);\n    SolrDocumentList slaveQueryResult = (SolrDocumentList) slaveQueryRsp.get(\"response\");\n    assertEquals(totalDocs, slaveQueryResult.getNumFound());\n\n    long timeTaken = System.nanoTime() - startTime;\n\n    long timeTakenInSeconds = TimeUnit.SECONDS.convert(timeTaken, TimeUnit.NANOSECONDS);\n\n    //Let's make sure it took more than approximateTimeInSeconds to make sure that it was throttled\n    boolean isElapsed = false;\n    if(timeTakenInSeconds - approximateTimeInSeconds > 0) {\n      isElapsed = true;\n    }\n    assertTrue(isElapsed);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bafca15d8e408346a67f4282ad1143b88023893b","date":1420034748,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/handler/TestReplicationHandler#testRateLimitedReplication().mjava","pathOld":"solr/core/src/test/org/apache/solr/handler/TestReplicationHandler#testRateLimitedReplication().mjava","sourceNew":"  @Test\n  public void testRateLimitedReplication() throws Exception {\n\n    //clean index\n    masterClient.deleteByQuery(\"*:*\");\n    slaveClient.deleteByQuery(\"*:*\");\n    masterClient.commit();\n    slaveClient.commit();\n\n    masterJetty.stop();\n    slaveJetty.stop();\n\n    //Start master with the new solrconfig\n    master.copyConfigFile(CONF_DIR + \"solrconfig-master-throttled.xml\", \"solrconfig.xml\");\n    useFactory(null);\n    masterJetty = createJetty(master);\n    masterClient.shutdown();\n    masterClient = createNewSolrClient(masterJetty.getLocalPort());\n\n    //index docs\n    final int totalDocs = TestUtil.nextInt(random(), 50, 100);\n    for (int i = 0; i < totalDocs; i++)\n      index(masterClient, \"id\", i, \"name\", TestUtil.randomSimpleString(random(), 1000 , 5000));\n\n    masterClient.commit();\n\n    //Check Index Size\n    String dataDir = master.getDataDir();\n    masterClient.shutdown();\n    masterJetty.stop();\n\n    Directory dir = FSDirectory.open(Paths.get(dataDir, \"index\"));\n    String[] files = dir.listAll();\n    long totalBytes = 0;\n    for(String file : files) {\n      totalBytes += dir.fileLength(file);\n    }\n\n    float approximateTimeInSeconds = Math.round( totalBytes/1024/1024/0.1 ); // maxWriteMBPerSec=0.1 in solrconfig\n\n    //Start again and replicate the data\n    useFactory(null);\n    masterJetty = createJetty(master);\n    masterClient = createNewSolrClient(masterJetty.getLocalPort());\n\n    //start slave\n    slave.setTestPort(masterJetty.getLocalPort());\n    slave.copyConfigFile(CONF_DIR + \"solrconfig-slave1.xml\", \"solrconfig.xml\");\n    slaveJetty = createJetty(slave);\n    slaveClient.shutdown();\n    slaveClient = createNewSolrClient(slaveJetty.getLocalPort());\n\n    long startTime = System.nanoTime();\n\n    pullFromMasterToSlave();\n\n    //Add a few more docs in the master. Just to make sure that we are replicating the correct index point\n    //These extra docs should not get replicated\n    new Thread(new AddExtraDocs(masterClient, totalDocs)).start();\n\n    //Wait and make sure that it actually replicated correctly.\n    NamedList slaveQueryRsp = rQuery(totalDocs, \"*:*\", slaveClient);\n    SolrDocumentList slaveQueryResult = (SolrDocumentList) slaveQueryRsp.get(\"response\");\n    assertEquals(totalDocs, slaveQueryResult.getNumFound());\n\n    long timeTaken = System.nanoTime() - startTime;\n\n    long timeTakenInSeconds = TimeUnit.SECONDS.convert(timeTaken, TimeUnit.NANOSECONDS);\n\n    //Let's make sure it took more than approximateTimeInSeconds to make sure that it was throttled\n    boolean isElapsed = false;\n    if(timeTakenInSeconds - approximateTimeInSeconds > 0) {\n      isElapsed = true;\n    }\n    assertTrue(isElapsed);\n  }\n\n","sourceOld":"  @Test\n  public void testRateLimitedReplication() throws Exception {\n\n    //clean index\n    masterClient.deleteByQuery(\"*:*\");\n    slaveClient.deleteByQuery(\"*:*\");\n    masterClient.commit();\n    slaveClient.commit();\n\n    masterJetty.stop();\n    slaveJetty.stop();\n\n    //Start master with the new solrconfig\n    master.copyConfigFile(CONF_DIR + \"solrconfig-master-throttled.xml\", \"solrconfig.xml\");\n    useFactory(null);\n    masterJetty = createJetty(master);\n    masterClient.shutdown();\n    masterClient = createNewSolrServer(masterJetty.getLocalPort());\n\n    //index docs\n    final int totalDocs = TestUtil.nextInt(random(), 50, 100);\n    for (int i = 0; i < totalDocs; i++)\n      index(masterClient, \"id\", i, \"name\", TestUtil.randomSimpleString(random(), 1000 , 5000));\n\n    masterClient.commit();\n\n    //Check Index Size\n    String dataDir = master.getDataDir();\n    masterClient.shutdown();\n    masterJetty.stop();\n\n    Directory dir = FSDirectory.open(Paths.get(dataDir, \"index\"));\n    String[] files = dir.listAll();\n    long totalBytes = 0;\n    for(String file : files) {\n      totalBytes += dir.fileLength(file);\n    }\n\n    float approximateTimeInSeconds = Math.round( totalBytes/1024/1024/0.1 ); // maxWriteMBPerSec=0.1 in solrconfig\n\n    //Start again and replicate the data\n    useFactory(null);\n    masterJetty = createJetty(master);\n    masterClient = createNewSolrServer(masterJetty.getLocalPort());\n\n    //start slave\n    slave.setTestPort(masterJetty.getLocalPort());\n    slave.copyConfigFile(CONF_DIR + \"solrconfig-slave1.xml\", \"solrconfig.xml\");\n    slaveJetty = createJetty(slave);\n    slaveClient.shutdown();\n    slaveClient = createNewSolrServer(slaveJetty.getLocalPort());\n\n    long startTime = System.nanoTime();\n\n    pullFromMasterToSlave();\n\n    //Add a few more docs in the master. Just to make sure that we are replicating the correct index point\n    //These extra docs should not get replicated\n    new Thread(new AddExtraDocs(masterClient, totalDocs)).start();\n\n    //Wait and make sure that it actually replicated correctly.\n    NamedList slaveQueryRsp = rQuery(totalDocs, \"*:*\", slaveClient);\n    SolrDocumentList slaveQueryResult = (SolrDocumentList) slaveQueryRsp.get(\"response\");\n    assertEquals(totalDocs, slaveQueryResult.getNumFound());\n\n    long timeTaken = System.nanoTime() - startTime;\n\n    long timeTakenInSeconds = TimeUnit.SECONDS.convert(timeTaken, TimeUnit.NANOSECONDS);\n\n    //Let's make sure it took more than approximateTimeInSeconds to make sure that it was throttled\n    boolean isElapsed = false;\n    if(timeTakenInSeconds - approximateTimeInSeconds > 0) {\n      isElapsed = true;\n    }\n    assertTrue(isElapsed);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"cc3b13b430571c2e169f98fe38e1e7666f88522d","date":1422446157,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/handler/TestReplicationHandler#testRateLimitedReplication().mjava","pathOld":"solr/core/src/test/org/apache/solr/handler/TestReplicationHandler#testRateLimitedReplication().mjava","sourceNew":"  @Test\n  public void testRateLimitedReplication() throws Exception {\n\n    //clean index\n    masterClient.deleteByQuery(\"*:*\");\n    slaveClient.deleteByQuery(\"*:*\");\n    masterClient.commit();\n    slaveClient.commit();\n\n    masterJetty.stop();\n    slaveJetty.stop();\n\n    //Start master with the new solrconfig\n    master.copyConfigFile(CONF_DIR + \"solrconfig-master-throttled.xml\", \"solrconfig.xml\");\n    useFactory(null);\n    masterJetty = createJetty(master);\n    masterClient.close();\n    masterClient = createNewSolrClient(masterJetty.getLocalPort());\n\n    //index docs\n    final int totalDocs = TestUtil.nextInt(random(), 50, 100);\n    for (int i = 0; i < totalDocs; i++)\n      index(masterClient, \"id\", i, \"name\", TestUtil.randomSimpleString(random(), 1000 , 5000));\n\n    masterClient.commit();\n\n    //Check Index Size\n    String dataDir = master.getDataDir();\n    masterClient.close();\n    masterJetty.stop();\n\n    Directory dir = FSDirectory.open(Paths.get(dataDir, \"index\"));\n    String[] files = dir.listAll();\n    long totalBytes = 0;\n    for(String file : files) {\n      totalBytes += dir.fileLength(file);\n    }\n\n    float approximateTimeInSeconds = Math.round( totalBytes/1024/1024/0.1 ); // maxWriteMBPerSec=0.1 in solrconfig\n\n    //Start again and replicate the data\n    useFactory(null);\n    masterJetty = createJetty(master);\n    masterClient = createNewSolrClient(masterJetty.getLocalPort());\n\n    //start slave\n    slave.setTestPort(masterJetty.getLocalPort());\n    slave.copyConfigFile(CONF_DIR + \"solrconfig-slave1.xml\", \"solrconfig.xml\");\n    slaveJetty = createJetty(slave);\n    slaveClient.close();\n    slaveClient = createNewSolrClient(slaveJetty.getLocalPort());\n\n    long startTime = System.nanoTime();\n\n    pullFromMasterToSlave();\n\n    //Add a few more docs in the master. Just to make sure that we are replicating the correct index point\n    //These extra docs should not get replicated\n    new Thread(new AddExtraDocs(masterClient, totalDocs)).start();\n\n    //Wait and make sure that it actually replicated correctly.\n    NamedList slaveQueryRsp = rQuery(totalDocs, \"*:*\", slaveClient);\n    SolrDocumentList slaveQueryResult = (SolrDocumentList) slaveQueryRsp.get(\"response\");\n    assertEquals(totalDocs, slaveQueryResult.getNumFound());\n\n    long timeTaken = System.nanoTime() - startTime;\n\n    long timeTakenInSeconds = TimeUnit.SECONDS.convert(timeTaken, TimeUnit.NANOSECONDS);\n\n    //Let's make sure it took more than approximateTimeInSeconds to make sure that it was throttled\n    boolean isElapsed = false;\n    if(timeTakenInSeconds - approximateTimeInSeconds > 0) {\n      isElapsed = true;\n    }\n    assertTrue(isElapsed);\n  }\n\n","sourceOld":"  @Test\n  public void testRateLimitedReplication() throws Exception {\n\n    //clean index\n    masterClient.deleteByQuery(\"*:*\");\n    slaveClient.deleteByQuery(\"*:*\");\n    masterClient.commit();\n    slaveClient.commit();\n\n    masterJetty.stop();\n    slaveJetty.stop();\n\n    //Start master with the new solrconfig\n    master.copyConfigFile(CONF_DIR + \"solrconfig-master-throttled.xml\", \"solrconfig.xml\");\n    useFactory(null);\n    masterJetty = createJetty(master);\n    masterClient.shutdown();\n    masterClient = createNewSolrClient(masterJetty.getLocalPort());\n\n    //index docs\n    final int totalDocs = TestUtil.nextInt(random(), 50, 100);\n    for (int i = 0; i < totalDocs; i++)\n      index(masterClient, \"id\", i, \"name\", TestUtil.randomSimpleString(random(), 1000 , 5000));\n\n    masterClient.commit();\n\n    //Check Index Size\n    String dataDir = master.getDataDir();\n    masterClient.shutdown();\n    masterJetty.stop();\n\n    Directory dir = FSDirectory.open(Paths.get(dataDir, \"index\"));\n    String[] files = dir.listAll();\n    long totalBytes = 0;\n    for(String file : files) {\n      totalBytes += dir.fileLength(file);\n    }\n\n    float approximateTimeInSeconds = Math.round( totalBytes/1024/1024/0.1 ); // maxWriteMBPerSec=0.1 in solrconfig\n\n    //Start again and replicate the data\n    useFactory(null);\n    masterJetty = createJetty(master);\n    masterClient = createNewSolrClient(masterJetty.getLocalPort());\n\n    //start slave\n    slave.setTestPort(masterJetty.getLocalPort());\n    slave.copyConfigFile(CONF_DIR + \"solrconfig-slave1.xml\", \"solrconfig.xml\");\n    slaveJetty = createJetty(slave);\n    slaveClient.shutdown();\n    slaveClient = createNewSolrClient(slaveJetty.getLocalPort());\n\n    long startTime = System.nanoTime();\n\n    pullFromMasterToSlave();\n\n    //Add a few more docs in the master. Just to make sure that we are replicating the correct index point\n    //These extra docs should not get replicated\n    new Thread(new AddExtraDocs(masterClient, totalDocs)).start();\n\n    //Wait and make sure that it actually replicated correctly.\n    NamedList slaveQueryRsp = rQuery(totalDocs, \"*:*\", slaveClient);\n    SolrDocumentList slaveQueryResult = (SolrDocumentList) slaveQueryRsp.get(\"response\");\n    assertEquals(totalDocs, slaveQueryResult.getNumFound());\n\n    long timeTaken = System.nanoTime() - startTime;\n\n    long timeTakenInSeconds = TimeUnit.SECONDS.convert(timeTaken, TimeUnit.NANOSECONDS);\n\n    //Let's make sure it took more than approximateTimeInSeconds to make sure that it was throttled\n    boolean isElapsed = false;\n    if(timeTakenInSeconds - approximateTimeInSeconds > 0) {\n      isElapsed = true;\n    }\n    assertTrue(isElapsed);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c42316df77794f7252857e7d5e9ce45ff1d65c61","date":1428666763,"type":3,"author":"Varun Thacker","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/handler/TestReplicationHandler#testRateLimitedReplication().mjava","pathOld":"solr/core/src/test/org/apache/solr/handler/TestReplicationHandler#testRateLimitedReplication().mjava","sourceNew":"  @Test\n  public void testRateLimitedReplication() throws Exception {\n\n    //clean index\n    masterClient.deleteByQuery(\"*:*\");\n    slaveClient.deleteByQuery(\"*:*\");\n    masterClient.commit();\n    slaveClient.commit();\n\n    masterJetty.stop();\n    slaveJetty.stop();\n\n    //Start master with the new solrconfig\n    master.copyConfigFile(CONF_DIR + \"solrconfig-master-throttled.xml\", \"solrconfig.xml\");\n    useFactory(null);\n    masterJetty = createJetty(master);\n    masterClient.close();\n    masterClient = createNewSolrClient(masterJetty.getLocalPort());\n\n    //index docs\n    final int totalDocs = TestUtil.nextInt(random(), 50, 100);\n    for (int i = 0; i < totalDocs; i++)\n      index(masterClient, \"id\", i, \"name\", TestUtil.randomSimpleString(random(), 1000 , 5000));\n\n    masterClient.commit();\n\n    //Check Index Size\n    String dataDir = master.getDataDir();\n    masterClient.close();\n    masterJetty.stop();\n\n    Directory dir = FSDirectory.open(Paths.get(dataDir).resolve(\"index\"));\n    String[] files = dir.listAll();\n    long totalBytes = 0;\n    for(String file : files) {\n      totalBytes += dir.fileLength(file);\n    }\n\n    float approximateTimeInSeconds = Math.round( totalBytes/1024/1024/0.1 ); // maxWriteMBPerSec=0.1 in solrconfig\n\n    //Start again and replicate the data\n    useFactory(null);\n    masterJetty = createJetty(master);\n    masterClient = createNewSolrClient(masterJetty.getLocalPort());\n\n    //start slave\n    slave.setTestPort(masterJetty.getLocalPort());\n    slave.copyConfigFile(CONF_DIR + \"solrconfig-slave1.xml\", \"solrconfig.xml\");\n    slaveJetty = createJetty(slave);\n    slaveClient.close();\n    slaveClient = createNewSolrClient(slaveJetty.getLocalPort());\n\n    long startTime = System.nanoTime();\n\n    pullFromMasterToSlave();\n\n    //Add a few more docs in the master. Just to make sure that we are replicating the correct index point\n    //These extra docs should not get replicated\n    new Thread(new AddExtraDocs(masterClient, totalDocs)).start();\n\n    //Wait and make sure that it actually replicated correctly.\n    NamedList slaveQueryRsp = rQuery(totalDocs, \"*:*\", slaveClient);\n    SolrDocumentList slaveQueryResult = (SolrDocumentList) slaveQueryRsp.get(\"response\");\n    assertEquals(totalDocs, slaveQueryResult.getNumFound());\n\n    long timeTaken = System.nanoTime() - startTime;\n\n    long timeTakenInSeconds = TimeUnit.SECONDS.convert(timeTaken, TimeUnit.NANOSECONDS);\n\n    //Let's make sure it took more than approximateTimeInSeconds to make sure that it was throttled\n    boolean isElapsed = false;\n    if(timeTakenInSeconds - approximateTimeInSeconds > 0) {\n      isElapsed = true;\n    }\n    assertTrue(isElapsed);\n  }\n\n","sourceOld":"  @Test\n  public void testRateLimitedReplication() throws Exception {\n\n    //clean index\n    masterClient.deleteByQuery(\"*:*\");\n    slaveClient.deleteByQuery(\"*:*\");\n    masterClient.commit();\n    slaveClient.commit();\n\n    masterJetty.stop();\n    slaveJetty.stop();\n\n    //Start master with the new solrconfig\n    master.copyConfigFile(CONF_DIR + \"solrconfig-master-throttled.xml\", \"solrconfig.xml\");\n    useFactory(null);\n    masterJetty = createJetty(master);\n    masterClient.close();\n    masterClient = createNewSolrClient(masterJetty.getLocalPort());\n\n    //index docs\n    final int totalDocs = TestUtil.nextInt(random(), 50, 100);\n    for (int i = 0; i < totalDocs; i++)\n      index(masterClient, \"id\", i, \"name\", TestUtil.randomSimpleString(random(), 1000 , 5000));\n\n    masterClient.commit();\n\n    //Check Index Size\n    String dataDir = master.getDataDir();\n    masterClient.close();\n    masterJetty.stop();\n\n    Directory dir = FSDirectory.open(Paths.get(dataDir, \"index\"));\n    String[] files = dir.listAll();\n    long totalBytes = 0;\n    for(String file : files) {\n      totalBytes += dir.fileLength(file);\n    }\n\n    float approximateTimeInSeconds = Math.round( totalBytes/1024/1024/0.1 ); // maxWriteMBPerSec=0.1 in solrconfig\n\n    //Start again and replicate the data\n    useFactory(null);\n    masterJetty = createJetty(master);\n    masterClient = createNewSolrClient(masterJetty.getLocalPort());\n\n    //start slave\n    slave.setTestPort(masterJetty.getLocalPort());\n    slave.copyConfigFile(CONF_DIR + \"solrconfig-slave1.xml\", \"solrconfig.xml\");\n    slaveJetty = createJetty(slave);\n    slaveClient.close();\n    slaveClient = createNewSolrClient(slaveJetty.getLocalPort());\n\n    long startTime = System.nanoTime();\n\n    pullFromMasterToSlave();\n\n    //Add a few more docs in the master. Just to make sure that we are replicating the correct index point\n    //These extra docs should not get replicated\n    new Thread(new AddExtraDocs(masterClient, totalDocs)).start();\n\n    //Wait and make sure that it actually replicated correctly.\n    NamedList slaveQueryRsp = rQuery(totalDocs, \"*:*\", slaveClient);\n    SolrDocumentList slaveQueryResult = (SolrDocumentList) slaveQueryRsp.get(\"response\");\n    assertEquals(totalDocs, slaveQueryResult.getNumFound());\n\n    long timeTaken = System.nanoTime() - startTime;\n\n    long timeTakenInSeconds = TimeUnit.SECONDS.convert(timeTaken, TimeUnit.NANOSECONDS);\n\n    //Let's make sure it took more than approximateTimeInSeconds to make sure that it was throttled\n    boolean isElapsed = false;\n    if(timeTakenInSeconds - approximateTimeInSeconds > 0) {\n      isElapsed = true;\n    }\n    assertTrue(isElapsed);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6b5ddf3643e31125b3391eed1cd74d889dcc3b09","date":1430386016,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/handler/TestReplicationHandler#testRateLimitedReplication().mjava","pathOld":"solr/core/src/test/org/apache/solr/handler/TestReplicationHandler#testRateLimitedReplication().mjava","sourceNew":"  @Test\n  public void testRateLimitedReplication() throws Exception {\n\n    //clean index\n    masterClient.deleteByQuery(\"*:*\");\n    slaveClient.deleteByQuery(\"*:*\");\n    masterClient.commit();\n    slaveClient.commit();\n\n    masterJetty.stop();\n    slaveJetty.stop();\n\n    //Start master with the new solrconfig\n    master.copyConfigFile(CONF_DIR + \"solrconfig-master-throttled.xml\", \"solrconfig.xml\");\n    useFactory(null);\n    masterJetty = createJetty(master);\n    masterClient.close();\n    masterClient = createNewSolrClient(masterJetty.getLocalPort());\n\n    //index docs\n    final int totalDocs = TestUtil.nextInt(random(), 50, 100);\n    for (int i = 0; i < totalDocs; i++)\n      index(masterClient, \"id\", i, \"name\", TestUtil.randomSimpleString(random(), 1000 , 5000));\n\n    masterClient.commit();\n\n    //Check Index Size\n    String dataDir = master.getDataDir();\n    masterClient.close();\n    masterJetty.stop();\n\n    Directory dir = FSDirectory.open(Paths.get(dataDir).resolve(\"index\"));\n    String[] files = dir.listAll();\n    long totalBytes = 0;\n    for(String file : files) {\n      totalBytes += dir.fileLength(file);\n    }\n\n    float approximateTimeInSeconds = Math.round( totalBytes/1024/1024/0.1 ); // maxWriteMBPerSec=0.1 in solrconfig\n\n    //Start again and replicate the data\n    useFactory(null);\n    masterJetty = createJetty(master);\n    masterClient = createNewSolrClient(masterJetty.getLocalPort());\n\n    //start slave\n    slave.setTestPort(masterJetty.getLocalPort());\n    slave.copyConfigFile(CONF_DIR + \"solrconfig-slave1.xml\", \"solrconfig.xml\");\n    slaveJetty = createJetty(slave);\n    slaveClient.close();\n    slaveClient = createNewSolrClient(slaveJetty.getLocalPort());\n\n    long startTime = System.nanoTime();\n\n    pullFromMasterToSlave();\n\n    //Add a few more docs in the master. Just to make sure that we are replicating the correct index point\n    //These extra docs should not get replicated\n    new Thread(new AddExtraDocs(masterClient, totalDocs)).start();\n\n    //Wait and make sure that it actually replicated correctly.\n    NamedList slaveQueryRsp = rQuery(totalDocs, \"*:*\", slaveClient);\n    SolrDocumentList slaveQueryResult = (SolrDocumentList) slaveQueryRsp.get(\"response\");\n    assertEquals(totalDocs, slaveQueryResult.getNumFound());\n\n    long timeTaken = System.nanoTime() - startTime;\n\n    long timeTakenInSeconds = TimeUnit.SECONDS.convert(timeTaken, TimeUnit.NANOSECONDS);\n\n    //Let's make sure it took more than approximateTimeInSeconds to make sure that it was throttled\n    log.info(\"approximateTimeInSeconds = \" + approximateTimeInSeconds + \" timeTakenInSeconds = \" + timeTakenInSeconds);\n    assertTrue(timeTakenInSeconds - approximateTimeInSeconds > 0);\n  }\n\n","sourceOld":"  @Test\n  public void testRateLimitedReplication() throws Exception {\n\n    //clean index\n    masterClient.deleteByQuery(\"*:*\");\n    slaveClient.deleteByQuery(\"*:*\");\n    masterClient.commit();\n    slaveClient.commit();\n\n    masterJetty.stop();\n    slaveJetty.stop();\n\n    //Start master with the new solrconfig\n    master.copyConfigFile(CONF_DIR + \"solrconfig-master-throttled.xml\", \"solrconfig.xml\");\n    useFactory(null);\n    masterJetty = createJetty(master);\n    masterClient.close();\n    masterClient = createNewSolrClient(masterJetty.getLocalPort());\n\n    //index docs\n    final int totalDocs = TestUtil.nextInt(random(), 50, 100);\n    for (int i = 0; i < totalDocs; i++)\n      index(masterClient, \"id\", i, \"name\", TestUtil.randomSimpleString(random(), 1000 , 5000));\n\n    masterClient.commit();\n\n    //Check Index Size\n    String dataDir = master.getDataDir();\n    masterClient.close();\n    masterJetty.stop();\n\n    Directory dir = FSDirectory.open(Paths.get(dataDir).resolve(\"index\"));\n    String[] files = dir.listAll();\n    long totalBytes = 0;\n    for(String file : files) {\n      totalBytes += dir.fileLength(file);\n    }\n\n    float approximateTimeInSeconds = Math.round( totalBytes/1024/1024/0.1 ); // maxWriteMBPerSec=0.1 in solrconfig\n\n    //Start again and replicate the data\n    useFactory(null);\n    masterJetty = createJetty(master);\n    masterClient = createNewSolrClient(masterJetty.getLocalPort());\n\n    //start slave\n    slave.setTestPort(masterJetty.getLocalPort());\n    slave.copyConfigFile(CONF_DIR + \"solrconfig-slave1.xml\", \"solrconfig.xml\");\n    slaveJetty = createJetty(slave);\n    slaveClient.close();\n    slaveClient = createNewSolrClient(slaveJetty.getLocalPort());\n\n    long startTime = System.nanoTime();\n\n    pullFromMasterToSlave();\n\n    //Add a few more docs in the master. Just to make sure that we are replicating the correct index point\n    //These extra docs should not get replicated\n    new Thread(new AddExtraDocs(masterClient, totalDocs)).start();\n\n    //Wait and make sure that it actually replicated correctly.\n    NamedList slaveQueryRsp = rQuery(totalDocs, \"*:*\", slaveClient);\n    SolrDocumentList slaveQueryResult = (SolrDocumentList) slaveQueryRsp.get(\"response\");\n    assertEquals(totalDocs, slaveQueryResult.getNumFound());\n\n    long timeTaken = System.nanoTime() - startTime;\n\n    long timeTakenInSeconds = TimeUnit.SECONDS.convert(timeTaken, TimeUnit.NANOSECONDS);\n\n    //Let's make sure it took more than approximateTimeInSeconds to make sure that it was throttled\n    boolean isElapsed = false;\n    if(timeTakenInSeconds - approximateTimeInSeconds > 0) {\n      isElapsed = true;\n    }\n    assertTrue(isElapsed);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bb222a3f9d9421d5c95afce73013fbd8de07ea1f","date":1543514331,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/handler/TestReplicationHandler#testRateLimitedReplication().mjava","pathOld":"solr/core/src/test/org/apache/solr/handler/TestReplicationHandler#testRateLimitedReplication().mjava","sourceNew":"  @Test\n  public void testRateLimitedReplication() throws Exception {\n\n    //clean index\n    masterClient.deleteByQuery(\"*:*\");\n    slaveClient.deleteByQuery(\"*:*\");\n    masterClient.commit();\n    slaveClient.commit();\n\n    masterJetty.stop();\n    slaveJetty.stop();\n\n    //Start master with the new solrconfig\n    master.copyConfigFile(CONF_DIR + \"solrconfig-master-throttled.xml\", \"solrconfig.xml\");\n    useFactory(null);\n    masterJetty = createAndStartJetty(master);\n    masterClient.close();\n    masterClient = createNewSolrClient(masterJetty.getLocalPort());\n\n    //index docs\n    final int totalDocs = TestUtil.nextInt(random(), 17, 53);\n    for (int i = 0; i < totalDocs; i++)\n      index(masterClient, \"id\", i, \"name\", TestUtil.randomSimpleString(random(), 1000 , 5000));\n\n    masterClient.commit();\n\n    //Check Index Size\n    String dataDir = master.getDataDir();\n    masterClient.close();\n    masterJetty.stop();\n\n    Directory dir = FSDirectory.open(Paths.get(dataDir).resolve(\"index\"));\n    String[] files = dir.listAll();\n    long totalBytes = 0;\n    for(String file : files) {\n      totalBytes += dir.fileLength(file);\n    }\n\n    float approximateTimeInSeconds = Math.round( totalBytes/1024/1024/0.1 ); // maxWriteMBPerSec=0.1 in solrconfig\n\n    //Start again and replicate the data\n    useFactory(null);\n    masterJetty = createAndStartJetty(master);\n    masterClient = createNewSolrClient(masterJetty.getLocalPort());\n\n    //start slave\n    slave.setTestPort(masterJetty.getLocalPort());\n    slave.copyConfigFile(CONF_DIR + \"solrconfig-slave1.xml\", \"solrconfig.xml\");\n    slaveJetty = createAndStartJetty(slave);\n    slaveClient.close();\n    slaveClient = createNewSolrClient(slaveJetty.getLocalPort());\n\n    long startTime = System.nanoTime();\n\n    pullFromMasterToSlave();\n\n    //Add a few more docs in the master. Just to make sure that we are replicating the correct index point\n    //These extra docs should not get replicated\n    new Thread(new AddExtraDocs(masterClient, totalDocs)).start();\n\n    //Wait and make sure that it actually replicated correctly.\n    NamedList slaveQueryRsp = rQuery(totalDocs, \"*:*\", slaveClient);\n    SolrDocumentList slaveQueryResult = (SolrDocumentList) slaveQueryRsp.get(\"response\");\n    assertEquals(totalDocs, slaveQueryResult.getNumFound());\n\n    long timeTaken = System.nanoTime() - startTime;\n\n    long timeTakenInSeconds = TimeUnit.SECONDS.convert(timeTaken, TimeUnit.NANOSECONDS);\n\n    //Let's make sure it took more than approximateTimeInSeconds to make sure that it was throttled\n    log.info(\"approximateTimeInSeconds = \" + approximateTimeInSeconds + \" timeTakenInSeconds = \" + timeTakenInSeconds);\n    assertTrue(timeTakenInSeconds - approximateTimeInSeconds > 0);\n  }\n\n","sourceOld":"  @Test\n  public void testRateLimitedReplication() throws Exception {\n\n    //clean index\n    masterClient.deleteByQuery(\"*:*\");\n    slaveClient.deleteByQuery(\"*:*\");\n    masterClient.commit();\n    slaveClient.commit();\n\n    masterJetty.stop();\n    slaveJetty.stop();\n\n    //Start master with the new solrconfig\n    master.copyConfigFile(CONF_DIR + \"solrconfig-master-throttled.xml\", \"solrconfig.xml\");\n    useFactory(null);\n    masterJetty = createJetty(master);\n    masterClient.close();\n    masterClient = createNewSolrClient(masterJetty.getLocalPort());\n\n    //index docs\n    final int totalDocs = TestUtil.nextInt(random(), 50, 100);\n    for (int i = 0; i < totalDocs; i++)\n      index(masterClient, \"id\", i, \"name\", TestUtil.randomSimpleString(random(), 1000 , 5000));\n\n    masterClient.commit();\n\n    //Check Index Size\n    String dataDir = master.getDataDir();\n    masterClient.close();\n    masterJetty.stop();\n\n    Directory dir = FSDirectory.open(Paths.get(dataDir).resolve(\"index\"));\n    String[] files = dir.listAll();\n    long totalBytes = 0;\n    for(String file : files) {\n      totalBytes += dir.fileLength(file);\n    }\n\n    float approximateTimeInSeconds = Math.round( totalBytes/1024/1024/0.1 ); // maxWriteMBPerSec=0.1 in solrconfig\n\n    //Start again and replicate the data\n    useFactory(null);\n    masterJetty = createJetty(master);\n    masterClient = createNewSolrClient(masterJetty.getLocalPort());\n\n    //start slave\n    slave.setTestPort(masterJetty.getLocalPort());\n    slave.copyConfigFile(CONF_DIR + \"solrconfig-slave1.xml\", \"solrconfig.xml\");\n    slaveJetty = createJetty(slave);\n    slaveClient.close();\n    slaveClient = createNewSolrClient(slaveJetty.getLocalPort());\n\n    long startTime = System.nanoTime();\n\n    pullFromMasterToSlave();\n\n    //Add a few more docs in the master. Just to make sure that we are replicating the correct index point\n    //These extra docs should not get replicated\n    new Thread(new AddExtraDocs(masterClient, totalDocs)).start();\n\n    //Wait and make sure that it actually replicated correctly.\n    NamedList slaveQueryRsp = rQuery(totalDocs, \"*:*\", slaveClient);\n    SolrDocumentList slaveQueryResult = (SolrDocumentList) slaveQueryRsp.get(\"response\");\n    assertEquals(totalDocs, slaveQueryResult.getNumFound());\n\n    long timeTaken = System.nanoTime() - startTime;\n\n    long timeTakenInSeconds = TimeUnit.SECONDS.convert(timeTaken, TimeUnit.NANOSECONDS);\n\n    //Let's make sure it took more than approximateTimeInSeconds to make sure that it was throttled\n    log.info(\"approximateTimeInSeconds = \" + approximateTimeInSeconds + \" timeTakenInSeconds = \" + timeTakenInSeconds);\n    assertTrue(timeTakenInSeconds - approximateTimeInSeconds > 0);\n  }\n\n","bugFix":["5a2d81cf6955f09cda03ed448bb9bb397d4b9742"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a966532d92cf9ba2856f15a8140151bb6b518e4b","date":1588290631,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/handler/TestReplicationHandler#testRateLimitedReplication().mjava","pathOld":"solr/core/src/test/org/apache/solr/handler/TestReplicationHandler#testRateLimitedReplication().mjava","sourceNew":"  @Test\n  public void testRateLimitedReplication() throws Exception {\n\n    //clean index\n    masterClient.deleteByQuery(\"*:*\");\n    slaveClient.deleteByQuery(\"*:*\");\n    masterClient.commit();\n    slaveClient.commit();\n\n    masterJetty.stop();\n    slaveJetty.stop();\n\n    //Start master with the new solrconfig\n    master.copyConfigFile(CONF_DIR + \"solrconfig-master-throttled.xml\", \"solrconfig.xml\");\n    useFactory(null);\n    masterJetty = createAndStartJetty(master);\n    masterClient.close();\n    masterClient = createNewSolrClient(masterJetty.getLocalPort());\n\n    //index docs\n    final int totalDocs = TestUtil.nextInt(random(), 17, 53);\n    for (int i = 0; i < totalDocs; i++)\n      index(masterClient, \"id\", i, \"name\", TestUtil.randomSimpleString(random(), 1000 , 5000));\n\n    masterClient.commit();\n\n    //Check Index Size\n    String dataDir = master.getDataDir();\n    masterClient.close();\n    masterJetty.stop();\n\n    Directory dir = FSDirectory.open(Paths.get(dataDir).resolve(\"index\"));\n    String[] files = dir.listAll();\n    long totalBytes = 0;\n    for(String file : files) {\n      totalBytes += dir.fileLength(file);\n    }\n\n    float approximateTimeInSeconds = Math.round( totalBytes/1024/1024/0.1 ); // maxWriteMBPerSec=0.1 in solrconfig\n\n    //Start again and replicate the data\n    useFactory(null);\n    masterJetty = createAndStartJetty(master);\n    masterClient = createNewSolrClient(masterJetty.getLocalPort());\n\n    //start slave\n    slave.setTestPort(masterJetty.getLocalPort());\n    slave.copyConfigFile(CONF_DIR + \"solrconfig-slave1.xml\", \"solrconfig.xml\");\n    slaveJetty = createAndStartJetty(slave);\n    slaveClient.close();\n    slaveClient = createNewSolrClient(slaveJetty.getLocalPort());\n\n    long startTime = System.nanoTime();\n\n    pullFromMasterToSlave();\n\n    //Add a few more docs in the master. Just to make sure that we are replicating the correct index point\n    //These extra docs should not get replicated\n    new Thread(new AddExtraDocs(masterClient, totalDocs)).start();\n\n    //Wait and make sure that it actually replicated correctly.\n    NamedList slaveQueryRsp = rQuery(totalDocs, \"*:*\", slaveClient);\n    SolrDocumentList slaveQueryResult = (SolrDocumentList) slaveQueryRsp.get(\"response\");\n    assertEquals(totalDocs, slaveQueryResult.getNumFound());\n\n    long timeTaken = System.nanoTime() - startTime;\n\n    long timeTakenInSeconds = TimeUnit.SECONDS.convert(timeTaken, TimeUnit.NANOSECONDS);\n\n    //Let's make sure it took more than approximateTimeInSeconds to make sure that it was throttled\n    log.info(\"approximateTimeInSeconds = {} timeTakenInSeconds = {}\"\n        , approximateTimeInSeconds, timeTakenInSeconds);\n    assertTrue(timeTakenInSeconds - approximateTimeInSeconds > 0);\n  }\n\n","sourceOld":"  @Test\n  public void testRateLimitedReplication() throws Exception {\n\n    //clean index\n    masterClient.deleteByQuery(\"*:*\");\n    slaveClient.deleteByQuery(\"*:*\");\n    masterClient.commit();\n    slaveClient.commit();\n\n    masterJetty.stop();\n    slaveJetty.stop();\n\n    //Start master with the new solrconfig\n    master.copyConfigFile(CONF_DIR + \"solrconfig-master-throttled.xml\", \"solrconfig.xml\");\n    useFactory(null);\n    masterJetty = createAndStartJetty(master);\n    masterClient.close();\n    masterClient = createNewSolrClient(masterJetty.getLocalPort());\n\n    //index docs\n    final int totalDocs = TestUtil.nextInt(random(), 17, 53);\n    for (int i = 0; i < totalDocs; i++)\n      index(masterClient, \"id\", i, \"name\", TestUtil.randomSimpleString(random(), 1000 , 5000));\n\n    masterClient.commit();\n\n    //Check Index Size\n    String dataDir = master.getDataDir();\n    masterClient.close();\n    masterJetty.stop();\n\n    Directory dir = FSDirectory.open(Paths.get(dataDir).resolve(\"index\"));\n    String[] files = dir.listAll();\n    long totalBytes = 0;\n    for(String file : files) {\n      totalBytes += dir.fileLength(file);\n    }\n\n    float approximateTimeInSeconds = Math.round( totalBytes/1024/1024/0.1 ); // maxWriteMBPerSec=0.1 in solrconfig\n\n    //Start again and replicate the data\n    useFactory(null);\n    masterJetty = createAndStartJetty(master);\n    masterClient = createNewSolrClient(masterJetty.getLocalPort());\n\n    //start slave\n    slave.setTestPort(masterJetty.getLocalPort());\n    slave.copyConfigFile(CONF_DIR + \"solrconfig-slave1.xml\", \"solrconfig.xml\");\n    slaveJetty = createAndStartJetty(slave);\n    slaveClient.close();\n    slaveClient = createNewSolrClient(slaveJetty.getLocalPort());\n\n    long startTime = System.nanoTime();\n\n    pullFromMasterToSlave();\n\n    //Add a few more docs in the master. Just to make sure that we are replicating the correct index point\n    //These extra docs should not get replicated\n    new Thread(new AddExtraDocs(masterClient, totalDocs)).start();\n\n    //Wait and make sure that it actually replicated correctly.\n    NamedList slaveQueryRsp = rQuery(totalDocs, \"*:*\", slaveClient);\n    SolrDocumentList slaveQueryResult = (SolrDocumentList) slaveQueryRsp.get(\"response\");\n    assertEquals(totalDocs, slaveQueryResult.getNumFound());\n\n    long timeTaken = System.nanoTime() - startTime;\n\n    long timeTakenInSeconds = TimeUnit.SECONDS.convert(timeTaken, TimeUnit.NANOSECONDS);\n\n    //Let's make sure it took more than approximateTimeInSeconds to make sure that it was throttled\n    log.info(\"approximateTimeInSeconds = \" + approximateTimeInSeconds + \" timeTakenInSeconds = \" + timeTakenInSeconds);\n    assertTrue(timeTakenInSeconds - approximateTimeInSeconds > 0);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e98520789adb1d5ad05afb4956eca0944a929688","date":1592430701,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/handler/TestReplicationHandler#testRateLimitedReplication().mjava","pathOld":"solr/core/src/test/org/apache/solr/handler/TestReplicationHandler#testRateLimitedReplication().mjava","sourceNew":"  @Test\n  public void testRateLimitedReplication() throws Exception {\n\n    //clean index\n    masterClient.deleteByQuery(\"*:*\");\n    slaveClient.deleteByQuery(\"*:*\");\n    masterClient.commit();\n    slaveClient.commit();\n\n    masterJetty.stop();\n    slaveJetty.stop();\n\n    //Start master with the new solrconfig\n    master.copyConfigFile(CONF_DIR + \"solrconfig-master-throttled.xml\", \"solrconfig.xml\");\n    useFactory(null);\n    masterJetty = createAndStartJetty(master);\n    masterClient.close();\n    masterClient = createNewSolrClient(masterJetty.getLocalPort());\n\n    //index docs\n    final int totalDocs = TestUtil.nextInt(random(), 17, 53);\n    for (int i = 0; i < totalDocs; i++)\n      index(masterClient, \"id\", i, \"name\", TestUtil.randomSimpleString(random(), 1000 , 5000));\n\n    masterClient.commit();\n\n    //Check Index Size\n    String dataDir = master.getDataDir();\n    masterClient.close();\n    masterJetty.stop();\n\n    Directory dir = FSDirectory.open(Paths.get(dataDir).resolve(\"index\"));\n    String[] files = dir.listAll();\n    long totalBytes = 0;\n    for(String file : files) {\n      totalBytes += dir.fileLength(file);\n    }\n\n    float approximateTimeInSeconds = Math.round( totalBytes/1024/1024/0.1 ); // maxWriteMBPerSec=0.1 in solrconfig\n\n    //Start again and replicate the data\n    useFactory(null);\n    masterJetty = createAndStartJetty(master);\n    masterClient = createNewSolrClient(masterJetty.getLocalPort());\n\n    //start slave\n    slave.setTestPort(masterJetty.getLocalPort());\n    slave.copyConfigFile(CONF_DIR + \"solrconfig-slave1.xml\", \"solrconfig.xml\");\n    slaveJetty = createAndStartJetty(slave);\n    slaveClient.close();\n    slaveClient = createNewSolrClient(slaveJetty.getLocalPort());\n\n    long startTime = System.nanoTime();\n\n    pullFromMasterToSlave();\n\n    //Add a few more docs in the master. Just to make sure that we are replicating the correct index point\n    //These extra docs should not get replicated\n    new Thread(new AddExtraDocs(masterClient, totalDocs)).start();\n\n    //Wait and make sure that it actually replicated correctly.\n    @SuppressWarnings({\"rawtypes\"})\n    NamedList slaveQueryRsp = rQuery(totalDocs, \"*:*\", slaveClient);\n    SolrDocumentList slaveQueryResult = (SolrDocumentList) slaveQueryRsp.get(\"response\");\n    assertEquals(totalDocs, slaveQueryResult.getNumFound());\n\n    long timeTaken = System.nanoTime() - startTime;\n\n    long timeTakenInSeconds = TimeUnit.SECONDS.convert(timeTaken, TimeUnit.NANOSECONDS);\n\n    //Let's make sure it took more than approximateTimeInSeconds to make sure that it was throttled\n    log.info(\"approximateTimeInSeconds = {} timeTakenInSeconds = {}\"\n        , approximateTimeInSeconds, timeTakenInSeconds);\n    assertTrue(timeTakenInSeconds - approximateTimeInSeconds > 0);\n  }\n\n","sourceOld":"  @Test\n  public void testRateLimitedReplication() throws Exception {\n\n    //clean index\n    masterClient.deleteByQuery(\"*:*\");\n    slaveClient.deleteByQuery(\"*:*\");\n    masterClient.commit();\n    slaveClient.commit();\n\n    masterJetty.stop();\n    slaveJetty.stop();\n\n    //Start master with the new solrconfig\n    master.copyConfigFile(CONF_DIR + \"solrconfig-master-throttled.xml\", \"solrconfig.xml\");\n    useFactory(null);\n    masterJetty = createAndStartJetty(master);\n    masterClient.close();\n    masterClient = createNewSolrClient(masterJetty.getLocalPort());\n\n    //index docs\n    final int totalDocs = TestUtil.nextInt(random(), 17, 53);\n    for (int i = 0; i < totalDocs; i++)\n      index(masterClient, \"id\", i, \"name\", TestUtil.randomSimpleString(random(), 1000 , 5000));\n\n    masterClient.commit();\n\n    //Check Index Size\n    String dataDir = master.getDataDir();\n    masterClient.close();\n    masterJetty.stop();\n\n    Directory dir = FSDirectory.open(Paths.get(dataDir).resolve(\"index\"));\n    String[] files = dir.listAll();\n    long totalBytes = 0;\n    for(String file : files) {\n      totalBytes += dir.fileLength(file);\n    }\n\n    float approximateTimeInSeconds = Math.round( totalBytes/1024/1024/0.1 ); // maxWriteMBPerSec=0.1 in solrconfig\n\n    //Start again and replicate the data\n    useFactory(null);\n    masterJetty = createAndStartJetty(master);\n    masterClient = createNewSolrClient(masterJetty.getLocalPort());\n\n    //start slave\n    slave.setTestPort(masterJetty.getLocalPort());\n    slave.copyConfigFile(CONF_DIR + \"solrconfig-slave1.xml\", \"solrconfig.xml\");\n    slaveJetty = createAndStartJetty(slave);\n    slaveClient.close();\n    slaveClient = createNewSolrClient(slaveJetty.getLocalPort());\n\n    long startTime = System.nanoTime();\n\n    pullFromMasterToSlave();\n\n    //Add a few more docs in the master. Just to make sure that we are replicating the correct index point\n    //These extra docs should not get replicated\n    new Thread(new AddExtraDocs(masterClient, totalDocs)).start();\n\n    //Wait and make sure that it actually replicated correctly.\n    NamedList slaveQueryRsp = rQuery(totalDocs, \"*:*\", slaveClient);\n    SolrDocumentList slaveQueryResult = (SolrDocumentList) slaveQueryRsp.get(\"response\");\n    assertEquals(totalDocs, slaveQueryResult.getNumFound());\n\n    long timeTaken = System.nanoTime() - startTime;\n\n    long timeTakenInSeconds = TimeUnit.SECONDS.convert(timeTaken, TimeUnit.NANOSECONDS);\n\n    //Let's make sure it took more than approximateTimeInSeconds to make sure that it was throttled\n    log.info(\"approximateTimeInSeconds = {} timeTakenInSeconds = {}\"\n        , approximateTimeInSeconds, timeTakenInSeconds);\n    assertTrue(timeTakenInSeconds - approximateTimeInSeconds > 0);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"65a5d87a40f9143cd55be76eb1dde1b32a8dae5e","date":1596664368,"type":3,"author":"Marcus","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/handler/TestReplicationHandler#testRateLimitedReplication().mjava","pathOld":"solr/core/src/test/org/apache/solr/handler/TestReplicationHandler#testRateLimitedReplication().mjava","sourceNew":"  @Test\n  public void testRateLimitedReplication() throws Exception {\n\n    //clean index\n    leaderClient.deleteByQuery(\"*:*\");\n    followerClient.deleteByQuery(\"*:*\");\n    leaderClient.commit();\n    followerClient.commit();\n\n    leaderJetty.stop();\n    followerJetty.stop();\n\n    //Start leader with the new solrconfig\n    leader.copyConfigFile(CONF_DIR + \"solrconfig-leader-throttled.xml\", \"solrconfig.xml\");\n    useFactory(null);\n    leaderJetty = createAndStartJetty(leader);\n    leaderClient.close();\n    leaderClient = createNewSolrClient(leaderJetty.getLocalPort());\n\n    //index docs\n    final int totalDocs = TestUtil.nextInt(random(), 17, 53);\n    for (int i = 0; i < totalDocs; i++)\n      index(leaderClient, \"id\", i, \"name\", TestUtil.randomSimpleString(random(), 1000 , 5000));\n\n    leaderClient.commit();\n\n    //Check Index Size\n    String dataDir = leader.getDataDir();\n    leaderClient.close();\n    leaderJetty.stop();\n\n    Directory dir = FSDirectory.open(Paths.get(dataDir).resolve(\"index\"));\n    String[] files = dir.listAll();\n    long totalBytes = 0;\n    for(String file : files) {\n      totalBytes += dir.fileLength(file);\n    }\n\n    float approximateTimeInSeconds = Math.round( totalBytes/1024/1024/0.1 ); // maxWriteMBPerSec=0.1 in solrconfig\n\n    //Start again and replicate the data\n    useFactory(null);\n    leaderJetty = createAndStartJetty(leader);\n    leaderClient = createNewSolrClient(leaderJetty.getLocalPort());\n\n    //start follower\n    follower.setTestPort(leaderJetty.getLocalPort());\n    follower.copyConfigFile(CONF_DIR + \"solrconfig-follower1.xml\", \"solrconfig.xml\");\n    followerJetty = createAndStartJetty(follower);\n    followerClient.close();\n    followerClient = createNewSolrClient(followerJetty.getLocalPort());\n\n    long startTime = System.nanoTime();\n\n    pullFromLeaderToFollower();\n\n    //Add a few more docs in the leader. Just to make sure that we are replicating the correct index point\n    //These extra docs should not get replicated\n    new Thread(new AddExtraDocs(leaderClient, totalDocs)).start();\n\n    //Wait and make sure that it actually replicated correctly.\n    @SuppressWarnings({\"rawtypes\"})\n    NamedList followerQueryRsp = rQuery(totalDocs, \"*:*\", followerClient);\n    SolrDocumentList followerQueryResult = (SolrDocumentList) followerQueryRsp.get(\"response\");\n    assertEquals(totalDocs, followerQueryResult.getNumFound());\n\n    long timeTaken = System.nanoTime() - startTime;\n\n    long timeTakenInSeconds = TimeUnit.SECONDS.convert(timeTaken, TimeUnit.NANOSECONDS);\n\n    //Let's make sure it took more than approximateTimeInSeconds to make sure that it was throttled\n    log.info(\"approximateTimeInSeconds = {} timeTakenInSeconds = {}\"\n        , approximateTimeInSeconds, timeTakenInSeconds);\n    assertTrue(timeTakenInSeconds - approximateTimeInSeconds > 0);\n  }\n\n","sourceOld":"  @Test\n  public void testRateLimitedReplication() throws Exception {\n\n    //clean index\n    masterClient.deleteByQuery(\"*:*\");\n    slaveClient.deleteByQuery(\"*:*\");\n    masterClient.commit();\n    slaveClient.commit();\n\n    masterJetty.stop();\n    slaveJetty.stop();\n\n    //Start master with the new solrconfig\n    master.copyConfigFile(CONF_DIR + \"solrconfig-master-throttled.xml\", \"solrconfig.xml\");\n    useFactory(null);\n    masterJetty = createAndStartJetty(master);\n    masterClient.close();\n    masterClient = createNewSolrClient(masterJetty.getLocalPort());\n\n    //index docs\n    final int totalDocs = TestUtil.nextInt(random(), 17, 53);\n    for (int i = 0; i < totalDocs; i++)\n      index(masterClient, \"id\", i, \"name\", TestUtil.randomSimpleString(random(), 1000 , 5000));\n\n    masterClient.commit();\n\n    //Check Index Size\n    String dataDir = master.getDataDir();\n    masterClient.close();\n    masterJetty.stop();\n\n    Directory dir = FSDirectory.open(Paths.get(dataDir).resolve(\"index\"));\n    String[] files = dir.listAll();\n    long totalBytes = 0;\n    for(String file : files) {\n      totalBytes += dir.fileLength(file);\n    }\n\n    float approximateTimeInSeconds = Math.round( totalBytes/1024/1024/0.1 ); // maxWriteMBPerSec=0.1 in solrconfig\n\n    //Start again and replicate the data\n    useFactory(null);\n    masterJetty = createAndStartJetty(master);\n    masterClient = createNewSolrClient(masterJetty.getLocalPort());\n\n    //start slave\n    slave.setTestPort(masterJetty.getLocalPort());\n    slave.copyConfigFile(CONF_DIR + \"solrconfig-slave1.xml\", \"solrconfig.xml\");\n    slaveJetty = createAndStartJetty(slave);\n    slaveClient.close();\n    slaveClient = createNewSolrClient(slaveJetty.getLocalPort());\n\n    long startTime = System.nanoTime();\n\n    pullFromMasterToSlave();\n\n    //Add a few more docs in the master. Just to make sure that we are replicating the correct index point\n    //These extra docs should not get replicated\n    new Thread(new AddExtraDocs(masterClient, totalDocs)).start();\n\n    //Wait and make sure that it actually replicated correctly.\n    @SuppressWarnings({\"rawtypes\"})\n    NamedList slaveQueryRsp = rQuery(totalDocs, \"*:*\", slaveClient);\n    SolrDocumentList slaveQueryResult = (SolrDocumentList) slaveQueryRsp.get(\"response\");\n    assertEquals(totalDocs, slaveQueryResult.getNumFound());\n\n    long timeTaken = System.nanoTime() - startTime;\n\n    long timeTakenInSeconds = TimeUnit.SECONDS.convert(timeTaken, TimeUnit.NANOSECONDS);\n\n    //Let's make sure it took more than approximateTimeInSeconds to make sure that it was throttled\n    log.info(\"approximateTimeInSeconds = {} timeTakenInSeconds = {}\"\n        , approximateTimeInSeconds, timeTakenInSeconds);\n    assertTrue(timeTakenInSeconds - approximateTimeInSeconds > 0);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"65a5d87a40f9143cd55be76eb1dde1b32a8dae5e":["e98520789adb1d5ad05afb4956eca0944a929688"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["6b5ddf3643e31125b3391eed1cd74d889dcc3b09"],"6b5ddf3643e31125b3391eed1cd74d889dcc3b09":["c42316df77794f7252857e7d5e9ce45ff1d65c61"],"5a2d81cf6955f09cda03ed448bb9bb397d4b9742":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cc3b13b430571c2e169f98fe38e1e7666f88522d":["bafca15d8e408346a67f4282ad1143b88023893b"],"bafca15d8e408346a67f4282ad1143b88023893b":["5a2d81cf6955f09cda03ed448bb9bb397d4b9742"],"a966532d92cf9ba2856f15a8140151bb6b518e4b":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"c42316df77794f7252857e7d5e9ce45ff1d65c61":["cc3b13b430571c2e169f98fe38e1e7666f88522d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["65a5d87a40f9143cd55be76eb1dde1b32a8dae5e"],"e98520789adb1d5ad05afb4956eca0944a929688":["a966532d92cf9ba2856f15a8140151bb6b518e4b"]},"commit2Childs":{"65a5d87a40f9143cd55be76eb1dde1b32a8dae5e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["a966532d92cf9ba2856f15a8140151bb6b518e4b"],"6b5ddf3643e31125b3391eed1cd74d889dcc3b09":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"5a2d81cf6955f09cda03ed448bb9bb397d4b9742":["bafca15d8e408346a67f4282ad1143b88023893b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["5a2d81cf6955f09cda03ed448bb9bb397d4b9742"],"cc3b13b430571c2e169f98fe38e1e7666f88522d":["c42316df77794f7252857e7d5e9ce45ff1d65c61"],"bafca15d8e408346a67f4282ad1143b88023893b":["cc3b13b430571c2e169f98fe38e1e7666f88522d"],"c42316df77794f7252857e7d5e9ce45ff1d65c61":["6b5ddf3643e31125b3391eed1cd74d889dcc3b09"],"a966532d92cf9ba2856f15a8140151bb6b518e4b":["e98520789adb1d5ad05afb4956eca0944a929688"],"e98520789adb1d5ad05afb4956eca0944a929688":["65a5d87a40f9143cd55be76eb1dde1b32a8dae5e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}