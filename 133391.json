{"path":"lucene/core/src/java/org/apache/lucene/search/CachingWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/CachingWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/CachingWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n\n    // Only cache if incoming acceptDocs is == live docs;\n    // if Lucene passes in more interesting acceptDocs in\n    // the future (@UweSays: it already does when you chain FilteredQuery) we don't want to over-cache:\n    final Bits liveDocs = reader.getLiveDocs();\n    final boolean doCacheAcceptDocs = (recacheDeletes && acceptDocs == liveDocs);\n\n    final Object key;\n    final Bits cacheAcceptDocs;\n    if (doCacheAcceptDocs) {\n      assert acceptDocs == liveDocs;\n      key = reader.getCombinedCoreAndDeletesKey();\n      cacheAcceptDocs = acceptDocs;\n    } else {\n      key = reader.getCoreCacheKey();\n      cacheAcceptDocs = null;\n    }\n\n    DocIdSet docIdSet = cache.get(key);\n    if (docIdSet != null) {\n      hitCount++;\n    } else {\n      missCount++;\n      docIdSet = docIdSetToCache(filter.getDocIdSet(context, cacheAcceptDocs), reader);\n      cache.put(key, docIdSet);\n    }\n\n    if (doCacheAcceptDocs) {\n      return docIdSet;\n    } else {\n      return BitsFilteredDocIdSet.wrap(docIdSet, acceptDocs);\n    }\n  }\n\n","sourceOld":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n\n    // Only cache if incoming acceptDocs is == live docs;\n    // if Lucene passes in more interesting acceptDocs in\n    // the future (@UweSays: it already does when you chain FilteredQuery) we don't want to over-cache:\n    final Bits liveDocs = reader.getLiveDocs();\n    final boolean doCacheAcceptDocs = (recacheDeletes && acceptDocs == liveDocs);\n\n    final Object key;\n    final Bits cacheAcceptDocs;\n    if (doCacheAcceptDocs) {\n      assert acceptDocs == liveDocs;\n      key = reader.getCombinedCoreAndDeletesKey();\n      cacheAcceptDocs = acceptDocs;\n    } else {\n      key = reader.getCoreCacheKey();\n      cacheAcceptDocs = null;\n    }\n\n    DocIdSet docIdSet = cache.get(key);\n    if (docIdSet != null) {\n      hitCount++;\n    } else {\n      missCount++;\n      docIdSet = docIdSetToCache(filter.getDocIdSet(context, cacheAcceptDocs), reader);\n      cache.put(key, docIdSet);\n    }\n\n    if (doCacheAcceptDocs) {\n      return docIdSet;\n    } else {\n      return BitsFilteredDocIdSet.wrap(docIdSet, acceptDocs);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9a3bd393140af58401b6bcd1d1f6bdc896c718c8","date":1354060578,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/CachingWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/CachingWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    final Object key = reader.getCoreCacheKey();\n\n    DocIdSet docIdSet = cache.get(key);\n    if (docIdSet != null) {\n      hitCount++;\n    } else {\n      missCount++;\n      docIdSet = docIdSetToCache(filter.getDocIdSet(context, null), reader);\n      cache.put(key, docIdSet);\n    }\n\n    return BitsFilteredDocIdSet.wrap(docIdSet, acceptDocs);\n  }\n\n","sourceOld":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n\n    // Only cache if incoming acceptDocs is == live docs;\n    // if Lucene passes in more interesting acceptDocs in\n    // the future (@UweSays: it already does when you chain FilteredQuery) we don't want to over-cache:\n    final Bits liveDocs = reader.getLiveDocs();\n    final boolean doCacheAcceptDocs = (recacheDeletes && acceptDocs == liveDocs);\n\n    final Object key;\n    final Bits cacheAcceptDocs;\n    if (doCacheAcceptDocs) {\n      assert acceptDocs == liveDocs;\n      key = reader.getCombinedCoreAndDeletesKey();\n      cacheAcceptDocs = acceptDocs;\n    } else {\n      key = reader.getCoreCacheKey();\n      cacheAcceptDocs = null;\n    }\n\n    DocIdSet docIdSet = cache.get(key);\n    if (docIdSet != null) {\n      hitCount++;\n    } else {\n      missCount++;\n      docIdSet = docIdSetToCache(filter.getDocIdSet(context, cacheAcceptDocs), reader);\n      cache.put(key, docIdSet);\n    }\n\n    if (doCacheAcceptDocs) {\n      return docIdSet;\n    } else {\n      return BitsFilteredDocIdSet.wrap(docIdSet, acceptDocs);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"407687e67faf6e1f02a211ca078d8e3eed631027","date":1355157407,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/search/CachingWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/CachingWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    final Object key = reader.getCoreCacheKey();\n\n    DocIdSet docIdSet = cache.get(key);\n    if (docIdSet != null) {\n      hitCount++;\n    } else {\n      missCount++;\n      docIdSet = docIdSetToCache(filter.getDocIdSet(context, null), reader);\n      cache.put(key, docIdSet);\n    }\n\n    return BitsFilteredDocIdSet.wrap(docIdSet, acceptDocs);\n  }\n\n","sourceOld":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n\n    // Only cache if incoming acceptDocs is == live docs;\n    // if Lucene passes in more interesting acceptDocs in\n    // the future (@UweSays: it already does when you chain FilteredQuery) we don't want to over-cache:\n    final Bits liveDocs = reader.getLiveDocs();\n    final boolean doCacheAcceptDocs = (recacheDeletes && acceptDocs == liveDocs);\n\n    final Object key;\n    final Bits cacheAcceptDocs;\n    if (doCacheAcceptDocs) {\n      assert acceptDocs == liveDocs;\n      key = reader.getCombinedCoreAndDeletesKey();\n      cacheAcceptDocs = acceptDocs;\n    } else {\n      key = reader.getCoreCacheKey();\n      cacheAcceptDocs = null;\n    }\n\n    DocIdSet docIdSet = cache.get(key);\n    if (docIdSet != null) {\n      hitCount++;\n    } else {\n      missCount++;\n      docIdSet = docIdSetToCache(filter.getDocIdSet(context, cacheAcceptDocs), reader);\n      cache.put(key, docIdSet);\n    }\n\n    if (doCacheAcceptDocs) {\n      return docIdSet;\n    } else {\n      return BitsFilteredDocIdSet.wrap(docIdSet, acceptDocs);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"dc06632ede7e48a5ddc6917badec25c8336feedc","date":1366983006,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/CachingWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/CachingWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    final Object key = reader.getCoreCacheKey();\n\n    DocIdSet docIdSet = cache.get(key);\n    if (docIdSet != null) {\n      hitCount++;\n    } else {\n      missCount++;\n      docIdSet = docIdSetToCache(filter.getDocIdSet(context, null), reader);\n      cache.put(key, docIdSet);\n    }\n\n    return docIdSet == EMPTY_DOCIDSET ? null : BitsFilteredDocIdSet.wrap(docIdSet, acceptDocs);\n  }\n\n","sourceOld":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    final Object key = reader.getCoreCacheKey();\n\n    DocIdSet docIdSet = cache.get(key);\n    if (docIdSet != null) {\n      hitCount++;\n    } else {\n      missCount++;\n      docIdSet = docIdSetToCache(filter.getDocIdSet(context, null), reader);\n      cache.put(key, docIdSet);\n    }\n\n    return BitsFilteredDocIdSet.wrap(docIdSet, acceptDocs);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"49a8cbd66bc94e18d7b9087e42dbc6cc0ee0c161","date":1378462032,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/CachingWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/CachingWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    final Object key = reader.getCoreCacheKey();\n\n    DocIdSet docIdSet = cache.get(key);\n    if (docIdSet != null) {\n      hitCount++;\n    } else {\n      missCount++;\n      docIdSet = docIdSetToCache(filter.getDocIdSet(context, null), reader);\n      assert docIdSet.isCacheable();\n      cache.put(key, docIdSet);\n    }\n\n    return docIdSet == EMPTY_DOCIDSET ? null : BitsFilteredDocIdSet.wrap(docIdSet, acceptDocs);\n  }\n\n","sourceOld":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    final Object key = reader.getCoreCacheKey();\n\n    DocIdSet docIdSet = cache.get(key);\n    if (docIdSet != null) {\n      hitCount++;\n    } else {\n      missCount++;\n      docIdSet = docIdSetToCache(filter.getDocIdSet(context, null), reader);\n      cache.put(key, docIdSet);\n    }\n\n    return docIdSet == EMPTY_DOCIDSET ? null : BitsFilteredDocIdSet.wrap(docIdSet, acceptDocs);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54ea8c8c94ae9da9a366175e2abbe1dde3aa0453","date":1402659583,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/CachingWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/CachingWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    final Object key = reader.getCoreCacheKey();\n\n    DocIdSet docIdSet = cache.get(key);\n    if (docIdSet != null) {\n      hitCount++;\n    } else {\n      missCount++;\n      docIdSet = docIdSetToCache(filter.getDocIdSet(context, null), reader);\n      assert docIdSet.isCacheable();\n      cache.put(key, docIdSet);\n    }\n\n    return docIdSet == EMPTY ? null : BitsFilteredDocIdSet.wrap(docIdSet, acceptDocs);\n  }\n\n","sourceOld":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    final Object key = reader.getCoreCacheKey();\n\n    DocIdSet docIdSet = cache.get(key);\n    if (docIdSet != null) {\n      hitCount++;\n    } else {\n      missCount++;\n      docIdSet = docIdSetToCache(filter.getDocIdSet(context, null), reader);\n      assert docIdSet.isCacheable();\n      cache.put(key, docIdSet);\n    }\n\n    return docIdSet == EMPTY_DOCIDSET ? null : BitsFilteredDocIdSet.wrap(docIdSet, acceptDocs);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c6f080a2ab37c464dd98db173f6cbf10dc74f211","date":1402946779,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/search/CachingWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/CachingWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    final Object key = reader.getCoreCacheKey();\n\n    DocIdSet docIdSet = cache.get(key);\n    if (docIdSet != null) {\n      hitCount++;\n    } else {\n      missCount++;\n      docIdSet = docIdSetToCache(filter.getDocIdSet(context, null), reader);\n      assert docIdSet.isCacheable();\n      cache.put(key, docIdSet);\n    }\n\n    return docIdSet == EMPTY ? null : BitsFilteredDocIdSet.wrap(docIdSet, acceptDocs);\n  }\n\n","sourceOld":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    final Object key = reader.getCoreCacheKey();\n\n    DocIdSet docIdSet = cache.get(key);\n    if (docIdSet != null) {\n      hitCount++;\n    } else {\n      missCount++;\n      docIdSet = docIdSetToCache(filter.getDocIdSet(context, null), reader);\n      assert docIdSet.isCacheable();\n      cache.put(key, docIdSet);\n    }\n\n    return docIdSet == EMPTY_DOCIDSET ? null : BitsFilteredDocIdSet.wrap(docIdSet, acceptDocs);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c9fb5f46e264daf5ba3860defe623a89d202dd87","date":1411516315,"type":4,"author":"Ryan Ernst","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/core/src/java/org/apache/lucene/search/CachingWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":null,"sourceOld":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    final Object key = reader.getCoreCacheKey();\n\n    DocIdSet docIdSet = cache.get(key);\n    if (docIdSet != null) {\n      hitCount++;\n    } else {\n      missCount++;\n      docIdSet = docIdSetToCache(filter.getDocIdSet(context, null), reader);\n      assert docIdSet.isCacheable();\n      cache.put(key, docIdSet);\n    }\n\n    return docIdSet == EMPTY ? null : BitsFilteredDocIdSet.wrap(docIdSet, acceptDocs);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"dc06632ede7e48a5ddc6917badec25c8336feedc":["9a3bd393140af58401b6bcd1d1f6bdc896c718c8"],"54ea8c8c94ae9da9a366175e2abbe1dde3aa0453":["49a8cbd66bc94e18d7b9087e42dbc6cc0ee0c161"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"407687e67faf6e1f02a211ca078d8e3eed631027":["3a119bbc8703c10faa329ec201c654b3a35a1e3e","9a3bd393140af58401b6bcd1d1f6bdc896c718c8"],"49a8cbd66bc94e18d7b9087e42dbc6cc0ee0c161":["dc06632ede7e48a5ddc6917badec25c8336feedc"],"9a3bd393140af58401b6bcd1d1f6bdc896c718c8":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"c6f080a2ab37c464dd98db173f6cbf10dc74f211":["49a8cbd66bc94e18d7b9087e42dbc6cc0ee0c161","54ea8c8c94ae9da9a366175e2abbe1dde3aa0453"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["54ea8c8c94ae9da9a366175e2abbe1dde3aa0453"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c9fb5f46e264daf5ba3860defe623a89d202dd87"]},"commit2Childs":{"dc06632ede7e48a5ddc6917badec25c8336feedc":["49a8cbd66bc94e18d7b9087e42dbc6cc0ee0c161"],"54ea8c8c94ae9da9a366175e2abbe1dde3aa0453":["c6f080a2ab37c464dd98db173f6cbf10dc74f211","c9fb5f46e264daf5ba3860defe623a89d202dd87"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["407687e67faf6e1f02a211ca078d8e3eed631027","9a3bd393140af58401b6bcd1d1f6bdc896c718c8"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"407687e67faf6e1f02a211ca078d8e3eed631027":[],"49a8cbd66bc94e18d7b9087e42dbc6cc0ee0c161":["54ea8c8c94ae9da9a366175e2abbe1dde3aa0453","c6f080a2ab37c464dd98db173f6cbf10dc74f211"],"9a3bd393140af58401b6bcd1d1f6bdc896c718c8":["dc06632ede7e48a5ddc6917badec25c8336feedc","407687e67faf6e1f02a211ca078d8e3eed631027"],"c6f080a2ab37c464dd98db173f6cbf10dc74f211":[],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["407687e67faf6e1f02a211ca078d8e3eed631027","c6f080a2ab37c464dd98db173f6cbf10dc74f211","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}