{"path":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader.ChunkIterator#next(int).mjava","commits":[{"id":"5e04b732c631a77cbbd25b6ce43c2a8abb1e9e69","date":1352818449,"type":1,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader.ChunkIterator#next(int).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader.ChunkIterator#next(int).mjava","sourceNew":"    /**\n     * Go to the chunk containing the provided doc ID.\n     */\n    void next(int doc) throws IOException {\n      assert doc >= docBase + chunkDocs : doc + \" \" + docBase + \" \" + chunkDocs;\n      fieldsStream.seek(indexReader.getStartPointer(doc));\n\n      final int docBase = fieldsStream.readVInt();\n      final int chunkDocs = fieldsStream.readVInt();\n      if (docBase < this.docBase + this.chunkDocs\n          || docBase + chunkDocs > numDocs) {\n        throw new CorruptIndexException(\"Corrupted: current docBase=\" + this.docBase\n            + \", current numDocs=\" + this.chunkDocs + \", new docBase=\" + docBase\n            + \", new numDocs=\" + chunkDocs);\n      }\n      this.docBase = docBase;\n      this.chunkDocs = chunkDocs;\n\n      if (chunkDocs > numStoredFields.length) {\n        final int newLength = ArrayUtil.oversize(chunkDocs, 4);\n        numStoredFields = new int[newLength];\n        lengths = new int[newLength];\n      }\n\n      if (chunkDocs == 1) {\n        numStoredFields[0] = fieldsStream.readVInt();\n        lengths[0] = fieldsStream.readVInt();\n      } else {\n        final int bitsPerStoredFields = fieldsStream.readVInt();\n        if (bitsPerStoredFields == 0) {\n          Arrays.fill(numStoredFields, 0, chunkDocs, fieldsStream.readVInt());\n        } else if (bitsPerStoredFields > 31) {\n          throw new CorruptIndexException(\"bitsPerStoredFields=\" + bitsPerStoredFields);\n        } else {\n          final PackedInts.ReaderIterator it = PackedInts.getReaderIteratorNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerStoredFields, 1);\n          for (int i = 0; i < chunkDocs; ++i) {\n            numStoredFields[i] = (int) it.next();\n          }\n        }\n\n        final int bitsPerLength = fieldsStream.readVInt();\n        if (bitsPerLength == 0) {\n          Arrays.fill(lengths, 0, chunkDocs, fieldsStream.readVInt());\n        } else if (bitsPerLength > 31) {\n          throw new CorruptIndexException(\"bitsPerLength=\" + bitsPerLength);\n        } else {\n          final PackedInts.ReaderIterator it = PackedInts.getReaderIteratorNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerLength, 1);\n          for (int i = 0; i < chunkDocs; ++i) {\n            lengths[i] = (int) it.next();\n          }\n        }\n      }\n    }\n\n","sourceOld":"    /**\n     * Go to the chunk containing the provided doc ID.\n     */\n    void next(int doc) throws IOException {\n      assert doc >= docBase + chunkDocs : doc + \" \" + docBase + \" \" + chunkDocs;\n      fieldsStream.seek(indexReader.getStartPointer(doc));\n\n      final int docBase = fieldsStream.readVInt();\n      final int chunkDocs = fieldsStream.readVInt();\n      if (docBase < this.docBase + this.chunkDocs\n          || docBase + chunkDocs > numDocs) {\n        throw new CorruptIndexException(\"Corrupted: current docBase=\" + this.docBase\n            + \", current numDocs=\" + this.chunkDocs + \", new docBase=\" + docBase\n            + \", new numDocs=\" + chunkDocs);\n      }\n      this.docBase = docBase;\n      this.chunkDocs = chunkDocs;\n\n      if (chunkDocs > numStoredFields.length) {\n        final int newLength = ArrayUtil.oversize(chunkDocs, 4);\n        numStoredFields = new int[newLength];\n        lengths = new int[newLength];\n      }\n\n      if (chunkDocs == 1) {\n        numStoredFields[0] = fieldsStream.readVInt();\n        lengths[0] = fieldsStream.readVInt();\n      } else {\n        final int bitsPerStoredFields = fieldsStream.readVInt();\n        if (bitsPerStoredFields == 0) {\n          Arrays.fill(numStoredFields, 0, chunkDocs, fieldsStream.readVInt());\n        } else if (bitsPerStoredFields > 31) {\n          throw new CorruptIndexException(\"bitsPerStoredFields=\" + bitsPerStoredFields);\n        } else {\n          final PackedInts.ReaderIterator it = PackedInts.getReaderIteratorNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerStoredFields, 1);\n          for (int i = 0; i < chunkDocs; ++i) {\n            numStoredFields[i] = (int) it.next();\n          }\n        }\n\n        final int bitsPerLength = fieldsStream.readVInt();\n        if (bitsPerLength == 0) {\n          Arrays.fill(lengths, 0, chunkDocs, fieldsStream.readVInt());\n        } else if (bitsPerLength > 31) {\n          throw new CorruptIndexException(\"bitsPerLength=\" + bitsPerLength);\n        } else {\n          final PackedInts.ReaderIterator it = PackedInts.getReaderIteratorNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerLength, 1);\n          for (int i = 0; i < chunkDocs; ++i) {\n            lengths[i] = (int) it.next();\n          }\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"407687e67faf6e1f02a211ca078d8e3eed631027","date":1355157407,"type":1,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader.ChunkIterator#next(int).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader.ChunkIterator#next(int).mjava","sourceNew":"    /**\n     * Go to the chunk containing the provided doc ID.\n     */\n    void next(int doc) throws IOException {\n      assert doc >= docBase + chunkDocs : doc + \" \" + docBase + \" \" + chunkDocs;\n      fieldsStream.seek(indexReader.getStartPointer(doc));\n\n      final int docBase = fieldsStream.readVInt();\n      final int chunkDocs = fieldsStream.readVInt();\n      if (docBase < this.docBase + this.chunkDocs\n          || docBase + chunkDocs > numDocs) {\n        throw new CorruptIndexException(\"Corrupted: current docBase=\" + this.docBase\n            + \", current numDocs=\" + this.chunkDocs + \", new docBase=\" + docBase\n            + \", new numDocs=\" + chunkDocs);\n      }\n      this.docBase = docBase;\n      this.chunkDocs = chunkDocs;\n\n      if (chunkDocs > numStoredFields.length) {\n        final int newLength = ArrayUtil.oversize(chunkDocs, 4);\n        numStoredFields = new int[newLength];\n        lengths = new int[newLength];\n      }\n\n      if (chunkDocs == 1) {\n        numStoredFields[0] = fieldsStream.readVInt();\n        lengths[0] = fieldsStream.readVInt();\n      } else {\n        final int bitsPerStoredFields = fieldsStream.readVInt();\n        if (bitsPerStoredFields == 0) {\n          Arrays.fill(numStoredFields, 0, chunkDocs, fieldsStream.readVInt());\n        } else if (bitsPerStoredFields > 31) {\n          throw new CorruptIndexException(\"bitsPerStoredFields=\" + bitsPerStoredFields);\n        } else {\n          final PackedInts.ReaderIterator it = PackedInts.getReaderIteratorNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerStoredFields, 1);\n          for (int i = 0; i < chunkDocs; ++i) {\n            numStoredFields[i] = (int) it.next();\n          }\n        }\n\n        final int bitsPerLength = fieldsStream.readVInt();\n        if (bitsPerLength == 0) {\n          Arrays.fill(lengths, 0, chunkDocs, fieldsStream.readVInt());\n        } else if (bitsPerLength > 31) {\n          throw new CorruptIndexException(\"bitsPerLength=\" + bitsPerLength);\n        } else {\n          final PackedInts.ReaderIterator it = PackedInts.getReaderIteratorNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerLength, 1);\n          for (int i = 0; i < chunkDocs; ++i) {\n            lengths[i] = (int) it.next();\n          }\n        }\n      }\n    }\n\n","sourceOld":"    /**\n     * Go to the chunk containing the provided doc ID.\n     */\n    void next(int doc) throws IOException {\n      assert doc >= docBase + chunkDocs : doc + \" \" + docBase + \" \" + chunkDocs;\n      fieldsStream.seek(indexReader.getStartPointer(doc));\n\n      final int docBase = fieldsStream.readVInt();\n      final int chunkDocs = fieldsStream.readVInt();\n      if (docBase < this.docBase + this.chunkDocs\n          || docBase + chunkDocs > numDocs) {\n        throw new CorruptIndexException(\"Corrupted: current docBase=\" + this.docBase\n            + \", current numDocs=\" + this.chunkDocs + \", new docBase=\" + docBase\n            + \", new numDocs=\" + chunkDocs);\n      }\n      this.docBase = docBase;\n      this.chunkDocs = chunkDocs;\n\n      if (chunkDocs > numStoredFields.length) {\n        final int newLength = ArrayUtil.oversize(chunkDocs, 4);\n        numStoredFields = new int[newLength];\n        lengths = new int[newLength];\n      }\n\n      if (chunkDocs == 1) {\n        numStoredFields[0] = fieldsStream.readVInt();\n        lengths[0] = fieldsStream.readVInt();\n      } else {\n        final int bitsPerStoredFields = fieldsStream.readVInt();\n        if (bitsPerStoredFields == 0) {\n          Arrays.fill(numStoredFields, 0, chunkDocs, fieldsStream.readVInt());\n        } else if (bitsPerStoredFields > 31) {\n          throw new CorruptIndexException(\"bitsPerStoredFields=\" + bitsPerStoredFields);\n        } else {\n          final PackedInts.ReaderIterator it = PackedInts.getReaderIteratorNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerStoredFields, 1);\n          for (int i = 0; i < chunkDocs; ++i) {\n            numStoredFields[i] = (int) it.next();\n          }\n        }\n\n        final int bitsPerLength = fieldsStream.readVInt();\n        if (bitsPerLength == 0) {\n          Arrays.fill(lengths, 0, chunkDocs, fieldsStream.readVInt());\n        } else if (bitsPerLength > 31) {\n          throw new CorruptIndexException(\"bitsPerLength=\" + bitsPerLength);\n        } else {\n          final PackedInts.ReaderIterator it = PackedInts.getReaderIteratorNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerLength, 1);\n          for (int i = 0; i < chunkDocs; ++i) {\n            lengths[i] = (int) it.next();\n          }\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"90f762b9c981401224de7f0a7c1ffc8fbc67574f","date":1366475889,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader.ChunkIterator#next(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader.ChunkIterator#next(int).mjava","sourceNew":"    /**\n     * Go to the chunk containing the provided doc ID.\n     */\n    void next(int doc) throws IOException {\n      assert doc >= docBase + chunkDocs : doc + \" \" + docBase + \" \" + chunkDocs;\n      fieldsStream.seek(indexReader.getStartPointer(doc));\n\n      final int docBase = fieldsStream.readVInt();\n      final int chunkDocs = fieldsStream.readVInt();\n      if (docBase < this.docBase + this.chunkDocs\n          || docBase + chunkDocs > numDocs) {\n        throw new CorruptIndexException(\"Corrupted: current docBase=\" + this.docBase\n            + \", current numDocs=\" + this.chunkDocs + \", new docBase=\" + docBase\n            + \", new numDocs=\" + chunkDocs + \" (resource=\" + fieldsStream + \")\");\n      }\n      this.docBase = docBase;\n      this.chunkDocs = chunkDocs;\n\n      if (chunkDocs > numStoredFields.length) {\n        final int newLength = ArrayUtil.oversize(chunkDocs, 4);\n        numStoredFields = new int[newLength];\n        lengths = new int[newLength];\n      }\n\n      if (chunkDocs == 1) {\n        numStoredFields[0] = fieldsStream.readVInt();\n        lengths[0] = fieldsStream.readVInt();\n      } else {\n        final int bitsPerStoredFields = fieldsStream.readVInt();\n        if (bitsPerStoredFields == 0) {\n          Arrays.fill(numStoredFields, 0, chunkDocs, fieldsStream.readVInt());\n        } else if (bitsPerStoredFields > 31) {\n          throw new CorruptIndexException(\"bitsPerStoredFields=\" + bitsPerStoredFields + \" (resource=\" + fieldsStream + \")\");\n        } else {\n          final PackedInts.ReaderIterator it = PackedInts.getReaderIteratorNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerStoredFields, 1);\n          for (int i = 0; i < chunkDocs; ++i) {\n            numStoredFields[i] = (int) it.next();\n          }\n        }\n\n        final int bitsPerLength = fieldsStream.readVInt();\n        if (bitsPerLength == 0) {\n          Arrays.fill(lengths, 0, chunkDocs, fieldsStream.readVInt());\n        } else if (bitsPerLength > 31) {\n          throw new CorruptIndexException(\"bitsPerLength=\" + bitsPerLength);\n        } else {\n          final PackedInts.ReaderIterator it = PackedInts.getReaderIteratorNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerLength, 1);\n          for (int i = 0; i < chunkDocs; ++i) {\n            lengths[i] = (int) it.next();\n          }\n        }\n      }\n    }\n\n","sourceOld":"    /**\n     * Go to the chunk containing the provided doc ID.\n     */\n    void next(int doc) throws IOException {\n      assert doc >= docBase + chunkDocs : doc + \" \" + docBase + \" \" + chunkDocs;\n      fieldsStream.seek(indexReader.getStartPointer(doc));\n\n      final int docBase = fieldsStream.readVInt();\n      final int chunkDocs = fieldsStream.readVInt();\n      if (docBase < this.docBase + this.chunkDocs\n          || docBase + chunkDocs > numDocs) {\n        throw new CorruptIndexException(\"Corrupted: current docBase=\" + this.docBase\n            + \", current numDocs=\" + this.chunkDocs + \", new docBase=\" + docBase\n            + \", new numDocs=\" + chunkDocs);\n      }\n      this.docBase = docBase;\n      this.chunkDocs = chunkDocs;\n\n      if (chunkDocs > numStoredFields.length) {\n        final int newLength = ArrayUtil.oversize(chunkDocs, 4);\n        numStoredFields = new int[newLength];\n        lengths = new int[newLength];\n      }\n\n      if (chunkDocs == 1) {\n        numStoredFields[0] = fieldsStream.readVInt();\n        lengths[0] = fieldsStream.readVInt();\n      } else {\n        final int bitsPerStoredFields = fieldsStream.readVInt();\n        if (bitsPerStoredFields == 0) {\n          Arrays.fill(numStoredFields, 0, chunkDocs, fieldsStream.readVInt());\n        } else if (bitsPerStoredFields > 31) {\n          throw new CorruptIndexException(\"bitsPerStoredFields=\" + bitsPerStoredFields);\n        } else {\n          final PackedInts.ReaderIterator it = PackedInts.getReaderIteratorNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerStoredFields, 1);\n          for (int i = 0; i < chunkDocs; ++i) {\n            numStoredFields[i] = (int) it.next();\n          }\n        }\n\n        final int bitsPerLength = fieldsStream.readVInt();\n        if (bitsPerLength == 0) {\n          Arrays.fill(lengths, 0, chunkDocs, fieldsStream.readVInt());\n        } else if (bitsPerLength > 31) {\n          throw new CorruptIndexException(\"bitsPerLength=\" + bitsPerLength);\n        } else {\n          final PackedInts.ReaderIterator it = PackedInts.getReaderIteratorNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerLength, 1);\n          for (int i = 0; i < chunkDocs; ++i) {\n            lengths[i] = (int) it.next();\n          }\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":["9a70ce9bddc6f985feb8e5e182aebe20872328d4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9a70ce9bddc6f985feb8e5e182aebe20872328d4","date":1411172748,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader.ChunkIterator#next(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader.ChunkIterator#next(int).mjava","sourceNew":"    /**\n     * Go to the chunk containing the provided doc ID.\n     */\n    void next(int doc) throws IOException {\n      assert doc >= docBase + chunkDocs : doc + \" \" + docBase + \" \" + chunkDocs;\n      fieldsStream.seek(indexReader.getStartPointer(doc));\n\n      final int docBase = fieldsStream.readVInt();\n      final int chunkDocs = fieldsStream.readVInt();\n      if (docBase < this.docBase + this.chunkDocs\n          || docBase + chunkDocs > numDocs) {\n        throw new CorruptIndexException(\"Corrupted: current docBase=\" + this.docBase\n            + \", current numDocs=\" + this.chunkDocs + \", new docBase=\" + docBase\n            + \", new numDocs=\" + chunkDocs, fieldsStream);\n      }\n      this.docBase = docBase;\n      this.chunkDocs = chunkDocs;\n\n      if (chunkDocs > numStoredFields.length) {\n        final int newLength = ArrayUtil.oversize(chunkDocs, 4);\n        numStoredFields = new int[newLength];\n        lengths = new int[newLength];\n      }\n\n      if (chunkDocs == 1) {\n        numStoredFields[0] = fieldsStream.readVInt();\n        lengths[0] = fieldsStream.readVInt();\n      } else {\n        final int bitsPerStoredFields = fieldsStream.readVInt();\n        if (bitsPerStoredFields == 0) {\n          Arrays.fill(numStoredFields, 0, chunkDocs, fieldsStream.readVInt());\n        } else if (bitsPerStoredFields > 31) {\n          throw new CorruptIndexException(\"bitsPerStoredFields=\" + bitsPerStoredFields, fieldsStream);\n        } else {\n          final PackedInts.ReaderIterator it = PackedInts.getReaderIteratorNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerStoredFields, 1);\n          for (int i = 0; i < chunkDocs; ++i) {\n            numStoredFields[i] = (int) it.next();\n          }\n        }\n\n        final int bitsPerLength = fieldsStream.readVInt();\n        if (bitsPerLength == 0) {\n          Arrays.fill(lengths, 0, chunkDocs, fieldsStream.readVInt());\n        } else if (bitsPerLength > 31) {\n          throw new CorruptIndexException(\"bitsPerLength=\" + bitsPerLength, fieldsStream);\n        } else {\n          final PackedInts.ReaderIterator it = PackedInts.getReaderIteratorNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerLength, 1);\n          for (int i = 0; i < chunkDocs; ++i) {\n            lengths[i] = (int) it.next();\n          }\n        }\n      }\n    }\n\n","sourceOld":"    /**\n     * Go to the chunk containing the provided doc ID.\n     */\n    void next(int doc) throws IOException {\n      assert doc >= docBase + chunkDocs : doc + \" \" + docBase + \" \" + chunkDocs;\n      fieldsStream.seek(indexReader.getStartPointer(doc));\n\n      final int docBase = fieldsStream.readVInt();\n      final int chunkDocs = fieldsStream.readVInt();\n      if (docBase < this.docBase + this.chunkDocs\n          || docBase + chunkDocs > numDocs) {\n        throw new CorruptIndexException(\"Corrupted: current docBase=\" + this.docBase\n            + \", current numDocs=\" + this.chunkDocs + \", new docBase=\" + docBase\n            + \", new numDocs=\" + chunkDocs + \" (resource=\" + fieldsStream + \")\");\n      }\n      this.docBase = docBase;\n      this.chunkDocs = chunkDocs;\n\n      if (chunkDocs > numStoredFields.length) {\n        final int newLength = ArrayUtil.oversize(chunkDocs, 4);\n        numStoredFields = new int[newLength];\n        lengths = new int[newLength];\n      }\n\n      if (chunkDocs == 1) {\n        numStoredFields[0] = fieldsStream.readVInt();\n        lengths[0] = fieldsStream.readVInt();\n      } else {\n        final int bitsPerStoredFields = fieldsStream.readVInt();\n        if (bitsPerStoredFields == 0) {\n          Arrays.fill(numStoredFields, 0, chunkDocs, fieldsStream.readVInt());\n        } else if (bitsPerStoredFields > 31) {\n          throw new CorruptIndexException(\"bitsPerStoredFields=\" + bitsPerStoredFields + \" (resource=\" + fieldsStream + \")\");\n        } else {\n          final PackedInts.ReaderIterator it = PackedInts.getReaderIteratorNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerStoredFields, 1);\n          for (int i = 0; i < chunkDocs; ++i) {\n            numStoredFields[i] = (int) it.next();\n          }\n        }\n\n        final int bitsPerLength = fieldsStream.readVInt();\n        if (bitsPerLength == 0) {\n          Arrays.fill(lengths, 0, chunkDocs, fieldsStream.readVInt());\n        } else if (bitsPerLength > 31) {\n          throw new CorruptIndexException(\"bitsPerLength=\" + bitsPerLength);\n        } else {\n          final PackedInts.ReaderIterator it = PackedInts.getReaderIteratorNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerLength, 1);\n          for (int i = 0; i < chunkDocs; ++i) {\n            lengths[i] = (int) it.next();\n          }\n        }\n      }\n    }\n\n","bugFix":["90f762b9c981401224de7f0a7c1ffc8fbc67574f","eba3cb2a268b9fb6f5be011fbaaf698699dcf24c"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1f09f483a0844bb9dc34fb10380cb053aa96219b","date":1418894001,"type":5,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader.BlockState#doReset(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader.ChunkIterator#next(int).mjava","sourceNew":"    private void doReset(int docID) throws IOException {\n      docBase = fieldsStream.readVInt();\n      final int token = fieldsStream.readVInt();\n      chunkDocs = token >>> 1;\n      if (contains(docID) == false\n          || docBase + chunkDocs > numDocs) {\n        throw new CorruptIndexException(\"Corrupted: docID=\" + docID\n            + \", docBase=\" + docBase + \", chunkDocs=\" + chunkDocs\n            + \", numDocs=\" + numDocs, fieldsStream);\n      }\n\n      sliced = (token & 1) != 0;\n\n      offsets = ArrayUtil.grow(offsets, chunkDocs + 1);\n      numStoredFields = ArrayUtil.grow(numStoredFields, chunkDocs);\n\n      if (chunkDocs == 1) {\n        numStoredFields[0] = fieldsStream.readVInt();\n        offsets[1] = fieldsStream.readVInt();\n      } else {\n        // Number of stored fields per document\n        final int bitsPerStoredFields = fieldsStream.readVInt();\n        if (bitsPerStoredFields == 0) {\n          Arrays.fill(numStoredFields, 0, chunkDocs, fieldsStream.readVInt());\n        } else if (bitsPerStoredFields > 31) {\n          throw new CorruptIndexException(\"bitsPerStoredFields=\" + bitsPerStoredFields, fieldsStream);\n        } else {\n          final PackedInts.ReaderIterator it = PackedInts.getReaderIteratorNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerStoredFields, 1);\n          for (int i = 0; i < chunkDocs; ++i) {\n            numStoredFields[i] = (int) it.next();\n          }\n        }\n\n        // The stream encodes the length of each document and we decode\n        // it into a list of monotonically increasing offsets\n        final int bitsPerLength = fieldsStream.readVInt();\n        if (bitsPerLength == 0) {\n          final int length = fieldsStream.readVInt();\n          for (int i = 0; i < chunkDocs; ++i) {\n            offsets[1 + i] = (1 + i) * length;\n          }\n        } else if (bitsPerStoredFields > 31) {\n          throw new CorruptIndexException(\"bitsPerLength=\" + bitsPerLength, fieldsStream);\n        } else {\n          final PackedInts.ReaderIterator it = PackedInts.getReaderIteratorNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerLength, 1);\n          for (int i = 0; i < chunkDocs; ++i) {\n            offsets[i + 1] = (int) it.next();\n          }\n          for (int i = 0; i < chunkDocs; ++i) {\n            offsets[i + 1] += offsets[i];\n          }\n        }\n\n        // Additional validation: only the empty document has a serialized length of 0\n        for (int i = 0; i < chunkDocs; ++i) {\n          final int len = offsets[i + 1] - offsets[i];\n          final int storedFields = numStoredFields[i];\n          if ((len == 0) != (storedFields == 0)) {\n            throw new CorruptIndexException(\"length=\" + len + \", numStoredFields=\" + storedFields, fieldsStream);\n          }\n        }\n\n      }\n\n      startPointer = fieldsStream.getFilePointer();\n\n      if (merging) {\n        final int totalLength = offsets[chunkDocs];\n        // decompress eagerly\n        if (sliced) {\n          bytes.offset = bytes.length = 0;\n          for (int decompressed = 0; decompressed < totalLength; ) {\n            final int toDecompress = Math.min(totalLength - decompressed, chunkSize);\n            decompressor.decompress(fieldsStream, toDecompress, 0, toDecompress, spare);\n            bytes.bytes = ArrayUtil.grow(bytes.bytes, bytes.length + spare.length);\n            System.arraycopy(spare.bytes, spare.offset, bytes.bytes, bytes.length, spare.length);\n            bytes.length += spare.length;\n            decompressed += toDecompress;\n          }\n        } else {\n          decompressor.decompress(fieldsStream, totalLength, 0, totalLength, bytes);\n        }\n        if (bytes.length != totalLength) {\n          throw new CorruptIndexException(\"Corrupted: expected chunk size = \" + totalLength + \", got \" + bytes.length, fieldsStream);\n        }\n      }\n    }\n\n","sourceOld":"    /**\n     * Go to the chunk containing the provided doc ID.\n     */\n    void next(int doc) throws IOException {\n      assert doc >= docBase + chunkDocs : doc + \" \" + docBase + \" \" + chunkDocs;\n      fieldsStream.seek(indexReader.getStartPointer(doc));\n\n      final int docBase = fieldsStream.readVInt();\n      final int chunkDocs = fieldsStream.readVInt();\n      if (docBase < this.docBase + this.chunkDocs\n          || docBase + chunkDocs > numDocs) {\n        throw new CorruptIndexException(\"Corrupted: current docBase=\" + this.docBase\n            + \", current numDocs=\" + this.chunkDocs + \", new docBase=\" + docBase\n            + \", new numDocs=\" + chunkDocs, fieldsStream);\n      }\n      this.docBase = docBase;\n      this.chunkDocs = chunkDocs;\n\n      if (chunkDocs > numStoredFields.length) {\n        final int newLength = ArrayUtil.oversize(chunkDocs, 4);\n        numStoredFields = new int[newLength];\n        lengths = new int[newLength];\n      }\n\n      if (chunkDocs == 1) {\n        numStoredFields[0] = fieldsStream.readVInt();\n        lengths[0] = fieldsStream.readVInt();\n      } else {\n        final int bitsPerStoredFields = fieldsStream.readVInt();\n        if (bitsPerStoredFields == 0) {\n          Arrays.fill(numStoredFields, 0, chunkDocs, fieldsStream.readVInt());\n        } else if (bitsPerStoredFields > 31) {\n          throw new CorruptIndexException(\"bitsPerStoredFields=\" + bitsPerStoredFields, fieldsStream);\n        } else {\n          final PackedInts.ReaderIterator it = PackedInts.getReaderIteratorNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerStoredFields, 1);\n          for (int i = 0; i < chunkDocs; ++i) {\n            numStoredFields[i] = (int) it.next();\n          }\n        }\n\n        final int bitsPerLength = fieldsStream.readVInt();\n        if (bitsPerLength == 0) {\n          Arrays.fill(lengths, 0, chunkDocs, fieldsStream.readVInt());\n        } else if (bitsPerLength > 31) {\n          throw new CorruptIndexException(\"bitsPerLength=\" + bitsPerLength, fieldsStream);\n        } else {\n          final PackedInts.ReaderIterator it = PackedInts.getReaderIteratorNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerLength, 1);\n          for (int i = 0; i < chunkDocs; ++i) {\n            lengths[i] = (int) it.next();\n          }\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"90f762b9c981401224de7f0a7c1ffc8fbc67574f":["5e04b732c631a77cbbd25b6ce43c2a8abb1e9e69"],"9a70ce9bddc6f985feb8e5e182aebe20872328d4":["90f762b9c981401224de7f0a7c1ffc8fbc67574f"],"5e04b732c631a77cbbd25b6ce43c2a8abb1e9e69":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"407687e67faf6e1f02a211ca078d8e3eed631027":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","5e04b732c631a77cbbd25b6ce43c2a8abb1e9e69"],"1f09f483a0844bb9dc34fb10380cb053aa96219b":["9a70ce9bddc6f985feb8e5e182aebe20872328d4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["1f09f483a0844bb9dc34fb10380cb053aa96219b"]},"commit2Childs":{"90f762b9c981401224de7f0a7c1ffc8fbc67574f":["9a70ce9bddc6f985feb8e5e182aebe20872328d4"],"9a70ce9bddc6f985feb8e5e182aebe20872328d4":["1f09f483a0844bb9dc34fb10380cb053aa96219b"],"5e04b732c631a77cbbd25b6ce43c2a8abb1e9e69":["90f762b9c981401224de7f0a7c1ffc8fbc67574f","407687e67faf6e1f02a211ca078d8e3eed631027"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["5e04b732c631a77cbbd25b6ce43c2a8abb1e9e69","407687e67faf6e1f02a211ca078d8e3eed631027"],"407687e67faf6e1f02a211ca078d8e3eed631027":[],"1f09f483a0844bb9dc34fb10380cb053aa96219b":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["407687e67faf6e1f02a211ca078d8e3eed631027","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}