{"path":"contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder#getQuery(Element).mjava","commits":[{"id":"d3c3c2404d1200c39220fa15054fae854db4e1ee","date":1140827958,"type":0,"author":"Mark Harwood","isMerge":false,"pathNew":"contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder#getQuery(Element).mjava","pathOld":"/dev/null","sourceNew":"\t/* (non-Javadoc)\r\n\t * @see org.apache.lucene.xmlparser.QueryObjectBuilder#process(org.w3c.dom.Element)\r\n\t */\r\n\tpublic Query getQuery(Element e) throws ParserException {\r\n\t\tString fieldsList=e.getAttribute(\"fieldNames\"); //a comma-delimited list of fields\r\n\t\tString fields[]=defaultFieldNames;\r\n\t\tif((fieldsList!=null)&&(fieldsList.trim().length()>0))\r\n\t\t{\r\n\t\t\tfields=fieldsList.trim().split(\",\");\r\n\t\t\t//trim the fieldnames\r\n\t\t\tfor (int i = 0; i < fields.length; i++) {\r\n\t\t\t\tfields[i]=fields[i].trim();\r\n\t\t\t}\r\n\t\t}\r\n\t\tMoreLikeThisQuery mlt=new MoreLikeThisQuery(DOMUtils.getText(e),fields,analyzer);\r\n\t\tmlt.setMaxQueryTerms(DOMUtils.getAttribute(e,\"maxQueryTerms\",defaultMaxQueryTerms));\r\n\t\tmlt.setMinTermFrequency(DOMUtils.getAttribute(e,\"minTermFrequency\",defaultMinTermFrequency));\r\n\t\tmlt.setPercentTermsToMatch(DOMUtils.getAttribute(e,\"percentTermsToMatch\",defaultPercentTermsToMatch)/100);\r\n\r\n\t\tmlt.setBoost(DOMUtils.getAttribute(e,\"boost\",1.0f));\r\n\r\n\t\treturn mlt;\r\n\t}\r\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5706b74946ebff9c666698df31106be9a192ab0d","date":1152738555,"type":3,"author":"Mark Harwood","isMerge":false,"pathNew":"contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder#getQuery(Element).mjava","pathOld":"contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder#getQuery(Element).mjava","sourceNew":"\t/* (non-Javadoc)\r\n\t * @see org.apache.lucene.xmlparser.QueryObjectBuilder#process(org.w3c.dom.Element)\r\n\t */\r\n\tpublic Query getQuery(Element e) throws ParserException {\r\n\t\tString fieldsList=e.getAttribute(\"fieldNames\"); //a comma-delimited list of fields\r\n\t\tString fields[]=defaultFieldNames;\r\n\t\tif((fieldsList!=null)&&(fieldsList.trim().length()>0))\r\n\t\t{\r\n\t\t\tfields=fieldsList.trim().split(\",\");\r\n\t\t\t//trim the fieldnames\r\n\t\t\tfor (int i = 0; i < fields.length; i++) {\r\n\t\t\t\tfields[i]=fields[i].trim();\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\t//Parse any \"stopWords\" attribute\r\n\t\t//TODO MoreLikeThis needs to ideally have per-field stopWords lists - until then \r\n\t\t//I use all analyzers/fields to generate multi-field compatible stop list\r\n\t\tString stopWords=e.getAttribute(\"stopWords\");\r\n\t\tSet stopWordsSet=null;\r\n\t\tif((stopWords!=null)&&(fields!=null))\r\n\t\t{\r\n\t\t    stopWordsSet=new HashSet();\r\n\t\t    for (int i = 0; i < fields.length; i++)\r\n            {\r\n                TokenStream ts = analyzer.tokenStream(fields[i],new StringReader(stopWords));\r\n                try\r\n                {\r\n\t                Token stopToken=ts.next();\r\n\t                while(stopToken!=null)\r\n\t                {\r\n\t                    stopWordsSet.add(stopToken.termText());\r\n\t                    stopToken=ts.next();\r\n\t                }\r\n                }\r\n                catch(IOException ioe)\r\n                {\r\n                    throw new ParserException(\"IoException parsing stop words list in \"\r\n                            +getClass().getName()+\":\"+ioe.getLocalizedMessage());\r\n                }\r\n            }\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\tMoreLikeThisQuery mlt=new MoreLikeThisQuery(DOMUtils.getText(e),fields,analyzer);\r\n\t\tmlt.setMaxQueryTerms(DOMUtils.getAttribute(e,\"maxQueryTerms\",defaultMaxQueryTerms));\r\n\t\tmlt.setMinTermFrequency(DOMUtils.getAttribute(e,\"minTermFrequency\",defaultMinTermFrequency));\r\n\t\tmlt.setPercentTermsToMatch(DOMUtils.getAttribute(e,\"percentTermsToMatch\",defaultPercentTermsToMatch)/100);\r\n\t\tmlt.setStopWords(stopWordsSet);\r\n\r\n\t\tmlt.setBoost(DOMUtils.getAttribute(e,\"boost\",1.0f));\r\n\r\n\t\treturn mlt;\r\n\t}\r\n\n","sourceOld":"\t/* (non-Javadoc)\r\n\t * @see org.apache.lucene.xmlparser.QueryObjectBuilder#process(org.w3c.dom.Element)\r\n\t */\r\n\tpublic Query getQuery(Element e) throws ParserException {\r\n\t\tString fieldsList=e.getAttribute(\"fieldNames\"); //a comma-delimited list of fields\r\n\t\tString fields[]=defaultFieldNames;\r\n\t\tif((fieldsList!=null)&&(fieldsList.trim().length()>0))\r\n\t\t{\r\n\t\t\tfields=fieldsList.trim().split(\",\");\r\n\t\t\t//trim the fieldnames\r\n\t\t\tfor (int i = 0; i < fields.length; i++) {\r\n\t\t\t\tfields[i]=fields[i].trim();\r\n\t\t\t}\r\n\t\t}\r\n\t\tMoreLikeThisQuery mlt=new MoreLikeThisQuery(DOMUtils.getText(e),fields,analyzer);\r\n\t\tmlt.setMaxQueryTerms(DOMUtils.getAttribute(e,\"maxQueryTerms\",defaultMaxQueryTerms));\r\n\t\tmlt.setMinTermFrequency(DOMUtils.getAttribute(e,\"minTermFrequency\",defaultMinTermFrequency));\r\n\t\tmlt.setPercentTermsToMatch(DOMUtils.getAttribute(e,\"percentTermsToMatch\",defaultPercentTermsToMatch)/100);\r\n\r\n\t\tmlt.setBoost(DOMUtils.getAttribute(e,\"boost\",1.0f));\r\n\r\n\t\treturn mlt;\r\n\t}\r\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5a90cc8f220330c2def1d91a24b75545cedf6230","date":1181254417,"type":3,"author":"Mark Harwood","isMerge":false,"pathNew":"contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder#getQuery(Element).mjava","pathOld":"contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder#getQuery(Element).mjava","sourceNew":"\t/* (non-Javadoc)\r\n\t * @see org.apache.lucene.xmlparser.QueryObjectBuilder#process(org.w3c.dom.Element)\r\n\t */\r\n\tpublic Query getQuery(Element e) throws ParserException {\r\n\t\tString fieldsList=e.getAttribute(\"fieldNames\"); //a comma-delimited list of fields\r\n\t\tString fields[]=defaultFieldNames;\r\n\t\tif((fieldsList!=null)&&(fieldsList.trim().length()>0))\r\n\t\t{\r\n\t\t\tfields=fieldsList.trim().split(\",\");\r\n\t\t\t//trim the fieldnames\r\n\t\t\tfor (int i = 0; i < fields.length; i++) {\r\n\t\t\t\tfields[i]=fields[i].trim();\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\t//Parse any \"stopWords\" attribute\r\n\t\t//TODO MoreLikeThis needs to ideally have per-field stopWords lists - until then \r\n\t\t//I use all analyzers/fields to generate multi-field compatible stop list\r\n\t\tString stopWords=e.getAttribute(\"stopWords\");\r\n\t\tSet stopWordsSet=null;\r\n\t\tif((stopWords!=null)&&(fields!=null))\r\n\t\t{\r\n\t\t    stopWordsSet=new HashSet();\r\n\t\t    for (int i = 0; i < fields.length; i++)\r\n            {\r\n                TokenStream ts = analyzer.tokenStream(fields[i],new StringReader(stopWords));\r\n                try\r\n                {\r\n\t                Token stopToken=ts.next();\r\n\t                while(stopToken!=null)\r\n\t                {\r\n\t                    stopWordsSet.add(stopToken.termText());\r\n\t                    stopToken=ts.next();\r\n\t                }\r\n                }\r\n                catch(IOException ioe)\r\n                {\r\n                    throw new ParserException(\"IoException parsing stop words list in \"\r\n                            +getClass().getName()+\":\"+ioe.getLocalizedMessage());\r\n                }\r\n            }\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\tMoreLikeThisQuery mlt=new MoreLikeThisQuery(DOMUtils.getText(e),fields,analyzer);\r\n\t\tmlt.setMaxQueryTerms(DOMUtils.getAttribute(e,\"maxQueryTerms\",defaultMaxQueryTerms));\r\n\t\tmlt.setMinTermFrequency(DOMUtils.getAttribute(e,\"minTermFrequency\",defaultMinTermFrequency));\r\n\t\tmlt.setPercentTermsToMatch(DOMUtils.getAttribute(e,\"percentTermsToMatch\",defaultPercentTermsToMatch)/100);\r\n\t\tmlt.setStopWords(stopWordsSet);\r\n\t\tint minDocFreq=DOMUtils.getAttribute(e,\"minDocFreq\",-1);\r\n\t\tif(minDocFreq>=0)\r\n\t\t{\r\n\t\t\tmlt.setMinDocFreq(minDocFreq);\r\n\t\t}\r\n\r\n\t\tmlt.setBoost(DOMUtils.getAttribute(e,\"boost\",1.0f));\r\n\r\n\t\treturn mlt;\r\n\t}\r\n\n","sourceOld":"\t/* (non-Javadoc)\r\n\t * @see org.apache.lucene.xmlparser.QueryObjectBuilder#process(org.w3c.dom.Element)\r\n\t */\r\n\tpublic Query getQuery(Element e) throws ParserException {\r\n\t\tString fieldsList=e.getAttribute(\"fieldNames\"); //a comma-delimited list of fields\r\n\t\tString fields[]=defaultFieldNames;\r\n\t\tif((fieldsList!=null)&&(fieldsList.trim().length()>0))\r\n\t\t{\r\n\t\t\tfields=fieldsList.trim().split(\",\");\r\n\t\t\t//trim the fieldnames\r\n\t\t\tfor (int i = 0; i < fields.length; i++) {\r\n\t\t\t\tfields[i]=fields[i].trim();\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\t//Parse any \"stopWords\" attribute\r\n\t\t//TODO MoreLikeThis needs to ideally have per-field stopWords lists - until then \r\n\t\t//I use all analyzers/fields to generate multi-field compatible stop list\r\n\t\tString stopWords=e.getAttribute(\"stopWords\");\r\n\t\tSet stopWordsSet=null;\r\n\t\tif((stopWords!=null)&&(fields!=null))\r\n\t\t{\r\n\t\t    stopWordsSet=new HashSet();\r\n\t\t    for (int i = 0; i < fields.length; i++)\r\n            {\r\n                TokenStream ts = analyzer.tokenStream(fields[i],new StringReader(stopWords));\r\n                try\r\n                {\r\n\t                Token stopToken=ts.next();\r\n\t                while(stopToken!=null)\r\n\t                {\r\n\t                    stopWordsSet.add(stopToken.termText());\r\n\t                    stopToken=ts.next();\r\n\t                }\r\n                }\r\n                catch(IOException ioe)\r\n                {\r\n                    throw new ParserException(\"IoException parsing stop words list in \"\r\n                            +getClass().getName()+\":\"+ioe.getLocalizedMessage());\r\n                }\r\n            }\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\tMoreLikeThisQuery mlt=new MoreLikeThisQuery(DOMUtils.getText(e),fields,analyzer);\r\n\t\tmlt.setMaxQueryTerms(DOMUtils.getAttribute(e,\"maxQueryTerms\",defaultMaxQueryTerms));\r\n\t\tmlt.setMinTermFrequency(DOMUtils.getAttribute(e,\"minTermFrequency\",defaultMinTermFrequency));\r\n\t\tmlt.setPercentTermsToMatch(DOMUtils.getAttribute(e,\"percentTermsToMatch\",defaultPercentTermsToMatch)/100);\r\n\t\tmlt.setStopWords(stopWordsSet);\r\n\r\n\t\tmlt.setBoost(DOMUtils.getAttribute(e,\"boost\",1.0f));\r\n\r\n\t\treturn mlt;\r\n\t}\r\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7e2cb543b41c145f33390f460ee743d6693c9c6c","date":1219243087,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder#getQuery(Element).mjava","pathOld":"contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder#getQuery(Element).mjava","sourceNew":"\t/* (non-Javadoc)\r\n\t * @see org.apache.lucene.xmlparser.QueryObjectBuilder#process(org.w3c.dom.Element)\r\n\t */\r\n\tpublic Query getQuery(Element e) throws ParserException {\r\n\t\tString fieldsList=e.getAttribute(\"fieldNames\"); //a comma-delimited list of fields\r\n\t\tString fields[]=defaultFieldNames;\r\n\t\tif((fieldsList!=null)&&(fieldsList.trim().length()>0))\r\n\t\t{\r\n\t\t\tfields=fieldsList.trim().split(\",\");\r\n\t\t\t//trim the fieldnames\r\n\t\t\tfor (int i = 0; i < fields.length; i++) {\r\n\t\t\t\tfields[i]=fields[i].trim();\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\t//Parse any \"stopWords\" attribute\r\n\t\t//TODO MoreLikeThis needs to ideally have per-field stopWords lists - until then \r\n\t\t//I use all analyzers/fields to generate multi-field compatible stop list\r\n\t\tString stopWords=e.getAttribute(\"stopWords\");\r\n\t\tSet stopWordsSet=null;\r\n\t\tif((stopWords!=null)&&(fields!=null))\r\n\t\t{\r\n\t\t    stopWordsSet=new HashSet();\r\n                    final Token reusableToken = new Token();\r\n\t\t    for (int i = 0; i < fields.length; i++)\r\n            {\r\n                TokenStream ts = analyzer.tokenStream(fields[i],new StringReader(stopWords));\r\n                try\r\n                {\r\n\t                for (Token nextToken = ts.next(reusableToken); nextToken != null; nextToken = ts.next(reusableToken)) {\r\n\t                    stopWordsSet.add(nextToken.term());\r\n\t                }\r\n                }\r\n                catch(IOException ioe)\r\n                {\r\n                    throw new ParserException(\"IoException parsing stop words list in \"\r\n                            +getClass().getName()+\":\"+ioe.getLocalizedMessage());\r\n                }\r\n            }\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\tMoreLikeThisQuery mlt=new MoreLikeThisQuery(DOMUtils.getText(e),fields,analyzer);\r\n\t\tmlt.setMaxQueryTerms(DOMUtils.getAttribute(e,\"maxQueryTerms\",defaultMaxQueryTerms));\r\n\t\tmlt.setMinTermFrequency(DOMUtils.getAttribute(e,\"minTermFrequency\",defaultMinTermFrequency));\r\n\t\tmlt.setPercentTermsToMatch(DOMUtils.getAttribute(e,\"percentTermsToMatch\",defaultPercentTermsToMatch)/100);\r\n\t\tmlt.setStopWords(stopWordsSet);\r\n\t\tint minDocFreq=DOMUtils.getAttribute(e,\"minDocFreq\",-1);\r\n\t\tif(minDocFreq>=0)\r\n\t\t{\r\n\t\t\tmlt.setMinDocFreq(minDocFreq);\r\n\t\t}\r\n\r\n\t\tmlt.setBoost(DOMUtils.getAttribute(e,\"boost\",1.0f));\r\n\r\n\t\treturn mlt;\r\n\t}\r\n\n","sourceOld":"\t/* (non-Javadoc)\r\n\t * @see org.apache.lucene.xmlparser.QueryObjectBuilder#process(org.w3c.dom.Element)\r\n\t */\r\n\tpublic Query getQuery(Element e) throws ParserException {\r\n\t\tString fieldsList=e.getAttribute(\"fieldNames\"); //a comma-delimited list of fields\r\n\t\tString fields[]=defaultFieldNames;\r\n\t\tif((fieldsList!=null)&&(fieldsList.trim().length()>0))\r\n\t\t{\r\n\t\t\tfields=fieldsList.trim().split(\",\");\r\n\t\t\t//trim the fieldnames\r\n\t\t\tfor (int i = 0; i < fields.length; i++) {\r\n\t\t\t\tfields[i]=fields[i].trim();\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\t//Parse any \"stopWords\" attribute\r\n\t\t//TODO MoreLikeThis needs to ideally have per-field stopWords lists - until then \r\n\t\t//I use all analyzers/fields to generate multi-field compatible stop list\r\n\t\tString stopWords=e.getAttribute(\"stopWords\");\r\n\t\tSet stopWordsSet=null;\r\n\t\tif((stopWords!=null)&&(fields!=null))\r\n\t\t{\r\n\t\t    stopWordsSet=new HashSet();\r\n\t\t    for (int i = 0; i < fields.length; i++)\r\n            {\r\n                TokenStream ts = analyzer.tokenStream(fields[i],new StringReader(stopWords));\r\n                try\r\n                {\r\n\t                Token stopToken=ts.next();\r\n\t                while(stopToken!=null)\r\n\t                {\r\n\t                    stopWordsSet.add(stopToken.termText());\r\n\t                    stopToken=ts.next();\r\n\t                }\r\n                }\r\n                catch(IOException ioe)\r\n                {\r\n                    throw new ParserException(\"IoException parsing stop words list in \"\r\n                            +getClass().getName()+\":\"+ioe.getLocalizedMessage());\r\n                }\r\n            }\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\tMoreLikeThisQuery mlt=new MoreLikeThisQuery(DOMUtils.getText(e),fields,analyzer);\r\n\t\tmlt.setMaxQueryTerms(DOMUtils.getAttribute(e,\"maxQueryTerms\",defaultMaxQueryTerms));\r\n\t\tmlt.setMinTermFrequency(DOMUtils.getAttribute(e,\"minTermFrequency\",defaultMinTermFrequency));\r\n\t\tmlt.setPercentTermsToMatch(DOMUtils.getAttribute(e,\"percentTermsToMatch\",defaultPercentTermsToMatch)/100);\r\n\t\tmlt.setStopWords(stopWordsSet);\r\n\t\tint minDocFreq=DOMUtils.getAttribute(e,\"minDocFreq\",-1);\r\n\t\tif(minDocFreq>=0)\r\n\t\t{\r\n\t\t\tmlt.setMinDocFreq(minDocFreq);\r\n\t\t}\r\n\r\n\t\tmlt.setBoost(DOMUtils.getAttribute(e,\"boost\",1.0f));\r\n\r\n\t\treturn mlt;\r\n\t}\r\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6a361a621b184d9b73c9c9a37323a9845b8f8260","date":1226370946,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder#getQuery(Element).mjava","pathOld":"contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder#getQuery(Element).mjava","sourceNew":"\t/* (non-Javadoc)\n\t * @see org.apache.lucene.xmlparser.QueryObjectBuilder#process(org.w3c.dom.Element)\n\t */\n\tpublic Query getQuery(Element e) throws ParserException {\n\t\tString fieldsList=e.getAttribute(\"fieldNames\"); //a comma-delimited list of fields\n\t\tString fields[]=defaultFieldNames;\n\t\tif((fieldsList!=null)&&(fieldsList.trim().length()>0))\n\t\t{\n\t\t\tfields=fieldsList.trim().split(\",\");\n\t\t\t//trim the fieldnames\n\t\t\tfor (int i = 0; i < fields.length; i++) {\n\t\t\t\tfields[i]=fields[i].trim();\n\t\t\t}\n\t\t}\n\t\t\n\t\t//Parse any \"stopWords\" attribute\n\t\t//TODO MoreLikeThis needs to ideally have per-field stopWords lists - until then \n\t\t//I use all analyzers/fields to generate multi-field compatible stop list\n\t\tString stopWords=e.getAttribute(\"stopWords\");\n\t\tSet stopWordsSet=null;\n\t\tif((stopWords!=null)&&(fields!=null))\n\t\t{\n\t\t    stopWordsSet=new HashSet();\n                    final Token reusableToken = new Token();\n\t\t    for (int i = 0; i < fields.length; i++)\n            {\n                TokenStream ts = analyzer.tokenStream(fields[i],new StringReader(stopWords));\n                try\n                {\n\t                for (Token nextToken = ts.next(reusableToken); nextToken != null; nextToken = ts.next(reusableToken)) {\n\t                    stopWordsSet.add(nextToken.term());\n\t                }\n                }\n                catch(IOException ioe)\n                {\n                    throw new ParserException(\"IoException parsing stop words list in \"\n                            +getClass().getName()+\":\"+ioe.getLocalizedMessage());\n                }\n            }\n\t\t}\n\t\t\n\t\t\n\t\tMoreLikeThisQuery mlt=new MoreLikeThisQuery(DOMUtils.getText(e),fields,analyzer);\n\t\tmlt.setMaxQueryTerms(DOMUtils.getAttribute(e,\"maxQueryTerms\",defaultMaxQueryTerms));\n\t\tmlt.setMinTermFrequency(DOMUtils.getAttribute(e,\"minTermFrequency\",defaultMinTermFrequency));\n\t\tmlt.setPercentTermsToMatch(DOMUtils.getAttribute(e,\"percentTermsToMatch\",defaultPercentTermsToMatch)/100);\n\t\tmlt.setStopWords(stopWordsSet);\n\t\tint minDocFreq=DOMUtils.getAttribute(e,\"minDocFreq\",-1);\n\t\tif(minDocFreq>=0)\n\t\t{\n\t\t\tmlt.setMinDocFreq(minDocFreq);\n\t\t}\n\n\t\tmlt.setBoost(DOMUtils.getAttribute(e,\"boost\",1.0f));\n\n\t\treturn mlt;\n\t}\n\n","sourceOld":"\t/* (non-Javadoc)\r\n\t * @see org.apache.lucene.xmlparser.QueryObjectBuilder#process(org.w3c.dom.Element)\r\n\t */\r\n\tpublic Query getQuery(Element e) throws ParserException {\r\n\t\tString fieldsList=e.getAttribute(\"fieldNames\"); //a comma-delimited list of fields\r\n\t\tString fields[]=defaultFieldNames;\r\n\t\tif((fieldsList!=null)&&(fieldsList.trim().length()>0))\r\n\t\t{\r\n\t\t\tfields=fieldsList.trim().split(\",\");\r\n\t\t\t//trim the fieldnames\r\n\t\t\tfor (int i = 0; i < fields.length; i++) {\r\n\t\t\t\tfields[i]=fields[i].trim();\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\t//Parse any \"stopWords\" attribute\r\n\t\t//TODO MoreLikeThis needs to ideally have per-field stopWords lists - until then \r\n\t\t//I use all analyzers/fields to generate multi-field compatible stop list\r\n\t\tString stopWords=e.getAttribute(\"stopWords\");\r\n\t\tSet stopWordsSet=null;\r\n\t\tif((stopWords!=null)&&(fields!=null))\r\n\t\t{\r\n\t\t    stopWordsSet=new HashSet();\r\n                    final Token reusableToken = new Token();\r\n\t\t    for (int i = 0; i < fields.length; i++)\r\n            {\r\n                TokenStream ts = analyzer.tokenStream(fields[i],new StringReader(stopWords));\r\n                try\r\n                {\r\n\t                for (Token nextToken = ts.next(reusableToken); nextToken != null; nextToken = ts.next(reusableToken)) {\r\n\t                    stopWordsSet.add(nextToken.term());\r\n\t                }\r\n                }\r\n                catch(IOException ioe)\r\n                {\r\n                    throw new ParserException(\"IoException parsing stop words list in \"\r\n                            +getClass().getName()+\":\"+ioe.getLocalizedMessage());\r\n                }\r\n            }\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\tMoreLikeThisQuery mlt=new MoreLikeThisQuery(DOMUtils.getText(e),fields,analyzer);\r\n\t\tmlt.setMaxQueryTerms(DOMUtils.getAttribute(e,\"maxQueryTerms\",defaultMaxQueryTerms));\r\n\t\tmlt.setMinTermFrequency(DOMUtils.getAttribute(e,\"minTermFrequency\",defaultMinTermFrequency));\r\n\t\tmlt.setPercentTermsToMatch(DOMUtils.getAttribute(e,\"percentTermsToMatch\",defaultPercentTermsToMatch)/100);\r\n\t\tmlt.setStopWords(stopWordsSet);\r\n\t\tint minDocFreq=DOMUtils.getAttribute(e,\"minDocFreq\",-1);\r\n\t\tif(minDocFreq>=0)\r\n\t\t{\r\n\t\t\tmlt.setMinDocFreq(minDocFreq);\r\n\t\t}\r\n\r\n\t\tmlt.setBoost(DOMUtils.getAttribute(e,\"boost\",1.0f));\r\n\r\n\t\treturn mlt;\r\n\t}\r\n\n","bugFix":null,"bugIntro":["ae46d105c94ea6ceb5201189bf9611bdef91b1b4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9b5756469957918cac40a831acec9cf01c8c2bb3","date":1249167152,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder#getQuery(Element).mjava","pathOld":"contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder#getQuery(Element).mjava","sourceNew":"\t/* (non-Javadoc)\n\t * @see org.apache.lucene.xmlparser.QueryObjectBuilder#process(org.w3c.dom.Element)\n\t */\n\tpublic Query getQuery(Element e) throws ParserException {\n\t\tString fieldsList=e.getAttribute(\"fieldNames\"); //a comma-delimited list of fields\n\t\tString fields[]=defaultFieldNames;\n\t\tif((fieldsList!=null)&&(fieldsList.trim().length()>0))\n\t\t{\n\t\t\tfields=fieldsList.trim().split(\",\");\n\t\t\t//trim the fieldnames\n\t\t\tfor (int i = 0; i < fields.length; i++) {\n\t\t\t\tfields[i]=fields[i].trim();\n\t\t\t}\n\t\t}\n\t\t\n\t\t//Parse any \"stopWords\" attribute\n\t\t//TODO MoreLikeThis needs to ideally have per-field stopWords lists - until then \n\t\t//I use all analyzers/fields to generate multi-field compatible stop list\n\t\tString stopWords=e.getAttribute(\"stopWords\");\n\t\tSet stopWordsSet=null;\n\t\tif((stopWords!=null)&&(fields!=null))\n\t\t{\n\t\t    stopWordsSet=new HashSet();\n\t\t    for (int i = 0; i < fields.length; i++)\n            {\n                TokenStream ts = analyzer.tokenStream(fields[i],new StringReader(stopWords));\n                TermAttribute termAtt = (TermAttribute) ts.addAttribute(TermAttribute.class);\n                try\n                {\n\t                while(ts.incrementToken()) {\n\t                    stopWordsSet.add(termAtt.term());\n\t                }\n                }\n                catch(IOException ioe)\n                {\n                    throw new ParserException(\"IoException parsing stop words list in \"\n                            +getClass().getName()+\":\"+ioe.getLocalizedMessage());\n                }\n            }\n\t\t}\n\t\t\n\t\t\n\t\tMoreLikeThisQuery mlt=new MoreLikeThisQuery(DOMUtils.getText(e),fields,analyzer);\n\t\tmlt.setMaxQueryTerms(DOMUtils.getAttribute(e,\"maxQueryTerms\",defaultMaxQueryTerms));\n\t\tmlt.setMinTermFrequency(DOMUtils.getAttribute(e,\"minTermFrequency\",defaultMinTermFrequency));\n\t\tmlt.setPercentTermsToMatch(DOMUtils.getAttribute(e,\"percentTermsToMatch\",defaultPercentTermsToMatch)/100);\n\t\tmlt.setStopWords(stopWordsSet);\n\t\tint minDocFreq=DOMUtils.getAttribute(e,\"minDocFreq\",-1);\n\t\tif(minDocFreq>=0)\n\t\t{\n\t\t\tmlt.setMinDocFreq(minDocFreq);\n\t\t}\n\n\t\tmlt.setBoost(DOMUtils.getAttribute(e,\"boost\",1.0f));\n\n\t\treturn mlt;\n\t}\n\n","sourceOld":"\t/* (non-Javadoc)\n\t * @see org.apache.lucene.xmlparser.QueryObjectBuilder#process(org.w3c.dom.Element)\n\t */\n\tpublic Query getQuery(Element e) throws ParserException {\n\t\tString fieldsList=e.getAttribute(\"fieldNames\"); //a comma-delimited list of fields\n\t\tString fields[]=defaultFieldNames;\n\t\tif((fieldsList!=null)&&(fieldsList.trim().length()>0))\n\t\t{\n\t\t\tfields=fieldsList.trim().split(\",\");\n\t\t\t//trim the fieldnames\n\t\t\tfor (int i = 0; i < fields.length; i++) {\n\t\t\t\tfields[i]=fields[i].trim();\n\t\t\t}\n\t\t}\n\t\t\n\t\t//Parse any \"stopWords\" attribute\n\t\t//TODO MoreLikeThis needs to ideally have per-field stopWords lists - until then \n\t\t//I use all analyzers/fields to generate multi-field compatible stop list\n\t\tString stopWords=e.getAttribute(\"stopWords\");\n\t\tSet stopWordsSet=null;\n\t\tif((stopWords!=null)&&(fields!=null))\n\t\t{\n\t\t    stopWordsSet=new HashSet();\n                    final Token reusableToken = new Token();\n\t\t    for (int i = 0; i < fields.length; i++)\n            {\n                TokenStream ts = analyzer.tokenStream(fields[i],new StringReader(stopWords));\n                try\n                {\n\t                for (Token nextToken = ts.next(reusableToken); nextToken != null; nextToken = ts.next(reusableToken)) {\n\t                    stopWordsSet.add(nextToken.term());\n\t                }\n                }\n                catch(IOException ioe)\n                {\n                    throw new ParserException(\"IoException parsing stop words list in \"\n                            +getClass().getName()+\":\"+ioe.getLocalizedMessage());\n                }\n            }\n\t\t}\n\t\t\n\t\t\n\t\tMoreLikeThisQuery mlt=new MoreLikeThisQuery(DOMUtils.getText(e),fields,analyzer);\n\t\tmlt.setMaxQueryTerms(DOMUtils.getAttribute(e,\"maxQueryTerms\",defaultMaxQueryTerms));\n\t\tmlt.setMinTermFrequency(DOMUtils.getAttribute(e,\"minTermFrequency\",defaultMinTermFrequency));\n\t\tmlt.setPercentTermsToMatch(DOMUtils.getAttribute(e,\"percentTermsToMatch\",defaultPercentTermsToMatch)/100);\n\t\tmlt.setStopWords(stopWordsSet);\n\t\tint minDocFreq=DOMUtils.getAttribute(e,\"minDocFreq\",-1);\n\t\tif(minDocFreq>=0)\n\t\t{\n\t\t\tmlt.setMinDocFreq(minDocFreq);\n\t\t}\n\n\t\tmlt.setBoost(DOMUtils.getAttribute(e,\"boost\",1.0f));\n\n\t\treturn mlt;\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8d78f014fded44fbde905f4f84cdc21907b371e8","date":1254383623,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder#getQuery(Element).mjava","pathOld":"contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder#getQuery(Element).mjava","sourceNew":"\t/* (non-Javadoc)\n\t * @see org.apache.lucene.xmlparser.QueryObjectBuilder#process(org.w3c.dom.Element)\n\t */\n\tpublic Query getQuery(Element e) throws ParserException {\n\t\tString fieldsList=e.getAttribute(\"fieldNames\"); //a comma-delimited list of fields\n\t\tString fields[]=defaultFieldNames;\n\t\tif((fieldsList!=null)&&(fieldsList.trim().length()>0))\n\t\t{\n\t\t\tfields=fieldsList.trim().split(\",\");\n\t\t\t//trim the fieldnames\n\t\t\tfor (int i = 0; i < fields.length; i++) {\n\t\t\t\tfields[i]=fields[i].trim();\n\t\t\t}\n\t\t}\n\t\t\n\t\t//Parse any \"stopWords\" attribute\n\t\t//TODO MoreLikeThis needs to ideally have per-field stopWords lists - until then \n\t\t//I use all analyzers/fields to generate multi-field compatible stop list\n\t\tString stopWords=e.getAttribute(\"stopWords\");\n\t\tSet stopWordsSet=null;\n\t\tif((stopWords!=null)&&(fields!=null))\n\t\t{\n\t\t    stopWordsSet=new HashSet();\n\t\t    for (int i = 0; i < fields.length; i++)\n            {\n                TokenStream ts = analyzer.tokenStream(fields[i],new StringReader(stopWords));\n                TermAttribute termAtt = ts.addAttribute(TermAttribute.class);\n                try\n                {\n\t                while(ts.incrementToken()) {\n\t                    stopWordsSet.add(termAtt.term());\n\t                }\n                }\n                catch(IOException ioe)\n                {\n                    throw new ParserException(\"IoException parsing stop words list in \"\n                            +getClass().getName()+\":\"+ioe.getLocalizedMessage());\n                }\n            }\n\t\t}\n\t\t\n\t\t\n\t\tMoreLikeThisQuery mlt=new MoreLikeThisQuery(DOMUtils.getText(e),fields,analyzer);\n\t\tmlt.setMaxQueryTerms(DOMUtils.getAttribute(e,\"maxQueryTerms\",defaultMaxQueryTerms));\n\t\tmlt.setMinTermFrequency(DOMUtils.getAttribute(e,\"minTermFrequency\",defaultMinTermFrequency));\n\t\tmlt.setPercentTermsToMatch(DOMUtils.getAttribute(e,\"percentTermsToMatch\",defaultPercentTermsToMatch)/100);\n\t\tmlt.setStopWords(stopWordsSet);\n\t\tint minDocFreq=DOMUtils.getAttribute(e,\"minDocFreq\",-1);\n\t\tif(minDocFreq>=0)\n\t\t{\n\t\t\tmlt.setMinDocFreq(minDocFreq);\n\t\t}\n\n\t\tmlt.setBoost(DOMUtils.getAttribute(e,\"boost\",1.0f));\n\n\t\treturn mlt;\n\t}\n\n","sourceOld":"\t/* (non-Javadoc)\n\t * @see org.apache.lucene.xmlparser.QueryObjectBuilder#process(org.w3c.dom.Element)\n\t */\n\tpublic Query getQuery(Element e) throws ParserException {\n\t\tString fieldsList=e.getAttribute(\"fieldNames\"); //a comma-delimited list of fields\n\t\tString fields[]=defaultFieldNames;\n\t\tif((fieldsList!=null)&&(fieldsList.trim().length()>0))\n\t\t{\n\t\t\tfields=fieldsList.trim().split(\",\");\n\t\t\t//trim the fieldnames\n\t\t\tfor (int i = 0; i < fields.length; i++) {\n\t\t\t\tfields[i]=fields[i].trim();\n\t\t\t}\n\t\t}\n\t\t\n\t\t//Parse any \"stopWords\" attribute\n\t\t//TODO MoreLikeThis needs to ideally have per-field stopWords lists - until then \n\t\t//I use all analyzers/fields to generate multi-field compatible stop list\n\t\tString stopWords=e.getAttribute(\"stopWords\");\n\t\tSet stopWordsSet=null;\n\t\tif((stopWords!=null)&&(fields!=null))\n\t\t{\n\t\t    stopWordsSet=new HashSet();\n\t\t    for (int i = 0; i < fields.length; i++)\n            {\n                TokenStream ts = analyzer.tokenStream(fields[i],new StringReader(stopWords));\n                TermAttribute termAtt = (TermAttribute) ts.addAttribute(TermAttribute.class);\n                try\n                {\n\t                while(ts.incrementToken()) {\n\t                    stopWordsSet.add(termAtt.term());\n\t                }\n                }\n                catch(IOException ioe)\n                {\n                    throw new ParserException(\"IoException parsing stop words list in \"\n                            +getClass().getName()+\":\"+ioe.getLocalizedMessage());\n                }\n            }\n\t\t}\n\t\t\n\t\t\n\t\tMoreLikeThisQuery mlt=new MoreLikeThisQuery(DOMUtils.getText(e),fields,analyzer);\n\t\tmlt.setMaxQueryTerms(DOMUtils.getAttribute(e,\"maxQueryTerms\",defaultMaxQueryTerms));\n\t\tmlt.setMinTermFrequency(DOMUtils.getAttribute(e,\"minTermFrequency\",defaultMinTermFrequency));\n\t\tmlt.setPercentTermsToMatch(DOMUtils.getAttribute(e,\"percentTermsToMatch\",defaultPercentTermsToMatch)/100);\n\t\tmlt.setStopWords(stopWordsSet);\n\t\tint minDocFreq=DOMUtils.getAttribute(e,\"minDocFreq\",-1);\n\t\tif(minDocFreq>=0)\n\t\t{\n\t\t\tmlt.setMinDocFreq(minDocFreq);\n\t\t}\n\n\t\tmlt.setBoost(DOMUtils.getAttribute(e,\"boost\",1.0f));\n\n\t\treturn mlt;\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c69d87d34a81230de56333f52f590caeb6d80667","date":1257848306,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder#getQuery(Element).mjava","pathOld":"contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder#getQuery(Element).mjava","sourceNew":"\t/* (non-Javadoc)\n\t * @see org.apache.lucene.xmlparser.QueryObjectBuilder#process(org.w3c.dom.Element)\n\t */\n\tpublic Query getQuery(Element e) throws ParserException {\n\t\tString fieldsList=e.getAttribute(\"fieldNames\"); //a comma-delimited list of fields\n\t\tString fields[]=defaultFieldNames;\n\t\tif((fieldsList!=null)&&(fieldsList.trim().length()>0))\n\t\t{\n\t\t\tfields=fieldsList.trim().split(\",\");\n\t\t\t//trim the fieldnames\n\t\t\tfor (int i = 0; i < fields.length; i++) {\n\t\t\t\tfields[i]=fields[i].trim();\n\t\t\t}\n\t\t}\n\t\t\n\t\t//Parse any \"stopWords\" attribute\n\t\t//TODO MoreLikeThis needs to ideally have per-field stopWords lists - until then \n\t\t//I use all analyzers/fields to generate multi-field compatible stop list\n\t\tString stopWords=e.getAttribute(\"stopWords\");\n\t\tSet<String> stopWordsSet=null;\n\t\tif((stopWords!=null)&&(fields!=null))\n\t\t{\n\t\t    stopWordsSet=new HashSet<String>();\n\t\t    for (int i = 0; i < fields.length; i++)\n            {\n                TokenStream ts = analyzer.tokenStream(fields[i],new StringReader(stopWords));\n                TermAttribute termAtt = ts.addAttribute(TermAttribute.class);\n                try\n                {\n\t                while(ts.incrementToken()) {\n\t                    stopWordsSet.add(termAtt.term());\n\t                }\n                }\n                catch(IOException ioe)\n                {\n                    throw new ParserException(\"IoException parsing stop words list in \"\n                            +getClass().getName()+\":\"+ioe.getLocalizedMessage());\n                }\n            }\n\t\t}\n\t\t\n\t\t\n\t\tMoreLikeThisQuery mlt=new MoreLikeThisQuery(DOMUtils.getText(e),fields,analyzer);\n\t\tmlt.setMaxQueryTerms(DOMUtils.getAttribute(e,\"maxQueryTerms\",defaultMaxQueryTerms));\n\t\tmlt.setMinTermFrequency(DOMUtils.getAttribute(e,\"minTermFrequency\",defaultMinTermFrequency));\n\t\tmlt.setPercentTermsToMatch(DOMUtils.getAttribute(e,\"percentTermsToMatch\",defaultPercentTermsToMatch)/100);\n\t\tmlt.setStopWords(stopWordsSet);\n\t\tint minDocFreq=DOMUtils.getAttribute(e,\"minDocFreq\",-1);\n\t\tif(minDocFreq>=0)\n\t\t{\n\t\t\tmlt.setMinDocFreq(minDocFreq);\n\t\t}\n\n\t\tmlt.setBoost(DOMUtils.getAttribute(e,\"boost\",1.0f));\n\n\t\treturn mlt;\n\t}\n\n","sourceOld":"\t/* (non-Javadoc)\n\t * @see org.apache.lucene.xmlparser.QueryObjectBuilder#process(org.w3c.dom.Element)\n\t */\n\tpublic Query getQuery(Element e) throws ParserException {\n\t\tString fieldsList=e.getAttribute(\"fieldNames\"); //a comma-delimited list of fields\n\t\tString fields[]=defaultFieldNames;\n\t\tif((fieldsList!=null)&&(fieldsList.trim().length()>0))\n\t\t{\n\t\t\tfields=fieldsList.trim().split(\",\");\n\t\t\t//trim the fieldnames\n\t\t\tfor (int i = 0; i < fields.length; i++) {\n\t\t\t\tfields[i]=fields[i].trim();\n\t\t\t}\n\t\t}\n\t\t\n\t\t//Parse any \"stopWords\" attribute\n\t\t//TODO MoreLikeThis needs to ideally have per-field stopWords lists - until then \n\t\t//I use all analyzers/fields to generate multi-field compatible stop list\n\t\tString stopWords=e.getAttribute(\"stopWords\");\n\t\tSet stopWordsSet=null;\n\t\tif((stopWords!=null)&&(fields!=null))\n\t\t{\n\t\t    stopWordsSet=new HashSet();\n\t\t    for (int i = 0; i < fields.length; i++)\n            {\n                TokenStream ts = analyzer.tokenStream(fields[i],new StringReader(stopWords));\n                TermAttribute termAtt = ts.addAttribute(TermAttribute.class);\n                try\n                {\n\t                while(ts.incrementToken()) {\n\t                    stopWordsSet.add(termAtt.term());\n\t                }\n                }\n                catch(IOException ioe)\n                {\n                    throw new ParserException(\"IoException parsing stop words list in \"\n                            +getClass().getName()+\":\"+ioe.getLocalizedMessage());\n                }\n            }\n\t\t}\n\t\t\n\t\t\n\t\tMoreLikeThisQuery mlt=new MoreLikeThisQuery(DOMUtils.getText(e),fields,analyzer);\n\t\tmlt.setMaxQueryTerms(DOMUtils.getAttribute(e,\"maxQueryTerms\",defaultMaxQueryTerms));\n\t\tmlt.setMinTermFrequency(DOMUtils.getAttribute(e,\"minTermFrequency\",defaultMinTermFrequency));\n\t\tmlt.setPercentTermsToMatch(DOMUtils.getAttribute(e,\"percentTermsToMatch\",defaultPercentTermsToMatch)/100);\n\t\tmlt.setStopWords(stopWordsSet);\n\t\tint minDocFreq=DOMUtils.getAttribute(e,\"minDocFreq\",-1);\n\t\tif(minDocFreq>=0)\n\t\t{\n\t\t\tmlt.setMinDocFreq(minDocFreq);\n\t\t}\n\n\t\tmlt.setBoost(DOMUtils.getAttribute(e,\"boost\",1.0f));\n\n\t\treturn mlt;\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder#getQuery(Element).mjava","pathOld":"contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder#getQuery(Element).mjava","sourceNew":"\t/* (non-Javadoc)\n\t * @see org.apache.lucene.xmlparser.QueryObjectBuilder#process(org.w3c.dom.Element)\n\t */\n\tpublic Query getQuery(Element e) throws ParserException {\n\t\tString fieldsList=e.getAttribute(\"fieldNames\"); //a comma-delimited list of fields\n\t\tString fields[]=defaultFieldNames;\n\t\tif((fieldsList!=null)&&(fieldsList.trim().length()>0))\n\t\t{\n\t\t\tfields=fieldsList.trim().split(\",\");\n\t\t\t//trim the fieldnames\n\t\t\tfor (int i = 0; i < fields.length; i++) {\n\t\t\t\tfields[i]=fields[i].trim();\n\t\t\t}\n\t\t}\n\t\t\n\t\t//Parse any \"stopWords\" attribute\n\t\t//TODO MoreLikeThis needs to ideally have per-field stopWords lists - until then \n\t\t//I use all analyzers/fields to generate multi-field compatible stop list\n\t\tString stopWords=e.getAttribute(\"stopWords\");\n\t\tSet<String> stopWordsSet=null;\n\t\tif((stopWords!=null)&&(fields!=null))\n\t\t{\n\t\t    stopWordsSet=new HashSet<String>();\n\t\t    for (int i = 0; i < fields.length; i++)\n            {\n                TokenStream ts = analyzer.tokenStream(fields[i],new StringReader(stopWords));\n                TermAttribute termAtt = ts.addAttribute(TermAttribute.class);\n                try\n                {\n\t                while(ts.incrementToken()) {\n\t                    stopWordsSet.add(termAtt.term());\n\t                }\n                }\n                catch(IOException ioe)\n                {\n                    throw new ParserException(\"IoException parsing stop words list in \"\n                            +getClass().getName()+\":\"+ioe.getLocalizedMessage());\n                }\n            }\n\t\t}\n\t\t\n\t\t\n\t\tMoreLikeThisQuery mlt=new MoreLikeThisQuery(DOMUtils.getText(e),fields,analyzer);\n\t\tmlt.setMaxQueryTerms(DOMUtils.getAttribute(e,\"maxQueryTerms\",defaultMaxQueryTerms));\n\t\tmlt.setMinTermFrequency(DOMUtils.getAttribute(e,\"minTermFrequency\",defaultMinTermFrequency));\n\t\tmlt.setPercentTermsToMatch(DOMUtils.getAttribute(e,\"percentTermsToMatch\",defaultPercentTermsToMatch)/100);\n\t\tmlt.setStopWords(stopWordsSet);\n\t\tint minDocFreq=DOMUtils.getAttribute(e,\"minDocFreq\",-1);\n\t\tif(minDocFreq>=0)\n\t\t{\n\t\t\tmlt.setMinDocFreq(minDocFreq);\n\t\t}\n\n\t\tmlt.setBoost(DOMUtils.getAttribute(e,\"boost\",1.0f));\n\n\t\treturn mlt;\n\t}\n\n","sourceOld":"\t/* (non-Javadoc)\n\t * @see org.apache.lucene.xmlparser.QueryObjectBuilder#process(org.w3c.dom.Element)\n\t */\n\tpublic Query getQuery(Element e) throws ParserException {\n\t\tString fieldsList=e.getAttribute(\"fieldNames\"); //a comma-delimited list of fields\n\t\tString fields[]=defaultFieldNames;\n\t\tif((fieldsList!=null)&&(fieldsList.trim().length()>0))\n\t\t{\n\t\t\tfields=fieldsList.trim().split(\",\");\n\t\t\t//trim the fieldnames\n\t\t\tfor (int i = 0; i < fields.length; i++) {\n\t\t\t\tfields[i]=fields[i].trim();\n\t\t\t}\n\t\t}\n\t\t\n\t\t//Parse any \"stopWords\" attribute\n\t\t//TODO MoreLikeThis needs to ideally have per-field stopWords lists - until then \n\t\t//I use all analyzers/fields to generate multi-field compatible stop list\n\t\tString stopWords=e.getAttribute(\"stopWords\");\n\t\tSet<String> stopWordsSet=null;\n\t\tif((stopWords!=null)&&(fields!=null))\n\t\t{\n\t\t    stopWordsSet=new HashSet<String>();\n\t\t    for (int i = 0; i < fields.length; i++)\n            {\n                TokenStream ts = analyzer.tokenStream(fields[i],new StringReader(stopWords));\n                TermAttribute termAtt = ts.addAttribute(TermAttribute.class);\n                try\n                {\n\t                while(ts.incrementToken()) {\n\t                    stopWordsSet.add(termAtt.term());\n\t                }\n                }\n                catch(IOException ioe)\n                {\n                    throw new ParserException(\"IoException parsing stop words list in \"\n                            +getClass().getName()+\":\"+ioe.getLocalizedMessage());\n                }\n            }\n\t\t}\n\t\t\n\t\t\n\t\tMoreLikeThisQuery mlt=new MoreLikeThisQuery(DOMUtils.getText(e),fields,analyzer);\n\t\tmlt.setMaxQueryTerms(DOMUtils.getAttribute(e,\"maxQueryTerms\",defaultMaxQueryTerms));\n\t\tmlt.setMinTermFrequency(DOMUtils.getAttribute(e,\"minTermFrequency\",defaultMinTermFrequency));\n\t\tmlt.setPercentTermsToMatch(DOMUtils.getAttribute(e,\"percentTermsToMatch\",defaultPercentTermsToMatch)/100);\n\t\tmlt.setStopWords(stopWordsSet);\n\t\tint minDocFreq=DOMUtils.getAttribute(e,\"minDocFreq\",-1);\n\t\tif(minDocFreq>=0)\n\t\t{\n\t\t\tmlt.setMinDocFreq(minDocFreq);\n\t\t}\n\n\t\tmlt.setBoost(DOMUtils.getAttribute(e,\"boost\",1.0f));\n\n\t\treturn mlt;\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"7e2cb543b41c145f33390f460ee743d6693c9c6c":["5a90cc8f220330c2def1d91a24b75545cedf6230"],"c69d87d34a81230de56333f52f590caeb6d80667":["8d78f014fded44fbde905f4f84cdc21907b371e8"],"5706b74946ebff9c666698df31106be9a192ab0d":["d3c3c2404d1200c39220fa15054fae854db4e1ee"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"9b5756469957918cac40a831acec9cf01c8c2bb3":["6a361a621b184d9b73c9c9a37323a9845b8f8260"],"5a90cc8f220330c2def1d91a24b75545cedf6230":["5706b74946ebff9c666698df31106be9a192ab0d"],"6a361a621b184d9b73c9c9a37323a9845b8f8260":["7e2cb543b41c145f33390f460ee743d6693c9c6c"],"d3c3c2404d1200c39220fa15054fae854db4e1ee":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"8d78f014fded44fbde905f4f84cdc21907b371e8":["9b5756469957918cac40a831acec9cf01c8c2bb3"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["c69d87d34a81230de56333f52f590caeb6d80667"]},"commit2Childs":{"7e2cb543b41c145f33390f460ee743d6693c9c6c":["6a361a621b184d9b73c9c9a37323a9845b8f8260"],"c69d87d34a81230de56333f52f590caeb6d80667":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"5706b74946ebff9c666698df31106be9a192ab0d":["5a90cc8f220330c2def1d91a24b75545cedf6230"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["d3c3c2404d1200c39220fa15054fae854db4e1ee"],"5a90cc8f220330c2def1d91a24b75545cedf6230":["7e2cb543b41c145f33390f460ee743d6693c9c6c"],"9b5756469957918cac40a831acec9cf01c8c2bb3":["8d78f014fded44fbde905f4f84cdc21907b371e8"],"d3c3c2404d1200c39220fa15054fae854db4e1ee":["5706b74946ebff9c666698df31106be9a192ab0d"],"6a361a621b184d9b73c9c9a37323a9845b8f8260":["9b5756469957918cac40a831acec9cf01c8c2bb3"],"8d78f014fded44fbde905f4f84cdc21907b371e8":["c69d87d34a81230de56333f52f590caeb6d80667"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}