{"path":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/BlockTermsWriter.TermsWriter#write(BytesRef,TermsEnum).mjava","commits":[{"id":"fa80a35d7c4b2b1e83082b275e3e8328ab93db52","date":1381766157,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/BlockTermsWriter.TermsWriter#write(BytesRef,TermsEnum).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/BlockTermsWriter.TermsWriter#finishTerm(BytesRef,TermStats).mjava","sourceNew":"    void write(BytesRef text, TermsEnum termsEnum) throws IOException {\n\n      BlockTermState state = postingsWriter.writeTerm(text, termsEnum, docsSeen);\n      if (state == null) {\n        // No docs for this term:\n        return;\n      }\n      sumDocFreq += state.docFreq;\n      sumTotalTermFreq += state.totalTermFreq;\n\n      assert state.docFreq > 0;\n      //System.out.println(\"BTW: finishTerm term=\" + fieldInfo.name + \":\" + text.utf8ToString() + \" \" + text + \" seg=\" + segment + \" df=\" + stats.docFreq);\n\n      TermStats stats = new TermStats(state.docFreq, state.totalTermFreq);\n      final boolean isIndexTerm = fieldIndexWriter.checkIndexTerm(text, stats);\n\n      if (isIndexTerm) {\n        if (pendingCount > 0) {\n          // Instead of writing each term, live, we gather terms\n          // in RAM in a pending buffer, and then write the\n          // entire block in between index terms:\n          flushBlock();\n        }\n        fieldIndexWriter.add(text, stats, out.getFilePointer());\n        //System.out.println(\"  index term!\");\n      }\n\n      if (pendingTerms.length == pendingCount) {\n        final TermEntry[] newArray = new TermEntry[ArrayUtil.oversize(pendingCount+1, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(pendingTerms, 0, newArray, 0, pendingCount);\n        for(int i=pendingCount;i<newArray.length;i++) {\n          newArray[i] = new TermEntry();\n        }\n        pendingTerms = newArray;\n      }\n      final TermEntry te = pendingTerms[pendingCount];\n      te.term.copyBytes(text);\n      te.state = state;\n\n      pendingCount++;\n      numTerms++;\n    }\n\n","sourceOld":"    @Override\n    public void finishTerm(BytesRef text, TermStats stats) throws IOException {\n\n      assert stats.docFreq > 0;\n      //System.out.println(\"BTW: finishTerm term=\" + fieldInfo.name + \":\" + text.utf8ToString() + \" \" + text + \" seg=\" + segment + \" df=\" + stats.docFreq);\n\n      final boolean isIndexTerm = fieldIndexWriter.checkIndexTerm(text, stats);\n\n      if (isIndexTerm) {\n        if (pendingCount > 0) {\n          // Instead of writing each term, live, we gather terms\n          // in RAM in a pending buffer, and then write the\n          // entire block in between index terms:\n          flushBlock();\n        }\n        fieldIndexWriter.add(text, stats, out.getFilePointer());\n        //System.out.println(\"  index term!\");\n      }\n\n      if (pendingTerms.length == pendingCount) {\n        final TermEntry[] newArray = new TermEntry[ArrayUtil.oversize(pendingCount+1, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(pendingTerms, 0, newArray, 0, pendingCount);\n        for(int i=pendingCount;i<newArray.length;i++) {\n          newArray[i] = new TermEntry();\n        }\n        pendingTerms = newArray;\n      }\n      final TermEntry te = pendingTerms[pendingCount];\n      te.term.copyBytes(text);\n      te.state = postingsWriter.newTermState();\n      te.state.docFreq = stats.docFreq;\n      te.state.totalTermFreq = stats.totalTermFreq;\n      postingsWriter.finishTerm(te.state);\n\n      pendingCount++;\n      numTerms++;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50","date":1407854805,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/BlockTermsWriter.TermsWriter#write(BytesRef,TermsEnum).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/BlockTermsWriter.TermsWriter#write(BytesRef,TermsEnum).mjava","sourceNew":"    void write(BytesRef text, TermsEnum termsEnum) throws IOException {\n\n      BlockTermState state = postingsWriter.writeTerm(text, termsEnum, docsSeen);\n      if (state == null) {\n        // No docs for this term:\n        return;\n      }\n      sumDocFreq += state.docFreq;\n      sumTotalTermFreq += state.totalTermFreq;\n\n      assert state.docFreq > 0;\n      //System.out.println(\"BTW: finishTerm term=\" + fieldInfo.name + \":\" + text.utf8ToString() + \" \" + text + \" seg=\" + segment + \" df=\" + stats.docFreq);\n\n      TermStats stats = new TermStats(state.docFreq, state.totalTermFreq);\n      final boolean isIndexTerm = fieldIndexWriter.checkIndexTerm(text, stats);\n\n      if (isIndexTerm) {\n        if (pendingCount > 0) {\n          // Instead of writing each term, live, we gather terms\n          // in RAM in a pending buffer, and then write the\n          // entire block in between index terms:\n          flushBlock();\n        }\n        fieldIndexWriter.add(text, stats, out.getFilePointer());\n        //System.out.println(\"  index term!\");\n      }\n\n      if (pendingTerms.length == pendingCount) {\n        pendingTerms = Arrays.copyOf(pendingTerms, ArrayUtil.oversize(pendingCount+1, RamUsageEstimator.NUM_BYTES_OBJECT_REF));\n        for(int i=pendingCount;i<pendingTerms.length;i++) {\n          pendingTerms[i] = new TermEntry();\n        }\n      }\n      final TermEntry te = pendingTerms[pendingCount];\n      te.term.copyBytes(text);\n      te.state = state;\n\n      pendingCount++;\n      numTerms++;\n    }\n\n","sourceOld":"    void write(BytesRef text, TermsEnum termsEnum) throws IOException {\n\n      BlockTermState state = postingsWriter.writeTerm(text, termsEnum, docsSeen);\n      if (state == null) {\n        // No docs for this term:\n        return;\n      }\n      sumDocFreq += state.docFreq;\n      sumTotalTermFreq += state.totalTermFreq;\n\n      assert state.docFreq > 0;\n      //System.out.println(\"BTW: finishTerm term=\" + fieldInfo.name + \":\" + text.utf8ToString() + \" \" + text + \" seg=\" + segment + \" df=\" + stats.docFreq);\n\n      TermStats stats = new TermStats(state.docFreq, state.totalTermFreq);\n      final boolean isIndexTerm = fieldIndexWriter.checkIndexTerm(text, stats);\n\n      if (isIndexTerm) {\n        if (pendingCount > 0) {\n          // Instead of writing each term, live, we gather terms\n          // in RAM in a pending buffer, and then write the\n          // entire block in between index terms:\n          flushBlock();\n        }\n        fieldIndexWriter.add(text, stats, out.getFilePointer());\n        //System.out.println(\"  index term!\");\n      }\n\n      if (pendingTerms.length == pendingCount) {\n        final TermEntry[] newArray = new TermEntry[ArrayUtil.oversize(pendingCount+1, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(pendingTerms, 0, newArray, 0, pendingCount);\n        for(int i=pendingCount;i<newArray.length;i++) {\n          newArray[i] = new TermEntry();\n        }\n        pendingTerms = newArray;\n      }\n      final TermEntry te = pendingTerms[pendingCount];\n      te.term.copyBytes(text);\n      te.state = state;\n\n      pendingCount++;\n      numTerms++;\n    }\n\n","bugFix":["b1add9ddc0005b07550d4350720aac22dc9886b3"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"622a708571e534680618b3c5e0c28ac539a47776","date":1517406892,"type":5,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/BlockTermsWriter.TermsWriter#write(BytesRef,TermsEnum,NormsProducer).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/BlockTermsWriter.TermsWriter#write(BytesRef,TermsEnum).mjava","sourceNew":"    void write(BytesRef text, TermsEnum termsEnum, NormsProducer norms) throws IOException {\n\n      BlockTermState state = postingsWriter.writeTerm(text, termsEnum, docsSeen, norms);\n      if (state == null) {\n        // No docs for this term:\n        return;\n      }\n      sumDocFreq += state.docFreq;\n      sumTotalTermFreq += state.totalTermFreq;\n\n      assert state.docFreq > 0;\n      //System.out.println(\"BTW: finishTerm term=\" + fieldInfo.name + \":\" + text.utf8ToString() + \" \" + text + \" seg=\" + segment + \" df=\" + stats.docFreq);\n\n      TermStats stats = new TermStats(state.docFreq, state.totalTermFreq);\n      final boolean isIndexTerm = fieldIndexWriter.checkIndexTerm(text, stats);\n\n      if (isIndexTerm) {\n        if (pendingCount > 0) {\n          // Instead of writing each term, live, we gather terms\n          // in RAM in a pending buffer, and then write the\n          // entire block in between index terms:\n          flushBlock();\n        }\n        fieldIndexWriter.add(text, stats, out.getFilePointer());\n        //System.out.println(\"  index term!\");\n      }\n\n      if (pendingTerms.length == pendingCount) {\n        pendingTerms = Arrays.copyOf(pendingTerms, ArrayUtil.oversize(pendingCount+1, RamUsageEstimator.NUM_BYTES_OBJECT_REF));\n        for(int i=pendingCount;i<pendingTerms.length;i++) {\n          pendingTerms[i] = new TermEntry();\n        }\n      }\n      final TermEntry te = pendingTerms[pendingCount];\n      te.term.copyBytes(text);\n      te.state = state;\n\n      pendingCount++;\n      numTerms++;\n    }\n\n","sourceOld":"    void write(BytesRef text, TermsEnum termsEnum) throws IOException {\n\n      BlockTermState state = postingsWriter.writeTerm(text, termsEnum, docsSeen);\n      if (state == null) {\n        // No docs for this term:\n        return;\n      }\n      sumDocFreq += state.docFreq;\n      sumTotalTermFreq += state.totalTermFreq;\n\n      assert state.docFreq > 0;\n      //System.out.println(\"BTW: finishTerm term=\" + fieldInfo.name + \":\" + text.utf8ToString() + \" \" + text + \" seg=\" + segment + \" df=\" + stats.docFreq);\n\n      TermStats stats = new TermStats(state.docFreq, state.totalTermFreq);\n      final boolean isIndexTerm = fieldIndexWriter.checkIndexTerm(text, stats);\n\n      if (isIndexTerm) {\n        if (pendingCount > 0) {\n          // Instead of writing each term, live, we gather terms\n          // in RAM in a pending buffer, and then write the\n          // entire block in between index terms:\n          flushBlock();\n        }\n        fieldIndexWriter.add(text, stats, out.getFilePointer());\n        //System.out.println(\"  index term!\");\n      }\n\n      if (pendingTerms.length == pendingCount) {\n        pendingTerms = Arrays.copyOf(pendingTerms, ArrayUtil.oversize(pendingCount+1, RamUsageEstimator.NUM_BYTES_OBJECT_REF));\n        for(int i=pendingCount;i<pendingTerms.length;i++) {\n          pendingTerms[i] = new TermEntry();\n        }\n      }\n      final TermEntry te = pendingTerms[pendingCount];\n      te.term.copyBytes(text);\n      te.state = state;\n\n      pendingCount++;\n      numTerms++;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"622a708571e534680618b3c5e0c28ac539a47776":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"fa80a35d7c4b2b1e83082b275e3e8328ab93db52":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50":["fa80a35d7c4b2b1e83082b275e3e8328ab93db52"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["622a708571e534680618b3c5e0c28ac539a47776"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["fa80a35d7c4b2b1e83082b275e3e8328ab93db52"],"622a708571e534680618b3c5e0c28ac539a47776":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"fa80a35d7c4b2b1e83082b275e3e8328ab93db52":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50":["622a708571e534680618b3c5e0c28ac539a47776"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}