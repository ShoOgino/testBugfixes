{"path":"lucene/core/src/java/org/apache/lucene/codecs/lucene45/Lucene45DocValuesConsumer#addTermsDict(FieldInfo,Iterable[BytesRef]).mjava","commits":[{"id":"11a746437bc5c0a0b3df0337ed249c387c812871","date":1376687959,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene45/Lucene45DocValuesConsumer#addTermsDict(FieldInfo,Iterable[BytesRef]).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/diskdv/DiskDocValuesConsumer#addTermsDict(FieldInfo,Iterable[BytesRef]).mjava","sourceNew":"  protected void addTermsDict(FieldInfo field, final Iterable<BytesRef> values) throws IOException {\n    // first check if its a \"fixed-length\" terms dict\n    int minLength = Integer.MAX_VALUE;\n    int maxLength = Integer.MIN_VALUE;\n    for (BytesRef v : values) {\n      minLength = Math.min(minLength, v.length);\n      maxLength = Math.max(maxLength, v.length);\n    }\n    if (minLength == maxLength) {\n      // no index needed: direct addressing by mult\n      addBinaryField(field, values);\n    } else {\n      // header\n      meta.writeVInt(field.number);\n      meta.writeByte(Lucene45DocValuesFormat.BINARY);\n      meta.writeVInt(BINARY_PREFIX_COMPRESSED);\n      // now write the bytes: sharing prefixes within a block\n      final long startFP = data.getFilePointer();\n      // currently, we have to store the delta from expected for every 1/nth term\n      // we could avoid this, but its not much and less overall RAM than the previous approach!\n      RAMOutputStream addressBuffer = new RAMOutputStream();\n      MonotonicBlockPackedWriter termAddresses = new MonotonicBlockPackedWriter(addressBuffer, BLOCK_SIZE);\n      BytesRef lastTerm = new BytesRef();\n      long count = 0;\n      for (BytesRef v : values) {\n        if (count % ADDRESS_INTERVAL == 0) {\n          termAddresses.add(data.getFilePointer() - startFP);\n          // force the first term in a block to be abs-encoded\n          lastTerm.length = 0;\n        }\n        \n        // prefix-code\n        int sharedPrefix = StringHelper.bytesDifference(lastTerm, v);\n        data.writeVInt(sharedPrefix);\n        data.writeVInt(v.length - sharedPrefix);\n        data.writeBytes(v.bytes, v.offset + sharedPrefix, v.length - sharedPrefix);\n        lastTerm.copyBytes(v);\n        count++;\n      }\n      final long indexStartFP = data.getFilePointer();\n      // write addresses of indexed terms\n      termAddresses.finish();\n      addressBuffer.writeTo(data);\n      addressBuffer = null;\n      termAddresses = null;\n      meta.writeVInt(minLength);\n      meta.writeVInt(maxLength);\n      meta.writeVLong(count);\n      meta.writeLong(startFP);\n      meta.writeVInt(ADDRESS_INTERVAL);\n      meta.writeLong(indexStartFP);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      meta.writeVInt(BLOCK_SIZE);\n    }\n  }\n\n","sourceOld":"  protected void addTermsDict(FieldInfo field, final Iterable<BytesRef> values) throws IOException {\n    // first check if its a \"fixed-length\" terms dict\n    int minLength = Integer.MAX_VALUE;\n    int maxLength = Integer.MIN_VALUE;\n    for (BytesRef v : values) {\n      minLength = Math.min(minLength, v.length);\n      maxLength = Math.max(maxLength, v.length);\n    }\n    if (minLength == maxLength) {\n      // no index needed: direct addressing by mult\n      addBinaryField(field, values);\n    } else {\n      // header\n      meta.writeVInt(field.number);\n      meta.writeByte(DiskDocValuesFormat.BINARY);\n      meta.writeVInt(BINARY_PREFIX_COMPRESSED);\n      // now write the bytes: sharing prefixes within a block\n      final long startFP = data.getFilePointer();\n      // currently, we have to store the delta from expected for every 1/nth term\n      // we could avoid this, but its not much and less overall RAM than the previous approach!\n      RAMOutputStream addressBuffer = new RAMOutputStream();\n      MonotonicBlockPackedWriter termAddresses = new MonotonicBlockPackedWriter(addressBuffer, BLOCK_SIZE);\n      BytesRef lastTerm = new BytesRef();\n      long count = 0;\n      for (BytesRef v : values) {\n        if (count % ADDRESS_INTERVAL == 0) {\n          termAddresses.add(data.getFilePointer() - startFP);\n          // force the first term in a block to be abs-encoded\n          lastTerm.length = 0;\n        }\n        \n        // prefix-code\n        int sharedPrefix = StringHelper.bytesDifference(lastTerm, v);\n        data.writeVInt(sharedPrefix);\n        data.writeVInt(v.length - sharedPrefix);\n        data.writeBytes(v.bytes, v.offset + sharedPrefix, v.length - sharedPrefix);\n        lastTerm.copyBytes(v);\n        count++;\n      }\n      final long indexStartFP = data.getFilePointer();\n      // write addresses of indexed terms\n      termAddresses.finish();\n      addressBuffer.writeTo(data);\n      addressBuffer = null;\n      termAddresses = null;\n      meta.writeVInt(minLength);\n      meta.writeVInt(maxLength);\n      meta.writeVLong(count);\n      meta.writeLong(startFP);\n      meta.writeVInt(ADDRESS_INTERVAL);\n      meta.writeLong(indexStartFP);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      meta.writeVInt(BLOCK_SIZE);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1a7bf5332d569e3d07c4b248462f5d212e26e9af","date":1376929683,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene45/Lucene45DocValuesConsumer#addTermsDict(FieldInfo,Iterable[BytesRef]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene45/Lucene45DocValuesConsumer#addTermsDict(FieldInfo,Iterable[BytesRef]).mjava","sourceNew":"  protected void addTermsDict(FieldInfo field, final Iterable<BytesRef> values) throws IOException {\n    // first check if its a \"fixed-length\" terms dict\n    int minLength = Integer.MAX_VALUE;\n    int maxLength = Integer.MIN_VALUE;\n    for (BytesRef v : values) {\n      minLength = Math.min(minLength, v.length);\n      maxLength = Math.max(maxLength, v.length);\n    }\n    if (minLength == maxLength) {\n      // no index needed: direct addressing by mult\n      addBinaryField(field, values);\n    } else {\n      // header\n      meta.writeVInt(field.number);\n      meta.writeByte(Lucene45DocValuesFormat.BINARY);\n      meta.writeVInt(BINARY_PREFIX_COMPRESSED);\n      meta.writeLong(-1L);\n      // now write the bytes: sharing prefixes within a block\n      final long startFP = data.getFilePointer();\n      // currently, we have to store the delta from expected for every 1/nth term\n      // we could avoid this, but its not much and less overall RAM than the previous approach!\n      RAMOutputStream addressBuffer = new RAMOutputStream();\n      MonotonicBlockPackedWriter termAddresses = new MonotonicBlockPackedWriter(addressBuffer, BLOCK_SIZE);\n      BytesRef lastTerm = new BytesRef();\n      long count = 0;\n      for (BytesRef v : values) {\n        if (count % ADDRESS_INTERVAL == 0) {\n          termAddresses.add(data.getFilePointer() - startFP);\n          // force the first term in a block to be abs-encoded\n          lastTerm.length = 0;\n        }\n        \n        // prefix-code\n        int sharedPrefix = StringHelper.bytesDifference(lastTerm, v);\n        data.writeVInt(sharedPrefix);\n        data.writeVInt(v.length - sharedPrefix);\n        data.writeBytes(v.bytes, v.offset + sharedPrefix, v.length - sharedPrefix);\n        lastTerm.copyBytes(v);\n        count++;\n      }\n      final long indexStartFP = data.getFilePointer();\n      // write addresses of indexed terms\n      termAddresses.finish();\n      addressBuffer.writeTo(data);\n      addressBuffer = null;\n      termAddresses = null;\n      meta.writeVInt(minLength);\n      meta.writeVInt(maxLength);\n      meta.writeVLong(count);\n      meta.writeLong(startFP);\n      meta.writeVInt(ADDRESS_INTERVAL);\n      meta.writeLong(indexStartFP);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      meta.writeVInt(BLOCK_SIZE);\n    }\n  }\n\n","sourceOld":"  protected void addTermsDict(FieldInfo field, final Iterable<BytesRef> values) throws IOException {\n    // first check if its a \"fixed-length\" terms dict\n    int minLength = Integer.MAX_VALUE;\n    int maxLength = Integer.MIN_VALUE;\n    for (BytesRef v : values) {\n      minLength = Math.min(minLength, v.length);\n      maxLength = Math.max(maxLength, v.length);\n    }\n    if (minLength == maxLength) {\n      // no index needed: direct addressing by mult\n      addBinaryField(field, values);\n    } else {\n      // header\n      meta.writeVInt(field.number);\n      meta.writeByte(Lucene45DocValuesFormat.BINARY);\n      meta.writeVInt(BINARY_PREFIX_COMPRESSED);\n      // now write the bytes: sharing prefixes within a block\n      final long startFP = data.getFilePointer();\n      // currently, we have to store the delta from expected for every 1/nth term\n      // we could avoid this, but its not much and less overall RAM than the previous approach!\n      RAMOutputStream addressBuffer = new RAMOutputStream();\n      MonotonicBlockPackedWriter termAddresses = new MonotonicBlockPackedWriter(addressBuffer, BLOCK_SIZE);\n      BytesRef lastTerm = new BytesRef();\n      long count = 0;\n      for (BytesRef v : values) {\n        if (count % ADDRESS_INTERVAL == 0) {\n          termAddresses.add(data.getFilePointer() - startFP);\n          // force the first term in a block to be abs-encoded\n          lastTerm.length = 0;\n        }\n        \n        // prefix-code\n        int sharedPrefix = StringHelper.bytesDifference(lastTerm, v);\n        data.writeVInt(sharedPrefix);\n        data.writeVInt(v.length - sharedPrefix);\n        data.writeBytes(v.bytes, v.offset + sharedPrefix, v.length - sharedPrefix);\n        lastTerm.copyBytes(v);\n        count++;\n      }\n      final long indexStartFP = data.getFilePointer();\n      // write addresses of indexed terms\n      termAddresses.finish();\n      addressBuffer.writeTo(data);\n      addressBuffer = null;\n      termAddresses = null;\n      meta.writeVInt(minLength);\n      meta.writeVInt(maxLength);\n      meta.writeVLong(count);\n      meta.writeLong(startFP);\n      meta.writeVInt(ADDRESS_INTERVAL);\n      meta.writeLong(indexStartFP);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      meta.writeVInt(BLOCK_SIZE);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"61558dab896ba60794837a7dd3b3be5b7940044d","date":1376939269,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene45/Lucene45DocValuesConsumer#addTermsDict(FieldInfo,Iterable[BytesRef]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene45/Lucene45DocValuesConsumer#addTermsDict(FieldInfo,Iterable[BytesRef]).mjava","sourceNew":"  /** expert: writes a value dictionary for a sorted/sortedset field */\n  protected void addTermsDict(FieldInfo field, final Iterable<BytesRef> values) throws IOException {\n    // first check if its a \"fixed-length\" terms dict\n    int minLength = Integer.MAX_VALUE;\n    int maxLength = Integer.MIN_VALUE;\n    for (BytesRef v : values) {\n      minLength = Math.min(minLength, v.length);\n      maxLength = Math.max(maxLength, v.length);\n    }\n    if (minLength == maxLength) {\n      // no index needed: direct addressing by mult\n      addBinaryField(field, values);\n    } else {\n      // header\n      meta.writeVInt(field.number);\n      meta.writeByte(Lucene45DocValuesFormat.BINARY);\n      meta.writeVInt(BINARY_PREFIX_COMPRESSED);\n      meta.writeLong(-1L);\n      // now write the bytes: sharing prefixes within a block\n      final long startFP = data.getFilePointer();\n      // currently, we have to store the delta from expected for every 1/nth term\n      // we could avoid this, but its not much and less overall RAM than the previous approach!\n      RAMOutputStream addressBuffer = new RAMOutputStream();\n      MonotonicBlockPackedWriter termAddresses = new MonotonicBlockPackedWriter(addressBuffer, BLOCK_SIZE);\n      BytesRef lastTerm = new BytesRef();\n      long count = 0;\n      for (BytesRef v : values) {\n        if (count % ADDRESS_INTERVAL == 0) {\n          termAddresses.add(data.getFilePointer() - startFP);\n          // force the first term in a block to be abs-encoded\n          lastTerm.length = 0;\n        }\n        \n        // prefix-code\n        int sharedPrefix = StringHelper.bytesDifference(lastTerm, v);\n        data.writeVInt(sharedPrefix);\n        data.writeVInt(v.length - sharedPrefix);\n        data.writeBytes(v.bytes, v.offset + sharedPrefix, v.length - sharedPrefix);\n        lastTerm.copyBytes(v);\n        count++;\n      }\n      final long indexStartFP = data.getFilePointer();\n      // write addresses of indexed terms\n      termAddresses.finish();\n      addressBuffer.writeTo(data);\n      addressBuffer = null;\n      termAddresses = null;\n      meta.writeVInt(minLength);\n      meta.writeVInt(maxLength);\n      meta.writeVLong(count);\n      meta.writeLong(startFP);\n      meta.writeVInt(ADDRESS_INTERVAL);\n      meta.writeLong(indexStartFP);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      meta.writeVInt(BLOCK_SIZE);\n    }\n  }\n\n","sourceOld":"  protected void addTermsDict(FieldInfo field, final Iterable<BytesRef> values) throws IOException {\n    // first check if its a \"fixed-length\" terms dict\n    int minLength = Integer.MAX_VALUE;\n    int maxLength = Integer.MIN_VALUE;\n    for (BytesRef v : values) {\n      minLength = Math.min(minLength, v.length);\n      maxLength = Math.max(maxLength, v.length);\n    }\n    if (minLength == maxLength) {\n      // no index needed: direct addressing by mult\n      addBinaryField(field, values);\n    } else {\n      // header\n      meta.writeVInt(field.number);\n      meta.writeByte(Lucene45DocValuesFormat.BINARY);\n      meta.writeVInt(BINARY_PREFIX_COMPRESSED);\n      meta.writeLong(-1L);\n      // now write the bytes: sharing prefixes within a block\n      final long startFP = data.getFilePointer();\n      // currently, we have to store the delta from expected for every 1/nth term\n      // we could avoid this, but its not much and less overall RAM than the previous approach!\n      RAMOutputStream addressBuffer = new RAMOutputStream();\n      MonotonicBlockPackedWriter termAddresses = new MonotonicBlockPackedWriter(addressBuffer, BLOCK_SIZE);\n      BytesRef lastTerm = new BytesRef();\n      long count = 0;\n      for (BytesRef v : values) {\n        if (count % ADDRESS_INTERVAL == 0) {\n          termAddresses.add(data.getFilePointer() - startFP);\n          // force the first term in a block to be abs-encoded\n          lastTerm.length = 0;\n        }\n        \n        // prefix-code\n        int sharedPrefix = StringHelper.bytesDifference(lastTerm, v);\n        data.writeVInt(sharedPrefix);\n        data.writeVInt(v.length - sharedPrefix);\n        data.writeBytes(v.bytes, v.offset + sharedPrefix, v.length - sharedPrefix);\n        lastTerm.copyBytes(v);\n        count++;\n      }\n      final long indexStartFP = data.getFilePointer();\n      // write addresses of indexed terms\n      termAddresses.finish();\n      addressBuffer.writeTo(data);\n      addressBuffer = null;\n      termAddresses = null;\n      meta.writeVInt(minLength);\n      meta.writeVInt(maxLength);\n      meta.writeVLong(count);\n      meta.writeLong(startFP);\n      meta.writeVInt(ADDRESS_INTERVAL);\n      meta.writeLong(indexStartFP);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      meta.writeVInt(BLOCK_SIZE);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e70ec9cf78e14cbbf13fd0e1a9aefa8081c325ff","date":1377034255,"type":1,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene45/Lucene45DocValuesConsumer#addTermsDict(FieldInfo,Iterable[BytesRef]).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/diskdv/DiskDocValuesConsumer#addTermsDict(FieldInfo,Iterable[BytesRef]).mjava","sourceNew":"  /** expert: writes a value dictionary for a sorted/sortedset field */\n  protected void addTermsDict(FieldInfo field, final Iterable<BytesRef> values) throws IOException {\n    // first check if its a \"fixed-length\" terms dict\n    int minLength = Integer.MAX_VALUE;\n    int maxLength = Integer.MIN_VALUE;\n    for (BytesRef v : values) {\n      minLength = Math.min(minLength, v.length);\n      maxLength = Math.max(maxLength, v.length);\n    }\n    if (minLength == maxLength) {\n      // no index needed: direct addressing by mult\n      addBinaryField(field, values);\n    } else {\n      // header\n      meta.writeVInt(field.number);\n      meta.writeByte(Lucene45DocValuesFormat.BINARY);\n      meta.writeVInt(BINARY_PREFIX_COMPRESSED);\n      meta.writeLong(-1L);\n      // now write the bytes: sharing prefixes within a block\n      final long startFP = data.getFilePointer();\n      // currently, we have to store the delta from expected for every 1/nth term\n      // we could avoid this, but its not much and less overall RAM than the previous approach!\n      RAMOutputStream addressBuffer = new RAMOutputStream();\n      MonotonicBlockPackedWriter termAddresses = new MonotonicBlockPackedWriter(addressBuffer, BLOCK_SIZE);\n      BytesRef lastTerm = new BytesRef();\n      long count = 0;\n      for (BytesRef v : values) {\n        if (count % ADDRESS_INTERVAL == 0) {\n          termAddresses.add(data.getFilePointer() - startFP);\n          // force the first term in a block to be abs-encoded\n          lastTerm.length = 0;\n        }\n        \n        // prefix-code\n        int sharedPrefix = StringHelper.bytesDifference(lastTerm, v);\n        data.writeVInt(sharedPrefix);\n        data.writeVInt(v.length - sharedPrefix);\n        data.writeBytes(v.bytes, v.offset + sharedPrefix, v.length - sharedPrefix);\n        lastTerm.copyBytes(v);\n        count++;\n      }\n      final long indexStartFP = data.getFilePointer();\n      // write addresses of indexed terms\n      termAddresses.finish();\n      addressBuffer.writeTo(data);\n      addressBuffer = null;\n      termAddresses = null;\n      meta.writeVInt(minLength);\n      meta.writeVInt(maxLength);\n      meta.writeVLong(count);\n      meta.writeLong(startFP);\n      meta.writeVInt(ADDRESS_INTERVAL);\n      meta.writeLong(indexStartFP);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      meta.writeVInt(BLOCK_SIZE);\n    }\n  }\n\n","sourceOld":"  protected void addTermsDict(FieldInfo field, final Iterable<BytesRef> values) throws IOException {\n    // first check if its a \"fixed-length\" terms dict\n    int minLength = Integer.MAX_VALUE;\n    int maxLength = Integer.MIN_VALUE;\n    for (BytesRef v : values) {\n      minLength = Math.min(minLength, v.length);\n      maxLength = Math.max(maxLength, v.length);\n    }\n    if (minLength == maxLength) {\n      // no index needed: direct addressing by mult\n      addBinaryField(field, values);\n    } else {\n      // header\n      meta.writeVInt(field.number);\n      meta.writeByte(DiskDocValuesFormat.BINARY);\n      meta.writeVInt(BINARY_PREFIX_COMPRESSED);\n      // now write the bytes: sharing prefixes within a block\n      final long startFP = data.getFilePointer();\n      // currently, we have to store the delta from expected for every 1/nth term\n      // we could avoid this, but its not much and less overall RAM than the previous approach!\n      RAMOutputStream addressBuffer = new RAMOutputStream();\n      MonotonicBlockPackedWriter termAddresses = new MonotonicBlockPackedWriter(addressBuffer, BLOCK_SIZE);\n      BytesRef lastTerm = new BytesRef();\n      long count = 0;\n      for (BytesRef v : values) {\n        if (count % ADDRESS_INTERVAL == 0) {\n          termAddresses.add(data.getFilePointer() - startFP);\n          // force the first term in a block to be abs-encoded\n          lastTerm.length = 0;\n        }\n        \n        // prefix-code\n        int sharedPrefix = StringHelper.bytesDifference(lastTerm, v);\n        data.writeVInt(sharedPrefix);\n        data.writeVInt(v.length - sharedPrefix);\n        data.writeBytes(v.bytes, v.offset + sharedPrefix, v.length - sharedPrefix);\n        lastTerm.copyBytes(v);\n        count++;\n      }\n      final long indexStartFP = data.getFilePointer();\n      // write addresses of indexed terms\n      termAddresses.finish();\n      addressBuffer.writeTo(data);\n      addressBuffer = null;\n      termAddresses = null;\n      meta.writeVInt(minLength);\n      meta.writeVInt(maxLength);\n      meta.writeVLong(count);\n      meta.writeLong(startFP);\n      meta.writeVInt(ADDRESS_INTERVAL);\n      meta.writeLong(indexStartFP);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      meta.writeVInt(BLOCK_SIZE);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3dffec77fb8f7d0e9ca4869dddd6af94528b4576","date":1377875202,"type":0,"author":"Han Jiang","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene45/Lucene45DocValuesConsumer#addTermsDict(FieldInfo,Iterable[BytesRef]).mjava","pathOld":"/dev/null","sourceNew":"  /** expert: writes a value dictionary for a sorted/sortedset field */\n  protected void addTermsDict(FieldInfo field, final Iterable<BytesRef> values) throws IOException {\n    // first check if its a \"fixed-length\" terms dict\n    int minLength = Integer.MAX_VALUE;\n    int maxLength = Integer.MIN_VALUE;\n    for (BytesRef v : values) {\n      minLength = Math.min(minLength, v.length);\n      maxLength = Math.max(maxLength, v.length);\n    }\n    if (minLength == maxLength) {\n      // no index needed: direct addressing by mult\n      addBinaryField(field, values);\n    } else {\n      // header\n      meta.writeVInt(field.number);\n      meta.writeByte(Lucene45DocValuesFormat.BINARY);\n      meta.writeVInt(BINARY_PREFIX_COMPRESSED);\n      meta.writeLong(-1L);\n      // now write the bytes: sharing prefixes within a block\n      final long startFP = data.getFilePointer();\n      // currently, we have to store the delta from expected for every 1/nth term\n      // we could avoid this, but its not much and less overall RAM than the previous approach!\n      RAMOutputStream addressBuffer = new RAMOutputStream();\n      MonotonicBlockPackedWriter termAddresses = new MonotonicBlockPackedWriter(addressBuffer, BLOCK_SIZE);\n      BytesRef lastTerm = new BytesRef();\n      long count = 0;\n      for (BytesRef v : values) {\n        if (count % ADDRESS_INTERVAL == 0) {\n          termAddresses.add(data.getFilePointer() - startFP);\n          // force the first term in a block to be abs-encoded\n          lastTerm.length = 0;\n        }\n        \n        // prefix-code\n        int sharedPrefix = StringHelper.bytesDifference(lastTerm, v);\n        data.writeVInt(sharedPrefix);\n        data.writeVInt(v.length - sharedPrefix);\n        data.writeBytes(v.bytes, v.offset + sharedPrefix, v.length - sharedPrefix);\n        lastTerm.copyBytes(v);\n        count++;\n      }\n      final long indexStartFP = data.getFilePointer();\n      // write addresses of indexed terms\n      termAddresses.finish();\n      addressBuffer.writeTo(data);\n      addressBuffer = null;\n      termAddresses = null;\n      meta.writeVInt(minLength);\n      meta.writeVInt(maxLength);\n      meta.writeVLong(count);\n      meta.writeLong(startFP);\n      meta.writeVInt(ADDRESS_INTERVAL);\n      meta.writeLong(indexStartFP);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      meta.writeVInt(BLOCK_SIZE);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50","date":1407854805,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene45/Lucene45DocValuesConsumer#addTermsDict(FieldInfo,Iterable[BytesRef]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene45/Lucene45DocValuesConsumer#addTermsDict(FieldInfo,Iterable[BytesRef]).mjava","sourceNew":"  /** expert: writes a value dictionary for a sorted/sortedset field */\n  protected void addTermsDict(FieldInfo field, final Iterable<BytesRef> values) throws IOException {\n    // first check if its a \"fixed-length\" terms dict\n    int minLength = Integer.MAX_VALUE;\n    int maxLength = Integer.MIN_VALUE;\n    for (BytesRef v : values) {\n      minLength = Math.min(minLength, v.length);\n      maxLength = Math.max(maxLength, v.length);\n    }\n    if (minLength == maxLength) {\n      // no index needed: direct addressing by mult\n      addBinaryField(field, values);\n    } else {\n      // header\n      meta.writeVInt(field.number);\n      meta.writeByte(Lucene45DocValuesFormat.BINARY);\n      meta.writeVInt(BINARY_PREFIX_COMPRESSED);\n      meta.writeLong(-1L);\n      // now write the bytes: sharing prefixes within a block\n      final long startFP = data.getFilePointer();\n      // currently, we have to store the delta from expected for every 1/nth term\n      // we could avoid this, but its not much and less overall RAM than the previous approach!\n      RAMOutputStream addressBuffer = new RAMOutputStream();\n      MonotonicBlockPackedWriter termAddresses = new MonotonicBlockPackedWriter(addressBuffer, BLOCK_SIZE);\n      BytesRefBuilder lastTerm = new BytesRefBuilder();\n      long count = 0;\n      for (BytesRef v : values) {\n        if (count % ADDRESS_INTERVAL == 0) {\n          termAddresses.add(data.getFilePointer() - startFP);\n          // force the first term in a block to be abs-encoded\n          lastTerm.clear();\n        }\n        \n        // prefix-code\n        int sharedPrefix = StringHelper.bytesDifference(lastTerm.get(), v);\n        data.writeVInt(sharedPrefix);\n        data.writeVInt(v.length - sharedPrefix);\n        data.writeBytes(v.bytes, v.offset + sharedPrefix, v.length - sharedPrefix);\n        lastTerm.copyBytes(v);\n        count++;\n      }\n      final long indexStartFP = data.getFilePointer();\n      // write addresses of indexed terms\n      termAddresses.finish();\n      addressBuffer.writeTo(data);\n      addressBuffer = null;\n      termAddresses = null;\n      meta.writeVInt(minLength);\n      meta.writeVInt(maxLength);\n      meta.writeVLong(count);\n      meta.writeLong(startFP);\n      meta.writeVInt(ADDRESS_INTERVAL);\n      meta.writeLong(indexStartFP);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      meta.writeVInt(BLOCK_SIZE);\n    }\n  }\n\n","sourceOld":"  /** expert: writes a value dictionary for a sorted/sortedset field */\n  protected void addTermsDict(FieldInfo field, final Iterable<BytesRef> values) throws IOException {\n    // first check if its a \"fixed-length\" terms dict\n    int minLength = Integer.MAX_VALUE;\n    int maxLength = Integer.MIN_VALUE;\n    for (BytesRef v : values) {\n      minLength = Math.min(minLength, v.length);\n      maxLength = Math.max(maxLength, v.length);\n    }\n    if (minLength == maxLength) {\n      // no index needed: direct addressing by mult\n      addBinaryField(field, values);\n    } else {\n      // header\n      meta.writeVInt(field.number);\n      meta.writeByte(Lucene45DocValuesFormat.BINARY);\n      meta.writeVInt(BINARY_PREFIX_COMPRESSED);\n      meta.writeLong(-1L);\n      // now write the bytes: sharing prefixes within a block\n      final long startFP = data.getFilePointer();\n      // currently, we have to store the delta from expected for every 1/nth term\n      // we could avoid this, but its not much and less overall RAM than the previous approach!\n      RAMOutputStream addressBuffer = new RAMOutputStream();\n      MonotonicBlockPackedWriter termAddresses = new MonotonicBlockPackedWriter(addressBuffer, BLOCK_SIZE);\n      BytesRef lastTerm = new BytesRef();\n      long count = 0;\n      for (BytesRef v : values) {\n        if (count % ADDRESS_INTERVAL == 0) {\n          termAddresses.add(data.getFilePointer() - startFP);\n          // force the first term in a block to be abs-encoded\n          lastTerm.length = 0;\n        }\n        \n        // prefix-code\n        int sharedPrefix = StringHelper.bytesDifference(lastTerm, v);\n        data.writeVInt(sharedPrefix);\n        data.writeVInt(v.length - sharedPrefix);\n        data.writeBytes(v.bytes, v.offset + sharedPrefix, v.length - sharedPrefix);\n        lastTerm.copyBytes(v);\n        count++;\n      }\n      final long indexStartFP = data.getFilePointer();\n      // write addresses of indexed terms\n      termAddresses.finish();\n      addressBuffer.writeTo(data);\n      addressBuffer = null;\n      termAddresses = null;\n      meta.writeVInt(minLength);\n      meta.writeVInt(maxLength);\n      meta.writeVLong(count);\n      meta.writeLong(startFP);\n      meta.writeVInt(ADDRESS_INTERVAL);\n      meta.writeLong(indexStartFP);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      meta.writeVInt(BLOCK_SIZE);\n    }\n  }\n\n","bugFix":["0ad01348544f9eb6ee985c300245013a75addfc6"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cc45c615dbb82bf79d5f9550286098367874fbf","date":1409571423,"type":5,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene45/Lucene45DocValuesConsumer#addTermsDict(FieldInfo,Iterable[BytesRef]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene45/Lucene45DocValuesConsumer#addTermsDict(FieldInfo,Iterable[BytesRef]).mjava","sourceNew":"  /** expert: writes a value dictionary for a sorted/sortedset field */\n  protected void addTermsDict(FieldInfo field, final Iterable<BytesRef> values) throws IOException {\n    // first check if its a \"fixed-length\" terms dict\n    int minLength = Integer.MAX_VALUE;\n    int maxLength = Integer.MIN_VALUE;\n    for (BytesRef v : values) {\n      minLength = Math.min(minLength, v.length);\n      maxLength = Math.max(maxLength, v.length);\n    }\n    if (minLength == maxLength) {\n      // no index needed: direct addressing by mult\n      addBinaryField(field, values);\n    } else {\n      // header\n      meta.writeVInt(field.number);\n      meta.writeByte(Lucene45DocValuesFormat.BINARY);\n      meta.writeVInt(BINARY_PREFIX_COMPRESSED);\n      meta.writeLong(-1L);\n      // now write the bytes: sharing prefixes within a block\n      final long startFP = data.getFilePointer();\n      // currently, we have to store the delta from expected for every 1/nth term\n      // we could avoid this, but its not much and less overall RAM than the previous approach!\n      RAMOutputStream addressBuffer = new RAMOutputStream();\n      MonotonicBlockPackedWriter termAddresses = new MonotonicBlockPackedWriter(addressBuffer, BLOCK_SIZE);\n      BytesRefBuilder lastTerm = new BytesRefBuilder();\n      long count = 0;\n      for (BytesRef v : values) {\n        if (count % ADDRESS_INTERVAL == 0) {\n          termAddresses.add(data.getFilePointer() - startFP);\n          // force the first term in a block to be abs-encoded\n          lastTerm.clear();\n        }\n        \n        // prefix-code\n        int sharedPrefix = StringHelper.bytesDifference(lastTerm.get(), v);\n        data.writeVInt(sharedPrefix);\n        data.writeVInt(v.length - sharedPrefix);\n        data.writeBytes(v.bytes, v.offset + sharedPrefix, v.length - sharedPrefix);\n        lastTerm.copyBytes(v);\n        count++;\n      }\n      final long indexStartFP = data.getFilePointer();\n      // write addresses of indexed terms\n      termAddresses.finish();\n      addressBuffer.writeTo(data);\n      addressBuffer = null;\n      termAddresses = null;\n      meta.writeVInt(minLength);\n      meta.writeVInt(maxLength);\n      meta.writeVLong(count);\n      meta.writeLong(startFP);\n      meta.writeVInt(ADDRESS_INTERVAL);\n      meta.writeLong(indexStartFP);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      meta.writeVInt(BLOCK_SIZE);\n    }\n  }\n\n","sourceOld":"  /** expert: writes a value dictionary for a sorted/sortedset field */\n  protected void addTermsDict(FieldInfo field, final Iterable<BytesRef> values) throws IOException {\n    // first check if its a \"fixed-length\" terms dict\n    int minLength = Integer.MAX_VALUE;\n    int maxLength = Integer.MIN_VALUE;\n    for (BytesRef v : values) {\n      minLength = Math.min(minLength, v.length);\n      maxLength = Math.max(maxLength, v.length);\n    }\n    if (minLength == maxLength) {\n      // no index needed: direct addressing by mult\n      addBinaryField(field, values);\n    } else {\n      // header\n      meta.writeVInt(field.number);\n      meta.writeByte(Lucene45DocValuesFormat.BINARY);\n      meta.writeVInt(BINARY_PREFIX_COMPRESSED);\n      meta.writeLong(-1L);\n      // now write the bytes: sharing prefixes within a block\n      final long startFP = data.getFilePointer();\n      // currently, we have to store the delta from expected for every 1/nth term\n      // we could avoid this, but its not much and less overall RAM than the previous approach!\n      RAMOutputStream addressBuffer = new RAMOutputStream();\n      MonotonicBlockPackedWriter termAddresses = new MonotonicBlockPackedWriter(addressBuffer, BLOCK_SIZE);\n      BytesRefBuilder lastTerm = new BytesRefBuilder();\n      long count = 0;\n      for (BytesRef v : values) {\n        if (count % ADDRESS_INTERVAL == 0) {\n          termAddresses.add(data.getFilePointer() - startFP);\n          // force the first term in a block to be abs-encoded\n          lastTerm.clear();\n        }\n        \n        // prefix-code\n        int sharedPrefix = StringHelper.bytesDifference(lastTerm.get(), v);\n        data.writeVInt(sharedPrefix);\n        data.writeVInt(v.length - sharedPrefix);\n        data.writeBytes(v.bytes, v.offset + sharedPrefix, v.length - sharedPrefix);\n        lastTerm.copyBytes(v);\n        count++;\n      }\n      final long indexStartFP = data.getFilePointer();\n      // write addresses of indexed terms\n      termAddresses.finish();\n      addressBuffer.writeTo(data);\n      addressBuffer = null;\n      termAddresses = null;\n      meta.writeVInt(minLength);\n      meta.writeVInt(maxLength);\n      meta.writeVLong(count);\n      meta.writeLong(startFP);\n      meta.writeVInt(ADDRESS_INTERVAL);\n      meta.writeLong(indexStartFP);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      meta.writeVInt(BLOCK_SIZE);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"402ad3ddc9da7b70da1b167667a60ece6a1381fb","date":1409656478,"type":5,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene45/Lucene45DocValuesConsumer#addTermsDict(FieldInfo,Iterable[BytesRef]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene45/Lucene45DocValuesConsumer#addTermsDict(FieldInfo,Iterable[BytesRef]).mjava","sourceNew":"  /** expert: writes a value dictionary for a sorted/sortedset field */\n  protected void addTermsDict(FieldInfo field, final Iterable<BytesRef> values) throws IOException {\n    // first check if its a \"fixed-length\" terms dict\n    int minLength = Integer.MAX_VALUE;\n    int maxLength = Integer.MIN_VALUE;\n    for (BytesRef v : values) {\n      minLength = Math.min(minLength, v.length);\n      maxLength = Math.max(maxLength, v.length);\n    }\n    if (minLength == maxLength) {\n      // no index needed: direct addressing by mult\n      addBinaryField(field, values);\n    } else {\n      // header\n      meta.writeVInt(field.number);\n      meta.writeByte(Lucene45DocValuesFormat.BINARY);\n      meta.writeVInt(BINARY_PREFIX_COMPRESSED);\n      meta.writeLong(-1L);\n      // now write the bytes: sharing prefixes within a block\n      final long startFP = data.getFilePointer();\n      // currently, we have to store the delta from expected for every 1/nth term\n      // we could avoid this, but its not much and less overall RAM than the previous approach!\n      RAMOutputStream addressBuffer = new RAMOutputStream();\n      MonotonicBlockPackedWriter termAddresses = new MonotonicBlockPackedWriter(addressBuffer, BLOCK_SIZE);\n      BytesRefBuilder lastTerm = new BytesRefBuilder();\n      long count = 0;\n      for (BytesRef v : values) {\n        if (count % ADDRESS_INTERVAL == 0) {\n          termAddresses.add(data.getFilePointer() - startFP);\n          // force the first term in a block to be abs-encoded\n          lastTerm.clear();\n        }\n        \n        // prefix-code\n        int sharedPrefix = StringHelper.bytesDifference(lastTerm.get(), v);\n        data.writeVInt(sharedPrefix);\n        data.writeVInt(v.length - sharedPrefix);\n        data.writeBytes(v.bytes, v.offset + sharedPrefix, v.length - sharedPrefix);\n        lastTerm.copyBytes(v);\n        count++;\n      }\n      final long indexStartFP = data.getFilePointer();\n      // write addresses of indexed terms\n      termAddresses.finish();\n      addressBuffer.writeTo(data);\n      addressBuffer = null;\n      termAddresses = null;\n      meta.writeVInt(minLength);\n      meta.writeVInt(maxLength);\n      meta.writeVLong(count);\n      meta.writeLong(startFP);\n      meta.writeVInt(ADDRESS_INTERVAL);\n      meta.writeLong(indexStartFP);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      meta.writeVInt(BLOCK_SIZE);\n    }\n  }\n\n","sourceOld":"  /** expert: writes a value dictionary for a sorted/sortedset field */\n  protected void addTermsDict(FieldInfo field, final Iterable<BytesRef> values) throws IOException {\n    // first check if its a \"fixed-length\" terms dict\n    int minLength = Integer.MAX_VALUE;\n    int maxLength = Integer.MIN_VALUE;\n    for (BytesRef v : values) {\n      minLength = Math.min(minLength, v.length);\n      maxLength = Math.max(maxLength, v.length);\n    }\n    if (minLength == maxLength) {\n      // no index needed: direct addressing by mult\n      addBinaryField(field, values);\n    } else {\n      // header\n      meta.writeVInt(field.number);\n      meta.writeByte(Lucene45DocValuesFormat.BINARY);\n      meta.writeVInt(BINARY_PREFIX_COMPRESSED);\n      meta.writeLong(-1L);\n      // now write the bytes: sharing prefixes within a block\n      final long startFP = data.getFilePointer();\n      // currently, we have to store the delta from expected for every 1/nth term\n      // we could avoid this, but its not much and less overall RAM than the previous approach!\n      RAMOutputStream addressBuffer = new RAMOutputStream();\n      MonotonicBlockPackedWriter termAddresses = new MonotonicBlockPackedWriter(addressBuffer, BLOCK_SIZE);\n      BytesRefBuilder lastTerm = new BytesRefBuilder();\n      long count = 0;\n      for (BytesRef v : values) {\n        if (count % ADDRESS_INTERVAL == 0) {\n          termAddresses.add(data.getFilePointer() - startFP);\n          // force the first term in a block to be abs-encoded\n          lastTerm.clear();\n        }\n        \n        // prefix-code\n        int sharedPrefix = StringHelper.bytesDifference(lastTerm.get(), v);\n        data.writeVInt(sharedPrefix);\n        data.writeVInt(v.length - sharedPrefix);\n        data.writeBytes(v.bytes, v.offset + sharedPrefix, v.length - sharedPrefix);\n        lastTerm.copyBytes(v);\n        count++;\n      }\n      final long indexStartFP = data.getFilePointer();\n      // write addresses of indexed terms\n      termAddresses.finish();\n      addressBuffer.writeTo(data);\n      addressBuffer = null;\n      termAddresses = null;\n      meta.writeVInt(minLength);\n      meta.writeVInt(maxLength);\n      meta.writeVLong(count);\n      meta.writeLong(startFP);\n      meta.writeVInt(ADDRESS_INTERVAL);\n      meta.writeLong(indexStartFP);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      meta.writeVInt(BLOCK_SIZE);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"11a746437bc5c0a0b3df0337ed249c387c812871":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"61558dab896ba60794837a7dd3b3be5b7940044d":["1a7bf5332d569e3d07c4b248462f5d212e26e9af"],"3dffec77fb8f7d0e9ca4869dddd6af94528b4576":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","e70ec9cf78e14cbbf13fd0e1a9aefa8081c325ff"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4cc45c615dbb82bf79d5f9550286098367874fbf":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"1a7bf5332d569e3d07c4b248462f5d212e26e9af":["11a746437bc5c0a0b3df0337ed249c387c812871"],"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50":["e70ec9cf78e14cbbf13fd0e1a9aefa8081c325ff"],"e70ec9cf78e14cbbf13fd0e1a9aefa8081c325ff":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","61558dab896ba60794837a7dd3b3be5b7940044d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["402ad3ddc9da7b70da1b167667a60ece6a1381fb"],"402ad3ddc9da7b70da1b167667a60ece6a1381fb":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50","4cc45c615dbb82bf79d5f9550286098367874fbf"]},"commit2Childs":{"11a746437bc5c0a0b3df0337ed249c387c812871":["1a7bf5332d569e3d07c4b248462f5d212e26e9af"],"61558dab896ba60794837a7dd3b3be5b7940044d":["e70ec9cf78e14cbbf13fd0e1a9aefa8081c325ff"],"3dffec77fb8f7d0e9ca4869dddd6af94528b4576":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["11a746437bc5c0a0b3df0337ed249c387c812871","3dffec77fb8f7d0e9ca4869dddd6af94528b4576","e70ec9cf78e14cbbf13fd0e1a9aefa8081c325ff"],"4cc45c615dbb82bf79d5f9550286098367874fbf":["402ad3ddc9da7b70da1b167667a60ece6a1381fb"],"1a7bf5332d569e3d07c4b248462f5d212e26e9af":["61558dab896ba60794837a7dd3b3be5b7940044d"],"e70ec9cf78e14cbbf13fd0e1a9aefa8081c325ff":["3dffec77fb8f7d0e9ca4869dddd6af94528b4576","7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50":["4cc45c615dbb82bf79d5f9550286098367874fbf","402ad3ddc9da7b70da1b167667a60ece6a1381fb"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"402ad3ddc9da7b70da1b167667a60ece6a1381fb":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["3dffec77fb8f7d0e9ca4869dddd6af94528b4576","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}