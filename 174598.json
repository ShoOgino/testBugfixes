{"path":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField#getCountsInArray(FacetFieldProcessorUIF,int[]).mjava","commits":[{"id":"4a7c13535572b8e97cc477fc3388a57321a7751a","date":1427500960,"type":0,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField#getCountsInArray(FacetFieldProcessorUIF,int[]).mjava","pathOld":"/dev/null","sourceNew":"  private void getCountsInArray(FacetFieldProcessorUIF processor, int[] counts) throws IOException {\n    DocSet docs = processor.fcontext.base;\n    int baseSize = docs.size();\n    int maxDoc = searcher.maxDoc();\n\n    if (baseSize < processor.effectiveMincount) {\n      return;\n    }\n\n    final int[] index = this.index;\n\n    boolean doNegative = baseSize > maxDoc >> 1 && termInstances > 0 && docs instanceof BitDocSet;\n\n    if (doNegative) {\n      FixedBitSet bs = ((BitDocSet) docs).getBits().clone();\n      bs.flip(0, maxDoc);\n      // TODO: when iterator across negative elements is available, use that\n      // instead of creating a new bitset and inverting.\n      docs = new BitDocSet(bs, maxDoc - baseSize);\n      // simply negating will mean that we have deleted docs in the set.\n      // that should be OK, as their entries in our table should be empty.\n    }\n\n    // For the biggest terms, do straight set intersections\n    for (TopTerm tt : bigTerms.values()) {\n      // TODO: counts could be deferred if sorting by index order\n      counts[tt.termNum] = searcher.numDocs(tt.termQuery, docs);\n    }\n\n    // TODO: we could short-circuit counting altogether for sorted faceting\n    // where we already have enough terms from the bigTerms\n\n    if (termInstances > 0) {\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n        int code = index[doc];\n\n        if ((code & 0xff) == 1) {\n          int pos = code >>> 8;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for (; ; ) {\n            int delta = 0;\n            for (; ; ) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            counts[tnum]++;\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (; ; ) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80) == 0) {\n              if (delta == 0) break;\n              tnum += delta - TNUM_OFFSET;\n              counts[tnum]++;\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n    if (doNegative) {\n      for (int i=0; i<numTermsInField; i++) {\n        counts[i] = maxTermCounts[i] - counts[i];\n      }\n    }\n\n    if (processor.allBucketsSlot >= 0) {\n      int all = 0;  // overflow potential\n      for (int i=0; i<numTermsInField; i++) {\n        all += counts[i];\n      }\n      counts[processor.allBucketsSlot] = all;\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":0,"author":"Ryan Ernst","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField#getCountsInArray(FacetFieldProcessorUIF,int[]).mjava","pathOld":"/dev/null","sourceNew":"  private void getCountsInArray(FacetFieldProcessorUIF processor, int[] counts) throws IOException {\n    DocSet docs = processor.fcontext.base;\n    int baseSize = docs.size();\n    int maxDoc = searcher.maxDoc();\n\n    if (baseSize < processor.effectiveMincount) {\n      return;\n    }\n\n    final int[] index = this.index;\n\n    boolean doNegative = baseSize > maxDoc >> 1 && termInstances > 0 && docs instanceof BitDocSet;\n\n    if (doNegative) {\n      FixedBitSet bs = ((BitDocSet) docs).getBits().clone();\n      bs.flip(0, maxDoc);\n      // TODO: when iterator across negative elements is available, use that\n      // instead of creating a new bitset and inverting.\n      docs = new BitDocSet(bs, maxDoc - baseSize);\n      // simply negating will mean that we have deleted docs in the set.\n      // that should be OK, as their entries in our table should be empty.\n    }\n\n    // For the biggest terms, do straight set intersections\n    for (TopTerm tt : bigTerms.values()) {\n      // TODO: counts could be deferred if sorting by index order\n      counts[tt.termNum] = searcher.numDocs(tt.termQuery, docs);\n    }\n\n    // TODO: we could short-circuit counting altogether for sorted faceting\n    // where we already have enough terms from the bigTerms\n\n    if (termInstances > 0) {\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n        int code = index[doc];\n\n        if ((code & 0xff) == 1) {\n          int pos = code >>> 8;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for (; ; ) {\n            int delta = 0;\n            for (; ; ) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            counts[tnum]++;\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (; ; ) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80) == 0) {\n              if (delta == 0) break;\n              tnum += delta - TNUM_OFFSET;\n              counts[tnum]++;\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n    if (doNegative) {\n      for (int i=0; i<numTermsInField; i++) {\n        counts[i] = maxTermCounts[i] - counts[i];\n      }\n    }\n\n    if (processor.allBucketsSlot >= 0) {\n      int all = 0;  // overflow potential\n      for (int i=0; i<numTermsInField; i++) {\n        all += counts[i];\n      }\n      counts[processor.allBucketsSlot] = all;\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"48a04370d92de1fba80afce42dd014d5a1e3aa52","date":1431204655,"type":5,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField#getCounts(FacetFieldProcessorUIF,CountSlotAcc).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField#getCountsInArray(FacetFieldProcessorUIF,int[]).mjava","sourceNew":"  private void getCounts(FacetFieldProcessorUIF processor, CountSlotAcc counts) throws IOException {\n    DocSet docs = processor.fcontext.base;\n    int baseSize = docs.size();\n    int maxDoc = searcher.maxDoc();\n\n    if (baseSize < processor.effectiveMincount) {\n      return;\n    }\n\n    final int[] index = this.index;\n\n    boolean doNegative = baseSize > maxDoc >> 1 && termInstances > 0 && docs instanceof BitDocSet;\n\n    if (doNegative) {\n      FixedBitSet bs = ((BitDocSet) docs).getBits().clone();\n      bs.flip(0, maxDoc);\n      // TODO: when iterator across negative elements is available, use that\n      // instead of creating a new bitset and inverting.\n      docs = new BitDocSet(bs, maxDoc - baseSize);\n      // simply negating will mean that we have deleted docs in the set.\n      // that should be OK, as their entries in our table should be empty.\n    }\n\n    // For the biggest terms, do straight set intersections\n    for (TopTerm tt : bigTerms.values()) {\n      // TODO: counts could be deferred if sorting by index order\n      counts.incrementCount(tt.termNum, searcher.numDocs(tt.termQuery, docs));\n    }\n\n    // TODO: we could short-circuit counting altogether for sorted faceting\n    // where we already have enough terms from the bigTerms\n\n    if (termInstances > 0) {\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n        int code = index[doc];\n\n        if ((code & 0xff) == 1) {\n          int pos = code >>> 8;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for (; ; ) {\n            int delta = 0;\n            for (; ; ) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            counts.incrementCount(tnum,1);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (; ; ) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80) == 0) {\n              if (delta == 0) break;\n              tnum += delta - TNUM_OFFSET;\n              counts.incrementCount(tnum,1);\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n    if (doNegative) {\n      for (int i=0; i<numTermsInField; i++) {\n //       counts[i] = maxTermCounts[i] - counts[i];\n        counts.incrementCount(i, maxTermCounts[i] - counts.getCount(i)*2);\n      }\n    }\n\n    if (processor.allBucketsSlot >= 0) {\n      int all = 0;  // overflow potential\n      for (int i=0; i<numTermsInField; i++) {\n        all += counts.getCount(i);\n      }\n      counts.incrementCount(processor.allBucketsSlot, all);\n    }\n  }\n\n","sourceOld":"  private void getCountsInArray(FacetFieldProcessorUIF processor, int[] counts) throws IOException {\n    DocSet docs = processor.fcontext.base;\n    int baseSize = docs.size();\n    int maxDoc = searcher.maxDoc();\n\n    if (baseSize < processor.effectiveMincount) {\n      return;\n    }\n\n    final int[] index = this.index;\n\n    boolean doNegative = baseSize > maxDoc >> 1 && termInstances > 0 && docs instanceof BitDocSet;\n\n    if (doNegative) {\n      FixedBitSet bs = ((BitDocSet) docs).getBits().clone();\n      bs.flip(0, maxDoc);\n      // TODO: when iterator across negative elements is available, use that\n      // instead of creating a new bitset and inverting.\n      docs = new BitDocSet(bs, maxDoc - baseSize);\n      // simply negating will mean that we have deleted docs in the set.\n      // that should be OK, as their entries in our table should be empty.\n    }\n\n    // For the biggest terms, do straight set intersections\n    for (TopTerm tt : bigTerms.values()) {\n      // TODO: counts could be deferred if sorting by index order\n      counts[tt.termNum] = searcher.numDocs(tt.termQuery, docs);\n    }\n\n    // TODO: we could short-circuit counting altogether for sorted faceting\n    // where we already have enough terms from the bigTerms\n\n    if (termInstances > 0) {\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n        int code = index[doc];\n\n        if ((code & 0xff) == 1) {\n          int pos = code >>> 8;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for (; ; ) {\n            int delta = 0;\n            for (; ; ) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            counts[tnum]++;\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (; ; ) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80) == 0) {\n              if (delta == 0) break;\n              tnum += delta - TNUM_OFFSET;\n              counts[tnum]++;\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n    if (doNegative) {\n      for (int i=0; i<numTermsInField; i++) {\n        counts[i] = maxTermCounts[i] - counts[i];\n      }\n    }\n\n    if (processor.allBucketsSlot >= 0) {\n      int all = 0;  // overflow potential\n      for (int i=0; i<numTermsInField; i++) {\n        all += counts[i];\n      }\n      counts[processor.allBucketsSlot] = all;\n    }\n  }\n\n","bugFix":null,"bugIntro":["1c841e27891873cab110ebeb89f124a8ec470176","1c841e27891873cab110ebeb89f124a8ec470176","1c841e27891873cab110ebeb89f124a8ec470176"],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","4a7c13535572b8e97cc477fc3388a57321a7751a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"48a04370d92de1fba80afce42dd014d5a1e3aa52":["4a7c13535572b8e97cc477fc3388a57321a7751a"],"4a7c13535572b8e97cc477fc3388a57321a7751a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["48a04370d92de1fba80afce42dd014d5a1e3aa52"]},"commit2Childs":{"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","4a7c13535572b8e97cc477fc3388a57321a7751a"],"48a04370d92de1fba80afce42dd014d5a1e3aa52":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"4a7c13535572b8e97cc477fc3388a57321a7751a":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","48a04370d92de1fba80afce42dd014d5a1e3aa52"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}