{"path":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesProducer#Lucene49DocValuesProducer(SegmentReadState,String,String,String,String).mjava","commits":[{"id":"4cc45c615dbb82bf79d5f9550286098367874fbf","date":1409571423,"type":1,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesProducer#Lucene49DocValuesProducer(SegmentReadState,String,String,String,String).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesProducer#Lucene49DocValuesProducer(SegmentReadState,String,String,String,String).mjava","sourceNew":"  /** expert: instantiates a new reader */\n  Lucene49DocValuesProducer(SegmentReadState state, String dataCodec, String dataExtension, String metaCodec, String metaExtension) throws IOException {\n    String metaName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, metaExtension);\n    // read in the entries from the metadata file.\n    ChecksumIndexInput in = state.directory.openChecksumInput(metaName, state.context);\n    this.maxDoc = state.segmentInfo.getDocCount();\n    boolean success = false;\n    try {\n      version = CodecUtil.checkHeader(in, metaCodec, \n                                      Lucene49DocValuesFormat.VERSION_START,\n                                      Lucene49DocValuesFormat.VERSION_CURRENT);\n      numerics = new HashMap<>();\n      ords = new HashMap<>();\n      ordIndexes = new HashMap<>();\n      binaries = new HashMap<>();\n      sortedSets = new HashMap<>();\n      sortedNumerics = new HashMap<>();\n      readFields(in, state.fieldInfos);\n\n      CodecUtil.checkFooter(in);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n    }\n\n    String dataName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, dataExtension);\n    this.data = state.directory.openInput(dataName, state.context);\n    success = false;\n    try {\n      final int version2 = CodecUtil.checkHeader(data, dataCodec, \n                                                 Lucene49DocValuesFormat.VERSION_START,\n                                                 Lucene49DocValuesFormat.VERSION_CURRENT);\n      if (version != version2) {\n        throw new CorruptIndexException(\"Format versions mismatch\");\n      }\n      \n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(data);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this.data);\n      }\n    }\n    \n    ramBytesUsed = new AtomicLong(RamUsageEstimator.shallowSizeOfInstance(getClass()));\n  }\n\n","sourceOld":"  /** expert: instantiates a new reader */\n  Lucene49DocValuesProducer(SegmentReadState state, String dataCodec, String dataExtension, String metaCodec, String metaExtension) throws IOException {\n    String metaName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, metaExtension);\n    // read in the entries from the metadata file.\n    ChecksumIndexInput in = state.directory.openChecksumInput(metaName, state.context);\n    this.maxDoc = state.segmentInfo.getDocCount();\n    boolean success = false;\n    try {\n      version = CodecUtil.checkHeader(in, metaCodec, \n                                      Lucene49DocValuesFormat.VERSION_START,\n                                      Lucene49DocValuesFormat.VERSION_CURRENT);\n      numerics = new HashMap<>();\n      ords = new HashMap<>();\n      ordIndexes = new HashMap<>();\n      binaries = new HashMap<>();\n      sortedSets = new HashMap<>();\n      sortedNumerics = new HashMap<>();\n      readFields(in, state.fieldInfos);\n\n      CodecUtil.checkFooter(in);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n    }\n\n    String dataName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, dataExtension);\n    this.data = state.directory.openInput(dataName, state.context);\n    success = false;\n    try {\n      final int version2 = CodecUtil.checkHeader(data, dataCodec, \n                                                 Lucene49DocValuesFormat.VERSION_START,\n                                                 Lucene49DocValuesFormat.VERSION_CURRENT);\n      if (version != version2) {\n        throw new CorruptIndexException(\"Format versions mismatch\");\n      }\n      \n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(data);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this.data);\n      }\n    }\n    \n    ramBytesUsed = new AtomicLong(RamUsageEstimator.shallowSizeOfInstance(getClass()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"402ad3ddc9da7b70da1b167667a60ece6a1381fb","date":1409656478,"type":1,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesProducer#Lucene49DocValuesProducer(SegmentReadState,String,String,String,String).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesProducer#Lucene49DocValuesProducer(SegmentReadState,String,String,String,String).mjava","sourceNew":"  /** expert: instantiates a new reader */\n  Lucene49DocValuesProducer(SegmentReadState state, String dataCodec, String dataExtension, String metaCodec, String metaExtension) throws IOException {\n    String metaName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, metaExtension);\n    // read in the entries from the metadata file.\n    ChecksumIndexInput in = state.directory.openChecksumInput(metaName, state.context);\n    this.maxDoc = state.segmentInfo.getDocCount();\n    boolean success = false;\n    try {\n      version = CodecUtil.checkHeader(in, metaCodec, \n                                      Lucene49DocValuesFormat.VERSION_START,\n                                      Lucene49DocValuesFormat.VERSION_CURRENT);\n      numerics = new HashMap<>();\n      ords = new HashMap<>();\n      ordIndexes = new HashMap<>();\n      binaries = new HashMap<>();\n      sortedSets = new HashMap<>();\n      sortedNumerics = new HashMap<>();\n      readFields(in, state.fieldInfos);\n\n      CodecUtil.checkFooter(in);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n    }\n\n    String dataName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, dataExtension);\n    this.data = state.directory.openInput(dataName, state.context);\n    success = false;\n    try {\n      final int version2 = CodecUtil.checkHeader(data, dataCodec, \n                                                 Lucene49DocValuesFormat.VERSION_START,\n                                                 Lucene49DocValuesFormat.VERSION_CURRENT);\n      if (version != version2) {\n        throw new CorruptIndexException(\"Format versions mismatch\");\n      }\n      \n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(data);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this.data);\n      }\n    }\n    \n    ramBytesUsed = new AtomicLong(RamUsageEstimator.shallowSizeOfInstance(getClass()));\n  }\n\n","sourceOld":"  /** expert: instantiates a new reader */\n  Lucene49DocValuesProducer(SegmentReadState state, String dataCodec, String dataExtension, String metaCodec, String metaExtension) throws IOException {\n    String metaName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, metaExtension);\n    // read in the entries from the metadata file.\n    ChecksumIndexInput in = state.directory.openChecksumInput(metaName, state.context);\n    this.maxDoc = state.segmentInfo.getDocCount();\n    boolean success = false;\n    try {\n      version = CodecUtil.checkHeader(in, metaCodec, \n                                      Lucene49DocValuesFormat.VERSION_START,\n                                      Lucene49DocValuesFormat.VERSION_CURRENT);\n      numerics = new HashMap<>();\n      ords = new HashMap<>();\n      ordIndexes = new HashMap<>();\n      binaries = new HashMap<>();\n      sortedSets = new HashMap<>();\n      sortedNumerics = new HashMap<>();\n      readFields(in, state.fieldInfos);\n\n      CodecUtil.checkFooter(in);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n    }\n\n    String dataName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, dataExtension);\n    this.data = state.directory.openInput(dataName, state.context);\n    success = false;\n    try {\n      final int version2 = CodecUtil.checkHeader(data, dataCodec, \n                                                 Lucene49DocValuesFormat.VERSION_START,\n                                                 Lucene49DocValuesFormat.VERSION_CURRENT);\n      if (version != version2) {\n        throw new CorruptIndexException(\"Format versions mismatch\");\n      }\n      \n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(data);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this.data);\n      }\n    }\n    \n    ramBytesUsed = new AtomicLong(RamUsageEstimator.shallowSizeOfInstance(getClass()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0936055c0eed56be3e4ae5c9db5b0e355390736a","date":1410874015,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesProducer#Lucene49DocValuesProducer(SegmentReadState,String,String,String,String).mjava","pathOld":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesProducer#Lucene49DocValuesProducer(SegmentReadState,String,String,String,String).mjava","sourceNew":"  /** expert: instantiates a new reader */\n  Lucene49DocValuesProducer(SegmentReadState state, String dataCodec, String dataExtension, String metaCodec, String metaExtension) throws IOException {\n    String metaName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, metaExtension);\n    // read in the entries from the metadata file.\n    ChecksumIndexInput in = state.directory.openChecksumInput(metaName, state.context);\n    this.maxDoc = state.segmentInfo.getDocCount();\n    boolean success = false;\n    try {\n      version = CodecUtil.checkHeader(in, metaCodec, \n                                      Lucene49DocValuesFormat.VERSION_START,\n                                      Lucene49DocValuesFormat.VERSION_CURRENT);\n      numerics = new HashMap<>();\n      ords = new HashMap<>();\n      ordIndexes = new HashMap<>();\n      binaries = new HashMap<>();\n      sortedSets = new HashMap<>();\n      sortedNumerics = new HashMap<>();\n      numFields = readFields(in, state.fieldInfos);\n\n      CodecUtil.checkFooter(in);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n    }\n\n    String dataName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, dataExtension);\n    this.data = state.directory.openInput(dataName, state.context);\n    success = false;\n    try {\n      final int version2 = CodecUtil.checkHeader(data, dataCodec, \n                                                 Lucene49DocValuesFormat.VERSION_START,\n                                                 Lucene49DocValuesFormat.VERSION_CURRENT);\n      if (version != version2) {\n        throw new CorruptIndexException(\"Format versions mismatch\");\n      }\n      \n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(data);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this.data);\n      }\n    }\n    \n    ramBytesUsed = new AtomicLong(RamUsageEstimator.shallowSizeOfInstance(getClass()));\n  }\n\n","sourceOld":"  /** expert: instantiates a new reader */\n  Lucene49DocValuesProducer(SegmentReadState state, String dataCodec, String dataExtension, String metaCodec, String metaExtension) throws IOException {\n    String metaName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, metaExtension);\n    // read in the entries from the metadata file.\n    ChecksumIndexInput in = state.directory.openChecksumInput(metaName, state.context);\n    this.maxDoc = state.segmentInfo.getDocCount();\n    boolean success = false;\n    try {\n      version = CodecUtil.checkHeader(in, metaCodec, \n                                      Lucene49DocValuesFormat.VERSION_START,\n                                      Lucene49DocValuesFormat.VERSION_CURRENT);\n      numerics = new HashMap<>();\n      ords = new HashMap<>();\n      ordIndexes = new HashMap<>();\n      binaries = new HashMap<>();\n      sortedSets = new HashMap<>();\n      sortedNumerics = new HashMap<>();\n      readFields(in, state.fieldInfos);\n\n      CodecUtil.checkFooter(in);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n    }\n\n    String dataName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, dataExtension);\n    this.data = state.directory.openInput(dataName, state.context);\n    success = false;\n    try {\n      final int version2 = CodecUtil.checkHeader(data, dataCodec, \n                                                 Lucene49DocValuesFormat.VERSION_START,\n                                                 Lucene49DocValuesFormat.VERSION_CURRENT);\n      if (version != version2) {\n        throw new CorruptIndexException(\"Format versions mismatch\");\n      }\n      \n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(data);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this.data);\n      }\n    }\n    \n    ramBytesUsed = new AtomicLong(RamUsageEstimator.shallowSizeOfInstance(getClass()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9a70ce9bddc6f985feb8e5e182aebe20872328d4","date":1411172748,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesProducer#Lucene49DocValuesProducer(SegmentReadState,String,String,String,String).mjava","pathOld":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesProducer#Lucene49DocValuesProducer(SegmentReadState,String,String,String,String).mjava","sourceNew":"  /** expert: instantiates a new reader */\n  Lucene49DocValuesProducer(SegmentReadState state, String dataCodec, String dataExtension, String metaCodec, String metaExtension) throws IOException {\n    String metaName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, metaExtension);\n    // read in the entries from the metadata file.\n    ChecksumIndexInput in = state.directory.openChecksumInput(metaName, state.context);\n    this.maxDoc = state.segmentInfo.getDocCount();\n    boolean success = false;\n    try {\n      version = CodecUtil.checkHeader(in, metaCodec, \n                                      Lucene49DocValuesFormat.VERSION_START,\n                                      Lucene49DocValuesFormat.VERSION_CURRENT);\n      numerics = new HashMap<>();\n      ords = new HashMap<>();\n      ordIndexes = new HashMap<>();\n      binaries = new HashMap<>();\n      sortedSets = new HashMap<>();\n      sortedNumerics = new HashMap<>();\n      numFields = readFields(in, state.fieldInfos);\n\n      CodecUtil.checkFooter(in);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n    }\n\n    String dataName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, dataExtension);\n    this.data = state.directory.openInput(dataName, state.context);\n    success = false;\n    try {\n      final int version2 = CodecUtil.checkHeader(data, dataCodec, \n                                                 Lucene49DocValuesFormat.VERSION_START,\n                                                 Lucene49DocValuesFormat.VERSION_CURRENT);\n      if (version != version2) {\n        throw new CorruptIndexException(\"Format versions mismatch: meta=\" + version + \", data=\" + version2, data);\n      }\n      \n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(data);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this.data);\n      }\n    }\n    \n    ramBytesUsed = new AtomicLong(RamUsageEstimator.shallowSizeOfInstance(getClass()));\n  }\n\n","sourceOld":"  /** expert: instantiates a new reader */\n  Lucene49DocValuesProducer(SegmentReadState state, String dataCodec, String dataExtension, String metaCodec, String metaExtension) throws IOException {\n    String metaName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, metaExtension);\n    // read in the entries from the metadata file.\n    ChecksumIndexInput in = state.directory.openChecksumInput(metaName, state.context);\n    this.maxDoc = state.segmentInfo.getDocCount();\n    boolean success = false;\n    try {\n      version = CodecUtil.checkHeader(in, metaCodec, \n                                      Lucene49DocValuesFormat.VERSION_START,\n                                      Lucene49DocValuesFormat.VERSION_CURRENT);\n      numerics = new HashMap<>();\n      ords = new HashMap<>();\n      ordIndexes = new HashMap<>();\n      binaries = new HashMap<>();\n      sortedSets = new HashMap<>();\n      sortedNumerics = new HashMap<>();\n      numFields = readFields(in, state.fieldInfos);\n\n      CodecUtil.checkFooter(in);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n    }\n\n    String dataName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, dataExtension);\n    this.data = state.directory.openInput(dataName, state.context);\n    success = false;\n    try {\n      final int version2 = CodecUtil.checkHeader(data, dataCodec, \n                                                 Lucene49DocValuesFormat.VERSION_START,\n                                                 Lucene49DocValuesFormat.VERSION_CURRENT);\n      if (version != version2) {\n        throw new CorruptIndexException(\"Format versions mismatch\");\n      }\n      \n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(data);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this.data);\n      }\n    }\n    \n    ramBytesUsed = new AtomicLong(RamUsageEstimator.shallowSizeOfInstance(getClass()));\n  }\n\n","bugFix":["8106bc60c7452250f84c65cdb43ab6b1d8eb1534"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bc8f80fee115148a0e4a0574560be06b494de821","date":1412069872,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesProducer#Lucene49DocValuesProducer(SegmentReadState,String,String,String,String).mjava","pathOld":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesProducer#Lucene49DocValuesProducer(SegmentReadState,String,String,String,String).mjava","sourceNew":"  /** expert: instantiates a new reader */\n  Lucene49DocValuesProducer(SegmentReadState state, String dataCodec, String dataExtension, String metaCodec, String metaExtension) throws IOException {\n    String metaName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, metaExtension);\n    // read in the entries from the metadata file.\n    ChecksumIndexInput in = state.directory.openChecksumInput(metaName, state.context);\n    this.maxDoc = state.segmentInfo.getDocCount();\n    merging = false;\n    boolean success = false;\n    try {\n      version = CodecUtil.checkHeader(in, metaCodec, \n                                      Lucene49DocValuesFormat.VERSION_START,\n                                      Lucene49DocValuesFormat.VERSION_CURRENT);\n      numerics = new HashMap<>();\n      ords = new HashMap<>();\n      ordIndexes = new HashMap<>();\n      binaries = new HashMap<>();\n      sortedSets = new HashMap<>();\n      sortedNumerics = new HashMap<>();\n      numFields = readFields(in, state.fieldInfos);\n\n      CodecUtil.checkFooter(in);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n    }\n\n    String dataName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, dataExtension);\n    this.data = state.directory.openInput(dataName, state.context);\n    success = false;\n    try {\n      final int version2 = CodecUtil.checkHeader(data, dataCodec, \n                                                 Lucene49DocValuesFormat.VERSION_START,\n                                                 Lucene49DocValuesFormat.VERSION_CURRENT);\n      if (version != version2) {\n        throw new CorruptIndexException(\"Format versions mismatch: meta=\" + version + \", data=\" + version2, data);\n      }\n      \n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(data);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this.data);\n      }\n    }\n    \n    ramBytesUsed = new AtomicLong(RamUsageEstimator.shallowSizeOfInstance(getClass()));\n  }\n\n","sourceOld":"  /** expert: instantiates a new reader */\n  Lucene49DocValuesProducer(SegmentReadState state, String dataCodec, String dataExtension, String metaCodec, String metaExtension) throws IOException {\n    String metaName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, metaExtension);\n    // read in the entries from the metadata file.\n    ChecksumIndexInput in = state.directory.openChecksumInput(metaName, state.context);\n    this.maxDoc = state.segmentInfo.getDocCount();\n    boolean success = false;\n    try {\n      version = CodecUtil.checkHeader(in, metaCodec, \n                                      Lucene49DocValuesFormat.VERSION_START,\n                                      Lucene49DocValuesFormat.VERSION_CURRENT);\n      numerics = new HashMap<>();\n      ords = new HashMap<>();\n      ordIndexes = new HashMap<>();\n      binaries = new HashMap<>();\n      sortedSets = new HashMap<>();\n      sortedNumerics = new HashMap<>();\n      numFields = readFields(in, state.fieldInfos);\n\n      CodecUtil.checkFooter(in);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n    }\n\n    String dataName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, dataExtension);\n    this.data = state.directory.openInput(dataName, state.context);\n    success = false;\n    try {\n      final int version2 = CodecUtil.checkHeader(data, dataCodec, \n                                                 Lucene49DocValuesFormat.VERSION_START,\n                                                 Lucene49DocValuesFormat.VERSION_CURRENT);\n      if (version != version2) {\n        throw new CorruptIndexException(\"Format versions mismatch: meta=\" + version + \", data=\" + version2, data);\n      }\n      \n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(data);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this.data);\n      }\n    }\n    \n    ramBytesUsed = new AtomicLong(RamUsageEstimator.shallowSizeOfInstance(getClass()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cc8131a9b74d0cc5fffc08abd266cd81e7a6746c","date":1412435885,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesProducer#Lucene49DocValuesProducer(SegmentReadState,String,String,String,String).mjava","pathOld":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesProducer#Lucene49DocValuesProducer(SegmentReadState,String,String,String,String).mjava","sourceNew":"  /** expert: instantiates a new reader */\n  Lucene49DocValuesProducer(SegmentReadState state, String dataCodec, String dataExtension, String metaCodec, String metaExtension) throws IOException {\n    String metaName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, metaExtension);\n    this.maxDoc = state.segmentInfo.getDocCount();\n    merging = false;\n    \n    int version = -1;\n    int numFields = -1;\n    \n    // read in the entries from the metadata file.\n    try (ChecksumIndexInput in = state.directory.openChecksumInput(metaName, state.context)) {\n      Throwable priorE = null;\n      try {\n        version = CodecUtil.checkHeader(in, metaCodec, \n                                            Lucene49DocValuesFormat.VERSION_START,\n                                            Lucene49DocValuesFormat.VERSION_CURRENT);\n        numFields = readFields(in, state.fieldInfos);\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(in, priorE);\n      }\n    }\n    this.numFields = numFields;\n\n    String dataName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, dataExtension);\n    this.data = state.directory.openInput(dataName, state.context);\n    boolean success = false;\n    try {\n      final int version2 = CodecUtil.checkHeader(data, dataCodec, \n                                                 Lucene49DocValuesFormat.VERSION_START,\n                                                 Lucene49DocValuesFormat.VERSION_CURRENT);\n      if (version != version2) {\n        throw new CorruptIndexException(\"Format versions mismatch: meta=\" + version + \", data=\" + version2, data);\n      }\n      \n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(data);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this.data);\n      }\n    }\n    \n    ramBytesUsed = new AtomicLong(RamUsageEstimator.shallowSizeOfInstance(getClass()));\n  }\n\n","sourceOld":"  /** expert: instantiates a new reader */\n  Lucene49DocValuesProducer(SegmentReadState state, String dataCodec, String dataExtension, String metaCodec, String metaExtension) throws IOException {\n    String metaName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, metaExtension);\n    // read in the entries from the metadata file.\n    ChecksumIndexInput in = state.directory.openChecksumInput(metaName, state.context);\n    this.maxDoc = state.segmentInfo.getDocCount();\n    merging = false;\n    boolean success = false;\n    try {\n      version = CodecUtil.checkHeader(in, metaCodec, \n                                      Lucene49DocValuesFormat.VERSION_START,\n                                      Lucene49DocValuesFormat.VERSION_CURRENT);\n      numerics = new HashMap<>();\n      ords = new HashMap<>();\n      ordIndexes = new HashMap<>();\n      binaries = new HashMap<>();\n      sortedSets = new HashMap<>();\n      sortedNumerics = new HashMap<>();\n      numFields = readFields(in, state.fieldInfos);\n\n      CodecUtil.checkFooter(in);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n    }\n\n    String dataName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, dataExtension);\n    this.data = state.directory.openInput(dataName, state.context);\n    success = false;\n    try {\n      final int version2 = CodecUtil.checkHeader(data, dataCodec, \n                                                 Lucene49DocValuesFormat.VERSION_START,\n                                                 Lucene49DocValuesFormat.VERSION_CURRENT);\n      if (version != version2) {\n        throw new CorruptIndexException(\"Format versions mismatch: meta=\" + version + \", data=\" + version2, data);\n      }\n      \n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(data);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this.data);\n      }\n    }\n    \n    ramBytesUsed = new AtomicLong(RamUsageEstimator.shallowSizeOfInstance(getClass()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9bb9a29a5e71a90295f175df8919802993142c9a","date":1412517673,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesProducer#Lucene49DocValuesProducer(SegmentReadState,String,String,String,String).mjava","pathOld":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesProducer#Lucene49DocValuesProducer(SegmentReadState,String,String,String,String).mjava","sourceNew":"  /** expert: instantiates a new reader */\n  Lucene49DocValuesProducer(SegmentReadState state, String dataCodec, String dataExtension, String metaCodec, String metaExtension) throws IOException {\n    String metaName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, metaExtension);\n    this.maxDoc = state.segmentInfo.getDocCount();\n    merging = false;\n    \n    int version = -1;\n    int numFields = -1;\n    \n    // read in the entries from the metadata file.\n    try (ChecksumIndexInput in = state.directory.openChecksumInput(metaName, state.context)) {\n      Throwable priorE = null;\n      try {\n        version = CodecUtil.checkHeader(in, metaCodec, \n                                            Lucene49DocValuesFormat.VERSION_START,\n                                            Lucene49DocValuesFormat.VERSION_CURRENT);\n        numFields = readFields(in, state.fieldInfos);\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(in, priorE);\n      }\n    }\n    this.numFields = numFields;\n\n    String dataName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, dataExtension);\n    this.data = state.directory.openInput(dataName, state.context);\n    boolean success = false;\n    try {\n      final int version2 = CodecUtil.checkHeader(data, dataCodec, \n                                                 Lucene49DocValuesFormat.VERSION_START,\n                                                 Lucene49DocValuesFormat.VERSION_CURRENT);\n      if (version != version2) {\n        throw new CorruptIndexException(\"Format versions mismatch: meta=\" + version + \", data=\" + version2, data);\n      }\n      \n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(data);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this.data);\n      }\n    }\n    \n    ramBytesUsed = new AtomicLong(RamUsageEstimator.shallowSizeOfInstance(getClass()));\n  }\n\n","sourceOld":"  /** expert: instantiates a new reader */\n  Lucene49DocValuesProducer(SegmentReadState state, String dataCodec, String dataExtension, String metaCodec, String metaExtension) throws IOException {\n    String metaName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, metaExtension);\n    // read in the entries from the metadata file.\n    ChecksumIndexInput in = state.directory.openChecksumInput(metaName, state.context);\n    this.maxDoc = state.segmentInfo.getDocCount();\n    boolean success = false;\n    try {\n      version = CodecUtil.checkHeader(in, metaCodec, \n                                      Lucene49DocValuesFormat.VERSION_START,\n                                      Lucene49DocValuesFormat.VERSION_CURRENT);\n      numerics = new HashMap<>();\n      ords = new HashMap<>();\n      ordIndexes = new HashMap<>();\n      binaries = new HashMap<>();\n      sortedSets = new HashMap<>();\n      sortedNumerics = new HashMap<>();\n      numFields = readFields(in, state.fieldInfos);\n\n      CodecUtil.checkFooter(in);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n    }\n\n    String dataName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, dataExtension);\n    this.data = state.directory.openInput(dataName, state.context);\n    success = false;\n    try {\n      final int version2 = CodecUtil.checkHeader(data, dataCodec, \n                                                 Lucene49DocValuesFormat.VERSION_START,\n                                                 Lucene49DocValuesFormat.VERSION_CURRENT);\n      if (version != version2) {\n        throw new CorruptIndexException(\"Format versions mismatch: meta=\" + version + \", data=\" + version2, data);\n      }\n      \n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(data);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this.data);\n      }\n    }\n    \n    ramBytesUsed = new AtomicLong(RamUsageEstimator.shallowSizeOfInstance(getClass()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"71387d8cb6923eb831b17a8b734608ba2e21c653","date":1414126093,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesProducer#Lucene49DocValuesProducer(SegmentReadState,String,String,String,String).mjava","sourceNew":null,"sourceOld":"  /** expert: instantiates a new reader */\n  Lucene49DocValuesProducer(SegmentReadState state, String dataCodec, String dataExtension, String metaCodec, String metaExtension) throws IOException {\n    String metaName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, metaExtension);\n    this.maxDoc = state.segmentInfo.getDocCount();\n    merging = false;\n    \n    int version = -1;\n    int numFields = -1;\n    \n    // read in the entries from the metadata file.\n    try (ChecksumIndexInput in = state.directory.openChecksumInput(metaName, state.context)) {\n      Throwable priorE = null;\n      try {\n        version = CodecUtil.checkHeader(in, metaCodec, \n                                            Lucene49DocValuesFormat.VERSION_START,\n                                            Lucene49DocValuesFormat.VERSION_CURRENT);\n        numFields = readFields(in, state.fieldInfos);\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(in, priorE);\n      }\n    }\n    this.numFields = numFields;\n\n    String dataName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, dataExtension);\n    this.data = state.directory.openInput(dataName, state.context);\n    boolean success = false;\n    try {\n      final int version2 = CodecUtil.checkHeader(data, dataCodec, \n                                                 Lucene49DocValuesFormat.VERSION_START,\n                                                 Lucene49DocValuesFormat.VERSION_CURRENT);\n      if (version != version2) {\n        throw new CorruptIndexException(\"Format versions mismatch: meta=\" + version + \", data=\" + version2, data);\n      }\n      \n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(data);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this.data);\n      }\n    }\n    \n    ramBytesUsed = new AtomicLong(RamUsageEstimator.shallowSizeOfInstance(getClass()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"9a70ce9bddc6f985feb8e5e182aebe20872328d4":["0936055c0eed56be3e4ae5c9db5b0e355390736a"],"bc8f80fee115148a0e4a0574560be06b494de821":["9a70ce9bddc6f985feb8e5e182aebe20872328d4"],"cc8131a9b74d0cc5fffc08abd266cd81e7a6746c":["bc8f80fee115148a0e4a0574560be06b494de821"],"9bb9a29a5e71a90295f175df8919802993142c9a":["9a70ce9bddc6f985feb8e5e182aebe20872328d4","cc8131a9b74d0cc5fffc08abd266cd81e7a6746c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4cc45c615dbb82bf79d5f9550286098367874fbf":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"0936055c0eed56be3e4ae5c9db5b0e355390736a":["402ad3ddc9da7b70da1b167667a60ece6a1381fb"],"71387d8cb6923eb831b17a8b734608ba2e21c653":["9bb9a29a5e71a90295f175df8919802993142c9a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["71387d8cb6923eb831b17a8b734608ba2e21c653"],"402ad3ddc9da7b70da1b167667a60ece6a1381fb":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","4cc45c615dbb82bf79d5f9550286098367874fbf"]},"commit2Childs":{"9a70ce9bddc6f985feb8e5e182aebe20872328d4":["bc8f80fee115148a0e4a0574560be06b494de821","9bb9a29a5e71a90295f175df8919802993142c9a"],"bc8f80fee115148a0e4a0574560be06b494de821":["cc8131a9b74d0cc5fffc08abd266cd81e7a6746c"],"cc8131a9b74d0cc5fffc08abd266cd81e7a6746c":["9bb9a29a5e71a90295f175df8919802993142c9a"],"9bb9a29a5e71a90295f175df8919802993142c9a":["71387d8cb6923eb831b17a8b734608ba2e21c653"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["4cc45c615dbb82bf79d5f9550286098367874fbf","402ad3ddc9da7b70da1b167667a60ece6a1381fb"],"4cc45c615dbb82bf79d5f9550286098367874fbf":["402ad3ddc9da7b70da1b167667a60ece6a1381fb"],"0936055c0eed56be3e4ae5c9db5b0e355390736a":["9a70ce9bddc6f985feb8e5e182aebe20872328d4"],"71387d8cb6923eb831b17a8b734608ba2e21c653":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"402ad3ddc9da7b70da1b167667a60ece6a1381fb":["0936055c0eed56be3e4ae5c9db5b0e355390736a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}