{"path":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#initDocValuesProducers(Codec).mjava","commits":[{"id":"ac14bdd59867c398bdb1a9cc50583bd3c93593e5","date":1382646404,"type":0,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#initDocValuesProducers(Codec).mjava","pathOld":"/dev/null","sourceNew":"  // initialize the per-field DocValuesProducer\n  private void initDocValuesProducers(Codec codec) throws IOException {\n    final Directory dir = core.cfsReader != null ? core.cfsReader : si.info.dir;\n    final DocValuesFormat dvFormat = codec.docValuesFormat();\n    final Map<Long,List<FieldInfo>> genInfos = getGenInfos();\n    \n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.initDocValuesProducers: segInfo=\" + si + \"; gens=\" + genInfos.keySet());\n    \n    for (Entry<Long,List<FieldInfo>> e : genInfos.entrySet()) {\n      Long gen = e.getKey();\n      List<FieldInfo> infos = e.getValue();\n      DocValuesProducer dvp = segDocValues.getDocValuesProducer(gen, si, IOContext.READ, dir, dvFormat, infos);\n      for (FieldInfo fi : infos) {\n        dvProducers.put(fi.name, dvp);\n      }\n    }\n    \n    dvGens.addAll(genInfos.keySet());\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["0567bdc5c86c94ced64201187cfcef2417d76dda","a5454fae2949cf13fdcc8a28cda5972a9e3d26d5"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1f3b037cd083286b2af89f96e768f85dcd8072d6","date":1396337805,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#initDocValuesProducers(Codec).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#initDocValuesProducers(Codec).mjava","sourceNew":"  // initialize the per-field DocValuesProducer\n  private void initDocValuesProducers(Codec codec) throws IOException {\n    final Directory dir = core.cfsReader != null ? core.cfsReader : si.info.dir;\n    final DocValuesFormat dvFormat = codec.docValuesFormat();\n    final Map<Long,List<FieldInfo>> genInfos = getGenInfos();\n    \n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.initDocValuesProducers: segInfo=\" + si + \"; gens=\" + genInfos.keySet());\n    \n    // TODO: can we avoid iterating over fieldinfos several times and creating maps of all this stuff if dv updates do not exist?\n    \n    for (Entry<Long,List<FieldInfo>> e : genInfos.entrySet()) {\n      Long gen = e.getKey();\n      List<FieldInfo> infos = e.getValue();\n      DocValuesProducer dvp = segDocValues.getDocValuesProducer(gen, si, IOContext.READ, dir, dvFormat, infos);\n      for (FieldInfo fi : infos) {\n        dvProducersByField.put(fi.name, dvp);\n        dvProducers.add(dvp);\n      }\n    }\n    \n    dvGens.addAll(genInfos.keySet());\n  }\n\n","sourceOld":"  // initialize the per-field DocValuesProducer\n  private void initDocValuesProducers(Codec codec) throws IOException {\n    final Directory dir = core.cfsReader != null ? core.cfsReader : si.info.dir;\n    final DocValuesFormat dvFormat = codec.docValuesFormat();\n    final Map<Long,List<FieldInfo>> genInfos = getGenInfos();\n    \n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.initDocValuesProducers: segInfo=\" + si + \"; gens=\" + genInfos.keySet());\n    \n    for (Entry<Long,List<FieldInfo>> e : genInfos.entrySet()) {\n      Long gen = e.getKey();\n      List<FieldInfo> infos = e.getValue();\n      DocValuesProducer dvp = segDocValues.getDocValuesProducer(gen, si, IOContext.READ, dir, dvFormat, infos);\n      for (FieldInfo fi : infos) {\n        dvProducers.put(fi.name, dvp);\n      }\n    }\n    \n    dvGens.addAll(genInfos.keySet());\n  }\n\n","bugFix":null,"bugIntro":["0567bdc5c86c94ced64201187cfcef2417d76dda"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5eb2511ababf862ea11e10761c70ee560cd84510","date":1396607225,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#initDocValuesProducers(Codec).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#initDocValuesProducers(Codec).mjava","sourceNew":"  // initialize the per-field DocValuesProducer\n  private void initDocValuesProducers(Codec codec) throws IOException {\n    final Directory dir = core.cfsReader != null ? core.cfsReader : si.info.dir;\n    final DocValuesFormat dvFormat = codec.docValuesFormat();\n    final Map<Long,List<FieldInfo>> genInfos = getGenInfos();\n    \n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.initDocValuesProducers: segInfo=\" + si + \"; gens=\" + genInfos.keySet());\n    \n    // TODO: can we avoid iterating over fieldinfos several times and creating maps of all this stuff if dv updates do not exist?\n    \n    for (Entry<Long,List<FieldInfo>> e : genInfos.entrySet()) {\n      Long gen = e.getKey();\n      List<FieldInfo> infos = e.getValue();\n      DocValuesProducer dvp = segDocValues.getDocValuesProducer(gen, si, IOContext.READ, dir, dvFormat, infos);\n      for (FieldInfo fi : infos) {\n        dvProducersByField.put(fi.name, dvp);\n        dvProducers.add(dvp);\n      }\n    }\n    \n    dvGens.addAll(genInfos.keySet());\n  }\n\n","sourceOld":"  // initialize the per-field DocValuesProducer\n  private void initDocValuesProducers(Codec codec) throws IOException {\n    final Directory dir = core.cfsReader != null ? core.cfsReader : si.info.dir;\n    final DocValuesFormat dvFormat = codec.docValuesFormat();\n    final Map<Long,List<FieldInfo>> genInfos = getGenInfos();\n    \n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.initDocValuesProducers: segInfo=\" + si + \"; gens=\" + genInfos.keySet());\n    \n    for (Entry<Long,List<FieldInfo>> e : genInfos.entrySet()) {\n      Long gen = e.getKey();\n      List<FieldInfo> infos = e.getValue();\n      DocValuesProducer dvp = segDocValues.getDocValuesProducer(gen, si, IOContext.READ, dir, dvFormat, infos);\n      for (FieldInfo fi : infos) {\n        dvProducers.put(fi.name, dvp);\n      }\n    }\n    \n    dvGens.addAll(genInfos.keySet());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c1d0b4a65bc57bd59cef05619306aa8ee7431a0f","date":1398696007,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#initDocValuesProducers(Codec).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#initDocValuesProducers(Codec).mjava","sourceNew":"  // initialize the per-field DocValuesProducer\n  private void initDocValuesProducers(Codec codec) throws IOException {\n    final Directory dir = core.cfsReader != null ? core.cfsReader : si.info.dir;\n    final DocValuesFormat dvFormat = codec.docValuesFormat();\n    final Map<Long,List<FieldInfo>> genInfos = getGenInfos();\n    \n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.initDocValuesProducers: segInfo=\" + si + \"; gens=\" + genInfos.keySet());\n    \n    // TODO: can we avoid iterating over fieldinfos several times and creating maps of all this stuff if dv updates do not exist?\n    \n    for (Entry<Long,List<FieldInfo>> e : genInfos.entrySet()) {\n      Long gen = e.getKey();\n      List<FieldInfo> infos = e.getValue();\n      DocValuesProducer dvp = segDocValues.getDocValuesProducer(gen, si, IOContext.READ, dir, dvFormat, infos);\n      for (FieldInfo fi : infos) {\n        dvProducersByField.put(fi.name, dvp);\n      }\n      dvProducers.add(dvp);\n    }\n    \n    dvGens.addAll(genInfos.keySet());\n  }\n\n","sourceOld":"  // initialize the per-field DocValuesProducer\n  private void initDocValuesProducers(Codec codec) throws IOException {\n    final Directory dir = core.cfsReader != null ? core.cfsReader : si.info.dir;\n    final DocValuesFormat dvFormat = codec.docValuesFormat();\n    final Map<Long,List<FieldInfo>> genInfos = getGenInfos();\n    \n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.initDocValuesProducers: segInfo=\" + si + \"; gens=\" + genInfos.keySet());\n    \n    // TODO: can we avoid iterating over fieldinfos several times and creating maps of all this stuff if dv updates do not exist?\n    \n    for (Entry<Long,List<FieldInfo>> e : genInfos.entrySet()) {\n      Long gen = e.getKey();\n      List<FieldInfo> infos = e.getValue();\n      DocValuesProducer dvp = segDocValues.getDocValuesProducer(gen, si, IOContext.READ, dir, dvFormat, infos);\n      for (FieldInfo fi : infos) {\n        dvProducersByField.put(fi.name, dvp);\n        dvProducers.add(dvp);\n      }\n    }\n    \n    dvGens.addAll(genInfos.keySet());\n  }\n\n","bugFix":null,"bugIntro":["0567bdc5c86c94ced64201187cfcef2417d76dda"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c0cd85fde84cb318b4dc97710dcf15e2959a1bbe","date":1398844771,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#initDocValuesProducers(Codec).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#initDocValuesProducers(Codec).mjava","sourceNew":"  // initialize the per-field DocValuesProducer\n  private void initDocValuesProducers(Codec codec) throws IOException {\n    final Directory dir = core.cfsReader != null ? core.cfsReader : si.info.dir;\n    final DocValuesFormat dvFormat = codec.docValuesFormat();\n    final Map<Long,List<FieldInfo>> genInfos = getGenInfos();\n    \n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.initDocValuesProducers: segInfo=\" + si + \"; gens=\" + genInfos.keySet());\n    \n    // TODO: can we avoid iterating over fieldinfos several times and creating maps of all this stuff if dv updates do not exist?\n    \n    for (Entry<Long,List<FieldInfo>> e : genInfos.entrySet()) {\n      Long gen = e.getKey();\n      List<FieldInfo> infos = e.getValue();\n      DocValuesProducer dvp = segDocValues.getDocValuesProducer(gen, si, IOContext.READ, dir, dvFormat, infos);\n      for (FieldInfo fi : infos) {\n        dvProducersByField.put(fi.name, dvp);\n      }\n      dvProducers.add(dvp);\n    }\n    \n    dvGens.addAll(genInfos.keySet());\n  }\n\n","sourceOld":"  // initialize the per-field DocValuesProducer\n  private void initDocValuesProducers(Codec codec) throws IOException {\n    final Directory dir = core.cfsReader != null ? core.cfsReader : si.info.dir;\n    final DocValuesFormat dvFormat = codec.docValuesFormat();\n    final Map<Long,List<FieldInfo>> genInfos = getGenInfos();\n    \n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.initDocValuesProducers: segInfo=\" + si + \"; gens=\" + genInfos.keySet());\n    \n    // TODO: can we avoid iterating over fieldinfos several times and creating maps of all this stuff if dv updates do not exist?\n    \n    for (Entry<Long,List<FieldInfo>> e : genInfos.entrySet()) {\n      Long gen = e.getKey();\n      List<FieldInfo> infos = e.getValue();\n      DocValuesProducer dvp = segDocValues.getDocValuesProducer(gen, si, IOContext.READ, dir, dvFormat, infos);\n      for (FieldInfo fi : infos) {\n        dvProducersByField.put(fi.name, dvp);\n        dvProducers.add(dvp);\n      }\n    }\n    \n    dvGens.addAll(genInfos.keySet());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a5454fae2949cf13fdcc8a28cda5972a9e3d26d5","date":1399547106,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#initDocValuesProducers(Codec).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#initDocValuesProducers(Codec).mjava","sourceNew":"  // initialize the per-field DocValuesProducer\n  private void initDocValuesProducers(Codec codec) throws IOException {\n    final Directory dir = core.cfsReader != null ? core.cfsReader : si.info.dir;\n    final DocValuesFormat dvFormat = codec.docValuesFormat();\n    final Map<Long,List<FieldInfo>> genInfos = getGenInfos();\n    \n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.initDocValuesProducers: segInfo=\" + si + \"; gens=\" + genInfos.keySet());\n    \n    // TODO: can we avoid iterating over fieldinfos several times and creating maps of all this stuff if dv updates do not exist?\n    \n    for (Entry<Long,List<FieldInfo>> e : genInfos.entrySet()) {\n      Long gen = e.getKey();\n      List<FieldInfo> infos = e.getValue();\n      DocValuesProducer dvp = segDocValues.getDocValuesProducer(gen, si, IOContext.READ, dir, dvFormat, infos);\n      dvGens.add(gen);\n      for (FieldInfo fi : infos) {\n        dvProducersByField.put(fi.name, dvp);\n      }\n      dvProducers.add(dvp);\n    }\n  }\n\n","sourceOld":"  // initialize the per-field DocValuesProducer\n  private void initDocValuesProducers(Codec codec) throws IOException {\n    final Directory dir = core.cfsReader != null ? core.cfsReader : si.info.dir;\n    final DocValuesFormat dvFormat = codec.docValuesFormat();\n    final Map<Long,List<FieldInfo>> genInfos = getGenInfos();\n    \n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.initDocValuesProducers: segInfo=\" + si + \"; gens=\" + genInfos.keySet());\n    \n    // TODO: can we avoid iterating over fieldinfos several times and creating maps of all this stuff if dv updates do not exist?\n    \n    for (Entry<Long,List<FieldInfo>> e : genInfos.entrySet()) {\n      Long gen = e.getKey();\n      List<FieldInfo> infos = e.getValue();\n      DocValuesProducer dvp = segDocValues.getDocValuesProducer(gen, si, IOContext.READ, dir, dvFormat, infos);\n      for (FieldInfo fi : infos) {\n        dvProducersByField.put(fi.name, dvp);\n      }\n      dvProducers.add(dvp);\n    }\n    \n    dvGens.addAll(genInfos.keySet());\n  }\n\n","bugFix":["ac14bdd59867c398bdb1a9cc50583bd3c93593e5"],"bugIntro":["0567bdc5c86c94ced64201187cfcef2417d76dda"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0567bdc5c86c94ced64201187cfcef2417d76dda","date":1400678298,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#initDocValuesProducers(Codec).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#initDocValuesProducers(Codec).mjava","sourceNew":"  // initialize the per-field DocValuesProducer\n  @SuppressWarnings(\"deprecation\")\n  private void initDocValuesProducers(Codec codec) throws IOException {\n    final Directory dir = core.cfsReader != null ? core.cfsReader : si.info.dir;\n    final DocValuesFormat dvFormat = codec.docValuesFormat();\n\n    if (!si.hasFieldUpdates()) {\n      // simple case, no DocValues updates\n      final DocValuesProducer dvp = segDocValues.getDocValuesProducer(-1L, si, IOContext.READ, dir, dvFormat, fieldInfos);\n      dvGens.add(-1L);\n      dvProducers.add(dvp);\n      for (FieldInfo fi : fieldInfos) {\n        if (!fi.hasDocValues()) continue;\n        assert fi.getDocValuesGen() == -1;\n        dvProducersByField.put(fi.name, dvp);\n      }\n      return;\n    }\n\n    Version ver;\n    try {\n      ver = Version.parseLeniently(si.info.getVersion());\n    } catch (IllegalArgumentException e) {\n      // happened in TestBackwardsCompatibility on a 4.0.0.2 index (no matching\n      // Version constant), anyway it's a pre-4.9 index.\n      ver = null;\n    }\n    if (ver != null && ver.onOrAfter(Version.LUCENE_4_9)) {\n      DocValuesProducer baseProducer = null;\n      for (FieldInfo fi : fieldInfos) {\n        if (!fi.hasDocValues()) continue;\n        long docValuesGen = fi.getDocValuesGen();\n        if (docValuesGen == -1) {\n          if (baseProducer == null) {\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.initDocValuesProducers: segInfo=\" + si + \"; gen=\" + docValuesGen + \"; field=\" + fi.name);\n            // the base producer gets all the fields, so the Codec can validate properly\n            baseProducer = segDocValues.getDocValuesProducer(docValuesGen, si, IOContext.READ, dir, dvFormat, fieldInfos);\n            dvGens.add(docValuesGen);\n            dvProducers.add(baseProducer);\n          }\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.initDocValuesProducers: segInfo=\" + si + \"; gen=\" + docValuesGen + \"; field=\" + fi.name);\n          dvProducersByField.put(fi.name, baseProducer);\n        } else {\n          assert !dvGens.contains(docValuesGen);\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.initDocValuesProducers: segInfo=\" + si + \"; gen=\" + docValuesGen + \"; field=\" + fi.name);\n          final DocValuesProducer dvp = segDocValues.getDocValuesProducer(docValuesGen, si, IOContext.READ, dir, dvFormat, new FieldInfos(new FieldInfo[] { fi }));\n          dvGens.add(docValuesGen);\n          dvProducers.add(dvp);\n          dvProducersByField.put(fi.name, dvp);\n        }\n      }\n    } else {\n      // For pre-4.9 indexes, especially with doc-values updates, multiple\n      // FieldInfos could belong to the same dvGen. Therefore need to make sure\n      // we initialize each DocValuesProducer once per gen.\n      Map<Long,List<FieldInfo>> genInfos = new HashMap<>();\n      for (FieldInfo fi : fieldInfos) {\n        if (!fi.hasDocValues()) continue;\n        List<FieldInfo> genFieldInfos = genInfos.get(fi.getDocValuesGen());\n        if (genFieldInfos == null) {\n          genFieldInfos = new ArrayList<>();\n          genInfos.put(fi.getDocValuesGen(), genFieldInfos);\n        }\n        genFieldInfos.add(fi);\n      }\n      \n      for (Map.Entry<Long,List<FieldInfo>> e : genInfos.entrySet()) {\n        long docValuesGen = e.getKey();\n        List<FieldInfo> infos = e.getValue();\n        final DocValuesProducer dvp;\n        if (docValuesGen == -1) {\n          // we need to send all FieldInfos to gen=-1, but later we need to\n          // record the DVP only for the \"true\" gen=-1 fields (not updated)\n          dvp = segDocValues.getDocValuesProducer(docValuesGen, si, IOContext.READ, dir, dvFormat, fieldInfos);\n        } else {\n          dvp = segDocValues.getDocValuesProducer(docValuesGen, si, IOContext.READ, dir, dvFormat, new FieldInfos(infos.toArray(new FieldInfo[infos.size()])));\n        }\n        dvGens.add(docValuesGen);\n        dvProducers.add(dvp);\n        for (FieldInfo fi : infos) {\n          dvProducersByField.put(fi.name, dvp);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  // initialize the per-field DocValuesProducer\n  private void initDocValuesProducers(Codec codec) throws IOException {\n    final Directory dir = core.cfsReader != null ? core.cfsReader : si.info.dir;\n    final DocValuesFormat dvFormat = codec.docValuesFormat();\n    final Map<Long,List<FieldInfo>> genInfos = getGenInfos();\n    \n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.initDocValuesProducers: segInfo=\" + si + \"; gens=\" + genInfos.keySet());\n    \n    // TODO: can we avoid iterating over fieldinfos several times and creating maps of all this stuff if dv updates do not exist?\n    \n    for (Entry<Long,List<FieldInfo>> e : genInfos.entrySet()) {\n      Long gen = e.getKey();\n      List<FieldInfo> infos = e.getValue();\n      DocValuesProducer dvp = segDocValues.getDocValuesProducer(gen, si, IOContext.READ, dir, dvFormat, infos);\n      dvGens.add(gen);\n      for (FieldInfo fi : infos) {\n        dvProducersByField.put(fi.name, dvp);\n      }\n      dvProducers.add(dvp);\n    }\n  }\n\n","bugFix":["c1d0b4a65bc57bd59cef05619306aa8ee7431a0f","1f3b037cd083286b2af89f96e768f85dcd8072d6","a5454fae2949cf13fdcc8a28cda5972a9e3d26d5","ac14bdd59867c398bdb1a9cc50583bd3c93593e5"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a656b32c3aa151037a8c52e9b134acc3cbf482bc","date":1400688195,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#initDocValuesProducers(Codec).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#initDocValuesProducers(Codec).mjava","sourceNew":"  // initialize the per-field DocValuesProducer\n  @SuppressWarnings(\"deprecation\")\n  private void initDocValuesProducers(Codec codec) throws IOException {\n    final Directory dir = core.cfsReader != null ? core.cfsReader : si.info.dir;\n    final DocValuesFormat dvFormat = codec.docValuesFormat();\n\n    if (!si.hasFieldUpdates()) {\n      // simple case, no DocValues updates\n      final DocValuesProducer dvp = segDocValues.getDocValuesProducer(-1L, si, IOContext.READ, dir, dvFormat, fieldInfos);\n      dvGens.add(-1L);\n      dvProducers.add(dvp);\n      for (FieldInfo fi : fieldInfos) {\n        if (!fi.hasDocValues()) continue;\n        assert fi.getDocValuesGen() == -1;\n        dvProducersByField.put(fi.name, dvp);\n      }\n      return;\n    }\n\n    Version ver;\n    try {\n      ver = Version.parseLeniently(si.info.getVersion());\n    } catch (IllegalArgumentException e) {\n      // happened in TestBackwardsCompatibility on a 4.0.0.2 index (no matching\n      // Version constant), anyway it's a pre-4.9 index.\n      ver = null;\n    }\n    if (ver != null && ver.onOrAfter(Version.LUCENE_4_9)) {\n      DocValuesProducer baseProducer = null;\n      for (FieldInfo fi : fieldInfos) {\n        if (!fi.hasDocValues()) continue;\n        long docValuesGen = fi.getDocValuesGen();\n        if (docValuesGen == -1) {\n          if (baseProducer == null) {\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.initDocValuesProducers: segInfo=\" + si + \"; gen=\" + docValuesGen + \"; field=\" + fi.name);\n            // the base producer gets all the fields, so the Codec can validate properly\n            baseProducer = segDocValues.getDocValuesProducer(docValuesGen, si, IOContext.READ, dir, dvFormat, fieldInfos);\n            dvGens.add(docValuesGen);\n            dvProducers.add(baseProducer);\n          }\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.initDocValuesProducers: segInfo=\" + si + \"; gen=\" + docValuesGen + \"; field=\" + fi.name);\n          dvProducersByField.put(fi.name, baseProducer);\n        } else {\n          assert !dvGens.contains(docValuesGen);\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.initDocValuesProducers: segInfo=\" + si + \"; gen=\" + docValuesGen + \"; field=\" + fi.name);\n          final DocValuesProducer dvp = segDocValues.getDocValuesProducer(docValuesGen, si, IOContext.READ, dir, dvFormat, new FieldInfos(new FieldInfo[] { fi }));\n          dvGens.add(docValuesGen);\n          dvProducers.add(dvp);\n          dvProducersByField.put(fi.name, dvp);\n        }\n      }\n    } else {\n      // For pre-4.9 indexes, especially with doc-values updates, multiple\n      // FieldInfos could belong to the same dvGen. Therefore need to make sure\n      // we initialize each DocValuesProducer once per gen.\n      Map<Long,List<FieldInfo>> genInfos = new HashMap<>();\n      for (FieldInfo fi : fieldInfos) {\n        if (!fi.hasDocValues()) continue;\n        List<FieldInfo> genFieldInfos = genInfos.get(fi.getDocValuesGen());\n        if (genFieldInfos == null) {\n          genFieldInfos = new ArrayList<>();\n          genInfos.put(fi.getDocValuesGen(), genFieldInfos);\n        }\n        genFieldInfos.add(fi);\n      }\n      \n      for (Map.Entry<Long,List<FieldInfo>> e : genInfos.entrySet()) {\n        long docValuesGen = e.getKey();\n        List<FieldInfo> infos = e.getValue();\n        final DocValuesProducer dvp;\n        if (docValuesGen == -1) {\n          // we need to send all FieldInfos to gen=-1, but later we need to\n          // record the DVP only for the \"true\" gen=-1 fields (not updated)\n          dvp = segDocValues.getDocValuesProducer(docValuesGen, si, IOContext.READ, dir, dvFormat, fieldInfos);\n        } else {\n          dvp = segDocValues.getDocValuesProducer(docValuesGen, si, IOContext.READ, dir, dvFormat, new FieldInfos(infos.toArray(new FieldInfo[infos.size()])));\n        }\n        dvGens.add(docValuesGen);\n        dvProducers.add(dvp);\n        for (FieldInfo fi : infos) {\n          dvProducersByField.put(fi.name, dvp);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  // initialize the per-field DocValuesProducer\n  private void initDocValuesProducers(Codec codec) throws IOException {\n    final Directory dir = core.cfsReader != null ? core.cfsReader : si.info.dir;\n    final DocValuesFormat dvFormat = codec.docValuesFormat();\n    final Map<Long,List<FieldInfo>> genInfos = getGenInfos();\n    \n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.initDocValuesProducers: segInfo=\" + si + \"; gens=\" + genInfos.keySet());\n    \n    // TODO: can we avoid iterating over fieldinfos several times and creating maps of all this stuff if dv updates do not exist?\n    \n    for (Entry<Long,List<FieldInfo>> e : genInfos.entrySet()) {\n      Long gen = e.getKey();\n      List<FieldInfo> infos = e.getValue();\n      DocValuesProducer dvp = segDocValues.getDocValuesProducer(gen, si, IOContext.READ, dir, dvFormat, infos);\n      dvGens.add(gen);\n      for (FieldInfo fi : infos) {\n        dvProducersByField.put(fi.name, dvp);\n      }\n      dvProducers.add(dvp);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7605579001505896d48b07160075a5c8b8e128e","date":1400758727,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#initDocValuesProducers(Codec).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#initDocValuesProducers(Codec).mjava","sourceNew":"  // initialize the per-field DocValuesProducer\n  @SuppressWarnings(\"deprecation\")\n  private void initDocValuesProducers(Codec codec) throws IOException {\n    final Directory dir = core.cfsReader != null ? core.cfsReader : si.info.dir;\n    final DocValuesFormat dvFormat = codec.docValuesFormat();\n\n    if (!si.hasFieldUpdates()) {\n      // simple case, no DocValues updates\n      final DocValuesProducer dvp = segDocValues.getDocValuesProducer(-1L, si, IOContext.READ, dir, dvFormat, fieldInfos);\n      dvGens.add(-1L);\n      dvProducers.add(dvp);\n      for (FieldInfo fi : fieldInfos) {\n        if (!fi.hasDocValues()) continue;\n        assert fi.getDocValuesGen() == -1;\n        dvProducersByField.put(fi.name, dvp);\n      }\n      return;\n    }\n\n    Version ver;\n    try {\n      ver = Version.parseLeniently(si.info.getVersion());\n    } catch (IllegalArgumentException e) {\n      // happened in TestBackwardsCompatibility on a 4.0.0.2 index (no matching\n      // Version constant), anyway it's a pre-4.9 index.\n      ver = null;\n    }\n    if (ver != null && ver.onOrAfter(Version.LUCENE_4_9)) {\n      DocValuesProducer baseProducer = null;\n      for (FieldInfo fi : fieldInfos) {\n        if (!fi.hasDocValues()) continue;\n        long docValuesGen = fi.getDocValuesGen();\n        if (docValuesGen == -1) {\n          if (baseProducer == null) {\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.initDocValuesProducers: segInfo=\" + si + \"; gen=\" + docValuesGen + \"; field=\" + fi.name);\n            // the base producer gets all the fields, so the Codec can validate properly\n            baseProducer = segDocValues.getDocValuesProducer(docValuesGen, si, IOContext.READ, dir, dvFormat, fieldInfos);\n            dvGens.add(docValuesGen);\n            dvProducers.add(baseProducer);\n          }\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.initDocValuesProducers: segInfo=\" + si + \"; gen=\" + docValuesGen + \"; field=\" + fi.name);\n          dvProducersByField.put(fi.name, baseProducer);\n        } else {\n          assert !dvGens.contains(docValuesGen);\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.initDocValuesProducers: segInfo=\" + si + \"; gen=\" + docValuesGen + \"; field=\" + fi.name);\n          final DocValuesProducer dvp = segDocValues.getDocValuesProducer(docValuesGen, si, IOContext.READ, dir, dvFormat, new FieldInfos(new FieldInfo[] { fi }));\n          dvGens.add(docValuesGen);\n          dvProducers.add(dvp);\n          dvProducersByField.put(fi.name, dvp);\n        }\n      }\n    } else {\n      // For pre-4.9 indexes, especially with doc-values updates, multiple\n      // FieldInfos could belong to the same dvGen. Therefore need to make sure\n      // we initialize each DocValuesProducer once per gen.\n      Map<Long,List<FieldInfo>> genInfos = new HashMap<>();\n      for (FieldInfo fi : fieldInfos) {\n        if (!fi.hasDocValues()) continue;\n        List<FieldInfo> genFieldInfos = genInfos.get(fi.getDocValuesGen());\n        if (genFieldInfos == null) {\n          genFieldInfos = new ArrayList<>();\n          genInfos.put(fi.getDocValuesGen(), genFieldInfos);\n        }\n        genFieldInfos.add(fi);\n      }\n      \n      for (Map.Entry<Long,List<FieldInfo>> e : genInfos.entrySet()) {\n        long docValuesGen = e.getKey();\n        List<FieldInfo> infos = e.getValue();\n        final DocValuesProducer dvp;\n        if (docValuesGen == -1) {\n          // we need to send all FieldInfos to gen=-1, but later we need to\n          // record the DVP only for the \"true\" gen=-1 fields (not updated)\n          dvp = segDocValues.getDocValuesProducer(docValuesGen, si, IOContext.READ, dir, dvFormat, fieldInfos);\n        } else {\n          dvp = segDocValues.getDocValuesProducer(docValuesGen, si, IOContext.READ, dir, dvFormat, new FieldInfos(infos.toArray(new FieldInfo[infos.size()])));\n        }\n        dvGens.add(docValuesGen);\n        dvProducers.add(dvp);\n        for (FieldInfo fi : infos) {\n          dvProducersByField.put(fi.name, dvp);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  // initialize the per-field DocValuesProducer\n  private void initDocValuesProducers(Codec codec) throws IOException {\n    final Directory dir = core.cfsReader != null ? core.cfsReader : si.info.dir;\n    final DocValuesFormat dvFormat = codec.docValuesFormat();\n    final Map<Long,List<FieldInfo>> genInfos = getGenInfos();\n    \n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.initDocValuesProducers: segInfo=\" + si + \"; gens=\" + genInfos.keySet());\n    \n    // TODO: can we avoid iterating over fieldinfos several times and creating maps of all this stuff if dv updates do not exist?\n    \n    for (Entry<Long,List<FieldInfo>> e : genInfos.entrySet()) {\n      Long gen = e.getKey();\n      List<FieldInfo> infos = e.getValue();\n      DocValuesProducer dvp = segDocValues.getDocValuesProducer(gen, si, IOContext.READ, dir, dvFormat, infos);\n      dvGens.add(gen);\n      for (FieldInfo fi : infos) {\n        dvProducersByField.put(fi.name, dvp);\n      }\n      dvProducers.add(dvp);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"70179a348a4367cb9fcf2d721a289651a8c125ac","date":1406551647,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#initDocValuesProducers(Codec).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#initDocValuesProducers(Codec).mjava","sourceNew":"  // initialize the per-field DocValuesProducer\n  @SuppressWarnings(\"deprecation\")\n  private void initDocValuesProducers(Codec codec) throws IOException {\n    final Directory dir = core.cfsReader != null ? core.cfsReader : si.info.dir;\n    final DocValuesFormat dvFormat = codec.docValuesFormat();\n\n    if (!si.hasFieldUpdates()) {\n      // simple case, no DocValues updates\n      final DocValuesProducer dvp = segDocValues.getDocValuesProducer(-1L, si, IOContext.READ, dir, dvFormat, fieldInfos);\n      dvGens.add(-1L);\n      dvProducers.add(dvp);\n      for (FieldInfo fi : fieldInfos) {\n        if (!fi.hasDocValues()) continue;\n        assert fi.getDocValuesGen() == -1;\n        dvProducersByField.put(fi.name, dvp);\n      }\n      return;\n    }\n\n    String ver = si.info.getVersion();\n    if (ver != null && StringHelper.getVersionComparator().compare(ver, \"4.9.0\") >= 0) {\n      DocValuesProducer baseProducer = null;\n      for (FieldInfo fi : fieldInfos) {\n        if (!fi.hasDocValues()) continue;\n        long docValuesGen = fi.getDocValuesGen();\n        if (docValuesGen == -1) {\n          if (baseProducer == null) {\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.initDocValuesProducers: segInfo=\" + si + \"; gen=\" + docValuesGen + \"; field=\" + fi.name);\n            // the base producer gets all the fields, so the Codec can validate properly\n            baseProducer = segDocValues.getDocValuesProducer(docValuesGen, si, IOContext.READ, dir, dvFormat, fieldInfos);\n            dvGens.add(docValuesGen);\n            dvProducers.add(baseProducer);\n          }\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.initDocValuesProducers: segInfo=\" + si + \"; gen=\" + docValuesGen + \"; field=\" + fi.name);\n          dvProducersByField.put(fi.name, baseProducer);\n        } else {\n          assert !dvGens.contains(docValuesGen);\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.initDocValuesProducers: segInfo=\" + si + \"; gen=\" + docValuesGen + \"; field=\" + fi.name);\n          final DocValuesProducer dvp = segDocValues.getDocValuesProducer(docValuesGen, si, IOContext.READ, dir, dvFormat, new FieldInfos(new FieldInfo[] { fi }));\n          dvGens.add(docValuesGen);\n          dvProducers.add(dvp);\n          dvProducersByField.put(fi.name, dvp);\n        }\n      }\n    } else {\n      // For pre-4.9 indexes, especially with doc-values updates, multiple\n      // FieldInfos could belong to the same dvGen. Therefore need to make sure\n      // we initialize each DocValuesProducer once per gen.\n      Map<Long,List<FieldInfo>> genInfos = new HashMap<>();\n      for (FieldInfo fi : fieldInfos) {\n        if (!fi.hasDocValues()) continue;\n        List<FieldInfo> genFieldInfos = genInfos.get(fi.getDocValuesGen());\n        if (genFieldInfos == null) {\n          genFieldInfos = new ArrayList<>();\n          genInfos.put(fi.getDocValuesGen(), genFieldInfos);\n        }\n        genFieldInfos.add(fi);\n      }\n      \n      for (Map.Entry<Long,List<FieldInfo>> e : genInfos.entrySet()) {\n        long docValuesGen = e.getKey();\n        List<FieldInfo> infos = e.getValue();\n        final DocValuesProducer dvp;\n        if (docValuesGen == -1) {\n          // we need to send all FieldInfos to gen=-1, but later we need to\n          // record the DVP only for the \"true\" gen=-1 fields (not updated)\n          dvp = segDocValues.getDocValuesProducer(docValuesGen, si, IOContext.READ, dir, dvFormat, fieldInfos);\n        } else {\n          dvp = segDocValues.getDocValuesProducer(docValuesGen, si, IOContext.READ, dir, dvFormat, new FieldInfos(infos.toArray(new FieldInfo[infos.size()])));\n        }\n        dvGens.add(docValuesGen);\n        dvProducers.add(dvp);\n        for (FieldInfo fi : infos) {\n          dvProducersByField.put(fi.name, dvp);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  // initialize the per-field DocValuesProducer\n  @SuppressWarnings(\"deprecation\")\n  private void initDocValuesProducers(Codec codec) throws IOException {\n    final Directory dir = core.cfsReader != null ? core.cfsReader : si.info.dir;\n    final DocValuesFormat dvFormat = codec.docValuesFormat();\n\n    if (!si.hasFieldUpdates()) {\n      // simple case, no DocValues updates\n      final DocValuesProducer dvp = segDocValues.getDocValuesProducer(-1L, si, IOContext.READ, dir, dvFormat, fieldInfos);\n      dvGens.add(-1L);\n      dvProducers.add(dvp);\n      for (FieldInfo fi : fieldInfos) {\n        if (!fi.hasDocValues()) continue;\n        assert fi.getDocValuesGen() == -1;\n        dvProducersByField.put(fi.name, dvp);\n      }\n      return;\n    }\n\n    Version ver;\n    try {\n      ver = Version.parseLeniently(si.info.getVersion());\n    } catch (IllegalArgumentException e) {\n      // happened in TestBackwardsCompatibility on a 4.0.0.2 index (no matching\n      // Version constant), anyway it's a pre-4.9 index.\n      ver = null;\n    }\n    if (ver != null && ver.onOrAfter(Version.LUCENE_4_9)) {\n      DocValuesProducer baseProducer = null;\n      for (FieldInfo fi : fieldInfos) {\n        if (!fi.hasDocValues()) continue;\n        long docValuesGen = fi.getDocValuesGen();\n        if (docValuesGen == -1) {\n          if (baseProducer == null) {\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.initDocValuesProducers: segInfo=\" + si + \"; gen=\" + docValuesGen + \"; field=\" + fi.name);\n            // the base producer gets all the fields, so the Codec can validate properly\n            baseProducer = segDocValues.getDocValuesProducer(docValuesGen, si, IOContext.READ, dir, dvFormat, fieldInfos);\n            dvGens.add(docValuesGen);\n            dvProducers.add(baseProducer);\n          }\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.initDocValuesProducers: segInfo=\" + si + \"; gen=\" + docValuesGen + \"; field=\" + fi.name);\n          dvProducersByField.put(fi.name, baseProducer);\n        } else {\n          assert !dvGens.contains(docValuesGen);\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.initDocValuesProducers: segInfo=\" + si + \"; gen=\" + docValuesGen + \"; field=\" + fi.name);\n          final DocValuesProducer dvp = segDocValues.getDocValuesProducer(docValuesGen, si, IOContext.READ, dir, dvFormat, new FieldInfos(new FieldInfo[] { fi }));\n          dvGens.add(docValuesGen);\n          dvProducers.add(dvp);\n          dvProducersByField.put(fi.name, dvp);\n        }\n      }\n    } else {\n      // For pre-4.9 indexes, especially with doc-values updates, multiple\n      // FieldInfos could belong to the same dvGen. Therefore need to make sure\n      // we initialize each DocValuesProducer once per gen.\n      Map<Long,List<FieldInfo>> genInfos = new HashMap<>();\n      for (FieldInfo fi : fieldInfos) {\n        if (!fi.hasDocValues()) continue;\n        List<FieldInfo> genFieldInfos = genInfos.get(fi.getDocValuesGen());\n        if (genFieldInfos == null) {\n          genFieldInfos = new ArrayList<>();\n          genInfos.put(fi.getDocValuesGen(), genFieldInfos);\n        }\n        genFieldInfos.add(fi);\n      }\n      \n      for (Map.Entry<Long,List<FieldInfo>> e : genInfos.entrySet()) {\n        long docValuesGen = e.getKey();\n        List<FieldInfo> infos = e.getValue();\n        final DocValuesProducer dvp;\n        if (docValuesGen == -1) {\n          // we need to send all FieldInfos to gen=-1, but later we need to\n          // record the DVP only for the \"true\" gen=-1 fields (not updated)\n          dvp = segDocValues.getDocValuesProducer(docValuesGen, si, IOContext.READ, dir, dvFormat, fieldInfos);\n        } else {\n          dvp = segDocValues.getDocValuesProducer(docValuesGen, si, IOContext.READ, dir, dvFormat, new FieldInfos(infos.toArray(new FieldInfo[infos.size()])));\n        }\n        dvGens.add(docValuesGen);\n        dvProducers.add(dvp);\n        for (FieldInfo fi : infos) {\n          dvProducersByField.put(fi.name, dvp);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"057a1793765d068ea9302f1a29e21734ee58d41e","date":1408130117,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#initDocValuesProducers(Codec).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#initDocValuesProducers(Codec).mjava","sourceNew":"  // initialize the per-field DocValuesProducer\n  @SuppressWarnings(\"deprecation\")\n  private void initDocValuesProducers(Codec codec) throws IOException {\n    final Directory dir = core.cfsReader != null ? core.cfsReader : si.info.dir;\n    final DocValuesFormat dvFormat = codec.docValuesFormat();\n\n    if (!si.hasFieldUpdates()) {\n      // simple case, no DocValues updates\n      final DocValuesProducer dvp = segDocValues.getDocValuesProducer(-1L, si, IOContext.READ, dir, dvFormat, fieldInfos);\n      dvGens.add(-1L);\n      dvProducers.add(dvp);\n      for (FieldInfo fi : fieldInfos) {\n        if (!fi.hasDocValues()) continue;\n        assert fi.getDocValuesGen() == -1;\n        dvProducersByField.put(fi.name, dvp);\n      }\n      return;\n    }\n\n    Version ver = si.info.getVersion();\n    if (ver != null && ver.onOrAfter(Version.LUCENE_4_9_0)) {\n      DocValuesProducer baseProducer = null;\n      for (FieldInfo fi : fieldInfos) {\n        if (!fi.hasDocValues()) continue;\n        long docValuesGen = fi.getDocValuesGen();\n        if (docValuesGen == -1) {\n          if (baseProducer == null) {\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.initDocValuesProducers: segInfo=\" + si + \"; gen=\" + docValuesGen + \"; field=\" + fi.name);\n            // the base producer gets all the fields, so the Codec can validate properly\n            baseProducer = segDocValues.getDocValuesProducer(docValuesGen, si, IOContext.READ, dir, dvFormat, fieldInfos);\n            dvGens.add(docValuesGen);\n            dvProducers.add(baseProducer);\n          }\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.initDocValuesProducers: segInfo=\" + si + \"; gen=\" + docValuesGen + \"; field=\" + fi.name);\n          dvProducersByField.put(fi.name, baseProducer);\n        } else {\n          assert !dvGens.contains(docValuesGen);\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.initDocValuesProducers: segInfo=\" + si + \"; gen=\" + docValuesGen + \"; field=\" + fi.name);\n          final DocValuesProducer dvp = segDocValues.getDocValuesProducer(docValuesGen, si, IOContext.READ, dir, dvFormat, new FieldInfos(new FieldInfo[] { fi }));\n          dvGens.add(docValuesGen);\n          dvProducers.add(dvp);\n          dvProducersByField.put(fi.name, dvp);\n        }\n      }\n    } else {\n      // For pre-4.9 indexes, especially with doc-values updates, multiple\n      // FieldInfos could belong to the same dvGen. Therefore need to make sure\n      // we initialize each DocValuesProducer once per gen.\n      Map<Long,List<FieldInfo>> genInfos = new HashMap<>();\n      for (FieldInfo fi : fieldInfos) {\n        if (!fi.hasDocValues()) continue;\n        List<FieldInfo> genFieldInfos = genInfos.get(fi.getDocValuesGen());\n        if (genFieldInfos == null) {\n          genFieldInfos = new ArrayList<>();\n          genInfos.put(fi.getDocValuesGen(), genFieldInfos);\n        }\n        genFieldInfos.add(fi);\n      }\n      \n      for (Map.Entry<Long,List<FieldInfo>> e : genInfos.entrySet()) {\n        long docValuesGen = e.getKey();\n        List<FieldInfo> infos = e.getValue();\n        final DocValuesProducer dvp;\n        if (docValuesGen == -1) {\n          // we need to send all FieldInfos to gen=-1, but later we need to\n          // record the DVP only for the \"true\" gen=-1 fields (not updated)\n          dvp = segDocValues.getDocValuesProducer(docValuesGen, si, IOContext.READ, dir, dvFormat, fieldInfos);\n        } else {\n          dvp = segDocValues.getDocValuesProducer(docValuesGen, si, IOContext.READ, dir, dvFormat, new FieldInfos(infos.toArray(new FieldInfo[infos.size()])));\n        }\n        dvGens.add(docValuesGen);\n        dvProducers.add(dvp);\n        for (FieldInfo fi : infos) {\n          dvProducersByField.put(fi.name, dvp);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  // initialize the per-field DocValuesProducer\n  @SuppressWarnings(\"deprecation\")\n  private void initDocValuesProducers(Codec codec) throws IOException {\n    final Directory dir = core.cfsReader != null ? core.cfsReader : si.info.dir;\n    final DocValuesFormat dvFormat = codec.docValuesFormat();\n\n    if (!si.hasFieldUpdates()) {\n      // simple case, no DocValues updates\n      final DocValuesProducer dvp = segDocValues.getDocValuesProducer(-1L, si, IOContext.READ, dir, dvFormat, fieldInfos);\n      dvGens.add(-1L);\n      dvProducers.add(dvp);\n      for (FieldInfo fi : fieldInfos) {\n        if (!fi.hasDocValues()) continue;\n        assert fi.getDocValuesGen() == -1;\n        dvProducersByField.put(fi.name, dvp);\n      }\n      return;\n    }\n\n    String ver = si.info.getVersion();\n    if (ver != null && StringHelper.getVersionComparator().compare(ver, \"4.9.0\") >= 0) {\n      DocValuesProducer baseProducer = null;\n      for (FieldInfo fi : fieldInfos) {\n        if (!fi.hasDocValues()) continue;\n        long docValuesGen = fi.getDocValuesGen();\n        if (docValuesGen == -1) {\n          if (baseProducer == null) {\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.initDocValuesProducers: segInfo=\" + si + \"; gen=\" + docValuesGen + \"; field=\" + fi.name);\n            // the base producer gets all the fields, so the Codec can validate properly\n            baseProducer = segDocValues.getDocValuesProducer(docValuesGen, si, IOContext.READ, dir, dvFormat, fieldInfos);\n            dvGens.add(docValuesGen);\n            dvProducers.add(baseProducer);\n          }\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.initDocValuesProducers: segInfo=\" + si + \"; gen=\" + docValuesGen + \"; field=\" + fi.name);\n          dvProducersByField.put(fi.name, baseProducer);\n        } else {\n          assert !dvGens.contains(docValuesGen);\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.initDocValuesProducers: segInfo=\" + si + \"; gen=\" + docValuesGen + \"; field=\" + fi.name);\n          final DocValuesProducer dvp = segDocValues.getDocValuesProducer(docValuesGen, si, IOContext.READ, dir, dvFormat, new FieldInfos(new FieldInfo[] { fi }));\n          dvGens.add(docValuesGen);\n          dvProducers.add(dvp);\n          dvProducersByField.put(fi.name, dvp);\n        }\n      }\n    } else {\n      // For pre-4.9 indexes, especially with doc-values updates, multiple\n      // FieldInfos could belong to the same dvGen. Therefore need to make sure\n      // we initialize each DocValuesProducer once per gen.\n      Map<Long,List<FieldInfo>> genInfos = new HashMap<>();\n      for (FieldInfo fi : fieldInfos) {\n        if (!fi.hasDocValues()) continue;\n        List<FieldInfo> genFieldInfos = genInfos.get(fi.getDocValuesGen());\n        if (genFieldInfos == null) {\n          genFieldInfos = new ArrayList<>();\n          genInfos.put(fi.getDocValuesGen(), genFieldInfos);\n        }\n        genFieldInfos.add(fi);\n      }\n      \n      for (Map.Entry<Long,List<FieldInfo>> e : genInfos.entrySet()) {\n        long docValuesGen = e.getKey();\n        List<FieldInfo> infos = e.getValue();\n        final DocValuesProducer dvp;\n        if (docValuesGen == -1) {\n          // we need to send all FieldInfos to gen=-1, but later we need to\n          // record the DVP only for the \"true\" gen=-1 fields (not updated)\n          dvp = segDocValues.getDocValuesProducer(docValuesGen, si, IOContext.READ, dir, dvFormat, fieldInfos);\n        } else {\n          dvp = segDocValues.getDocValuesProducer(docValuesGen, si, IOContext.READ, dir, dvFormat, new FieldInfos(infos.toArray(new FieldInfo[infos.size()])));\n        }\n        dvGens.add(docValuesGen);\n        dvProducers.add(dvp);\n        for (FieldInfo fi : infos) {\n          dvProducersByField.put(fi.name, dvp);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"22a2e66dfda83847e80095b8693c660742ab3e9c","date":1408628796,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentDocValuesProducer#SegmentDocValuesProducer(SegmentCommitInfo,Directory,FieldInfos,SegmentDocValues,DocValuesFormat).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#initDocValuesProducers(Codec).mjava","sourceNew":"  SegmentDocValuesProducer(SegmentCommitInfo si, Directory dir, FieldInfos fieldInfos, SegmentDocValues segDocValues, DocValuesFormat dvFormat) throws IOException {\n    Version ver = si.info.getVersion();\n    if (ver != null && ver.onOrAfter(Version.LUCENE_4_9_0)) {\n      DocValuesProducer baseProducer = null;\n      for (FieldInfo fi : fieldInfos) {\n        if (!fi.hasDocValues()) continue;\n        long docValuesGen = fi.getDocValuesGen();\n        if (docValuesGen == -1) {\n          if (baseProducer == null) {\n            // the base producer gets all the fields, so the Codec can validate properly\n            baseProducer = segDocValues.getDocValuesProducer(docValuesGen, si, IOContext.READ, dir, dvFormat, fieldInfos);\n            dvGens.add(docValuesGen);\n            dvProducers.add(baseProducer);\n          }\n          dvProducersByField.put(fi.name, baseProducer);\n        } else {\n          assert !dvGens.contains(docValuesGen);\n          final DocValuesProducer dvp = segDocValues.getDocValuesProducer(docValuesGen, si, IOContext.READ, dir, dvFormat, new FieldInfos(new FieldInfo[] { fi }));\n          dvGens.add(docValuesGen);\n          dvProducers.add(dvp);\n          dvProducersByField.put(fi.name, dvp);\n        }\n      }\n    } else {\n      // For pre-4.9 indexes, especially with doc-values updates, multiple\n      // FieldInfos could belong to the same dvGen. Therefore need to make sure\n      // we initialize each DocValuesProducer once per gen.\n      Map<Long,List<FieldInfo>> genInfos = new HashMap<>();\n      for (FieldInfo fi : fieldInfos) {\n        if (!fi.hasDocValues()) continue;\n        List<FieldInfo> genFieldInfos = genInfos.get(fi.getDocValuesGen());\n        if (genFieldInfos == null) {\n          genFieldInfos = new ArrayList<>();\n          genInfos.put(fi.getDocValuesGen(), genFieldInfos);\n        }\n        genFieldInfos.add(fi);\n      }\n      \n      for (Map.Entry<Long,List<FieldInfo>> e : genInfos.entrySet()) {\n        long docValuesGen = e.getKey();\n        List<FieldInfo> infos = e.getValue();\n        final DocValuesProducer dvp;\n        if (docValuesGen == -1) {\n          // we need to send all FieldInfos to gen=-1, but later we need to\n          // record the DVP only for the \"true\" gen=-1 fields (not updated)\n          dvp = segDocValues.getDocValuesProducer(docValuesGen, si, IOContext.READ, dir, dvFormat, fieldInfos);\n        } else {\n          dvp = segDocValues.getDocValuesProducer(docValuesGen, si, IOContext.READ, dir, dvFormat, new FieldInfos(infos.toArray(new FieldInfo[infos.size()])));\n        }\n        dvGens.add(docValuesGen);\n        dvProducers.add(dvp);\n        for (FieldInfo fi : infos) {\n          dvProducersByField.put(fi.name, dvp);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  // initialize the per-field DocValuesProducer\n  @SuppressWarnings(\"deprecation\")\n  private void initDocValuesProducers(Codec codec) throws IOException {\n    final Directory dir = core.cfsReader != null ? core.cfsReader : si.info.dir;\n    final DocValuesFormat dvFormat = codec.docValuesFormat();\n\n    if (!si.hasFieldUpdates()) {\n      // simple case, no DocValues updates\n      final DocValuesProducer dvp = segDocValues.getDocValuesProducer(-1L, si, IOContext.READ, dir, dvFormat, fieldInfos);\n      dvGens.add(-1L);\n      dvProducers.add(dvp);\n      for (FieldInfo fi : fieldInfos) {\n        if (!fi.hasDocValues()) continue;\n        assert fi.getDocValuesGen() == -1;\n        dvProducersByField.put(fi.name, dvp);\n      }\n      return;\n    }\n\n    Version ver = si.info.getVersion();\n    if (ver != null && ver.onOrAfter(Version.LUCENE_4_9_0)) {\n      DocValuesProducer baseProducer = null;\n      for (FieldInfo fi : fieldInfos) {\n        if (!fi.hasDocValues()) continue;\n        long docValuesGen = fi.getDocValuesGen();\n        if (docValuesGen == -1) {\n          if (baseProducer == null) {\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.initDocValuesProducers: segInfo=\" + si + \"; gen=\" + docValuesGen + \"; field=\" + fi.name);\n            // the base producer gets all the fields, so the Codec can validate properly\n            baseProducer = segDocValues.getDocValuesProducer(docValuesGen, si, IOContext.READ, dir, dvFormat, fieldInfos);\n            dvGens.add(docValuesGen);\n            dvProducers.add(baseProducer);\n          }\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.initDocValuesProducers: segInfo=\" + si + \"; gen=\" + docValuesGen + \"; field=\" + fi.name);\n          dvProducersByField.put(fi.name, baseProducer);\n        } else {\n          assert !dvGens.contains(docValuesGen);\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.initDocValuesProducers: segInfo=\" + si + \"; gen=\" + docValuesGen + \"; field=\" + fi.name);\n          final DocValuesProducer dvp = segDocValues.getDocValuesProducer(docValuesGen, si, IOContext.READ, dir, dvFormat, new FieldInfos(new FieldInfo[] { fi }));\n          dvGens.add(docValuesGen);\n          dvProducers.add(dvp);\n          dvProducersByField.put(fi.name, dvp);\n        }\n      }\n    } else {\n      // For pre-4.9 indexes, especially with doc-values updates, multiple\n      // FieldInfos could belong to the same dvGen. Therefore need to make sure\n      // we initialize each DocValuesProducer once per gen.\n      Map<Long,List<FieldInfo>> genInfos = new HashMap<>();\n      for (FieldInfo fi : fieldInfos) {\n        if (!fi.hasDocValues()) continue;\n        List<FieldInfo> genFieldInfos = genInfos.get(fi.getDocValuesGen());\n        if (genFieldInfos == null) {\n          genFieldInfos = new ArrayList<>();\n          genInfos.put(fi.getDocValuesGen(), genFieldInfos);\n        }\n        genFieldInfos.add(fi);\n      }\n      \n      for (Map.Entry<Long,List<FieldInfo>> e : genInfos.entrySet()) {\n        long docValuesGen = e.getKey();\n        List<FieldInfo> infos = e.getValue();\n        final DocValuesProducer dvp;\n        if (docValuesGen == -1) {\n          // we need to send all FieldInfos to gen=-1, but later we need to\n          // record the DVP only for the \"true\" gen=-1 fields (not updated)\n          dvp = segDocValues.getDocValuesProducer(docValuesGen, si, IOContext.READ, dir, dvFormat, fieldInfos);\n        } else {\n          dvp = segDocValues.getDocValuesProducer(docValuesGen, si, IOContext.READ, dir, dvFormat, new FieldInfos(infos.toArray(new FieldInfo[infos.size()])));\n        }\n        dvGens.add(docValuesGen);\n        dvProducers.add(dvp);\n        for (FieldInfo fi : infos) {\n          dvProducersByField.put(fi.name, dvp);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"5eb2511ababf862ea11e10761c70ee560cd84510":["ac14bdd59867c398bdb1a9cc50583bd3c93593e5","1f3b037cd083286b2af89f96e768f85dcd8072d6"],"c1d0b4a65bc57bd59cef05619306aa8ee7431a0f":["1f3b037cd083286b2af89f96e768f85dcd8072d6"],"1f3b037cd083286b2af89f96e768f85dcd8072d6":["ac14bdd59867c398bdb1a9cc50583bd3c93593e5"],"c0cd85fde84cb318b4dc97710dcf15e2959a1bbe":["1f3b037cd083286b2af89f96e768f85dcd8072d6","c1d0b4a65bc57bd59cef05619306aa8ee7431a0f"],"0567bdc5c86c94ced64201187cfcef2417d76dda":["a5454fae2949cf13fdcc8a28cda5972a9e3d26d5"],"a5454fae2949cf13fdcc8a28cda5972a9e3d26d5":["c1d0b4a65bc57bd59cef05619306aa8ee7431a0f"],"b7605579001505896d48b07160075a5c8b8e128e":["a5454fae2949cf13fdcc8a28cda5972a9e3d26d5","0567bdc5c86c94ced64201187cfcef2417d76dda"],"057a1793765d068ea9302f1a29e21734ee58d41e":["70179a348a4367cb9fcf2d721a289651a8c125ac"],"ac14bdd59867c398bdb1a9cc50583bd3c93593e5":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a656b32c3aa151037a8c52e9b134acc3cbf482bc":["a5454fae2949cf13fdcc8a28cda5972a9e3d26d5","0567bdc5c86c94ced64201187cfcef2417d76dda"],"22a2e66dfda83847e80095b8693c660742ab3e9c":["057a1793765d068ea9302f1a29e21734ee58d41e"],"70179a348a4367cb9fcf2d721a289651a8c125ac":["0567bdc5c86c94ced64201187cfcef2417d76dda"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["22a2e66dfda83847e80095b8693c660742ab3e9c"]},"commit2Childs":{"5eb2511ababf862ea11e10761c70ee560cd84510":[],"1f3b037cd083286b2af89f96e768f85dcd8072d6":["5eb2511ababf862ea11e10761c70ee560cd84510","c1d0b4a65bc57bd59cef05619306aa8ee7431a0f","c0cd85fde84cb318b4dc97710dcf15e2959a1bbe"],"c1d0b4a65bc57bd59cef05619306aa8ee7431a0f":["c0cd85fde84cb318b4dc97710dcf15e2959a1bbe","a5454fae2949cf13fdcc8a28cda5972a9e3d26d5"],"c0cd85fde84cb318b4dc97710dcf15e2959a1bbe":[],"0567bdc5c86c94ced64201187cfcef2417d76dda":["b7605579001505896d48b07160075a5c8b8e128e","a656b32c3aa151037a8c52e9b134acc3cbf482bc","70179a348a4367cb9fcf2d721a289651a8c125ac"],"a5454fae2949cf13fdcc8a28cda5972a9e3d26d5":["0567bdc5c86c94ced64201187cfcef2417d76dda","b7605579001505896d48b07160075a5c8b8e128e","a656b32c3aa151037a8c52e9b134acc3cbf482bc"],"b7605579001505896d48b07160075a5c8b8e128e":[],"057a1793765d068ea9302f1a29e21734ee58d41e":["22a2e66dfda83847e80095b8693c660742ab3e9c"],"ac14bdd59867c398bdb1a9cc50583bd3c93593e5":["5eb2511ababf862ea11e10761c70ee560cd84510","1f3b037cd083286b2af89f96e768f85dcd8072d6"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["ac14bdd59867c398bdb1a9cc50583bd3c93593e5"],"a656b32c3aa151037a8c52e9b134acc3cbf482bc":[],"70179a348a4367cb9fcf2d721a289651a8c125ac":["057a1793765d068ea9302f1a29e21734ee58d41e"],"22a2e66dfda83847e80095b8693c660742ab3e9c":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["5eb2511ababf862ea11e10761c70ee560cd84510","c0cd85fde84cb318b4dc97710dcf15e2959a1bbe","b7605579001505896d48b07160075a5c8b8e128e","a656b32c3aa151037a8c52e9b134acc3cbf482bc","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}