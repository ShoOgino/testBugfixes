{"path":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","sourceNew":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir);\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", StringField.TYPE_UNSTORED));\n    writer.addDocument(doc);\n    DirectoryReader reader = writer.getReader();\n    AtomicReader r = getOnlySegmentReader(reader);\n    DocsEnum disi = _TestUtil.docs(random, r, \"foo\", new BytesRef(\"bar\"), null, null, false);\n    int docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = _TestUtil.docs(random, te, null, disi, false);\n    docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir);\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", StringField.TYPE_UNSTORED));\n    writer.addDocument(doc);\n    DirectoryReader reader = writer.getReader();\n    AtomicReader r = getOnlySegmentReader(reader);\n    DocsEnum disi = _TestUtil.docs(random, r, \"foo\", new BytesRef(\"bar\"), null, null, false);\n    int docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = _TestUtil.docs(random, te, null, disi, false);\n    docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","sourceNew":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", StringField.TYPE_UNSTORED));\n    writer.addDocument(doc);\n    DirectoryReader reader = writer.getReader();\n    AtomicReader r = getOnlySegmentReader(reader);\n    DocsEnum disi = _TestUtil.docs(random(), r, \"foo\", new BytesRef(\"bar\"), null, null, false);\n    int docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = _TestUtil.docs(random(), te, null, disi, false);\n    docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir);\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", StringField.TYPE_UNSTORED));\n    writer.addDocument(doc);\n    DirectoryReader reader = writer.getReader();\n    AtomicReader r = getOnlySegmentReader(reader);\n    DocsEnum disi = _TestUtil.docs(random, r, \"foo\", new BytesRef(\"bar\"), null, null, false);\n    int docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = _TestUtil.docs(random, te, null, disi, false);\n    docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":["02331260bb246364779cb6f04919ca47900d01bb"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"04f07771a2a7dd3a395700665ed839c3dae2def2","date":1339350139,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","sourceNew":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"foo\", \"bar\", Field.Store.NO));\n    writer.addDocument(doc);\n    DirectoryReader reader = writer.getReader();\n    AtomicReader r = getOnlySegmentReader(reader);\n    DocsEnum disi = _TestUtil.docs(random(), r, \"foo\", new BytesRef(\"bar\"), null, null, false);\n    int docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = _TestUtil.docs(random(), te, null, disi, false);\n    docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", StringField.TYPE_UNSTORED));\n    writer.addDocument(doc);\n    DirectoryReader reader = writer.getReader();\n    AtomicReader r = getOnlySegmentReader(reader);\n    DocsEnum disi = _TestUtil.docs(random(), r, \"foo\", new BytesRef(\"bar\"), null, null, false);\n    int docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = _TestUtil.docs(random(), te, null, disi, false);\n    docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","bugFix":["1ed947d41796fd2096684c439e8a9b69aac940cf"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"02331260bb246364779cb6f04919ca47900d01bb","date":1343749884,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","sourceNew":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"foo\", \"bar\", Field.Store.NO));\n    writer.addDocument(doc);\n    DirectoryReader reader = writer.getReader();\n    AtomicReader r = getOnlySegmentReader(reader);\n    DocsEnum disi = _TestUtil.docs(random(), r, \"foo\", new BytesRef(\"bar\"), null, null, 0);\n    int docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = _TestUtil.docs(random(), te, null, disi, 0);\n    docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"foo\", \"bar\", Field.Store.NO));\n    writer.addDocument(doc);\n    DirectoryReader reader = writer.getReader();\n    AtomicReader r = getOnlySegmentReader(reader);\n    DocsEnum disi = _TestUtil.docs(random(), r, \"foo\", new BytesRef(\"bar\"), null, null, false);\n    int docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = _TestUtil.docs(random(), te, null, disi, false);\n    docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","bugFix":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","date":1343768312,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","sourceNew":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"foo\", \"bar\", Field.Store.NO));\n    writer.addDocument(doc);\n    DirectoryReader reader = writer.getReader();\n    AtomicReader r = getOnlySegmentReader(reader);\n    DocsEnum disi = _TestUtil.docs(random(), r, \"foo\", new BytesRef(\"bar\"), null, null, 0);\n    int docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = _TestUtil.docs(random(), te, null, disi, 0);\n    docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"foo\", \"bar\", Field.Store.NO));\n    writer.addDocument(doc);\n    DirectoryReader reader = writer.getReader();\n    AtomicReader r = getOnlySegmentReader(reader);\n    DocsEnum disi = _TestUtil.docs(random(), r, \"foo\", new BytesRef(\"bar\"), null, null, false);\n    int docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = _TestUtil.docs(random(), te, null, disi, false);\n    docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d6f074e73200c07d54f242d3880a8da5a35ff97b","date":1344507653,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","sourceNew":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"foo\", \"bar\", Field.Store.NO));\n    writer.addDocument(doc);\n    DirectoryReader reader = writer.getReader();\n    AtomicReader r = getOnlySegmentReader(reader);\n    DocsEnum disi = _TestUtil.docs(random(), r, \"foo\", new BytesRef(\"bar\"), null, null, 0);\n    int docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = _TestUtil.docs(random(), te, null, disi, 0);\n    docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"foo\", \"bar\", Field.Store.NO));\n    writer.addDocument(doc);\n    DirectoryReader reader = writer.getReader();\n    AtomicReader r = getOnlySegmentReader(reader);\n    DocsEnum disi = _TestUtil.docs(random(), r, \"foo\", new BytesRef(\"bar\"), null, null, false);\n    int docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = _TestUtil.docs(random(), te, null, disi, false);\n    docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"15250ca94ba8ab3bcdd476daf6bf3f3febb92640","date":1355200097,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","sourceNew":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"foo\", \"bar\", Field.Store.NO));\n    writer.addDocument(doc);\n    DirectoryReader reader = writer.getReader();\n    AtomicReader r = getOnlySegmentReader(reader);\n    DocsEnum disi = _TestUtil.docs(random(), r, \"foo\", new BytesRef(\"bar\"), null, null, DocsEnum.FLAG_NONE);\n    int docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = _TestUtil.docs(random(), te, null, disi, DocsEnum.FLAG_NONE);\n    docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"foo\", \"bar\", Field.Store.NO));\n    writer.addDocument(doc);\n    DirectoryReader reader = writer.getReader();\n    AtomicReader r = getOnlySegmentReader(reader);\n    DocsEnum disi = _TestUtil.docs(random(), r, \"foo\", new BytesRef(\"bar\"), null, null, 0);\n    int docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = _TestUtil.docs(random(), te, null, disi, 0);\n    docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d3fcb70cf561547c7bb1506e0cf32ca7b1287064","date":1357616416,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","sourceNew":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"foo\", \"bar\", Field.Store.NO));\n    writer.addDocument(doc);\n    DirectoryReader reader = writer.getReader();\n    AtomicReader r = getOnlySegmentReader(reader);\n    DocsEnum disi = _TestUtil.docs(random(), r, \"foo\", new BytesRef(\"bar\"), null, null, DocsEnum.FLAG_NONE);\n    int docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = _TestUtil.docs(random(), te, null, disi, DocsEnum.FLAG_NONE);\n    docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"foo\", \"bar\", Field.Store.NO));\n    writer.addDocument(doc);\n    DirectoryReader reader = writer.getReader();\n    AtomicReader r = getOnlySegmentReader(reader);\n    DocsEnum disi = _TestUtil.docs(random(), r, \"foo\", new BytesRef(\"bar\"), null, null, 0);\n    int docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = _TestUtil.docs(random(), te, null, disi, 0);\n    docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"af527d067afb6ca5bd58afc7b9a5fbc0f80979af","date":1366034882,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","sourceNew":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"foo\", \"bar\", Field.Store.NO));\n    writer.addDocument(doc);\n    DirectoryReader reader = writer.getReader();\n    AtomicReader r = getOnlySegmentReader(reader);\n    DocsEnum disi = _TestUtil.docs(random(), r, \"foo\", new BytesRef(\"bar\"), null, null, DocsEnum.FLAG_NONE);\n    int docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = _TestUtil.docs(random(), te, null, disi, DocsEnum.FLAG_NONE);\n    docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"foo\", \"bar\", Field.Store.NO));\n    writer.addDocument(doc);\n    DirectoryReader reader = writer.getReader();\n    AtomicReader r = getOnlySegmentReader(reader);\n    DocsEnum disi = _TestUtil.docs(random(), r, \"foo\", new BytesRef(\"bar\"), null, null, DocsEnum.FLAG_NONE);\n    int docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = _TestUtil.docs(random(), te, null, disi, DocsEnum.FLAG_NONE);\n    docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"eee5f2a24465d2c9a5f86ab84b7c35041a30fda8","date":1373996650,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","sourceNew":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"foo\", \"bar\", Field.Store.NO));\n    writer.addDocument(doc);\n    DirectoryReader reader = writer.getReader();\n    AtomicReader r = getOnlySegmentReader(reader);\n    DocsEnum disi = _TestUtil.docs(random(), r, \"foo\", new BytesRef(\"bar\"), null, null, DocsEnum.FLAG_NONE);\n    int docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\")));\n    disi = _TestUtil.docs(random(), te, null, disi, DocsEnum.FLAG_NONE);\n    docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"foo\", \"bar\", Field.Store.NO));\n    writer.addDocument(doc);\n    DirectoryReader reader = writer.getReader();\n    AtomicReader r = getOnlySegmentReader(reader);\n    DocsEnum disi = _TestUtil.docs(random(), r, \"foo\", new BytesRef(\"bar\"), null, null, DocsEnum.FLAG_NONE);\n    int docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = _TestUtil.docs(random(), te, null, disi, DocsEnum.FLAG_NONE);\n    docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","date":1376366778,"type":3,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","sourceNew":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"foo\", \"bar\", Field.Store.NO));\n    writer.addDocument(doc);\n    DirectoryReader reader = writer.getReader();\n    AtomicReader r = getOnlySegmentReader(reader);\n    DocsEnum disi = _TestUtil.docs(random(), r, \"foo\", new BytesRef(\"bar\"), null, null, DocsEnum.FLAG_NONE);\n    int docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\")));\n    disi = _TestUtil.docs(random(), te, null, disi, DocsEnum.FLAG_NONE);\n    docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"foo\", \"bar\", Field.Store.NO));\n    writer.addDocument(doc);\n    DirectoryReader reader = writer.getReader();\n    AtomicReader r = getOnlySegmentReader(reader);\n    DocsEnum disi = _TestUtil.docs(random(), r, \"foo\", new BytesRef(\"bar\"), null, null, DocsEnum.FLAG_NONE);\n    int docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = _TestUtil.docs(random(), te, null, disi, DocsEnum.FLAG_NONE);\n    docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6613659748fe4411a7dcf85266e55db1f95f7315","date":1392773913,"type":3,"author":"Benson Margulies","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","sourceNew":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"foo\", \"bar\", Field.Store.NO));\n    writer.addDocument(doc);\n    DirectoryReader reader = writer.getReader();\n    AtomicReader r = getOnlySegmentReader(reader);\n    DocsEnum disi = TestUtil.docs(random(), r, \"foo\", new BytesRef(\"bar\"), null, null, DocsEnum.FLAG_NONE);\n    int docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\")));\n    disi = TestUtil.docs(random(), te, null, disi, DocsEnum.FLAG_NONE);\n    docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"foo\", \"bar\", Field.Store.NO));\n    writer.addDocument(doc);\n    DirectoryReader reader = writer.getReader();\n    AtomicReader r = getOnlySegmentReader(reader);\n    DocsEnum disi = _TestUtil.docs(random(), r, \"foo\", new BytesRef(\"bar\"), null, null, DocsEnum.FLAG_NONE);\n    int docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\")));\n    disi = _TestUtil.docs(random(), te, null, disi, DocsEnum.FLAG_NONE);\n    docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","sourceNew":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"foo\", \"bar\", Field.Store.NO));\n    writer.addDocument(doc);\n    DirectoryReader reader = writer.getReader();\n    AtomicReader r = getOnlySegmentReader(reader);\n    DocsEnum disi = TestUtil.docs(random(), r, \"foo\", new BytesRef(\"bar\"), null, null, DocsEnum.FLAG_NONE);\n    int docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\")));\n    disi = TestUtil.docs(random(), te, null, disi, DocsEnum.FLAG_NONE);\n    docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.shutdown();\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"foo\", \"bar\", Field.Store.NO));\n    writer.addDocument(doc);\n    DirectoryReader reader = writer.getReader();\n    AtomicReader r = getOnlySegmentReader(reader);\n    DocsEnum disi = TestUtil.docs(random(), r, \"foo\", new BytesRef(\"bar\"), null, null, DocsEnum.FLAG_NONE);\n    int docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\")));\n    disi = TestUtil.docs(random(), te, null, disi, DocsEnum.FLAG_NONE);\n    docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","sourceNew":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"foo\", \"bar\", Field.Store.NO));\n    writer.addDocument(doc);\n    DirectoryReader reader = writer.getReader();\n    AtomicReader r = getOnlySegmentReader(reader);\n    DocsEnum disi = TestUtil.docs(random(), r, \"foo\", new BytesRef(\"bar\"), null, null, DocsEnum.FLAG_NONE);\n    int docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\")));\n    disi = TestUtil.docs(random(), te, null, disi, DocsEnum.FLAG_NONE);\n    docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"foo\", \"bar\", Field.Store.NO));\n    writer.addDocument(doc);\n    DirectoryReader reader = writer.getReader();\n    AtomicReader r = getOnlySegmentReader(reader);\n    DocsEnum disi = TestUtil.docs(random(), r, \"foo\", new BytesRef(\"bar\"), null, null, DocsEnum.FLAG_NONE);\n    int docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\")));\n    disi = TestUtil.docs(random(), te, null, disi, DocsEnum.FLAG_NONE);\n    docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.shutdown();\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c9fb5f46e264daf5ba3860defe623a89d202dd87","date":1411516315,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","sourceNew":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"foo\", \"bar\", Field.Store.NO));\n    writer.addDocument(doc);\n    DirectoryReader reader = writer.getReader();\n    LeafReader r = getOnlySegmentReader(reader);\n    DocsEnum disi = TestUtil.docs(random(), r, \"foo\", new BytesRef(\"bar\"), null, null, DocsEnum.FLAG_NONE);\n    int docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\")));\n    disi = TestUtil.docs(random(), te, null, disi, DocsEnum.FLAG_NONE);\n    docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"foo\", \"bar\", Field.Store.NO));\n    writer.addDocument(doc);\n    DirectoryReader reader = writer.getReader();\n    AtomicReader r = getOnlySegmentReader(reader);\n    DocsEnum disi = TestUtil.docs(random(), r, \"foo\", new BytesRef(\"bar\"), null, null, DocsEnum.FLAG_NONE);\n    int docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\")));\n    disi = TestUtil.docs(random(), te, null, disi, DocsEnum.FLAG_NONE);\n    docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":["0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"51f5280f31484820499077f41fcdfe92d527d9dc","date":1423229122,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","sourceNew":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"foo\", \"bar\", Field.Store.NO));\n    writer.addDocument(doc);\n    DirectoryReader reader = writer.getReader();\n    LeafReader r = getOnlySegmentReader(reader);\n    PostingsEnum disi = TestUtil.docs(random(), r, \"foo\", new BytesRef(\"bar\"), null, null, PostingsEnum.FLAG_NONE);\n    int docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\")));\n    disi = TestUtil.docs(random(), te, null, disi, PostingsEnum.FLAG_NONE);\n    docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"foo\", \"bar\", Field.Store.NO));\n    writer.addDocument(doc);\n    DirectoryReader reader = writer.getReader();\n    LeafReader r = getOnlySegmentReader(reader);\n    DocsEnum disi = TestUtil.docs(random(), r, \"foo\", new BytesRef(\"bar\"), null, null, DocsEnum.FLAG_NONE);\n    int docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\")));\n    disi = TestUtil.docs(random(), te, null, disi, DocsEnum.FLAG_NONE);\n    docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e73063b92d958076ef4ae8beb5f493e8ccdcecb4","date":1424177215,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","sourceNew":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"foo\", \"bar\", Field.Store.NO));\n    writer.addDocument(doc);\n    DirectoryReader reader = writer.getReader();\n    LeafReader r = getOnlySegmentReader(reader);\n    PostingsEnum disi = TestUtil.docs(random(), r, \"foo\", new BytesRef(\"bar\"), null, null, PostingsEnum.NONE);\n    int docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\")));\n    disi = TestUtil.docs(random(), te, null, disi, PostingsEnum.NONE);\n    docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"foo\", \"bar\", Field.Store.NO));\n    writer.addDocument(doc);\n    DirectoryReader reader = writer.getReader();\n    LeafReader r = getOnlySegmentReader(reader);\n    PostingsEnum disi = TestUtil.docs(random(), r, \"foo\", new BytesRef(\"bar\"), null, null, PostingsEnum.FLAG_NONE);\n    int docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\")));\n    disi = TestUtil.docs(random(), te, null, disi, PostingsEnum.FLAG_NONE);\n    docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82","date":1428522487,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","sourceNew":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"foo\", \"bar\", Field.Store.NO));\n    writer.addDocument(doc);\n    DirectoryReader reader = writer.getReader();\n    LeafReader r = getOnlySegmentReader(reader);\n    PostingsEnum disi = TestUtil.docs(random(), r, \"foo\", new BytesRef(\"bar\"), null, null, PostingsEnum.NONE);\n    int docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator();\n    assertTrue(te.seekExact(new BytesRef(\"bar\")));\n    disi = TestUtil.docs(random(), te, null, disi, PostingsEnum.NONE);\n    docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"foo\", \"bar\", Field.Store.NO));\n    writer.addDocument(doc);\n    DirectoryReader reader = writer.getReader();\n    LeafReader r = getOnlySegmentReader(reader);\n    PostingsEnum disi = TestUtil.docs(random(), r, \"foo\", new BytesRef(\"bar\"), null, null, PostingsEnum.NONE);\n    int docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\")));\n    disi = TestUtil.docs(random(), te, null, disi, PostingsEnum.NONE);\n    docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0f4464508ee83288c8c4585b533f9faaa93aa314","date":1435240759,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","sourceNew":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"foo\", \"bar\", Field.Store.NO));\n    writer.addDocument(doc);\n    DirectoryReader reader = writer.getReader();\n    LeafReader r = getOnlySegmentReader(reader);\n    PostingsEnum disi = TestUtil.docs(random(), r, \"foo\", new BytesRef(\"bar\"), null, PostingsEnum.NONE);\n    int docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator();\n    assertTrue(te.seekExact(new BytesRef(\"bar\")));\n    disi = TestUtil.docs(random(), te, disi, PostingsEnum.NONE);\n    docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"foo\", \"bar\", Field.Store.NO));\n    writer.addDocument(doc);\n    DirectoryReader reader = writer.getReader();\n    LeafReader r = getOnlySegmentReader(reader);\n    PostingsEnum disi = TestUtil.docs(random(), r, \"foo\", new BytesRef(\"bar\"), null, null, PostingsEnum.NONE);\n    int docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator();\n    assertTrue(te.seekExact(new BytesRef(\"bar\")));\n    disi = TestUtil.docs(random(), te, null, disi, PostingsEnum.NONE);\n    docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1","date":1457644139,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","sourceNew":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"foo\", \"bar\", Field.Store.NO));\n    writer.addDocument(doc);\n    DirectoryReader reader = writer.getReader();\n    LeafReader r = getOnlyLeafReader(reader);\n    PostingsEnum disi = TestUtil.docs(random(), r, \"foo\", new BytesRef(\"bar\"), null, PostingsEnum.NONE);\n    int docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator();\n    assertTrue(te.seekExact(new BytesRef(\"bar\")));\n    disi = TestUtil.docs(random(), te, disi, PostingsEnum.NONE);\n    docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"foo\", \"bar\", Field.Store.NO));\n    writer.addDocument(doc);\n    DirectoryReader reader = writer.getReader();\n    LeafReader r = getOnlySegmentReader(reader);\n    PostingsEnum disi = TestUtil.docs(random(), r, \"foo\", new BytesRef(\"bar\"), null, PostingsEnum.NONE);\n    int docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator();\n    assertTrue(te.seekExact(new BytesRef(\"bar\")));\n    disi = TestUtil.docs(random(), te, disi, PostingsEnum.NONE);\n    docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","bugFix":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82":["e73063b92d958076ef4ae8beb5f493e8ccdcecb4"],"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["02331260bb246364779cb6f04919ca47900d01bb","15250ca94ba8ab3bcdd476daf6bf3f3febb92640"],"af527d067afb6ca5bd58afc7b9a5fbc0f80979af":["15250ca94ba8ab3bcdd476daf6bf3f3febb92640"],"6613659748fe4411a7dcf85266e55db1f95f7315":["eee5f2a24465d2c9a5f86ab84b7c35041a30fda8"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"51f5280f31484820499077f41fcdfe92d527d9dc":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"04f07771a2a7dd3a395700665ed839c3dae2def2":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82"],"e73063b92d958076ef4ae8beb5f493e8ccdcecb4":["51f5280f31484820499077f41fcdfe92d527d9dc"],"15250ca94ba8ab3bcdd476daf6bf3f3febb92640":["02331260bb246364779cb6f04919ca47900d01bb"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":["04f07771a2a7dd3a395700665ed839c3dae2def2","02331260bb246364779cb6f04919ca47900d01bb"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":["af527d067afb6ca5bd58afc7b9a5fbc0f80979af"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["04f07771a2a7dd3a395700665ed839c3dae2def2","02331260bb246364779cb6f04919ca47900d01bb"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["6613659748fe4411a7dcf85266e55db1f95f7315"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"eee5f2a24465d2c9a5f86ab84b7c35041a30fda8":["af527d067afb6ca5bd58afc7b9a5fbc0f80979af"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1"],"02331260bb246364779cb6f04919ca47900d01bb":["04f07771a2a7dd3a395700665ed839c3dae2def2"]},"commit2Childs":{"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":[],"af527d067afb6ca5bd58afc7b9a5fbc0f80979af":["8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","eee5f2a24465d2c9a5f86ab84b7c35041a30fda8"],"6613659748fe4411a7dcf85266e55db1f95f7315":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"51f5280f31484820499077f41fcdfe92d527d9dc":["e73063b92d958076ef4ae8beb5f493e8ccdcecb4"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["51f5280f31484820499077f41fcdfe92d527d9dc"],"0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"04f07771a2a7dd3a395700665ed839c3dae2def2":["b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b","02331260bb246364779cb6f04919ca47900d01bb"],"e73063b92d958076ef4ae8beb5f493e8ccdcecb4":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1"],"15250ca94ba8ab3bcdd476daf6bf3f3febb92640":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","af527d067afb6ca5bd58afc7b9a5fbc0f80979af"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":[],"d6f074e73200c07d54f242d3880a8da5a35ff97b":[],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"eee5f2a24465d2c9a5f86ab84b7c35041a30fda8":["6613659748fe4411a7dcf85266e55db1f95f7315"],"02331260bb246364779cb6f04919ca47900d01bb":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","15250ca94ba8ab3bcdd476daf6bf3f3febb92640","b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","d6f074e73200c07d54f242d3880a8da5a35ff97b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}