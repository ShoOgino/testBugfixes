{"path":"lucene/core/src/java/org/apache/lucene/codecs/FieldsConsumer#merge(MergeState).mjava","commits":[{"id":"22a2e66dfda83847e80095b8693c660742ab3e9c","date":1408628796,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/FieldsConsumer#merge(MergeState).mjava","pathOld":"/dev/null","sourceNew":"  /** Merges in the fields from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  and maps around deleted documents, and calls {@link #write(Fields)}.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public void merge(MergeState mergeState) throws IOException {\n    final List<Fields> fields = new ArrayList<>();\n    final List<ReaderSlice> slices = new ArrayList<>();\n\n    int docBase = 0;\n\n    for(int readerIndex=0;readerIndex<mergeState.readers.size();readerIndex++) {\n      final AtomicReader reader = mergeState.readers.get(readerIndex);\n      final Fields f = reader.fields();\n      final int maxDoc = reader.maxDoc();\n      if (f != null) {\n        slices.add(new ReaderSlice(docBase, maxDoc, readerIndex));\n        fields.add(f);\n      }\n      docBase += maxDoc;\n    }\n\n    Fields mergedFields = new MappedMultiFields(mergeState, \n                                                new MultiFields(fields.toArray(Fields.EMPTY_ARRAY),\n                                                                slices.toArray(ReaderSlice.EMPTY_ARRAY)));\n    write(mergedFields);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["8028ab7a24273833d53d35eb160dba5b57283cf5"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c9fb5f46e264daf5ba3860defe623a89d202dd87","date":1411516315,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/FieldsConsumer#merge(MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/FieldsConsumer#merge(MergeState).mjava","sourceNew":"  /** Merges in the fields from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  and maps around deleted documents, and calls {@link #write(Fields)}.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public void merge(MergeState mergeState) throws IOException {\n    final List<Fields> fields = new ArrayList<>();\n    final List<ReaderSlice> slices = new ArrayList<>();\n\n    int docBase = 0;\n\n    for(int readerIndex=0;readerIndex<mergeState.readers.size();readerIndex++) {\n      final LeafReader reader = mergeState.readers.get(readerIndex);\n      final Fields f = reader.fields();\n      final int maxDoc = reader.maxDoc();\n      if (f != null) {\n        slices.add(new ReaderSlice(docBase, maxDoc, readerIndex));\n        fields.add(f);\n      }\n      docBase += maxDoc;\n    }\n\n    Fields mergedFields = new MappedMultiFields(mergeState, \n                                                new MultiFields(fields.toArray(Fields.EMPTY_ARRAY),\n                                                                slices.toArray(ReaderSlice.EMPTY_ARRAY)));\n    write(mergedFields);\n  }\n\n","sourceOld":"  /** Merges in the fields from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  and maps around deleted documents, and calls {@link #write(Fields)}.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public void merge(MergeState mergeState) throws IOException {\n    final List<Fields> fields = new ArrayList<>();\n    final List<ReaderSlice> slices = new ArrayList<>();\n\n    int docBase = 0;\n\n    for(int readerIndex=0;readerIndex<mergeState.readers.size();readerIndex++) {\n      final AtomicReader reader = mergeState.readers.get(readerIndex);\n      final Fields f = reader.fields();\n      final int maxDoc = reader.maxDoc();\n      if (f != null) {\n        slices.add(new ReaderSlice(docBase, maxDoc, readerIndex));\n        fields.add(f);\n      }\n      docBase += maxDoc;\n    }\n\n    Fields mergedFields = new MappedMultiFields(mergeState, \n                                                new MultiFields(fields.toArray(Fields.EMPTY_ARRAY),\n                                                                slices.toArray(ReaderSlice.EMPTY_ARRAY)));\n    write(mergedFields);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2131047ecceac64b54ba70feec3d26bbd7e483d7","date":1411862069,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/FieldsConsumer#merge(MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/FieldsConsumer#merge(MergeState).mjava","sourceNew":"  /** Merges in the fields from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  and maps around deleted documents, and calls {@link #write(Fields)}.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public void merge(MergeState mergeState) throws IOException {\n    final List<Fields> fields = new ArrayList<>();\n    final List<ReaderSlice> slices = new ArrayList<>();\n\n    int docBase = 0;\n\n    for(int readerIndex=0;readerIndex<mergeState.fieldsProducers.length;readerIndex++) {\n      final FieldsProducer f = mergeState.fieldsProducers[readerIndex];\n\n      final int maxDoc = mergeState.maxDocs[readerIndex];\n      if (f != null) {\n        f.checkIntegrity();\n        slices.add(new ReaderSlice(docBase, maxDoc, readerIndex));\n        fields.add(f);\n      }\n      docBase += maxDoc;\n    }\n\n    Fields mergedFields = new MappedMultiFields(mergeState, \n                                                new MultiFields(fields.toArray(Fields.EMPTY_ARRAY),\n                                                                slices.toArray(ReaderSlice.EMPTY_ARRAY)));\n    write(mergedFields);\n  }\n\n","sourceOld":"  /** Merges in the fields from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  and maps around deleted documents, and calls {@link #write(Fields)}.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public void merge(MergeState mergeState) throws IOException {\n    final List<Fields> fields = new ArrayList<>();\n    final List<ReaderSlice> slices = new ArrayList<>();\n\n    int docBase = 0;\n\n    for(int readerIndex=0;readerIndex<mergeState.readers.size();readerIndex++) {\n      final LeafReader reader = mergeState.readers.get(readerIndex);\n      final Fields f = reader.fields();\n      final int maxDoc = reader.maxDoc();\n      if (f != null) {\n        slices.add(new ReaderSlice(docBase, maxDoc, readerIndex));\n        fields.add(f);\n      }\n      docBase += maxDoc;\n    }\n\n    Fields mergedFields = new MappedMultiFields(mergeState, \n                                                new MultiFields(fields.toArray(Fields.EMPTY_ARRAY),\n                                                                slices.toArray(ReaderSlice.EMPTY_ARRAY)));\n    write(mergedFields);\n  }\n\n","bugFix":null,"bugIntro":["8028ab7a24273833d53d35eb160dba5b57283cf5"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9bb9a29a5e71a90295f175df8919802993142c9a","date":1412517673,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/FieldsConsumer#merge(MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/FieldsConsumer#merge(MergeState).mjava","sourceNew":"  /** Merges in the fields from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  and maps around deleted documents, and calls {@link #write(Fields)}.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public void merge(MergeState mergeState) throws IOException {\n    final List<Fields> fields = new ArrayList<>();\n    final List<ReaderSlice> slices = new ArrayList<>();\n\n    int docBase = 0;\n\n    for(int readerIndex=0;readerIndex<mergeState.fieldsProducers.length;readerIndex++) {\n      final FieldsProducer f = mergeState.fieldsProducers[readerIndex];\n\n      final int maxDoc = mergeState.maxDocs[readerIndex];\n      if (f != null) {\n        f.checkIntegrity();\n        slices.add(new ReaderSlice(docBase, maxDoc, readerIndex));\n        fields.add(f);\n      }\n      docBase += maxDoc;\n    }\n\n    Fields mergedFields = new MappedMultiFields(mergeState, \n                                                new MultiFields(fields.toArray(Fields.EMPTY_ARRAY),\n                                                                slices.toArray(ReaderSlice.EMPTY_ARRAY)));\n    write(mergedFields);\n  }\n\n","sourceOld":"  /** Merges in the fields from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  and maps around deleted documents, and calls {@link #write(Fields)}.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public void merge(MergeState mergeState) throws IOException {\n    final List<Fields> fields = new ArrayList<>();\n    final List<ReaderSlice> slices = new ArrayList<>();\n\n    int docBase = 0;\n\n    for(int readerIndex=0;readerIndex<mergeState.readers.size();readerIndex++) {\n      final LeafReader reader = mergeState.readers.get(readerIndex);\n      final Fields f = reader.fields();\n      final int maxDoc = reader.maxDoc();\n      if (f != null) {\n        slices.add(new ReaderSlice(docBase, maxDoc, readerIndex));\n        fields.add(f);\n      }\n      docBase += maxDoc;\n    }\n\n    Fields mergedFields = new MappedMultiFields(mergeState, \n                                                new MultiFields(fields.toArray(Fields.EMPTY_ARRAY),\n                                                                slices.toArray(ReaderSlice.EMPTY_ARRAY)));\n    write(mergedFields);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8028ab7a24273833d53d35eb160dba5b57283cf5","date":1416767720,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/FieldsConsumer#merge(MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/FieldsConsumer#merge(MergeState).mjava","sourceNew":"  /** Merges in the fields from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  and maps around deleted documents, and calls {@link #write(Fields)}.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public void merge(MergeState mergeState) throws IOException {\n    final List<Fields> fields = new ArrayList<>();\n    final List<ReaderSlice> slices = new ArrayList<>();\n\n    int docBase = 0;\n\n    for(int readerIndex=0;readerIndex<mergeState.fieldsProducers.length;readerIndex++) {\n      final FieldsProducer f = mergeState.fieldsProducers[readerIndex];\n\n      final int maxDoc = mergeState.maxDocs[readerIndex];\n      f.checkIntegrity();\n      slices.add(new ReaderSlice(docBase, maxDoc, readerIndex));\n      fields.add(f);\n      docBase += maxDoc;\n    }\n\n    Fields mergedFields = new MappedMultiFields(mergeState, \n                                                new MultiFields(fields.toArray(Fields.EMPTY_ARRAY),\n                                                                slices.toArray(ReaderSlice.EMPTY_ARRAY)));\n    write(mergedFields);\n  }\n\n","sourceOld":"  /** Merges in the fields from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  and maps around deleted documents, and calls {@link #write(Fields)}.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public void merge(MergeState mergeState) throws IOException {\n    final List<Fields> fields = new ArrayList<>();\n    final List<ReaderSlice> slices = new ArrayList<>();\n\n    int docBase = 0;\n\n    for(int readerIndex=0;readerIndex<mergeState.fieldsProducers.length;readerIndex++) {\n      final FieldsProducer f = mergeState.fieldsProducers[readerIndex];\n\n      final int maxDoc = mergeState.maxDocs[readerIndex];\n      if (f != null) {\n        f.checkIntegrity();\n        slices.add(new ReaderSlice(docBase, maxDoc, readerIndex));\n        fields.add(f);\n      }\n      docBase += maxDoc;\n    }\n\n    Fields mergedFields = new MappedMultiFields(mergeState, \n                                                new MultiFields(fields.toArray(Fields.EMPTY_ARRAY),\n                                                                slices.toArray(ReaderSlice.EMPTY_ARRAY)));\n    write(mergedFields);\n  }\n\n","bugFix":["2131047ecceac64b54ba70feec3d26bbd7e483d7","22a2e66dfda83847e80095b8693c660742ab3e9c"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"622a708571e534680618b3c5e0c28ac539a47776","date":1517406892,"type":5,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/FieldsConsumer#merge(MergeState,NormsProducer).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/FieldsConsumer#merge(MergeState).mjava","sourceNew":"  /** Merges in the fields from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  and maps around deleted documents, and calls {@link #write(Fields,NormsProducer)}.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public void merge(MergeState mergeState, NormsProducer norms) throws IOException {\n    final List<Fields> fields = new ArrayList<>();\n    final List<ReaderSlice> slices = new ArrayList<>();\n\n    int docBase = 0;\n\n    for(int readerIndex=0;readerIndex<mergeState.fieldsProducers.length;readerIndex++) {\n      final FieldsProducer f = mergeState.fieldsProducers[readerIndex];\n\n      final int maxDoc = mergeState.maxDocs[readerIndex];\n      f.checkIntegrity();\n      slices.add(new ReaderSlice(docBase, maxDoc, readerIndex));\n      fields.add(f);\n      docBase += maxDoc;\n    }\n\n    Fields mergedFields = new MappedMultiFields(mergeState, \n                                                new MultiFields(fields.toArray(Fields.EMPTY_ARRAY),\n                                                                slices.toArray(ReaderSlice.EMPTY_ARRAY)));\n    write(mergedFields, norms);\n  }\n\n","sourceOld":"  /** Merges in the fields from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  and maps around deleted documents, and calls {@link #write(Fields)}.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public void merge(MergeState mergeState) throws IOException {\n    final List<Fields> fields = new ArrayList<>();\n    final List<ReaderSlice> slices = new ArrayList<>();\n\n    int docBase = 0;\n\n    for(int readerIndex=0;readerIndex<mergeState.fieldsProducers.length;readerIndex++) {\n      final FieldsProducer f = mergeState.fieldsProducers[readerIndex];\n\n      final int maxDoc = mergeState.maxDocs[readerIndex];\n      f.checkIntegrity();\n      slices.add(new ReaderSlice(docBase, maxDoc, readerIndex));\n      fields.add(f);\n      docBase += maxDoc;\n    }\n\n    Fields mergedFields = new MappedMultiFields(mergeState, \n                                                new MultiFields(fields.toArray(Fields.EMPTY_ARRAY),\n                                                                slices.toArray(ReaderSlice.EMPTY_ARRAY)));\n    write(mergedFields);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"8028ab7a24273833d53d35eb160dba5b57283cf5":["9bb9a29a5e71a90295f175df8919802993142c9a"],"9bb9a29a5e71a90295f175df8919802993142c9a":["c9fb5f46e264daf5ba3860defe623a89d202dd87","2131047ecceac64b54ba70feec3d26bbd7e483d7"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"622a708571e534680618b3c5e0c28ac539a47776":["8028ab7a24273833d53d35eb160dba5b57283cf5"],"2131047ecceac64b54ba70feec3d26bbd7e483d7":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"22a2e66dfda83847e80095b8693c660742ab3e9c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["22a2e66dfda83847e80095b8693c660742ab3e9c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["622a708571e534680618b3c5e0c28ac539a47776"]},"commit2Childs":{"8028ab7a24273833d53d35eb160dba5b57283cf5":["622a708571e534680618b3c5e0c28ac539a47776"],"9bb9a29a5e71a90295f175df8919802993142c9a":["8028ab7a24273833d53d35eb160dba5b57283cf5"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["22a2e66dfda83847e80095b8693c660742ab3e9c"],"2131047ecceac64b54ba70feec3d26bbd7e483d7":["9bb9a29a5e71a90295f175df8919802993142c9a"],"622a708571e534680618b3c5e0c28ac539a47776":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"22a2e66dfda83847e80095b8693c660742ab3e9c":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["9bb9a29a5e71a90295f175df8919802993142c9a","2131047ecceac64b54ba70feec3d26bbd7e483d7"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}