{"path":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/TokenSources#getAnyTokenStream(IndexReader,int,String,Analyzer).mjava","commits":[{"id":"043c298cb215f13ba7b9b81d20760704e8f93d66","date":1107566743,"type":1,"author":"Erik Hatcher","isMerge":false,"pathNew":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/TokenSources#getAnyTokenStream(IndexReader,int,String,Analyzer).mjava","pathOld":"sandbox/contributions/highlighter/src/java/org/apache/lucene/search/highlight/TokenSources#getAnyTokenStream(IndexReader,int,String,Analyzer).mjava","sourceNew":"    /**\n     * A convenience method that tries a number of approaches to getting a token stream.\n     * The cost of finding there are no termVectors in the index is minimal (1000 invocations still \n     * registers 0 ms). So this \"lazy\" (flexible?) approach to coding is probably acceptable\n     * @param reader\n     * @param docId\n     * @param field\n     * @param analyzer\n     * @return null if field not stored correctly \n     * @throws IOException\n     */\n    public static TokenStream getAnyTokenStream(IndexReader reader,int docId, String field,Analyzer analyzer) throws IOException\n    {\n\t\tTokenStream ts=null;\n\n\t\tTermFreqVector tfv=(TermFreqVector) reader.getTermFreqVector(docId,field);\n\t\tif(tfv!=null)\n\t\t{\n\t\t    if(tfv instanceof TermPositionVector)\n\t\t    {\n\t\t        ts=getTokenStream((TermPositionVector) tfv);\n\t\t    }\n\t\t}\n\t\t//No token info stored so fall back to analyzing raw content\n\t\tif(ts==null)\n\t\t{\n\t\t    ts=getTokenStream(reader,docId,field,analyzer);\n\t\t}\n\t\treturn ts;\n    }\n\n","sourceOld":"    /**\n     * A convenience method that tries a number of approaches to getting a token stream.\n     * The cost of finding there are no termVectors in the index is minimal (1000 invocations still \n     * registers 0 ms). So this \"lazy\" (flexible?) approach to coding is probably acceptable\n     * @param reader\n     * @param docId\n     * @param field\n     * @param analyzer\n     * @return null if field not stored correctly \n     * @throws IOException\n     */\n    public static TokenStream getAnyTokenStream(IndexReader reader,int docId, String field,Analyzer analyzer) throws IOException\n    {\n\t\tTokenStream ts=null;\n\n\t\tTermFreqVector tfv=(TermFreqVector) reader.getTermFreqVector(docId,field);\n\t\tif(tfv!=null)\n\t\t{\n\t\t    if(tfv instanceof TermPositionVector)\n\t\t    {\n\t\t        ts=getTokenStream((TermPositionVector) tfv);\n\t\t    }\n\t\t}\n\t\t//No token info stored so fall back to analyzing raw content\n\t\tif(ts==null)\n\t\t{\n\t\t    ts=getTokenStream(reader,docId,field,analyzer);\n\t\t}\n\t\treturn ts;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ffdf794cee8d43eb612df752c592cef2dc3e75ae","date":1256465578,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/TokenSources#getAnyTokenStream(IndexReader,int,String,Analyzer).mjava","pathOld":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/TokenSources#getAnyTokenStream(IndexReader,int,String,Analyzer).mjava","sourceNew":"    /**\n     * A convenience method that tries a number of approaches to getting a token stream.\n     * The cost of finding there are no termVectors in the index is minimal (1000 invocations still \n     * registers 0 ms). So this \"lazy\" (flexible?) approach to coding is probably acceptable\n     * @param reader\n     * @param docId\n     * @param field\n     * @param analyzer\n     * @return null if field not stored correctly \n     * @throws IOException\n     */\n    public static TokenStream getAnyTokenStream(IndexReader reader,int docId, String field,Analyzer analyzer) throws IOException\n    {\n\t\tTokenStream ts=null;\n\n\t\tTermFreqVector tfv = reader.getTermFreqVector(docId,field);\n\t\tif(tfv!=null)\n\t\t{\n\t\t    if(tfv instanceof TermPositionVector)\n\t\t    {\n\t\t        ts=getTokenStream((TermPositionVector) tfv);\n\t\t    }\n\t\t}\n\t\t//No token info stored so fall back to analyzing raw content\n\t\tif(ts==null)\n\t\t{\n\t\t    ts=getTokenStream(reader,docId,field,analyzer);\n\t\t}\n\t\treturn ts;\n    }\n\n","sourceOld":"    /**\n     * A convenience method that tries a number of approaches to getting a token stream.\n     * The cost of finding there are no termVectors in the index is minimal (1000 invocations still \n     * registers 0 ms). So this \"lazy\" (flexible?) approach to coding is probably acceptable\n     * @param reader\n     * @param docId\n     * @param field\n     * @param analyzer\n     * @return null if field not stored correctly \n     * @throws IOException\n     */\n    public static TokenStream getAnyTokenStream(IndexReader reader,int docId, String field,Analyzer analyzer) throws IOException\n    {\n\t\tTokenStream ts=null;\n\n\t\tTermFreqVector tfv=(TermFreqVector) reader.getTermFreqVector(docId,field);\n\t\tif(tfv!=null)\n\t\t{\n\t\t    if(tfv instanceof TermPositionVector)\n\t\t    {\n\t\t        ts=getTokenStream((TermPositionVector) tfv);\n\t\t    }\n\t\t}\n\t\t//No token info stored so fall back to analyzing raw content\n\t\tif(ts==null)\n\t\t{\n\t\t    ts=getTokenStream(reader,docId,field,analyzer);\n\t\t}\n\t\treturn ts;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fafd002a407d38098f1f0edf4365f971102ae0ef","date":1262804916,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/TokenSources#getAnyTokenStream(IndexReader,int,String,Analyzer).mjava","pathOld":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/TokenSources#getAnyTokenStream(IndexReader,int,String,Analyzer).mjava","sourceNew":"  /**\n   * A convenience method that tries a number of approaches to getting a token\n   * stream. The cost of finding there are no termVectors in the index is\n   * minimal (1000 invocations still registers 0 ms). So this \"lazy\" (flexible?)\n   * approach to coding is probably acceptable\n   * \n   * @param reader\n   * @param docId\n   * @param field\n   * @param analyzer\n   * @return null if field not stored correctly\n   * @throws IOException\n   */\n  public static TokenStream getAnyTokenStream(IndexReader reader, int docId,\n      String field, Analyzer analyzer) throws IOException {\n    TokenStream ts = null;\n\n    TermFreqVector tfv = reader.getTermFreqVector(docId, field);\n    if (tfv != null) {\n      if (tfv instanceof TermPositionVector) {\n        ts = getTokenStream((TermPositionVector) tfv);\n      }\n    }\n    // No token info stored so fall back to analyzing raw content\n    if (ts == null) {\n      ts = getTokenStream(reader, docId, field, analyzer);\n    }\n    return ts;\n  }\n\n","sourceOld":"    /**\n     * A convenience method that tries a number of approaches to getting a token stream.\n     * The cost of finding there are no termVectors in the index is minimal (1000 invocations still \n     * registers 0 ms). So this \"lazy\" (flexible?) approach to coding is probably acceptable\n     * @param reader\n     * @param docId\n     * @param field\n     * @param analyzer\n     * @return null if field not stored correctly \n     * @throws IOException\n     */\n    public static TokenStream getAnyTokenStream(IndexReader reader,int docId, String field,Analyzer analyzer) throws IOException\n    {\n\t\tTokenStream ts=null;\n\n\t\tTermFreqVector tfv = reader.getTermFreqVector(docId,field);\n\t\tif(tfv!=null)\n\t\t{\n\t\t    if(tfv instanceof TermPositionVector)\n\t\t    {\n\t\t        ts=getTokenStream((TermPositionVector) tfv);\n\t\t    }\n\t\t}\n\t\t//No token info stored so fall back to analyzing raw content\n\t\tif(ts==null)\n\t\t{\n\t\t    ts=getTokenStream(reader,docId,field,analyzer);\n\t\t}\n\t\treturn ts;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/java/org/apache/lucene/search/highlight/TokenSources#getAnyTokenStream(IndexReader,int,String,Analyzer).mjava","pathOld":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/TokenSources#getAnyTokenStream(IndexReader,int,String,Analyzer).mjava","sourceNew":"  /**\n   * A convenience method that tries a number of approaches to getting a token\n   * stream. The cost of finding there are no termVectors in the index is\n   * minimal (1000 invocations still registers 0 ms). So this \"lazy\" (flexible?)\n   * approach to coding is probably acceptable\n   * \n   * @param reader\n   * @param docId\n   * @param field\n   * @param analyzer\n   * @return null if field not stored correctly\n   * @throws IOException\n   */\n  public static TokenStream getAnyTokenStream(IndexReader reader, int docId,\n      String field, Analyzer analyzer) throws IOException {\n    TokenStream ts = null;\n\n    TermFreqVector tfv = reader.getTermFreqVector(docId, field);\n    if (tfv != null) {\n      if (tfv instanceof TermPositionVector) {\n        ts = getTokenStream((TermPositionVector) tfv);\n      }\n    }\n    // No token info stored so fall back to analyzing raw content\n    if (ts == null) {\n      ts = getTokenStream(reader, docId, field, analyzer);\n    }\n    return ts;\n  }\n\n","sourceOld":"  /**\n   * A convenience method that tries a number of approaches to getting a token\n   * stream. The cost of finding there are no termVectors in the index is\n   * minimal (1000 invocations still registers 0 ms). So this \"lazy\" (flexible?)\n   * approach to coding is probably acceptable\n   * \n   * @param reader\n   * @param docId\n   * @param field\n   * @param analyzer\n   * @return null if field not stored correctly\n   * @throws IOException\n   */\n  public static TokenStream getAnyTokenStream(IndexReader reader, int docId,\n      String field, Analyzer analyzer) throws IOException {\n    TokenStream ts = null;\n\n    TermFreqVector tfv = reader.getTermFreqVector(docId, field);\n    if (tfv != null) {\n      if (tfv instanceof TermPositionVector) {\n        ts = getTokenStream((TermPositionVector) tfv);\n      }\n    }\n    // No token info stored so fall back to analyzing raw content\n    if (ts == null) {\n      ts = getTokenStream(reader, docId, field, analyzer);\n    }\n    return ts;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"ffdf794cee8d43eb612df752c592cef2dc3e75ae":["043c298cb215f13ba7b9b81d20760704e8f93d66"],"043c298cb215f13ba7b9b81d20760704e8f93d66":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"fafd002a407d38098f1f0edf4365f971102ae0ef":["ffdf794cee8d43eb612df752c592cef2dc3e75ae"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["fafd002a407d38098f1f0edf4365f971102ae0ef"]},"commit2Childs":{"ffdf794cee8d43eb612df752c592cef2dc3e75ae":["fafd002a407d38098f1f0edf4365f971102ae0ef"],"043c298cb215f13ba7b9b81d20760704e8f93d66":["ffdf794cee8d43eb612df752c592cef2dc3e75ae"],"fafd002a407d38098f1f0edf4365f971102ae0ef":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["043c298cb215f13ba7b9b81d20760704e8f93d66"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}