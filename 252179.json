{"path":"contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/TrecDocMaker#getNextDocData().mjava","commits":[{"id":"e89c3770b3944888d0ff89f39fe010644f0d1854","date":1171287140,"type":0,"author":"Grant Ingersoll","isMerge":false,"pathNew":"contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/TrecDocMaker#getNextDocData().mjava","pathOld":"/dev/null","sourceNew":"  protected DocData getNextDocData() throws Exception {\r\n    if (reader==null) {\r\n      openNextFile();\r\n    }\r\n    // 1. skip until doc start\r\n    read(\"<DOC>\",null,false,false); \r\n    // 2. name\r\n    StringBuffer sb = read(\"<DOCNO>\",null,true,false);\r\n    String name = sb.substring(\"<DOCNO>\".length());\r\n    name = name.substring(0,name.indexOf(\"</DOCNO>\"))+\"_\"+iteration;\r\n    // 3. skip until doc header\r\n    read(\"<DOCHDR>\",null,false,false); \r\n    // 4. date\r\n    sb = read(\"Date: \",null,true,false);\r\n    String dateStr = sb.substring(\"Date: \".length());\r\n    // 5. skip until end of doc header\r\n    read(\"</DOCHDR>\",null,false,false); \r\n    // 6. collect until end of doc\r\n    sb = read(\"</DOC>\",null,false,true);\r\n    // this is the next document, so parse it  \r\n    HTMLParser p = new HTMLParser(new StringReader(sb.toString()));\r\n    // title\r\n    String title = p.getTitle();\r\n    // properties \r\n    Properties props = p.getMetaTags(); \r\n    // body\r\n    Reader r = p.getReader();\r\n    char c[] = new char[1024];\r\n    StringBuffer bodyBuf = new StringBuffer();\r\n    int n;\r\n    while ((n = r.read(c)) >= 0) {\r\n      if (n>0) {\r\n        bodyBuf.append(c,0,n);\r\n      }\r\n    }\r\n    addBytes(bodyBuf.length());\r\n    \r\n    DocData dd = new DocData();\r\n    \r\n    dd.date = dateFormat.parse(dateStr.trim());\r\n    dd.name = name;\r\n    dd.title = title;\r\n    dd.body = bodyBuf.toString();\r\n    dd.props = props;\r\n    return dd;\r\n  }\r\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c55a660bceaf72068ba1fbf6856388430c0a7334","date":1174007816,"type":3,"author":"Doron Cohen","isMerge":false,"pathNew":"contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/TrecDocMaker#getNextDocData().mjava","pathOld":"contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/TrecDocMaker#getNextDocData().mjava","sourceNew":"  protected DocData getNextDocData() throws Exception {\r\n    if (reader==null) {\r\n      openNextFile();\r\n    }\r\n    // 1. skip until doc start\r\n    read(\"<DOC>\",null,false,false); \r\n    // 2. name\r\n    StringBuffer sb = read(\"<DOCNO>\",null,true,false);\r\n    String name = sb.substring(\"<DOCNO>\".length());\r\n    name = name.substring(0,name.indexOf(\"</DOCNO>\"))+\"_\"+iteration;\r\n    // 3. skip until doc header\r\n    read(\"<DOCHDR>\",null,false,false); \r\n    // 4. date\r\n    sb = read(\"Date: \",null,true,false);\r\n    String dateStr = sb.substring(\"Date: \".length());\r\n    // 5. skip until end of doc header\r\n    read(\"</DOCHDR>\",null,false,false); \r\n    // 6. collect until end of doc\r\n    sb = read(\"</DOC>\",null,false,true);\r\n    // this is the next document, so parse it \r\n    // TODO use a more robust html parser (current one aborts parsing quite easily). \r\n    HTMLParser p = new HTMLParser(new StringReader(sb.toString()));\r\n    // title\r\n    String title = p.getTitle();\r\n    // properties \r\n    Properties props = p.getMetaTags(); \r\n    // body\r\n    Reader r = p.getReader();\r\n    char c[] = new char[1024];\r\n    StringBuffer bodyBuf = new StringBuffer();\r\n    int n;\r\n    while ((n = r.read(c)) >= 0) {\r\n      if (n>0) {\r\n        bodyBuf.append(c,0,n);\r\n      }\r\n    }\r\n    r.close();\r\n    addBytes(bodyBuf.length());\r\n    \r\n    DocData dd = new DocData();\r\n\r\n    try {\r\n      dd.date = dateFormat.parse(dateStr.trim());\r\n    } catch (ParseException e) {\r\n      // do not fail test just because a date could not be parsed\r\n      System.out.println(\"ignoring date parse exception (assigning 'now') for: \"+dateStr);\r\n      dd.date = new Date(); // now \r\n    }\r\n    dd.name = name;\r\n    dd.title = title;\r\n    dd.body = bodyBuf.toString();\r\n    dd.props = props;\r\n    return dd;\r\n  }\r\n\n","sourceOld":"  protected DocData getNextDocData() throws Exception {\r\n    if (reader==null) {\r\n      openNextFile();\r\n    }\r\n    // 1. skip until doc start\r\n    read(\"<DOC>\",null,false,false); \r\n    // 2. name\r\n    StringBuffer sb = read(\"<DOCNO>\",null,true,false);\r\n    String name = sb.substring(\"<DOCNO>\".length());\r\n    name = name.substring(0,name.indexOf(\"</DOCNO>\"))+\"_\"+iteration;\r\n    // 3. skip until doc header\r\n    read(\"<DOCHDR>\",null,false,false); \r\n    // 4. date\r\n    sb = read(\"Date: \",null,true,false);\r\n    String dateStr = sb.substring(\"Date: \".length());\r\n    // 5. skip until end of doc header\r\n    read(\"</DOCHDR>\",null,false,false); \r\n    // 6. collect until end of doc\r\n    sb = read(\"</DOC>\",null,false,true);\r\n    // this is the next document, so parse it  \r\n    HTMLParser p = new HTMLParser(new StringReader(sb.toString()));\r\n    // title\r\n    String title = p.getTitle();\r\n    // properties \r\n    Properties props = p.getMetaTags(); \r\n    // body\r\n    Reader r = p.getReader();\r\n    char c[] = new char[1024];\r\n    StringBuffer bodyBuf = new StringBuffer();\r\n    int n;\r\n    while ((n = r.read(c)) >= 0) {\r\n      if (n>0) {\r\n        bodyBuf.append(c,0,n);\r\n      }\r\n    }\r\n    addBytes(bodyBuf.length());\r\n    \r\n    DocData dd = new DocData();\r\n    \r\n    dd.date = dateFormat.parse(dateStr.trim());\r\n    dd.name = name;\r\n    dd.title = title;\r\n    dd.body = bodyBuf.toString();\r\n    dd.props = props;\r\n    return dd;\r\n  }\r\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"81573e29e6e5db648330b225c60d44b1c3eb388e","date":1174927593,"type":3,"author":"Doron Cohen","isMerge":false,"pathNew":"contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/TrecDocMaker#getNextDocData().mjava","pathOld":"contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/TrecDocMaker#getNextDocData().mjava","sourceNew":"  protected DocData getNextDocData() throws NoMoreDataException, Exception {\r\n    if (reader==null) {\r\n      openNextFile();\r\n    }\r\n    // 1. skip until doc start\r\n    read(\"<DOC>\",null,false,false); \r\n    // 2. name\r\n    StringBuffer sb = read(\"<DOCNO>\",null,true,false);\r\n    String name = sb.substring(\"<DOCNO>\".length());\r\n    name = name.substring(0,name.indexOf(\"</DOCNO>\"))+\"_\"+iteration;\r\n    // 3. skip until doc header\r\n    read(\"<DOCHDR>\",null,false,false); \r\n    // 4. date\r\n    sb = read(\"Date: \",null,true,false);\r\n    String dateStr = sb.substring(\"Date: \".length());\r\n    // 5. skip until end of doc header\r\n    read(\"</DOCHDR>\",null,false,false); \r\n    // 6. collect until end of doc\r\n    sb = read(\"</DOC>\",null,false,true);\r\n    // this is the next document, so parse it \r\n    Date date = parseDate(dateStr);\r\n    HTMLParser p = getHtmlParser();\r\n    DocData docData = p.parse(name, date, sb, dateFormat[0]);\r\n    addBytes(sb.length()); // count char length of parsed html text (larger than the plain doc body text). \r\n    \r\n    return docData;\r\n  }\r\n\n","sourceOld":"  protected DocData getNextDocData() throws Exception {\r\n    if (reader==null) {\r\n      openNextFile();\r\n    }\r\n    // 1. skip until doc start\r\n    read(\"<DOC>\",null,false,false); \r\n    // 2. name\r\n    StringBuffer sb = read(\"<DOCNO>\",null,true,false);\r\n    String name = sb.substring(\"<DOCNO>\".length());\r\n    name = name.substring(0,name.indexOf(\"</DOCNO>\"))+\"_\"+iteration;\r\n    // 3. skip until doc header\r\n    read(\"<DOCHDR>\",null,false,false); \r\n    // 4. date\r\n    sb = read(\"Date: \",null,true,false);\r\n    String dateStr = sb.substring(\"Date: \".length());\r\n    // 5. skip until end of doc header\r\n    read(\"</DOCHDR>\",null,false,false); \r\n    // 6. collect until end of doc\r\n    sb = read(\"</DOC>\",null,false,true);\r\n    // this is the next document, so parse it \r\n    // TODO use a more robust html parser (current one aborts parsing quite easily). \r\n    HTMLParser p = new HTMLParser(new StringReader(sb.toString()));\r\n    // title\r\n    String title = p.getTitle();\r\n    // properties \r\n    Properties props = p.getMetaTags(); \r\n    // body\r\n    Reader r = p.getReader();\r\n    char c[] = new char[1024];\r\n    StringBuffer bodyBuf = new StringBuffer();\r\n    int n;\r\n    while ((n = r.read(c)) >= 0) {\r\n      if (n>0) {\r\n        bodyBuf.append(c,0,n);\r\n      }\r\n    }\r\n    r.close();\r\n    addBytes(bodyBuf.length());\r\n    \r\n    DocData dd = new DocData();\r\n\r\n    try {\r\n      dd.date = dateFormat.parse(dateStr.trim());\r\n    } catch (ParseException e) {\r\n      // do not fail test just because a date could not be parsed\r\n      System.out.println(\"ignoring date parse exception (assigning 'now') for: \"+dateStr);\r\n      dd.date = new Date(); // now \r\n    }\r\n    dd.name = name;\r\n    dd.title = title;\r\n    dd.body = bodyBuf.toString();\r\n    dd.props = props;\r\n    return dd;\r\n  }\r\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3738fa43eaa87dc7b393fe98b04cde1019e20bac","date":1175557034,"type":3,"author":"Otis Gospodnetic","isMerge":false,"pathNew":"contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/TrecDocMaker#getNextDocData().mjava","pathOld":"contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/TrecDocMaker#getNextDocData().mjava","sourceNew":"  protected DocData getNextDocData() throws NoMoreDataException, Exception {\n    if (reader==null) {\n      openNextFile();\n    }\n    // 1. skip until doc start\n    read(\"<DOC>\",null,false,false); \n    // 2. name\n    StringBuffer sb = read(\"<DOCNO>\",null,true,false);\n    String name = sb.substring(\"<DOCNO>\".length());\n    name = name.substring(0,name.indexOf(\"</DOCNO>\"))+\"_\"+iteration;\n    // 3. skip until doc header\n    read(\"<DOCHDR>\",null,false,false); \n    // 4. date\n    sb = read(\"Date: \",null,true,false);\n    String dateStr = sb.substring(\"Date: \".length());\n    // 5. skip until end of doc header\n    read(\"</DOCHDR>\",null,false,false); \n    // 6. collect until end of doc\n    sb = read(\"</DOC>\",null,false,true);\n    // this is the next document, so parse it \n    Date date = parseDate(dateStr);\n    HTMLParser p = getHtmlParser();\n    DocData docData = p.parse(name, date, sb, dateFormat[0]);\n    addBytes(sb.length()); // count char length of parsed html text (larger than the plain doc body text). \n    \n    return docData;\n  }\n\n","sourceOld":"  protected DocData getNextDocData() throws NoMoreDataException, Exception {\r\n    if (reader==null) {\r\n      openNextFile();\r\n    }\r\n    // 1. skip until doc start\r\n    read(\"<DOC>\",null,false,false); \r\n    // 2. name\r\n    StringBuffer sb = read(\"<DOCNO>\",null,true,false);\r\n    String name = sb.substring(\"<DOCNO>\".length());\r\n    name = name.substring(0,name.indexOf(\"</DOCNO>\"))+\"_\"+iteration;\r\n    // 3. skip until doc header\r\n    read(\"<DOCHDR>\",null,false,false); \r\n    // 4. date\r\n    sb = read(\"Date: \",null,true,false);\r\n    String dateStr = sb.substring(\"Date: \".length());\r\n    // 5. skip until end of doc header\r\n    read(\"</DOCHDR>\",null,false,false); \r\n    // 6. collect until end of doc\r\n    sb = read(\"</DOC>\",null,false,true);\r\n    // this is the next document, so parse it \r\n    Date date = parseDate(dateStr);\r\n    HTMLParser p = getHtmlParser();\r\n    DocData docData = p.parse(name, date, sb, dateFormat[0]);\r\n    addBytes(sb.length()); // count char length of parsed html text (larger than the plain doc body text). \r\n    \r\n    return docData;\r\n  }\r\n\n","bugFix":null,"bugIntro":["87c64a12419171222386231ce507096ac851b3cd","f58dbed2db5b1fe7e0910a67b4d5640eb60dfe4e"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"87c64a12419171222386231ce507096ac851b3cd","date":1182882441,"type":3,"author":"Doron Cohen","isMerge":false,"pathNew":"contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/TrecDocMaker#getNextDocData().mjava","pathOld":"contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/TrecDocMaker#getNextDocData().mjava","sourceNew":"  protected DocData getNextDocData() throws NoMoreDataException, Exception {\n    if (reader==null) {\n      openNextFile();\n    }\n    // 1. skip until doc start\n    read(\"<DOC>\",null,false,false); \n    // 2. name\n    StringBuffer sb = read(\"<DOCNO>\",null,true,false);\n    String name = sb.substring(\"<DOCNO>\".length());\n    name = name.substring(0,name.indexOf(\"</DOCNO>\"))+\"_\"+iteration;\n    // 3. skip until doc header\n    read(\"<DOCHDR>\",null,false,false); \n    // 4. date\n    sb = read(\"Date: \",null,true,false);\n    String dateStr = sb.substring(\"Date: \".length());\n    // 5. skip until end of doc header\n    read(\"</DOCHDR>\",null,false,false); \n    // 6. collect until end of doc\n    sb = read(\"</DOC>\",null,false,true);\n    // this is the next document, so parse it \n    Date date = parseDate(dateStr);\n    HTMLParser p = getHtmlParser();\n    DocData docData = p.parse(name, date, sb, getDateFormat(0));\n    addBytes(sb.length()); // count char length of parsed html text (larger than the plain doc body text). \n    \n    return docData;\n  }\n\n","sourceOld":"  protected DocData getNextDocData() throws NoMoreDataException, Exception {\n    if (reader==null) {\n      openNextFile();\n    }\n    // 1. skip until doc start\n    read(\"<DOC>\",null,false,false); \n    // 2. name\n    StringBuffer sb = read(\"<DOCNO>\",null,true,false);\n    String name = sb.substring(\"<DOCNO>\".length());\n    name = name.substring(0,name.indexOf(\"</DOCNO>\"))+\"_\"+iteration;\n    // 3. skip until doc header\n    read(\"<DOCHDR>\",null,false,false); \n    // 4. date\n    sb = read(\"Date: \",null,true,false);\n    String dateStr = sb.substring(\"Date: \".length());\n    // 5. skip until end of doc header\n    read(\"</DOCHDR>\",null,false,false); \n    // 6. collect until end of doc\n    sb = read(\"</DOC>\",null,false,true);\n    // this is the next document, so parse it \n    Date date = parseDate(dateStr);\n    HTMLParser p = getHtmlParser();\n    DocData docData = p.parse(name, date, sb, dateFormat[0]);\n    addBytes(sb.length()); // count char length of parsed html text (larger than the plain doc body text). \n    \n    return docData;\n  }\n\n","bugFix":["3738fa43eaa87dc7b393fe98b04cde1019e20bac"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9e306aa2b55906fefcef7d8e864c24a744e616dd","date":1197530818,"type":3,"author":"Doron Cohen","isMerge":false,"pathNew":"contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/TrecDocMaker#getNextDocData().mjava","pathOld":"contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/TrecDocMaker#getNextDocData().mjava","sourceNew":"  protected synchronized DocData getNextDocData() throws NoMoreDataException, Exception {\n    if (reader==null) {\n      openNextFile();\n    }\n    // 1. skip until doc start\n    read(\"<DOC>\",null,false,false); \n    // 2. name\n    StringBuffer sb = read(\"<DOCNO>\",null,true,false);\n    String name = sb.substring(\"<DOCNO>\".length());\n    name = name.substring(0,name.indexOf(\"</DOCNO>\"))+\"_\"+iteration;\n    // 3. skip until doc header\n    read(\"<DOCHDR>\",null,false,false); \n    // 4. date\n    sb = read(\"Date: \",null,true,false);\n    String dateStr = sb.substring(\"Date: \".length());\n    // 5. skip until end of doc header\n    read(\"</DOCHDR>\",null,false,false); \n    // 6. collect until end of doc\n    sb = read(\"</DOC>\",null,false,true);\n    // this is the next document, so parse it \n    Date date = parseDate(dateStr);\n    HTMLParser p = getHtmlParser();\n    DocData docData = p.parse(name, date, sb, getDateFormat(0));\n    addBytes(sb.length()); // count char length of parsed html text (larger than the plain doc body text). \n    \n    return docData;\n  }\n\n","sourceOld":"  protected DocData getNextDocData() throws NoMoreDataException, Exception {\n    if (reader==null) {\n      openNextFile();\n    }\n    // 1. skip until doc start\n    read(\"<DOC>\",null,false,false); \n    // 2. name\n    StringBuffer sb = read(\"<DOCNO>\",null,true,false);\n    String name = sb.substring(\"<DOCNO>\".length());\n    name = name.substring(0,name.indexOf(\"</DOCNO>\"))+\"_\"+iteration;\n    // 3. skip until doc header\n    read(\"<DOCHDR>\",null,false,false); \n    // 4. date\n    sb = read(\"Date: \",null,true,false);\n    String dateStr = sb.substring(\"Date: \".length());\n    // 5. skip until end of doc header\n    read(\"</DOCHDR>\",null,false,false); \n    // 6. collect until end of doc\n    sb = read(\"</DOC>\",null,false,true);\n    // this is the next document, so parse it \n    Date date = parseDate(dateStr);\n    HTMLParser p = getHtmlParser();\n    DocData docData = p.parse(name, date, sb, getDateFormat(0));\n    addBytes(sb.length()); // count char length of parsed html text (larger than the plain doc body text). \n    \n    return docData;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f58dbed2db5b1fe7e0910a67b4d5640eb60dfe4e","date":1231760243,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/TrecDocMaker#getNextDocData().mjava","pathOld":"contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/TrecDocMaker#getNextDocData().mjava","sourceNew":"  protected synchronized DocData getNextDocData() throws NoMoreDataException, Exception {\n    if (reader==null) {\n      openNextFile();\n    }\n    // 1. skip until doc start\n    read(DOC,null,false,false,null); \n    // 2. name\n    StringBuffer sb = read(DOCNO,null,true,false,null);\n    String name = sb.substring(DOCNO.length(), sb.indexOf(TERM_DOCNO, DOCNO.length()));\n    name = name + \"_\" + iteration;\n    // 3. skip until doc header\n    read(DOCHDR,null,false,false,null);\n    boolean findTerminatingDocHdr = false;\n    // 4. date\n    sb = read(DATE,null,true,false,TERM_DOCHDR);\n    String dateStr = null;\n    if (sb.length() != 0) {\n      // Date found.\n      dateStr = sb.substring(DATE.length());\n      findTerminatingDocHdr = true;\n    }\n\n    // 5. skip until end of doc header\n    if (findTerminatingDocHdr) {\n      read(TERM_DOCHDR,null,false,false,null); \n    }\n    // 6. collect until end of doc\n    sb = read(TERM_DOC,null,false,true,null);\n    // this is the next document, so parse it \n    Date date = dateStr != null ? parseDate(dateStr) : null;\n    HTMLParser p = getHtmlParser();\n    DocData docData = p.parse(name, date, sb, getDateFormat(0));\n    addBytes(sb.length()); // count char length of parsed html text (larger than the plain doc body text). \n    \n    return docData;\n  }\n\n","sourceOld":"  protected synchronized DocData getNextDocData() throws NoMoreDataException, Exception {\n    if (reader==null) {\n      openNextFile();\n    }\n    // 1. skip until doc start\n    read(\"<DOC>\",null,false,false); \n    // 2. name\n    StringBuffer sb = read(\"<DOCNO>\",null,true,false);\n    String name = sb.substring(\"<DOCNO>\".length());\n    name = name.substring(0,name.indexOf(\"</DOCNO>\"))+\"_\"+iteration;\n    // 3. skip until doc header\n    read(\"<DOCHDR>\",null,false,false); \n    // 4. date\n    sb = read(\"Date: \",null,true,false);\n    String dateStr = sb.substring(\"Date: \".length());\n    // 5. skip until end of doc header\n    read(\"</DOCHDR>\",null,false,false); \n    // 6. collect until end of doc\n    sb = read(\"</DOC>\",null,false,true);\n    // this is the next document, so parse it \n    Date date = parseDate(dateStr);\n    HTMLParser p = getHtmlParser();\n    DocData docData = p.parse(name, date, sb, getDateFormat(0));\n    addBytes(sb.length()); // count char length of parsed html text (larger than the plain doc body text). \n    \n    return docData;\n  }\n\n","bugFix":["3738fa43eaa87dc7b393fe98b04cde1019e20bac"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6944b9fa6d8ef96b83ae2d3a4332d03b3857355b","date":1245355139,"type":4,"author":"Mark Robert Miller","isMerge":false,"pathNew":"/dev/null","pathOld":"contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/TrecDocMaker#getNextDocData().mjava","sourceNew":null,"sourceOld":"  protected synchronized DocData getNextDocData() throws NoMoreDataException, Exception {\n    if (reader==null) {\n      openNextFile();\n    }\n    // 1. skip until doc start\n    read(DOC,null,false,false,null); \n    // 2. name\n    StringBuffer sb = read(DOCNO,null,true,false,null);\n    String name = sb.substring(DOCNO.length(), sb.indexOf(TERM_DOCNO, DOCNO.length()));\n    name = name + \"_\" + iteration;\n    // 3. skip until doc header\n    read(DOCHDR,null,false,false,null);\n    boolean findTerminatingDocHdr = false;\n    // 4. date\n    sb = read(DATE,null,true,false,TERM_DOCHDR);\n    String dateStr = null;\n    if (sb.length() != 0) {\n      // Date found.\n      dateStr = sb.substring(DATE.length());\n      findTerminatingDocHdr = true;\n    }\n\n    // 5. skip until end of doc header\n    if (findTerminatingDocHdr) {\n      read(TERM_DOCHDR,null,false,false,null); \n    }\n    // 6. collect until end of doc\n    sb = read(TERM_DOC,null,false,true,null);\n    // this is the next document, so parse it \n    Date date = dateStr != null ? parseDate(dateStr) : null;\n    HTMLParser p = getHtmlParser();\n    DocData docData = p.parse(name, date, sb, getDateFormat(0));\n    addBytes(sb.length()); // count char length of parsed html text (larger than the plain doc body text). \n    \n    return docData;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"9e306aa2b55906fefcef7d8e864c24a744e616dd":["87c64a12419171222386231ce507096ac851b3cd"],"87c64a12419171222386231ce507096ac851b3cd":["3738fa43eaa87dc7b393fe98b04cde1019e20bac"],"6944b9fa6d8ef96b83ae2d3a4332d03b3857355b":["f58dbed2db5b1fe7e0910a67b4d5640eb60dfe4e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3738fa43eaa87dc7b393fe98b04cde1019e20bac":["81573e29e6e5db648330b225c60d44b1c3eb388e"],"e89c3770b3944888d0ff89f39fe010644f0d1854":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"f58dbed2db5b1fe7e0910a67b4d5640eb60dfe4e":["9e306aa2b55906fefcef7d8e864c24a744e616dd"],"c55a660bceaf72068ba1fbf6856388430c0a7334":["e89c3770b3944888d0ff89f39fe010644f0d1854"],"81573e29e6e5db648330b225c60d44b1c3eb388e":["c55a660bceaf72068ba1fbf6856388430c0a7334"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["6944b9fa6d8ef96b83ae2d3a4332d03b3857355b"]},"commit2Childs":{"9e306aa2b55906fefcef7d8e864c24a744e616dd":["f58dbed2db5b1fe7e0910a67b4d5640eb60dfe4e"],"87c64a12419171222386231ce507096ac851b3cd":["9e306aa2b55906fefcef7d8e864c24a744e616dd"],"6944b9fa6d8ef96b83ae2d3a4332d03b3857355b":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["e89c3770b3944888d0ff89f39fe010644f0d1854"],"3738fa43eaa87dc7b393fe98b04cde1019e20bac":["87c64a12419171222386231ce507096ac851b3cd"],"e89c3770b3944888d0ff89f39fe010644f0d1854":["c55a660bceaf72068ba1fbf6856388430c0a7334"],"f58dbed2db5b1fe7e0910a67b4d5640eb60dfe4e":["6944b9fa6d8ef96b83ae2d3a4332d03b3857355b"],"c55a660bceaf72068ba1fbf6856388430c0a7334":["81573e29e6e5db648330b225c60d44b1c3eb388e"],"81573e29e6e5db648330b225c60d44b1c3eb388e":["3738fa43eaa87dc7b393fe98b04cde1019e20bac"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}