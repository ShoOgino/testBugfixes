{"path":"solr/core/src/java/org/apache/solr/update/HdfsTransactionLog.HDFSReverseReader#next().mjava","commits":[{"id":"849494cf2f3a96af5c8c84995108ddd8456fcd04","date":1372277913,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/HdfsTransactionLog.HDFSReverseReader#next().mjava","pathOld":"/dev/null","sourceNew":"    /** Returns the next object from the log, or null if none available.\n     *\n     * @return The log record, or null if EOF\n     * @throws IOException If there is a low-level I/O error.\n     */\n    public Object next() throws IOException {\n      if (prevPos <= 0) return null;\n\n      long endOfThisRecord = prevPos;\n\n      int thisLength = nextLength;\n\n      long recordStart = prevPos - thisLength;  // back up to the beginning of the next record\n      prevPos = recordStart - 4;  // back up 4 more to read the length of the next record\n\n      if (prevPos <= 0) return null;  // this record is the header\n\n      long bufferPos = fis.getBufferPos();\n      if (prevPos >= bufferPos) {\n        // nothing to do... we're within the current buffer\n      } else {\n        // Position buffer so that this record is at the end.\n        // For small records, this will cause subsequent calls to next() to be within the buffer.\n        long seekPos =  endOfThisRecord - fis.getBufferSize();\n        seekPos = Math.min(seekPos, prevPos); // seek to the start of the record if it's larger then the block size.\n        seekPos = Math.max(seekPos, 0);\n        fis.seek(seekPos);\n        fis.peek();  // cause buffer to be filled\n      }\n\n      fis.seek(prevPos);\n      nextLength = fis.readInt();     // this is the length of the *next* record (i.e. closer to the beginning)\n\n      // TODO: optionally skip document data\n      Object o = codec.readVal(fis);\n\n      // assert fis.position() == prevPos + 4 + thisLength;  // this is only true if we read all the data (and we currently skip reading SolrInputDocument\n      return o;\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"37a0f60745e53927c4c876cfe5b5a58170f0646c","date":1373994005,"type":0,"author":"Han Jiang","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/update/HdfsTransactionLog.HDFSReverseReader#next().mjava","pathOld":"/dev/null","sourceNew":"    /** Returns the next object from the log, or null if none available.\n     *\n     * @return The log record, or null if EOF\n     * @throws IOException If there is a low-level I/O error.\n     */\n    public Object next() throws IOException {\n      if (prevPos <= 0) return null;\n\n      long endOfThisRecord = prevPos;\n\n      int thisLength = nextLength;\n\n      long recordStart = prevPos - thisLength;  // back up to the beginning of the next record\n      prevPos = recordStart - 4;  // back up 4 more to read the length of the next record\n\n      if (prevPos <= 0) return null;  // this record is the header\n\n      long bufferPos = fis.getBufferPos();\n      if (prevPos >= bufferPos) {\n        // nothing to do... we're within the current buffer\n      } else {\n        // Position buffer so that this record is at the end.\n        // For small records, this will cause subsequent calls to next() to be within the buffer.\n        long seekPos =  endOfThisRecord - fis.getBufferSize();\n        seekPos = Math.min(seekPos, prevPos); // seek to the start of the record if it's larger then the block size.\n        seekPos = Math.max(seekPos, 0);\n        fis.seek(seekPos);\n        fis.peek();  // cause buffer to be filled\n      }\n\n      fis.seek(prevPos);\n      nextLength = fis.readInt();     // this is the length of the *next* record (i.e. closer to the beginning)\n\n      // TODO: optionally skip document data\n      Object o = codec.readVal(fis);\n\n      // assert fis.position() == prevPos + 4 + thisLength;  // this is only true if we read all the data (and we currently skip reading SolrInputDocument\n      return o;\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"849494cf2f3a96af5c8c84995108ddd8456fcd04":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","849494cf2f3a96af5c8c84995108ddd8456fcd04"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["849494cf2f3a96af5c8c84995108ddd8456fcd04"]},"commit2Childs":{"849494cf2f3a96af5c8c84995108ddd8456fcd04":["37a0f60745e53927c4c876cfe5b5a58170f0646c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["849494cf2f3a96af5c8c84995108ddd8456fcd04","37a0f60745e53927c4c876cfe5b5a58170f0646c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["37a0f60745e53927c4c876cfe5b5a58170f0646c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}