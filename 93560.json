{"path":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#splitByUniqueKeyTest().mjava","commits":[{"id":"6146c07c0dee1ae1e42926167acd127fed5ef59d","date":1516129420,"type":1,"author":"Varun Thacker","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#splitByUniqueKeyTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByUniqueKeyTest().mjava","sourceNew":"  private void splitByUniqueKeyTest() throws Exception {\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getSlice(SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    if (usually())  {\n      List<DocRouter.Range> ranges = router.partitionRange(4, shard1Range);\n      // 75% of range goes to shard1_0 and the rest to shard1_1\n      subRanges.add(new DocRouter.Range(ranges.get(0).min, ranges.get(2).max));\n      subRanges.add(ranges.get(3));\n    } else  {\n      subRanges = router.partitionRange(2, shard1Range);\n    }\n    final List<DocRouter.Range> ranges = subRanges;\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    del(\"*:*\");\n    for (int id = 0; id <= 100; id++) {\n      String shardKey = \"\" + (char)('a' + (id % 26)); // See comment in ShardRoutingTest for hash distribution\n      indexAndUpdateCount(router, ranges, docCounts, shardKey + \"!\" + String.valueOf(id), id);\n    }\n    commit();\n\n    Thread indexThread = new Thread() {\n      @Override\n      public void run() {\n        Random random = random();\n        int max = atLeast(random, 401);\n        int sleep = atLeast(random, 25);\n        log.info(\"SHARDSPLITTEST: Going to add \" + max + \" number of docs at 1 doc per \" + sleep + \"ms\");\n        Set<String> deleted = new HashSet<>();\n        for (int id = 101; id < max; id++) {\n          try {\n            indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n            Thread.sleep(sleep);\n            if (usually(random))  {\n              String delId = String.valueOf(random.nextInt(id - 101 + 1) + 101);\n              if (deleted.contains(delId))  continue;\n              try {\n                deleteAndUpdateCount(router, ranges, docCounts, delId);\n                deleted.add(delId);\n              } catch (Exception e) {\n                log.error(\"Exception while deleting docs\", e);\n              }\n            }\n          } catch (Exception e) {\n            log.error(\"Exception while adding doc id = \" + id, e);\n            // do not select this id for deletion ever\n            deleted.add(String.valueOf(id));\n          }\n        }\n      }\n    };\n    indexThread.start();\n\n    try {\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, subRanges, null);\n          log.info(\"Layout after split: \\n\");\n          printLayout();\n          break;\n        } catch (HttpSolrClient.RemoteSolrException e) {\n          if (e.code() != 500)  {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n    } finally {\n      try {\n        indexThread.join();\n      } catch (InterruptedException e) {\n        log.error(\"Indexing thread interrupted\", e);\n      }\n    }\n\n    waitForRecoveriesToFinish(true);\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n  }\n\n","sourceOld":"  private void splitByUniqueKeyTest() throws Exception {\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getSlice(SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    if (usually())  {\n      List<DocRouter.Range> ranges = router.partitionRange(4, shard1Range);\n      // 75% of range goes to shard1_0 and the rest to shard1_1\n      subRanges.add(new DocRouter.Range(ranges.get(0).min, ranges.get(2).max));\n      subRanges.add(ranges.get(3));\n    } else  {\n      subRanges = router.partitionRange(2, shard1Range);\n    }\n    final List<DocRouter.Range> ranges = subRanges;\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    del(\"*:*\");\n    for (int id = 0; id <= 100; id++) {\n      String shardKey = \"\" + (char)('a' + (id % 26)); // See comment in ShardRoutingTest for hash distribution\n      indexAndUpdateCount(router, ranges, docCounts, shardKey + \"!\" + String.valueOf(id), id);\n    }\n    commit();\n\n    Thread indexThread = new Thread() {\n      @Override\n      public void run() {\n        Random random = random();\n        int max = atLeast(random, 401);\n        int sleep = atLeast(random, 25);\n        log.info(\"SHARDSPLITTEST: Going to add \" + max + \" number of docs at 1 doc per \" + sleep + \"ms\");\n        Set<String> deleted = new HashSet<>();\n        for (int id = 101; id < max; id++) {\n          try {\n            indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n            Thread.sleep(sleep);\n            if (usually(random))  {\n              String delId = String.valueOf(random.nextInt(id - 101 + 1) + 101);\n              if (deleted.contains(delId))  continue;\n              try {\n                deleteAndUpdateCount(router, ranges, docCounts, delId);\n                deleted.add(delId);\n              } catch (Exception e) {\n                log.error(\"Exception while deleting docs\", e);\n              }\n            }\n          } catch (Exception e) {\n            log.error(\"Exception while adding doc id = \" + id, e);\n            // do not select this id for deletion ever\n            deleted.add(String.valueOf(id));\n          }\n        }\n      }\n    };\n    indexThread.start();\n\n    try {\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, subRanges, null);\n          log.info(\"Layout after split: \\n\");\n          printLayout();\n          break;\n        } catch (HttpSolrClient.RemoteSolrException e) {\n          if (e.code() != 500)  {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n    } finally {\n      try {\n        indexThread.join();\n      } catch (InterruptedException e) {\n        log.error(\"Indexing thread interrupted\", e);\n      }\n    }\n\n    waitForRecoveriesToFinish(true);\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b94236357aaa22b76c10629851fe4e376e0cea82","date":1516710914,"type":1,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#splitByUniqueKeyTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByUniqueKeyTest().mjava","sourceNew":"  private void splitByUniqueKeyTest() throws Exception {\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getSlice(SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    if (usually())  {\n      List<DocRouter.Range> ranges = router.partitionRange(4, shard1Range);\n      // 75% of range goes to shard1_0 and the rest to shard1_1\n      subRanges.add(new DocRouter.Range(ranges.get(0).min, ranges.get(2).max));\n      subRanges.add(ranges.get(3));\n    } else  {\n      subRanges = router.partitionRange(2, shard1Range);\n    }\n    final List<DocRouter.Range> ranges = subRanges;\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    del(\"*:*\");\n    for (int id = 0; id <= 100; id++) {\n      String shardKey = \"\" + (char)('a' + (id % 26)); // See comment in ShardRoutingTest for hash distribution\n      indexAndUpdateCount(router, ranges, docCounts, shardKey + \"!\" + String.valueOf(id), id);\n    }\n    commit();\n\n    Thread indexThread = new Thread() {\n      @Override\n      public void run() {\n        Random random = random();\n        int max = atLeast(random, 401);\n        int sleep = atLeast(random, 25);\n        log.info(\"SHARDSPLITTEST: Going to add \" + max + \" number of docs at 1 doc per \" + sleep + \"ms\");\n        Set<String> deleted = new HashSet<>();\n        for (int id = 101; id < max; id++) {\n          try {\n            indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n            Thread.sleep(sleep);\n            if (usually(random))  {\n              String delId = String.valueOf(random.nextInt(id - 101 + 1) + 101);\n              if (deleted.contains(delId))  continue;\n              try {\n                deleteAndUpdateCount(router, ranges, docCounts, delId);\n                deleted.add(delId);\n              } catch (Exception e) {\n                log.error(\"Exception while deleting docs\", e);\n              }\n            }\n          } catch (Exception e) {\n            log.error(\"Exception while adding doc id = \" + id, e);\n            // do not select this id for deletion ever\n            deleted.add(String.valueOf(id));\n          }\n        }\n      }\n    };\n    indexThread.start();\n\n    try {\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, subRanges, null);\n          log.info(\"Layout after split: \\n\");\n          printLayout();\n          break;\n        } catch (HttpSolrClient.RemoteSolrException e) {\n          if (e.code() != 500)  {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n    } finally {\n      try {\n        indexThread.join();\n      } catch (InterruptedException e) {\n        log.error(\"Indexing thread interrupted\", e);\n      }\n    }\n\n    waitForRecoveriesToFinish(true);\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n  }\n\n","sourceOld":"  private void splitByUniqueKeyTest() throws Exception {\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getSlice(SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    if (usually())  {\n      List<DocRouter.Range> ranges = router.partitionRange(4, shard1Range);\n      // 75% of range goes to shard1_0 and the rest to shard1_1\n      subRanges.add(new DocRouter.Range(ranges.get(0).min, ranges.get(2).max));\n      subRanges.add(ranges.get(3));\n    } else  {\n      subRanges = router.partitionRange(2, shard1Range);\n    }\n    final List<DocRouter.Range> ranges = subRanges;\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    del(\"*:*\");\n    for (int id = 0; id <= 100; id++) {\n      String shardKey = \"\" + (char)('a' + (id % 26)); // See comment in ShardRoutingTest for hash distribution\n      indexAndUpdateCount(router, ranges, docCounts, shardKey + \"!\" + String.valueOf(id), id);\n    }\n    commit();\n\n    Thread indexThread = new Thread() {\n      @Override\n      public void run() {\n        Random random = random();\n        int max = atLeast(random, 401);\n        int sleep = atLeast(random, 25);\n        log.info(\"SHARDSPLITTEST: Going to add \" + max + \" number of docs at 1 doc per \" + sleep + \"ms\");\n        Set<String> deleted = new HashSet<>();\n        for (int id = 101; id < max; id++) {\n          try {\n            indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n            Thread.sleep(sleep);\n            if (usually(random))  {\n              String delId = String.valueOf(random.nextInt(id - 101 + 1) + 101);\n              if (deleted.contains(delId))  continue;\n              try {\n                deleteAndUpdateCount(router, ranges, docCounts, delId);\n                deleted.add(delId);\n              } catch (Exception e) {\n                log.error(\"Exception while deleting docs\", e);\n              }\n            }\n          } catch (Exception e) {\n            log.error(\"Exception while adding doc id = \" + id, e);\n            // do not select this id for deletion ever\n            deleted.add(String.valueOf(id));\n          }\n        }\n      }\n    };\n    indexThread.start();\n\n    try {\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, subRanges, null);\n          log.info(\"Layout after split: \\n\");\n          printLayout();\n          break;\n        } catch (HttpSolrClient.RemoteSolrException e) {\n          if (e.code() != 500)  {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n    } finally {\n      try {\n        indexThread.join();\n      } catch (InterruptedException e) {\n        log.error(\"Indexing thread interrupted\", e);\n      }\n    }\n\n    waitForRecoveriesToFinish(true);\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"20c968c14aace7cf49843bf2c1fafc7fd3845659","date":1533133859,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#splitByUniqueKeyTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#splitByUniqueKeyTest().mjava","sourceNew":"  private void splitByUniqueKeyTest() throws Exception {\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getSlice(SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    if (usually())  {\n      List<DocRouter.Range> ranges = router.partitionRange(4, shard1Range);\n      // 75% of range goes to shard1_0 and the rest to shard1_1\n      subRanges.add(new DocRouter.Range(ranges.get(0).min, ranges.get(2).max));\n      subRanges.add(ranges.get(3));\n    } else  {\n      subRanges = router.partitionRange(2, shard1Range);\n    }\n    final List<DocRouter.Range> ranges = subRanges;\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    cloudClient.getZkStateReader().forceUpdateCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION);\n    clusterState = cloudClient.getZkStateReader().getClusterState();\n    log.debug(\"-- COLLECTION: {}\", clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION));\n    del(\"*:*\");\n    for (int id = 0; id <= 100; id++) {\n      String shardKey = \"\" + (char)('a' + (id % 26)); // See comment in ShardRoutingTest for hash distribution\n      indexAndUpdateCount(router, ranges, docCounts, shardKey + \"!\" + String.valueOf(id), id);\n    }\n    commit();\n\n    Thread indexThread = new Thread() {\n      @Override\n      public void run() {\n        Random random = random();\n        int max = atLeast(random, 401);\n        int sleep = atLeast(random, 25);\n        log.info(\"SHARDSPLITTEST: Going to add \" + max + \" number of docs at 1 doc per \" + sleep + \"ms\");\n        Set<String> deleted = new HashSet<>();\n        for (int id = 101; id < max; id++) {\n          try {\n            indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n            Thread.sleep(sleep);\n            if (usually(random))  {\n              String delId = String.valueOf(random.nextInt(id - 101 + 1) + 101);\n              if (deleted.contains(delId))  continue;\n              try {\n                deleteAndUpdateCount(router, ranges, docCounts, delId);\n                deleted.add(delId);\n              } catch (Exception e) {\n                log.error(\"Exception while deleting docs\", e);\n              }\n            }\n          } catch (Exception e) {\n            log.error(\"Exception while adding doc id = \" + id, e);\n            // do not select this id for deletion ever\n            deleted.add(String.valueOf(id));\n          }\n        }\n      }\n    };\n    indexThread.start();\n\n    try {\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, subRanges, null, false);\n          log.info(\"Layout after split: \\n\");\n          printLayout();\n          break;\n        } catch (HttpSolrClient.RemoteSolrException e) {\n          if (e.code() != 500)  {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n    } finally {\n      try {\n        indexThread.join();\n      } catch (InterruptedException e) {\n        log.error(\"Indexing thread interrupted\", e);\n      }\n    }\n\n    waitForRecoveriesToFinish(true);\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n  }\n\n","sourceOld":"  private void splitByUniqueKeyTest() throws Exception {\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getSlice(SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    if (usually())  {\n      List<DocRouter.Range> ranges = router.partitionRange(4, shard1Range);\n      // 75% of range goes to shard1_0 and the rest to shard1_1\n      subRanges.add(new DocRouter.Range(ranges.get(0).min, ranges.get(2).max));\n      subRanges.add(ranges.get(3));\n    } else  {\n      subRanges = router.partitionRange(2, shard1Range);\n    }\n    final List<DocRouter.Range> ranges = subRanges;\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    del(\"*:*\");\n    for (int id = 0; id <= 100; id++) {\n      String shardKey = \"\" + (char)('a' + (id % 26)); // See comment in ShardRoutingTest for hash distribution\n      indexAndUpdateCount(router, ranges, docCounts, shardKey + \"!\" + String.valueOf(id), id);\n    }\n    commit();\n\n    Thread indexThread = new Thread() {\n      @Override\n      public void run() {\n        Random random = random();\n        int max = atLeast(random, 401);\n        int sleep = atLeast(random, 25);\n        log.info(\"SHARDSPLITTEST: Going to add \" + max + \" number of docs at 1 doc per \" + sleep + \"ms\");\n        Set<String> deleted = new HashSet<>();\n        for (int id = 101; id < max; id++) {\n          try {\n            indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n            Thread.sleep(sleep);\n            if (usually(random))  {\n              String delId = String.valueOf(random.nextInt(id - 101 + 1) + 101);\n              if (deleted.contains(delId))  continue;\n              try {\n                deleteAndUpdateCount(router, ranges, docCounts, delId);\n                deleted.add(delId);\n              } catch (Exception e) {\n                log.error(\"Exception while deleting docs\", e);\n              }\n            }\n          } catch (Exception e) {\n            log.error(\"Exception while adding doc id = \" + id, e);\n            // do not select this id for deletion ever\n            deleted.add(String.valueOf(id));\n          }\n        }\n      }\n    };\n    indexThread.start();\n\n    try {\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, subRanges, null);\n          log.info(\"Layout after split: \\n\");\n          printLayout();\n          break;\n        } catch (HttpSolrClient.RemoteSolrException e) {\n          if (e.code() != 500)  {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n    } finally {\n      try {\n        indexThread.join();\n      } catch (InterruptedException e) {\n        log.error(\"Indexing thread interrupted\", e);\n      }\n    }\n\n    waitForRecoveriesToFinish(true);\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2ffc8d70d9f57a62a24c3dd15b66e353de935054","date":1533178472,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#splitByUniqueKeyTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#splitByUniqueKeyTest().mjava","sourceNew":"  private void splitByUniqueKeyTest() throws Exception {\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getSlice(SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    if (usually())  {\n      List<DocRouter.Range> ranges = router.partitionRange(4, shard1Range);\n      // 75% of range goes to shard1_0 and the rest to shard1_1\n      subRanges.add(new DocRouter.Range(ranges.get(0).min, ranges.get(2).max));\n      subRanges.add(ranges.get(3));\n    } else  {\n      subRanges = router.partitionRange(2, shard1Range);\n    }\n    final Set<String> documentIds = ConcurrentHashMap.newKeySet(1024);\n    final List<DocRouter.Range> ranges = subRanges;\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    cloudClient.getZkStateReader().forceUpdateCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION);\n    clusterState = cloudClient.getZkStateReader().getClusterState();\n    log.debug(\"-- COLLECTION: {}\", clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION));\n    del(\"*:*\");\n    for (int id = 0; id <= 100; id++) {\n      String shardKey = \"\" + (char)('a' + (id % 26)); // See comment in ShardRoutingTest for hash distribution\n      indexAndUpdateCount(router, ranges, docCounts, shardKey + \"!\" + String.valueOf(id), id, documentIds);\n    }\n    commit();\n\n    Thread indexThread = new Thread() {\n      @Override\n      public void run() {\n        Random random = random();\n        int max = atLeast(random, 401);\n        int sleep = atLeast(random, 25);\n        log.info(\"SHARDSPLITTEST: Going to add \" + max + \" number of docs at 1 doc per \" + sleep + \"ms\");\n        Set<String> deleted = new HashSet<>();\n        for (int id = 101; id < max; id++) {\n          try {\n            indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id, documentIds);\n            Thread.sleep(sleep);\n            if (usually(random))  {\n              String delId = String.valueOf(random.nextInt(id - 101 + 1) + 101);\n              if (deleted.contains(delId))  continue;\n              try {\n                deleteAndUpdateCount(router, ranges, docCounts, delId);\n                deleted.add(delId);\n                documentIds.remove(String.valueOf(delId));\n              } catch (Exception e) {\n                log.error(\"Exception while deleting docs\", e);\n              }\n            }\n          } catch (Exception e) {\n            log.error(\"Exception while adding doc id = \" + id, e);\n            // do not select this id for deletion ever\n            deleted.add(String.valueOf(id));\n          }\n        }\n      }\n    };\n    indexThread.start();\n\n    try {\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, subRanges, null, false);\n          log.info(\"Layout after split: \\n\");\n          printLayout();\n          break;\n        } catch (HttpSolrClient.RemoteSolrException e) {\n          if (e.code() != 500)  {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n    } finally {\n      try {\n        indexThread.join();\n      } catch (InterruptedException e) {\n        log.error(\"Indexing thread interrupted\", e);\n      }\n    }\n\n    waitForRecoveriesToFinish(true);\n    checkDocCountsAndShardStates(docCounts, numReplicas, documentIds);\n  }\n\n","sourceOld":"  private void splitByUniqueKeyTest() throws Exception {\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getSlice(SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    if (usually())  {\n      List<DocRouter.Range> ranges = router.partitionRange(4, shard1Range);\n      // 75% of range goes to shard1_0 and the rest to shard1_1\n      subRanges.add(new DocRouter.Range(ranges.get(0).min, ranges.get(2).max));\n      subRanges.add(ranges.get(3));\n    } else  {\n      subRanges = router.partitionRange(2, shard1Range);\n    }\n    final List<DocRouter.Range> ranges = subRanges;\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    cloudClient.getZkStateReader().forceUpdateCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION);\n    clusterState = cloudClient.getZkStateReader().getClusterState();\n    log.debug(\"-- COLLECTION: {}\", clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION));\n    del(\"*:*\");\n    for (int id = 0; id <= 100; id++) {\n      String shardKey = \"\" + (char)('a' + (id % 26)); // See comment in ShardRoutingTest for hash distribution\n      indexAndUpdateCount(router, ranges, docCounts, shardKey + \"!\" + String.valueOf(id), id);\n    }\n    commit();\n\n    Thread indexThread = new Thread() {\n      @Override\n      public void run() {\n        Random random = random();\n        int max = atLeast(random, 401);\n        int sleep = atLeast(random, 25);\n        log.info(\"SHARDSPLITTEST: Going to add \" + max + \" number of docs at 1 doc per \" + sleep + \"ms\");\n        Set<String> deleted = new HashSet<>();\n        for (int id = 101; id < max; id++) {\n          try {\n            indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n            Thread.sleep(sleep);\n            if (usually(random))  {\n              String delId = String.valueOf(random.nextInt(id - 101 + 1) + 101);\n              if (deleted.contains(delId))  continue;\n              try {\n                deleteAndUpdateCount(router, ranges, docCounts, delId);\n                deleted.add(delId);\n              } catch (Exception e) {\n                log.error(\"Exception while deleting docs\", e);\n              }\n            }\n          } catch (Exception e) {\n            log.error(\"Exception while adding doc id = \" + id, e);\n            // do not select this id for deletion ever\n            deleted.add(String.valueOf(id));\n          }\n        }\n      }\n    };\n    indexThread.start();\n\n    try {\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, subRanges, null, false);\n          log.info(\"Layout after split: \\n\");\n          printLayout();\n          break;\n        } catch (HttpSolrClient.RemoteSolrException e) {\n          if (e.code() != 500)  {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n    } finally {\n      try {\n        indexThread.join();\n      } catch (InterruptedException e) {\n        log.error(\"Indexing thread interrupted\", e);\n      }\n    }\n\n    waitForRecoveriesToFinish(true);\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a9be06eb0504cb6312c2a585959299e40280d9ba","date":1534415825,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#splitByUniqueKeyTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#splitByUniqueKeyTest().mjava","sourceNew":"  private void splitByUniqueKeyTest() throws Exception {\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getSlice(SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    if (usually())  {\n      List<DocRouter.Range> ranges = router.partitionRange(4, shard1Range);\n      // 75% of range goes to shard1_0 and the rest to shard1_1\n      subRanges.add(new DocRouter.Range(ranges.get(0).min, ranges.get(2).max));\n      subRanges.add(ranges.get(3));\n    } else  {\n      subRanges = router.partitionRange(2, shard1Range);\n    }\n    final Set<String> documentIds = ConcurrentHashMap.newKeySet(1024);\n    final List<DocRouter.Range> ranges = subRanges;\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    cloudClient.getZkStateReader().forceUpdateCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION);\n    clusterState = cloudClient.getZkStateReader().getClusterState();\n    log.debug(\"-- COLLECTION: {}\", clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION));\n    del(\"*:*\");\n    for (int id = 0; id <= 100; id++) {\n      String shardKey = \"\" + (char)('a' + (id % 26)); // See comment in ShardRoutingTest for hash distribution\n      indexAndUpdateCount(router, ranges, docCounts, shardKey + \"!\" + String.valueOf(id), id, documentIds);\n    }\n    commit();\n\n    Thread indexThread = new Thread(() -> {\n      Random random = random();\n      int max = atLeast(random, 401);\n      int sleep = atLeast(random, 25);\n      log.info(\"SHARDSPLITTEST: Going to add \" + max + \" number of docs at 1 doc per \" + sleep + \"ms\");\n      Set<String> deleted = new HashSet<>();\n      for (int id = 101; id < max; id++) {\n        try {\n          indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id, documentIds);\n          Thread.sleep(sleep);\n          if (usually(random))  {\n            String delId = String.valueOf(random.nextInt(id - 101 + 1) + 101);\n            if (deleted.contains(delId))  continue;\n            try {\n              deleteAndUpdateCount(router, ranges, docCounts, delId);\n              deleted.add(delId);\n              documentIds.remove(String.valueOf(delId));\n            } catch (Exception e) {\n              log.error(\"Exception while deleting docs\", e);\n            }\n          }\n        } catch (Exception e) {\n          log.error(\"Exception while adding doc id = \" + id, e);\n          // do not select this id for deletion ever\n          deleted.add(String.valueOf(id));\n        }\n      }\n    });\n    indexThread.start();\n\n    try {\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, subRanges, null, false);\n          log.info(\"Layout after split: \\n\");\n          printLayout();\n          break;\n        } catch (HttpSolrClient.RemoteSolrException e) {\n          if (e.code() != 500)  {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n    } finally {\n      try {\n        indexThread.join();\n      } catch (InterruptedException e) {\n        log.error(\"Indexing thread interrupted\", e);\n      }\n    }\n\n    waitForRecoveriesToFinish(true);\n    checkDocCountsAndShardStates(docCounts, numReplicas, documentIds);\n  }\n\n","sourceOld":"  private void splitByUniqueKeyTest() throws Exception {\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getSlice(SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    if (usually())  {\n      List<DocRouter.Range> ranges = router.partitionRange(4, shard1Range);\n      // 75% of range goes to shard1_0 and the rest to shard1_1\n      subRanges.add(new DocRouter.Range(ranges.get(0).min, ranges.get(2).max));\n      subRanges.add(ranges.get(3));\n    } else  {\n      subRanges = router.partitionRange(2, shard1Range);\n    }\n    final Set<String> documentIds = ConcurrentHashMap.newKeySet(1024);\n    final List<DocRouter.Range> ranges = subRanges;\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    cloudClient.getZkStateReader().forceUpdateCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION);\n    clusterState = cloudClient.getZkStateReader().getClusterState();\n    log.debug(\"-- COLLECTION: {}\", clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION));\n    del(\"*:*\");\n    for (int id = 0; id <= 100; id++) {\n      String shardKey = \"\" + (char)('a' + (id % 26)); // See comment in ShardRoutingTest for hash distribution\n      indexAndUpdateCount(router, ranges, docCounts, shardKey + \"!\" + String.valueOf(id), id, documentIds);\n    }\n    commit();\n\n    Thread indexThread = new Thread() {\n      @Override\n      public void run() {\n        Random random = random();\n        int max = atLeast(random, 401);\n        int sleep = atLeast(random, 25);\n        log.info(\"SHARDSPLITTEST: Going to add \" + max + \" number of docs at 1 doc per \" + sleep + \"ms\");\n        Set<String> deleted = new HashSet<>();\n        for (int id = 101; id < max; id++) {\n          try {\n            indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id, documentIds);\n            Thread.sleep(sleep);\n            if (usually(random))  {\n              String delId = String.valueOf(random.nextInt(id - 101 + 1) + 101);\n              if (deleted.contains(delId))  continue;\n              try {\n                deleteAndUpdateCount(router, ranges, docCounts, delId);\n                deleted.add(delId);\n                documentIds.remove(String.valueOf(delId));\n              } catch (Exception e) {\n                log.error(\"Exception while deleting docs\", e);\n              }\n            }\n          } catch (Exception e) {\n            log.error(\"Exception while adding doc id = \" + id, e);\n            // do not select this id for deletion ever\n            deleted.add(String.valueOf(id));\n          }\n        }\n      }\n    };\n    indexThread.start();\n\n    try {\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, subRanges, null, false);\n          log.info(\"Layout after split: \\n\");\n          printLayout();\n          break;\n        } catch (HttpSolrClient.RemoteSolrException e) {\n          if (e.code() != 500)  {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n    } finally {\n      try {\n        indexThread.join();\n      } catch (InterruptedException e) {\n        log.error(\"Indexing thread interrupted\", e);\n      }\n    }\n\n    waitForRecoveriesToFinish(true);\n    checkDocCountsAndShardStates(docCounts, numReplicas, documentIds);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"db96734b79e26d948b59f68bd4564c4836a71acf","date":1585375566,"type":3,"author":"Munendra S N","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#splitByUniqueKeyTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#splitByUniqueKeyTest().mjava","sourceNew":"  private void splitByUniqueKeyTest() throws Exception {\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getSlice(SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    if (usually())  {\n      List<DocRouter.Range> ranges = router.partitionRange(4, shard1Range);\n      // 75% of range goes to shard1_0 and the rest to shard1_1\n      subRanges.add(new DocRouter.Range(ranges.get(0).min, ranges.get(2).max));\n      subRanges.add(ranges.get(3));\n    } else  {\n      subRanges = router.partitionRange(2, shard1Range);\n    }\n    final Set<String> documentIds = ConcurrentHashMap.newKeySet(1024);\n    final List<DocRouter.Range> ranges = subRanges;\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    cloudClient.getZkStateReader().forceUpdateCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION);\n    clusterState = cloudClient.getZkStateReader().getClusterState();\n    log.debug(\"-- COLLECTION: {}\", clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION));\n    del(\"*:*\");\n    for (int id = 0; id <= 100; id++) {\n      String shardKey = \"\" + (char)('a' + (id % 26)); // See comment in ShardRoutingTest for hash distribution\n      indexAndUpdateCount(router, ranges, docCounts, shardKey + \"!\" + String.valueOf(id), id, documentIds);\n    }\n    commit();\n\n    Thread indexThread = new Thread(() -> {\n      Random random = random();\n      int max = atLeast(random, 401);\n      int sleep = atLeast(random, 25);\n      log.info(\"SHARDSPLITTEST: Going to add \" + max + \" number of docs at 1 doc per \" + sleep + \"ms\");\n      Set<String> deleted = new HashSet<>();\n      for (int id = 101; id < max; id++) {\n        try {\n          indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id, documentIds);\n          Thread.sleep(sleep);\n          if (usually(random))  {\n            String delId = String.valueOf(random.nextInt(id - 101 + 1) + 101);\n            if (deleted.contains(delId))  continue;\n            try {\n              deleteAndUpdateCount(router, ranges, docCounts, delId);\n              deleted.add(delId);\n              documentIds.remove(String.valueOf(delId));\n            } catch (Exception e) {\n              log.error(\"Exception while deleting docs\", e);\n            }\n          }\n        } catch (Exception e) {\n          log.error(\"Exception while adding doc id = \" + id, e);\n          // do not select this id for deletion ever\n          deleted.add(String.valueOf(id));\n        }\n      }\n    });\n    indexThread.start();\n\n    try {\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, subRanges, null, false);\n          log.info(\"Layout after split: \\n\");\n          printLayout();\n          break;\n        } catch (BaseHttpSolrClient.RemoteSolrException e) {\n          if (e.code() != 500)  {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n    } finally {\n      try {\n        indexThread.join();\n      } catch (InterruptedException e) {\n        log.error(\"Indexing thread interrupted\", e);\n      }\n    }\n\n    waitForRecoveriesToFinish(true);\n    checkDocCountsAndShardStates(docCounts, numReplicas, documentIds);\n  }\n\n","sourceOld":"  private void splitByUniqueKeyTest() throws Exception {\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getSlice(SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    if (usually())  {\n      List<DocRouter.Range> ranges = router.partitionRange(4, shard1Range);\n      // 75% of range goes to shard1_0 and the rest to shard1_1\n      subRanges.add(new DocRouter.Range(ranges.get(0).min, ranges.get(2).max));\n      subRanges.add(ranges.get(3));\n    } else  {\n      subRanges = router.partitionRange(2, shard1Range);\n    }\n    final Set<String> documentIds = ConcurrentHashMap.newKeySet(1024);\n    final List<DocRouter.Range> ranges = subRanges;\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    cloudClient.getZkStateReader().forceUpdateCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION);\n    clusterState = cloudClient.getZkStateReader().getClusterState();\n    log.debug(\"-- COLLECTION: {}\", clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION));\n    del(\"*:*\");\n    for (int id = 0; id <= 100; id++) {\n      String shardKey = \"\" + (char)('a' + (id % 26)); // See comment in ShardRoutingTest for hash distribution\n      indexAndUpdateCount(router, ranges, docCounts, shardKey + \"!\" + String.valueOf(id), id, documentIds);\n    }\n    commit();\n\n    Thread indexThread = new Thread(() -> {\n      Random random = random();\n      int max = atLeast(random, 401);\n      int sleep = atLeast(random, 25);\n      log.info(\"SHARDSPLITTEST: Going to add \" + max + \" number of docs at 1 doc per \" + sleep + \"ms\");\n      Set<String> deleted = new HashSet<>();\n      for (int id = 101; id < max; id++) {\n        try {\n          indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id, documentIds);\n          Thread.sleep(sleep);\n          if (usually(random))  {\n            String delId = String.valueOf(random.nextInt(id - 101 + 1) + 101);\n            if (deleted.contains(delId))  continue;\n            try {\n              deleteAndUpdateCount(router, ranges, docCounts, delId);\n              deleted.add(delId);\n              documentIds.remove(String.valueOf(delId));\n            } catch (Exception e) {\n              log.error(\"Exception while deleting docs\", e);\n            }\n          }\n        } catch (Exception e) {\n          log.error(\"Exception while adding doc id = \" + id, e);\n          // do not select this id for deletion ever\n          deleted.add(String.valueOf(id));\n        }\n      }\n    });\n    indexThread.start();\n\n    try {\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, subRanges, null, false);\n          log.info(\"Layout after split: \\n\");\n          printLayout();\n          break;\n        } catch (HttpSolrClient.RemoteSolrException e) {\n          if (e.code() != 500)  {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n    } finally {\n      try {\n        indexThread.join();\n      } catch (InterruptedException e) {\n        log.error(\"Indexing thread interrupted\", e);\n      }\n    }\n\n    waitForRecoveriesToFinish(true);\n    checkDocCountsAndShardStates(docCounts, numReplicas, documentIds);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fe9f2c4a0d7ac164e4bdd4eee7f87131aec83fd4","date":1588172214,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#splitByUniqueKeyTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#splitByUniqueKeyTest().mjava","sourceNew":"  private void splitByUniqueKeyTest() throws Exception {\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getSlice(SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    if (usually())  {\n      List<DocRouter.Range> ranges = router.partitionRange(4, shard1Range);\n      // 75% of range goes to shard1_0 and the rest to shard1_1\n      subRanges.add(new DocRouter.Range(ranges.get(0).min, ranges.get(2).max));\n      subRanges.add(ranges.get(3));\n    } else  {\n      subRanges = router.partitionRange(2, shard1Range);\n    }\n    final Set<String> documentIds = ConcurrentHashMap.newKeySet(1024);\n    final List<DocRouter.Range> ranges = subRanges;\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    cloudClient.getZkStateReader().forceUpdateCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION);\n    clusterState = cloudClient.getZkStateReader().getClusterState();\n    if (log.isDebugEnabled()) {\n      log.debug(\"-- COLLECTION: {}\", clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION));\n    }\n    del(\"*:*\");\n    for (int id = 0; id <= 100; id++) {\n      String shardKey = \"\" + (char)('a' + (id % 26)); // See comment in ShardRoutingTest for hash distribution\n      indexAndUpdateCount(router, ranges, docCounts, shardKey + \"!\" + String.valueOf(id), id, documentIds);\n    }\n    commit();\n\n    Thread indexThread = new Thread(() -> {\n      Random random = random();\n      int max = atLeast(random, 401);\n      int sleep = atLeast(random, 25);\n      log.info(\"SHARDSPLITTEST: Going to add {} number of docs at 1 doc per {} ms\", max, sleep);\n      Set<String> deleted = new HashSet<>();\n      for (int id = 101; id < max; id++) {\n        try {\n          indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id, documentIds);\n          Thread.sleep(sleep);\n          if (usually(random))  {\n            String delId = String.valueOf(random.nextInt(id - 101 + 1) + 101);\n            if (deleted.contains(delId))  continue;\n            try {\n              deleteAndUpdateCount(router, ranges, docCounts, delId);\n              deleted.add(delId);\n              documentIds.remove(String.valueOf(delId));\n            } catch (Exception e) {\n              log.error(\"Exception while deleting docs\", e);\n            }\n          }\n        } catch (Exception e) {\n          log.error(\"Exception while adding doc id = {}\", id, e);\n          // do not select this id for deletion ever\n          deleted.add(String.valueOf(id));\n        }\n      }\n    });\n    indexThread.start();\n\n    try {\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, subRanges, null, false);\n          log.info(\"Layout after split: \\n\");\n          printLayout();\n          break;\n        } catch (BaseHttpSolrClient.RemoteSolrException e) {\n          if (e.code() != 500)  {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. {}\", (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n    } finally {\n      try {\n        indexThread.join();\n      } catch (InterruptedException e) {\n        log.error(\"Indexing thread interrupted\", e);\n      }\n    }\n\n    waitForRecoveriesToFinish(true);\n    checkDocCountsAndShardStates(docCounts, numReplicas, documentIds);\n  }\n\n","sourceOld":"  private void splitByUniqueKeyTest() throws Exception {\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getSlice(SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    if (usually())  {\n      List<DocRouter.Range> ranges = router.partitionRange(4, shard1Range);\n      // 75% of range goes to shard1_0 and the rest to shard1_1\n      subRanges.add(new DocRouter.Range(ranges.get(0).min, ranges.get(2).max));\n      subRanges.add(ranges.get(3));\n    } else  {\n      subRanges = router.partitionRange(2, shard1Range);\n    }\n    final Set<String> documentIds = ConcurrentHashMap.newKeySet(1024);\n    final List<DocRouter.Range> ranges = subRanges;\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    cloudClient.getZkStateReader().forceUpdateCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION);\n    clusterState = cloudClient.getZkStateReader().getClusterState();\n    log.debug(\"-- COLLECTION: {}\", clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION));\n    del(\"*:*\");\n    for (int id = 0; id <= 100; id++) {\n      String shardKey = \"\" + (char)('a' + (id % 26)); // See comment in ShardRoutingTest for hash distribution\n      indexAndUpdateCount(router, ranges, docCounts, shardKey + \"!\" + String.valueOf(id), id, documentIds);\n    }\n    commit();\n\n    Thread indexThread = new Thread(() -> {\n      Random random = random();\n      int max = atLeast(random, 401);\n      int sleep = atLeast(random, 25);\n      log.info(\"SHARDSPLITTEST: Going to add \" + max + \" number of docs at 1 doc per \" + sleep + \"ms\");\n      Set<String> deleted = new HashSet<>();\n      for (int id = 101; id < max; id++) {\n        try {\n          indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id, documentIds);\n          Thread.sleep(sleep);\n          if (usually(random))  {\n            String delId = String.valueOf(random.nextInt(id - 101 + 1) + 101);\n            if (deleted.contains(delId))  continue;\n            try {\n              deleteAndUpdateCount(router, ranges, docCounts, delId);\n              deleted.add(delId);\n              documentIds.remove(String.valueOf(delId));\n            } catch (Exception e) {\n              log.error(\"Exception while deleting docs\", e);\n            }\n          }\n        } catch (Exception e) {\n          log.error(\"Exception while adding doc id = \" + id, e);\n          // do not select this id for deletion ever\n          deleted.add(String.valueOf(id));\n        }\n      }\n    });\n    indexThread.start();\n\n    try {\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, subRanges, null, false);\n          log.info(\"Layout after split: \\n\");\n          printLayout();\n          break;\n        } catch (BaseHttpSolrClient.RemoteSolrException e) {\n          if (e.code() != 500)  {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n    } finally {\n      try {\n        indexThread.join();\n      } catch (InterruptedException e) {\n        log.error(\"Indexing thread interrupted\", e);\n      }\n    }\n\n    waitForRecoveriesToFinish(true);\n    checkDocCountsAndShardStates(docCounts, numReplicas, documentIds);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b94236357aaa22b76c10629851fe4e376e0cea82":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","6146c07c0dee1ae1e42926167acd127fed5ef59d"],"fe9f2c4a0d7ac164e4bdd4eee7f87131aec83fd4":["db96734b79e26d948b59f68bd4564c4836a71acf"],"a9be06eb0504cb6312c2a585959299e40280d9ba":["2ffc8d70d9f57a62a24c3dd15b66e353de935054"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"6146c07c0dee1ae1e42926167acd127fed5ef59d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"db96734b79e26d948b59f68bd4564c4836a71acf":["a9be06eb0504cb6312c2a585959299e40280d9ba"],"2ffc8d70d9f57a62a24c3dd15b66e353de935054":["20c968c14aace7cf49843bf2c1fafc7fd3845659"],"20c968c14aace7cf49843bf2c1fafc7fd3845659":["b94236357aaa22b76c10629851fe4e376e0cea82"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["fe9f2c4a0d7ac164e4bdd4eee7f87131aec83fd4"]},"commit2Childs":{"b94236357aaa22b76c10629851fe4e376e0cea82":["20c968c14aace7cf49843bf2c1fafc7fd3845659"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b94236357aaa22b76c10629851fe4e376e0cea82","6146c07c0dee1ae1e42926167acd127fed5ef59d"],"fe9f2c4a0d7ac164e4bdd4eee7f87131aec83fd4":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a9be06eb0504cb6312c2a585959299e40280d9ba":["db96734b79e26d948b59f68bd4564c4836a71acf"],"6146c07c0dee1ae1e42926167acd127fed5ef59d":["b94236357aaa22b76c10629851fe4e376e0cea82"],"db96734b79e26d948b59f68bd4564c4836a71acf":["fe9f2c4a0d7ac164e4bdd4eee7f87131aec83fd4"],"2ffc8d70d9f57a62a24c3dd15b66e353de935054":["a9be06eb0504cb6312c2a585959299e40280d9ba"],"20c968c14aace7cf49843bf2c1fafc7fd3845659":["2ffc8d70d9f57a62a24c3dd15b66e353de935054"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}