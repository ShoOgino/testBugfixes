{"path":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpansEnum#beforeClass().mjava","commits":[{"id":"30de45e50bdc1a79a6797f34dca6271c8866cb6e","date":1427790465,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpansEnum#beforeClass().mjava","pathOld":"/dev/null","sourceNew":"  @BeforeClass\n  public static void beforeClass() throws Exception {\n    simplePayloadAnalyzer = new Analyzer() {\n        @Override\n        public TokenStreamComponents createComponents(String fieldName) {\n          Tokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, true);\n          return new TokenStreamComponents(tokenizer, new SimplePayloadFilter(tokenizer));\n        }\n    };\n\n    directory = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory,\n        newIndexWriterConfig(simplePayloadAnalyzer)\n            .setMaxBufferedDocs(TestUtil.nextInt(random(), 100, 1000)).setMergePolicy(newLogMergePolicy()));\n    //writer.infoStream = System.out;\n    for (int i = 0; i < 10; i++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"field\", English.intToEnglish(i), Field.Store.YES));\n      writer.addDocument(doc);\n    }\n    for (int i = 100; i < 110; i++) {\n      Document doc = new Document(); // doc id 10-19 have 100-109\n      doc.add(newTextField(\"field\", English.intToEnglish(i), Field.Store.YES));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = newSearcher(reader);\n    writer.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fab172655716b96f7e42376116235017a922de3a","date":1427850611,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpansEnum#beforeClass().mjava","pathOld":"/dev/null","sourceNew":"  @BeforeClass\n  public static void beforeClass() throws Exception {\n    simplePayloadAnalyzer = new Analyzer() {\n        @Override\n        public TokenStreamComponents createComponents(String fieldName) {\n          Tokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, true);\n          return new TokenStreamComponents(tokenizer, new SimplePayloadFilter(tokenizer));\n        }\n    };\n\n    directory = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory,\n        newIndexWriterConfig(simplePayloadAnalyzer)\n            .setMaxBufferedDocs(TestUtil.nextInt(random(), 100, 1000)).setMergePolicy(newLogMergePolicy()));\n    //writer.infoStream = System.out;\n    for (int i = 0; i < 10; i++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"field\", English.intToEnglish(i), Field.Store.YES));\n      writer.addDocument(doc);\n    }\n    for (int i = 100; i < 110; i++) {\n      Document doc = new Document(); // doc id 10-19 have 100-109\n      doc.add(newTextField(\"field\", English.intToEnglish(i), Field.Store.YES));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = newSearcher(reader);\n    writer.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c4f600f812447b5512daeaf8e5c9df5dbcc4a254","date":1428874774,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpansEnum#beforeClass().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpansEnum#beforeClass().mjava","sourceNew":"  @BeforeClass\n  public static void beforeClass() throws Exception {\n    directory = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory,\n        newIndexWriterConfig(new MockAnalyzer(random()))\n            .setMaxBufferedDocs(TestUtil.nextInt(random(), 100, 1000)).setMergePolicy(newLogMergePolicy()));\n    //writer.infoStream = System.out;\n    for (int i = 0; i < 10; i++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"field\", English.intToEnglish(i), Field.Store.YES));\n      writer.addDocument(doc);\n    }\n    for (int i = 100; i < 110; i++) {\n      Document doc = new Document(); // doc id 10-19 have 100-109\n      doc.add(newTextField(\"field\", English.intToEnglish(i), Field.Store.YES));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = newSearcher(reader);\n    writer.close();\n  }\n\n","sourceOld":"  @BeforeClass\n  public static void beforeClass() throws Exception {\n    simplePayloadAnalyzer = new Analyzer() {\n        @Override\n        public TokenStreamComponents createComponents(String fieldName) {\n          Tokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, true);\n          return new TokenStreamComponents(tokenizer, new SimplePayloadFilter(tokenizer));\n        }\n    };\n\n    directory = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory,\n        newIndexWriterConfig(simplePayloadAnalyzer)\n            .setMaxBufferedDocs(TestUtil.nextInt(random(), 100, 1000)).setMergePolicy(newLogMergePolicy()));\n    //writer.infoStream = System.out;\n    for (int i = 0; i < 10; i++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"field\", English.intToEnglish(i), Field.Store.YES));\n      writer.addDocument(doc);\n    }\n    for (int i = 100; i < 110; i++) {\n      Document doc = new Document(); // doc id 10-19 have 100-109\n      doc.add(newTextField(\"field\", English.intToEnglish(i), Field.Store.YES));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = newSearcher(reader);\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"c4f600f812447b5512daeaf8e5c9df5dbcc4a254":["30de45e50bdc1a79a6797f34dca6271c8866cb6e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"30de45e50bdc1a79a6797f34dca6271c8866cb6e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"fab172655716b96f7e42376116235017a922de3a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","30de45e50bdc1a79a6797f34dca6271c8866cb6e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c4f600f812447b5512daeaf8e5c9df5dbcc4a254"]},"commit2Childs":{"c4f600f812447b5512daeaf8e5c9df5dbcc4a254":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["30de45e50bdc1a79a6797f34dca6271c8866cb6e","fab172655716b96f7e42376116235017a922de3a"],"30de45e50bdc1a79a6797f34dca6271c8866cb6e":["c4f600f812447b5512daeaf8e5c9df5dbcc4a254","fab172655716b96f7e42376116235017a922de3a"],"fab172655716b96f7e42376116235017a922de3a":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["fab172655716b96f7e42376116235017a922de3a","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}