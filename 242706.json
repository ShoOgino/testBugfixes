{"path":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#testSplitLocking().mjava","commits":[{"id":"ae70f2df00762dfce0455c0e39381848762662e5","date":1539113410,"type":0,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#testSplitLocking().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testSplitLocking() throws Exception {\n    waitForThingsToLevelOut(15);\n    String collectionName = \"testSplitLocking\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 2);\n    create.setMaxShardsPerNode(5); // some high number so we can create replicas without hindrance\n    create.process(cloudClient);\n    waitForRecoveriesToFinish(collectionName, false);\n\n    TestInjection.splitLatch = new CountDownLatch(1); // simulate a long split operation\n    String path = ZkStateReader.COLLECTIONS_ZKNODE + \"/\" + collectionName + \"/\" + SHARD1 + \"-splitting\";\n    final AtomicReference<Exception> exc = new AtomicReference<>();\n    try {\n      Runnable r = () -> {\n        try {\n          trySplit(collectionName, null, SHARD1, 1);\n        } catch (Exception e) {\n          exc.set(e);\n        }\n      };\n      Thread t = new Thread(r);\n      t.start();\n      // wait for the split to start executing\n      TimeOut timeOut = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n      while (!timeOut.hasTimedOut()) {\n        timeOut.sleep(500);\n        if (cloudClient.getZkStateReader().getZkClient().exists(path, true)) {\n          log.info(\"=== found lock node\");\n          break;\n        }\n      }\n      assertFalse(\"timed out waiting for the lock znode to appear\", timeOut.hasTimedOut());\n      assertNull(\"unexpected exception: \" + exc.get(), exc.get());\n      log.info(\"=== trying second split\");\n      try {\n        trySplit(collectionName, null, SHARD1, 1);\n        fail(\"expected to fail due to locking but succeeded\");\n      } catch (Exception e) {\n        log.info(\"Expected failure: \" + e.toString());\n      }\n\n      // make sure the lock still exists\n      assertTrue(\"lock znode expected but missing\", cloudClient.getZkStateReader().getZkClient().exists(path, true));\n      // let the first split proceed\n      TestInjection.splitLatch.countDown();\n      timeOut = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n      while (!timeOut.hasTimedOut()) {\n        timeOut.sleep(500);\n        if (!cloudClient.getZkStateReader().getZkClient().exists(path, true)) {\n          break;\n        }\n      }\n      assertFalse(\"timed out waiting for the lock znode to disappear\", timeOut.hasTimedOut());\n    } finally {\n      TestInjection.reset();\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bb222a3f9d9421d5c95afce73013fbd8de07ea1f","date":1543514331,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#testSplitLocking().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#testSplitLocking().mjava","sourceNew":"  @Test\n  public void testSplitLocking() throws Exception {\n    waitForThingsToLevelOut(15);\n    String collectionName = \"testSplitLocking\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 2);\n    create.setMaxShardsPerNode(5); // some high number so we can create replicas without hindrance\n    create.process(cloudClient);\n    \n    cloudClient.waitForState(collectionName, 30, TimeUnit.SECONDS, SolrCloudTestCase.activeClusterShape(1, 2));\n    \n    waitForRecoveriesToFinish(collectionName, false);\n\n    TestInjection.splitLatch = new CountDownLatch(1); // simulate a long split operation\n    String path = ZkStateReader.COLLECTIONS_ZKNODE + \"/\" + collectionName + \"/\" + SHARD1 + \"-splitting\";\n    final AtomicReference<Exception> exc = new AtomicReference<>();\n    try {\n      Runnable r = () -> {\n        try {\n          trySplit(collectionName, null, SHARD1, 1);\n        } catch (Exception e) {\n          exc.set(e);\n        }\n      };\n      Thread t = new Thread(r);\n      t.start();\n      // wait for the split to start executing\n      TimeOut timeOut = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n      while (!timeOut.hasTimedOut()) {\n        timeOut.sleep(500);\n        if (cloudClient.getZkStateReader().getZkClient().exists(path, true)) {\n          log.info(\"=== found lock node\");\n          break;\n        }\n      }\n      assertFalse(\"timed out waiting for the lock znode to appear\", timeOut.hasTimedOut());\n      assertNull(\"unexpected exception: \" + exc.get(), exc.get());\n      log.info(\"=== trying second split\");\n      try {\n        trySplit(collectionName, null, SHARD1, 1);\n        fail(\"expected to fail due to locking but succeeded\");\n      } catch (Exception e) {\n        log.info(\"Expected failure: \" + e.toString());\n      }\n\n      // make sure the lock still exists\n      assertTrue(\"lock znode expected but missing\", cloudClient.getZkStateReader().getZkClient().exists(path, true));\n      // let the first split proceed\n      TestInjection.splitLatch.countDown();\n      timeOut = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n      while (!timeOut.hasTimedOut()) {\n        timeOut.sleep(500);\n        if (!cloudClient.getZkStateReader().getZkClient().exists(path, true)) {\n          break;\n        }\n      }\n      assertFalse(\"timed out waiting for the lock znode to disappear\", timeOut.hasTimedOut());\n    } finally {\n      TestInjection.reset();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testSplitLocking() throws Exception {\n    waitForThingsToLevelOut(15);\n    String collectionName = \"testSplitLocking\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 2);\n    create.setMaxShardsPerNode(5); // some high number so we can create replicas without hindrance\n    create.process(cloudClient);\n    waitForRecoveriesToFinish(collectionName, false);\n\n    TestInjection.splitLatch = new CountDownLatch(1); // simulate a long split operation\n    String path = ZkStateReader.COLLECTIONS_ZKNODE + \"/\" + collectionName + \"/\" + SHARD1 + \"-splitting\";\n    final AtomicReference<Exception> exc = new AtomicReference<>();\n    try {\n      Runnable r = () -> {\n        try {\n          trySplit(collectionName, null, SHARD1, 1);\n        } catch (Exception e) {\n          exc.set(e);\n        }\n      };\n      Thread t = new Thread(r);\n      t.start();\n      // wait for the split to start executing\n      TimeOut timeOut = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n      while (!timeOut.hasTimedOut()) {\n        timeOut.sleep(500);\n        if (cloudClient.getZkStateReader().getZkClient().exists(path, true)) {\n          log.info(\"=== found lock node\");\n          break;\n        }\n      }\n      assertFalse(\"timed out waiting for the lock znode to appear\", timeOut.hasTimedOut());\n      assertNull(\"unexpected exception: \" + exc.get(), exc.get());\n      log.info(\"=== trying second split\");\n      try {\n        trySplit(collectionName, null, SHARD1, 1);\n        fail(\"expected to fail due to locking but succeeded\");\n      } catch (Exception e) {\n        log.info(\"Expected failure: \" + e.toString());\n      }\n\n      // make sure the lock still exists\n      assertTrue(\"lock znode expected but missing\", cloudClient.getZkStateReader().getZkClient().exists(path, true));\n      // let the first split proceed\n      TestInjection.splitLatch.countDown();\n      timeOut = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n      while (!timeOut.hasTimedOut()) {\n        timeOut.sleep(500);\n        if (!cloudClient.getZkStateReader().getZkClient().exists(path, true)) {\n          break;\n        }\n      }\n      assertFalse(\"timed out waiting for the lock znode to disappear\", timeOut.hasTimedOut());\n    } finally {\n      TestInjection.reset();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"add1e7dd742ea533ff4318cea83ca0a1f669f662","date":1585262285,"type":3,"author":"Mike Drob","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#testSplitLocking().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#testSplitLocking().mjava","sourceNew":"  @Test\n  public void testSplitLocking() throws Exception {\n    waitForThingsToLevelOut(15, TimeUnit.SECONDS);\n    String collectionName = \"testSplitLocking\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 2);\n    create.setMaxShardsPerNode(5); // some high number so we can create replicas without hindrance\n    create.process(cloudClient);\n    \n    cloudClient.waitForState(collectionName, 30, TimeUnit.SECONDS, SolrCloudTestCase.activeClusterShape(1, 2));\n    \n    waitForRecoveriesToFinish(collectionName, false);\n\n    TestInjection.splitLatch = new CountDownLatch(1); // simulate a long split operation\n    String path = ZkStateReader.COLLECTIONS_ZKNODE + \"/\" + collectionName + \"/\" + SHARD1 + \"-splitting\";\n    final AtomicReference<Exception> exc = new AtomicReference<>();\n    try {\n      Runnable r = () -> {\n        try {\n          trySplit(collectionName, null, SHARD1, 1);\n        } catch (Exception e) {\n          exc.set(e);\n        }\n      };\n      Thread t = new Thread(r);\n      t.start();\n      // wait for the split to start executing\n      TimeOut timeOut = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n      while (!timeOut.hasTimedOut()) {\n        timeOut.sleep(500);\n        if (cloudClient.getZkStateReader().getZkClient().exists(path, true)) {\n          log.info(\"=== found lock node\");\n          break;\n        }\n      }\n      assertFalse(\"timed out waiting for the lock znode to appear\", timeOut.hasTimedOut());\n      assertNull(\"unexpected exception: \" + exc.get(), exc.get());\n      log.info(\"=== trying second split\");\n      try {\n        trySplit(collectionName, null, SHARD1, 1);\n        fail(\"expected to fail due to locking but succeeded\");\n      } catch (Exception e) {\n        log.info(\"Expected failure: \" + e.toString());\n      }\n\n      // make sure the lock still exists\n      assertTrue(\"lock znode expected but missing\", cloudClient.getZkStateReader().getZkClient().exists(path, true));\n      // let the first split proceed\n      TestInjection.splitLatch.countDown();\n      timeOut = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n      while (!timeOut.hasTimedOut()) {\n        timeOut.sleep(500);\n        if (!cloudClient.getZkStateReader().getZkClient().exists(path, true)) {\n          break;\n        }\n      }\n      assertFalse(\"timed out waiting for the lock znode to disappear\", timeOut.hasTimedOut());\n    } finally {\n      TestInjection.reset();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testSplitLocking() throws Exception {\n    waitForThingsToLevelOut(15);\n    String collectionName = \"testSplitLocking\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 2);\n    create.setMaxShardsPerNode(5); // some high number so we can create replicas without hindrance\n    create.process(cloudClient);\n    \n    cloudClient.waitForState(collectionName, 30, TimeUnit.SECONDS, SolrCloudTestCase.activeClusterShape(1, 2));\n    \n    waitForRecoveriesToFinish(collectionName, false);\n\n    TestInjection.splitLatch = new CountDownLatch(1); // simulate a long split operation\n    String path = ZkStateReader.COLLECTIONS_ZKNODE + \"/\" + collectionName + \"/\" + SHARD1 + \"-splitting\";\n    final AtomicReference<Exception> exc = new AtomicReference<>();\n    try {\n      Runnable r = () -> {\n        try {\n          trySplit(collectionName, null, SHARD1, 1);\n        } catch (Exception e) {\n          exc.set(e);\n        }\n      };\n      Thread t = new Thread(r);\n      t.start();\n      // wait for the split to start executing\n      TimeOut timeOut = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n      while (!timeOut.hasTimedOut()) {\n        timeOut.sleep(500);\n        if (cloudClient.getZkStateReader().getZkClient().exists(path, true)) {\n          log.info(\"=== found lock node\");\n          break;\n        }\n      }\n      assertFalse(\"timed out waiting for the lock znode to appear\", timeOut.hasTimedOut());\n      assertNull(\"unexpected exception: \" + exc.get(), exc.get());\n      log.info(\"=== trying second split\");\n      try {\n        trySplit(collectionName, null, SHARD1, 1);\n        fail(\"expected to fail due to locking but succeeded\");\n      } catch (Exception e) {\n        log.info(\"Expected failure: \" + e.toString());\n      }\n\n      // make sure the lock still exists\n      assertTrue(\"lock znode expected but missing\", cloudClient.getZkStateReader().getZkClient().exists(path, true));\n      // let the first split proceed\n      TestInjection.splitLatch.countDown();\n      timeOut = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n      while (!timeOut.hasTimedOut()) {\n        timeOut.sleep(500);\n        if (!cloudClient.getZkStateReader().getZkClient().exists(path, true)) {\n          break;\n        }\n      }\n      assertFalse(\"timed out waiting for the lock znode to disappear\", timeOut.hasTimedOut());\n    } finally {\n      TestInjection.reset();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fe9f2c4a0d7ac164e4bdd4eee7f87131aec83fd4","date":1588172214,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#testSplitLocking().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#testSplitLocking().mjava","sourceNew":"  @Test\n  public void testSplitLocking() throws Exception {\n    waitForThingsToLevelOut(15, TimeUnit.SECONDS);\n    String collectionName = \"testSplitLocking\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 2);\n    create.setMaxShardsPerNode(5); // some high number so we can create replicas without hindrance\n    create.process(cloudClient);\n    \n    cloudClient.waitForState(collectionName, 30, TimeUnit.SECONDS, SolrCloudTestCase.activeClusterShape(1, 2));\n    \n    waitForRecoveriesToFinish(collectionName, false);\n\n    TestInjection.splitLatch = new CountDownLatch(1); // simulate a long split operation\n    String path = ZkStateReader.COLLECTIONS_ZKNODE + \"/\" + collectionName + \"/\" + SHARD1 + \"-splitting\";\n    final AtomicReference<Exception> exc = new AtomicReference<>();\n    try {\n      Runnable r = () -> {\n        try {\n          trySplit(collectionName, null, SHARD1, 1);\n        } catch (Exception e) {\n          exc.set(e);\n        }\n      };\n      Thread t = new Thread(r);\n      t.start();\n      // wait for the split to start executing\n      TimeOut timeOut = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n      while (!timeOut.hasTimedOut()) {\n        timeOut.sleep(500);\n        if (cloudClient.getZkStateReader().getZkClient().exists(path, true)) {\n          log.info(\"=== found lock node\");\n          break;\n        }\n      }\n      assertFalse(\"timed out waiting for the lock znode to appear\", timeOut.hasTimedOut());\n      assertNull(\"unexpected exception: \" + exc.get(), exc.get());\n      log.info(\"=== trying second split\");\n      try {\n        trySplit(collectionName, null, SHARD1, 1);\n        fail(\"expected to fail due to locking but succeeded\");\n      } catch (Exception e) {\n        log.info(\"Expected failure: {}\", e);\n      }\n\n      // make sure the lock still exists\n      assertTrue(\"lock znode expected but missing\", cloudClient.getZkStateReader().getZkClient().exists(path, true));\n      // let the first split proceed\n      TestInjection.splitLatch.countDown();\n      timeOut = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n      while (!timeOut.hasTimedOut()) {\n        timeOut.sleep(500);\n        if (!cloudClient.getZkStateReader().getZkClient().exists(path, true)) {\n          break;\n        }\n      }\n      assertFalse(\"timed out waiting for the lock znode to disappear\", timeOut.hasTimedOut());\n    } finally {\n      TestInjection.reset();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testSplitLocking() throws Exception {\n    waitForThingsToLevelOut(15, TimeUnit.SECONDS);\n    String collectionName = \"testSplitLocking\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 2);\n    create.setMaxShardsPerNode(5); // some high number so we can create replicas without hindrance\n    create.process(cloudClient);\n    \n    cloudClient.waitForState(collectionName, 30, TimeUnit.SECONDS, SolrCloudTestCase.activeClusterShape(1, 2));\n    \n    waitForRecoveriesToFinish(collectionName, false);\n\n    TestInjection.splitLatch = new CountDownLatch(1); // simulate a long split operation\n    String path = ZkStateReader.COLLECTIONS_ZKNODE + \"/\" + collectionName + \"/\" + SHARD1 + \"-splitting\";\n    final AtomicReference<Exception> exc = new AtomicReference<>();\n    try {\n      Runnable r = () -> {\n        try {\n          trySplit(collectionName, null, SHARD1, 1);\n        } catch (Exception e) {\n          exc.set(e);\n        }\n      };\n      Thread t = new Thread(r);\n      t.start();\n      // wait for the split to start executing\n      TimeOut timeOut = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n      while (!timeOut.hasTimedOut()) {\n        timeOut.sleep(500);\n        if (cloudClient.getZkStateReader().getZkClient().exists(path, true)) {\n          log.info(\"=== found lock node\");\n          break;\n        }\n      }\n      assertFalse(\"timed out waiting for the lock znode to appear\", timeOut.hasTimedOut());\n      assertNull(\"unexpected exception: \" + exc.get(), exc.get());\n      log.info(\"=== trying second split\");\n      try {\n        trySplit(collectionName, null, SHARD1, 1);\n        fail(\"expected to fail due to locking but succeeded\");\n      } catch (Exception e) {\n        log.info(\"Expected failure: \" + e.toString());\n      }\n\n      // make sure the lock still exists\n      assertTrue(\"lock znode expected but missing\", cloudClient.getZkStateReader().getZkClient().exists(path, true));\n      // let the first split proceed\n      TestInjection.splitLatch.countDown();\n      timeOut = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n      while (!timeOut.hasTimedOut()) {\n        timeOut.sleep(500);\n        if (!cloudClient.getZkStateReader().getZkClient().exists(path, true)) {\n          break;\n        }\n      }\n      assertFalse(\"timed out waiting for the lock znode to disappear\", timeOut.hasTimedOut());\n    } finally {\n      TestInjection.reset();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e","date":1594223844,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#testSplitLocking().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#testSplitLocking().mjava","sourceNew":"  @Test\n  public void testSplitLocking() throws Exception {\n    waitForThingsToLevelOut(15, TimeUnit.SECONDS);\n    String collectionName = \"testSplitLocking\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 2);\n    create.process(cloudClient);\n    \n    cloudClient.waitForState(collectionName, 30, TimeUnit.SECONDS, SolrCloudTestCase.activeClusterShape(1, 2));\n    \n    waitForRecoveriesToFinish(collectionName, false);\n\n    TestInjection.splitLatch = new CountDownLatch(1); // simulate a long split operation\n    String path = ZkStateReader.COLLECTIONS_ZKNODE + \"/\" + collectionName + \"/\" + SHARD1 + \"-splitting\";\n    final AtomicReference<Exception> exc = new AtomicReference<>();\n    try {\n      Runnable r = () -> {\n        try {\n          trySplit(collectionName, null, SHARD1, 1);\n        } catch (Exception e) {\n          exc.set(e);\n        }\n      };\n      Thread t = new Thread(r);\n      t.start();\n      // wait for the split to start executing\n      TimeOut timeOut = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n      while (!timeOut.hasTimedOut()) {\n        timeOut.sleep(500);\n        if (cloudClient.getZkStateReader().getZkClient().exists(path, true)) {\n          log.info(\"=== found lock node\");\n          break;\n        }\n      }\n      assertFalse(\"timed out waiting for the lock znode to appear\", timeOut.hasTimedOut());\n      assertNull(\"unexpected exception: \" + exc.get(), exc.get());\n      log.info(\"=== trying second split\");\n      try {\n        trySplit(collectionName, null, SHARD1, 1);\n        fail(\"expected to fail due to locking but succeeded\");\n      } catch (Exception e) {\n        log.info(\"Expected failure: {}\", e);\n      }\n\n      // make sure the lock still exists\n      assertTrue(\"lock znode expected but missing\", cloudClient.getZkStateReader().getZkClient().exists(path, true));\n      // let the first split proceed\n      TestInjection.splitLatch.countDown();\n      timeOut = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n      while (!timeOut.hasTimedOut()) {\n        timeOut.sleep(500);\n        if (!cloudClient.getZkStateReader().getZkClient().exists(path, true)) {\n          break;\n        }\n      }\n      assertFalse(\"timed out waiting for the lock znode to disappear\", timeOut.hasTimedOut());\n    } finally {\n      TestInjection.reset();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testSplitLocking() throws Exception {\n    waitForThingsToLevelOut(15, TimeUnit.SECONDS);\n    String collectionName = \"testSplitLocking\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 2);\n    create.setMaxShardsPerNode(5); // some high number so we can create replicas without hindrance\n    create.process(cloudClient);\n    \n    cloudClient.waitForState(collectionName, 30, TimeUnit.SECONDS, SolrCloudTestCase.activeClusterShape(1, 2));\n    \n    waitForRecoveriesToFinish(collectionName, false);\n\n    TestInjection.splitLatch = new CountDownLatch(1); // simulate a long split operation\n    String path = ZkStateReader.COLLECTIONS_ZKNODE + \"/\" + collectionName + \"/\" + SHARD1 + \"-splitting\";\n    final AtomicReference<Exception> exc = new AtomicReference<>();\n    try {\n      Runnable r = () -> {\n        try {\n          trySplit(collectionName, null, SHARD1, 1);\n        } catch (Exception e) {\n          exc.set(e);\n        }\n      };\n      Thread t = new Thread(r);\n      t.start();\n      // wait for the split to start executing\n      TimeOut timeOut = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n      while (!timeOut.hasTimedOut()) {\n        timeOut.sleep(500);\n        if (cloudClient.getZkStateReader().getZkClient().exists(path, true)) {\n          log.info(\"=== found lock node\");\n          break;\n        }\n      }\n      assertFalse(\"timed out waiting for the lock znode to appear\", timeOut.hasTimedOut());\n      assertNull(\"unexpected exception: \" + exc.get(), exc.get());\n      log.info(\"=== trying second split\");\n      try {\n        trySplit(collectionName, null, SHARD1, 1);\n        fail(\"expected to fail due to locking but succeeded\");\n      } catch (Exception e) {\n        log.info(\"Expected failure: {}\", e);\n      }\n\n      // make sure the lock still exists\n      assertTrue(\"lock znode expected but missing\", cloudClient.getZkStateReader().getZkClient().exists(path, true));\n      // let the first split proceed\n      TestInjection.splitLatch.countDown();\n      timeOut = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n      while (!timeOut.hasTimedOut()) {\n        timeOut.sleep(500);\n        if (!cloudClient.getZkStateReader().getZkClient().exists(path, true)) {\n          break;\n        }\n      }\n      assertFalse(\"timed out waiting for the lock znode to disappear\", timeOut.hasTimedOut());\n    } finally {\n      TestInjection.reset();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["ae70f2df00762dfce0455c0e39381848762662e5"],"fe9f2c4a0d7ac164e4bdd4eee7f87131aec83fd4":["add1e7dd742ea533ff4318cea83ca0a1f669f662"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"add1e7dd742ea533ff4318cea83ca0a1f669f662":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e":["fe9f2c4a0d7ac164e4bdd4eee7f87131aec83fd4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["e46a76bb135597b8bf35930cfdb3702bdd1cbe6e"],"ae70f2df00762dfce0455c0e39381848762662e5":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["add1e7dd742ea533ff4318cea83ca0a1f669f662"],"fe9f2c4a0d7ac164e4bdd4eee7f87131aec83fd4":["e46a76bb135597b8bf35930cfdb3702bdd1cbe6e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["ae70f2df00762dfce0455c0e39381848762662e5"],"add1e7dd742ea533ff4318cea83ca0a1f669f662":["fe9f2c4a0d7ac164e4bdd4eee7f87131aec83fd4"],"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"ae70f2df00762dfce0455c0e39381848762662e5":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}