{"path":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#test().mjava","commits":[{"id":"abb23fcc2461782ab204e61213240feb77d355aa","date":1422029612,"type":1,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#doTest().mjava","sourceNew":"  @Test\n  @ShardsFixed(num = 4)\n  public void test() throws Exception {\n    // setLoggingLevel(null);\n\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    // make sure we have leaders for each shard\n    for (int j = 1; j < sliceCount; j++) {\n      zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n    }      // make sure we again have leaders for each shard\n    \n    waitForRecoveriesToFinish(false);\n    \n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    del(\"*:*\");\n    queryAndCompareShards(params(\"q\", \"*:*\", \"distrib\", \"false\", \"sanity_check\", \"is_empty\"));\n\n    // ask every individual replica of every shard to update+commit the same doc id\n    // with an incrementing counter on each update+commit\n    int foo_i_counter = 0;\n    for (SolrClient client : clients) {\n      foo_i_counter++;\n      indexDoc(client, params(\"commit\", \"true\"), // SOLR-4923\n               sdoc(id,1, i1,100, tlong,100, \"foo_i\", foo_i_counter));\n      // after every update+commit, check all the shards consistency\n      queryAndCompareShards(params(\"q\", \"id:1\", \"distrib\", \"false\", \n                                   \"sanity_check\", \"non_distrib_id_1_lookup\"));\n      queryAndCompareShards(params(\"q\", \"id:1\", \n                                   \"sanity_check\", \"distrib_id_1_lookup\"));\n    }\n\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\"\n            ,\"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\"\n    );\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\"\n    );\n    indexr(id,4, i1, -100 ,tlong, 101,t1,\"the quick fox jumped over the lazy dog\"\n    );\n    indexr(id,5, i1, 500, tlong, 500 ,t1,\"the quick fox jumped way over the lazy dog\"\n    );\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,t1,\"no eggs on wall, lesson learned\", oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n    queryAndCompareShards(params(\"q\", \"*:*\", \n                                 \"sort\", \"id desc\",\n                                 \"distrib\", \"false\", \n                                 \"sanity_check\", \"is_empty\"));\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" desc\"});\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" asc\"});\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" asc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"}); \n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 desc\"});\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"{!func}\"+i1});// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(false, new String[] {\"q\",\"{!func}\"+i1, \"fl\",\"*,score\"});  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\"});  // no fields in returned docs\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\"});\n\n    handle.put(\"score\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\",\"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\"});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"matchesnothing\",\"fl\",\"*,score\"});  \n\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.offset\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2});\n\n    // test faceting multiple things at once\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1});\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"}\n    );\n    query(false, new Object[] {\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\"});\n\n    // test field that is valid in schema but missing in all shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2});\n    // test field that is valid in schema and missing in some shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2});\n\n    query(false, new Object[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1});\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    // check a complex key name\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(false, new Object[] {\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"*:*\", \"rows\",100});\n    }\n\n    // test debugging\n    handle.put(\"explain\", SKIPVAL);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP);\n    query(false, new Object[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY});\n\n    // try commitWithin\n    long before = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"commitWithin\", 10);\n    add(cloudClient, params , getDoc(\"id\", 300));\n    \n    long timeout = System.currentTimeMillis() + 45000;\n    while (cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound() != before + 1) {\n      if (timeout <= System.currentTimeMillis()) {\n        fail(\"commitWithin did not work\");\n      }\n      Thread.sleep(100);\n    }\n    \n    for (SolrClient client : clients) {\n      assertEquals(\"commitWithin did not work on node: \" + ((HttpSolrClient)client).getBaseURL(), before + 1, client.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // would be better if these where all separate tests - but much, much\n    // slower\n    doOptimisticLockingAndUpdating();\n    testShardParamVariations();\n    testMultipleCollections();\n    testANewCollectionInOneInstance();\n    testSearchByCollectionName();\n    testUpdateByCollectionName();\n    testANewCollectionInOneInstanceWithManualShardAssignement();\n    testNumberOfCommitsWithCommitAfterAdd();\n\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-explicit\");\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-implicit\");\n\n    testStopAndStartCoresInOneInstance();\n    testFailedCoreCreateCleansUp();\n    // Thread.sleep(10000000000L);\n    if (DEBUG) {\n      super.printLayout();\n    }\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    // setLoggingLevel(null);\n\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    // make sure we have leaders for each shard\n    for (int j = 1; j < sliceCount; j++) {\n      zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n    }      // make sure we again have leaders for each shard\n    \n    waitForRecoveriesToFinish(false);\n    \n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    del(\"*:*\");\n    queryAndCompareShards(params(\"q\", \"*:*\", \"distrib\", \"false\", \"sanity_check\", \"is_empty\"));\n\n    // ask every individual replica of every shard to update+commit the same doc id\n    // with an incrementing counter on each update+commit\n    int foo_i_counter = 0;\n    for (SolrClient client : clients) {\n      foo_i_counter++;\n      indexDoc(client, params(\"commit\", \"true\"), // SOLR-4923\n               sdoc(id,1, i1,100, tlong,100, \"foo_i\", foo_i_counter));\n      // after every update+commit, check all the shards consistency\n      queryAndCompareShards(params(\"q\", \"id:1\", \"distrib\", \"false\", \n                                   \"sanity_check\", \"non_distrib_id_1_lookup\"));\n      queryAndCompareShards(params(\"q\", \"id:1\", \n                                   \"sanity_check\", \"distrib_id_1_lookup\"));\n    }\n\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\"\n            ,\"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\"\n    );\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\"\n    );\n    indexr(id,4, i1, -100 ,tlong, 101,t1,\"the quick fox jumped over the lazy dog\"\n    );\n    indexr(id,5, i1, 500, tlong, 500 ,t1,\"the quick fox jumped way over the lazy dog\"\n    );\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,t1,\"no eggs on wall, lesson learned\", oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n    queryAndCompareShards(params(\"q\", \"*:*\", \n                                 \"sort\", \"id desc\",\n                                 \"distrib\", \"false\", \n                                 \"sanity_check\", \"is_empty\"));\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" desc\"});\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" asc\"});\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" asc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"}); \n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 desc\"});\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"{!func}\"+i1});// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(false, new String[] {\"q\",\"{!func}\"+i1, \"fl\",\"*,score\"});  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\"});  // no fields in returned docs\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\"});\n\n    handle.put(\"score\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\",\"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\"});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"matchesnothing\",\"fl\",\"*,score\"});  \n\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.offset\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2});\n\n    // test faceting multiple things at once\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1});\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"}\n    );\n    query(false, new Object[] {\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\"});\n\n    // test field that is valid in schema but missing in all shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2});\n    // test field that is valid in schema and missing in some shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2});\n\n    query(false, new Object[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1});\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    // check a complex key name\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(false, new Object[] {\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"*:*\", \"rows\",100});\n    }\n\n    // test debugging\n    handle.put(\"explain\", SKIPVAL);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP);\n    query(false, new Object[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY});\n\n    // try commitWithin\n    long before = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"commitWithin\", 10);\n    add(cloudClient, params , getDoc(\"id\", 300));\n    \n    long timeout = System.currentTimeMillis() + 45000;\n    while (cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound() != before + 1) {\n      if (timeout <= System.currentTimeMillis()) {\n        fail(\"commitWithin did not work\");\n      }\n      Thread.sleep(100);\n    }\n    \n    for (SolrClient client : clients) {\n      assertEquals(\"commitWithin did not work on node: \" + ((HttpSolrClient)client).getBaseURL(), before + 1, client.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // would be better if these where all separate tests - but much, much\n    // slower\n    doOptimisticLockingAndUpdating();\n    testShardParamVariations();\n    testMultipleCollections();\n    testANewCollectionInOneInstance();\n    testSearchByCollectionName();\n    testUpdateByCollectionName();\n    testANewCollectionInOneInstanceWithManualShardAssignement();\n    testNumberOfCommitsWithCommitAfterAdd();\n\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-explicit\");\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-implicit\");\n\n    testStopAndStartCoresInOneInstance();\n    testFailedCoreCreateCleansUp();\n    // Thread.sleep(10000000000L);\n    if (DEBUG) {\n      super.printLayout();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bcf9886c8ff537aafde14de48ebf744f5673f08b","date":1439041198,"type":3,"author":"Ramkumar Aiyengar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#test().mjava","sourceNew":"  @Test\n  @ShardsFixed(num = 4)\n  public void test() throws Exception {\n    // setLoggingLevel(null);\n\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    // make sure we have leaders for each shard\n    for (int j = 1; j < sliceCount; j++) {\n      zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n    }      // make sure we again have leaders for each shard\n    \n    waitForRecoveriesToFinish(false);\n    \n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    del(\"*:*\");\n    queryAndCompareShards(params(\"q\", \"*:*\", \"distrib\", \"false\", \"sanity_check\", \"is_empty\"));\n\n    // ask every individual replica of every shard to update+commit the same doc id\n    // with an incrementing counter on each update+commit\n    int foo_i_counter = 0;\n    for (SolrClient client : clients) {\n      foo_i_counter++;\n      indexDoc(client, params(\"commit\", \"true\"), // SOLR-4923\n               sdoc(id,1, i1,100, tlong,100, \"foo_i\", foo_i_counter));\n      // after every update+commit, check all the shards consistency\n      queryAndCompareShards(params(\"q\", \"id:1\", \"distrib\", \"false\", \n                                   \"sanity_check\", \"non_distrib_id_1_lookup\"));\n      queryAndCompareShards(params(\"q\", \"id:1\", \n                                   \"sanity_check\", \"distrib_id_1_lookup\"));\n    }\n\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\"\n            ,\"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\"\n    );\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\"\n    );\n    indexr(id,4, i1, -100 ,tlong, 101,t1,\"the quick fox jumped over the lazy dog\"\n    );\n    indexr(id,5, i1, 500, tlong, 500 ,t1,\"the quick fox jumped way over the lazy dog\"\n    );\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,t1,\"no eggs on wall, lesson learned\", oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n    queryAndCompareShards(params(\"q\", \"*:*\", \n                                 \"sort\", \"id desc\",\n                                 \"distrib\", \"false\", \n                                 \"sanity_check\", \"is_empty\"));\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" desc\"});\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" asc\"});\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" asc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"}); \n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 desc\"});\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"{!func}\"+i1});// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(false, new String[] {\"q\",\"{!func}\"+i1, \"fl\",\"*,score\"});  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\"});  // no fields in returned docs\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\"});\n\n    handle.put(\"score\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\",\"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\"});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"matchesnothing\",\"fl\",\"*,score\"});  \n\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.offset\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2});\n\n    // test faceting multiple things at once\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1});\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"}\n    );\n    query(false, new Object[] {\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\"});\n\n    // test field that is valid in schema but missing in all shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2});\n    // test field that is valid in schema and missing in some shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2});\n\n    query(false, new Object[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1});\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    // check a complex key name\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(false, new Object[] {\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"*:*\", \"rows\",100});\n    }\n\n    // test debugging\n    handle.put(\"explain\", SKIPVAL);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP);\n    query(false, new Object[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY});\n\n    // try commitWithin\n    long before = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"commitWithin\", 10);\n    add(cloudClient, params, getDoc(\"id\", 300));\n\n    TimeOut timeout = new TimeOut(45, TimeUnit.SECONDS);\n    while (cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound() != before + 1) {\n      if (timeout.hasTimedOut()) {\n        fail(\"commitWithin did not work\");\n      }\n      Thread.sleep(100);\n    }\n    \n    for (SolrClient client : clients) {\n      assertEquals(\"commitWithin did not work on node: \" + ((HttpSolrClient)client).getBaseURL(), before + 1, client.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // would be better if these where all separate tests - but much, much\n    // slower\n    doOptimisticLockingAndUpdating();\n    testShardParamVariations();\n    testMultipleCollections();\n    testANewCollectionInOneInstance();\n    testSearchByCollectionName();\n    testUpdateByCollectionName();\n    testANewCollectionInOneInstanceWithManualShardAssignement();\n    testNumberOfCommitsWithCommitAfterAdd();\n\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-explicit\");\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-implicit\");\n\n    testStopAndStartCoresInOneInstance();\n    testFailedCoreCreateCleansUp();\n    // Thread.sleep(10000000000L);\n    if (DEBUG) {\n      super.printLayout();\n    }\n  }\n\n","sourceOld":"  @Test\n  @ShardsFixed(num = 4)\n  public void test() throws Exception {\n    // setLoggingLevel(null);\n\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    // make sure we have leaders for each shard\n    for (int j = 1; j < sliceCount; j++) {\n      zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n    }      // make sure we again have leaders for each shard\n    \n    waitForRecoveriesToFinish(false);\n    \n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    del(\"*:*\");\n    queryAndCompareShards(params(\"q\", \"*:*\", \"distrib\", \"false\", \"sanity_check\", \"is_empty\"));\n\n    // ask every individual replica of every shard to update+commit the same doc id\n    // with an incrementing counter on each update+commit\n    int foo_i_counter = 0;\n    for (SolrClient client : clients) {\n      foo_i_counter++;\n      indexDoc(client, params(\"commit\", \"true\"), // SOLR-4923\n               sdoc(id,1, i1,100, tlong,100, \"foo_i\", foo_i_counter));\n      // after every update+commit, check all the shards consistency\n      queryAndCompareShards(params(\"q\", \"id:1\", \"distrib\", \"false\", \n                                   \"sanity_check\", \"non_distrib_id_1_lookup\"));\n      queryAndCompareShards(params(\"q\", \"id:1\", \n                                   \"sanity_check\", \"distrib_id_1_lookup\"));\n    }\n\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\"\n            ,\"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\"\n    );\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\"\n    );\n    indexr(id,4, i1, -100 ,tlong, 101,t1,\"the quick fox jumped over the lazy dog\"\n    );\n    indexr(id,5, i1, 500, tlong, 500 ,t1,\"the quick fox jumped way over the lazy dog\"\n    );\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,t1,\"no eggs on wall, lesson learned\", oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n    queryAndCompareShards(params(\"q\", \"*:*\", \n                                 \"sort\", \"id desc\",\n                                 \"distrib\", \"false\", \n                                 \"sanity_check\", \"is_empty\"));\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" desc\"});\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" asc\"});\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" asc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"}); \n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 desc\"});\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"{!func}\"+i1});// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(false, new String[] {\"q\",\"{!func}\"+i1, \"fl\",\"*,score\"});  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\"});  // no fields in returned docs\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\"});\n\n    handle.put(\"score\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\",\"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\"});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"matchesnothing\",\"fl\",\"*,score\"});  \n\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.offset\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2});\n\n    // test faceting multiple things at once\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1});\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"}\n    );\n    query(false, new Object[] {\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\"});\n\n    // test field that is valid in schema but missing in all shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2});\n    // test field that is valid in schema and missing in some shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2});\n\n    query(false, new Object[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1});\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    // check a complex key name\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(false, new Object[] {\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"*:*\", \"rows\",100});\n    }\n\n    // test debugging\n    handle.put(\"explain\", SKIPVAL);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP);\n    query(false, new Object[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY});\n\n    // try commitWithin\n    long before = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"commitWithin\", 10);\n    add(cloudClient, params , getDoc(\"id\", 300));\n    \n    long timeout = System.currentTimeMillis() + 45000;\n    while (cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound() != before + 1) {\n      if (timeout <= System.currentTimeMillis()) {\n        fail(\"commitWithin did not work\");\n      }\n      Thread.sleep(100);\n    }\n    \n    for (SolrClient client : clients) {\n      assertEquals(\"commitWithin did not work on node: \" + ((HttpSolrClient)client).getBaseURL(), before + 1, client.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // would be better if these where all separate tests - but much, much\n    // slower\n    doOptimisticLockingAndUpdating();\n    testShardParamVariations();\n    testMultipleCollections();\n    testANewCollectionInOneInstance();\n    testSearchByCollectionName();\n    testUpdateByCollectionName();\n    testANewCollectionInOneInstanceWithManualShardAssignement();\n    testNumberOfCommitsWithCommitAfterAdd();\n\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-explicit\");\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-implicit\");\n\n    testStopAndStartCoresInOneInstance();\n    testFailedCoreCreateCleansUp();\n    // Thread.sleep(10000000000L);\n    if (DEBUG) {\n      super.printLayout();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"85b44c11e08024d47ec99e6befad81bd16391ad9","date":1449497290,"type":3,"author":"Christine Poerschke","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#test().mjava","sourceNew":"  @Test\n  @ShardsFixed(num = 4)\n  public void test() throws Exception {\n    // setLoggingLevel(null);\n\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    // make sure we have leaders for each shard\n    for (int j = 1; j < sliceCount; j++) {\n      zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n    }      // make sure we again have leaders for each shard\n    \n    waitForRecoveriesToFinish(false);\n    \n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    del(\"*:*\");\n    queryAndCompareShards(params(\"q\", \"*:*\", \"distrib\", \"false\", \"sanity_check\", \"is_empty\"));\n\n    // ask every individual replica of every shard to update+commit the same doc id\n    // with an incrementing counter on each update+commit\n    int foo_i_counter = 0;\n    for (SolrClient client : clients) {\n      foo_i_counter++;\n      indexDoc(client, params(\"commit\", \"true\"), // SOLR-4923\n               sdoc(id,1, i1,100, tlong,100, \"foo_i\", foo_i_counter));\n      // after every update+commit, check all the shards consistency\n      queryAndCompareShards(params(\"q\", \"id:1\", \"distrib\", \"false\", \n                                   \"sanity_check\", \"non_distrib_id_1_lookup\"));\n      queryAndCompareShards(params(\"q\", \"id:1\", \n                                   \"sanity_check\", \"distrib_id_1_lookup\"));\n    }\n\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\"\n            ,\"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\"\n    );\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\"\n    );\n    indexr(id,4, i1, -100 ,tlong, 101,t1,\"the quick fox jumped over the lazy dog\"\n    );\n    indexr(id,5, i1, 500, tlong, 500 ,t1,\"the quick fox jumped way over the lazy dog\"\n    );\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,t1,\"no eggs on wall, lesson learned\", oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n    queryAndCompareShards(params(\"q\", \"*:*\", \n                                 \"sort\", \"id desc\",\n                                 \"distrib\", \"false\", \n                                 \"sanity_check\", \"is_empty\"));\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" desc\"});\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" asc\"});\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" asc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"}); \n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 desc\"});\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"{!func}\"+i1});// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(false, new String[] {\"q\",\"{!func}\"+i1, \"fl\",\"*,score\"});  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\"});  // no fields in returned docs\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\"});\n\n    handle.put(\"score\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\",\"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\"});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"matchesnothing\",\"fl\",\"*,score\"});  \n\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.offset\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2});\n\n    // test faceting multiple things at once\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1});\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"}\n    );\n    query(false, new Object[] {\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\"});\n\n    // test field that is valid in schema but missing in all shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2});\n    // test field that is valid in schema and missing in some shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2});\n\n    query(false, new Object[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1});\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    // check a complex key name\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(false, new Object[] {\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"*:*\", \"rows\",100});\n    }\n\n    // test debugging\n    handle.put(\"explain\", SKIPVAL);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP);\n    query(false, new Object[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY});\n\n    // try commitWithin\n    long before = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    for (SolrClient client : clients) {\n      assertEquals(\"unexpected pre-commitWithin document count on node: \" + ((HttpSolrClient)client).getBaseURL(), before, client.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"commitWithin\", 10);\n    add(cloudClient, params, getDoc(\"id\", 300));\n\n    final List<SolrClient> clientsToCheck = new ArrayList<>(clients);\n    TimeOut timeout = new TimeOut(45, TimeUnit.SECONDS);\n    do {\n      final Iterator<SolrClient> it = clientsToCheck.iterator();\n      while (it.hasNext()) {\n        final SolrClient sc = it.next();\n        if ((before + 1) == sc.query(new SolrQuery(\"*:*\")).getResults().getNumFound()) {\n          it.remove();\n        }\n      }\n      Thread.sleep(100);\n    } while (!clientsToCheck.isEmpty() && !timeout.hasTimedOut());\n    \n    assertTrue(\"commitWithin did not work on some nodes: \"+clientsToCheck, clientsToCheck.isEmpty());\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // would be better if these where all separate tests - but much, much\n    // slower\n    doOptimisticLockingAndUpdating();\n    testShardParamVariations();\n    testMultipleCollections();\n    testANewCollectionInOneInstance();\n    testSearchByCollectionName();\n    testUpdateByCollectionName();\n    testANewCollectionInOneInstanceWithManualShardAssignement();\n    testNumberOfCommitsWithCommitAfterAdd();\n\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-explicit\");\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-implicit\");\n\n    testStopAndStartCoresInOneInstance();\n    testFailedCoreCreateCleansUp();\n    // Thread.sleep(10000000000L);\n    if (DEBUG) {\n      super.printLayout();\n    }\n  }\n\n","sourceOld":"  @Test\n  @ShardsFixed(num = 4)\n  public void test() throws Exception {\n    // setLoggingLevel(null);\n\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    // make sure we have leaders for each shard\n    for (int j = 1; j < sliceCount; j++) {\n      zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n    }      // make sure we again have leaders for each shard\n    \n    waitForRecoveriesToFinish(false);\n    \n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    del(\"*:*\");\n    queryAndCompareShards(params(\"q\", \"*:*\", \"distrib\", \"false\", \"sanity_check\", \"is_empty\"));\n\n    // ask every individual replica of every shard to update+commit the same doc id\n    // with an incrementing counter on each update+commit\n    int foo_i_counter = 0;\n    for (SolrClient client : clients) {\n      foo_i_counter++;\n      indexDoc(client, params(\"commit\", \"true\"), // SOLR-4923\n               sdoc(id,1, i1,100, tlong,100, \"foo_i\", foo_i_counter));\n      // after every update+commit, check all the shards consistency\n      queryAndCompareShards(params(\"q\", \"id:1\", \"distrib\", \"false\", \n                                   \"sanity_check\", \"non_distrib_id_1_lookup\"));\n      queryAndCompareShards(params(\"q\", \"id:1\", \n                                   \"sanity_check\", \"distrib_id_1_lookup\"));\n    }\n\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\"\n            ,\"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\"\n    );\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\"\n    );\n    indexr(id,4, i1, -100 ,tlong, 101,t1,\"the quick fox jumped over the lazy dog\"\n    );\n    indexr(id,5, i1, 500, tlong, 500 ,t1,\"the quick fox jumped way over the lazy dog\"\n    );\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,t1,\"no eggs on wall, lesson learned\", oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n    queryAndCompareShards(params(\"q\", \"*:*\", \n                                 \"sort\", \"id desc\",\n                                 \"distrib\", \"false\", \n                                 \"sanity_check\", \"is_empty\"));\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" desc\"});\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" asc\"});\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" asc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"}); \n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 desc\"});\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"{!func}\"+i1});// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(false, new String[] {\"q\",\"{!func}\"+i1, \"fl\",\"*,score\"});  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\"});  // no fields in returned docs\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\"});\n\n    handle.put(\"score\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\",\"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\"});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"matchesnothing\",\"fl\",\"*,score\"});  \n\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.offset\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2});\n\n    // test faceting multiple things at once\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1});\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"}\n    );\n    query(false, new Object[] {\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\"});\n\n    // test field that is valid in schema but missing in all shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2});\n    // test field that is valid in schema and missing in some shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2});\n\n    query(false, new Object[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1});\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    // check a complex key name\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(false, new Object[] {\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"*:*\", \"rows\",100});\n    }\n\n    // test debugging\n    handle.put(\"explain\", SKIPVAL);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP);\n    query(false, new Object[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY});\n\n    // try commitWithin\n    long before = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"commitWithin\", 10);\n    add(cloudClient, params, getDoc(\"id\", 300));\n\n    TimeOut timeout = new TimeOut(45, TimeUnit.SECONDS);\n    while (cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound() != before + 1) {\n      if (timeout.hasTimedOut()) {\n        fail(\"commitWithin did not work\");\n      }\n      Thread.sleep(100);\n    }\n    \n    for (SolrClient client : clients) {\n      assertEquals(\"commitWithin did not work on node: \" + ((HttpSolrClient)client).getBaseURL(), before + 1, client.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // would be better if these where all separate tests - but much, much\n    // slower\n    doOptimisticLockingAndUpdating();\n    testShardParamVariations();\n    testMultipleCollections();\n    testANewCollectionInOneInstance();\n    testSearchByCollectionName();\n    testUpdateByCollectionName();\n    testANewCollectionInOneInstanceWithManualShardAssignement();\n    testNumberOfCommitsWithCommitAfterAdd();\n\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-explicit\");\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-implicit\");\n\n    testStopAndStartCoresInOneInstance();\n    testFailedCoreCreateCleansUp();\n    // Thread.sleep(10000000000L);\n    if (DEBUG) {\n      super.printLayout();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"175a04d27a2b736171e7e51ca46a03b2aec094d4","date":1452534768,"type":3,"author":"Christine Poerschke","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#test().mjava","sourceNew":"  @Test\n  @ShardsFixed(num = 4)\n  public void test() throws Exception {\n    // setLoggingLevel(null);\n\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    // make sure we have leaders for each shard\n    for (int j = 1; j < sliceCount; j++) {\n      zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n    }      // make sure we again have leaders for each shard\n    \n    waitForRecoveriesToFinish(false);\n    \n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    del(\"*:*\");\n    queryAndCompareShards(params(\"q\", \"*:*\", \"distrib\", \"false\", \"sanity_check\", \"is_empty\"));\n\n    // ask every individual replica of every shard to update+commit the same doc id\n    // with an incrementing counter on each update+commit\n    int foo_i_counter = 0;\n    for (SolrClient client : clients) {\n      foo_i_counter++;\n      indexDoc(client, params(\"commit\", \"true\"), // SOLR-4923\n               sdoc(id,1, i1,100, tlong,100, \"foo_i\", foo_i_counter));\n      // after every update+commit, check all the shards consistency\n      queryAndCompareShards(params(\"q\", \"id:1\", \"distrib\", \"false\", \n                                   \"sanity_check\", \"non_distrib_id_1_lookup\"));\n      queryAndCompareShards(params(\"q\", \"id:1\", \n                                   \"sanity_check\", \"distrib_id_1_lookup\"));\n    }\n\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\"\n            ,\"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\"\n    );\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\"\n    );\n    indexr(id,4, i1, -100 ,tlong, 101,t1,\"the quick fox jumped over the lazy dog\"\n    );\n    indexr(id,5, i1, 500, tlong, 500 ,t1,\"the quick fox jumped way over the lazy dog\"\n    );\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,t1,\"no eggs on wall, lesson learned\", oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n    queryAndCompareShards(params(\"q\", \"*:*\", \n                                 \"sort\", \"id desc\",\n                                 \"distrib\", \"false\", \n                                 \"sanity_check\", \"is_empty\"));\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" desc\"});\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" asc\"});\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" asc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"}); \n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 desc\"});\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"{!func}\"+i1});// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(false, new String[] {\"q\",\"{!func}\"+i1, \"fl\",\"*,score\"});  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\"});  // no fields in returned docs\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\"});\n\n    handle.put(\"score\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\",\"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\"});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"matchesnothing\",\"fl\",\"*,score\"});  \n\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.offset\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2});\n\n    // test faceting multiple things at once\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1});\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"}\n    );\n    query(false, new Object[] {\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\"});\n\n    // test field that is valid in schema but missing in all shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2});\n    // test field that is valid in schema and missing in some shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2});\n\n    query(false, new Object[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1});\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    // check a complex key name\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(false, new Object[] {\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"*:*\", \"rows\",100});\n    }\n\n    // test debugging\n    handle.put(\"explain\", SKIPVAL);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP);\n    query(false, new Object[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY});\n\n    // try commitWithin\n    long before = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    for (SolrClient client : clients) {\n      assertEquals(\"unexpected pre-commitWithin document count on node: \" + ((HttpSolrClient)client).getBaseURL(), before, client.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"commitWithin\", 10);\n    add(cloudClient, params, getDoc(\"id\", 300));\n\n    final List<SolrClient> clientsToCheck = new ArrayList<>(clients);\n    TimeOut timeout = new TimeOut(45, TimeUnit.SECONDS);\n    do {\n      final Iterator<SolrClient> it = clientsToCheck.iterator();\n      while (it.hasNext()) {\n        final SolrClient sc = it.next();\n        if ((before + 1) == sc.query(new SolrQuery(\"*:*\")).getResults().getNumFound()) {\n          it.remove();\n        }\n      }\n      Thread.sleep(100);\n    } while (!clientsToCheck.isEmpty() && !timeout.hasTimedOut());\n    \n    assertTrue(\"commitWithin did not work on some nodes: \"+clientsToCheck, clientsToCheck.isEmpty());\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // would be better if these where all separate tests - but much, much\n    // slower\n    doOptimisticLockingAndUpdating();\n    testShardParamVariations();\n    testMultipleCollections();\n    testANewCollectionInOneInstance();\n    testSearchByCollectionName();\n    testUpdateByCollectionName();\n    testANewCollectionInOneInstanceWithManualShardAssignement();\n    testNumberOfCommitsWithCommitAfterAdd();\n\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-explicit\");\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-implicit\");\n\n    testStopAndStartCoresInOneInstance();\n    // Thread.sleep(10000000000L);\n    if (DEBUG) {\n      super.printLayout();\n    }\n  }\n\n","sourceOld":"  @Test\n  @ShardsFixed(num = 4)\n  public void test() throws Exception {\n    // setLoggingLevel(null);\n\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    // make sure we have leaders for each shard\n    for (int j = 1; j < sliceCount; j++) {\n      zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n    }      // make sure we again have leaders for each shard\n    \n    waitForRecoveriesToFinish(false);\n    \n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    del(\"*:*\");\n    queryAndCompareShards(params(\"q\", \"*:*\", \"distrib\", \"false\", \"sanity_check\", \"is_empty\"));\n\n    // ask every individual replica of every shard to update+commit the same doc id\n    // with an incrementing counter on each update+commit\n    int foo_i_counter = 0;\n    for (SolrClient client : clients) {\n      foo_i_counter++;\n      indexDoc(client, params(\"commit\", \"true\"), // SOLR-4923\n               sdoc(id,1, i1,100, tlong,100, \"foo_i\", foo_i_counter));\n      // after every update+commit, check all the shards consistency\n      queryAndCompareShards(params(\"q\", \"id:1\", \"distrib\", \"false\", \n                                   \"sanity_check\", \"non_distrib_id_1_lookup\"));\n      queryAndCompareShards(params(\"q\", \"id:1\", \n                                   \"sanity_check\", \"distrib_id_1_lookup\"));\n    }\n\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\"\n            ,\"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\"\n    );\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\"\n    );\n    indexr(id,4, i1, -100 ,tlong, 101,t1,\"the quick fox jumped over the lazy dog\"\n    );\n    indexr(id,5, i1, 500, tlong, 500 ,t1,\"the quick fox jumped way over the lazy dog\"\n    );\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,t1,\"no eggs on wall, lesson learned\", oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n    queryAndCompareShards(params(\"q\", \"*:*\", \n                                 \"sort\", \"id desc\",\n                                 \"distrib\", \"false\", \n                                 \"sanity_check\", \"is_empty\"));\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" desc\"});\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" asc\"});\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" asc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"}); \n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 desc\"});\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"{!func}\"+i1});// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(false, new String[] {\"q\",\"{!func}\"+i1, \"fl\",\"*,score\"});  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\"});  // no fields in returned docs\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\"});\n\n    handle.put(\"score\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\",\"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\"});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"matchesnothing\",\"fl\",\"*,score\"});  \n\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.offset\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2});\n\n    // test faceting multiple things at once\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1});\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"}\n    );\n    query(false, new Object[] {\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\"});\n\n    // test field that is valid in schema but missing in all shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2});\n    // test field that is valid in schema and missing in some shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2});\n\n    query(false, new Object[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1});\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    // check a complex key name\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(false, new Object[] {\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"*:*\", \"rows\",100});\n    }\n\n    // test debugging\n    handle.put(\"explain\", SKIPVAL);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP);\n    query(false, new Object[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY});\n\n    // try commitWithin\n    long before = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    for (SolrClient client : clients) {\n      assertEquals(\"unexpected pre-commitWithin document count on node: \" + ((HttpSolrClient)client).getBaseURL(), before, client.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"commitWithin\", 10);\n    add(cloudClient, params, getDoc(\"id\", 300));\n\n    final List<SolrClient> clientsToCheck = new ArrayList<>(clients);\n    TimeOut timeout = new TimeOut(45, TimeUnit.SECONDS);\n    do {\n      final Iterator<SolrClient> it = clientsToCheck.iterator();\n      while (it.hasNext()) {\n        final SolrClient sc = it.next();\n        if ((before + 1) == sc.query(new SolrQuery(\"*:*\")).getResults().getNumFound()) {\n          it.remove();\n        }\n      }\n      Thread.sleep(100);\n    } while (!clientsToCheck.isEmpty() && !timeout.hasTimedOut());\n    \n    assertTrue(\"commitWithin did not work on some nodes: \"+clientsToCheck, clientsToCheck.isEmpty());\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // would be better if these where all separate tests - but much, much\n    // slower\n    doOptimisticLockingAndUpdating();\n    testShardParamVariations();\n    testMultipleCollections();\n    testANewCollectionInOneInstance();\n    testSearchByCollectionName();\n    testUpdateByCollectionName();\n    testANewCollectionInOneInstanceWithManualShardAssignement();\n    testNumberOfCommitsWithCommitAfterAdd();\n\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-explicit\");\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-implicit\");\n\n    testStopAndStartCoresInOneInstance();\n    testFailedCoreCreateCleansUp();\n    // Thread.sleep(10000000000L);\n    if (DEBUG) {\n      super.printLayout();\n    }\n  }\n\n","bugFix":["36f2b01395ef2bc334ebf2f94f2fe44e0f2921b1"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"68423be363a30c5a005b0eb6830c749d93b2b8db","date":1454893700,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#test().mjava","sourceNew":"  @Test\n  @ShardsFixed(num = 4)\n  public void test() throws Exception {\n    // setLoggingLevel(null);\n\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    // make sure we have leaders for each shard\n    for (int j = 1; j < sliceCount; j++) {\n      zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n    }      // make sure we again have leaders for each shard\n    \n    waitForRecoveriesToFinish(false);\n    \n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    del(\"*:*\");\n    queryAndCompareShards(params(\"q\", \"*:*\", \"distrib\", \"false\", \"sanity_check\", \"is_empty\"));\n\n    // ask every individual replica of every shard to update+commit the same doc id\n    // with an incrementing counter on each update+commit\n    int foo_i_counter = 0;\n    for (SolrClient client : clients) {\n      foo_i_counter++;\n      indexDoc(client, params(\"commit\", \"true\"), // SOLR-4923\n               sdoc(id,1, i1,100, tlong,100, \"foo_i\", foo_i_counter));\n      // after every update+commit, check all the shards consistency\n      queryAndCompareShards(params(\"q\", \"id:1\", \"distrib\", \"false\", \n                                   \"sanity_check\", \"non_distrib_id_1_lookup\"));\n      queryAndCompareShards(params(\"q\", \"id:1\", \n                                   \"sanity_check\", \"distrib_id_1_lookup\"));\n    }\n\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\"\n            ,\"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\"\n    );\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\"\n    );\n    indexr(id,4, i1, -100 ,tlong, 101,t1,\"the quick fox jumped over the lazy dog\"\n    );\n    indexr(id,5, i1, 500, tlong, 500 ,t1,\"the quick fox jumped way over the lazy dog\"\n    );\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,t1,\"no eggs on wall, lesson learned\", oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n    queryAndCompareShards(params(\"q\", \"*:*\", \n                                 \"sort\", \"id desc\",\n                                 \"distrib\", \"false\", \n                                 \"sanity_check\", \"is_empty\"));\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" desc\"});\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" asc\"});\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" asc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"}); \n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 desc\"});\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"{!func}\"+i1});// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(false, new String[] {\"q\",\"{!func}\"+i1, \"fl\",\"*,score\"});  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\"});  // no fields in returned docs\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\"});\n\n    handle.put(\"score\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\",\"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\"});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"matchesnothing\",\"fl\",\"*,score\"});  \n\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.offset\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2});\n\n    // test faceting multiple things at once\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1});\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"}\n    );\n    query(false, new Object[] {\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\"});\n\n    // test field that is valid in schema but missing in all shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2});\n    // test field that is valid in schema and missing in some shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2});\n\n    query(false, new Object[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1});\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    // check a complex key name\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(false, new Object[] {\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"*:*\", \"rows\",100});\n    }\n\n    // test debugging\n    handle.put(\"explain\", SKIPVAL);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP);\n    query(false, new Object[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY});\n\n    // try add commitWithin\n    long before = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    for (SolrClient client : clients) {\n      assertEquals(\"unexpected pre-commitWithin document count on node: \" + ((HttpSolrClient)client).getBaseURL(), before, client.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"commitWithin\", 10);\n    add(cloudClient, params , getDoc(\"id\", 300), getDoc(\"id\", 301));\n\n    waitForDocCount(before + 2, 30000, \"add commitWithin did not work\");\n\n    // try deleteById commitWithin\n    UpdateRequest deleteByIdReq = new UpdateRequest();\n    deleteByIdReq.deleteById(\"300\");\n    deleteByIdReq.setCommitWithin(10);\n    deleteByIdReq.process(cloudClient);\n\n    waitForDocCount(before + 1, 30000, \"deleteById commitWithin did not work\");\n\n    // try deleteByQuery commitWithin\n    UpdateRequest deleteByQueryReq = new UpdateRequest();\n    deleteByQueryReq.deleteByQuery(\"id:301\");\n    deleteByQueryReq.setCommitWithin(10);\n    deleteByQueryReq.process(cloudClient);\n\n    waitForDocCount(before, 30000, \"deleteByQuery commitWithin did not work\");\n\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // would be better if these where all separate tests - but much, much\n    // slower\n    doOptimisticLockingAndUpdating();\n    testShardParamVariations();\n    testMultipleCollections();\n    testANewCollectionInOneInstance();\n    testSearchByCollectionName();\n    testUpdateByCollectionName();\n    testANewCollectionInOneInstanceWithManualShardAssignement();\n    testNumberOfCommitsWithCommitAfterAdd();\n\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-explicit\");\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-implicit\");\n\n    testStopAndStartCoresInOneInstance();\n    // Thread.sleep(10000000000L);\n    if (DEBUG) {\n      super.printLayout();\n    }\n  }\n\n","sourceOld":"  @Test\n  @ShardsFixed(num = 4)\n  public void test() throws Exception {\n    // setLoggingLevel(null);\n\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    // make sure we have leaders for each shard\n    for (int j = 1; j < sliceCount; j++) {\n      zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n    }      // make sure we again have leaders for each shard\n    \n    waitForRecoveriesToFinish(false);\n    \n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    del(\"*:*\");\n    queryAndCompareShards(params(\"q\", \"*:*\", \"distrib\", \"false\", \"sanity_check\", \"is_empty\"));\n\n    // ask every individual replica of every shard to update+commit the same doc id\n    // with an incrementing counter on each update+commit\n    int foo_i_counter = 0;\n    for (SolrClient client : clients) {\n      foo_i_counter++;\n      indexDoc(client, params(\"commit\", \"true\"), // SOLR-4923\n               sdoc(id,1, i1,100, tlong,100, \"foo_i\", foo_i_counter));\n      // after every update+commit, check all the shards consistency\n      queryAndCompareShards(params(\"q\", \"id:1\", \"distrib\", \"false\", \n                                   \"sanity_check\", \"non_distrib_id_1_lookup\"));\n      queryAndCompareShards(params(\"q\", \"id:1\", \n                                   \"sanity_check\", \"distrib_id_1_lookup\"));\n    }\n\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\"\n            ,\"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\"\n    );\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\"\n    );\n    indexr(id,4, i1, -100 ,tlong, 101,t1,\"the quick fox jumped over the lazy dog\"\n    );\n    indexr(id,5, i1, 500, tlong, 500 ,t1,\"the quick fox jumped way over the lazy dog\"\n    );\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,t1,\"no eggs on wall, lesson learned\", oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n    queryAndCompareShards(params(\"q\", \"*:*\", \n                                 \"sort\", \"id desc\",\n                                 \"distrib\", \"false\", \n                                 \"sanity_check\", \"is_empty\"));\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" desc\"});\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" asc\"});\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" asc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"}); \n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 desc\"});\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"{!func}\"+i1});// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(false, new String[] {\"q\",\"{!func}\"+i1, \"fl\",\"*,score\"});  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\"});  // no fields in returned docs\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\"});\n\n    handle.put(\"score\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\",\"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\"});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"matchesnothing\",\"fl\",\"*,score\"});  \n\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.offset\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2});\n\n    // test faceting multiple things at once\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1});\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"}\n    );\n    query(false, new Object[] {\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\"});\n\n    // test field that is valid in schema but missing in all shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2});\n    // test field that is valid in schema and missing in some shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2});\n\n    query(false, new Object[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1});\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    // check a complex key name\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(false, new Object[] {\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"*:*\", \"rows\",100});\n    }\n\n    // test debugging\n    handle.put(\"explain\", SKIPVAL);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP);\n    query(false, new Object[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY});\n\n    // try commitWithin\n    long before = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    for (SolrClient client : clients) {\n      assertEquals(\"unexpected pre-commitWithin document count on node: \" + ((HttpSolrClient)client).getBaseURL(), before, client.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"commitWithin\", 10);\n    add(cloudClient, params, getDoc(\"id\", 300));\n\n    final List<SolrClient> clientsToCheck = new ArrayList<>(clients);\n    TimeOut timeout = new TimeOut(45, TimeUnit.SECONDS);\n    do {\n      final Iterator<SolrClient> it = clientsToCheck.iterator();\n      while (it.hasNext()) {\n        final SolrClient sc = it.next();\n        if ((before + 1) == sc.query(new SolrQuery(\"*:*\")).getResults().getNumFound()) {\n          it.remove();\n        }\n      }\n      Thread.sleep(100);\n    } while (!clientsToCheck.isEmpty() && !timeout.hasTimedOut());\n    \n    assertTrue(\"commitWithin did not work on some nodes: \"+clientsToCheck, clientsToCheck.isEmpty());\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // would be better if these where all separate tests - but much, much\n    // slower\n    doOptimisticLockingAndUpdating();\n    testShardParamVariations();\n    testMultipleCollections();\n    testANewCollectionInOneInstance();\n    testSearchByCollectionName();\n    testUpdateByCollectionName();\n    testANewCollectionInOneInstanceWithManualShardAssignement();\n    testNumberOfCommitsWithCommitAfterAdd();\n\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-explicit\");\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-implicit\");\n\n    testStopAndStartCoresInOneInstance();\n    // Thread.sleep(10000000000L);\n    if (DEBUG) {\n      super.printLayout();\n    }\n  }\n\n","bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"82fbc9a4af34a68002cd5cf8bbac6b604aeef413","date":1474634253,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#test().mjava","sourceNew":"  @Test\n  @ShardsFixed(num = 4)\n  public void test() throws Exception {\n    // setLoggingLevel(null);\n\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    // make sure we have leaders for each shard\n    for (int j = 1; j < sliceCount; j++) {\n      zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n    }      // make sure we again have leaders for each shard\n    \n    waitForRecoveriesToFinish(false);\n    \n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    del(\"*:*\");\n    queryAndCompareShards(params(\"q\", \"*:*\", \"distrib\", \"false\", \"sanity_check\", \"is_empty\"));\n\n    // ask every individual replica of every shard to update+commit the same doc id\n    // with an incrementing counter on each update+commit\n    int foo_i_counter = 0;\n    for (SolrClient client : clients) {\n      foo_i_counter++;\n      indexDoc(client, params(\"commit\", \"true\"), // SOLR-4923\n               sdoc(id,1, i1,100, tlong,100, \"foo_i\", foo_i_counter));\n      // after every update+commit, check all the shards consistency\n      queryAndCompareShards(params(\"q\", \"id:1\", \"distrib\", \"false\", \n                                   \"sanity_check\", \"non_distrib_id_1_lookup\"));\n      queryAndCompareShards(params(\"q\", \"id:1\", \n                                   \"sanity_check\", \"distrib_id_1_lookup\"));\n    }\n\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\"\n            ,\"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\"\n    );\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\"\n    );\n    indexr(id,4, i1, -100 ,tlong, 101,t1,\"the quick fox jumped over the lazy dog\"\n    );\n    indexr(id,5, i1, 500, tlong, 500 ,t1,\"the quick fox jumped way over the lazy dog\"\n    );\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,t1,\"no eggs on wall, lesson learned\", oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n    queryAndCompareShards(params(\"q\", \"*:*\", \n                                 \"sort\", \"id desc\",\n                                 \"distrib\", \"false\", \n                                 \"sanity_check\", \"is_empty\"));\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" desc\"});\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" asc\"});\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" asc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"}); \n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 desc\"});\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"{!func}\"+i1});// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(false, new String[] {\"q\",\"{!func}\"+i1, \"fl\",\"*,score\"});  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\"});  // no fields in returned docs\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\"});\n\n    handle.put(\"score\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\",\"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\"});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"matchesnothing\",\"fl\",\"*,score\"});  \n\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.offset\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2});\n\n    // test faceting multiple things at once\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1});\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"}\n    );\n    query(false, new Object[] {\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\"});\n\n    // test field that is valid in schema but missing in all shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2});\n    // test field that is valid in schema and missing in some shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2});\n\n    query(false, new Object[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1});\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    // check a complex key name\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(false, new Object[] {\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"*:*\", \"rows\",100});\n    }\n\n    // test debugging\n    handle.put(\"explain\", SKIPVAL);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP);\n    query(false, new Object[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY});\n\n    // try add commitWithin\n    long before = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    for (SolrClient client : clients) {\n      assertEquals(\"unexpected pre-commitWithin document count on node: \" + ((HttpSolrClient)client).getBaseURL(), before, client.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"commitWithin\", 10);\n    add(cloudClient, params , getDoc(\"id\", 300), getDoc(\"id\", 301));\n\n    waitForDocCount(before + 2, 30000, \"add commitWithin did not work\");\n\n    // try deleteById commitWithin\n    UpdateRequest deleteByIdReq = new UpdateRequest();\n    deleteByIdReq.deleteById(\"300\");\n    deleteByIdReq.setCommitWithin(10);\n    deleteByIdReq.process(cloudClient);\n\n    waitForDocCount(before + 1, 30000, \"deleteById commitWithin did not work\");\n\n    // try deleteByQuery commitWithin\n    UpdateRequest deleteByQueryReq = new UpdateRequest();\n    deleteByQueryReq.deleteByQuery(\"id:301\");\n    deleteByQueryReq.setCommitWithin(10);\n    deleteByQueryReq.process(cloudClient);\n\n    waitForDocCount(before, 30000, \"deleteByQuery commitWithin did not work\");\n\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // would be better if these where all separate tests - but much, much\n    // slower\n    doOptimisticLockingAndUpdating();\n    testShardParamVariations();\n    testMultipleCollections();\n    testANewCollectionInOneInstance();\n    testSearchByCollectionName();\n    testUpdateByCollectionName();\n    testANewCollectionInOneInstanceWithManualShardAssignement();\n    testNumberOfCommitsWithCommitAfterAdd();\n\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-explicit\");\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-implicit\");\n\n    testStopAndStartCoresInOneInstance();\n  }\n\n","sourceOld":"  @Test\n  @ShardsFixed(num = 4)\n  public void test() throws Exception {\n    // setLoggingLevel(null);\n\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    // make sure we have leaders for each shard\n    for (int j = 1; j < sliceCount; j++) {\n      zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n    }      // make sure we again have leaders for each shard\n    \n    waitForRecoveriesToFinish(false);\n    \n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    del(\"*:*\");\n    queryAndCompareShards(params(\"q\", \"*:*\", \"distrib\", \"false\", \"sanity_check\", \"is_empty\"));\n\n    // ask every individual replica of every shard to update+commit the same doc id\n    // with an incrementing counter on each update+commit\n    int foo_i_counter = 0;\n    for (SolrClient client : clients) {\n      foo_i_counter++;\n      indexDoc(client, params(\"commit\", \"true\"), // SOLR-4923\n               sdoc(id,1, i1,100, tlong,100, \"foo_i\", foo_i_counter));\n      // after every update+commit, check all the shards consistency\n      queryAndCompareShards(params(\"q\", \"id:1\", \"distrib\", \"false\", \n                                   \"sanity_check\", \"non_distrib_id_1_lookup\"));\n      queryAndCompareShards(params(\"q\", \"id:1\", \n                                   \"sanity_check\", \"distrib_id_1_lookup\"));\n    }\n\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\"\n            ,\"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\"\n    );\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\"\n    );\n    indexr(id,4, i1, -100 ,tlong, 101,t1,\"the quick fox jumped over the lazy dog\"\n    );\n    indexr(id,5, i1, 500, tlong, 500 ,t1,\"the quick fox jumped way over the lazy dog\"\n    );\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,t1,\"no eggs on wall, lesson learned\", oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n    queryAndCompareShards(params(\"q\", \"*:*\", \n                                 \"sort\", \"id desc\",\n                                 \"distrib\", \"false\", \n                                 \"sanity_check\", \"is_empty\"));\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" desc\"});\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" asc\"});\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" asc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"}); \n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 desc\"});\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"{!func}\"+i1});// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(false, new String[] {\"q\",\"{!func}\"+i1, \"fl\",\"*,score\"});  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\"});  // no fields in returned docs\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\"});\n\n    handle.put(\"score\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\",\"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\"});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"matchesnothing\",\"fl\",\"*,score\"});  \n\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.offset\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2});\n\n    // test faceting multiple things at once\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1});\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"}\n    );\n    query(false, new Object[] {\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\"});\n\n    // test field that is valid in schema but missing in all shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2});\n    // test field that is valid in schema and missing in some shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2});\n\n    query(false, new Object[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1});\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    // check a complex key name\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(false, new Object[] {\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"*:*\", \"rows\",100});\n    }\n\n    // test debugging\n    handle.put(\"explain\", SKIPVAL);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP);\n    query(false, new Object[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY});\n\n    // try add commitWithin\n    long before = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    for (SolrClient client : clients) {\n      assertEquals(\"unexpected pre-commitWithin document count on node: \" + ((HttpSolrClient)client).getBaseURL(), before, client.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"commitWithin\", 10);\n    add(cloudClient, params , getDoc(\"id\", 300), getDoc(\"id\", 301));\n\n    waitForDocCount(before + 2, 30000, \"add commitWithin did not work\");\n\n    // try deleteById commitWithin\n    UpdateRequest deleteByIdReq = new UpdateRequest();\n    deleteByIdReq.deleteById(\"300\");\n    deleteByIdReq.setCommitWithin(10);\n    deleteByIdReq.process(cloudClient);\n\n    waitForDocCount(before + 1, 30000, \"deleteById commitWithin did not work\");\n\n    // try deleteByQuery commitWithin\n    UpdateRequest deleteByQueryReq = new UpdateRequest();\n    deleteByQueryReq.deleteByQuery(\"id:301\");\n    deleteByQueryReq.setCommitWithin(10);\n    deleteByQueryReq.process(cloudClient);\n\n    waitForDocCount(before, 30000, \"deleteByQuery commitWithin did not work\");\n\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // would be better if these where all separate tests - but much, much\n    // slower\n    doOptimisticLockingAndUpdating();\n    testShardParamVariations();\n    testMultipleCollections();\n    testANewCollectionInOneInstance();\n    testSearchByCollectionName();\n    testUpdateByCollectionName();\n    testANewCollectionInOneInstanceWithManualShardAssignement();\n    testNumberOfCommitsWithCommitAfterAdd();\n\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-explicit\");\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-implicit\");\n\n    testStopAndStartCoresInOneInstance();\n    // Thread.sleep(10000000000L);\n    if (DEBUG) {\n      super.printLayout();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"17e5da53e4e5bd659e22add9bba1cfa222e7e30d","date":1475435902,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#test().mjava","sourceNew":"  @Test\n  @ShardsFixed(num = 4)\n  public void test() throws Exception {\n    // setLoggingLevel(null);\n\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    // make sure we have leaders for each shard\n    for (int j = 1; j < sliceCount; j++) {\n      zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n    }      // make sure we again have leaders for each shard\n    \n    waitForRecoveriesToFinish(false);\n    \n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    del(\"*:*\");\n    queryAndCompareShards(params(\"q\", \"*:*\", \"distrib\", \"false\", \"sanity_check\", \"is_empty\"));\n\n    // ask every individual replica of every shard to update+commit the same doc id\n    // with an incrementing counter on each update+commit\n    int foo_i_counter = 0;\n    for (SolrClient client : clients) {\n      foo_i_counter++;\n      indexDoc(client, params(\"commit\", \"true\"), // SOLR-4923\n               sdoc(id,1, i1,100, tlong,100, \"foo_i\", foo_i_counter));\n      // after every update+commit, check all the shards consistency\n      queryAndCompareShards(params(\"q\", \"id:1\", \"distrib\", \"false\", \n                                   \"sanity_check\", \"non_distrib_id_1_lookup\"));\n      queryAndCompareShards(params(\"q\", \"id:1\", \n                                   \"sanity_check\", \"distrib_id_1_lookup\"));\n    }\n\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\"\n            ,\"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\"\n    );\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\"\n    );\n    indexr(id,4, i1, -100 ,tlong, 101,t1,\"the quick fox jumped over the lazy dog\"\n    );\n    indexr(id,5, i1, 500, tlong, 500 ,t1,\"the quick fox jumped way over the lazy dog\"\n    );\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,t1,\"no eggs on wall, lesson learned\", oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n    queryAndCompareShards(params(\"q\", \"*:*\", \n                                 \"sort\", \"id desc\",\n                                 \"distrib\", \"false\", \n                                 \"sanity_check\", \"is_empty\"));\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" desc\"});\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" asc\"});\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" asc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"}); \n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 desc\"});\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"{!func}\"+i1});// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(false, new String[] {\"q\",\"{!func}\"+i1, \"fl\",\"*,score\"});  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\"});  // no fields in returned docs\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\"});\n\n    handle.put(\"score\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\",\"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\"});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"matchesnothing\",\"fl\",\"*,score\"});  \n\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.offset\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2});\n\n    // test faceting multiple things at once\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1});\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"}\n    );\n    query(false, new Object[] {\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\"});\n\n    // test field that is valid in schema but missing in all shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2});\n    // test field that is valid in schema and missing in some shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2});\n\n    query(false, new Object[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1});\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    // check a complex key name\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(false, new Object[] {\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"*:*\", \"rows\",100});\n    }\n\n    // test debugging\n    handle.put(\"explain\", SKIPVAL);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP);\n    query(false, new Object[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY});\n\n    // try add commitWithin\n    long before = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    for (SolrClient client : clients) {\n      assertEquals(\"unexpected pre-commitWithin document count on node: \" + ((HttpSolrClient)client).getBaseURL(), before, client.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"commitWithin\", 10);\n    add(cloudClient, params , getDoc(\"id\", 300), getDoc(\"id\", 301));\n\n    waitForDocCount(before + 2, 30000, \"add commitWithin did not work\");\n\n    // try deleteById commitWithin\n    UpdateRequest deleteByIdReq = new UpdateRequest();\n    deleteByIdReq.deleteById(\"300\");\n    deleteByIdReq.setCommitWithin(10);\n    deleteByIdReq.process(cloudClient);\n\n    waitForDocCount(before + 1, 30000, \"deleteById commitWithin did not work\");\n\n    // try deleteByQuery commitWithin\n    UpdateRequest deleteByQueryReq = new UpdateRequest();\n    deleteByQueryReq.deleteByQuery(\"id:301\");\n    deleteByQueryReq.setCommitWithin(10);\n    deleteByQueryReq.process(cloudClient);\n\n    waitForDocCount(before, 30000, \"deleteByQuery commitWithin did not work\");\n\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // would be better if these where all separate tests - but much, much\n    // slower\n    doOptimisticLockingAndUpdating();\n    testShardParamVariations();\n    testMultipleCollections();\n    testANewCollectionInOneInstance();\n    testSearchByCollectionName();\n    testUpdateByCollectionName();\n    testANewCollectionInOneInstanceWithManualShardAssignement();\n    testNumberOfCommitsWithCommitAfterAdd();\n\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-explicit\");\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-implicit\");\n\n    testStopAndStartCoresInOneInstance();\n  }\n\n","sourceOld":"  @Test\n  @ShardsFixed(num = 4)\n  public void test() throws Exception {\n    // setLoggingLevel(null);\n\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    // make sure we have leaders for each shard\n    for (int j = 1; j < sliceCount; j++) {\n      zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n    }      // make sure we again have leaders for each shard\n    \n    waitForRecoveriesToFinish(false);\n    \n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    del(\"*:*\");\n    queryAndCompareShards(params(\"q\", \"*:*\", \"distrib\", \"false\", \"sanity_check\", \"is_empty\"));\n\n    // ask every individual replica of every shard to update+commit the same doc id\n    // with an incrementing counter on each update+commit\n    int foo_i_counter = 0;\n    for (SolrClient client : clients) {\n      foo_i_counter++;\n      indexDoc(client, params(\"commit\", \"true\"), // SOLR-4923\n               sdoc(id,1, i1,100, tlong,100, \"foo_i\", foo_i_counter));\n      // after every update+commit, check all the shards consistency\n      queryAndCompareShards(params(\"q\", \"id:1\", \"distrib\", \"false\", \n                                   \"sanity_check\", \"non_distrib_id_1_lookup\"));\n      queryAndCompareShards(params(\"q\", \"id:1\", \n                                   \"sanity_check\", \"distrib_id_1_lookup\"));\n    }\n\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\"\n            ,\"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\"\n    );\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\"\n    );\n    indexr(id,4, i1, -100 ,tlong, 101,t1,\"the quick fox jumped over the lazy dog\"\n    );\n    indexr(id,5, i1, 500, tlong, 500 ,t1,\"the quick fox jumped way over the lazy dog\"\n    );\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,t1,\"no eggs on wall, lesson learned\", oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n    queryAndCompareShards(params(\"q\", \"*:*\", \n                                 \"sort\", \"id desc\",\n                                 \"distrib\", \"false\", \n                                 \"sanity_check\", \"is_empty\"));\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" desc\"});\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" asc\"});\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" asc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"}); \n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 desc\"});\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"{!func}\"+i1});// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(false, new String[] {\"q\",\"{!func}\"+i1, \"fl\",\"*,score\"});  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\"});  // no fields in returned docs\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\"});\n\n    handle.put(\"score\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\",\"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\"});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"matchesnothing\",\"fl\",\"*,score\"});  \n\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.offset\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2});\n\n    // test faceting multiple things at once\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1});\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"}\n    );\n    query(false, new Object[] {\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\"});\n\n    // test field that is valid in schema but missing in all shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2});\n    // test field that is valid in schema and missing in some shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2});\n\n    query(false, new Object[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1});\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    // check a complex key name\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(false, new Object[] {\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"*:*\", \"rows\",100});\n    }\n\n    // test debugging\n    handle.put(\"explain\", SKIPVAL);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP);\n    query(false, new Object[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY});\n\n    // try add commitWithin\n    long before = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    for (SolrClient client : clients) {\n      assertEquals(\"unexpected pre-commitWithin document count on node: \" + ((HttpSolrClient)client).getBaseURL(), before, client.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"commitWithin\", 10);\n    add(cloudClient, params , getDoc(\"id\", 300), getDoc(\"id\", 301));\n\n    waitForDocCount(before + 2, 30000, \"add commitWithin did not work\");\n\n    // try deleteById commitWithin\n    UpdateRequest deleteByIdReq = new UpdateRequest();\n    deleteByIdReq.deleteById(\"300\");\n    deleteByIdReq.setCommitWithin(10);\n    deleteByIdReq.process(cloudClient);\n\n    waitForDocCount(before + 1, 30000, \"deleteById commitWithin did not work\");\n\n    // try deleteByQuery commitWithin\n    UpdateRequest deleteByQueryReq = new UpdateRequest();\n    deleteByQueryReq.deleteByQuery(\"id:301\");\n    deleteByQueryReq.setCommitWithin(10);\n    deleteByQueryReq.process(cloudClient);\n\n    waitForDocCount(before, 30000, \"deleteByQuery commitWithin did not work\");\n\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // would be better if these where all separate tests - but much, much\n    // slower\n    doOptimisticLockingAndUpdating();\n    testShardParamVariations();\n    testMultipleCollections();\n    testANewCollectionInOneInstance();\n    testSearchByCollectionName();\n    testUpdateByCollectionName();\n    testANewCollectionInOneInstanceWithManualShardAssignement();\n    testNumberOfCommitsWithCommitAfterAdd();\n\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-explicit\");\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-implicit\");\n\n    testStopAndStartCoresInOneInstance();\n    // Thread.sleep(10000000000L);\n    if (DEBUG) {\n      super.printLayout();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#test().mjava","sourceNew":"  @Test\n  @ShardsFixed(num = 4)\n  public void test() throws Exception {\n    // setLoggingLevel(null);\n\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    // make sure we have leaders for each shard\n    for (int j = 1; j < sliceCount; j++) {\n      zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n    }      // make sure we again have leaders for each shard\n    \n    waitForRecoveriesToFinish(false);\n    \n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    del(\"*:*\");\n    queryAndCompareShards(params(\"q\", \"*:*\", \"distrib\", \"false\", \"sanity_check\", \"is_empty\"));\n\n    // ask every individual replica of every shard to update+commit the same doc id\n    // with an incrementing counter on each update+commit\n    int foo_i_counter = 0;\n    for (SolrClient client : clients) {\n      foo_i_counter++;\n      indexDoc(client, params(\"commit\", \"true\"), // SOLR-4923\n               sdoc(id,1, i1,100, tlong,100, \"foo_i\", foo_i_counter));\n      // after every update+commit, check all the shards consistency\n      queryAndCompareShards(params(\"q\", \"id:1\", \"distrib\", \"false\", \n                                   \"sanity_check\", \"non_distrib_id_1_lookup\"));\n      queryAndCompareShards(params(\"q\", \"id:1\", \n                                   \"sanity_check\", \"distrib_id_1_lookup\"));\n    }\n\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\"\n            ,\"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\"\n    );\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\"\n    );\n    indexr(id,4, i1, -100 ,tlong, 101,t1,\"the quick fox jumped over the lazy dog\"\n    );\n    indexr(id,5, i1, 500, tlong, 500 ,t1,\"the quick fox jumped way over the lazy dog\"\n    );\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,t1,\"no eggs on wall, lesson learned\", oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n    queryAndCompareShards(params(\"q\", \"*:*\", \n                                 \"sort\", \"id desc\",\n                                 \"distrib\", \"false\", \n                                 \"sanity_check\", \"is_empty\"));\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" desc\"});\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" asc\"});\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" asc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"}); \n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 desc\"});\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"{!func}\"+i1});// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(false, new String[] {\"q\",\"{!func}\"+i1, \"fl\",\"*,score\"});  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\"});  // no fields in returned docs\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\"});\n\n    handle.put(\"score\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\",\"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\"});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"matchesnothing\",\"fl\",\"*,score\"});  \n\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.offset\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2});\n\n    // test faceting multiple things at once\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1});\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"}\n    );\n    query(false, new Object[] {\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\"});\n\n    // test field that is valid in schema but missing in all shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2});\n    // test field that is valid in schema and missing in some shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2});\n\n    query(false, new Object[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1});\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    // check a complex key name\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(false, new Object[] {\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"*:*\", \"rows\",100});\n    }\n\n    // test debugging\n    handle.put(\"explain\", SKIPVAL);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP);\n    query(false, new Object[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY});\n\n    // try add commitWithin\n    long before = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    for (SolrClient client : clients) {\n      assertEquals(\"unexpected pre-commitWithin document count on node: \" + ((HttpSolrClient)client).getBaseURL(), before, client.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"commitWithin\", 10);\n    add(cloudClient, params , getDoc(\"id\", 300), getDoc(\"id\", 301));\n\n    waitForDocCount(before + 2, 30000, \"add commitWithin did not work\");\n\n    // try deleteById commitWithin\n    UpdateRequest deleteByIdReq = new UpdateRequest();\n    deleteByIdReq.deleteById(\"300\");\n    deleteByIdReq.setCommitWithin(10);\n    deleteByIdReq.process(cloudClient);\n\n    waitForDocCount(before + 1, 30000, \"deleteById commitWithin did not work\");\n\n    // try deleteByQuery commitWithin\n    UpdateRequest deleteByQueryReq = new UpdateRequest();\n    deleteByQueryReq.deleteByQuery(\"id:301\");\n    deleteByQueryReq.setCommitWithin(10);\n    deleteByQueryReq.process(cloudClient);\n\n    waitForDocCount(before, 30000, \"deleteByQuery commitWithin did not work\");\n\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // would be better if these where all separate tests - but much, much\n    // slower\n    doOptimisticLockingAndUpdating();\n    testShardParamVariations();\n    testMultipleCollections();\n    testANewCollectionInOneInstance();\n    testSearchByCollectionName();\n    testUpdateByCollectionName();\n    testANewCollectionInOneInstanceWithManualShardAssignement();\n    testNumberOfCommitsWithCommitAfterAdd();\n\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-explicit\");\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-implicit\");\n\n    testStopAndStartCoresInOneInstance();\n  }\n\n","sourceOld":"  @Test\n  @ShardsFixed(num = 4)\n  public void test() throws Exception {\n    // setLoggingLevel(null);\n\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    // make sure we have leaders for each shard\n    for (int j = 1; j < sliceCount; j++) {\n      zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n    }      // make sure we again have leaders for each shard\n    \n    waitForRecoveriesToFinish(false);\n    \n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    del(\"*:*\");\n    queryAndCompareShards(params(\"q\", \"*:*\", \"distrib\", \"false\", \"sanity_check\", \"is_empty\"));\n\n    // ask every individual replica of every shard to update+commit the same doc id\n    // with an incrementing counter on each update+commit\n    int foo_i_counter = 0;\n    for (SolrClient client : clients) {\n      foo_i_counter++;\n      indexDoc(client, params(\"commit\", \"true\"), // SOLR-4923\n               sdoc(id,1, i1,100, tlong,100, \"foo_i\", foo_i_counter));\n      // after every update+commit, check all the shards consistency\n      queryAndCompareShards(params(\"q\", \"id:1\", \"distrib\", \"false\", \n                                   \"sanity_check\", \"non_distrib_id_1_lookup\"));\n      queryAndCompareShards(params(\"q\", \"id:1\", \n                                   \"sanity_check\", \"distrib_id_1_lookup\"));\n    }\n\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\"\n            ,\"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\"\n    );\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\"\n    );\n    indexr(id,4, i1, -100 ,tlong, 101,t1,\"the quick fox jumped over the lazy dog\"\n    );\n    indexr(id,5, i1, 500, tlong, 500 ,t1,\"the quick fox jumped way over the lazy dog\"\n    );\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,t1,\"no eggs on wall, lesson learned\", oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n    queryAndCompareShards(params(\"q\", \"*:*\", \n                                 \"sort\", \"id desc\",\n                                 \"distrib\", \"false\", \n                                 \"sanity_check\", \"is_empty\"));\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" desc\"});\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" asc\"});\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" asc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"}); \n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 desc\"});\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"{!func}\"+i1});// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(false, new String[] {\"q\",\"{!func}\"+i1, \"fl\",\"*,score\"});  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\"});  // no fields in returned docs\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\"});\n\n    handle.put(\"score\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\",\"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\"});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"matchesnothing\",\"fl\",\"*,score\"});  \n\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.offset\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2});\n\n    // test faceting multiple things at once\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1});\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"}\n    );\n    query(false, new Object[] {\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\"});\n\n    // test field that is valid in schema but missing in all shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2});\n    // test field that is valid in schema and missing in some shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2});\n\n    query(false, new Object[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1});\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    // check a complex key name\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(false, new Object[] {\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"*:*\", \"rows\",100});\n    }\n\n    // test debugging\n    handle.put(\"explain\", SKIPVAL);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP);\n    query(false, new Object[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY});\n\n    // try add commitWithin\n    long before = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    for (SolrClient client : clients) {\n      assertEquals(\"unexpected pre-commitWithin document count on node: \" + ((HttpSolrClient)client).getBaseURL(), before, client.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"commitWithin\", 10);\n    add(cloudClient, params , getDoc(\"id\", 300), getDoc(\"id\", 301));\n\n    waitForDocCount(before + 2, 30000, \"add commitWithin did not work\");\n\n    // try deleteById commitWithin\n    UpdateRequest deleteByIdReq = new UpdateRequest();\n    deleteByIdReq.deleteById(\"300\");\n    deleteByIdReq.setCommitWithin(10);\n    deleteByIdReq.process(cloudClient);\n\n    waitForDocCount(before + 1, 30000, \"deleteById commitWithin did not work\");\n\n    // try deleteByQuery commitWithin\n    UpdateRequest deleteByQueryReq = new UpdateRequest();\n    deleteByQueryReq.deleteByQuery(\"id:301\");\n    deleteByQueryReq.setCommitWithin(10);\n    deleteByQueryReq.process(cloudClient);\n\n    waitForDocCount(before, 30000, \"deleteByQuery commitWithin did not work\");\n\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // would be better if these where all separate tests - but much, much\n    // slower\n    doOptimisticLockingAndUpdating();\n    testShardParamVariations();\n    testMultipleCollections();\n    testANewCollectionInOneInstance();\n    testSearchByCollectionName();\n    testUpdateByCollectionName();\n    testANewCollectionInOneInstanceWithManualShardAssignement();\n    testNumberOfCommitsWithCommitAfterAdd();\n\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-explicit\");\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-implicit\");\n\n    testStopAndStartCoresInOneInstance();\n    // Thread.sleep(10000000000L);\n    if (DEBUG) {\n      super.printLayout();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a71f63026529f3c1f03cfdd664910873ab2369ae","date":1497543264,"type":3,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#test().mjava","sourceNew":"  @Test\n  @ShardsFixed(num = 4)\n  public void test() throws Exception {\n    // setLoggingLevel(null);\n\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    // make sure we have leaders for each shard\n    for (int j = 1; j < sliceCount; j++) {\n      zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n    }      // make sure we again have leaders for each shard\n    \n    waitForRecoveriesToFinish(false);\n    \n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    del(\"*:*\");\n    queryAndCompareShards(params(\"q\", \"*:*\", \"distrib\", \"false\", \"sanity_check\", \"is_empty\"));\n\n    // ask every individual replica of every shard to update+commit the same doc id\n    // with an incrementing counter on each update+commit\n    int foo_i_counter = 0;\n    for (SolrClient client : clients) {\n      foo_i_counter++;\n      indexDoc(client, params(\"commit\", \"true\"), // SOLR-4923\n               sdoc(id,1, i1,100, tlong,100, \"foo_i\", foo_i_counter));\n      // after every update+commit, check all the shards consistency\n      queryAndCompareShards(params(\"q\", \"id:1\", \"distrib\", \"false\", \n                                   \"sanity_check\", \"non_distrib_id_1_lookup\"));\n      queryAndCompareShards(params(\"q\", \"id:1\", \n                                   \"sanity_check\", \"distrib_id_1_lookup\"));\n    }\n\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\"\n            ,\"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\"\n    );\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\"\n    );\n    indexr(id,4, i1, -100 ,tlong, 101,t1,\"the quick fox jumped over the lazy dog\"\n    );\n    indexr(id,5, i1, 500, tlong, 500 ,t1,\"the quick fox jumped way over the lazy dog\"\n    );\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,t1,\"no eggs on wall, lesson learned\", oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n    queryAndCompareShards(params(\"q\", \"*:*\", \n                                 \"sort\", \"id desc\",\n                                 \"distrib\", \"false\", \n                                 \"sanity_check\", \"is_empty\"));\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" desc\"});\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" asc\"});\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" asc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"}); \n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 desc\"});\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"{!func}\"+i1});// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(false, new String[] {\"q\",\"{!func}\"+i1, \"fl\",\"*,score\"});  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\"});  // no fields in returned docs\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\"});\n\n    handle.put(\"score\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\",\"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\"});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"matchesnothing\",\"fl\",\"*,score\"});  \n\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.offset\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2});\n\n    // test faceting multiple things at once\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1});\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id_i1:[1 TO 7]\", \"fq\",\"{!tag=b}id_i1:[3 TO 9]\"}\n    );\n    query(false, new Object[] {\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\"});\n\n    // test field that is valid in schema but missing in all shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2});\n    // test field that is valid in schema and missing in some shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2});\n\n    query(false, new Object[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1});\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    // check a complex key name\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(false, new Object[] {\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"*:*\", \"rows\",100});\n    }\n\n    // test debugging\n    handle.put(\"explain\", SKIPVAL);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP);\n    query(false, new Object[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY});\n\n    // try add commitWithin\n    long before = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    for (SolrClient client : clients) {\n      assertEquals(\"unexpected pre-commitWithin document count on node: \" + ((HttpSolrClient)client).getBaseURL(), before, client.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"commitWithin\", 10);\n    add(cloudClient, params , getDoc(\"id\", 300), getDoc(\"id\", 301));\n\n    waitForDocCount(before + 2, 30000, \"add commitWithin did not work\");\n\n    // try deleteById commitWithin\n    UpdateRequest deleteByIdReq = new UpdateRequest();\n    deleteByIdReq.deleteById(\"300\");\n    deleteByIdReq.setCommitWithin(10);\n    deleteByIdReq.process(cloudClient);\n\n    waitForDocCount(before + 1, 30000, \"deleteById commitWithin did not work\");\n\n    // try deleteByQuery commitWithin\n    UpdateRequest deleteByQueryReq = new UpdateRequest();\n    deleteByQueryReq.deleteByQuery(\"id:301\");\n    deleteByQueryReq.setCommitWithin(10);\n    deleteByQueryReq.process(cloudClient);\n\n    waitForDocCount(before, 30000, \"deleteByQuery commitWithin did not work\");\n\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // would be better if these where all separate tests - but much, much\n    // slower\n    doOptimisticLockingAndUpdating();\n    testShardParamVariations();\n    testMultipleCollections();\n    testANewCollectionInOneInstance();\n    testSearchByCollectionName();\n    testUpdateByCollectionName();\n    testANewCollectionInOneInstanceWithManualShardAssignement();\n    testNumberOfCommitsWithCommitAfterAdd();\n\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-explicit\");\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-implicit\");\n\n    testStopAndStartCoresInOneInstance();\n  }\n\n","sourceOld":"  @Test\n  @ShardsFixed(num = 4)\n  public void test() throws Exception {\n    // setLoggingLevel(null);\n\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    // make sure we have leaders for each shard\n    for (int j = 1; j < sliceCount; j++) {\n      zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n    }      // make sure we again have leaders for each shard\n    \n    waitForRecoveriesToFinish(false);\n    \n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    del(\"*:*\");\n    queryAndCompareShards(params(\"q\", \"*:*\", \"distrib\", \"false\", \"sanity_check\", \"is_empty\"));\n\n    // ask every individual replica of every shard to update+commit the same doc id\n    // with an incrementing counter on each update+commit\n    int foo_i_counter = 0;\n    for (SolrClient client : clients) {\n      foo_i_counter++;\n      indexDoc(client, params(\"commit\", \"true\"), // SOLR-4923\n               sdoc(id,1, i1,100, tlong,100, \"foo_i\", foo_i_counter));\n      // after every update+commit, check all the shards consistency\n      queryAndCompareShards(params(\"q\", \"id:1\", \"distrib\", \"false\", \n                                   \"sanity_check\", \"non_distrib_id_1_lookup\"));\n      queryAndCompareShards(params(\"q\", \"id:1\", \n                                   \"sanity_check\", \"distrib_id_1_lookup\"));\n    }\n\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\"\n            ,\"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\"\n    );\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\"\n    );\n    indexr(id,4, i1, -100 ,tlong, 101,t1,\"the quick fox jumped over the lazy dog\"\n    );\n    indexr(id,5, i1, 500, tlong, 500 ,t1,\"the quick fox jumped way over the lazy dog\"\n    );\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,t1,\"no eggs on wall, lesson learned\", oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n    queryAndCompareShards(params(\"q\", \"*:*\", \n                                 \"sort\", \"id desc\",\n                                 \"distrib\", \"false\", \n                                 \"sanity_check\", \"is_empty\"));\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" desc\"});\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" asc\"});\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" asc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"}); \n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 desc\"});\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"{!func}\"+i1});// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(false, new String[] {\"q\",\"{!func}\"+i1, \"fl\",\"*,score\"});  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\"});  // no fields in returned docs\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\"});\n\n    handle.put(\"score\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\",\"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\"});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"matchesnothing\",\"fl\",\"*,score\"});  \n\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.offset\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2});\n\n    // test faceting multiple things at once\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1});\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"}\n    );\n    query(false, new Object[] {\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\"});\n\n    // test field that is valid in schema but missing in all shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2});\n    // test field that is valid in schema and missing in some shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2});\n\n    query(false, new Object[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1});\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    // check a complex key name\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(false, new Object[] {\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"*:*\", \"rows\",100});\n    }\n\n    // test debugging\n    handle.put(\"explain\", SKIPVAL);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP);\n    query(false, new Object[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY});\n\n    // try add commitWithin\n    long before = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    for (SolrClient client : clients) {\n      assertEquals(\"unexpected pre-commitWithin document count on node: \" + ((HttpSolrClient)client).getBaseURL(), before, client.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"commitWithin\", 10);\n    add(cloudClient, params , getDoc(\"id\", 300), getDoc(\"id\", 301));\n\n    waitForDocCount(before + 2, 30000, \"add commitWithin did not work\");\n\n    // try deleteById commitWithin\n    UpdateRequest deleteByIdReq = new UpdateRequest();\n    deleteByIdReq.deleteById(\"300\");\n    deleteByIdReq.setCommitWithin(10);\n    deleteByIdReq.process(cloudClient);\n\n    waitForDocCount(before + 1, 30000, \"deleteById commitWithin did not work\");\n\n    // try deleteByQuery commitWithin\n    UpdateRequest deleteByQueryReq = new UpdateRequest();\n    deleteByQueryReq.deleteByQuery(\"id:301\");\n    deleteByQueryReq.setCommitWithin(10);\n    deleteByQueryReq.process(cloudClient);\n\n    waitForDocCount(before, 30000, \"deleteByQuery commitWithin did not work\");\n\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // would be better if these where all separate tests - but much, much\n    // slower\n    doOptimisticLockingAndUpdating();\n    testShardParamVariations();\n    testMultipleCollections();\n    testANewCollectionInOneInstance();\n    testSearchByCollectionName();\n    testUpdateByCollectionName();\n    testANewCollectionInOneInstanceWithManualShardAssignement();\n    testNumberOfCommitsWithCommitAfterAdd();\n\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-explicit\");\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-implicit\");\n\n    testStopAndStartCoresInOneInstance();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9","date":1498028748,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#test().mjava","sourceNew":"  @Test\n  @ShardsFixed(num = 4)\n  public void test() throws Exception {\n    // setLoggingLevel(null);\n\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    // make sure we have leaders for each shard\n    for (int j = 1; j < sliceCount; j++) {\n      zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n    }      // make sure we again have leaders for each shard\n    \n    waitForRecoveriesToFinish(false);\n    \n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    del(\"*:*\");\n    queryAndCompareShards(params(\"q\", \"*:*\", \"distrib\", \"false\", \"sanity_check\", \"is_empty\"));\n\n    // ask every individual replica of every shard to update+commit the same doc id\n    // with an incrementing counter on each update+commit\n    int foo_i_counter = 0;\n    for (SolrClient client : clients) {\n      foo_i_counter++;\n      indexDoc(client, params(\"commit\", \"true\"), // SOLR-4923\n               sdoc(id,1, i1,100, tlong,100, \"foo_i\", foo_i_counter));\n      // after every update+commit, check all the shards consistency\n      queryAndCompareShards(params(\"q\", \"id:1\", \"distrib\", \"false\", \n                                   \"sanity_check\", \"non_distrib_id_1_lookup\"));\n      queryAndCompareShards(params(\"q\", \"id:1\", \n                                   \"sanity_check\", \"distrib_id_1_lookup\"));\n    }\n\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\"\n            ,\"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\"\n    );\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\"\n    );\n    indexr(id,4, i1, -100 ,tlong, 101,t1,\"the quick fox jumped over the lazy dog\"\n    );\n    indexr(id,5, i1, 500, tlong, 500 ,t1,\"the quick fox jumped way over the lazy dog\"\n    );\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,t1,\"no eggs on wall, lesson learned\", oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n    queryAndCompareShards(params(\"q\", \"*:*\", \n                                 \"sort\", \"id desc\",\n                                 \"distrib\", \"false\", \n                                 \"sanity_check\", \"is_empty\"));\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" desc\"});\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" asc\"});\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" asc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"}); \n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 desc\"});\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"{!func}\"+i1});// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(false, new String[] {\"q\",\"{!func}\"+i1, \"fl\",\"*,score\"});  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\"});  // no fields in returned docs\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\"});\n\n    handle.put(\"score\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\",\"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\"});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"matchesnothing\",\"fl\",\"*,score\"});  \n\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.offset\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2});\n\n    // test faceting multiple things at once\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1});\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id_i1:[1 TO 7]\", \"fq\",\"{!tag=b}id_i1:[3 TO 9]\"}\n    );\n    query(false, new Object[] {\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\"});\n\n    // test field that is valid in schema but missing in all shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2});\n    // test field that is valid in schema and missing in some shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2});\n\n    query(false, new Object[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1});\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    // check a complex key name\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(false, new Object[] {\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"*:*\", \"rows\",100});\n    }\n\n    // test debugging\n    handle.put(\"explain\", SKIPVAL);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP);\n    query(false, new Object[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY});\n\n    // try add commitWithin\n    long before = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    for (SolrClient client : clients) {\n      assertEquals(\"unexpected pre-commitWithin document count on node: \" + ((HttpSolrClient)client).getBaseURL(), before, client.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"commitWithin\", 10);\n    add(cloudClient, params , getDoc(\"id\", 300), getDoc(\"id\", 301));\n\n    waitForDocCount(before + 2, 30000, \"add commitWithin did not work\");\n\n    // try deleteById commitWithin\n    UpdateRequest deleteByIdReq = new UpdateRequest();\n    deleteByIdReq.deleteById(\"300\");\n    deleteByIdReq.setCommitWithin(10);\n    deleteByIdReq.process(cloudClient);\n\n    waitForDocCount(before + 1, 30000, \"deleteById commitWithin did not work\");\n\n    // try deleteByQuery commitWithin\n    UpdateRequest deleteByQueryReq = new UpdateRequest();\n    deleteByQueryReq.deleteByQuery(\"id:301\");\n    deleteByQueryReq.setCommitWithin(10);\n    deleteByQueryReq.process(cloudClient);\n\n    waitForDocCount(before, 30000, \"deleteByQuery commitWithin did not work\");\n\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // would be better if these where all separate tests - but much, much\n    // slower\n    doOptimisticLockingAndUpdating();\n    testShardParamVariations();\n    testMultipleCollections();\n    testANewCollectionInOneInstance();\n    testSearchByCollectionName();\n    testUpdateByCollectionName();\n    testANewCollectionInOneInstanceWithManualShardAssignement();\n    testNumberOfCommitsWithCommitAfterAdd();\n\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-explicit\");\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-implicit\");\n\n    testStopAndStartCoresInOneInstance();\n  }\n\n","sourceOld":"  @Test\n  @ShardsFixed(num = 4)\n  public void test() throws Exception {\n    // setLoggingLevel(null);\n\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    // make sure we have leaders for each shard\n    for (int j = 1; j < sliceCount; j++) {\n      zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n    }      // make sure we again have leaders for each shard\n    \n    waitForRecoveriesToFinish(false);\n    \n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    del(\"*:*\");\n    queryAndCompareShards(params(\"q\", \"*:*\", \"distrib\", \"false\", \"sanity_check\", \"is_empty\"));\n\n    // ask every individual replica of every shard to update+commit the same doc id\n    // with an incrementing counter on each update+commit\n    int foo_i_counter = 0;\n    for (SolrClient client : clients) {\n      foo_i_counter++;\n      indexDoc(client, params(\"commit\", \"true\"), // SOLR-4923\n               sdoc(id,1, i1,100, tlong,100, \"foo_i\", foo_i_counter));\n      // after every update+commit, check all the shards consistency\n      queryAndCompareShards(params(\"q\", \"id:1\", \"distrib\", \"false\", \n                                   \"sanity_check\", \"non_distrib_id_1_lookup\"));\n      queryAndCompareShards(params(\"q\", \"id:1\", \n                                   \"sanity_check\", \"distrib_id_1_lookup\"));\n    }\n\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\"\n            ,\"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\"\n    );\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\"\n    );\n    indexr(id,4, i1, -100 ,tlong, 101,t1,\"the quick fox jumped over the lazy dog\"\n    );\n    indexr(id,5, i1, 500, tlong, 500 ,t1,\"the quick fox jumped way over the lazy dog\"\n    );\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,t1,\"no eggs on wall, lesson learned\", oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n    queryAndCompareShards(params(\"q\", \"*:*\", \n                                 \"sort\", \"id desc\",\n                                 \"distrib\", \"false\", \n                                 \"sanity_check\", \"is_empty\"));\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" desc\"});\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" asc\"});\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" asc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"}); \n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 desc\"});\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"{!func}\"+i1});// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(false, new String[] {\"q\",\"{!func}\"+i1, \"fl\",\"*,score\"});  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\"});  // no fields in returned docs\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\"});\n\n    handle.put(\"score\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\",\"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\"});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"matchesnothing\",\"fl\",\"*,score\"});  \n\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.offset\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2});\n\n    // test faceting multiple things at once\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1});\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"}\n    );\n    query(false, new Object[] {\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\"});\n\n    // test field that is valid in schema but missing in all shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2});\n    // test field that is valid in schema and missing in some shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2});\n\n    query(false, new Object[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1});\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    // check a complex key name\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(false, new Object[] {\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"*:*\", \"rows\",100});\n    }\n\n    // test debugging\n    handle.put(\"explain\", SKIPVAL);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP);\n    query(false, new Object[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY});\n\n    // try add commitWithin\n    long before = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    for (SolrClient client : clients) {\n      assertEquals(\"unexpected pre-commitWithin document count on node: \" + ((HttpSolrClient)client).getBaseURL(), before, client.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"commitWithin\", 10);\n    add(cloudClient, params , getDoc(\"id\", 300), getDoc(\"id\", 301));\n\n    waitForDocCount(before + 2, 30000, \"add commitWithin did not work\");\n\n    // try deleteById commitWithin\n    UpdateRequest deleteByIdReq = new UpdateRequest();\n    deleteByIdReq.deleteById(\"300\");\n    deleteByIdReq.setCommitWithin(10);\n    deleteByIdReq.process(cloudClient);\n\n    waitForDocCount(before + 1, 30000, \"deleteById commitWithin did not work\");\n\n    // try deleteByQuery commitWithin\n    UpdateRequest deleteByQueryReq = new UpdateRequest();\n    deleteByQueryReq.deleteByQuery(\"id:301\");\n    deleteByQueryReq.setCommitWithin(10);\n    deleteByQueryReq.process(cloudClient);\n\n    waitForDocCount(before, 30000, \"deleteByQuery commitWithin did not work\");\n\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // would be better if these where all separate tests - but much, much\n    // slower\n    doOptimisticLockingAndUpdating();\n    testShardParamVariations();\n    testMultipleCollections();\n    testANewCollectionInOneInstance();\n    testSearchByCollectionName();\n    testUpdateByCollectionName();\n    testANewCollectionInOneInstanceWithManualShardAssignement();\n    testNumberOfCommitsWithCommitAfterAdd();\n\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-explicit\");\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-implicit\");\n\n    testStopAndStartCoresInOneInstance();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"28288370235ed02234a64753cdbf0c6ec096304a","date":1498726817,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#test().mjava","sourceNew":"  @Test\n  @ShardsFixed(num = 4)\n  public void test() throws Exception {\n    // setLoggingLevel(null);\n\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    // make sure we have leaders for each shard\n    for (int j = 1; j < sliceCount; j++) {\n      zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n    }      // make sure we again have leaders for each shard\n    \n    waitForRecoveriesToFinish(false);\n    \n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    del(\"*:*\");\n    queryAndCompareShards(params(\"q\", \"*:*\", \"distrib\", \"false\", \"sanity_check\", \"is_empty\"));\n\n    // ask every individual replica of every shard to update+commit the same doc id\n    // with an incrementing counter on each update+commit\n    int foo_i_counter = 0;\n    for (SolrClient client : clients) {\n      foo_i_counter++;\n      indexDoc(client, params(\"commit\", \"true\"), // SOLR-4923\n               sdoc(id,1, i1,100, tlong,100, \"foo_i\", foo_i_counter));\n      // after every update+commit, check all the shards consistency\n      queryAndCompareShards(params(\"q\", \"id:1\", \"distrib\", \"false\", \n                                   \"sanity_check\", \"non_distrib_id_1_lookup\"));\n      queryAndCompareShards(params(\"q\", \"id:1\", \n                                   \"sanity_check\", \"distrib_id_1_lookup\"));\n    }\n\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\"\n            ,\"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\"\n    );\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\"\n    );\n    indexr(id,4, i1, -100 ,tlong, 101,t1,\"the quick fox jumped over the lazy dog\"\n    );\n    indexr(id,5, i1, 500, tlong, 500 ,t1,\"the quick fox jumped way over the lazy dog\"\n    );\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,t1,\"no eggs on wall, lesson learned\", oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n    queryAndCompareShards(params(\"q\", \"*:*\", \n                                 \"sort\", \"id desc\",\n                                 \"distrib\", \"false\", \n                                 \"sanity_check\", \"is_empty\"));\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" desc\"});\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" asc\"});\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" asc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"}); \n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 desc\"});\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"{!func}\"+i1});// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(false, new String[] {\"q\",\"{!func}\"+i1, \"fl\",\"*,score\"});  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\"});  // no fields in returned docs\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\"});\n\n    handle.put(\"score\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\",\"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\"});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"matchesnothing\",\"fl\",\"*,score\"});  \n\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.offset\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2});\n\n    // test faceting multiple things at once\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1});\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id_i1:[1 TO 7]\", \"fq\",\"{!tag=b}id_i1:[3 TO 9]\"}\n    );\n    query(false, new Object[] {\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\"});\n\n    // test field that is valid in schema but missing in all shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2});\n    // test field that is valid in schema and missing in some shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2});\n\n    query(false, new Object[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1});\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    // check a complex key name\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(false, new Object[] {\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"*:*\", \"rows\",100});\n    }\n\n    // test debugging\n    handle.put(\"explain\", SKIPVAL);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP);\n    query(false, new Object[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY});\n\n    // try add commitWithin\n    long before = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    for (SolrClient client : clients) {\n      assertEquals(\"unexpected pre-commitWithin document count on node: \" + ((HttpSolrClient)client).getBaseURL(), before, client.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"commitWithin\", 10);\n    add(cloudClient, params , getDoc(\"id\", 300), getDoc(\"id\", 301));\n\n    waitForDocCount(before + 2, 30000, \"add commitWithin did not work\");\n\n    // try deleteById commitWithin\n    UpdateRequest deleteByIdReq = new UpdateRequest();\n    deleteByIdReq.deleteById(\"300\");\n    deleteByIdReq.setCommitWithin(10);\n    deleteByIdReq.process(cloudClient);\n\n    waitForDocCount(before + 1, 30000, \"deleteById commitWithin did not work\");\n\n    // try deleteByQuery commitWithin\n    UpdateRequest deleteByQueryReq = new UpdateRequest();\n    deleteByQueryReq.deleteByQuery(\"id:301\");\n    deleteByQueryReq.setCommitWithin(10);\n    deleteByQueryReq.process(cloudClient);\n\n    waitForDocCount(before, 30000, \"deleteByQuery commitWithin did not work\");\n\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // would be better if these where all separate tests - but much, much\n    // slower\n    doOptimisticLockingAndUpdating();\n    testShardParamVariations();\n    testMultipleCollections();\n    testANewCollectionInOneInstance();\n    testSearchByCollectionName();\n    testUpdateByCollectionName();\n    testANewCollectionInOneInstanceWithManualShardAssignement();\n    testNumberOfCommitsWithCommitAfterAdd();\n\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-explicit\");\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-implicit\");\n\n    testStopAndStartCoresInOneInstance();\n  }\n\n","sourceOld":"  @Test\n  @ShardsFixed(num = 4)\n  public void test() throws Exception {\n    // setLoggingLevel(null);\n\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    // make sure we have leaders for each shard\n    for (int j = 1; j < sliceCount; j++) {\n      zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n    }      // make sure we again have leaders for each shard\n    \n    waitForRecoveriesToFinish(false);\n    \n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    del(\"*:*\");\n    queryAndCompareShards(params(\"q\", \"*:*\", \"distrib\", \"false\", \"sanity_check\", \"is_empty\"));\n\n    // ask every individual replica of every shard to update+commit the same doc id\n    // with an incrementing counter on each update+commit\n    int foo_i_counter = 0;\n    for (SolrClient client : clients) {\n      foo_i_counter++;\n      indexDoc(client, params(\"commit\", \"true\"), // SOLR-4923\n               sdoc(id,1, i1,100, tlong,100, \"foo_i\", foo_i_counter));\n      // after every update+commit, check all the shards consistency\n      queryAndCompareShards(params(\"q\", \"id:1\", \"distrib\", \"false\", \n                                   \"sanity_check\", \"non_distrib_id_1_lookup\"));\n      queryAndCompareShards(params(\"q\", \"id:1\", \n                                   \"sanity_check\", \"distrib_id_1_lookup\"));\n    }\n\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\"\n            ,\"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\"\n    );\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\"\n    );\n    indexr(id,4, i1, -100 ,tlong, 101,t1,\"the quick fox jumped over the lazy dog\"\n    );\n    indexr(id,5, i1, 500, tlong, 500 ,t1,\"the quick fox jumped way over the lazy dog\"\n    );\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,t1,\"no eggs on wall, lesson learned\", oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n    queryAndCompareShards(params(\"q\", \"*:*\", \n                                 \"sort\", \"id desc\",\n                                 \"distrib\", \"false\", \n                                 \"sanity_check\", \"is_empty\"));\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" desc\"});\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" asc\"});\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" asc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"}); \n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 desc\"});\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"{!func}\"+i1});// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(false, new String[] {\"q\",\"{!func}\"+i1, \"fl\",\"*,score\"});  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\"});  // no fields in returned docs\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\"});\n\n    handle.put(\"score\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\",\"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\"});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"matchesnothing\",\"fl\",\"*,score\"});  \n\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.offset\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2});\n\n    // test faceting multiple things at once\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1});\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"}\n    );\n    query(false, new Object[] {\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\"});\n\n    // test field that is valid in schema but missing in all shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2});\n    // test field that is valid in schema and missing in some shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2});\n\n    query(false, new Object[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1});\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    // check a complex key name\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(false, new Object[] {\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"*:*\", \"rows\",100});\n    }\n\n    // test debugging\n    handle.put(\"explain\", SKIPVAL);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP);\n    query(false, new Object[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS});\n    query(false, new Object[] {\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY});\n\n    // try add commitWithin\n    long before = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    for (SolrClient client : clients) {\n      assertEquals(\"unexpected pre-commitWithin document count on node: \" + ((HttpSolrClient)client).getBaseURL(), before, client.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"commitWithin\", 10);\n    add(cloudClient, params , getDoc(\"id\", 300), getDoc(\"id\", 301));\n\n    waitForDocCount(before + 2, 30000, \"add commitWithin did not work\");\n\n    // try deleteById commitWithin\n    UpdateRequest deleteByIdReq = new UpdateRequest();\n    deleteByIdReq.deleteById(\"300\");\n    deleteByIdReq.setCommitWithin(10);\n    deleteByIdReq.process(cloudClient);\n\n    waitForDocCount(before + 1, 30000, \"deleteById commitWithin did not work\");\n\n    // try deleteByQuery commitWithin\n    UpdateRequest deleteByQueryReq = new UpdateRequest();\n    deleteByQueryReq.deleteByQuery(\"id:301\");\n    deleteByQueryReq.setCommitWithin(10);\n    deleteByQueryReq.process(cloudClient);\n\n    waitForDocCount(before, 30000, \"deleteByQuery commitWithin did not work\");\n\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // would be better if these where all separate tests - but much, much\n    // slower\n    doOptimisticLockingAndUpdating();\n    testShardParamVariations();\n    testMultipleCollections();\n    testANewCollectionInOneInstance();\n    testSearchByCollectionName();\n    testUpdateByCollectionName();\n    testANewCollectionInOneInstanceWithManualShardAssignement();\n    testNumberOfCommitsWithCommitAfterAdd();\n\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-explicit\");\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-implicit\");\n\n    testStopAndStartCoresInOneInstance();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a1c374690db69470f6aa4bffc43dcacf1f4e3e49","date":1529007399,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#test().mjava","sourceNew":"  @Test\n  @ShardsFixed(num = 4)\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 12-Jun-2018\n  public void test() throws Exception {\n    // setLoggingLevel(null);\n\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    // make sure we have leaders for each shard\n    for (int j = 1; j < sliceCount; j++) {\n      zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n    }      // make sure we again have leaders for each shard\n    \n    waitForRecoveriesToFinish(false);\n    \n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    del(\"*:*\");\n    queryAndCompareShards(params(\"q\", \"*:*\", \"distrib\", \"false\", \"sanity_check\", \"is_empty\"));\n\n    // ask every individual replica of every shard to update+commit the same doc id\n    // with an incrementing counter on each update+commit\n    int foo_i_counter = 0;\n    for (SolrClient client : clients) {\n      foo_i_counter++;\n      indexDoc(client, params(\"commit\", \"true\"), // SOLR-4923\n               sdoc(id,1, i1,100, tlong,100, \"foo_i\", foo_i_counter));\n      // after every update+commit, check all the shards consistency\n      queryAndCompareShards(params(\"q\", \"id:1\", \"distrib\", \"false\", \n                                   \"sanity_check\", \"non_distrib_id_1_lookup\"));\n      queryAndCompareShards(params(\"q\", \"id:1\", \n                                   \"sanity_check\", \"distrib_id_1_lookup\"));\n    }\n\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\"\n            ,\"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\"\n    );\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\"\n    );\n    indexr(id,4, i1, -100 ,tlong, 101,t1,\"the quick fox jumped over the lazy dog\"\n    );\n    indexr(id,5, i1, 500, tlong, 500 ,t1,\"the quick fox jumped way over the lazy dog\"\n    );\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,t1,\"no eggs on wall, lesson learned\", oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n    queryAndCompareShards(params(\"q\", \"*:*\", \n                                 \"sort\", \"id desc\",\n                                 \"distrib\", \"false\", \n                                 \"sanity_check\", \"is_empty\"));\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" desc\"});\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" asc\"});\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" asc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"}); \n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 desc\"});\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"{!func}\"+i1});// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(false, new String[] {\"q\",\"{!func}\"+i1, \"fl\",\"*,score\"});  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\"});  // no fields in returned docs\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\"});\n\n    handle.put(\"score\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\",\"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\"});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"matchesnothing\",\"fl\",\"*,score\"});  \n\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.offset\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2});\n\n    // test faceting multiple things at once\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1});\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id_i1:[1 TO 7]\", \"fq\",\"{!tag=b}id_i1:[3 TO 9]\"}\n    );\n    query(false, new Object[] {\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\"});\n\n    // test field that is valid in schema but missing in all shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2});\n    // test field that is valid in schema and missing in some shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2});\n\n    query(false, new Object[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1});\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    // check a complex key name\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(false, new Object[] {\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"*:*\", \"rows\",100});\n    }\n\n    // test debugging\n    handle.put(\"explain\", SKIPVAL);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP);\n    query(false, new Object[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY});\n\n    // try add commitWithin\n    long before = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    for (SolrClient client : clients) {\n      assertEquals(\"unexpected pre-commitWithin document count on node: \" + ((HttpSolrClient)client).getBaseURL(), before, client.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"commitWithin\", 10);\n    add(cloudClient, params , getDoc(\"id\", 300), getDoc(\"id\", 301));\n\n    waitForDocCount(before + 2, 30000, \"add commitWithin did not work\");\n\n    // try deleteById commitWithin\n    UpdateRequest deleteByIdReq = new UpdateRequest();\n    deleteByIdReq.deleteById(\"300\");\n    deleteByIdReq.setCommitWithin(10);\n    deleteByIdReq.process(cloudClient);\n\n    waitForDocCount(before + 1, 30000, \"deleteById commitWithin did not work\");\n\n    // try deleteByQuery commitWithin\n    UpdateRequest deleteByQueryReq = new UpdateRequest();\n    deleteByQueryReq.deleteByQuery(\"id:301\");\n    deleteByQueryReq.setCommitWithin(10);\n    deleteByQueryReq.process(cloudClient);\n\n    waitForDocCount(before, 30000, \"deleteByQuery commitWithin did not work\");\n\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // would be better if these where all separate tests - but much, much\n    // slower\n    doOptimisticLockingAndUpdating();\n    testShardParamVariations();\n    testMultipleCollections();\n    testANewCollectionInOneInstance();\n    testSearchByCollectionName();\n    testUpdateByCollectionName();\n    testANewCollectionInOneInstanceWithManualShardAssignement();\n    testNumberOfCommitsWithCommitAfterAdd();\n\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-explicit\");\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-implicit\");\n\n    testStopAndStartCoresInOneInstance();\n  }\n\n","sourceOld":"  @Test\n  @ShardsFixed(num = 4)\n  public void test() throws Exception {\n    // setLoggingLevel(null);\n\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    // make sure we have leaders for each shard\n    for (int j = 1; j < sliceCount; j++) {\n      zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n    }      // make sure we again have leaders for each shard\n    \n    waitForRecoveriesToFinish(false);\n    \n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    del(\"*:*\");\n    queryAndCompareShards(params(\"q\", \"*:*\", \"distrib\", \"false\", \"sanity_check\", \"is_empty\"));\n\n    // ask every individual replica of every shard to update+commit the same doc id\n    // with an incrementing counter on each update+commit\n    int foo_i_counter = 0;\n    for (SolrClient client : clients) {\n      foo_i_counter++;\n      indexDoc(client, params(\"commit\", \"true\"), // SOLR-4923\n               sdoc(id,1, i1,100, tlong,100, \"foo_i\", foo_i_counter));\n      // after every update+commit, check all the shards consistency\n      queryAndCompareShards(params(\"q\", \"id:1\", \"distrib\", \"false\", \n                                   \"sanity_check\", \"non_distrib_id_1_lookup\"));\n      queryAndCompareShards(params(\"q\", \"id:1\", \n                                   \"sanity_check\", \"distrib_id_1_lookup\"));\n    }\n\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\"\n            ,\"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\"\n    );\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\"\n    );\n    indexr(id,4, i1, -100 ,tlong, 101,t1,\"the quick fox jumped over the lazy dog\"\n    );\n    indexr(id,5, i1, 500, tlong, 500 ,t1,\"the quick fox jumped way over the lazy dog\"\n    );\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,t1,\"no eggs on wall, lesson learned\", oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n    queryAndCompareShards(params(\"q\", \"*:*\", \n                                 \"sort\", \"id desc\",\n                                 \"distrib\", \"false\", \n                                 \"sanity_check\", \"is_empty\"));\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" desc\"});\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" asc\"});\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" asc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"}); \n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 desc\"});\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"{!func}\"+i1});// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(false, new String[] {\"q\",\"{!func}\"+i1, \"fl\",\"*,score\"});  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\"});  // no fields in returned docs\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\"});\n\n    handle.put(\"score\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\",\"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\"});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"matchesnothing\",\"fl\",\"*,score\"});  \n\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.offset\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2});\n\n    // test faceting multiple things at once\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1});\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id_i1:[1 TO 7]\", \"fq\",\"{!tag=b}id_i1:[3 TO 9]\"}\n    );\n    query(false, new Object[] {\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\"});\n\n    // test field that is valid in schema but missing in all shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2});\n    // test field that is valid in schema and missing in some shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2});\n\n    query(false, new Object[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1});\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    // check a complex key name\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(false, new Object[] {\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"*:*\", \"rows\",100});\n    }\n\n    // test debugging\n    handle.put(\"explain\", SKIPVAL);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP);\n    query(false, new Object[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY});\n\n    // try add commitWithin\n    long before = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    for (SolrClient client : clients) {\n      assertEquals(\"unexpected pre-commitWithin document count on node: \" + ((HttpSolrClient)client).getBaseURL(), before, client.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"commitWithin\", 10);\n    add(cloudClient, params , getDoc(\"id\", 300), getDoc(\"id\", 301));\n\n    waitForDocCount(before + 2, 30000, \"add commitWithin did not work\");\n\n    // try deleteById commitWithin\n    UpdateRequest deleteByIdReq = new UpdateRequest();\n    deleteByIdReq.deleteById(\"300\");\n    deleteByIdReq.setCommitWithin(10);\n    deleteByIdReq.process(cloudClient);\n\n    waitForDocCount(before + 1, 30000, \"deleteById commitWithin did not work\");\n\n    // try deleteByQuery commitWithin\n    UpdateRequest deleteByQueryReq = new UpdateRequest();\n    deleteByQueryReq.deleteByQuery(\"id:301\");\n    deleteByQueryReq.setCommitWithin(10);\n    deleteByQueryReq.process(cloudClient);\n\n    waitForDocCount(before, 30000, \"deleteByQuery commitWithin did not work\");\n\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // would be better if these where all separate tests - but much, much\n    // slower\n    doOptimisticLockingAndUpdating();\n    testShardParamVariations();\n    testMultipleCollections();\n    testANewCollectionInOneInstance();\n    testSearchByCollectionName();\n    testUpdateByCollectionName();\n    testANewCollectionInOneInstanceWithManualShardAssignement();\n    testNumberOfCommitsWithCommitAfterAdd();\n\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-explicit\");\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-implicit\");\n\n    testStopAndStartCoresInOneInstance();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26","date":1531589977,"type":3,"author":"Michael Braun","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#test().mjava","sourceNew":"  @Test\n  @ShardsFixed(num = 4)\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 12-Jun-2018\n  public void test() throws Exception {\n    // setLoggingLevel(null);\n\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    // make sure we have leaders for each shard\n    for (int j = 1; j < sliceCount; j++) {\n      zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n    }      // make sure we again have leaders for each shard\n    \n    waitForRecoveriesToFinish(false);\n    \n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    del(\"*:*\");\n    queryAndCompareShards(params(\"q\", \"*:*\", \"distrib\", \"false\", \"sanity_check\", \"is_empty\"));\n\n    // ask every individual replica of every shard to update+commit the same doc id\n    // with an incrementing counter on each update+commit\n    int foo_i_counter = 0;\n    for (SolrClient client : clients) {\n      foo_i_counter++;\n      indexDoc(client, params(\"commit\", \"true\"), // SOLR-4923\n               sdoc(id,1, i1,100, tlong,100, \"foo_i\", foo_i_counter));\n      // after every update+commit, check all the shards consistency\n      queryAndCompareShards(params(\"q\", \"id:1\", \"distrib\", \"false\", \n                                   \"sanity_check\", \"non_distrib_id_1_lookup\"));\n      queryAndCompareShards(params(\"q\", \"id:1\", \n                                   \"sanity_check\", \"distrib_id_1_lookup\"));\n    }\n\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\"\n            ,\"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\"\n    );\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\"\n    );\n    indexr(id,4, i1, -100 ,tlong, 101,t1,\"the quick fox jumped over the lazy dog\"\n    );\n    indexr(id,5, i1, 500, tlong, 500 ,t1,\"the quick fox jumped way over the lazy dog\"\n    );\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,t1,\"no eggs on wall, lesson learned\", oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n    queryAndCompareShards(params(\"q\", \"*:*\", \n                                 \"sort\", \"id desc\",\n                                 \"distrib\", \"false\", \n                                 \"sanity_check\", \"is_empty\"));\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" desc\"});\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" asc\"});\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" asc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"}); \n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 desc\"});\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"{!func}\"+i1});// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(false, new String[] {\"q\",\"{!func}\"+i1, \"fl\",\"*,score\"});  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\"});  // no fields in returned docs\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\"});\n\n    handle.put(\"score\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\",\"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\"});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"matchesnothing\",\"fl\",\"*,score\"});  \n\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.offset\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2});\n\n    // test faceting multiple things at once\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1});\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id_i1:[1 TO 7]\", \"fq\",\"{!tag=b}id_i1:[3 TO 9]\"}\n    );\n    query(false, new Object[] {\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\"});\n\n    // test field that is valid in schema but missing in all shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2});\n    // test field that is valid in schema and missing in some shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2});\n\n    query(false, new Object[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1});\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    // check a complex key name\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(false, new Object[] {\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"*:*\", \"rows\",100});\n    }\n\n    // test debugging\n    handle.put(\"explain\", SKIPVAL);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP);\n    query(false, new Object[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY});\n\n    // try add commitWithin\n    long before = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    for (SolrClient client : clients) {\n      assertEquals(\"unexpected pre-commitWithin document count on node: \" + ((HttpSolrClient)client).getBaseURL(), before, client.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"commitWithin\", 10);\n    add(cloudClient, params , getDoc(\"id\", 300), getDoc(\"id\", 301));\n\n    waitForDocCount(before + 2, 30000, \"add commitWithin did not work\");\n\n    // try deleteById commitWithin\n    UpdateRequest deleteByIdReq = new UpdateRequest();\n    deleteByIdReq.deleteById(\"300\");\n    deleteByIdReq.setCommitWithin(10);\n    deleteByIdReq.process(cloudClient);\n\n    waitForDocCount(before + 1, 30000, \"deleteById commitWithin did not work\");\n\n    // try deleteByQuery commitWithin\n    UpdateRequest deleteByQueryReq = new UpdateRequest();\n    deleteByQueryReq.deleteByQuery(\"id:301\");\n    deleteByQueryReq.setCommitWithin(10);\n    deleteByQueryReq.process(cloudClient);\n\n    waitForDocCount(before, 30000, \"deleteByQuery commitWithin did not work\");\n\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // would be better if these where all separate tests - but much, much\n    // slower\n    doOptimisticLockingAndUpdating();\n    testShardParamVariations();\n    testMultipleCollections();\n    testANewCollectionInOneInstance();\n    testSearchByCollectionName();\n    testUpdateByCollectionName();\n    testANewCollectionInOneInstanceWithManualShardAssignement();\n    testNumberOfCommitsWithCommitAfterAdd();\n\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-explicit\");\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-implicit\");\n\n    testStopAndStartCoresInOneInstance();\n  }\n\n","sourceOld":"  @Test\n  @ShardsFixed(num = 4)\n  public void test() throws Exception {\n    // setLoggingLevel(null);\n\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    // make sure we have leaders for each shard\n    for (int j = 1; j < sliceCount; j++) {\n      zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n    }      // make sure we again have leaders for each shard\n    \n    waitForRecoveriesToFinish(false);\n    \n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    del(\"*:*\");\n    queryAndCompareShards(params(\"q\", \"*:*\", \"distrib\", \"false\", \"sanity_check\", \"is_empty\"));\n\n    // ask every individual replica of every shard to update+commit the same doc id\n    // with an incrementing counter on each update+commit\n    int foo_i_counter = 0;\n    for (SolrClient client : clients) {\n      foo_i_counter++;\n      indexDoc(client, params(\"commit\", \"true\"), // SOLR-4923\n               sdoc(id,1, i1,100, tlong,100, \"foo_i\", foo_i_counter));\n      // after every update+commit, check all the shards consistency\n      queryAndCompareShards(params(\"q\", \"id:1\", \"distrib\", \"false\", \n                                   \"sanity_check\", \"non_distrib_id_1_lookup\"));\n      queryAndCompareShards(params(\"q\", \"id:1\", \n                                   \"sanity_check\", \"distrib_id_1_lookup\"));\n    }\n\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\"\n            ,\"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\"\n    );\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\"\n    );\n    indexr(id,4, i1, -100 ,tlong, 101,t1,\"the quick fox jumped over the lazy dog\"\n    );\n    indexr(id,5, i1, 500, tlong, 500 ,t1,\"the quick fox jumped way over the lazy dog\"\n    );\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,t1,\"no eggs on wall, lesson learned\", oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n    queryAndCompareShards(params(\"q\", \"*:*\", \n                                 \"sort\", \"id desc\",\n                                 \"distrib\", \"false\", \n                                 \"sanity_check\", \"is_empty\"));\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" desc\"});\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" asc\"});\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" asc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"}); \n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 desc\"});\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"{!func}\"+i1});// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(false, new String[] {\"q\",\"{!func}\"+i1, \"fl\",\"*,score\"});  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\"});  // no fields in returned docs\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\"});\n\n    handle.put(\"score\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\",\"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\"});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"matchesnothing\",\"fl\",\"*,score\"});  \n\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.offset\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2});\n\n    // test faceting multiple things at once\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1});\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id_i1:[1 TO 7]\", \"fq\",\"{!tag=b}id_i1:[3 TO 9]\"}\n    );\n    query(false, new Object[] {\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\"});\n\n    // test field that is valid in schema but missing in all shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2});\n    // test field that is valid in schema and missing in some shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2});\n\n    query(false, new Object[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1});\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    // check a complex key name\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(false, new Object[] {\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"*:*\", \"rows\",100});\n    }\n\n    // test debugging\n    handle.put(\"explain\", SKIPVAL);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP);\n    query(false, new Object[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY});\n\n    // try add commitWithin\n    long before = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    for (SolrClient client : clients) {\n      assertEquals(\"unexpected pre-commitWithin document count on node: \" + ((HttpSolrClient)client).getBaseURL(), before, client.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"commitWithin\", 10);\n    add(cloudClient, params , getDoc(\"id\", 300), getDoc(\"id\", 301));\n\n    waitForDocCount(before + 2, 30000, \"add commitWithin did not work\");\n\n    // try deleteById commitWithin\n    UpdateRequest deleteByIdReq = new UpdateRequest();\n    deleteByIdReq.deleteById(\"300\");\n    deleteByIdReq.setCommitWithin(10);\n    deleteByIdReq.process(cloudClient);\n\n    waitForDocCount(before + 1, 30000, \"deleteById commitWithin did not work\");\n\n    // try deleteByQuery commitWithin\n    UpdateRequest deleteByQueryReq = new UpdateRequest();\n    deleteByQueryReq.deleteByQuery(\"id:301\");\n    deleteByQueryReq.setCommitWithin(10);\n    deleteByQueryReq.process(cloudClient);\n\n    waitForDocCount(before, 30000, \"deleteByQuery commitWithin did not work\");\n\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // would be better if these where all separate tests - but much, much\n    // slower\n    doOptimisticLockingAndUpdating();\n    testShardParamVariations();\n    testMultipleCollections();\n    testANewCollectionInOneInstance();\n    testSearchByCollectionName();\n    testUpdateByCollectionName();\n    testANewCollectionInOneInstanceWithManualShardAssignement();\n    testNumberOfCommitsWithCommitAfterAdd();\n\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-explicit\");\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-implicit\");\n\n    testStopAndStartCoresInOneInstance();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","date":1531905561,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#test().mjava","sourceNew":"  @Test\n  @ShardsFixed(num = 4)\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 12-Jun-2018\n  public void test() throws Exception {\n    // setLoggingLevel(null);\n\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    // make sure we have leaders for each shard\n    for (int j = 1; j < sliceCount; j++) {\n      zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n    }      // make sure we again have leaders for each shard\n    \n    waitForRecoveriesToFinish(false);\n    \n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    del(\"*:*\");\n    queryAndCompareShards(params(\"q\", \"*:*\", \"distrib\", \"false\", \"sanity_check\", \"is_empty\"));\n\n    // ask every individual replica of every shard to update+commit the same doc id\n    // with an incrementing counter on each update+commit\n    int foo_i_counter = 0;\n    for (SolrClient client : clients) {\n      foo_i_counter++;\n      indexDoc(client, params(\"commit\", \"true\"), // SOLR-4923\n               sdoc(id,1, i1,100, tlong,100, \"foo_i\", foo_i_counter));\n      // after every update+commit, check all the shards consistency\n      queryAndCompareShards(params(\"q\", \"id:1\", \"distrib\", \"false\", \n                                   \"sanity_check\", \"non_distrib_id_1_lookup\"));\n      queryAndCompareShards(params(\"q\", \"id:1\", \n                                   \"sanity_check\", \"distrib_id_1_lookup\"));\n    }\n\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\"\n            ,\"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\"\n    );\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\"\n    );\n    indexr(id,4, i1, -100 ,tlong, 101,t1,\"the quick fox jumped over the lazy dog\"\n    );\n    indexr(id,5, i1, 500, tlong, 500 ,t1,\"the quick fox jumped way over the lazy dog\"\n    );\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,t1,\"no eggs on wall, lesson learned\", oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n    queryAndCompareShards(params(\"q\", \"*:*\", \n                                 \"sort\", \"id desc\",\n                                 \"distrib\", \"false\", \n                                 \"sanity_check\", \"is_empty\"));\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" desc\"});\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" asc\"});\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" asc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"}); \n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 desc\"});\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"{!func}\"+i1});// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(false, new String[] {\"q\",\"{!func}\"+i1, \"fl\",\"*,score\"});  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\"});  // no fields in returned docs\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\"});\n\n    handle.put(\"score\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\",\"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\"});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"matchesnothing\",\"fl\",\"*,score\"});  \n\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.offset\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2});\n\n    // test faceting multiple things at once\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1});\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id_i1:[1 TO 7]\", \"fq\",\"{!tag=b}id_i1:[3 TO 9]\"}\n    );\n    query(false, new Object[] {\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\"});\n\n    // test field that is valid in schema but missing in all shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2});\n    // test field that is valid in schema and missing in some shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2});\n\n    query(false, new Object[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1});\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    // check a complex key name\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(false, new Object[] {\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"*:*\", \"rows\",100});\n    }\n\n    // test debugging\n    handle.put(\"explain\", SKIPVAL);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP);\n    query(false, new Object[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY});\n\n    // try add commitWithin\n    long before = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    for (SolrClient client : clients) {\n      assertEquals(\"unexpected pre-commitWithin document count on node: \" + ((HttpSolrClient)client).getBaseURL(), before, client.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"commitWithin\", 10);\n    add(cloudClient, params , getDoc(\"id\", 300), getDoc(\"id\", 301));\n\n    waitForDocCount(before + 2, 30000, \"add commitWithin did not work\");\n\n    // try deleteById commitWithin\n    UpdateRequest deleteByIdReq = new UpdateRequest();\n    deleteByIdReq.deleteById(\"300\");\n    deleteByIdReq.setCommitWithin(10);\n    deleteByIdReq.process(cloudClient);\n\n    waitForDocCount(before + 1, 30000, \"deleteById commitWithin did not work\");\n\n    // try deleteByQuery commitWithin\n    UpdateRequest deleteByQueryReq = new UpdateRequest();\n    deleteByQueryReq.deleteByQuery(\"id:301\");\n    deleteByQueryReq.setCommitWithin(10);\n    deleteByQueryReq.process(cloudClient);\n\n    waitForDocCount(before, 30000, \"deleteByQuery commitWithin did not work\");\n\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // would be better if these where all separate tests - but much, much\n    // slower\n    doOptimisticLockingAndUpdating();\n    testShardParamVariations();\n    testMultipleCollections();\n    testANewCollectionInOneInstance();\n    testSearchByCollectionName();\n    testUpdateByCollectionName();\n    testANewCollectionInOneInstanceWithManualShardAssignement();\n    testNumberOfCommitsWithCommitAfterAdd();\n\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-explicit\");\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-implicit\");\n\n    testStopAndStartCoresInOneInstance();\n  }\n\n","sourceOld":"  @Test\n  @ShardsFixed(num = 4)\n  public void test() throws Exception {\n    // setLoggingLevel(null);\n\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    // make sure we have leaders for each shard\n    for (int j = 1; j < sliceCount; j++) {\n      zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n    }      // make sure we again have leaders for each shard\n    \n    waitForRecoveriesToFinish(false);\n    \n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    del(\"*:*\");\n    queryAndCompareShards(params(\"q\", \"*:*\", \"distrib\", \"false\", \"sanity_check\", \"is_empty\"));\n\n    // ask every individual replica of every shard to update+commit the same doc id\n    // with an incrementing counter on each update+commit\n    int foo_i_counter = 0;\n    for (SolrClient client : clients) {\n      foo_i_counter++;\n      indexDoc(client, params(\"commit\", \"true\"), // SOLR-4923\n               sdoc(id,1, i1,100, tlong,100, \"foo_i\", foo_i_counter));\n      // after every update+commit, check all the shards consistency\n      queryAndCompareShards(params(\"q\", \"id:1\", \"distrib\", \"false\", \n                                   \"sanity_check\", \"non_distrib_id_1_lookup\"));\n      queryAndCompareShards(params(\"q\", \"id:1\", \n                                   \"sanity_check\", \"distrib_id_1_lookup\"));\n    }\n\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\"\n            ,\"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\"\n    );\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\"\n    );\n    indexr(id,4, i1, -100 ,tlong, 101,t1,\"the quick fox jumped over the lazy dog\"\n    );\n    indexr(id,5, i1, 500, tlong, 500 ,t1,\"the quick fox jumped way over the lazy dog\"\n    );\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,t1,\"no eggs on wall, lesson learned\", oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n    queryAndCompareShards(params(\"q\", \"*:*\", \n                                 \"sort\", \"id desc\",\n                                 \"distrib\", \"false\", \n                                 \"sanity_check\", \"is_empty\"));\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" desc\"});\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" asc\"});\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" asc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"}); \n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 desc\"});\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"{!func}\"+i1});// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(false, new String[] {\"q\",\"{!func}\"+i1, \"fl\",\"*,score\"});  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\"});  // no fields in returned docs\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\"});\n\n    handle.put(\"score\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\",\"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\"});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"matchesnothing\",\"fl\",\"*,score\"});  \n\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.offset\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2});\n\n    // test faceting multiple things at once\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1});\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id_i1:[1 TO 7]\", \"fq\",\"{!tag=b}id_i1:[3 TO 9]\"}\n    );\n    query(false, new Object[] {\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\"});\n\n    // test field that is valid in schema but missing in all shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2});\n    // test field that is valid in schema and missing in some shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2});\n\n    query(false, new Object[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1});\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    // check a complex key name\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(false, new Object[] {\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"*:*\", \"rows\",100});\n    }\n\n    // test debugging\n    handle.put(\"explain\", SKIPVAL);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP);\n    query(false, new Object[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY});\n\n    // try add commitWithin\n    long before = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    for (SolrClient client : clients) {\n      assertEquals(\"unexpected pre-commitWithin document count on node: \" + ((HttpSolrClient)client).getBaseURL(), before, client.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"commitWithin\", 10);\n    add(cloudClient, params , getDoc(\"id\", 300), getDoc(\"id\", 301));\n\n    waitForDocCount(before + 2, 30000, \"add commitWithin did not work\");\n\n    // try deleteById commitWithin\n    UpdateRequest deleteByIdReq = new UpdateRequest();\n    deleteByIdReq.deleteById(\"300\");\n    deleteByIdReq.setCommitWithin(10);\n    deleteByIdReq.process(cloudClient);\n\n    waitForDocCount(before + 1, 30000, \"deleteById commitWithin did not work\");\n\n    // try deleteByQuery commitWithin\n    UpdateRequest deleteByQueryReq = new UpdateRequest();\n    deleteByQueryReq.deleteByQuery(\"id:301\");\n    deleteByQueryReq.setCommitWithin(10);\n    deleteByQueryReq.process(cloudClient);\n\n    waitForDocCount(before, 30000, \"deleteByQuery commitWithin did not work\");\n\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // would be better if these where all separate tests - but much, much\n    // slower\n    doOptimisticLockingAndUpdating();\n    testShardParamVariations();\n    testMultipleCollections();\n    testANewCollectionInOneInstance();\n    testSearchByCollectionName();\n    testUpdateByCollectionName();\n    testANewCollectionInOneInstanceWithManualShardAssignement();\n    testNumberOfCommitsWithCommitAfterAdd();\n\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-explicit\");\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-implicit\");\n\n    testStopAndStartCoresInOneInstance();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d2d6b868457b26b5a2145b8441b1cfcfc0692b02","date":1534307099,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#test().mjava","sourceNew":"  @Test\n  @ShardsFixed(num = 4)\n  //DO NOT ENABLE @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 12-Jun-2018\n  public void test() throws Exception {\n    // setLoggingLevel(null);\n\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    // make sure we have leaders for each shard\n    for (int j = 1; j < sliceCount; j++) {\n      zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n    }      // make sure we again have leaders for each shard\n    \n    waitForRecoveriesToFinish(false);\n    \n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    del(\"*:*\");\n    queryAndCompareShards(params(\"q\", \"*:*\", \"distrib\", \"false\", \"sanity_check\", \"is_empty\"));\n\n    // ask every individual replica of every shard to update+commit the same doc id\n    // with an incrementing counter on each update+commit\n    int foo_i_counter = 0;\n    for (SolrClient client : clients) {\n      foo_i_counter++;\n      indexDoc(client, params(\"commit\", \"true\"), // SOLR-4923\n               sdoc(id,1, i1,100, tlong,100, \"foo_i\", foo_i_counter));\n      // after every update+commit, check all the shards consistency\n      queryAndCompareShards(params(\"q\", \"id:1\", \"distrib\", \"false\", \n                                   \"sanity_check\", \"non_distrib_id_1_lookup\"));\n      queryAndCompareShards(params(\"q\", \"id:1\", \n                                   \"sanity_check\", \"distrib_id_1_lookup\"));\n    }\n\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\"\n            ,\"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\"\n    );\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\"\n    );\n    indexr(id,4, i1, -100 ,tlong, 101,t1,\"the quick fox jumped over the lazy dog\"\n    );\n    indexr(id,5, i1, 500, tlong, 500 ,t1,\"the quick fox jumped way over the lazy dog\"\n    );\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,t1,\"no eggs on wall, lesson learned\", oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n    queryAndCompareShards(params(\"q\", \"*:*\", \n                                 \"sort\", \"id desc\",\n                                 \"distrib\", \"false\", \n                                 \"sanity_check\", \"is_empty\"));\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" desc\"});\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" asc\"});\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" asc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"}); \n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 desc\"});\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"{!func}\"+i1});// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(false, new String[] {\"q\",\"{!func}\"+i1, \"fl\",\"*,score\"});  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\"});  // no fields in returned docs\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\"});\n\n    handle.put(\"score\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\",\"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\"});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"matchesnothing\",\"fl\",\"*,score\"});  \n\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.offset\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2});\n\n    // test faceting multiple things at once\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1});\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id_i1:[1 TO 7]\", \"fq\",\"{!tag=b}id_i1:[3 TO 9]\"}\n    );\n    query(false, new Object[] {\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\"});\n\n    // test field that is valid in schema but missing in all shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2});\n    // test field that is valid in schema and missing in some shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2});\n\n    query(false, new Object[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1});\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    // check a complex key name\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(false, new Object[] {\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"*:*\", \"rows\",100});\n    }\n\n    // test debugging\n    handle.put(\"explain\", SKIPVAL);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP);\n    query(false, new Object[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY});\n\n    // try add commitWithin\n    long before = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    for (SolrClient client : clients) {\n      assertEquals(\"unexpected pre-commitWithin document count on node: \" + ((HttpSolrClient)client).getBaseURL(), before, client.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"commitWithin\", 10);\n    add(cloudClient, params , getDoc(\"id\", 300), getDoc(\"id\", 301));\n\n    waitForDocCount(before + 2, 30000, \"add commitWithin did not work\");\n\n    // try deleteById commitWithin\n    UpdateRequest deleteByIdReq = new UpdateRequest();\n    deleteByIdReq.deleteById(\"300\");\n    deleteByIdReq.setCommitWithin(10);\n    deleteByIdReq.process(cloudClient);\n\n    waitForDocCount(before + 1, 30000, \"deleteById commitWithin did not work\");\n\n    // try deleteByQuery commitWithin\n    UpdateRequest deleteByQueryReq = new UpdateRequest();\n    deleteByQueryReq.deleteByQuery(\"id:301\");\n    deleteByQueryReq.setCommitWithin(10);\n    deleteByQueryReq.process(cloudClient);\n\n    waitForDocCount(before, 30000, \"deleteByQuery commitWithin did not work\");\n\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // would be better if these where all separate tests - but much, much\n    // slower\n    doOptimisticLockingAndUpdating();\n    testShardParamVariations();\n    testMultipleCollections();\n    testANewCollectionInOneInstance();\n    testSearchByCollectionName();\n    testUpdateByCollectionName();\n    testANewCollectionInOneInstanceWithManualShardAssignement();\n    testNumberOfCommitsWithCommitAfterAdd();\n\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-explicit\");\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-implicit\");\n\n    testStopAndStartCoresInOneInstance();\n  }\n\n","sourceOld":"  @Test\n  @ShardsFixed(num = 4)\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 12-Jun-2018\n  public void test() throws Exception {\n    // setLoggingLevel(null);\n\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    // make sure we have leaders for each shard\n    for (int j = 1; j < sliceCount; j++) {\n      zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n    }      // make sure we again have leaders for each shard\n    \n    waitForRecoveriesToFinish(false);\n    \n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    del(\"*:*\");\n    queryAndCompareShards(params(\"q\", \"*:*\", \"distrib\", \"false\", \"sanity_check\", \"is_empty\"));\n\n    // ask every individual replica of every shard to update+commit the same doc id\n    // with an incrementing counter on each update+commit\n    int foo_i_counter = 0;\n    for (SolrClient client : clients) {\n      foo_i_counter++;\n      indexDoc(client, params(\"commit\", \"true\"), // SOLR-4923\n               sdoc(id,1, i1,100, tlong,100, \"foo_i\", foo_i_counter));\n      // after every update+commit, check all the shards consistency\n      queryAndCompareShards(params(\"q\", \"id:1\", \"distrib\", \"false\", \n                                   \"sanity_check\", \"non_distrib_id_1_lookup\"));\n      queryAndCompareShards(params(\"q\", \"id:1\", \n                                   \"sanity_check\", \"distrib_id_1_lookup\"));\n    }\n\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\"\n            ,\"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\"\n    );\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\"\n    );\n    indexr(id,4, i1, -100 ,tlong, 101,t1,\"the quick fox jumped over the lazy dog\"\n    );\n    indexr(id,5, i1, 500, tlong, 500 ,t1,\"the quick fox jumped way over the lazy dog\"\n    );\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,t1,\"no eggs on wall, lesson learned\", oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n    queryAndCompareShards(params(\"q\", \"*:*\", \n                                 \"sort\", \"id desc\",\n                                 \"distrib\", \"false\", \n                                 \"sanity_check\", \"is_empty\"));\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" desc\"});\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" asc\"});\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" asc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"}); \n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 desc\"});\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"{!func}\"+i1});// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(false, new String[] {\"q\",\"{!func}\"+i1, \"fl\",\"*,score\"});  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\"});  // no fields in returned docs\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\"});\n\n    handle.put(\"score\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\",\"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\"});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"matchesnothing\",\"fl\",\"*,score\"});  \n\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.offset\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2});\n\n    // test faceting multiple things at once\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1});\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id_i1:[1 TO 7]\", \"fq\",\"{!tag=b}id_i1:[3 TO 9]\"}\n    );\n    query(false, new Object[] {\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\"});\n\n    // test field that is valid in schema but missing in all shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2});\n    // test field that is valid in schema and missing in some shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2});\n\n    query(false, new Object[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1});\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    // check a complex key name\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(false, new Object[] {\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"*:*\", \"rows\",100});\n    }\n\n    // test debugging\n    handle.put(\"explain\", SKIPVAL);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP);\n    query(false, new Object[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY});\n\n    // try add commitWithin\n    long before = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    for (SolrClient client : clients) {\n      assertEquals(\"unexpected pre-commitWithin document count on node: \" + ((HttpSolrClient)client).getBaseURL(), before, client.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"commitWithin\", 10);\n    add(cloudClient, params , getDoc(\"id\", 300), getDoc(\"id\", 301));\n\n    waitForDocCount(before + 2, 30000, \"add commitWithin did not work\");\n\n    // try deleteById commitWithin\n    UpdateRequest deleteByIdReq = new UpdateRequest();\n    deleteByIdReq.deleteById(\"300\");\n    deleteByIdReq.setCommitWithin(10);\n    deleteByIdReq.process(cloudClient);\n\n    waitForDocCount(before + 1, 30000, \"deleteById commitWithin did not work\");\n\n    // try deleteByQuery commitWithin\n    UpdateRequest deleteByQueryReq = new UpdateRequest();\n    deleteByQueryReq.deleteByQuery(\"id:301\");\n    deleteByQueryReq.setCommitWithin(10);\n    deleteByQueryReq.process(cloudClient);\n\n    waitForDocCount(before, 30000, \"deleteByQuery commitWithin did not work\");\n\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // would be better if these where all separate tests - but much, much\n    // slower\n    doOptimisticLockingAndUpdating();\n    testShardParamVariations();\n    testMultipleCollections();\n    testANewCollectionInOneInstance();\n    testSearchByCollectionName();\n    testUpdateByCollectionName();\n    testANewCollectionInOneInstanceWithManualShardAssignement();\n    testNumberOfCommitsWithCommitAfterAdd();\n\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-explicit\");\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-implicit\");\n\n    testStopAndStartCoresInOneInstance();\n  }\n\n","bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"44dd40f6c2c1465aebf4677bab10f696c7ea18d8","date":1539566013,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#test().mjava","sourceNew":"  @Test\n  @ShardsFixed(num = 4)\n  //DO NOT ENABLE @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 12-Jun-2018\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 14-Oct-2018\n  public void test() throws Exception {\n    // setLoggingLevel(null);\n\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    // make sure we have leaders for each shard\n    for (int j = 1; j < sliceCount; j++) {\n      zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n    }      // make sure we again have leaders for each shard\n    \n    waitForRecoveriesToFinish(false);\n    \n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    del(\"*:*\");\n    queryAndCompareShards(params(\"q\", \"*:*\", \"distrib\", \"false\", \"sanity_check\", \"is_empty\"));\n\n    // ask every individual replica of every shard to update+commit the same doc id\n    // with an incrementing counter on each update+commit\n    int foo_i_counter = 0;\n    for (SolrClient client : clients) {\n      foo_i_counter++;\n      indexDoc(client, params(\"commit\", \"true\"), // SOLR-4923\n               sdoc(id,1, i1,100, tlong,100, \"foo_i\", foo_i_counter));\n      // after every update+commit, check all the shards consistency\n      queryAndCompareShards(params(\"q\", \"id:1\", \"distrib\", \"false\", \n                                   \"sanity_check\", \"non_distrib_id_1_lookup\"));\n      queryAndCompareShards(params(\"q\", \"id:1\", \n                                   \"sanity_check\", \"distrib_id_1_lookup\"));\n    }\n\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\"\n            ,\"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\"\n    );\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\"\n    );\n    indexr(id,4, i1, -100 ,tlong, 101,t1,\"the quick fox jumped over the lazy dog\"\n    );\n    indexr(id,5, i1, 500, tlong, 500 ,t1,\"the quick fox jumped way over the lazy dog\"\n    );\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,t1,\"no eggs on wall, lesson learned\", oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n    queryAndCompareShards(params(\"q\", \"*:*\", \n                                 \"sort\", \"id desc\",\n                                 \"distrib\", \"false\", \n                                 \"sanity_check\", \"is_empty\"));\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" desc\"});\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" asc\"});\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" asc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"}); \n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 desc\"});\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"{!func}\"+i1});// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(false, new String[] {\"q\",\"{!func}\"+i1, \"fl\",\"*,score\"});  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\"});  // no fields in returned docs\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\"});\n\n    handle.put(\"score\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\",\"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\"});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"matchesnothing\",\"fl\",\"*,score\"});  \n\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.offset\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2});\n\n    // test faceting multiple things at once\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1});\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id_i1:[1 TO 7]\", \"fq\",\"{!tag=b}id_i1:[3 TO 9]\"}\n    );\n    query(false, new Object[] {\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\"});\n\n    // test field that is valid in schema but missing in all shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2});\n    // test field that is valid in schema and missing in some shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2});\n\n    query(false, new Object[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1});\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    // check a complex key name\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(false, new Object[] {\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"*:*\", \"rows\",100});\n    }\n\n    // test debugging\n    handle.put(\"explain\", SKIPVAL);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP);\n    query(false, new Object[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY});\n\n    // try add commitWithin\n    long before = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    for (SolrClient client : clients) {\n      assertEquals(\"unexpected pre-commitWithin document count on node: \" + ((HttpSolrClient)client).getBaseURL(), before, client.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"commitWithin\", 10);\n    add(cloudClient, params , getDoc(\"id\", 300), getDoc(\"id\", 301));\n\n    waitForDocCount(before + 2, 30000, \"add commitWithin did not work\");\n\n    // try deleteById commitWithin\n    UpdateRequest deleteByIdReq = new UpdateRequest();\n    deleteByIdReq.deleteById(\"300\");\n    deleteByIdReq.setCommitWithin(10);\n    deleteByIdReq.process(cloudClient);\n\n    waitForDocCount(before + 1, 30000, \"deleteById commitWithin did not work\");\n\n    // try deleteByQuery commitWithin\n    UpdateRequest deleteByQueryReq = new UpdateRequest();\n    deleteByQueryReq.deleteByQuery(\"id:301\");\n    deleteByQueryReq.setCommitWithin(10);\n    deleteByQueryReq.process(cloudClient);\n\n    waitForDocCount(before, 30000, \"deleteByQuery commitWithin did not work\");\n\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // would be better if these where all separate tests - but much, much\n    // slower\n    doOptimisticLockingAndUpdating();\n    testShardParamVariations();\n    testMultipleCollections();\n    testANewCollectionInOneInstance();\n    testSearchByCollectionName();\n    testUpdateByCollectionName();\n    testANewCollectionInOneInstanceWithManualShardAssignement();\n    testNumberOfCommitsWithCommitAfterAdd();\n\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-explicit\");\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-implicit\");\n\n    testStopAndStartCoresInOneInstance();\n  }\n\n","sourceOld":"  @Test\n  @ShardsFixed(num = 4)\n  //DO NOT ENABLE @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 12-Jun-2018\n  public void test() throws Exception {\n    // setLoggingLevel(null);\n\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    // make sure we have leaders for each shard\n    for (int j = 1; j < sliceCount; j++) {\n      zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n    }      // make sure we again have leaders for each shard\n    \n    waitForRecoveriesToFinish(false);\n    \n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    del(\"*:*\");\n    queryAndCompareShards(params(\"q\", \"*:*\", \"distrib\", \"false\", \"sanity_check\", \"is_empty\"));\n\n    // ask every individual replica of every shard to update+commit the same doc id\n    // with an incrementing counter on each update+commit\n    int foo_i_counter = 0;\n    for (SolrClient client : clients) {\n      foo_i_counter++;\n      indexDoc(client, params(\"commit\", \"true\"), // SOLR-4923\n               sdoc(id,1, i1,100, tlong,100, \"foo_i\", foo_i_counter));\n      // after every update+commit, check all the shards consistency\n      queryAndCompareShards(params(\"q\", \"id:1\", \"distrib\", \"false\", \n                                   \"sanity_check\", \"non_distrib_id_1_lookup\"));\n      queryAndCompareShards(params(\"q\", \"id:1\", \n                                   \"sanity_check\", \"distrib_id_1_lookup\"));\n    }\n\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\"\n            ,\"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\"\n    );\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\"\n    );\n    indexr(id,4, i1, -100 ,tlong, 101,t1,\"the quick fox jumped over the lazy dog\"\n    );\n    indexr(id,5, i1, 500, tlong, 500 ,t1,\"the quick fox jumped way over the lazy dog\"\n    );\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,t1,\"no eggs on wall, lesson learned\", oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n    queryAndCompareShards(params(\"q\", \"*:*\", \n                                 \"sort\", \"id desc\",\n                                 \"distrib\", \"false\", \n                                 \"sanity_check\", \"is_empty\"));\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" desc\"});\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" asc\"});\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" asc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"}); \n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 desc\"});\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"{!func}\"+i1});// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(false, new String[] {\"q\",\"{!func}\"+i1, \"fl\",\"*,score\"});  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\"});  // no fields in returned docs\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\"});\n\n    handle.put(\"score\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\",\"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\"});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"matchesnothing\",\"fl\",\"*,score\"});  \n\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.offset\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2});\n\n    // test faceting multiple things at once\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1});\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id_i1:[1 TO 7]\", \"fq\",\"{!tag=b}id_i1:[3 TO 9]\"}\n    );\n    query(false, new Object[] {\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\"});\n\n    // test field that is valid in schema but missing in all shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2});\n    // test field that is valid in schema and missing in some shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2});\n\n    query(false, new Object[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1});\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    // check a complex key name\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(false, new Object[] {\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"*:*\", \"rows\",100});\n    }\n\n    // test debugging\n    handle.put(\"explain\", SKIPVAL);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP);\n    query(false, new Object[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY});\n\n    // try add commitWithin\n    long before = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    for (SolrClient client : clients) {\n      assertEquals(\"unexpected pre-commitWithin document count on node: \" + ((HttpSolrClient)client).getBaseURL(), before, client.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"commitWithin\", 10);\n    add(cloudClient, params , getDoc(\"id\", 300), getDoc(\"id\", 301));\n\n    waitForDocCount(before + 2, 30000, \"add commitWithin did not work\");\n\n    // try deleteById commitWithin\n    UpdateRequest deleteByIdReq = new UpdateRequest();\n    deleteByIdReq.deleteById(\"300\");\n    deleteByIdReq.setCommitWithin(10);\n    deleteByIdReq.process(cloudClient);\n\n    waitForDocCount(before + 1, 30000, \"deleteById commitWithin did not work\");\n\n    // try deleteByQuery commitWithin\n    UpdateRequest deleteByQueryReq = new UpdateRequest();\n    deleteByQueryReq.deleteByQuery(\"id:301\");\n    deleteByQueryReq.setCommitWithin(10);\n    deleteByQueryReq.process(cloudClient);\n\n    waitForDocCount(before, 30000, \"deleteByQuery commitWithin did not work\");\n\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // would be better if these where all separate tests - but much, much\n    // slower\n    doOptimisticLockingAndUpdating();\n    testShardParamVariations();\n    testMultipleCollections();\n    testANewCollectionInOneInstance();\n    testSearchByCollectionName();\n    testUpdateByCollectionName();\n    testANewCollectionInOneInstanceWithManualShardAssignement();\n    testNumberOfCommitsWithCommitAfterAdd();\n\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-explicit\");\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-implicit\");\n\n    testStopAndStartCoresInOneInstance();\n  }\n\n","bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bb222a3f9d9421d5c95afce73013fbd8de07ea1f","date":1543514331,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#test().mjava","sourceNew":"  @Test\n  @ShardsFixed(num = 4)\n  public void test() throws Exception {\n    // setLoggingLevel(null);\n\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    // make sure we have leaders for each shard\n    for (int j = 1; j < sliceCount; j++) {\n      zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n    }      // make sure we again have leaders for each shard\n    \n    waitForRecoveriesToFinish(false);\n    \n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    del(\"*:*\");\n    queryAndCompareShards(params(\"q\", \"*:*\", \"distrib\", \"false\", \"sanity_check\", \"is_empty\"));\n\n    // ask every individual replica of every shard to update+commit the same doc id\n    // with an incrementing counter on each update+commit\n    int foo_i_counter = 0;\n    for (SolrClient client : clients) {\n      foo_i_counter++;\n      indexDoc(client, params(\"commit\", \"true\"), // SOLR-4923\n               sdoc(id,1, i1,100, tlong,100, \"foo_i\", foo_i_counter));\n      // after every update+commit, check all the shards consistency\n      queryAndCompareShards(params(\"q\", \"id:1\", \"distrib\", \"false\", \n                                   \"sanity_check\", \"non_distrib_id_1_lookup\"));\n      queryAndCompareShards(params(\"q\", \"id:1\", \n                                   \"sanity_check\", \"distrib_id_1_lookup\"));\n    }\n\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\"\n            ,\"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\"\n    );\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\"\n    );\n    indexr(id,4, i1, -100 ,tlong, 101,t1,\"the quick fox jumped over the lazy dog\"\n    );\n    indexr(id,5, i1, 500, tlong, 500 ,t1,\"the quick fox jumped way over the lazy dog\"\n    );\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,t1,\"no eggs on wall, lesson learned\", oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n    queryAndCompareShards(params(\"q\", \"*:*\", \n                                 \"sort\", \"id desc\",\n                                 \"distrib\", \"false\", \n                                 \"sanity_check\", \"is_empty\"));\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" desc\"});\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" asc\"});\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" asc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"}); \n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 desc\"});\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"{!func}\"+i1});// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(false, new String[] {\"q\",\"{!func}\"+i1, \"fl\",\"*,score\"});  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\"});  // no fields in returned docs\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\"});\n\n    handle.put(\"score\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\",\"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\"});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"matchesnothing\",\"fl\",\"*,score\"});  \n\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.offset\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2});\n\n    // test faceting multiple things at once\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1});\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id_i1:[1 TO 7]\", \"fq\",\"{!tag=b}id_i1:[3 TO 9]\"}\n    );\n    query(false, new Object[] {\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\"});\n\n    // test field that is valid in schema but missing in all shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2});\n    // test field that is valid in schema and missing in some shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2});\n\n    query(false, new Object[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1});\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    // check a complex key name\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(false, new Object[] {\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"*:*\", \"rows\",100});\n    }\n\n    // test debugging\n    handle.put(\"explain\", SKIPVAL);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP);\n    query(false, new Object[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY});\n\n    // try add commitWithin\n    long before = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    for (SolrClient client : clients) {\n      assertEquals(\"unexpected pre-commitWithin document count on node: \" + ((HttpSolrClient)client).getBaseURL(), before, client.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"commitWithin\", 10);\n    add(cloudClient, params , getDoc(\"id\", 300), getDoc(\"id\", 301));\n\n    newSearcherHook.waitForSearcher(DEFAULT_COLLECTION, 2, 20000, false);\n    \n    ClusterState clusterState = getCommonCloudSolrClient().getZkStateReader().getClusterState();\n    DocCollection dColl = clusterState.getCollection(DEFAULT_COLLECTION);\n\n    assertSliceCounts(\"should have found 2 docs, 300 and 301\", before + 2, dColl);\n\n    // try deleteById commitWithin\n    UpdateRequest deleteByIdReq = new UpdateRequest();\n    deleteByIdReq.deleteById(\"300\");\n    deleteByIdReq.setCommitWithin(10);\n    deleteByIdReq.process(cloudClient);\n    \n    newSearcherHook.waitForSearcher(DEFAULT_COLLECTION, 2, 20000, false);\n\n    assertSliceCounts(\"deleteById commitWithin did not work\", before + 1, dColl);\n    \n    // try deleteByQuery commitWithin\n    UpdateRequest deleteByQueryReq = new UpdateRequest();\n    deleteByQueryReq.deleteByQuery(\"id:301\");\n    deleteByQueryReq.setCommitWithin(10);\n    deleteByQueryReq.process(cloudClient);\n\n    newSearcherHook.waitForSearcher(DEFAULT_COLLECTION, 2, 20000, false);\n    \n    assertSliceCounts(\"deleteByQuery commitWithin did not work\", before, dColl);\n    \n\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // would be better if these where all separate tests - but much, much\n    // slower\n    doOptimisticLockingAndUpdating();\n    testShardParamVariations();\n    testMultipleCollections();\n    testANewCollectionInOneInstance();\n    testSearchByCollectionName();\n    testUpdateByCollectionName();\n    testANewCollectionInOneInstanceWithManualShardAssignement();\n    testNumberOfCommitsWithCommitAfterAdd();\n\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-explicit\");\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-implicit\");\n\n    testStopAndStartCoresInOneInstance();\n  }\n\n","sourceOld":"  @Test\n  @ShardsFixed(num = 4)\n  //DO NOT ENABLE @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 12-Jun-2018\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 14-Oct-2018\n  public void test() throws Exception {\n    // setLoggingLevel(null);\n\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    // make sure we have leaders for each shard\n    for (int j = 1; j < sliceCount; j++) {\n      zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n    }      // make sure we again have leaders for each shard\n    \n    waitForRecoveriesToFinish(false);\n    \n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    del(\"*:*\");\n    queryAndCompareShards(params(\"q\", \"*:*\", \"distrib\", \"false\", \"sanity_check\", \"is_empty\"));\n\n    // ask every individual replica of every shard to update+commit the same doc id\n    // with an incrementing counter on each update+commit\n    int foo_i_counter = 0;\n    for (SolrClient client : clients) {\n      foo_i_counter++;\n      indexDoc(client, params(\"commit\", \"true\"), // SOLR-4923\n               sdoc(id,1, i1,100, tlong,100, \"foo_i\", foo_i_counter));\n      // after every update+commit, check all the shards consistency\n      queryAndCompareShards(params(\"q\", \"id:1\", \"distrib\", \"false\", \n                                   \"sanity_check\", \"non_distrib_id_1_lookup\"));\n      queryAndCompareShards(params(\"q\", \"id:1\", \n                                   \"sanity_check\", \"distrib_id_1_lookup\"));\n    }\n\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\"\n            ,\"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\"\n    );\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\"\n    );\n    indexr(id,4, i1, -100 ,tlong, 101,t1,\"the quick fox jumped over the lazy dog\"\n    );\n    indexr(id,5, i1, 500, tlong, 500 ,t1,\"the quick fox jumped way over the lazy dog\"\n    );\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,t1,\"no eggs on wall, lesson learned\", oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n    queryAndCompareShards(params(\"q\", \"*:*\", \n                                 \"sort\", \"id desc\",\n                                 \"distrib\", \"false\", \n                                 \"sanity_check\", \"is_empty\"));\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" desc\"});\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" asc\"});\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" asc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"}); \n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 desc\"});\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"{!func}\"+i1});// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(false, new String[] {\"q\",\"{!func}\"+i1, \"fl\",\"*,score\"});  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\"});  // no fields in returned docs\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\"});\n\n    handle.put(\"score\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\",\"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\"});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"matchesnothing\",\"fl\",\"*,score\"});  \n\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.offset\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2});\n\n    // test faceting multiple things at once\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1});\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id_i1:[1 TO 7]\", \"fq\",\"{!tag=b}id_i1:[3 TO 9]\"}\n    );\n    query(false, new Object[] {\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\"});\n\n    // test field that is valid in schema but missing in all shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2});\n    // test field that is valid in schema and missing in some shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2});\n\n    query(false, new Object[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1});\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    // check a complex key name\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(false, new Object[] {\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"*:*\", \"rows\",100});\n    }\n\n    // test debugging\n    handle.put(\"explain\", SKIPVAL);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP);\n    query(false, new Object[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY});\n\n    // try add commitWithin\n    long before = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    for (SolrClient client : clients) {\n      assertEquals(\"unexpected pre-commitWithin document count on node: \" + ((HttpSolrClient)client).getBaseURL(), before, client.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"commitWithin\", 10);\n    add(cloudClient, params , getDoc(\"id\", 300), getDoc(\"id\", 301));\n\n    waitForDocCount(before + 2, 30000, \"add commitWithin did not work\");\n\n    // try deleteById commitWithin\n    UpdateRequest deleteByIdReq = new UpdateRequest();\n    deleteByIdReq.deleteById(\"300\");\n    deleteByIdReq.setCommitWithin(10);\n    deleteByIdReq.process(cloudClient);\n\n    waitForDocCount(before + 1, 30000, \"deleteById commitWithin did not work\");\n\n    // try deleteByQuery commitWithin\n    UpdateRequest deleteByQueryReq = new UpdateRequest();\n    deleteByQueryReq.deleteByQuery(\"id:301\");\n    deleteByQueryReq.setCommitWithin(10);\n    deleteByQueryReq.process(cloudClient);\n\n    waitForDocCount(before, 30000, \"deleteByQuery commitWithin did not work\");\n\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // would be better if these where all separate tests - but much, much\n    // slower\n    doOptimisticLockingAndUpdating();\n    testShardParamVariations();\n    testMultipleCollections();\n    testANewCollectionInOneInstance();\n    testSearchByCollectionName();\n    testUpdateByCollectionName();\n    testANewCollectionInOneInstanceWithManualShardAssignement();\n    testNumberOfCommitsWithCommitAfterAdd();\n\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-explicit\");\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-implicit\");\n\n    testStopAndStartCoresInOneInstance();\n  }\n\n","bugFix":["68423be363a30c5a005b0eb6830c749d93b2b8db","44dd40f6c2c1465aebf4677bab10f696c7ea18d8","d2d6b868457b26b5a2145b8441b1cfcfc0692b02"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8d35c84fdef07284c122012ca4000d3b7285a66e","date":1545962630,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#test().mjava","sourceNew":"  @Test\n  @ShardsFixed(num = 4)\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // annotated on: 24-Dec-2018\n  public void test() throws Exception {\n    // setLoggingLevel(null);\n\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    // make sure we have leaders for each shard\n    for (int j = 1; j < sliceCount; j++) {\n      zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n    }      // make sure we again have leaders for each shard\n    \n    waitForRecoveriesToFinish(false);\n    \n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    del(\"*:*\");\n    queryAndCompareShards(params(\"q\", \"*:*\", \"distrib\", \"false\", \"sanity_check\", \"is_empty\"));\n\n    // ask every individual replica of every shard to update+commit the same doc id\n    // with an incrementing counter on each update+commit\n    int foo_i_counter = 0;\n    for (SolrClient client : clients) {\n      foo_i_counter++;\n      indexDoc(client, params(\"commit\", \"true\"), // SOLR-4923\n               sdoc(id,1, i1,100, tlong,100, \"foo_i\", foo_i_counter));\n      // after every update+commit, check all the shards consistency\n      queryAndCompareShards(params(\"q\", \"id:1\", \"distrib\", \"false\", \n                                   \"sanity_check\", \"non_distrib_id_1_lookup\"));\n      queryAndCompareShards(params(\"q\", \"id:1\", \n                                   \"sanity_check\", \"distrib_id_1_lookup\"));\n    }\n\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\"\n            ,\"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\"\n    );\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\"\n    );\n    indexr(id,4, i1, -100 ,tlong, 101,t1,\"the quick fox jumped over the lazy dog\"\n    );\n    indexr(id,5, i1, 500, tlong, 500 ,t1,\"the quick fox jumped way over the lazy dog\"\n    );\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,t1,\"no eggs on wall, lesson learned\", oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n    queryAndCompareShards(params(\"q\", \"*:*\", \n                                 \"sort\", \"id desc\",\n                                 \"distrib\", \"false\", \n                                 \"sanity_check\", \"is_empty\"));\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" desc\"});\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" asc\"});\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" asc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"}); \n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 desc\"});\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"{!func}\"+i1});// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(false, new String[] {\"q\",\"{!func}\"+i1, \"fl\",\"*,score\"});  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\"});  // no fields in returned docs\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\"});\n\n    handle.put(\"score\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\",\"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\"});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"matchesnothing\",\"fl\",\"*,score\"});  \n\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.offset\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2});\n\n    // test faceting multiple things at once\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1});\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id_i1:[1 TO 7]\", \"fq\",\"{!tag=b}id_i1:[3 TO 9]\"}\n    );\n    query(false, new Object[] {\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\"});\n\n    // test field that is valid in schema but missing in all shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2});\n    // test field that is valid in schema and missing in some shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2});\n\n    query(false, new Object[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1});\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    // check a complex key name\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(false, new Object[] {\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"*:*\", \"rows\",100});\n    }\n\n    // test debugging\n    handle.put(\"explain\", SKIPVAL);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP);\n    query(false, new Object[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY});\n\n    // try add commitWithin\n    long before = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    for (SolrClient client : clients) {\n      assertEquals(\"unexpected pre-commitWithin document count on node: \" + ((HttpSolrClient)client).getBaseURL(), before, client.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"commitWithin\", 10);\n    add(cloudClient, params , getDoc(\"id\", 300), getDoc(\"id\", 301));\n\n    newSearcherHook.waitForSearcher(DEFAULT_COLLECTION, 2, 20000, false);\n    \n    ClusterState clusterState = getCommonCloudSolrClient().getZkStateReader().getClusterState();\n    DocCollection dColl = clusterState.getCollection(DEFAULT_COLLECTION);\n\n    assertSliceCounts(\"should have found 2 docs, 300 and 301\", before + 2, dColl);\n\n    // try deleteById commitWithin\n    UpdateRequest deleteByIdReq = new UpdateRequest();\n    deleteByIdReq.deleteById(\"300\");\n    deleteByIdReq.setCommitWithin(10);\n    deleteByIdReq.process(cloudClient);\n    \n    newSearcherHook.waitForSearcher(DEFAULT_COLLECTION, 2, 20000, false);\n\n    assertSliceCounts(\"deleteById commitWithin did not work\", before + 1, dColl);\n    \n    // try deleteByQuery commitWithin\n    UpdateRequest deleteByQueryReq = new UpdateRequest();\n    deleteByQueryReq.deleteByQuery(\"id:301\");\n    deleteByQueryReq.setCommitWithin(10);\n    deleteByQueryReq.process(cloudClient);\n\n    newSearcherHook.waitForSearcher(DEFAULT_COLLECTION, 2, 20000, false);\n    \n    assertSliceCounts(\"deleteByQuery commitWithin did not work\", before, dColl);\n    \n\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // would be better if these where all separate tests - but much, much\n    // slower\n    doOptimisticLockingAndUpdating();\n    testShardParamVariations();\n    testMultipleCollections();\n    testANewCollectionInOneInstance();\n    testSearchByCollectionName();\n    testUpdateByCollectionName();\n    testANewCollectionInOneInstanceWithManualShardAssignement();\n    testNumberOfCommitsWithCommitAfterAdd();\n\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-explicit\");\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-implicit\");\n\n    testStopAndStartCoresInOneInstance();\n  }\n\n","sourceOld":"  @Test\n  @ShardsFixed(num = 4)\n  public void test() throws Exception {\n    // setLoggingLevel(null);\n\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    // make sure we have leaders for each shard\n    for (int j = 1; j < sliceCount; j++) {\n      zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n    }      // make sure we again have leaders for each shard\n    \n    waitForRecoveriesToFinish(false);\n    \n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    del(\"*:*\");\n    queryAndCompareShards(params(\"q\", \"*:*\", \"distrib\", \"false\", \"sanity_check\", \"is_empty\"));\n\n    // ask every individual replica of every shard to update+commit the same doc id\n    // with an incrementing counter on each update+commit\n    int foo_i_counter = 0;\n    for (SolrClient client : clients) {\n      foo_i_counter++;\n      indexDoc(client, params(\"commit\", \"true\"), // SOLR-4923\n               sdoc(id,1, i1,100, tlong,100, \"foo_i\", foo_i_counter));\n      // after every update+commit, check all the shards consistency\n      queryAndCompareShards(params(\"q\", \"id:1\", \"distrib\", \"false\", \n                                   \"sanity_check\", \"non_distrib_id_1_lookup\"));\n      queryAndCompareShards(params(\"q\", \"id:1\", \n                                   \"sanity_check\", \"distrib_id_1_lookup\"));\n    }\n\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\"\n            ,\"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\"\n    );\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\"\n    );\n    indexr(id,4, i1, -100 ,tlong, 101,t1,\"the quick fox jumped over the lazy dog\"\n    );\n    indexr(id,5, i1, 500, tlong, 500 ,t1,\"the quick fox jumped way over the lazy dog\"\n    );\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,t1,\"no eggs on wall, lesson learned\", oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n    queryAndCompareShards(params(\"q\", \"*:*\", \n                                 \"sort\", \"id desc\",\n                                 \"distrib\", \"false\", \n                                 \"sanity_check\", \"is_empty\"));\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" desc\"});\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" asc\"});\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" asc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"}); \n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 desc\"});\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"{!func}\"+i1});// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(false, new String[] {\"q\",\"{!func}\"+i1, \"fl\",\"*,score\"});  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\"});  // no fields in returned docs\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\"});\n\n    handle.put(\"score\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\",\"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\"});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"matchesnothing\",\"fl\",\"*,score\"});  \n\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.offset\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2});\n\n    // test faceting multiple things at once\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1});\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id_i1:[1 TO 7]\", \"fq\",\"{!tag=b}id_i1:[3 TO 9]\"}\n    );\n    query(false, new Object[] {\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\"});\n\n    // test field that is valid in schema but missing in all shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2});\n    // test field that is valid in schema and missing in some shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2});\n\n    query(false, new Object[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1});\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    // check a complex key name\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(false, new Object[] {\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"*:*\", \"rows\",100});\n    }\n\n    // test debugging\n    handle.put(\"explain\", SKIPVAL);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP);\n    query(false, new Object[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY});\n\n    // try add commitWithin\n    long before = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    for (SolrClient client : clients) {\n      assertEquals(\"unexpected pre-commitWithin document count on node: \" + ((HttpSolrClient)client).getBaseURL(), before, client.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"commitWithin\", 10);\n    add(cloudClient, params , getDoc(\"id\", 300), getDoc(\"id\", 301));\n\n    newSearcherHook.waitForSearcher(DEFAULT_COLLECTION, 2, 20000, false);\n    \n    ClusterState clusterState = getCommonCloudSolrClient().getZkStateReader().getClusterState();\n    DocCollection dColl = clusterState.getCollection(DEFAULT_COLLECTION);\n\n    assertSliceCounts(\"should have found 2 docs, 300 and 301\", before + 2, dColl);\n\n    // try deleteById commitWithin\n    UpdateRequest deleteByIdReq = new UpdateRequest();\n    deleteByIdReq.deleteById(\"300\");\n    deleteByIdReq.setCommitWithin(10);\n    deleteByIdReq.process(cloudClient);\n    \n    newSearcherHook.waitForSearcher(DEFAULT_COLLECTION, 2, 20000, false);\n\n    assertSliceCounts(\"deleteById commitWithin did not work\", before + 1, dColl);\n    \n    // try deleteByQuery commitWithin\n    UpdateRequest deleteByQueryReq = new UpdateRequest();\n    deleteByQueryReq.deleteByQuery(\"id:301\");\n    deleteByQueryReq.setCommitWithin(10);\n    deleteByQueryReq.process(cloudClient);\n\n    newSearcherHook.waitForSearcher(DEFAULT_COLLECTION, 2, 20000, false);\n    \n    assertSliceCounts(\"deleteByQuery commitWithin did not work\", before, dColl);\n    \n\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // would be better if these where all separate tests - but much, much\n    // slower\n    doOptimisticLockingAndUpdating();\n    testShardParamVariations();\n    testMultipleCollections();\n    testANewCollectionInOneInstance();\n    testSearchByCollectionName();\n    testUpdateByCollectionName();\n    testANewCollectionInOneInstanceWithManualShardAssignement();\n    testNumberOfCommitsWithCommitAfterAdd();\n\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-explicit\");\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-implicit\");\n\n    testStopAndStartCoresInOneInstance();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b5c929d2716fa79d443b93a82adb1da5b578ebd8","date":1550428858,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#test().mjava","sourceNew":"  @Test\n  @ShardsFixed(num = 4)\n  // commented out on: 17-Feb-2019   @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // annotated on: 24-Dec-2018\n  public void test() throws Exception {\n    // setLoggingLevel(null);\n\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    // make sure we have leaders for each shard\n    for (int j = 1; j < sliceCount; j++) {\n      zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n    }      // make sure we again have leaders for each shard\n    \n    waitForRecoveriesToFinish(false);\n    \n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    del(\"*:*\");\n    queryAndCompareShards(params(\"q\", \"*:*\", \"distrib\", \"false\", \"sanity_check\", \"is_empty\"));\n\n    // ask every individual replica of every shard to update+commit the same doc id\n    // with an incrementing counter on each update+commit\n    int foo_i_counter = 0;\n    for (SolrClient client : clients) {\n      foo_i_counter++;\n      indexDoc(client, params(\"commit\", \"true\"), // SOLR-4923\n               sdoc(id,1, i1,100, tlong,100, \"foo_i\", foo_i_counter));\n      // after every update+commit, check all the shards consistency\n      queryAndCompareShards(params(\"q\", \"id:1\", \"distrib\", \"false\", \n                                   \"sanity_check\", \"non_distrib_id_1_lookup\"));\n      queryAndCompareShards(params(\"q\", \"id:1\", \n                                   \"sanity_check\", \"distrib_id_1_lookup\"));\n    }\n\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\"\n            ,\"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\"\n    );\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\"\n    );\n    indexr(id,4, i1, -100 ,tlong, 101,t1,\"the quick fox jumped over the lazy dog\"\n    );\n    indexr(id,5, i1, 500, tlong, 500 ,t1,\"the quick fox jumped way over the lazy dog\"\n    );\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,t1,\"no eggs on wall, lesson learned\", oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n    queryAndCompareShards(params(\"q\", \"*:*\", \n                                 \"sort\", \"id desc\",\n                                 \"distrib\", \"false\", \n                                 \"sanity_check\", \"is_empty\"));\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" desc\"});\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" asc\"});\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" asc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"}); \n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 desc\"});\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"{!func}\"+i1});// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(false, new String[] {\"q\",\"{!func}\"+i1, \"fl\",\"*,score\"});  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\"});  // no fields in returned docs\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\"});\n\n    handle.put(\"score\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\",\"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\"});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"matchesnothing\",\"fl\",\"*,score\"});  \n\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.offset\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2});\n\n    // test faceting multiple things at once\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1});\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id_i1:[1 TO 7]\", \"fq\",\"{!tag=b}id_i1:[3 TO 9]\"}\n    );\n    query(false, new Object[] {\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\"});\n\n    // test field that is valid in schema but missing in all shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2});\n    // test field that is valid in schema and missing in some shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2});\n\n    query(false, new Object[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1});\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    // check a complex key name\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(false, new Object[] {\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"*:*\", \"rows\",100});\n    }\n\n    // test debugging\n    handle.put(\"explain\", SKIPVAL);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP);\n    query(false, new Object[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY});\n\n    // try add commitWithin\n    long before = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    for (SolrClient client : clients) {\n      assertEquals(\"unexpected pre-commitWithin document count on node: \" + ((HttpSolrClient)client).getBaseURL(), before, client.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"commitWithin\", 10);\n    add(cloudClient, params , getDoc(\"id\", 300), getDoc(\"id\", 301));\n\n    newSearcherHook.waitForSearcher(DEFAULT_COLLECTION, 2, 20000, false);\n    \n    ClusterState clusterState = getCommonCloudSolrClient().getZkStateReader().getClusterState();\n    DocCollection dColl = clusterState.getCollection(DEFAULT_COLLECTION);\n\n    assertSliceCounts(\"should have found 2 docs, 300 and 301\", before + 2, dColl);\n\n    // try deleteById commitWithin\n    UpdateRequest deleteByIdReq = new UpdateRequest();\n    deleteByIdReq.deleteById(\"300\");\n    deleteByIdReq.setCommitWithin(10);\n    deleteByIdReq.process(cloudClient);\n    \n    newSearcherHook.waitForSearcher(DEFAULT_COLLECTION, 2, 20000, false);\n\n    assertSliceCounts(\"deleteById commitWithin did not work\", before + 1, dColl);\n    \n    // try deleteByQuery commitWithin\n    UpdateRequest deleteByQueryReq = new UpdateRequest();\n    deleteByQueryReq.deleteByQuery(\"id:301\");\n    deleteByQueryReq.setCommitWithin(10);\n    deleteByQueryReq.process(cloudClient);\n\n    newSearcherHook.waitForSearcher(DEFAULT_COLLECTION, 2, 20000, false);\n    \n    assertSliceCounts(\"deleteByQuery commitWithin did not work\", before, dColl);\n    \n\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // would be better if these where all separate tests - but much, much\n    // slower\n    doOptimisticLockingAndUpdating();\n    testShardParamVariations();\n    testMultipleCollections();\n    testANewCollectionInOneInstance();\n    testSearchByCollectionName();\n    testUpdateByCollectionName();\n    testANewCollectionInOneInstanceWithManualShardAssignement();\n    testNumberOfCommitsWithCommitAfterAdd();\n\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-explicit\");\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-implicit\");\n\n    testStopAndStartCoresInOneInstance();\n  }\n\n","sourceOld":"  @Test\n  @ShardsFixed(num = 4)\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // annotated on: 24-Dec-2018\n  public void test() throws Exception {\n    // setLoggingLevel(null);\n\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    // make sure we have leaders for each shard\n    for (int j = 1; j < sliceCount; j++) {\n      zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n    }      // make sure we again have leaders for each shard\n    \n    waitForRecoveriesToFinish(false);\n    \n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    del(\"*:*\");\n    queryAndCompareShards(params(\"q\", \"*:*\", \"distrib\", \"false\", \"sanity_check\", \"is_empty\"));\n\n    // ask every individual replica of every shard to update+commit the same doc id\n    // with an incrementing counter on each update+commit\n    int foo_i_counter = 0;\n    for (SolrClient client : clients) {\n      foo_i_counter++;\n      indexDoc(client, params(\"commit\", \"true\"), // SOLR-4923\n               sdoc(id,1, i1,100, tlong,100, \"foo_i\", foo_i_counter));\n      // after every update+commit, check all the shards consistency\n      queryAndCompareShards(params(\"q\", \"id:1\", \"distrib\", \"false\", \n                                   \"sanity_check\", \"non_distrib_id_1_lookup\"));\n      queryAndCompareShards(params(\"q\", \"id:1\", \n                                   \"sanity_check\", \"distrib_id_1_lookup\"));\n    }\n\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\"\n            ,\"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\"\n    );\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\"\n    );\n    indexr(id,4, i1, -100 ,tlong, 101,t1,\"the quick fox jumped over the lazy dog\"\n    );\n    indexr(id,5, i1, 500, tlong, 500 ,t1,\"the quick fox jumped way over the lazy dog\"\n    );\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,t1,\"no eggs on wall, lesson learned\", oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n    queryAndCompareShards(params(\"q\", \"*:*\", \n                                 \"sort\", \"id desc\",\n                                 \"distrib\", \"false\", \n                                 \"sanity_check\", \"is_empty\"));\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" desc\"});\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" asc\"});\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" asc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"}); \n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 desc\"});\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"{!func}\"+i1});// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(false, new String[] {\"q\",\"{!func}\"+i1, \"fl\",\"*,score\"});  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\"});  // no fields in returned docs\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\"});\n\n    handle.put(\"score\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\",\"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\"});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"matchesnothing\",\"fl\",\"*,score\"});  \n\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.offset\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2});\n\n    // test faceting multiple things at once\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1});\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id_i1:[1 TO 7]\", \"fq\",\"{!tag=b}id_i1:[3 TO 9]\"}\n    );\n    query(false, new Object[] {\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\"});\n\n    // test field that is valid in schema but missing in all shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2});\n    // test field that is valid in schema and missing in some shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2});\n\n    query(false, new Object[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1});\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    // check a complex key name\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(false, new Object[] {\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"*:*\", \"rows\",100});\n    }\n\n    // test debugging\n    handle.put(\"explain\", SKIPVAL);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP);\n    query(false, new Object[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY});\n\n    // try add commitWithin\n    long before = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    for (SolrClient client : clients) {\n      assertEquals(\"unexpected pre-commitWithin document count on node: \" + ((HttpSolrClient)client).getBaseURL(), before, client.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"commitWithin\", 10);\n    add(cloudClient, params , getDoc(\"id\", 300), getDoc(\"id\", 301));\n\n    newSearcherHook.waitForSearcher(DEFAULT_COLLECTION, 2, 20000, false);\n    \n    ClusterState clusterState = getCommonCloudSolrClient().getZkStateReader().getClusterState();\n    DocCollection dColl = clusterState.getCollection(DEFAULT_COLLECTION);\n\n    assertSliceCounts(\"should have found 2 docs, 300 and 301\", before + 2, dColl);\n\n    // try deleteById commitWithin\n    UpdateRequest deleteByIdReq = new UpdateRequest();\n    deleteByIdReq.deleteById(\"300\");\n    deleteByIdReq.setCommitWithin(10);\n    deleteByIdReq.process(cloudClient);\n    \n    newSearcherHook.waitForSearcher(DEFAULT_COLLECTION, 2, 20000, false);\n\n    assertSliceCounts(\"deleteById commitWithin did not work\", before + 1, dColl);\n    \n    // try deleteByQuery commitWithin\n    UpdateRequest deleteByQueryReq = new UpdateRequest();\n    deleteByQueryReq.deleteByQuery(\"id:301\");\n    deleteByQueryReq.setCommitWithin(10);\n    deleteByQueryReq.process(cloudClient);\n\n    newSearcherHook.waitForSearcher(DEFAULT_COLLECTION, 2, 20000, false);\n    \n    assertSliceCounts(\"deleteByQuery commitWithin did not work\", before, dColl);\n    \n\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // would be better if these where all separate tests - but much, much\n    // slower\n    doOptimisticLockingAndUpdating();\n    testShardParamVariations();\n    testMultipleCollections();\n    testANewCollectionInOneInstance();\n    testSearchByCollectionName();\n    testUpdateByCollectionName();\n    testANewCollectionInOneInstanceWithManualShardAssignement();\n    testNumberOfCommitsWithCommitAfterAdd();\n\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-explicit\");\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-implicit\");\n\n    testStopAndStartCoresInOneInstance();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bd66051e8d8d59ae300cec8b60f56810394a7511","date":1559669226,"type":3,"author":"erick","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#test().mjava","sourceNew":"  @Test\n  @ShardsFixed(num = 4)\n  // commented out on: 17-Feb-2019   @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // annotated on: 24-Dec-2018\n  public void test() throws Exception {\n    // setLoggingLevel(null);\n\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    // make sure we have leaders for each shard\n    for (int j = 1; j < sliceCount; j++) {\n      zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n    }      // make sure we again have leaders for each shard\n    \n    waitForRecoveriesToFinish(false);\n    \n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    del(\"*:*\");\n    queryAndCompareShards(params(\"q\", \"*:*\", \"distrib\", \"false\", \"sanity_check\", \"is_empty\"));\n\n    // ask every individual replica of every shard to update+commit the same doc id\n    // with an incrementing counter on each update+commit\n    int foo_i_counter = 0;\n    for (SolrClient client : clients) {\n      foo_i_counter++;\n      indexDoc(client, params(\"commit\", \"true\"), // SOLR-4923\n               sdoc(id,1, i1,100, tlong,100, \"foo_i\", foo_i_counter));\n      // after every update+commit, check all the shards consistency\n      queryAndCompareShards(params(\"q\", \"id:1\", \"distrib\", \"false\", \n                                   \"sanity_check\", \"non_distrib_id_1_lookup\"));\n      queryAndCompareShards(params(\"q\", \"id:1\", \n                                   \"sanity_check\", \"distrib_id_1_lookup\"));\n    }\n\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\"\n            ,\"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d, tsort, \"now is the time for all good men\");\n    indexr(id, 2, i1, 50, tlong, 50, t1, \"to come to the aid of their country.\"\n        , tsort, \"to come to the aid of their country.\");\n    indexr(id, 3, i1, 2, tlong, 2, t1, \"how now brown cow\", tsort, \"how now brown cow\");\n    indexr(id, 4, i1, -100, tlong, 101, t1, \"the quick fox jumped over the lazy dog\"\n        , tsort, \"the quick fox jumped over the lazy dog\");\n    indexr(id, 5, i1, 500, tlong, 500, t1, \"the quick fox jumped way over the lazy dog\"\n        , tsort, \"the quick fox jumped over the lazy dog\");\n    indexr(id, 6, i1, -600, tlong, 600, t1, \"humpty dumpy sat on a wall\", tsort, \"the quick fox jumped over the lazy dog\");\n    indexr(id, 7, i1, 123, tlong, 123, t1, \"humpty dumpy had a great fall\", tsort, \"the quick fox jumped over the lazy dog\");\n    indexr(id,8, i1, 876, tlong, 876,t1,\"all the kings horses and all the kings men\",tsort,\"all the kings horses and all the kings men\");\n    indexr(id, 9, i1, 7, tlong, 7, t1, \"couldn't put humpty together again\", tsort, \"the quick fox jumped over the lazy dog\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\",tsort,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,t1,\"An eye for eye only ends up making the whole world blind.\"\n        ,tsort,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,t1,\"Great works are performed, not by strength, but by perseverance.\",\n        tsort,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,t1,\"no eggs on wall, lesson learned\", oddField, \"odd man out\",\n        tsort,\"no eggs on wall, lesson learned\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    testTokenizedGrouping();\n    testSortableTextFaceting();\n    testSortableTextSorting();\n    testSortableTextGrouping();\n\n    queryAndCompareShards(params(\"q\", \"*:*\", \n                                 \"sort\", \"id desc\",\n                                 \"distrib\", \"false\", \n                                 \"sanity_check\", \"is_empty\"));\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" desc\"});\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" asc\"});\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" asc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"}); \n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 desc\"});\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"{!func}\"+i1});// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(false, new String[] {\"q\",\"{!func}\"+i1, \"fl\",\"*,score\"});  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\"});  // no fields in returned docs\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\"});\n\n    handle.put(\"score\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\",\"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\"});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"matchesnothing\",\"fl\",\"*,score\"});  \n\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.offset\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2});\n\n    // test faceting multiple things at once\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1});\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id_i1:[1 TO 7]\", \"fq\",\"{!tag=b}id_i1:[3 TO 9]\"}\n    );\n    query(false, new Object[] {\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\"});\n\n    // test field that is valid in schema but missing in all shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2});\n    // test field that is valid in schema and missing in some shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2});\n\n    query(false, new Object[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1});\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    // check a complex key name\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(false, new Object[] {\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"*:*\", \"rows\",100});\n    }\n\n    // test debugging\n    handle.put(\"explain\", SKIPVAL);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP);\n    query(false, new Object[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY});\n\n    // try add commitWithin\n    long before = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    for (SolrClient client : clients) {\n      assertEquals(\"unexpected pre-commitWithin document count on node: \" + ((HttpSolrClient)client).getBaseURL(), before, client.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"commitWithin\", 10);\n    add(cloudClient, params , getDoc(\"id\", 300), getDoc(\"id\", 301));\n\n    newSearcherHook.waitForSearcher(DEFAULT_COLLECTION, 2, 20000, false);\n    \n    ClusterState clusterState = getCommonCloudSolrClient().getZkStateReader().getClusterState();\n    DocCollection dColl = clusterState.getCollection(DEFAULT_COLLECTION);\n\n    assertSliceCounts(\"should have found 2 docs, 300 and 301\", before + 2, dColl);\n\n    // try deleteById commitWithin\n    UpdateRequest deleteByIdReq = new UpdateRequest();\n    deleteByIdReq.deleteById(\"300\");\n    deleteByIdReq.setCommitWithin(10);\n    deleteByIdReq.process(cloudClient);\n    \n    newSearcherHook.waitForSearcher(DEFAULT_COLLECTION, 2, 20000, false);\n\n    assertSliceCounts(\"deleteById commitWithin did not work\", before + 1, dColl);\n    \n    // try deleteByQuery commitWithin\n    UpdateRequest deleteByQueryReq = new UpdateRequest();\n    deleteByQueryReq.deleteByQuery(\"id:301\");\n    deleteByQueryReq.setCommitWithin(10);\n    deleteByQueryReq.process(cloudClient);\n\n    newSearcherHook.waitForSearcher(DEFAULT_COLLECTION, 2, 20000, false);\n    \n    assertSliceCounts(\"deleteByQuery commitWithin did not work\", before, dColl);\n    \n\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // would be better if these where all separate tests - but much, much\n    // slower\n    doOptimisticLockingAndUpdating();\n    testShardParamVariations();\n    testMultipleCollections();\n    testANewCollectionInOneInstance();\n    testSearchByCollectionName();\n    testUpdateByCollectionName();\n    testANewCollectionInOneInstanceWithManualShardAssignement();\n    testNumberOfCommitsWithCommitAfterAdd();\n\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-explicit\");\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-implicit\");\n\n    testStopAndStartCoresInOneInstance();\n  }\n\n","sourceOld":"  @Test\n  @ShardsFixed(num = 4)\n  // commented out on: 17-Feb-2019   @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // annotated on: 24-Dec-2018\n  public void test() throws Exception {\n    // setLoggingLevel(null);\n\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    // make sure we have leaders for each shard\n    for (int j = 1; j < sliceCount; j++) {\n      zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n    }      // make sure we again have leaders for each shard\n    \n    waitForRecoveriesToFinish(false);\n    \n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    del(\"*:*\");\n    queryAndCompareShards(params(\"q\", \"*:*\", \"distrib\", \"false\", \"sanity_check\", \"is_empty\"));\n\n    // ask every individual replica of every shard to update+commit the same doc id\n    // with an incrementing counter on each update+commit\n    int foo_i_counter = 0;\n    for (SolrClient client : clients) {\n      foo_i_counter++;\n      indexDoc(client, params(\"commit\", \"true\"), // SOLR-4923\n               sdoc(id,1, i1,100, tlong,100, \"foo_i\", foo_i_counter));\n      // after every update+commit, check all the shards consistency\n      queryAndCompareShards(params(\"q\", \"id:1\", \"distrib\", \"false\", \n                                   \"sanity_check\", \"non_distrib_id_1_lookup\"));\n      queryAndCompareShards(params(\"q\", \"id:1\", \n                                   \"sanity_check\", \"distrib_id_1_lookup\"));\n    }\n\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\"\n            ,\"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\"\n    );\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\"\n    );\n    indexr(id,4, i1, -100 ,tlong, 101,t1,\"the quick fox jumped over the lazy dog\"\n    );\n    indexr(id,5, i1, 500, tlong, 500 ,t1,\"the quick fox jumped way over the lazy dog\"\n    );\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,t1,\"no eggs on wall, lesson learned\", oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n    queryAndCompareShards(params(\"q\", \"*:*\", \n                                 \"sort\", \"id desc\",\n                                 \"distrib\", \"false\", \n                                 \"sanity_check\", \"is_empty\"));\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" desc\"});\n      query(false, new String[] {\"q\",\"*:*\", \"sort\",f+\" asc\"});\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" asc\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"}); \n    query(false, new String[] {\"q\",\"*:*\", \"sort\",\"n_tl1 desc\"});\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"{!func}\"+i1});// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(false, new String[] {\"q\",\"{!func}\"+i1, \"fl\",\"*,score\"});  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\"});  // no fields in returned docs\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\"});\n\n    handle.put(\"score\", SKIPVAL);\n    query(false, new String[] {\"q\",\"quick\",\"fl\",\"*,score\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\"});\n    query(false, new String[] {\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\"});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1});\n\n    query(false, new String[] {\"q\",\"matchesnothing\",\"fl\",\"*,score\"});  \n\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"count\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.limit\",-1, \"facet.sort\",\"index\", \"facet.mincount\",2});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.offset\",1});\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2});\n\n    // test faceting multiple things at once\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1});\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id_i1:[1 TO 7]\", \"fq\",\"{!tag=b}id_i1:[3 TO 9]\"}\n    );\n    query(false, new Object[] {\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\"});\n\n    // test field that is valid in schema but missing in all shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2});\n    // test field that is valid in schema and missing in some shards\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2});\n\n    query(false, new Object[] {\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1});\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    // check a complex key name\n    query(false, new Object[] {\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5});\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(false, new Object[] {\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1});\n      query(false, new Object[] {\"q\",\"*:*\", \"rows\",100});\n    }\n\n    // test debugging\n    handle.put(\"explain\", SKIPVAL);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP);\n    query(false, new Object[] {\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\"});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS});\n    query(false, new Object[] {\"q\", \"id_i1:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY});\n\n    // try add commitWithin\n    long before = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    for (SolrClient client : clients) {\n      assertEquals(\"unexpected pre-commitWithin document count on node: \" + ((HttpSolrClient)client).getBaseURL(), before, client.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"commitWithin\", 10);\n    add(cloudClient, params , getDoc(\"id\", 300), getDoc(\"id\", 301));\n\n    newSearcherHook.waitForSearcher(DEFAULT_COLLECTION, 2, 20000, false);\n    \n    ClusterState clusterState = getCommonCloudSolrClient().getZkStateReader().getClusterState();\n    DocCollection dColl = clusterState.getCollection(DEFAULT_COLLECTION);\n\n    assertSliceCounts(\"should have found 2 docs, 300 and 301\", before + 2, dColl);\n\n    // try deleteById commitWithin\n    UpdateRequest deleteByIdReq = new UpdateRequest();\n    deleteByIdReq.deleteById(\"300\");\n    deleteByIdReq.setCommitWithin(10);\n    deleteByIdReq.process(cloudClient);\n    \n    newSearcherHook.waitForSearcher(DEFAULT_COLLECTION, 2, 20000, false);\n\n    assertSliceCounts(\"deleteById commitWithin did not work\", before + 1, dColl);\n    \n    // try deleteByQuery commitWithin\n    UpdateRequest deleteByQueryReq = new UpdateRequest();\n    deleteByQueryReq.deleteByQuery(\"id:301\");\n    deleteByQueryReq.setCommitWithin(10);\n    deleteByQueryReq.process(cloudClient);\n\n    newSearcherHook.waitForSearcher(DEFAULT_COLLECTION, 2, 20000, false);\n    \n    assertSliceCounts(\"deleteByQuery commitWithin did not work\", before, dColl);\n    \n\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // would be better if these where all separate tests - but much, much\n    // slower\n    doOptimisticLockingAndUpdating();\n    testShardParamVariations();\n    testMultipleCollections();\n    testANewCollectionInOneInstance();\n    testSearchByCollectionName();\n    testUpdateByCollectionName();\n    testANewCollectionInOneInstanceWithManualShardAssignement();\n    testNumberOfCommitsWithCommitAfterAdd();\n\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-explicit\");\n    testUpdateProcessorsRunOnlyOnce(\"distrib-dup-test-chain-implicit\");\n\n    testStopAndStartCoresInOneInstance();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"44dd40f6c2c1465aebf4677bab10f696c7ea18d8":["d2d6b868457b26b5a2145b8441b1cfcfc0692b02"],"d2d6b868457b26b5a2145b8441b1cfcfc0692b02":["a1c374690db69470f6aa4bffc43dcacf1f4e3e49"],"68423be363a30c5a005b0eb6830c749d93b2b8db":["175a04d27a2b736171e7e51ca46a03b2aec094d4"],"82fbc9a4af34a68002cd5cf8bbac6b604aeef413":["68423be363a30c5a005b0eb6830c749d93b2b8db"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["44dd40f6c2c1465aebf4677bab10f696c7ea18d8"],"abb23fcc2461782ab204e61213240feb77d355aa":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a71f63026529f3c1f03cfdd664910873ab2369ae":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"b5c929d2716fa79d443b93a82adb1da5b578ebd8":["8d35c84fdef07284c122012ca4000d3b7285a66e"],"175a04d27a2b736171e7e51ca46a03b2aec094d4":["85b44c11e08024d47ec99e6befad81bd16391ad9"],"bd66051e8d8d59ae300cec8b60f56810394a7511":["b5c929d2716fa79d443b93a82adb1da5b578ebd8"],"28288370235ed02234a64753cdbf0c6ec096304a":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d","a71f63026529f3c1f03cfdd664910873ab2369ae"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["68423be363a30c5a005b0eb6830c749d93b2b8db","17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"8d35c84fdef07284c122012ca4000d3b7285a66e":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":["28288370235ed02234a64753cdbf0c6ec096304a","a1c374690db69470f6aa4bffc43dcacf1f4e3e49"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["68423be363a30c5a005b0eb6830c749d93b2b8db","82fbc9a4af34a68002cd5cf8bbac6b604aeef413"],"bcf9886c8ff537aafde14de48ebf744f5673f08b":["abb23fcc2461782ab204e61213240feb77d355aa"],"2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d","a71f63026529f3c1f03cfdd664910873ab2369ae"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["bd66051e8d8d59ae300cec8b60f56810394a7511"],"a1c374690db69470f6aa4bffc43dcacf1f4e3e49":["28288370235ed02234a64753cdbf0c6ec096304a"],"85b44c11e08024d47ec99e6befad81bd16391ad9":["bcf9886c8ff537aafde14de48ebf744f5673f08b"],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":["28288370235ed02234a64753cdbf0c6ec096304a","a1c374690db69470f6aa4bffc43dcacf1f4e3e49"]},"commit2Childs":{"44dd40f6c2c1465aebf4677bab10f696c7ea18d8":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"d2d6b868457b26b5a2145b8441b1cfcfc0692b02":["44dd40f6c2c1465aebf4677bab10f696c7ea18d8"],"68423be363a30c5a005b0eb6830c749d93b2b8db":["82fbc9a4af34a68002cd5cf8bbac6b604aeef413","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"82fbc9a4af34a68002cd5cf8bbac6b604aeef413":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["8d35c84fdef07284c122012ca4000d3b7285a66e"],"abb23fcc2461782ab204e61213240feb77d355aa":["bcf9886c8ff537aafde14de48ebf744f5673f08b"],"a71f63026529f3c1f03cfdd664910873ab2369ae":["28288370235ed02234a64753cdbf0c6ec096304a","2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9"],"175a04d27a2b736171e7e51ca46a03b2aec094d4":["68423be363a30c5a005b0eb6830c749d93b2b8db"],"b5c929d2716fa79d443b93a82adb1da5b578ebd8":["bd66051e8d8d59ae300cec8b60f56810394a7511"],"bd66051e8d8d59ae300cec8b60f56810394a7511":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"28288370235ed02234a64753cdbf0c6ec096304a":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","a1c374690db69470f6aa4bffc43dcacf1f4e3e49","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"8d35c84fdef07284c122012ca4000d3b7285a66e":["b5c929d2716fa79d443b93a82adb1da5b578ebd8"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["abb23fcc2461782ab204e61213240feb77d355aa"],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["a71f63026529f3c1f03cfdd664910873ab2369ae","28288370235ed02234a64753cdbf0c6ec096304a","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9"],"bcf9886c8ff537aafde14de48ebf744f5673f08b":["85b44c11e08024d47ec99e6befad81bd16391ad9"],"2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9":[],"a1c374690db69470f6aa4bffc43dcacf1f4e3e49":["d2d6b868457b26b5a2145b8441b1cfcfc0692b02","0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"85b44c11e08024d47ec99e6befad81bd16391ad9":["175a04d27a2b736171e7e51ca46a03b2aec094d4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":[]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9","cd5edd1f2b162a5cfa08efd17851a07373a96817","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}