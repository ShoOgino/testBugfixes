{"path":"src/test/org/apache/lucene/collation/CollationTestBase#testCollationKeySort(Analyzer,Analyzer,Analyzer,Analyzer,String).mjava","commits":[{"id":"4275990669802f4c50b4de5d3252a0987854ad68","date":1260360486,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"src/test/org/apache/lucene/collation/CollationTestBase#testCollationKeySort(Analyzer,Analyzer,Analyzer,Analyzer,String).mjava","pathOld":"contrib/collation/src/test/org/apache/lucene/collation/CollationTestBase#testCollationKeySort(Analyzer,Analyzer,Analyzer,Analyzer,String).mjava","sourceNew":"  // Test using various international locales with accented characters (which\n  // sort differently depending on locale)\n  //\n  // Copied (and slightly modified) from \n  // org.apache.lucene.search.TestSort.testInternationalSort()\n  //  \n  public void testCollationKeySort(Analyzer usAnalyzer,\n                                   Analyzer franceAnalyzer,\n                                   Analyzer swedenAnalyzer,\n                                   Analyzer denmarkAnalyzer,\n                                   String usResult) throws Exception {\n    RAMDirectory indexStore = new RAMDirectory();\n    PerFieldAnalyzerWrapper analyzer\n      = new PerFieldAnalyzerWrapper(new WhitespaceAnalyzer());\n    analyzer.addAnalyzer(\"US\", usAnalyzer);\n    analyzer.addAnalyzer(\"France\", franceAnalyzer);\n    analyzer.addAnalyzer(\"Sweden\", swedenAnalyzer);\n    analyzer.addAnalyzer(\"Denmark\", denmarkAnalyzer);\n    IndexWriter writer = new IndexWriter \n      (indexStore, analyzer, true, IndexWriter.MaxFieldLength.LIMITED);\n\n    // document data:\n    // the tracer field is used to determine which document was hit\n    String[][] sortData = new String[][] {\n      // tracer contents US                 France             Sweden (sv_SE)     Denmark (da_DK)\n      {  \"A\",   \"x\",     \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\"      },\n      {  \"B\",   \"y\",     \"HAT\",             \"HAT\",             \"HAT\",             \"HAT\"             },\n      {  \"C\",   \"x\",     \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\" },\n      {  \"D\",   \"y\",     \"HUT\",             \"HUT\",             \"HUT\",             \"HUT\"             },\n      {  \"E\",   \"x\",     \"peach\",           \"peach\",           \"peach\",           \"peach\"           },\n      {  \"F\",   \"y\",     \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\"        },\n      {  \"G\",   \"x\",     \"sin\",             \"sin\",             \"sin\",             \"sin\"             },\n      {  \"H\",   \"y\",     \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\"        },\n      {  \"I\",   \"x\",     \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\"        },\n      {  \"J\",   \"y\",     \"HOT\",             \"HOT\",             \"HOT\",             \"HOT\"             },\n    };\n\n    for (int i = 0 ; i < sortData.length ; ++i) {\n      Document doc = new Document();\n      doc.add(new Field(\"tracer\", sortData[i][0], \n                        Field.Store.YES, Field.Index.NO));\n      doc.add(new Field(\"contents\", sortData[i][1], \n                        Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][2] != null) \n        doc.add(new Field(\"US\", sortData[i][2], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][3] != null) \n        doc.add(new Field(\"France\", sortData[i][3], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][4] != null)\n        doc.add(new Field(\"Sweden\", sortData[i][4], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][5] != null) \n        doc.add(new Field(\"Denmark\", sortData[i][5], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      writer.addDocument(doc);\n    }\n    writer.optimize();\n    writer.close();\n    Searcher searcher = new IndexSearcher(indexStore, true);\n\n    Sort sort = new Sort();\n    Query queryX = new TermQuery(new Term (\"contents\", \"x\"));\n    Query queryY = new TermQuery(new Term (\"contents\", \"y\"));\n    \n    sort.setSort(new SortField(\"US\", SortField.STRING));\n    assertMatches(searcher, queryY, sort, usResult);\n\n    sort.setSort(new SortField(\"France\", SortField.STRING));\n    assertMatches(searcher, queryX, sort, \"EACGI\");\n\n    sort.setSort(new SortField(\"Sweden\", SortField.STRING));\n    assertMatches(searcher, queryY, sort, \"BJDFH\");\n\n    sort.setSort(new SortField(\"Denmark\", SortField.STRING));\n    assertMatches(searcher, queryY, sort, \"BJDHF\");\n  }\n\n","sourceOld":"  // Test using various international locales with accented characters (which\n  // sort differently depending on locale)\n  //\n  // Copied (and slightly modified) from \n  // org.apache.lucene.search.TestSort.testInternationalSort()\n  //  \n  public void testCollationKeySort(Analyzer usAnalyzer,\n                                   Analyzer franceAnalyzer,\n                                   Analyzer swedenAnalyzer,\n                                   Analyzer denmarkAnalyzer,\n                                   String usResult) throws Exception {\n    RAMDirectory indexStore = new RAMDirectory();\n    PerFieldAnalyzerWrapper analyzer\n      = new PerFieldAnalyzerWrapper(new WhitespaceAnalyzer());\n    analyzer.addAnalyzer(\"US\", usAnalyzer);\n    analyzer.addAnalyzer(\"France\", franceAnalyzer);\n    analyzer.addAnalyzer(\"Sweden\", swedenAnalyzer);\n    analyzer.addAnalyzer(\"Denmark\", denmarkAnalyzer);\n    IndexWriter writer = new IndexWriter \n      (indexStore, analyzer, true, IndexWriter.MaxFieldLength.LIMITED);\n\n    // document data:\n    // the tracer field is used to determine which document was hit\n    String[][] sortData = new String[][] {\n      // tracer contents US                 France             Sweden (sv_SE)     Denmark (da_DK)\n      {  \"A\",   \"x\",     \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\"      },\n      {  \"B\",   \"y\",     \"HAT\",             \"HAT\",             \"HAT\",             \"HAT\"             },\n      {  \"C\",   \"x\",     \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\" },\n      {  \"D\",   \"y\",     \"HUT\",             \"HUT\",             \"HUT\",             \"HUT\"             },\n      {  \"E\",   \"x\",     \"peach\",           \"peach\",           \"peach\",           \"peach\"           },\n      {  \"F\",   \"y\",     \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\"        },\n      {  \"G\",   \"x\",     \"sin\",             \"sin\",             \"sin\",             \"sin\"             },\n      {  \"H\",   \"y\",     \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\"        },\n      {  \"I\",   \"x\",     \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\"        },\n      {  \"J\",   \"y\",     \"HOT\",             \"HOT\",             \"HOT\",             \"HOT\"             },\n    };\n\n    for (int i = 0 ; i < sortData.length ; ++i) {\n      Document doc = new Document();\n      doc.add(new Field(\"tracer\", sortData[i][0], \n                        Field.Store.YES, Field.Index.NO));\n      doc.add(new Field(\"contents\", sortData[i][1], \n                        Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][2] != null) \n        doc.add(new Field(\"US\", sortData[i][2], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][3] != null) \n        doc.add(new Field(\"France\", sortData[i][3], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][4] != null)\n        doc.add(new Field(\"Sweden\", sortData[i][4], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][5] != null) \n        doc.add(new Field(\"Denmark\", sortData[i][5], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      writer.addDocument(doc);\n    }\n    writer.optimize();\n    writer.close();\n    Searcher searcher = new IndexSearcher(indexStore, true);\n\n    Sort sort = new Sort();\n    Query queryX = new TermQuery(new Term (\"contents\", \"x\"));\n    Query queryY = new TermQuery(new Term (\"contents\", \"y\"));\n    \n    sort.setSort(new SortField(\"US\", SortField.STRING));\n    assertMatches(searcher, queryY, sort, usResult);\n\n    sort.setSort(new SortField(\"France\", SortField.STRING));\n    assertMatches(searcher, queryX, sort, \"EACGI\");\n\n    sort.setSort(new SortField(\"Sweden\", SortField.STRING));\n    assertMatches(searcher, queryY, sort, \"BJDFH\");\n\n    sort.setSort(new SortField(\"Denmark\", SortField.STRING));\n    assertMatches(searcher, queryY, sort, \"BJDHF\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fe0932c1d340f83fb0a611e5829b3046a1cc1152","date":1264946739,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/test/org/apache/lucene/collation/CollationTestBase#testCollationKeySort(Analyzer,Analyzer,Analyzer,Analyzer,String).mjava","pathOld":"src/test/org/apache/lucene/collation/CollationTestBase#testCollationKeySort(Analyzer,Analyzer,Analyzer,Analyzer,String).mjava","sourceNew":"  // Test using various international locales with accented characters (which\n  // sort differently depending on locale)\n  //\n  // Copied (and slightly modified) from \n  // org.apache.lucene.search.TestSort.testInternationalSort()\n  //  \n  public void testCollationKeySort(Analyzer usAnalyzer,\n                                   Analyzer franceAnalyzer,\n                                   Analyzer swedenAnalyzer,\n                                   Analyzer denmarkAnalyzer,\n                                   String usResult) throws Exception {\n    RAMDirectory indexStore = new RAMDirectory();\n    PerFieldAnalyzerWrapper analyzer\n      = new PerFieldAnalyzerWrapper(new WhitespaceAnalyzer(Version.LUCENE_CURRENT));\n    analyzer.addAnalyzer(\"US\", usAnalyzer);\n    analyzer.addAnalyzer(\"France\", franceAnalyzer);\n    analyzer.addAnalyzer(\"Sweden\", swedenAnalyzer);\n    analyzer.addAnalyzer(\"Denmark\", denmarkAnalyzer);\n    IndexWriter writer = new IndexWriter \n      (indexStore, analyzer, true, IndexWriter.MaxFieldLength.LIMITED);\n\n    // document data:\n    // the tracer field is used to determine which document was hit\n    String[][] sortData = new String[][] {\n      // tracer contents US                 France             Sweden (sv_SE)     Denmark (da_DK)\n      {  \"A\",   \"x\",     \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\"      },\n      {  \"B\",   \"y\",     \"HAT\",             \"HAT\",             \"HAT\",             \"HAT\"             },\n      {  \"C\",   \"x\",     \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\" },\n      {  \"D\",   \"y\",     \"HUT\",             \"HUT\",             \"HUT\",             \"HUT\"             },\n      {  \"E\",   \"x\",     \"peach\",           \"peach\",           \"peach\",           \"peach\"           },\n      {  \"F\",   \"y\",     \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\"        },\n      {  \"G\",   \"x\",     \"sin\",             \"sin\",             \"sin\",             \"sin\"             },\n      {  \"H\",   \"y\",     \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\"        },\n      {  \"I\",   \"x\",     \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\"        },\n      {  \"J\",   \"y\",     \"HOT\",             \"HOT\",             \"HOT\",             \"HOT\"             },\n    };\n\n    for (int i = 0 ; i < sortData.length ; ++i) {\n      Document doc = new Document();\n      doc.add(new Field(\"tracer\", sortData[i][0], \n                        Field.Store.YES, Field.Index.NO));\n      doc.add(new Field(\"contents\", sortData[i][1], \n                        Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][2] != null) \n        doc.add(new Field(\"US\", sortData[i][2], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][3] != null) \n        doc.add(new Field(\"France\", sortData[i][3], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][4] != null)\n        doc.add(new Field(\"Sweden\", sortData[i][4], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][5] != null) \n        doc.add(new Field(\"Denmark\", sortData[i][5], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      writer.addDocument(doc);\n    }\n    writer.optimize();\n    writer.close();\n    Searcher searcher = new IndexSearcher(indexStore, true);\n\n    Sort sort = new Sort();\n    Query queryX = new TermQuery(new Term (\"contents\", \"x\"));\n    Query queryY = new TermQuery(new Term (\"contents\", \"y\"));\n    \n    sort.setSort(new SortField(\"US\", SortField.STRING));\n    assertMatches(searcher, queryY, sort, usResult);\n\n    sort.setSort(new SortField(\"France\", SortField.STRING));\n    assertMatches(searcher, queryX, sort, \"EACGI\");\n\n    sort.setSort(new SortField(\"Sweden\", SortField.STRING));\n    assertMatches(searcher, queryY, sort, \"BJDFH\");\n\n    sort.setSort(new SortField(\"Denmark\", SortField.STRING));\n    assertMatches(searcher, queryY, sort, \"BJDHF\");\n  }\n\n","sourceOld":"  // Test using various international locales with accented characters (which\n  // sort differently depending on locale)\n  //\n  // Copied (and slightly modified) from \n  // org.apache.lucene.search.TestSort.testInternationalSort()\n  //  \n  public void testCollationKeySort(Analyzer usAnalyzer,\n                                   Analyzer franceAnalyzer,\n                                   Analyzer swedenAnalyzer,\n                                   Analyzer denmarkAnalyzer,\n                                   String usResult) throws Exception {\n    RAMDirectory indexStore = new RAMDirectory();\n    PerFieldAnalyzerWrapper analyzer\n      = new PerFieldAnalyzerWrapper(new WhitespaceAnalyzer());\n    analyzer.addAnalyzer(\"US\", usAnalyzer);\n    analyzer.addAnalyzer(\"France\", franceAnalyzer);\n    analyzer.addAnalyzer(\"Sweden\", swedenAnalyzer);\n    analyzer.addAnalyzer(\"Denmark\", denmarkAnalyzer);\n    IndexWriter writer = new IndexWriter \n      (indexStore, analyzer, true, IndexWriter.MaxFieldLength.LIMITED);\n\n    // document data:\n    // the tracer field is used to determine which document was hit\n    String[][] sortData = new String[][] {\n      // tracer contents US                 France             Sweden (sv_SE)     Denmark (da_DK)\n      {  \"A\",   \"x\",     \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\"      },\n      {  \"B\",   \"y\",     \"HAT\",             \"HAT\",             \"HAT\",             \"HAT\"             },\n      {  \"C\",   \"x\",     \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\" },\n      {  \"D\",   \"y\",     \"HUT\",             \"HUT\",             \"HUT\",             \"HUT\"             },\n      {  \"E\",   \"x\",     \"peach\",           \"peach\",           \"peach\",           \"peach\"           },\n      {  \"F\",   \"y\",     \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\"        },\n      {  \"G\",   \"x\",     \"sin\",             \"sin\",             \"sin\",             \"sin\"             },\n      {  \"H\",   \"y\",     \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\"        },\n      {  \"I\",   \"x\",     \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\"        },\n      {  \"J\",   \"y\",     \"HOT\",             \"HOT\",             \"HOT\",             \"HOT\"             },\n    };\n\n    for (int i = 0 ; i < sortData.length ; ++i) {\n      Document doc = new Document();\n      doc.add(new Field(\"tracer\", sortData[i][0], \n                        Field.Store.YES, Field.Index.NO));\n      doc.add(new Field(\"contents\", sortData[i][1], \n                        Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][2] != null) \n        doc.add(new Field(\"US\", sortData[i][2], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][3] != null) \n        doc.add(new Field(\"France\", sortData[i][3], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][4] != null)\n        doc.add(new Field(\"Sweden\", sortData[i][4], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][5] != null) \n        doc.add(new Field(\"Denmark\", sortData[i][5], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      writer.addDocument(doc);\n    }\n    writer.optimize();\n    writer.close();\n    Searcher searcher = new IndexSearcher(indexStore, true);\n\n    Sort sort = new Sort();\n    Query queryX = new TermQuery(new Term (\"contents\", \"x\"));\n    Query queryY = new TermQuery(new Term (\"contents\", \"y\"));\n    \n    sort.setSort(new SortField(\"US\", SortField.STRING));\n    assertMatches(searcher, queryY, sort, usResult);\n\n    sort.setSort(new SortField(\"France\", SortField.STRING));\n    assertMatches(searcher, queryX, sort, \"EACGI\");\n\n    sort.setSort(new SortField(\"Sweden\", SortField.STRING));\n    assertMatches(searcher, queryY, sort, \"BJDFH\");\n\n    sort.setSort(new SortField(\"Denmark\", SortField.STRING));\n    assertMatches(searcher, queryY, sort, \"BJDHF\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"55f083e91bb056b57de136da1dfc3b9b6ecc4ef6","date":1265808957,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/test/org/apache/lucene/collation/CollationTestBase#testCollationKeySort(Analyzer,Analyzer,Analyzer,Analyzer,String).mjava","pathOld":"src/test/org/apache/lucene/collation/CollationTestBase#testCollationKeySort(Analyzer,Analyzer,Analyzer,Analyzer,String).mjava","sourceNew":"  // Test using various international locales with accented characters (which\n  // sort differently depending on locale)\n  //\n  // Copied (and slightly modified) from \n  // org.apache.lucene.search.TestSort.testInternationalSort()\n  //  \n  public void testCollationKeySort(Analyzer usAnalyzer,\n                                   Analyzer franceAnalyzer,\n                                   Analyzer swedenAnalyzer,\n                                   Analyzer denmarkAnalyzer,\n                                   String usResult) throws Exception {\n    RAMDirectory indexStore = new RAMDirectory();\n    PerFieldAnalyzerWrapper analyzer\n      = new PerFieldAnalyzerWrapper(new WhitespaceAnalyzer(TEST_VERSION_CURRENT));\n    analyzer.addAnalyzer(\"US\", usAnalyzer);\n    analyzer.addAnalyzer(\"France\", franceAnalyzer);\n    analyzer.addAnalyzer(\"Sweden\", swedenAnalyzer);\n    analyzer.addAnalyzer(\"Denmark\", denmarkAnalyzer);\n    IndexWriter writer = new IndexWriter \n      (indexStore, analyzer, true, IndexWriter.MaxFieldLength.LIMITED);\n\n    // document data:\n    // the tracer field is used to determine which document was hit\n    String[][] sortData = new String[][] {\n      // tracer contents US                 France             Sweden (sv_SE)     Denmark (da_DK)\n      {  \"A\",   \"x\",     \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\"      },\n      {  \"B\",   \"y\",     \"HAT\",             \"HAT\",             \"HAT\",             \"HAT\"             },\n      {  \"C\",   \"x\",     \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\" },\n      {  \"D\",   \"y\",     \"HUT\",             \"HUT\",             \"HUT\",             \"HUT\"             },\n      {  \"E\",   \"x\",     \"peach\",           \"peach\",           \"peach\",           \"peach\"           },\n      {  \"F\",   \"y\",     \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\"        },\n      {  \"G\",   \"x\",     \"sin\",             \"sin\",             \"sin\",             \"sin\"             },\n      {  \"H\",   \"y\",     \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\"        },\n      {  \"I\",   \"x\",     \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\"        },\n      {  \"J\",   \"y\",     \"HOT\",             \"HOT\",             \"HOT\",             \"HOT\"             },\n    };\n\n    for (int i = 0 ; i < sortData.length ; ++i) {\n      Document doc = new Document();\n      doc.add(new Field(\"tracer\", sortData[i][0], \n                        Field.Store.YES, Field.Index.NO));\n      doc.add(new Field(\"contents\", sortData[i][1], \n                        Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][2] != null) \n        doc.add(new Field(\"US\", sortData[i][2], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][3] != null) \n        doc.add(new Field(\"France\", sortData[i][3], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][4] != null)\n        doc.add(new Field(\"Sweden\", sortData[i][4], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][5] != null) \n        doc.add(new Field(\"Denmark\", sortData[i][5], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      writer.addDocument(doc);\n    }\n    writer.optimize();\n    writer.close();\n    Searcher searcher = new IndexSearcher(indexStore, true);\n\n    Sort sort = new Sort();\n    Query queryX = new TermQuery(new Term (\"contents\", \"x\"));\n    Query queryY = new TermQuery(new Term (\"contents\", \"y\"));\n    \n    sort.setSort(new SortField(\"US\", SortField.STRING));\n    assertMatches(searcher, queryY, sort, usResult);\n\n    sort.setSort(new SortField(\"France\", SortField.STRING));\n    assertMatches(searcher, queryX, sort, \"EACGI\");\n\n    sort.setSort(new SortField(\"Sweden\", SortField.STRING));\n    assertMatches(searcher, queryY, sort, \"BJDFH\");\n\n    sort.setSort(new SortField(\"Denmark\", SortField.STRING));\n    assertMatches(searcher, queryY, sort, \"BJDHF\");\n  }\n\n","sourceOld":"  // Test using various international locales with accented characters (which\n  // sort differently depending on locale)\n  //\n  // Copied (and slightly modified) from \n  // org.apache.lucene.search.TestSort.testInternationalSort()\n  //  \n  public void testCollationKeySort(Analyzer usAnalyzer,\n                                   Analyzer franceAnalyzer,\n                                   Analyzer swedenAnalyzer,\n                                   Analyzer denmarkAnalyzer,\n                                   String usResult) throws Exception {\n    RAMDirectory indexStore = new RAMDirectory();\n    PerFieldAnalyzerWrapper analyzer\n      = new PerFieldAnalyzerWrapper(new WhitespaceAnalyzer(Version.LUCENE_CURRENT));\n    analyzer.addAnalyzer(\"US\", usAnalyzer);\n    analyzer.addAnalyzer(\"France\", franceAnalyzer);\n    analyzer.addAnalyzer(\"Sweden\", swedenAnalyzer);\n    analyzer.addAnalyzer(\"Denmark\", denmarkAnalyzer);\n    IndexWriter writer = new IndexWriter \n      (indexStore, analyzer, true, IndexWriter.MaxFieldLength.LIMITED);\n\n    // document data:\n    // the tracer field is used to determine which document was hit\n    String[][] sortData = new String[][] {\n      // tracer contents US                 France             Sweden (sv_SE)     Denmark (da_DK)\n      {  \"A\",   \"x\",     \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\"      },\n      {  \"B\",   \"y\",     \"HAT\",             \"HAT\",             \"HAT\",             \"HAT\"             },\n      {  \"C\",   \"x\",     \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\" },\n      {  \"D\",   \"y\",     \"HUT\",             \"HUT\",             \"HUT\",             \"HUT\"             },\n      {  \"E\",   \"x\",     \"peach\",           \"peach\",           \"peach\",           \"peach\"           },\n      {  \"F\",   \"y\",     \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\"        },\n      {  \"G\",   \"x\",     \"sin\",             \"sin\",             \"sin\",             \"sin\"             },\n      {  \"H\",   \"y\",     \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\"        },\n      {  \"I\",   \"x\",     \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\"        },\n      {  \"J\",   \"y\",     \"HOT\",             \"HOT\",             \"HOT\",             \"HOT\"             },\n    };\n\n    for (int i = 0 ; i < sortData.length ; ++i) {\n      Document doc = new Document();\n      doc.add(new Field(\"tracer\", sortData[i][0], \n                        Field.Store.YES, Field.Index.NO));\n      doc.add(new Field(\"contents\", sortData[i][1], \n                        Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][2] != null) \n        doc.add(new Field(\"US\", sortData[i][2], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][3] != null) \n        doc.add(new Field(\"France\", sortData[i][3], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][4] != null)\n        doc.add(new Field(\"Sweden\", sortData[i][4], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][5] != null) \n        doc.add(new Field(\"Denmark\", sortData[i][5], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      writer.addDocument(doc);\n    }\n    writer.optimize();\n    writer.close();\n    Searcher searcher = new IndexSearcher(indexStore, true);\n\n    Sort sort = new Sort();\n    Query queryX = new TermQuery(new Term (\"contents\", \"x\"));\n    Query queryY = new TermQuery(new Term (\"contents\", \"y\"));\n    \n    sort.setSort(new SortField(\"US\", SortField.STRING));\n    assertMatches(searcher, queryY, sort, usResult);\n\n    sort.setSort(new SortField(\"France\", SortField.STRING));\n    assertMatches(searcher, queryX, sort, \"EACGI\");\n\n    sort.setSort(new SortField(\"Sweden\", SortField.STRING));\n    assertMatches(searcher, queryY, sort, \"BJDFH\");\n\n    sort.setSort(new SortField(\"Denmark\", SortField.STRING));\n    assertMatches(searcher, queryY, sort, \"BJDHF\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1cedb00d2dd44640194401179358a2e3ba6051bf","date":1268243626,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/collation/CollationTestBase#testCollationKeySort(Analyzer,Analyzer,Analyzer,Analyzer,String).mjava","pathOld":"src/test/org/apache/lucene/collation/CollationTestBase#testCollationKeySort(Analyzer,Analyzer,Analyzer,Analyzer,String).mjava","sourceNew":"  // Test using various international locales with accented characters (which\n  // sort differently depending on locale)\n  //\n  // Copied (and slightly modified) from \n  // org.apache.lucene.search.TestSort.testInternationalSort()\n  //  \n  public void testCollationKeySort(Analyzer usAnalyzer,\n                                   Analyzer franceAnalyzer,\n                                   Analyzer swedenAnalyzer,\n                                   Analyzer denmarkAnalyzer,\n                                   String usResult) throws Exception {\n    RAMDirectory indexStore = new RAMDirectory();\n    PerFieldAnalyzerWrapper analyzer\n      = new PerFieldAnalyzerWrapper(new WhitespaceAnalyzer(TEST_VERSION_CURRENT));\n    analyzer.addAnalyzer(\"US\", usAnalyzer);\n    analyzer.addAnalyzer(\"France\", franceAnalyzer);\n    analyzer.addAnalyzer(\"Sweden\", swedenAnalyzer);\n    analyzer.addAnalyzer(\"Denmark\", denmarkAnalyzer);\n    IndexWriter writer = new IndexWriter(indexStore, new IndexWriterConfig(TEST_VERSION_CURRENT).setAnalyzer(analyzer));\n\n    // document data:\n    // the tracer field is used to determine which document was hit\n    String[][] sortData = new String[][] {\n      // tracer contents US                 France             Sweden (sv_SE)     Denmark (da_DK)\n      {  \"A\",   \"x\",     \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\"      },\n      {  \"B\",   \"y\",     \"HAT\",             \"HAT\",             \"HAT\",             \"HAT\"             },\n      {  \"C\",   \"x\",     \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\" },\n      {  \"D\",   \"y\",     \"HUT\",             \"HUT\",             \"HUT\",             \"HUT\"             },\n      {  \"E\",   \"x\",     \"peach\",           \"peach\",           \"peach\",           \"peach\"           },\n      {  \"F\",   \"y\",     \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\"        },\n      {  \"G\",   \"x\",     \"sin\",             \"sin\",             \"sin\",             \"sin\"             },\n      {  \"H\",   \"y\",     \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\"        },\n      {  \"I\",   \"x\",     \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\"        },\n      {  \"J\",   \"y\",     \"HOT\",             \"HOT\",             \"HOT\",             \"HOT\"             },\n    };\n\n    for (int i = 0 ; i < sortData.length ; ++i) {\n      Document doc = new Document();\n      doc.add(new Field(\"tracer\", sortData[i][0], \n                        Field.Store.YES, Field.Index.NO));\n      doc.add(new Field(\"contents\", sortData[i][1], \n                        Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][2] != null) \n        doc.add(new Field(\"US\", sortData[i][2], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][3] != null) \n        doc.add(new Field(\"France\", sortData[i][3], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][4] != null)\n        doc.add(new Field(\"Sweden\", sortData[i][4], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][5] != null) \n        doc.add(new Field(\"Denmark\", sortData[i][5], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      writer.addDocument(doc);\n    }\n    writer.optimize();\n    writer.close();\n    Searcher searcher = new IndexSearcher(indexStore, true);\n\n    Sort sort = new Sort();\n    Query queryX = new TermQuery(new Term (\"contents\", \"x\"));\n    Query queryY = new TermQuery(new Term (\"contents\", \"y\"));\n    \n    sort.setSort(new SortField(\"US\", SortField.STRING));\n    assertMatches(searcher, queryY, sort, usResult);\n\n    sort.setSort(new SortField(\"France\", SortField.STRING));\n    assertMatches(searcher, queryX, sort, \"EACGI\");\n\n    sort.setSort(new SortField(\"Sweden\", SortField.STRING));\n    assertMatches(searcher, queryY, sort, \"BJDFH\");\n\n    sort.setSort(new SortField(\"Denmark\", SortField.STRING));\n    assertMatches(searcher, queryY, sort, \"BJDHF\");\n  }\n\n","sourceOld":"  // Test using various international locales with accented characters (which\n  // sort differently depending on locale)\n  //\n  // Copied (and slightly modified) from \n  // org.apache.lucene.search.TestSort.testInternationalSort()\n  //  \n  public void testCollationKeySort(Analyzer usAnalyzer,\n                                   Analyzer franceAnalyzer,\n                                   Analyzer swedenAnalyzer,\n                                   Analyzer denmarkAnalyzer,\n                                   String usResult) throws Exception {\n    RAMDirectory indexStore = new RAMDirectory();\n    PerFieldAnalyzerWrapper analyzer\n      = new PerFieldAnalyzerWrapper(new WhitespaceAnalyzer(TEST_VERSION_CURRENT));\n    analyzer.addAnalyzer(\"US\", usAnalyzer);\n    analyzer.addAnalyzer(\"France\", franceAnalyzer);\n    analyzer.addAnalyzer(\"Sweden\", swedenAnalyzer);\n    analyzer.addAnalyzer(\"Denmark\", denmarkAnalyzer);\n    IndexWriter writer = new IndexWriter \n      (indexStore, analyzer, true, IndexWriter.MaxFieldLength.LIMITED);\n\n    // document data:\n    // the tracer field is used to determine which document was hit\n    String[][] sortData = new String[][] {\n      // tracer contents US                 France             Sweden (sv_SE)     Denmark (da_DK)\n      {  \"A\",   \"x\",     \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\"      },\n      {  \"B\",   \"y\",     \"HAT\",             \"HAT\",             \"HAT\",             \"HAT\"             },\n      {  \"C\",   \"x\",     \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\" },\n      {  \"D\",   \"y\",     \"HUT\",             \"HUT\",             \"HUT\",             \"HUT\"             },\n      {  \"E\",   \"x\",     \"peach\",           \"peach\",           \"peach\",           \"peach\"           },\n      {  \"F\",   \"y\",     \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\"        },\n      {  \"G\",   \"x\",     \"sin\",             \"sin\",             \"sin\",             \"sin\"             },\n      {  \"H\",   \"y\",     \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\"        },\n      {  \"I\",   \"x\",     \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\"        },\n      {  \"J\",   \"y\",     \"HOT\",             \"HOT\",             \"HOT\",             \"HOT\"             },\n    };\n\n    for (int i = 0 ; i < sortData.length ; ++i) {\n      Document doc = new Document();\n      doc.add(new Field(\"tracer\", sortData[i][0], \n                        Field.Store.YES, Field.Index.NO));\n      doc.add(new Field(\"contents\", sortData[i][1], \n                        Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][2] != null) \n        doc.add(new Field(\"US\", sortData[i][2], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][3] != null) \n        doc.add(new Field(\"France\", sortData[i][3], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][4] != null)\n        doc.add(new Field(\"Sweden\", sortData[i][4], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][5] != null) \n        doc.add(new Field(\"Denmark\", sortData[i][5], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      writer.addDocument(doc);\n    }\n    writer.optimize();\n    writer.close();\n    Searcher searcher = new IndexSearcher(indexStore, true);\n\n    Sort sort = new Sort();\n    Query queryX = new TermQuery(new Term (\"contents\", \"x\"));\n    Query queryY = new TermQuery(new Term (\"contents\", \"y\"));\n    \n    sort.setSort(new SortField(\"US\", SortField.STRING));\n    assertMatches(searcher, queryY, sort, usResult);\n\n    sort.setSort(new SortField(\"France\", SortField.STRING));\n    assertMatches(searcher, queryX, sort, \"EACGI\");\n\n    sort.setSort(new SortField(\"Sweden\", SortField.STRING));\n    assertMatches(searcher, queryY, sort, \"BJDFH\");\n\n    sort.setSort(new SortField(\"Denmark\", SortField.STRING));\n    assertMatches(searcher, queryY, sort, \"BJDHF\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e52fea2c4081a1e552b98506691990be59503168","date":1268250331,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/collation/CollationTestBase#testCollationKeySort(Analyzer,Analyzer,Analyzer,Analyzer,String).mjava","pathOld":"src/test/org/apache/lucene/collation/CollationTestBase#testCollationKeySort(Analyzer,Analyzer,Analyzer,Analyzer,String).mjava","sourceNew":"  // Test using various international locales with accented characters (which\n  // sort differently depending on locale)\n  //\n  // Copied (and slightly modified) from \n  // org.apache.lucene.search.TestSort.testInternationalSort()\n  //  \n  public void testCollationKeySort(Analyzer usAnalyzer,\n                                   Analyzer franceAnalyzer,\n                                   Analyzer swedenAnalyzer,\n                                   Analyzer denmarkAnalyzer,\n                                   String usResult) throws Exception {\n    RAMDirectory indexStore = new RAMDirectory();\n    PerFieldAnalyzerWrapper analyzer\n      = new PerFieldAnalyzerWrapper(new WhitespaceAnalyzer(TEST_VERSION_CURRENT));\n    analyzer.addAnalyzer(\"US\", usAnalyzer);\n    analyzer.addAnalyzer(\"France\", franceAnalyzer);\n    analyzer.addAnalyzer(\"Sweden\", swedenAnalyzer);\n    analyzer.addAnalyzer(\"Denmark\", denmarkAnalyzer);\n    IndexWriter writer = new IndexWriter \n      (indexStore, analyzer, true, IndexWriter.MaxFieldLength.LIMITED);\n\n    // document data:\n    // the tracer field is used to determine which document was hit\n    String[][] sortData = new String[][] {\n      // tracer contents US                 France             Sweden (sv_SE)     Denmark (da_DK)\n      {  \"A\",   \"x\",     \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\"      },\n      {  \"B\",   \"y\",     \"HAT\",             \"HAT\",             \"HAT\",             \"HAT\"             },\n      {  \"C\",   \"x\",     \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\" },\n      {  \"D\",   \"y\",     \"HUT\",             \"HUT\",             \"HUT\",             \"HUT\"             },\n      {  \"E\",   \"x\",     \"peach\",           \"peach\",           \"peach\",           \"peach\"           },\n      {  \"F\",   \"y\",     \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\"        },\n      {  \"G\",   \"x\",     \"sin\",             \"sin\",             \"sin\",             \"sin\"             },\n      {  \"H\",   \"y\",     \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\"        },\n      {  \"I\",   \"x\",     \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\"        },\n      {  \"J\",   \"y\",     \"HOT\",             \"HOT\",             \"HOT\",             \"HOT\"             },\n    };\n\n    for (int i = 0 ; i < sortData.length ; ++i) {\n      Document doc = new Document();\n      doc.add(new Field(\"tracer\", sortData[i][0], \n                        Field.Store.YES, Field.Index.NO));\n      doc.add(new Field(\"contents\", sortData[i][1], \n                        Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][2] != null) \n        doc.add(new Field(\"US\", sortData[i][2], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][3] != null) \n        doc.add(new Field(\"France\", sortData[i][3], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][4] != null)\n        doc.add(new Field(\"Sweden\", sortData[i][4], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][5] != null) \n        doc.add(new Field(\"Denmark\", sortData[i][5], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      writer.addDocument(doc);\n    }\n    writer.optimize();\n    writer.close();\n    Searcher searcher = new IndexSearcher(indexStore, true);\n\n    Sort sort = new Sort();\n    Query queryX = new TermQuery(new Term (\"contents\", \"x\"));\n    Query queryY = new TermQuery(new Term (\"contents\", \"y\"));\n    \n    sort.setSort(new SortField(\"US\", SortField.STRING));\n    assertMatches(searcher, queryY, sort, usResult);\n\n    sort.setSort(new SortField(\"France\", SortField.STRING));\n    assertMatches(searcher, queryX, sort, \"EACGI\");\n\n    sort.setSort(new SortField(\"Sweden\", SortField.STRING));\n    assertMatches(searcher, queryY, sort, \"BJDFH\");\n\n    sort.setSort(new SortField(\"Denmark\", SortField.STRING));\n    assertMatches(searcher, queryY, sort, \"BJDHF\");\n  }\n\n","sourceOld":"  // Test using various international locales with accented characters (which\n  // sort differently depending on locale)\n  //\n  // Copied (and slightly modified) from \n  // org.apache.lucene.search.TestSort.testInternationalSort()\n  //  \n  public void testCollationKeySort(Analyzer usAnalyzer,\n                                   Analyzer franceAnalyzer,\n                                   Analyzer swedenAnalyzer,\n                                   Analyzer denmarkAnalyzer,\n                                   String usResult) throws Exception {\n    RAMDirectory indexStore = new RAMDirectory();\n    PerFieldAnalyzerWrapper analyzer\n      = new PerFieldAnalyzerWrapper(new WhitespaceAnalyzer(TEST_VERSION_CURRENT));\n    analyzer.addAnalyzer(\"US\", usAnalyzer);\n    analyzer.addAnalyzer(\"France\", franceAnalyzer);\n    analyzer.addAnalyzer(\"Sweden\", swedenAnalyzer);\n    analyzer.addAnalyzer(\"Denmark\", denmarkAnalyzer);\n    IndexWriter writer = new IndexWriter(indexStore, new IndexWriterConfig(TEST_VERSION_CURRENT).setAnalyzer(analyzer));\n\n    // document data:\n    // the tracer field is used to determine which document was hit\n    String[][] sortData = new String[][] {\n      // tracer contents US                 France             Sweden (sv_SE)     Denmark (da_DK)\n      {  \"A\",   \"x\",     \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\"      },\n      {  \"B\",   \"y\",     \"HAT\",             \"HAT\",             \"HAT\",             \"HAT\"             },\n      {  \"C\",   \"x\",     \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\" },\n      {  \"D\",   \"y\",     \"HUT\",             \"HUT\",             \"HUT\",             \"HUT\"             },\n      {  \"E\",   \"x\",     \"peach\",           \"peach\",           \"peach\",           \"peach\"           },\n      {  \"F\",   \"y\",     \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\"        },\n      {  \"G\",   \"x\",     \"sin\",             \"sin\",             \"sin\",             \"sin\"             },\n      {  \"H\",   \"y\",     \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\"        },\n      {  \"I\",   \"x\",     \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\"        },\n      {  \"J\",   \"y\",     \"HOT\",             \"HOT\",             \"HOT\",             \"HOT\"             },\n    };\n\n    for (int i = 0 ; i < sortData.length ; ++i) {\n      Document doc = new Document();\n      doc.add(new Field(\"tracer\", sortData[i][0], \n                        Field.Store.YES, Field.Index.NO));\n      doc.add(new Field(\"contents\", sortData[i][1], \n                        Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][2] != null) \n        doc.add(new Field(\"US\", sortData[i][2], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][3] != null) \n        doc.add(new Field(\"France\", sortData[i][3], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][4] != null)\n        doc.add(new Field(\"Sweden\", sortData[i][4], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][5] != null) \n        doc.add(new Field(\"Denmark\", sortData[i][5], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      writer.addDocument(doc);\n    }\n    writer.optimize();\n    writer.close();\n    Searcher searcher = new IndexSearcher(indexStore, true);\n\n    Sort sort = new Sort();\n    Query queryX = new TermQuery(new Term (\"contents\", \"x\"));\n    Query queryY = new TermQuery(new Term (\"contents\", \"y\"));\n    \n    sort.setSort(new SortField(\"US\", SortField.STRING));\n    assertMatches(searcher, queryY, sort, usResult);\n\n    sort.setSort(new SortField(\"France\", SortField.STRING));\n    assertMatches(searcher, queryX, sort, \"EACGI\");\n\n    sort.setSort(new SortField(\"Sweden\", SortField.STRING));\n    assertMatches(searcher, queryY, sort, \"BJDFH\");\n\n    sort.setSort(new SortField(\"Denmark\", SortField.STRING));\n    assertMatches(searcher, queryY, sort, \"BJDHF\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8","date":1268494368,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/collation/CollationTestBase#testCollationKeySort(Analyzer,Analyzer,Analyzer,Analyzer,String).mjava","pathOld":"src/test/org/apache/lucene/collation/CollationTestBase#testCollationKeySort(Analyzer,Analyzer,Analyzer,Analyzer,String).mjava","sourceNew":"  // Test using various international locales with accented characters (which\n  // sort differently depending on locale)\n  //\n  // Copied (and slightly modified) from \n  // org.apache.lucene.search.TestSort.testInternationalSort()\n  //  \n  public void testCollationKeySort(Analyzer usAnalyzer,\n                                   Analyzer franceAnalyzer,\n                                   Analyzer swedenAnalyzer,\n                                   Analyzer denmarkAnalyzer,\n                                   String usResult) throws Exception {\n    RAMDirectory indexStore = new RAMDirectory();\n    PerFieldAnalyzerWrapper analyzer\n      = new PerFieldAnalyzerWrapper(new WhitespaceAnalyzer(TEST_VERSION_CURRENT));\n    analyzer.addAnalyzer(\"US\", usAnalyzer);\n    analyzer.addAnalyzer(\"France\", franceAnalyzer);\n    analyzer.addAnalyzer(\"Sweden\", swedenAnalyzer);\n    analyzer.addAnalyzer(\"Denmark\", denmarkAnalyzer);\n    IndexWriter writer = new IndexWriter(indexStore, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, analyzer));\n\n    // document data:\n    // the tracer field is used to determine which document was hit\n    String[][] sortData = new String[][] {\n      // tracer contents US                 France             Sweden (sv_SE)     Denmark (da_DK)\n      {  \"A\",   \"x\",     \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\"      },\n      {  \"B\",   \"y\",     \"HAT\",             \"HAT\",             \"HAT\",             \"HAT\"             },\n      {  \"C\",   \"x\",     \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\" },\n      {  \"D\",   \"y\",     \"HUT\",             \"HUT\",             \"HUT\",             \"HUT\"             },\n      {  \"E\",   \"x\",     \"peach\",           \"peach\",           \"peach\",           \"peach\"           },\n      {  \"F\",   \"y\",     \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\"        },\n      {  \"G\",   \"x\",     \"sin\",             \"sin\",             \"sin\",             \"sin\"             },\n      {  \"H\",   \"y\",     \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\"        },\n      {  \"I\",   \"x\",     \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\"        },\n      {  \"J\",   \"y\",     \"HOT\",             \"HOT\",             \"HOT\",             \"HOT\"             },\n    };\n\n    for (int i = 0 ; i < sortData.length ; ++i) {\n      Document doc = new Document();\n      doc.add(new Field(\"tracer\", sortData[i][0], \n                        Field.Store.YES, Field.Index.NO));\n      doc.add(new Field(\"contents\", sortData[i][1], \n                        Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][2] != null) \n        doc.add(new Field(\"US\", sortData[i][2], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][3] != null) \n        doc.add(new Field(\"France\", sortData[i][3], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][4] != null)\n        doc.add(new Field(\"Sweden\", sortData[i][4], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][5] != null) \n        doc.add(new Field(\"Denmark\", sortData[i][5], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      writer.addDocument(doc);\n    }\n    writer.optimize();\n    writer.close();\n    Searcher searcher = new IndexSearcher(indexStore, true);\n\n    Sort sort = new Sort();\n    Query queryX = new TermQuery(new Term (\"contents\", \"x\"));\n    Query queryY = new TermQuery(new Term (\"contents\", \"y\"));\n    \n    sort.setSort(new SortField(\"US\", SortField.STRING));\n    assertMatches(searcher, queryY, sort, usResult);\n\n    sort.setSort(new SortField(\"France\", SortField.STRING));\n    assertMatches(searcher, queryX, sort, \"EACGI\");\n\n    sort.setSort(new SortField(\"Sweden\", SortField.STRING));\n    assertMatches(searcher, queryY, sort, \"BJDFH\");\n\n    sort.setSort(new SortField(\"Denmark\", SortField.STRING));\n    assertMatches(searcher, queryY, sort, \"BJDHF\");\n  }\n\n","sourceOld":"  // Test using various international locales with accented characters (which\n  // sort differently depending on locale)\n  //\n  // Copied (and slightly modified) from \n  // org.apache.lucene.search.TestSort.testInternationalSort()\n  //  \n  public void testCollationKeySort(Analyzer usAnalyzer,\n                                   Analyzer franceAnalyzer,\n                                   Analyzer swedenAnalyzer,\n                                   Analyzer denmarkAnalyzer,\n                                   String usResult) throws Exception {\n    RAMDirectory indexStore = new RAMDirectory();\n    PerFieldAnalyzerWrapper analyzer\n      = new PerFieldAnalyzerWrapper(new WhitespaceAnalyzer(TEST_VERSION_CURRENT));\n    analyzer.addAnalyzer(\"US\", usAnalyzer);\n    analyzer.addAnalyzer(\"France\", franceAnalyzer);\n    analyzer.addAnalyzer(\"Sweden\", swedenAnalyzer);\n    analyzer.addAnalyzer(\"Denmark\", denmarkAnalyzer);\n    IndexWriter writer = new IndexWriter \n      (indexStore, analyzer, true, IndexWriter.MaxFieldLength.LIMITED);\n\n    // document data:\n    // the tracer field is used to determine which document was hit\n    String[][] sortData = new String[][] {\n      // tracer contents US                 France             Sweden (sv_SE)     Denmark (da_DK)\n      {  \"A\",   \"x\",     \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\"      },\n      {  \"B\",   \"y\",     \"HAT\",             \"HAT\",             \"HAT\",             \"HAT\"             },\n      {  \"C\",   \"x\",     \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\" },\n      {  \"D\",   \"y\",     \"HUT\",             \"HUT\",             \"HUT\",             \"HUT\"             },\n      {  \"E\",   \"x\",     \"peach\",           \"peach\",           \"peach\",           \"peach\"           },\n      {  \"F\",   \"y\",     \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\"        },\n      {  \"G\",   \"x\",     \"sin\",             \"sin\",             \"sin\",             \"sin\"             },\n      {  \"H\",   \"y\",     \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\"        },\n      {  \"I\",   \"x\",     \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\"        },\n      {  \"J\",   \"y\",     \"HOT\",             \"HOT\",             \"HOT\",             \"HOT\"             },\n    };\n\n    for (int i = 0 ; i < sortData.length ; ++i) {\n      Document doc = new Document();\n      doc.add(new Field(\"tracer\", sortData[i][0], \n                        Field.Store.YES, Field.Index.NO));\n      doc.add(new Field(\"contents\", sortData[i][1], \n                        Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][2] != null) \n        doc.add(new Field(\"US\", sortData[i][2], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][3] != null) \n        doc.add(new Field(\"France\", sortData[i][3], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][4] != null)\n        doc.add(new Field(\"Sweden\", sortData[i][4], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][5] != null) \n        doc.add(new Field(\"Denmark\", sortData[i][5], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      writer.addDocument(doc);\n    }\n    writer.optimize();\n    writer.close();\n    Searcher searcher = new IndexSearcher(indexStore, true);\n\n    Sort sort = new Sort();\n    Query queryX = new TermQuery(new Term (\"contents\", \"x\"));\n    Query queryY = new TermQuery(new Term (\"contents\", \"y\"));\n    \n    sort.setSort(new SortField(\"US\", SortField.STRING));\n    assertMatches(searcher, queryY, sort, usResult);\n\n    sort.setSort(new SortField(\"France\", SortField.STRING));\n    assertMatches(searcher, queryX, sort, \"EACGI\");\n\n    sort.setSort(new SortField(\"Sweden\", SortField.STRING));\n    assertMatches(searcher, queryY, sort, \"BJDFH\");\n\n    sort.setSort(new SortField(\"Denmark\", SortField.STRING));\n    assertMatches(searcher, queryY, sort, \"BJDHF\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/collation/CollationTestBase#testCollationKeySort(Analyzer,Analyzer,Analyzer,Analyzer,String).mjava","pathOld":"src/test/org/apache/lucene/collation/CollationTestBase#testCollationKeySort(Analyzer,Analyzer,Analyzer,Analyzer,String).mjava","sourceNew":"  // Test using various international locales with accented characters (which\n  // sort differently depending on locale)\n  //\n  // Copied (and slightly modified) from \n  // org.apache.lucene.search.TestSort.testInternationalSort()\n  //  \n  public void testCollationKeySort(Analyzer usAnalyzer,\n                                   Analyzer franceAnalyzer,\n                                   Analyzer swedenAnalyzer,\n                                   Analyzer denmarkAnalyzer,\n                                   String usResult) throws Exception {\n    RAMDirectory indexStore = new RAMDirectory();\n    PerFieldAnalyzerWrapper analyzer\n      = new PerFieldAnalyzerWrapper(new WhitespaceAnalyzer(TEST_VERSION_CURRENT));\n    analyzer.addAnalyzer(\"US\", usAnalyzer);\n    analyzer.addAnalyzer(\"France\", franceAnalyzer);\n    analyzer.addAnalyzer(\"Sweden\", swedenAnalyzer);\n    analyzer.addAnalyzer(\"Denmark\", denmarkAnalyzer);\n    IndexWriter writer = new IndexWriter(indexStore, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, analyzer));\n\n    // document data:\n    // the tracer field is used to determine which document was hit\n    String[][] sortData = new String[][] {\n      // tracer contents US                 France             Sweden (sv_SE)     Denmark (da_DK)\n      {  \"A\",   \"x\",     \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\"      },\n      {  \"B\",   \"y\",     \"HAT\",             \"HAT\",             \"HAT\",             \"HAT\"             },\n      {  \"C\",   \"x\",     \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\" },\n      {  \"D\",   \"y\",     \"HUT\",             \"HUT\",             \"HUT\",             \"HUT\"             },\n      {  \"E\",   \"x\",     \"peach\",           \"peach\",           \"peach\",           \"peach\"           },\n      {  \"F\",   \"y\",     \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\"        },\n      {  \"G\",   \"x\",     \"sin\",             \"sin\",             \"sin\",             \"sin\"             },\n      {  \"H\",   \"y\",     \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\"        },\n      {  \"I\",   \"x\",     \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\"        },\n      {  \"J\",   \"y\",     \"HOT\",             \"HOT\",             \"HOT\",             \"HOT\"             },\n    };\n\n    for (int i = 0 ; i < sortData.length ; ++i) {\n      Document doc = new Document();\n      doc.add(new Field(\"tracer\", sortData[i][0], \n                        Field.Store.YES, Field.Index.NO));\n      doc.add(new Field(\"contents\", sortData[i][1], \n                        Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][2] != null) \n        doc.add(new Field(\"US\", sortData[i][2], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][3] != null) \n        doc.add(new Field(\"France\", sortData[i][3], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][4] != null)\n        doc.add(new Field(\"Sweden\", sortData[i][4], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][5] != null) \n        doc.add(new Field(\"Denmark\", sortData[i][5], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      writer.addDocument(doc);\n    }\n    writer.optimize();\n    writer.close();\n    Searcher searcher = new IndexSearcher(indexStore, true);\n\n    Sort sort = new Sort();\n    Query queryX = new TermQuery(new Term (\"contents\", \"x\"));\n    Query queryY = new TermQuery(new Term (\"contents\", \"y\"));\n    \n    sort.setSort(new SortField(\"US\", SortField.STRING));\n    assertMatches(searcher, queryY, sort, usResult);\n\n    sort.setSort(new SortField(\"France\", SortField.STRING));\n    assertMatches(searcher, queryX, sort, \"EACGI\");\n\n    sort.setSort(new SortField(\"Sweden\", SortField.STRING));\n    assertMatches(searcher, queryY, sort, \"BJDFH\");\n\n    sort.setSort(new SortField(\"Denmark\", SortField.STRING));\n    assertMatches(searcher, queryY, sort, \"BJDHF\");\n  }\n\n","sourceOld":"  // Test using various international locales with accented characters (which\n  // sort differently depending on locale)\n  //\n  // Copied (and slightly modified) from \n  // org.apache.lucene.search.TestSort.testInternationalSort()\n  //  \n  public void testCollationKeySort(Analyzer usAnalyzer,\n                                   Analyzer franceAnalyzer,\n                                   Analyzer swedenAnalyzer,\n                                   Analyzer denmarkAnalyzer,\n                                   String usResult) throws Exception {\n    RAMDirectory indexStore = new RAMDirectory();\n    PerFieldAnalyzerWrapper analyzer\n      = new PerFieldAnalyzerWrapper(new WhitespaceAnalyzer(TEST_VERSION_CURRENT));\n    analyzer.addAnalyzer(\"US\", usAnalyzer);\n    analyzer.addAnalyzer(\"France\", franceAnalyzer);\n    analyzer.addAnalyzer(\"Sweden\", swedenAnalyzer);\n    analyzer.addAnalyzer(\"Denmark\", denmarkAnalyzer);\n    IndexWriter writer = new IndexWriter(indexStore, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, analyzer));\n\n    // document data:\n    // the tracer field is used to determine which document was hit\n    String[][] sortData = new String[][] {\n      // tracer contents US                 France             Sweden (sv_SE)     Denmark (da_DK)\n      {  \"A\",   \"x\",     \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\"      },\n      {  \"B\",   \"y\",     \"HAT\",             \"HAT\",             \"HAT\",             \"HAT\"             },\n      {  \"C\",   \"x\",     \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\" },\n      {  \"D\",   \"y\",     \"HUT\",             \"HUT\",             \"HUT\",             \"HUT\"             },\n      {  \"E\",   \"x\",     \"peach\",           \"peach\",           \"peach\",           \"peach\"           },\n      {  \"F\",   \"y\",     \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\"        },\n      {  \"G\",   \"x\",     \"sin\",             \"sin\",             \"sin\",             \"sin\"             },\n      {  \"H\",   \"y\",     \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\"        },\n      {  \"I\",   \"x\",     \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\"        },\n      {  \"J\",   \"y\",     \"HOT\",             \"HOT\",             \"HOT\",             \"HOT\"             },\n    };\n\n    for (int i = 0 ; i < sortData.length ; ++i) {\n      Document doc = new Document();\n      doc.add(new Field(\"tracer\", sortData[i][0], \n                        Field.Store.YES, Field.Index.NO));\n      doc.add(new Field(\"contents\", sortData[i][1], \n                        Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][2] != null) \n        doc.add(new Field(\"US\", sortData[i][2], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][3] != null) \n        doc.add(new Field(\"France\", sortData[i][3], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][4] != null)\n        doc.add(new Field(\"Sweden\", sortData[i][4], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      if (sortData[i][5] != null) \n        doc.add(new Field(\"Denmark\", sortData[i][5], \n                          Field.Store.NO, Field.Index.ANALYZED));\n      writer.addDocument(doc);\n    }\n    writer.optimize();\n    writer.close();\n    Searcher searcher = new IndexSearcher(indexStore, true);\n\n    Sort sort = new Sort();\n    Query queryX = new TermQuery(new Term (\"contents\", \"x\"));\n    Query queryY = new TermQuery(new Term (\"contents\", \"y\"));\n    \n    sort.setSort(new SortField(\"US\", SortField.STRING));\n    assertMatches(searcher, queryY, sort, usResult);\n\n    sort.setSort(new SortField(\"France\", SortField.STRING));\n    assertMatches(searcher, queryX, sort, \"EACGI\");\n\n    sort.setSort(new SortField(\"Sweden\", SortField.STRING));\n    assertMatches(searcher, queryY, sort, \"BJDFH\");\n\n    sort.setSort(new SortField(\"Denmark\", SortField.STRING));\n    assertMatches(searcher, queryY, sort, \"BJDHF\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8":["e52fea2c4081a1e552b98506691990be59503168"],"4275990669802f4c50b4de5d3252a0987854ad68":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"fe0932c1d340f83fb0a611e5829b3046a1cc1152":["4275990669802f4c50b4de5d3252a0987854ad68"],"55f083e91bb056b57de136da1dfc3b9b6ecc4ef6":["fe0932c1d340f83fb0a611e5829b3046a1cc1152"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"1cedb00d2dd44640194401179358a2e3ba6051bf":["55f083e91bb056b57de136da1dfc3b9b6ecc4ef6"],"e52fea2c4081a1e552b98506691990be59503168":["1cedb00d2dd44640194401179358a2e3ba6051bf"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8"]},"commit2Childs":{"84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"4275990669802f4c50b4de5d3252a0987854ad68":["fe0932c1d340f83fb0a611e5829b3046a1cc1152"],"fe0932c1d340f83fb0a611e5829b3046a1cc1152":["55f083e91bb056b57de136da1dfc3b9b6ecc4ef6"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["4275990669802f4c50b4de5d3252a0987854ad68"],"55f083e91bb056b57de136da1dfc3b9b6ecc4ef6":["1cedb00d2dd44640194401179358a2e3ba6051bf"],"1cedb00d2dd44640194401179358a2e3ba6051bf":["e52fea2c4081a1e552b98506691990be59503168"],"e52fea2c4081a1e552b98506691990be59503168":["84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}