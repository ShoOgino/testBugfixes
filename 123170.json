{"path":"lucene/src/test-framework/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[],Integer).mjava","commits":[{"id":"f0b9dc55f42953d6740cddbc92cb0d19fe1ba0ce","date":1297021734,"type":1,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/src/test-framework/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[],Integer).mjava","pathOld":"lucene/src/test/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[],Integer).mjava","sourceNew":"  public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[], Integer finalOffset) throws IOException {\n    assertNotNull(output);\n    CheckClearAttributesAttribute checkClearAtt = ts.addAttribute(CheckClearAttributesAttribute.class);\n    \n    assertTrue(\"has no CharTermAttribute\", ts.hasAttribute(CharTermAttribute.class));\n    CharTermAttribute termAtt = ts.getAttribute(CharTermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null || finalOffset != null) {\n      assertTrue(\"has no OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has no TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has no PositionIncrementAttribute\", ts.hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = ts.getAttribute(PositionIncrementAttribute.class);\n    }\n    \n    ts.reset();\n    for (int i = 0; i < output.length; i++) {\n      // extra safety to enforce, that the state is not preserved and also assign bogus values\n      ts.clearAttributes();\n      termAtt.setEmpty().append(\"bogusTerm\");\n      if (offsetAtt != null) offsetAtt.setOffset(14584724,24683243);\n      if (typeAtt != null) typeAtt.setType(\"bogusType\");\n      if (posIncrAtt != null) posIncrAtt.setPositionIncrement(45987657);\n      \n      checkClearAtt.getAndResetClearCalled(); // reset it, because we called clearAttribute() before\n      assertTrue(\"token \"+i+\" does not exist\", ts.incrementToken());\n      assertTrue(\"clearAttributes() was not called correctly in TokenStream chain\", checkClearAtt.getAndResetClearCalled());\n      \n      assertEquals(\"term \"+i, output[i], termAtt.toString());\n      if (startOffsets != null)\n        assertEquals(\"startOffset \"+i, startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null)\n        assertEquals(\"endOffset \"+i, endOffsets[i], offsetAtt.endOffset());\n      if (types != null)\n        assertEquals(\"type \"+i, types[i], typeAtt.type());\n      if (posIncrements != null)\n        assertEquals(\"posIncrement \"+i, posIncrements[i], posIncrAtt.getPositionIncrement());\n    }\n    assertFalse(\"end of stream\", ts.incrementToken());\n    ts.end();\n    if (finalOffset != null)\n      assertEquals(\"finalOffset \", finalOffset.intValue(), offsetAtt.endOffset());\n    ts.close();\n  }\n\n","sourceOld":"  public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[], Integer finalOffset) throws IOException {\n    assertNotNull(output);\n    CheckClearAttributesAttribute checkClearAtt = ts.addAttribute(CheckClearAttributesAttribute.class);\n    \n    assertTrue(\"has no CharTermAttribute\", ts.hasAttribute(CharTermAttribute.class));\n    CharTermAttribute termAtt = ts.getAttribute(CharTermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null || finalOffset != null) {\n      assertTrue(\"has no OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has no TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has no PositionIncrementAttribute\", ts.hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = ts.getAttribute(PositionIncrementAttribute.class);\n    }\n    \n    ts.reset();\n    for (int i = 0; i < output.length; i++) {\n      // extra safety to enforce, that the state is not preserved and also assign bogus values\n      ts.clearAttributes();\n      termAtt.setEmpty().append(\"bogusTerm\");\n      if (offsetAtt != null) offsetAtt.setOffset(14584724,24683243);\n      if (typeAtt != null) typeAtt.setType(\"bogusType\");\n      if (posIncrAtt != null) posIncrAtt.setPositionIncrement(45987657);\n      \n      checkClearAtt.getAndResetClearCalled(); // reset it, because we called clearAttribute() before\n      assertTrue(\"token \"+i+\" does not exist\", ts.incrementToken());\n      assertTrue(\"clearAttributes() was not called correctly in TokenStream chain\", checkClearAtt.getAndResetClearCalled());\n      \n      assertEquals(\"term \"+i, output[i], termAtt.toString());\n      if (startOffsets != null)\n        assertEquals(\"startOffset \"+i, startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null)\n        assertEquals(\"endOffset \"+i, endOffsets[i], offsetAtt.endOffset());\n      if (types != null)\n        assertEquals(\"type \"+i, types[i], typeAtt.type());\n      if (posIncrements != null)\n        assertEquals(\"posIncrement \"+i, posIncrements[i], posIncrAtt.getPositionIncrement());\n    }\n    assertFalse(\"end of stream\", ts.incrementToken());\n    ts.end();\n    if (finalOffset != null)\n      assertEquals(\"finalOffset \", finalOffset.intValue(), offsetAtt.endOffset());\n    ts.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":1,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test-framework/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[],Integer).mjava","pathOld":"lucene/src/test/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[],Integer).mjava","sourceNew":"  public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[], Integer finalOffset) throws IOException {\n    assertNotNull(output);\n    CheckClearAttributesAttribute checkClearAtt = ts.addAttribute(CheckClearAttributesAttribute.class);\n    \n    assertTrue(\"has no CharTermAttribute\", ts.hasAttribute(CharTermAttribute.class));\n    CharTermAttribute termAtt = ts.getAttribute(CharTermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null || finalOffset != null) {\n      assertTrue(\"has no OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has no TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has no PositionIncrementAttribute\", ts.hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = ts.getAttribute(PositionIncrementAttribute.class);\n    }\n    \n    ts.reset();\n    for (int i = 0; i < output.length; i++) {\n      // extra safety to enforce, that the state is not preserved and also assign bogus values\n      ts.clearAttributes();\n      termAtt.setEmpty().append(\"bogusTerm\");\n      if (offsetAtt != null) offsetAtt.setOffset(14584724,24683243);\n      if (typeAtt != null) typeAtt.setType(\"bogusType\");\n      if (posIncrAtt != null) posIncrAtt.setPositionIncrement(45987657);\n      \n      checkClearAtt.getAndResetClearCalled(); // reset it, because we called clearAttribute() before\n      assertTrue(\"token \"+i+\" does not exist\", ts.incrementToken());\n      assertTrue(\"clearAttributes() was not called correctly in TokenStream chain\", checkClearAtt.getAndResetClearCalled());\n      \n      assertEquals(\"term \"+i, output[i], termAtt.toString());\n      if (startOffsets != null)\n        assertEquals(\"startOffset \"+i, startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null)\n        assertEquals(\"endOffset \"+i, endOffsets[i], offsetAtt.endOffset());\n      if (types != null)\n        assertEquals(\"type \"+i, types[i], typeAtt.type());\n      if (posIncrements != null)\n        assertEquals(\"posIncrement \"+i, posIncrements[i], posIncrAtt.getPositionIncrement());\n    }\n    assertFalse(\"end of stream\", ts.incrementToken());\n    ts.end();\n    if (finalOffset != null)\n      assertEquals(\"finalOffset \", finalOffset.intValue(), offsetAtt.endOffset());\n    ts.close();\n  }\n\n","sourceOld":"  public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[], Integer finalOffset) throws IOException {\n    assertNotNull(output);\n    CheckClearAttributesAttribute checkClearAtt = ts.addAttribute(CheckClearAttributesAttribute.class);\n    \n    assertTrue(\"has no CharTermAttribute\", ts.hasAttribute(CharTermAttribute.class));\n    CharTermAttribute termAtt = ts.getAttribute(CharTermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null || finalOffset != null) {\n      assertTrue(\"has no OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has no TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has no PositionIncrementAttribute\", ts.hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = ts.getAttribute(PositionIncrementAttribute.class);\n    }\n    \n    ts.reset();\n    for (int i = 0; i < output.length; i++) {\n      // extra safety to enforce, that the state is not preserved and also assign bogus values\n      ts.clearAttributes();\n      termAtt.setEmpty().append(\"bogusTerm\");\n      if (offsetAtt != null) offsetAtt.setOffset(14584724,24683243);\n      if (typeAtt != null) typeAtt.setType(\"bogusType\");\n      if (posIncrAtt != null) posIncrAtt.setPositionIncrement(45987657);\n      \n      checkClearAtt.getAndResetClearCalled(); // reset it, because we called clearAttribute() before\n      assertTrue(\"token \"+i+\" does not exist\", ts.incrementToken());\n      assertTrue(\"clearAttributes() was not called correctly in TokenStream chain\", checkClearAtt.getAndResetClearCalled());\n      \n      assertEquals(\"term \"+i, output[i], termAtt.toString());\n      if (startOffsets != null)\n        assertEquals(\"startOffset \"+i, startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null)\n        assertEquals(\"endOffset \"+i, endOffsets[i], offsetAtt.endOffset());\n      if (types != null)\n        assertEquals(\"type \"+i, types[i], typeAtt.type());\n      if (posIncrements != null)\n        assertEquals(\"posIncrement \"+i, posIncrements[i], posIncrAtt.getPositionIncrement());\n    }\n    assertFalse(\"end of stream\", ts.incrementToken());\n    ts.end();\n    if (finalOffset != null)\n      assertEquals(\"finalOffset \", finalOffset.intValue(), offsetAtt.endOffset());\n    ts.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bde51b089eb7f86171eb3406e38a274743f9b7ac","date":1298336439,"type":1,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test-framework/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[],Integer).mjava","pathOld":"lucene/src/test/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[],Integer).mjava","sourceNew":"  public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[], Integer finalOffset) throws IOException {\n    assertNotNull(output);\n    CheckClearAttributesAttribute checkClearAtt = ts.addAttribute(CheckClearAttributesAttribute.class);\n    \n    assertTrue(\"has no CharTermAttribute\", ts.hasAttribute(CharTermAttribute.class));\n    CharTermAttribute termAtt = ts.getAttribute(CharTermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null || finalOffset != null) {\n      assertTrue(\"has no OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has no TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has no PositionIncrementAttribute\", ts.hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = ts.getAttribute(PositionIncrementAttribute.class);\n    }\n    \n    ts.reset();\n    for (int i = 0; i < output.length; i++) {\n      // extra safety to enforce, that the state is not preserved and also assign bogus values\n      ts.clearAttributes();\n      termAtt.setEmpty().append(\"bogusTerm\");\n      if (offsetAtt != null) offsetAtt.setOffset(14584724,24683243);\n      if (typeAtt != null) typeAtt.setType(\"bogusType\");\n      if (posIncrAtt != null) posIncrAtt.setPositionIncrement(45987657);\n      \n      checkClearAtt.getAndResetClearCalled(); // reset it, because we called clearAttribute() before\n      assertTrue(\"token \"+i+\" does not exist\", ts.incrementToken());\n      assertTrue(\"clearAttributes() was not called correctly in TokenStream chain\", checkClearAtt.getAndResetClearCalled());\n      \n      assertEquals(\"term \"+i, output[i], termAtt.toString());\n      if (startOffsets != null)\n        assertEquals(\"startOffset \"+i, startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null)\n        assertEquals(\"endOffset \"+i, endOffsets[i], offsetAtt.endOffset());\n      if (types != null)\n        assertEquals(\"type \"+i, types[i], typeAtt.type());\n      if (posIncrements != null)\n        assertEquals(\"posIncrement \"+i, posIncrements[i], posIncrAtt.getPositionIncrement());\n    }\n    assertFalse(\"end of stream\", ts.incrementToken());\n    ts.end();\n    if (finalOffset != null)\n      assertEquals(\"finalOffset \", finalOffset.intValue(), offsetAtt.endOffset());\n    ts.close();\n  }\n\n","sourceOld":"  public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[], Integer finalOffset) throws IOException {\n    assertNotNull(output);\n    CheckClearAttributesAttribute checkClearAtt = ts.addAttribute(CheckClearAttributesAttribute.class);\n    \n    assertTrue(\"has no CharTermAttribute\", ts.hasAttribute(CharTermAttribute.class));\n    CharTermAttribute termAtt = ts.getAttribute(CharTermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null || finalOffset != null) {\n      assertTrue(\"has no OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has no TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has no PositionIncrementAttribute\", ts.hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = ts.getAttribute(PositionIncrementAttribute.class);\n    }\n    \n    ts.reset();\n    for (int i = 0; i < output.length; i++) {\n      // extra safety to enforce, that the state is not preserved and also assign bogus values\n      ts.clearAttributes();\n      termAtt.setEmpty().append(\"bogusTerm\");\n      if (offsetAtt != null) offsetAtt.setOffset(14584724,24683243);\n      if (typeAtt != null) typeAtt.setType(\"bogusType\");\n      if (posIncrAtt != null) posIncrAtt.setPositionIncrement(45987657);\n      \n      checkClearAtt.getAndResetClearCalled(); // reset it, because we called clearAttribute() before\n      assertTrue(\"token \"+i+\" does not exist\", ts.incrementToken());\n      assertTrue(\"clearAttributes() was not called correctly in TokenStream chain\", checkClearAtt.getAndResetClearCalled());\n      \n      assertEquals(\"term \"+i, output[i], termAtt.toString());\n      if (startOffsets != null)\n        assertEquals(\"startOffset \"+i, startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null)\n        assertEquals(\"endOffset \"+i, endOffsets[i], offsetAtt.endOffset());\n      if (types != null)\n        assertEquals(\"type \"+i, types[i], typeAtt.type());\n      if (posIncrements != null)\n        assertEquals(\"posIncrement \"+i, posIncrements[i], posIncrAtt.getPositionIncrement());\n    }\n    assertFalse(\"end of stream\", ts.incrementToken());\n    ts.end();\n    if (finalOffset != null)\n      assertEquals(\"finalOffset \", finalOffset.intValue(), offsetAtt.endOffset());\n    ts.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"217827c5ead25d2f1e89bdcad7f9f498221d185d","date":1303446587,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test-framework/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[],Integer).mjava","pathOld":"lucene/src/test-framework/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[],Integer).mjava","sourceNew":"  public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[], Integer finalOffset) throws IOException {\n    assertNotNull(output);\n    CheckClearAttributesAttribute checkClearAtt = ts.addAttribute(CheckClearAttributesAttribute.class);\n    \n    assertTrue(\"has no CharTermAttribute\", ts.hasAttribute(CharTermAttribute.class));\n    CharTermAttribute termAtt = ts.getAttribute(CharTermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null || finalOffset != null) {\n      assertTrue(\"has no OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has no TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has no PositionIncrementAttribute\", ts.hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = ts.getAttribute(PositionIncrementAttribute.class);\n    }\n    \n    ts.reset();\n    for (int i = 0; i < output.length; i++) {\n      // extra safety to enforce, that the state is not preserved and also assign bogus values\n      ts.clearAttributes();\n      termAtt.setEmpty().append(\"bogusTerm\");\n      if (offsetAtt != null) offsetAtt.setOffset(14584724,24683243);\n      if (typeAtt != null) typeAtt.setType(\"bogusType\");\n      if (posIncrAtt != null) posIncrAtt.setPositionIncrement(45987657);\n      \n      checkClearAtt.getAndResetClearCalled(); // reset it, because we called clearAttribute() before\n      assertTrue(\"token \"+i+\" does not exist\", ts.incrementToken());\n      assertTrue(\"clearAttributes() was not called correctly in TokenStream chain\", checkClearAtt.getAndResetClearCalled());\n      \n      assertEquals(\"term \"+i, output[i], termAtt.toString());\n      if (startOffsets != null)\n        assertEquals(\"startOffset \"+i, startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null)\n        assertEquals(\"endOffset \"+i, endOffsets[i], offsetAtt.endOffset());\n      if (types != null)\n        assertEquals(\"type \"+i, types[i], typeAtt.type());\n      if (posIncrements != null)\n        assertEquals(\"posIncrement \"+i, posIncrements[i], posIncrAtt.getPositionIncrement());\n      \n      // we can enforce some basic things about a few attributes even if the caller doesn't check:\n      if (offsetAtt != null) {\n        assertTrue(\"startOffset must be >= 0\", offsetAtt.startOffset() >= 0);\n        assertTrue(\"endOffset must be >= 0\", offsetAtt.endOffset() >= 0);\n        assertTrue(\"endOffset must be >= startOffset\", offsetAtt.endOffset() >= offsetAtt.startOffset());\n      }\n      if (posIncrAtt != null) {\n        assertTrue(\"posIncrement must be >= 0\", posIncrAtt.getPositionIncrement() >= 0);\n      }\n    }\n    assertFalse(\"end of stream\", ts.incrementToken());\n    ts.end();\n    if (finalOffset != null)\n      assertEquals(\"finalOffset \", finalOffset.intValue(), offsetAtt.endOffset());\n    if (offsetAtt != null) {\n      assertTrue(\"finalOffset must be >= 0\", offsetAtt.endOffset() >= 0);\n    }\n    ts.close();\n  }\n\n","sourceOld":"  public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[], Integer finalOffset) throws IOException {\n    assertNotNull(output);\n    CheckClearAttributesAttribute checkClearAtt = ts.addAttribute(CheckClearAttributesAttribute.class);\n    \n    assertTrue(\"has no CharTermAttribute\", ts.hasAttribute(CharTermAttribute.class));\n    CharTermAttribute termAtt = ts.getAttribute(CharTermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null || finalOffset != null) {\n      assertTrue(\"has no OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has no TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has no PositionIncrementAttribute\", ts.hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = ts.getAttribute(PositionIncrementAttribute.class);\n    }\n    \n    ts.reset();\n    for (int i = 0; i < output.length; i++) {\n      // extra safety to enforce, that the state is not preserved and also assign bogus values\n      ts.clearAttributes();\n      termAtt.setEmpty().append(\"bogusTerm\");\n      if (offsetAtt != null) offsetAtt.setOffset(14584724,24683243);\n      if (typeAtt != null) typeAtt.setType(\"bogusType\");\n      if (posIncrAtt != null) posIncrAtt.setPositionIncrement(45987657);\n      \n      checkClearAtt.getAndResetClearCalled(); // reset it, because we called clearAttribute() before\n      assertTrue(\"token \"+i+\" does not exist\", ts.incrementToken());\n      assertTrue(\"clearAttributes() was not called correctly in TokenStream chain\", checkClearAtt.getAndResetClearCalled());\n      \n      assertEquals(\"term \"+i, output[i], termAtt.toString());\n      if (startOffsets != null)\n        assertEquals(\"startOffset \"+i, startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null)\n        assertEquals(\"endOffset \"+i, endOffsets[i], offsetAtt.endOffset());\n      if (types != null)\n        assertEquals(\"type \"+i, types[i], typeAtt.type());\n      if (posIncrements != null)\n        assertEquals(\"posIncrement \"+i, posIncrements[i], posIncrAtt.getPositionIncrement());\n    }\n    assertFalse(\"end of stream\", ts.incrementToken());\n    ts.end();\n    if (finalOffset != null)\n      assertEquals(\"finalOffset \", finalOffset.intValue(), offsetAtt.endOffset());\n    ts.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d493718201f0d0c54c773fb323d87bbd2fbffe41","date":1303546048,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test-framework/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[],Integer).mjava","pathOld":"lucene/src/test-framework/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[],Integer).mjava","sourceNew":"  public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[], Integer finalOffset) throws IOException {\n    assertNotNull(output);\n    CheckClearAttributesAttribute checkClearAtt = ts.addAttribute(CheckClearAttributesAttribute.class);\n    \n    assertTrue(\"has no CharTermAttribute\", ts.hasAttribute(CharTermAttribute.class));\n    CharTermAttribute termAtt = ts.getAttribute(CharTermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null || finalOffset != null) {\n      assertTrue(\"has no OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has no TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has no PositionIncrementAttribute\", ts.hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = ts.getAttribute(PositionIncrementAttribute.class);\n    }\n    \n    ts.reset();\n    for (int i = 0; i < output.length; i++) {\n      // extra safety to enforce, that the state is not preserved and also assign bogus values\n      ts.clearAttributes();\n      termAtt.setEmpty().append(\"bogusTerm\");\n      if (offsetAtt != null) offsetAtt.setOffset(14584724,24683243);\n      if (typeAtt != null) typeAtt.setType(\"bogusType\");\n      if (posIncrAtt != null) posIncrAtt.setPositionIncrement(45987657);\n      \n      checkClearAtt.getAndResetClearCalled(); // reset it, because we called clearAttribute() before\n      assertTrue(\"token \"+i+\" does not exist\", ts.incrementToken());\n      assertTrue(\"clearAttributes() was not called correctly in TokenStream chain\", checkClearAtt.getAndResetClearCalled());\n      \n      assertEquals(\"term \"+i, output[i], termAtt.toString());\n      if (startOffsets != null)\n        assertEquals(\"startOffset \"+i, startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null)\n        assertEquals(\"endOffset \"+i, endOffsets[i], offsetAtt.endOffset());\n      if (types != null)\n        assertEquals(\"type \"+i, types[i], typeAtt.type());\n      if (posIncrements != null)\n        assertEquals(\"posIncrement \"+i, posIncrements[i], posIncrAtt.getPositionIncrement());\n      \n      // we can enforce some basic things about a few attributes even if the caller doesn't check:\n      if (offsetAtt != null) {\n        assertTrue(\"startOffset must be >= 0\", offsetAtt.startOffset() >= 0);\n        assertTrue(\"endOffset must be >= 0\", offsetAtt.endOffset() >= 0);\n        assertTrue(\"endOffset must be >= startOffset\", offsetAtt.endOffset() >= offsetAtt.startOffset());\n      }\n      if (posIncrAtt != null) {\n        assertTrue(\"posIncrement must be >= 0\", posIncrAtt.getPositionIncrement() >= 0);\n      }\n    }\n    assertFalse(\"end of stream\", ts.incrementToken());\n    ts.end();\n    if (finalOffset != null)\n      assertEquals(\"finalOffset \", finalOffset.intValue(), offsetAtt.endOffset());\n    if (offsetAtt != null) {\n      assertTrue(\"finalOffset must be >= 0\", offsetAtt.endOffset() >= 0);\n    }\n    ts.close();\n  }\n\n","sourceOld":"  public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[], Integer finalOffset) throws IOException {\n    assertNotNull(output);\n    CheckClearAttributesAttribute checkClearAtt = ts.addAttribute(CheckClearAttributesAttribute.class);\n    \n    assertTrue(\"has no CharTermAttribute\", ts.hasAttribute(CharTermAttribute.class));\n    CharTermAttribute termAtt = ts.getAttribute(CharTermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null || finalOffset != null) {\n      assertTrue(\"has no OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has no TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has no PositionIncrementAttribute\", ts.hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = ts.getAttribute(PositionIncrementAttribute.class);\n    }\n    \n    ts.reset();\n    for (int i = 0; i < output.length; i++) {\n      // extra safety to enforce, that the state is not preserved and also assign bogus values\n      ts.clearAttributes();\n      termAtt.setEmpty().append(\"bogusTerm\");\n      if (offsetAtt != null) offsetAtt.setOffset(14584724,24683243);\n      if (typeAtt != null) typeAtt.setType(\"bogusType\");\n      if (posIncrAtt != null) posIncrAtt.setPositionIncrement(45987657);\n      \n      checkClearAtt.getAndResetClearCalled(); // reset it, because we called clearAttribute() before\n      assertTrue(\"token \"+i+\" does not exist\", ts.incrementToken());\n      assertTrue(\"clearAttributes() was not called correctly in TokenStream chain\", checkClearAtt.getAndResetClearCalled());\n      \n      assertEquals(\"term \"+i, output[i], termAtt.toString());\n      if (startOffsets != null)\n        assertEquals(\"startOffset \"+i, startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null)\n        assertEquals(\"endOffset \"+i, endOffsets[i], offsetAtt.endOffset());\n      if (types != null)\n        assertEquals(\"type \"+i, types[i], typeAtt.type());\n      if (posIncrements != null)\n        assertEquals(\"posIncrement \"+i, posIncrements[i], posIncrAtt.getPositionIncrement());\n    }\n    assertFalse(\"end of stream\", ts.incrementToken());\n    ts.end();\n    if (finalOffset != null)\n      assertEquals(\"finalOffset \", finalOffset.intValue(), offsetAtt.endOffset());\n    ts.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test-framework/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[],Integer).mjava","pathOld":"lucene/src/test-framework/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[],Integer).mjava","sourceNew":"  public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[], Integer finalOffset) throws IOException {\n    assertNotNull(output);\n    CheckClearAttributesAttribute checkClearAtt = ts.addAttribute(CheckClearAttributesAttribute.class);\n    \n    assertTrue(\"has no CharTermAttribute\", ts.hasAttribute(CharTermAttribute.class));\n    CharTermAttribute termAtt = ts.getAttribute(CharTermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null || finalOffset != null) {\n      assertTrue(\"has no OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has no TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has no PositionIncrementAttribute\", ts.hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = ts.getAttribute(PositionIncrementAttribute.class);\n    }\n    \n    ts.reset();\n    for (int i = 0; i < output.length; i++) {\n      // extra safety to enforce, that the state is not preserved and also assign bogus values\n      ts.clearAttributes();\n      termAtt.setEmpty().append(\"bogusTerm\");\n      if (offsetAtt != null) offsetAtt.setOffset(14584724,24683243);\n      if (typeAtt != null) typeAtt.setType(\"bogusType\");\n      if (posIncrAtt != null) posIncrAtt.setPositionIncrement(45987657);\n      \n      checkClearAtt.getAndResetClearCalled(); // reset it, because we called clearAttribute() before\n      assertTrue(\"token \"+i+\" does not exist\", ts.incrementToken());\n      assertTrue(\"clearAttributes() was not called correctly in TokenStream chain\", checkClearAtt.getAndResetClearCalled());\n      \n      assertEquals(\"term \"+i, output[i], termAtt.toString());\n      if (startOffsets != null)\n        assertEquals(\"startOffset \"+i, startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null)\n        assertEquals(\"endOffset \"+i, endOffsets[i], offsetAtt.endOffset());\n      if (types != null)\n        assertEquals(\"type \"+i, types[i], typeAtt.type());\n      if (posIncrements != null)\n        assertEquals(\"posIncrement \"+i, posIncrements[i], posIncrAtt.getPositionIncrement());\n      \n      // we can enforce some basic things about a few attributes even if the caller doesn't check:\n      if (offsetAtt != null) {\n        assertTrue(\"startOffset must be >= 0\", offsetAtt.startOffset() >= 0);\n        assertTrue(\"endOffset must be >= 0\", offsetAtt.endOffset() >= 0);\n        assertTrue(\"endOffset must be >= startOffset\", offsetAtt.endOffset() >= offsetAtt.startOffset());\n      }\n      if (posIncrAtt != null) {\n        assertTrue(\"posIncrement must be >= 0\", posIncrAtt.getPositionIncrement() >= 0);\n      }\n    }\n    assertFalse(\"end of stream\", ts.incrementToken());\n    ts.end();\n    if (finalOffset != null)\n      assertEquals(\"finalOffset \", finalOffset.intValue(), offsetAtt.endOffset());\n    if (offsetAtt != null) {\n      assertTrue(\"finalOffset must be >= 0\", offsetAtt.endOffset() >= 0);\n    }\n    ts.close();\n  }\n\n","sourceOld":"  public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[], Integer finalOffset) throws IOException {\n    assertNotNull(output);\n    CheckClearAttributesAttribute checkClearAtt = ts.addAttribute(CheckClearAttributesAttribute.class);\n    \n    assertTrue(\"has no CharTermAttribute\", ts.hasAttribute(CharTermAttribute.class));\n    CharTermAttribute termAtt = ts.getAttribute(CharTermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null || finalOffset != null) {\n      assertTrue(\"has no OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has no TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has no PositionIncrementAttribute\", ts.hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = ts.getAttribute(PositionIncrementAttribute.class);\n    }\n    \n    ts.reset();\n    for (int i = 0; i < output.length; i++) {\n      // extra safety to enforce, that the state is not preserved and also assign bogus values\n      ts.clearAttributes();\n      termAtt.setEmpty().append(\"bogusTerm\");\n      if (offsetAtt != null) offsetAtt.setOffset(14584724,24683243);\n      if (typeAtt != null) typeAtt.setType(\"bogusType\");\n      if (posIncrAtt != null) posIncrAtt.setPositionIncrement(45987657);\n      \n      checkClearAtt.getAndResetClearCalled(); // reset it, because we called clearAttribute() before\n      assertTrue(\"token \"+i+\" does not exist\", ts.incrementToken());\n      assertTrue(\"clearAttributes() was not called correctly in TokenStream chain\", checkClearAtt.getAndResetClearCalled());\n      \n      assertEquals(\"term \"+i, output[i], termAtt.toString());\n      if (startOffsets != null)\n        assertEquals(\"startOffset \"+i, startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null)\n        assertEquals(\"endOffset \"+i, endOffsets[i], offsetAtt.endOffset());\n      if (types != null)\n        assertEquals(\"type \"+i, types[i], typeAtt.type());\n      if (posIncrements != null)\n        assertEquals(\"posIncrement \"+i, posIncrements[i], posIncrAtt.getPositionIncrement());\n    }\n    assertFalse(\"end of stream\", ts.incrementToken());\n    ts.end();\n    if (finalOffset != null)\n      assertEquals(\"finalOffset \", finalOffset.intValue(), offsetAtt.endOffset());\n    ts.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test-framework/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[],Integer).mjava","pathOld":"lucene/src/test-framework/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[],Integer).mjava","sourceNew":"  public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[], Integer finalOffset) throws IOException {\n    assertNotNull(output);\n    CheckClearAttributesAttribute checkClearAtt = ts.addAttribute(CheckClearAttributesAttribute.class);\n    \n    assertTrue(\"has no CharTermAttribute\", ts.hasAttribute(CharTermAttribute.class));\n    CharTermAttribute termAtt = ts.getAttribute(CharTermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null || finalOffset != null) {\n      assertTrue(\"has no OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has no TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has no PositionIncrementAttribute\", ts.hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = ts.getAttribute(PositionIncrementAttribute.class);\n    }\n    \n    ts.reset();\n    for (int i = 0; i < output.length; i++) {\n      // extra safety to enforce, that the state is not preserved and also assign bogus values\n      ts.clearAttributes();\n      termAtt.setEmpty().append(\"bogusTerm\");\n      if (offsetAtt != null) offsetAtt.setOffset(14584724,24683243);\n      if (typeAtt != null) typeAtt.setType(\"bogusType\");\n      if (posIncrAtt != null) posIncrAtt.setPositionIncrement(45987657);\n      \n      checkClearAtt.getAndResetClearCalled(); // reset it, because we called clearAttribute() before\n      assertTrue(\"token \"+i+\" does not exist\", ts.incrementToken());\n      assertTrue(\"clearAttributes() was not called correctly in TokenStream chain\", checkClearAtt.getAndResetClearCalled());\n      \n      assertEquals(\"term \"+i, output[i], termAtt.toString());\n      if (startOffsets != null)\n        assertEquals(\"startOffset \"+i, startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null)\n        assertEquals(\"endOffset \"+i, endOffsets[i], offsetAtt.endOffset());\n      if (types != null)\n        assertEquals(\"type \"+i, types[i], typeAtt.type());\n      if (posIncrements != null)\n        assertEquals(\"posIncrement \"+i, posIncrements[i], posIncrAtt.getPositionIncrement());\n      \n      // we can enforce some basic things about a few attributes even if the caller doesn't check:\n      if (offsetAtt != null) {\n        assertTrue(\"startOffset must be >= 0\", offsetAtt.startOffset() >= 0);\n        assertTrue(\"endOffset must be >= 0\", offsetAtt.endOffset() >= 0);\n        assertTrue(\"endOffset must be >= startOffset\", offsetAtt.endOffset() >= offsetAtt.startOffset());\n      }\n      if (posIncrAtt != null) {\n        assertTrue(\"posIncrement must be >= 0\", posIncrAtt.getPositionIncrement() >= 0);\n      }\n    }\n    assertFalse(\"end of stream\", ts.incrementToken());\n    ts.end();\n    if (finalOffset != null)\n      assertEquals(\"finalOffset \", finalOffset.intValue(), offsetAtt.endOffset());\n    if (offsetAtt != null) {\n      assertTrue(\"finalOffset must be >= 0\", offsetAtt.endOffset() >= 0);\n    }\n    ts.close();\n  }\n\n","sourceOld":"  public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[], Integer finalOffset) throws IOException {\n    assertNotNull(output);\n    CheckClearAttributesAttribute checkClearAtt = ts.addAttribute(CheckClearAttributesAttribute.class);\n    \n    assertTrue(\"has no CharTermAttribute\", ts.hasAttribute(CharTermAttribute.class));\n    CharTermAttribute termAtt = ts.getAttribute(CharTermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null || finalOffset != null) {\n      assertTrue(\"has no OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has no TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has no PositionIncrementAttribute\", ts.hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = ts.getAttribute(PositionIncrementAttribute.class);\n    }\n    \n    ts.reset();\n    for (int i = 0; i < output.length; i++) {\n      // extra safety to enforce, that the state is not preserved and also assign bogus values\n      ts.clearAttributes();\n      termAtt.setEmpty().append(\"bogusTerm\");\n      if (offsetAtt != null) offsetAtt.setOffset(14584724,24683243);\n      if (typeAtt != null) typeAtt.setType(\"bogusType\");\n      if (posIncrAtt != null) posIncrAtt.setPositionIncrement(45987657);\n      \n      checkClearAtt.getAndResetClearCalled(); // reset it, because we called clearAttribute() before\n      assertTrue(\"token \"+i+\" does not exist\", ts.incrementToken());\n      assertTrue(\"clearAttributes() was not called correctly in TokenStream chain\", checkClearAtt.getAndResetClearCalled());\n      \n      assertEquals(\"term \"+i, output[i], termAtt.toString());\n      if (startOffsets != null)\n        assertEquals(\"startOffset \"+i, startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null)\n        assertEquals(\"endOffset \"+i, endOffsets[i], offsetAtt.endOffset());\n      if (types != null)\n        assertEquals(\"type \"+i, types[i], typeAtt.type());\n      if (posIncrements != null)\n        assertEquals(\"posIncrement \"+i, posIncrements[i], posIncrAtt.getPositionIncrement());\n    }\n    assertFalse(\"end of stream\", ts.incrementToken());\n    ts.end();\n    if (finalOffset != null)\n      assertEquals(\"finalOffset \", finalOffset.intValue(), offsetAtt.endOffset());\n    ts.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7b91922b55d15444d554721b352861d028eb8278","date":1320421415,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test-framework/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[],Integer).mjava","pathOld":"lucene/src/test-framework/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[],Integer).mjava","sourceNew":"  public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[], Integer finalOffset) throws IOException {\n    assertNotNull(output);\n    CheckClearAttributesAttribute checkClearAtt = ts.addAttribute(CheckClearAttributesAttribute.class);\n    \n    assertTrue(\"has no CharTermAttribute\", ts.hasAttribute(CharTermAttribute.class));\n    CharTermAttribute termAtt = ts.getAttribute(CharTermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null || finalOffset != null) {\n      assertTrue(\"has no OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has no TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has no PositionIncrementAttribute\", ts.hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = ts.getAttribute(PositionIncrementAttribute.class);\n    }\n    \n    ts.reset();\n    for (int i = 0; i < output.length; i++) {\n      // extra safety to enforce, that the state is not preserved and also assign bogus values\n      ts.clearAttributes();\n      termAtt.setEmpty().append(\"bogusTerm\");\n      if (offsetAtt != null) offsetAtt.setOffset(14584724,24683243);\n      if (typeAtt != null) typeAtt.setType(\"bogusType\");\n      if (posIncrAtt != null) posIncrAtt.setPositionIncrement(45987657);\n      \n      checkClearAtt.getAndResetClearCalled(); // reset it, because we called clearAttribute() before\n      assertTrue(\"token \"+i+\" does not exist\", ts.incrementToken());\n      assertTrue(\"clearAttributes() was not called correctly in TokenStream chain\", checkClearAtt.getAndResetClearCalled());\n      \n      assertEquals(\"term \"+i, output[i], termAtt.toString());\n      if (startOffsets != null)\n        assertEquals(\"startOffset \"+i, startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null)\n        assertEquals(\"endOffset \"+i, endOffsets[i], offsetAtt.endOffset());\n      if (types != null)\n        assertEquals(\"type \"+i, types[i], typeAtt.type());\n      if (posIncrements != null)\n        assertEquals(\"posIncrement \"+i, posIncrements[i], posIncrAtt.getPositionIncrement());\n      \n      // we can enforce some basic things about a few attributes even if the caller doesn't check:\n      if (offsetAtt != null) {\n        assertTrue(\"startOffset must be >= 0\", offsetAtt.startOffset() >= 0);\n        assertTrue(\"endOffset must be >= 0\", offsetAtt.endOffset() >= 0);\n        assertTrue(\"endOffset must be >= startOffset\", offsetAtt.endOffset() >= offsetAtt.startOffset());\n      }\n      if (posIncrAtt != null) {\n        assertTrue(\"posIncrement must be >= 0\", posIncrAtt.getPositionIncrement() >= 0);\n      }\n    }\n    assertFalse(\"end of stream\", ts.incrementToken());\n    ts.end();\n    if (finalOffset != null)\n      assertEquals(\"finalOffset \", finalOffset.intValue(), offsetAtt.endOffset());\n    if (offsetAtt != null) {\n      assertTrue(\"finalOffset must be >= 0\", offsetAtt.endOffset() >= 0);\n    }\n    ts.close();\n  }\n\n","sourceOld":"  public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[], Integer finalOffset) throws IOException {\n    assertNotNull(output);\n    CheckClearAttributesAttribute checkClearAtt = ts.addAttribute(CheckClearAttributesAttribute.class);\n    \n    assertTrue(\"has no CharTermAttribute\", ts.hasAttribute(CharTermAttribute.class));\n    CharTermAttribute termAtt = ts.getAttribute(CharTermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null || finalOffset != null) {\n      assertTrue(\"has no OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has no TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has no PositionIncrementAttribute\", ts.hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = ts.getAttribute(PositionIncrementAttribute.class);\n    }\n    \n    ts.reset();\n    for (int i = 0; i < output.length; i++) {\n      // extra safety to enforce, that the state is not preserved and also assign bogus values\n      ts.clearAttributes();\n      termAtt.setEmpty().append(\"bogusTerm\");\n      if (offsetAtt != null) offsetAtt.setOffset(14584724,24683243);\n      if (typeAtt != null) typeAtt.setType(\"bogusType\");\n      if (posIncrAtt != null) posIncrAtt.setPositionIncrement(45987657);\n      \n      checkClearAtt.getAndResetClearCalled(); // reset it, because we called clearAttribute() before\n      assertTrue(\"token \"+i+\" does not exist\", ts.incrementToken());\n      assertTrue(\"clearAttributes() was not called correctly in TokenStream chain\", checkClearAtt.getAndResetClearCalled());\n      \n      assertEquals(\"term \"+i, output[i], termAtt.toString());\n      if (startOffsets != null)\n        assertEquals(\"startOffset \"+i, startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null)\n        assertEquals(\"endOffset \"+i, endOffsets[i], offsetAtt.endOffset());\n      if (types != null)\n        assertEquals(\"type \"+i, types[i], typeAtt.type());\n      if (posIncrements != null)\n        assertEquals(\"posIncrement \"+i, posIncrements[i], posIncrAtt.getPositionIncrement());\n      \n      // we can enforce some basic things about a few attributes even if the caller doesn't check:\n      if (offsetAtt != null) {\n        assertTrue(\"startOffset must be >= 0\", offsetAtt.startOffset() >= 0);\n        assertTrue(\"endOffset must be >= 0\", offsetAtt.endOffset() >= 0);\n        assertTrue(\"endOffset must be >= startOffset\", offsetAtt.endOffset() >= offsetAtt.startOffset());\n      }\n      if (posIncrAtt != null) {\n        assertTrue(\"posIncrement must be >= 0\", posIncrAtt.getPositionIncrement() >= 0);\n      }\n    }\n    assertFalse(\"end of stream\", ts.incrementToken());\n    ts.end();\n    if (finalOffset != null)\n      assertEquals(\"finalOffset \", finalOffset.intValue(), offsetAtt.endOffset());\n    if (offsetAtt != null) {\n      assertTrue(\"finalOffset must be >= 0\", offsetAtt.endOffset() >= 0);\n    }\n    ts.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"7b91922b55d15444d554721b352861d028eb8278":["217827c5ead25d2f1e89bdcad7f9f498221d185d"],"a3776dccca01c11e7046323cfad46a3b4a471233":["f0b9dc55f42953d6740cddbc92cb0d19fe1ba0ce","217827c5ead25d2f1e89bdcad7f9f498221d185d"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","f0b9dc55f42953d6740cddbc92cb0d19fe1ba0ce"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["29ef99d61cda9641b6250bf9567329a6e65f901d","217827c5ead25d2f1e89bdcad7f9f498221d185d"],"217827c5ead25d2f1e89bdcad7f9f498221d185d":["f0b9dc55f42953d6740cddbc92cb0d19fe1ba0ce"],"d493718201f0d0c54c773fb323d87bbd2fbffe41":["bde51b089eb7f86171eb3406e38a274743f9b7ac","217827c5ead25d2f1e89bdcad7f9f498221d185d"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","f0b9dc55f42953d6740cddbc92cb0d19fe1ba0ce"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["7b91922b55d15444d554721b352861d028eb8278"],"f0b9dc55f42953d6740cddbc92cb0d19fe1ba0ce":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"7b91922b55d15444d554721b352861d028eb8278":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a3776dccca01c11e7046323cfad46a3b4a471233":[],"29ef99d61cda9641b6250bf9567329a6e65f901d":["135621f3a0670a9394eb563224a3b76cc4dddc0f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["29ef99d61cda9641b6250bf9567329a6e65f901d","bde51b089eb7f86171eb3406e38a274743f9b7ac","f0b9dc55f42953d6740cddbc92cb0d19fe1ba0ce"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":[],"217827c5ead25d2f1e89bdcad7f9f498221d185d":["7b91922b55d15444d554721b352861d028eb8278","a3776dccca01c11e7046323cfad46a3b4a471233","135621f3a0670a9394eb563224a3b76cc4dddc0f","d493718201f0d0c54c773fb323d87bbd2fbffe41"],"d493718201f0d0c54c773fb323d87bbd2fbffe41":[],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["d493718201f0d0c54c773fb323d87bbd2fbffe41"],"f0b9dc55f42953d6740cddbc92cb0d19fe1ba0ce":["a3776dccca01c11e7046323cfad46a3b4a471233","29ef99d61cda9641b6250bf9567329a6e65f901d","217827c5ead25d2f1e89bdcad7f9f498221d185d","bde51b089eb7f86171eb3406e38a274743f9b7ac"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a3776dccca01c11e7046323cfad46a3b4a471233","135621f3a0670a9394eb563224a3b76cc4dddc0f","d493718201f0d0c54c773fb323d87bbd2fbffe41","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}