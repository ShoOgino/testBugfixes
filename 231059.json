{"path":"src/test/org/apache/solr/analysis/TestElisionFilterFactory#testElision().mjava","commits":[{"id":"2fd023a662cc25ae7e0ad0f33d71c476a16d0579","date":1261403630,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"src/test/org/apache/solr/analysis/TestElisionFilterFactory#testElision().mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Ensure the filter actually normalizes text.\n   */\n  public void testElision() throws Exception {\n    Reader reader = new StringReader(\"l'avion\");\n    Tokenizer tokenizer = new WhitespaceTokenizer(reader);\n    ElisionFilterFactory factory = new ElisionFilterFactory();\n    ResourceLoader loader = solrConfig.getResourceLoader();\n    Map<String,String> args = new HashMap<String,String>();\n    args.put(\"articles\", \"frenchArticles.txt\");\n    factory.init(args);\n    factory.inform(loader);\n    TokenStream stream = factory.create(tokenizer);\n    assertTokenStreamContents(stream, new String[] { \"avion\" });\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d32aa039d84ab454629ee28b64c63d777b5c9ce3","date":1268237977,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"src/test/org/apache/solr/analysis/TestElisionFilterFactory#testElision().mjava","pathOld":"src/test/org/apache/solr/analysis/TestElisionFilterFactory#testElision().mjava","sourceNew":"  /**\n   * Ensure the filter actually normalizes text.\n   */\n  public void testElision() throws Exception {\n    Reader reader = new StringReader(\"l'avion\");\n    Tokenizer tokenizer = new WhitespaceTokenizer(reader);\n    ElisionFilterFactory factory = new ElisionFilterFactory();\n    ResourceLoader loader = new SolrResourceLoader(null, null);\n    Map<String,String> args = new HashMap<String,String>();\n    args.put(\"articles\", \"frenchArticles.txt\");\n    factory.init(args);\n    factory.inform(loader);\n    TokenStream stream = factory.create(tokenizer);\n    assertTokenStreamContents(stream, new String[] { \"avion\" });\n  }\n\n","sourceOld":"  /**\n   * Ensure the filter actually normalizes text.\n   */\n  public void testElision() throws Exception {\n    Reader reader = new StringReader(\"l'avion\");\n    Tokenizer tokenizer = new WhitespaceTokenizer(reader);\n    ElisionFilterFactory factory = new ElisionFilterFactory();\n    ResourceLoader loader = solrConfig.getResourceLoader();\n    Map<String,String> args = new HashMap<String,String>();\n    args.put(\"articles\", \"frenchArticles.txt\");\n    factory.init(args);\n    factory.inform(loader);\n    TokenStream stream = factory.create(tokenizer);\n    assertTokenStreamContents(stream, new String[] { \"avion\" });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bc92360b2f163f0139d6be8fbf710421c8864347","date":1268735782,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/test/org/apache/solr/analysis/TestElisionFilterFactory#testElision().mjava","pathOld":"src/test/org/apache/solr/analysis/TestElisionFilterFactory#testElision().mjava","sourceNew":"  /**\n   * Ensure the filter actually normalizes text.\n   */\n  public void testElision() throws Exception {\n    Reader reader = new StringReader(\"l'avion\");\n    Tokenizer tokenizer = new WhitespaceTokenizer(reader);\n    ElisionFilterFactory factory = new ElisionFilterFactory();\n    factory.init(DEFAULT_VERSION_PARAM);\n    ResourceLoader loader = new SolrResourceLoader(null, null);\n    Map<String,String> args = new HashMap<String,String>();\n    args.put(\"articles\", \"frenchArticles.txt\");\n    factory.init(args);\n    factory.inform(loader);\n    TokenStream stream = factory.create(tokenizer);\n    assertTokenStreamContents(stream, new String[] { \"avion\" });\n  }\n\n","sourceOld":"  /**\n   * Ensure the filter actually normalizes text.\n   */\n  public void testElision() throws Exception {\n    Reader reader = new StringReader(\"l'avion\");\n    Tokenizer tokenizer = new WhitespaceTokenizer(reader);\n    ElisionFilterFactory factory = new ElisionFilterFactory();\n    ResourceLoader loader = new SolrResourceLoader(null, null);\n    Map<String,String> args = new HashMap<String,String>();\n    args.put(\"articles\", \"frenchArticles.txt\");\n    factory.init(args);\n    factory.inform(loader);\n    TokenStream stream = factory.create(tokenizer);\n    assertTokenStreamContents(stream, new String[] { \"avion\" });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ad94625fb8d088209f46650c8097196fec67f00c","date":1453508319,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/src/test/org/apache/solr/analysis/TestElisionFilterFactory#testElision().mjava","pathOld":"src/test/org/apache/solr/analysis/TestElisionFilterFactory#testElision().mjava","sourceNew":"  /**\n   * Ensure the filter actually normalizes text.\n   */\n  public void testElision() throws Exception {\n    Reader reader = new StringReader(\"l'avion\");\n    Tokenizer tokenizer = new WhitespaceTokenizer(reader);\n    ElisionFilterFactory factory = new ElisionFilterFactory();\n    factory.init(DEFAULT_VERSION_PARAM);\n    ResourceLoader loader = new SolrResourceLoader(null, null);\n    Map<String,String> args = new HashMap<String,String>();\n    args.put(\"articles\", \"frenchArticles.txt\");\n    factory.init(args);\n    factory.inform(loader);\n    TokenStream stream = factory.create(tokenizer);\n    assertTokenStreamContents(stream, new String[] { \"avion\" });\n  }\n\n","sourceOld":"  /**\n   * Ensure the filter actually normalizes text.\n   */\n  public void testElision() throws Exception {\n    Reader reader = new StringReader(\"l'avion\");\n    Tokenizer tokenizer = new WhitespaceTokenizer(reader);\n    ElisionFilterFactory factory = new ElisionFilterFactory();\n    factory.init(DEFAULT_VERSION_PARAM);\n    ResourceLoader loader = new SolrResourceLoader(null, null);\n    Map<String,String> args = new HashMap<String,String>();\n    args.put(\"articles\", \"frenchArticles.txt\");\n    factory.init(args);\n    factory.inform(loader);\n    TokenStream stream = factory.create(tokenizer);\n    assertTokenStreamContents(stream, new String[] { \"avion\" });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"d32aa039d84ab454629ee28b64c63d777b5c9ce3":["2fd023a662cc25ae7e0ad0f33d71c476a16d0579"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"ad94625fb8d088209f46650c8097196fec67f00c":["bc92360b2f163f0139d6be8fbf710421c8864347"],"2fd023a662cc25ae7e0ad0f33d71c476a16d0579":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"bc92360b2f163f0139d6be8fbf710421c8864347":["d32aa039d84ab454629ee28b64c63d777b5c9ce3"]},"commit2Childs":{"d32aa039d84ab454629ee28b64c63d777b5c9ce3":["bc92360b2f163f0139d6be8fbf710421c8864347"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["2fd023a662cc25ae7e0ad0f33d71c476a16d0579"],"ad94625fb8d088209f46650c8097196fec67f00c":[],"2fd023a662cc25ae7e0ad0f33d71c476a16d0579":["d32aa039d84ab454629ee28b64c63d777b5c9ce3"],"bc92360b2f163f0139d6be8fbf710421c8864347":["ad94625fb8d088209f46650c8097196fec67f00c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["ad94625fb8d088209f46650c8097196fec67f00c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"pathCommit":null}