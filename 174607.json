{"path":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","commits":[{"id":"e99275efa2c9c9ae3bdba986218af82f2bf3dc30","date":1354658499,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean).mjava","sourceNew":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    if (fields == null) {\n      msg(infoStream, \"OK [no fields/terms]\");\n      return status;\n    }\n    \n    DocsEnum docs = null;\n    DocsEnum docsAndFreqs = null;\n    DocsAndPositionsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (!fieldInfo.isIndexed()) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      // term vectors cannot omit TF\n      final boolean hasFreqs = isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0;\n\n      final TermsEnum termsEnum = terms.iterator(null);\n      \n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRef lastTerm = null;\n      \n      Comparator<BytesRef> termComp = terms.getComparator();\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = BytesRef.deepCopyOf(term);\n        } else {\n          if (termComp.compare(lastTerm, term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.docs(liveDocs, docs);\n        postings = termsEnum.docsAndPositions(liveDocs, postings);\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final DocsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docs, 0);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.docsAndPositions(liveDocs, postings);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.docs(liveDocs, docs, 0);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        }\n      }\n      \n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        if (fieldTerms instanceof BlockTreeTermsReader.FieldReader) {\n          final BlockTreeTermsReader.Stats stats = ((BlockTreeTermsReader.FieldReader) fieldTerms).computeStats();\n          assert stats != null;\n          if (status.blockTreeStats == null) {\n            status.blockTreeStats = new HashMap<String,BlockTreeTermsReader.Stats>();\n          }\n          status.blockTreeStats.put(field, stats);\n        }\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          DocsEnum d = termsEnum.docs(null, null, 0);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.docs(liveDocs, docs, 0);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i], true)) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.docs(null, docs, 0);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, \"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String,BlockTreeTermsReader.Stats> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    if (fields == null) {\n      msg(\"OK [no fields/terms]\");\n      return status;\n    }\n    \n    DocsEnum docs = null;\n    DocsEnum docsAndFreqs = null;\n    DocsAndPositionsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (!fieldInfo.isIndexed()) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      // term vectors cannot omit TF\n      final boolean hasFreqs = isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0;\n\n      final TermsEnum termsEnum = terms.iterator(null);\n      \n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRef lastTerm = null;\n      \n      Comparator<BytesRef> termComp = terms.getComparator();\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = BytesRef.deepCopyOf(term);\n        } else {\n          if (termComp.compare(lastTerm, term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.docs(liveDocs, docs);\n        postings = termsEnum.docsAndPositions(liveDocs, postings);\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final DocsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docs, 0);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.docsAndPositions(liveDocs, postings);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.docs(liveDocs, docs, 0);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        }\n      }\n      \n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        if (fieldTerms instanceof BlockTreeTermsReader.FieldReader) {\n          final BlockTreeTermsReader.Stats stats = ((BlockTreeTermsReader.FieldReader) fieldTerms).computeStats();\n          assert stats != null;\n          if (status.blockTreeStats == null) {\n            status.blockTreeStats = new HashMap<String,BlockTreeTermsReader.Stats>();\n          }\n          status.blockTreeStats.put(field, stats);\n        }\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          DocsEnum d = termsEnum.docs(null, null, 0);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.docs(liveDocs, docs, 0);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i], true)) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.docs(null, docs, 0);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(\"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String,BlockTreeTermsReader.Stats> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d3fcb70cf561547c7bb1506e0cf32ca7b1287064","date":1357616416,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","sourceNew":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    if (fields == null) {\n      msg(infoStream, \"OK [no fields/terms]\");\n      return status;\n    }\n    \n    DocsEnum docs = null;\n    DocsEnum docsAndFreqs = null;\n    DocsAndPositionsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (!fieldInfo.isIndexed()) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      // term vectors cannot omit TF\n      final boolean hasFreqs = isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0;\n\n      final TermsEnum termsEnum = terms.iterator(null);\n      \n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRef lastTerm = null;\n      \n      Comparator<BytesRef> termComp = terms.getComparator();\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = BytesRef.deepCopyOf(term);\n        } else {\n          if (termComp.compare(lastTerm, term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.docs(liveDocs, docs);\n        postings = termsEnum.docsAndPositions(liveDocs, postings);\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final DocsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.docsAndPositions(liveDocs, postings);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        }\n      }\n      \n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        if (fieldTerms instanceof BlockTreeTermsReader.FieldReader) {\n          final BlockTreeTermsReader.Stats stats = ((BlockTreeTermsReader.FieldReader) fieldTerms).computeStats();\n          assert stats != null;\n          if (status.blockTreeStats == null) {\n            status.blockTreeStats = new HashMap<String,BlockTreeTermsReader.Stats>();\n          }\n          status.blockTreeStats.put(field, stats);\n        }\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          DocsEnum d = termsEnum.docs(null, null, DocsEnum.FLAG_NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i], true)) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, \"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String,BlockTreeTermsReader.Stats> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    if (fields == null) {\n      msg(infoStream, \"OK [no fields/terms]\");\n      return status;\n    }\n    \n    DocsEnum docs = null;\n    DocsEnum docsAndFreqs = null;\n    DocsAndPositionsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (!fieldInfo.isIndexed()) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      // term vectors cannot omit TF\n      final boolean hasFreqs = isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0;\n\n      final TermsEnum termsEnum = terms.iterator(null);\n      \n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRef lastTerm = null;\n      \n      Comparator<BytesRef> termComp = terms.getComparator();\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = BytesRef.deepCopyOf(term);\n        } else {\n          if (termComp.compare(lastTerm, term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.docs(liveDocs, docs);\n        postings = termsEnum.docsAndPositions(liveDocs, postings);\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final DocsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docs, 0);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.docsAndPositions(liveDocs, postings);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.docs(liveDocs, docs, 0);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        }\n      }\n      \n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        if (fieldTerms instanceof BlockTreeTermsReader.FieldReader) {\n          final BlockTreeTermsReader.Stats stats = ((BlockTreeTermsReader.FieldReader) fieldTerms).computeStats();\n          assert stats != null;\n          if (status.blockTreeStats == null) {\n            status.blockTreeStats = new HashMap<String,BlockTreeTermsReader.Stats>();\n          }\n          status.blockTreeStats.put(field, stats);\n        }\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          DocsEnum d = termsEnum.docs(null, null, 0);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.docs(liveDocs, docs, 0);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i], true)) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.docs(null, docs, 0);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, \"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String,BlockTreeTermsReader.Stats> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e93b477a465bb7b012eb16214d6fe0214003e3ab","date":1359058944,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","sourceNew":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    if (fields == null) {\n      msg(infoStream, \"OK [no fields/terms]\");\n      return status;\n    }\n    \n    DocsEnum docs = null;\n    DocsEnum docsAndFreqs = null;\n    DocsAndPositionsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (!fieldInfo.isIndexed()) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      // term vectors cannot omit TF\n      final boolean hasFreqs = isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0;\n\n      final TermsEnum termsEnum = terms.iterator(null);\n      \n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRef lastTerm = null;\n      \n      Comparator<BytesRef> termComp = terms.getComparator();\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        \n        checkBounds(term);\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = BytesRef.deepCopyOf(term);\n        } else {\n          if (termComp.compare(lastTerm, term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.docs(liveDocs, docs);\n        postings = termsEnum.docsAndPositions(liveDocs, postings);\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final DocsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                checkBounds(payload);\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.docsAndPositions(liveDocs, postings);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        }\n      }\n      \n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        if (fieldTerms instanceof BlockTreeTermsReader.FieldReader) {\n          final BlockTreeTermsReader.Stats stats = ((BlockTreeTermsReader.FieldReader) fieldTerms).computeStats();\n          assert stats != null;\n          if (status.blockTreeStats == null) {\n            status.blockTreeStats = new HashMap<String,BlockTreeTermsReader.Stats>();\n          }\n          status.blockTreeStats.put(field, stats);\n        }\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          DocsEnum d = termsEnum.docs(null, null, DocsEnum.FLAG_NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i], true)) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, \"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String,BlockTreeTermsReader.Stats> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    if (fields == null) {\n      msg(infoStream, \"OK [no fields/terms]\");\n      return status;\n    }\n    \n    DocsEnum docs = null;\n    DocsEnum docsAndFreqs = null;\n    DocsAndPositionsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (!fieldInfo.isIndexed()) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      // term vectors cannot omit TF\n      final boolean hasFreqs = isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0;\n\n      final TermsEnum termsEnum = terms.iterator(null);\n      \n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRef lastTerm = null;\n      \n      Comparator<BytesRef> termComp = terms.getComparator();\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = BytesRef.deepCopyOf(term);\n        } else {\n          if (termComp.compare(lastTerm, term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.docs(liveDocs, docs);\n        postings = termsEnum.docsAndPositions(liveDocs, postings);\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final DocsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.docsAndPositions(liveDocs, postings);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        }\n      }\n      \n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        if (fieldTerms instanceof BlockTreeTermsReader.FieldReader) {\n          final BlockTreeTermsReader.Stats stats = ((BlockTreeTermsReader.FieldReader) fieldTerms).computeStats();\n          assert stats != null;\n          if (status.blockTreeStats == null) {\n            status.blockTreeStats = new HashMap<String,BlockTreeTermsReader.Stats>();\n          }\n          status.blockTreeStats.put(field, stats);\n        }\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          DocsEnum d = termsEnum.docs(null, null, DocsEnum.FLAG_NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i], true)) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, \"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String,BlockTreeTermsReader.Stats> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"59d00acb12c9809438e21de7c24f016356973d46","date":1359349254,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","sourceNew":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    if (fields == null) {\n      msg(infoStream, \"OK [no fields/terms]\");\n      return status;\n    }\n    \n    DocsEnum docs = null;\n    DocsEnum docsAndFreqs = null;\n    DocsAndPositionsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (!fieldInfo.isIndexed()) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      // term vectors cannot omit TF\n      final boolean hasFreqs = isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0;\n\n      final TermsEnum termsEnum = terms.iterator(null);\n      \n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRef lastTerm = null;\n      \n      Comparator<BytesRef> termComp = terms.getComparator();\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = BytesRef.deepCopyOf(term);\n        } else {\n          if (termComp.compare(lastTerm, term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.docs(liveDocs, docs);\n        postings = termsEnum.docsAndPositions(liveDocs, postings);\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final DocsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.docsAndPositions(liveDocs, postings);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        }\n      }\n      \n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        if (fieldTerms instanceof BlockTreeTermsReader.FieldReader) {\n          final BlockTreeTermsReader.Stats stats = ((BlockTreeTermsReader.FieldReader) fieldTerms).computeStats();\n          assert stats != null;\n          if (status.blockTreeStats == null) {\n            status.blockTreeStats = new HashMap<String,BlockTreeTermsReader.Stats>();\n          }\n          status.blockTreeStats.put(field, stats);\n        }\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          DocsEnum d = termsEnum.docs(null, null, DocsEnum.FLAG_NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i], true)) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, \"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String,BlockTreeTermsReader.Stats> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    if (fields == null) {\n      msg(infoStream, \"OK [no fields/terms]\");\n      return status;\n    }\n    \n    DocsEnum docs = null;\n    DocsEnum docsAndFreqs = null;\n    DocsAndPositionsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (!fieldInfo.isIndexed()) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      // term vectors cannot omit TF\n      final boolean hasFreqs = isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0;\n\n      final TermsEnum termsEnum = terms.iterator(null);\n      \n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRef lastTerm = null;\n      \n      Comparator<BytesRef> termComp = terms.getComparator();\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        \n        checkBounds(term);\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = BytesRef.deepCopyOf(term);\n        } else {\n          if (termComp.compare(lastTerm, term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.docs(liveDocs, docs);\n        postings = termsEnum.docsAndPositions(liveDocs, postings);\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final DocsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                checkBounds(payload);\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.docsAndPositions(liveDocs, postings);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        }\n      }\n      \n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        if (fieldTerms instanceof BlockTreeTermsReader.FieldReader) {\n          final BlockTreeTermsReader.Stats stats = ((BlockTreeTermsReader.FieldReader) fieldTerms).computeStats();\n          assert stats != null;\n          if (status.blockTreeStats == null) {\n            status.blockTreeStats = new HashMap<String,BlockTreeTermsReader.Stats>();\n          }\n          status.blockTreeStats.put(field, stats);\n        }\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          DocsEnum d = termsEnum.docs(null, null, DocsEnum.FLAG_NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i], true)) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, \"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String,BlockTreeTermsReader.Stats> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d4d69c535930b5cce125cff868d40f6373dc27d4","date":1360270101,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    if (fields == null) {\n      msg(infoStream, \"OK [no fields/terms]\");\n      return status;\n    }\n    \n    DocsEnum docs = null;\n    DocsEnum docsAndFreqs = null;\n    DocsAndPositionsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (!fieldInfo.isIndexed()) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      // term vectors cannot omit TF\n      final boolean hasFreqs = isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0;\n\n      final TermsEnum termsEnum = terms.iterator(null);\n      \n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRef lastTerm = null;\n      \n      Comparator<BytesRef> termComp = terms.getComparator();\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = BytesRef.deepCopyOf(term);\n        } else {\n          if (termComp.compare(lastTerm, term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.docs(liveDocs, docs);\n        postings = termsEnum.docsAndPositions(liveDocs, postings);\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final DocsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.docsAndPositions(liveDocs, postings);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        }\n      }\n      \n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        if (fieldTerms instanceof BlockTreeTermsReader.FieldReader) {\n          final BlockTreeTermsReader.Stats stats = ((BlockTreeTermsReader.FieldReader) fieldTerms).computeStats();\n          assert stats != null;\n          if (status.blockTreeStats == null) {\n            status.blockTreeStats = new HashMap<String,BlockTreeTermsReader.Stats>();\n          }\n          status.blockTreeStats.put(field, stats);\n        }\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          DocsEnum d = termsEnum.docs(null, null, DocsEnum.FLAG_NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i], true)) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, \"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String,BlockTreeTermsReader.Stats> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"eee5f2a24465d2c9a5f86ab84b7c35041a30fda8","date":1373996650,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","sourceNew":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    if (fields == null) {\n      msg(infoStream, \"OK [no fields/terms]\");\n      return status;\n    }\n    \n    DocsEnum docs = null;\n    DocsEnum docsAndFreqs = null;\n    DocsAndPositionsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (!fieldInfo.isIndexed()) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      // term vectors cannot omit TF\n      final boolean hasFreqs = isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0;\n\n      final TermsEnum termsEnum = terms.iterator(null);\n      \n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRef lastTerm = null;\n      \n      Comparator<BytesRef> termComp = terms.getComparator();\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = BytesRef.deepCopyOf(term);\n        } else {\n          if (termComp.compare(lastTerm, term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.docs(liveDocs, docs);\n        postings = termsEnum.docsAndPositions(liveDocs, postings);\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final DocsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.docsAndPositions(liveDocs, postings);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        }\n      }\n      \n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        if (fieldTerms instanceof BlockTreeTermsReader.FieldReader) {\n          final BlockTreeTermsReader.Stats stats = ((BlockTreeTermsReader.FieldReader) fieldTerms).computeStats();\n          assert stats != null;\n          if (status.blockTreeStats == null) {\n            status.blockTreeStats = new HashMap<String,BlockTreeTermsReader.Stats>();\n          }\n          status.blockTreeStats.put(field, stats);\n        }\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          DocsEnum d = termsEnum.docs(null, null, DocsEnum.FLAG_NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, \"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String,BlockTreeTermsReader.Stats> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    if (fields == null) {\n      msg(infoStream, \"OK [no fields/terms]\");\n      return status;\n    }\n    \n    DocsEnum docs = null;\n    DocsEnum docsAndFreqs = null;\n    DocsAndPositionsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (!fieldInfo.isIndexed()) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      // term vectors cannot omit TF\n      final boolean hasFreqs = isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0;\n\n      final TermsEnum termsEnum = terms.iterator(null);\n      \n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRef lastTerm = null;\n      \n      Comparator<BytesRef> termComp = terms.getComparator();\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = BytesRef.deepCopyOf(term);\n        } else {\n          if (termComp.compare(lastTerm, term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.docs(liveDocs, docs);\n        postings = termsEnum.docsAndPositions(liveDocs, postings);\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final DocsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.docsAndPositions(liveDocs, postings);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        }\n      }\n      \n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        if (fieldTerms instanceof BlockTreeTermsReader.FieldReader) {\n          final BlockTreeTermsReader.Stats stats = ((BlockTreeTermsReader.FieldReader) fieldTerms).computeStats();\n          assert stats != null;\n          if (status.blockTreeStats == null) {\n            status.blockTreeStats = new HashMap<String,BlockTreeTermsReader.Stats>();\n          }\n          status.blockTreeStats.put(field, stats);\n        }\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          DocsEnum d = termsEnum.docs(null, null, DocsEnum.FLAG_NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i], true)) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, \"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String,BlockTreeTermsReader.Stats> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","date":1376366778,"type":3,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","sourceNew":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    if (fields == null) {\n      msg(infoStream, \"OK [no fields/terms]\");\n      return status;\n    }\n    \n    DocsEnum docs = null;\n    DocsEnum docsAndFreqs = null;\n    DocsAndPositionsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (!fieldInfo.isIndexed()) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      // term vectors cannot omit TF\n      final boolean hasFreqs = isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0;\n\n      final TermsEnum termsEnum = terms.iterator(null);\n      \n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRef lastTerm = null;\n      \n      Comparator<BytesRef> termComp = terms.getComparator();\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = BytesRef.deepCopyOf(term);\n        } else {\n          if (termComp.compare(lastTerm, term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.docs(liveDocs, docs);\n        postings = termsEnum.docsAndPositions(liveDocs, postings);\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final DocsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.docsAndPositions(liveDocs, postings);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        }\n      }\n      \n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        if (fieldTerms instanceof BlockTreeTermsReader.FieldReader) {\n          final BlockTreeTermsReader.Stats stats = ((BlockTreeTermsReader.FieldReader) fieldTerms).computeStats();\n          assert stats != null;\n          if (status.blockTreeStats == null) {\n            status.blockTreeStats = new HashMap<String,BlockTreeTermsReader.Stats>();\n          }\n          status.blockTreeStats.put(field, stats);\n        }\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          DocsEnum d = termsEnum.docs(null, null, DocsEnum.FLAG_NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, \"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String,BlockTreeTermsReader.Stats> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    if (fields == null) {\n      msg(infoStream, \"OK [no fields/terms]\");\n      return status;\n    }\n    \n    DocsEnum docs = null;\n    DocsEnum docsAndFreqs = null;\n    DocsAndPositionsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (!fieldInfo.isIndexed()) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      // term vectors cannot omit TF\n      final boolean hasFreqs = isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0;\n\n      final TermsEnum termsEnum = terms.iterator(null);\n      \n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRef lastTerm = null;\n      \n      Comparator<BytesRef> termComp = terms.getComparator();\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = BytesRef.deepCopyOf(term);\n        } else {\n          if (termComp.compare(lastTerm, term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.docs(liveDocs, docs);\n        postings = termsEnum.docsAndPositions(liveDocs, postings);\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final DocsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.docsAndPositions(liveDocs, postings);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        }\n      }\n      \n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        if (fieldTerms instanceof BlockTreeTermsReader.FieldReader) {\n          final BlockTreeTermsReader.Stats stats = ((BlockTreeTermsReader.FieldReader) fieldTerms).computeStats();\n          assert stats != null;\n          if (status.blockTreeStats == null) {\n            status.blockTreeStats = new HashMap<String,BlockTreeTermsReader.Stats>();\n          }\n          status.blockTreeStats.put(field, stats);\n        }\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          DocsEnum d = termsEnum.docs(null, null, DocsEnum.FLAG_NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i], true)) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, \"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String,BlockTreeTermsReader.Stats> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"519bac5f6a2dc1779d2fe8e51d9e1762ec94b4a5","date":1379624229,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","sourceNew":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    if (fields == null) {\n      msg(infoStream, \"OK [no fields/terms]\");\n      return status;\n    }\n    \n    DocsEnum docs = null;\n    DocsEnum docsAndFreqs = null;\n    DocsAndPositionsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (!fieldInfo.isIndexed()) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      // term vectors cannot omit TF\n      final boolean hasFreqs = isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0;\n\n      final TermsEnum termsEnum = terms.iterator(null);\n      \n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRef lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = BytesRef.deepCopyOf(term);\n        } else {\n          if (lastTerm.compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.docs(liveDocs, docs);\n        postings = termsEnum.docsAndPositions(liveDocs, postings);\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final DocsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.docsAndPositions(liveDocs, postings);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        }\n      }\n      \n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        if (fieldTerms instanceof BlockTreeTermsReader.FieldReader) {\n          final BlockTreeTermsReader.Stats stats = ((BlockTreeTermsReader.FieldReader) fieldTerms).computeStats();\n          assert stats != null;\n          if (status.blockTreeStats == null) {\n            status.blockTreeStats = new HashMap<String,BlockTreeTermsReader.Stats>();\n          }\n          status.blockTreeStats.put(field, stats);\n        }\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          DocsEnum d = termsEnum.docs(null, null, DocsEnum.FLAG_NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, \"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String,BlockTreeTermsReader.Stats> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    if (fields == null) {\n      msg(infoStream, \"OK [no fields/terms]\");\n      return status;\n    }\n    \n    DocsEnum docs = null;\n    DocsEnum docsAndFreqs = null;\n    DocsAndPositionsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (!fieldInfo.isIndexed()) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      // term vectors cannot omit TF\n      final boolean hasFreqs = isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0;\n\n      final TermsEnum termsEnum = terms.iterator(null);\n      \n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRef lastTerm = null;\n      \n      Comparator<BytesRef> termComp = terms.getComparator();\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = BytesRef.deepCopyOf(term);\n        } else {\n          if (termComp.compare(lastTerm, term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.docs(liveDocs, docs);\n        postings = termsEnum.docsAndPositions(liveDocs, postings);\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final DocsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.docsAndPositions(liveDocs, postings);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        }\n      }\n      \n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        if (fieldTerms instanceof BlockTreeTermsReader.FieldReader) {\n          final BlockTreeTermsReader.Stats stats = ((BlockTreeTermsReader.FieldReader) fieldTerms).computeStats();\n          assert stats != null;\n          if (status.blockTreeStats == null) {\n            status.blockTreeStats = new HashMap<String,BlockTreeTermsReader.Stats>();\n          }\n          status.blockTreeStats.put(field, stats);\n        }\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          DocsEnum d = termsEnum.docs(null, null, DocsEnum.FLAG_NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, \"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String,BlockTreeTermsReader.Stats> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50","7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50","7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50","7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50","7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"34bbd0c9efc37fd35a3ffdb47172aaebf7ab06db","date":1381416174,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","sourceNew":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    if (fields == null) {\n      msg(infoStream, \"OK [no fields/terms]\");\n      return status;\n    }\n    \n    DocsEnum docs = null;\n    DocsEnum docsAndFreqs = null;\n    DocsAndPositionsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (!fieldInfo.isIndexed()) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n      \n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRef lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = BytesRef.deepCopyOf(term);\n        } else {\n          if (lastTerm.compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.docs(liveDocs, docs);\n        postings = termsEnum.docsAndPositions(liveDocs, postings);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final DocsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (docs2.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.docsAndPositions(liveDocs, postings);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        }\n      }\n      \n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        if (fieldTerms instanceof BlockTreeTermsReader.FieldReader) {\n          final BlockTreeTermsReader.Stats stats = ((BlockTreeTermsReader.FieldReader) fieldTerms).computeStats();\n          assert stats != null;\n          if (status.blockTreeStats == null) {\n            status.blockTreeStats = new HashMap<String,BlockTreeTermsReader.Stats>();\n          }\n          status.blockTreeStats.put(field, stats);\n        }\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          DocsEnum d = termsEnum.docs(null, null, DocsEnum.FLAG_NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, \"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String,BlockTreeTermsReader.Stats> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    if (fields == null) {\n      msg(infoStream, \"OK [no fields/terms]\");\n      return status;\n    }\n    \n    DocsEnum docs = null;\n    DocsEnum docsAndFreqs = null;\n    DocsAndPositionsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (!fieldInfo.isIndexed()) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      // term vectors cannot omit TF\n      final boolean hasFreqs = isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0;\n\n      final TermsEnum termsEnum = terms.iterator(null);\n      \n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRef lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = BytesRef.deepCopyOf(term);\n        } else {\n          if (lastTerm.compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.docs(liveDocs, docs);\n        postings = termsEnum.docsAndPositions(liveDocs, postings);\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final DocsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.docsAndPositions(liveDocs, postings);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        }\n      }\n      \n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        if (fieldTerms instanceof BlockTreeTermsReader.FieldReader) {\n          final BlockTreeTermsReader.Stats stats = ((BlockTreeTermsReader.FieldReader) fieldTerms).computeStats();\n          assert stats != null;\n          if (status.blockTreeStats == null) {\n            status.blockTreeStats = new HashMap<String,BlockTreeTermsReader.Stats>();\n          }\n          status.blockTreeStats.put(field, stats);\n        }\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          DocsEnum d = termsEnum.docs(null, null, DocsEnum.FLAG_NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, \"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String,BlockTreeTermsReader.Stats> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","sourceNew":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    if (fields == null) {\n      msg(infoStream, \"OK [no fields/terms]\");\n      return status;\n    }\n    \n    DocsEnum docs = null;\n    DocsEnum docsAndFreqs = null;\n    DocsAndPositionsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (!fieldInfo.isIndexed()) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n      \n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRef lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = BytesRef.deepCopyOf(term);\n        } else {\n          if (lastTerm.compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.docs(liveDocs, docs);\n        postings = termsEnum.docsAndPositions(liveDocs, postings);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final DocsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (docs2.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.docsAndPositions(liveDocs, postings);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        }\n      }\n      \n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        if (fieldTerms instanceof BlockTreeTermsReader.FieldReader) {\n          final BlockTreeTermsReader.Stats stats = ((BlockTreeTermsReader.FieldReader) fieldTerms).computeStats();\n          assert stats != null;\n          if (status.blockTreeStats == null) {\n            status.blockTreeStats = new HashMap<>();\n          }\n          status.blockTreeStats.put(field, stats);\n        }\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          DocsEnum d = termsEnum.docs(null, null, DocsEnum.FLAG_NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, \"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String,BlockTreeTermsReader.Stats> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    if (fields == null) {\n      msg(infoStream, \"OK [no fields/terms]\");\n      return status;\n    }\n    \n    DocsEnum docs = null;\n    DocsEnum docsAndFreqs = null;\n    DocsAndPositionsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (!fieldInfo.isIndexed()) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n      \n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRef lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = BytesRef.deepCopyOf(term);\n        } else {\n          if (lastTerm.compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.docs(liveDocs, docs);\n        postings = termsEnum.docsAndPositions(liveDocs, postings);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final DocsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (docs2.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.docsAndPositions(liveDocs, postings);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        }\n      }\n      \n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        if (fieldTerms instanceof BlockTreeTermsReader.FieldReader) {\n          final BlockTreeTermsReader.Stats stats = ((BlockTreeTermsReader.FieldReader) fieldTerms).computeStats();\n          assert stats != null;\n          if (status.blockTreeStats == null) {\n            status.blockTreeStats = new HashMap<String,BlockTreeTermsReader.Stats>();\n          }\n          status.blockTreeStats.put(field, stats);\n        }\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          DocsEnum d = termsEnum.docs(null, null, DocsEnum.FLAG_NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, \"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String,BlockTreeTermsReader.Stats> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0974f33be0e2189e71f36b67f1017f4072b1a126","date":1398347867,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","sourceNew":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    if (fields == null) {\n      msg(infoStream, \"OK [no fields/terms]\");\n      return status;\n    }\n    \n    DocsEnum docs = null;\n    DocsEnum docsAndFreqs = null;\n    DocsAndPositionsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (!fieldInfo.isIndexed()) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef bb = terms.getMin();\n      assert bb.isValid();\n      final BytesRef minTerm = bb == null ? null : BytesRef.deepCopyOf(bb);\n      \n      bb = terms.getMax();\n      assert bb.isValid();\n      final BytesRef maxTerm = bb == null ? null : BytesRef.deepCopyOf(bb);\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n      \n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRef lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = BytesRef.deepCopyOf(term);\n        } else {\n          if (lastTerm.compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n        \n        if (term.compareTo(minTerm) < 0) {\n          throw new RuntimeException(\"invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(maxTerm) > 0) {\n          throw new RuntimeException(\"invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.docs(liveDocs, docs);\n        postings = termsEnum.docsAndPositions(liveDocs, postings);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final DocsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (docs2.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.docsAndPositions(liveDocs, postings);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        }\n      }\n      \n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        if (fieldTerms instanceof BlockTreeTermsReader.FieldReader) {\n          final BlockTreeTermsReader.Stats stats = ((BlockTreeTermsReader.FieldReader) fieldTerms).computeStats();\n          assert stats != null;\n          if (status.blockTreeStats == null) {\n            status.blockTreeStats = new HashMap<>();\n          }\n          status.blockTreeStats.put(field, stats);\n        }\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          DocsEnum d = termsEnum.docs(null, null, DocsEnum.FLAG_NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, \"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String,BlockTreeTermsReader.Stats> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    if (fields == null) {\n      msg(infoStream, \"OK [no fields/terms]\");\n      return status;\n    }\n    \n    DocsEnum docs = null;\n    DocsEnum docsAndFreqs = null;\n    DocsAndPositionsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (!fieldInfo.isIndexed()) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n      \n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRef lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = BytesRef.deepCopyOf(term);\n        } else {\n          if (lastTerm.compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.docs(liveDocs, docs);\n        postings = termsEnum.docsAndPositions(liveDocs, postings);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final DocsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (docs2.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.docsAndPositions(liveDocs, postings);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        }\n      }\n      \n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        if (fieldTerms instanceof BlockTreeTermsReader.FieldReader) {\n          final BlockTreeTermsReader.Stats stats = ((BlockTreeTermsReader.FieldReader) fieldTerms).computeStats();\n          assert stats != null;\n          if (status.blockTreeStats == null) {\n            status.blockTreeStats = new HashMap<>();\n          }\n          status.blockTreeStats.put(field, stats);\n        }\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          DocsEnum d = termsEnum.docs(null, null, DocsEnum.FLAG_NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, \"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String,BlockTreeTermsReader.Stats> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":["6b64ceb507ba9aa71920c0bfad91032e2c03d42f","6b64ceb507ba9aa71920c0bfad91032e2c03d42f","6b64ceb507ba9aa71920c0bfad91032e2c03d42f","6b64ceb507ba9aa71920c0bfad91032e2c03d42f","6b64ceb507ba9aa71920c0bfad91032e2c03d42f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f890447ef156e598bffbdc5aab15a68b458c3612","date":1398350662,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","sourceNew":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    if (fields == null) {\n      msg(infoStream, \"OK [no fields/terms]\");\n      return status;\n    }\n    \n    DocsEnum docs = null;\n    DocsEnum docsAndFreqs = null;\n    DocsAndPositionsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (!fieldInfo.isIndexed()) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef bb = terms.getMin();\n      BytesRef minTerm;\n      if (bb != null) {\n        assert bb.isValid();\n        minTerm = BytesRef.deepCopyOf(bb);\n      } else {\n        minTerm = null;\n      }\n\n      BytesRef maxTerm;\n      bb = terms.getMax();\n      if (bb != null) {\n        assert bb.isValid();\n        maxTerm = BytesRef.deepCopyOf(bb);\n        if (minTerm == null) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n        }\n      } else {\n        maxTerm = null;\n        if (minTerm != null) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n      \n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRef lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = BytesRef.deepCopyOf(term);\n        } else {\n          if (lastTerm.compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n        \n        if (minTerm == null) {\n          // We checked this above:\n          assert maxTerm == null;\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(minTerm) < 0) {\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(maxTerm) > 0) {\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.docs(liveDocs, docs);\n        postings = termsEnum.docsAndPositions(liveDocs, postings);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final DocsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (docs2.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.docsAndPositions(liveDocs, postings);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        if (fieldTerms instanceof BlockTreeTermsReader.FieldReader) {\n          final BlockTreeTermsReader.Stats stats = ((BlockTreeTermsReader.FieldReader) fieldTerms).computeStats();\n          assert stats != null;\n          if (status.blockTreeStats == null) {\n            status.blockTreeStats = new HashMap<>();\n          }\n          status.blockTreeStats.put(field, stats);\n        }\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          DocsEnum d = termsEnum.docs(null, null, DocsEnum.FLAG_NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, \"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String,BlockTreeTermsReader.Stats> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    if (fields == null) {\n      msg(infoStream, \"OK [no fields/terms]\");\n      return status;\n    }\n    \n    DocsEnum docs = null;\n    DocsEnum docsAndFreqs = null;\n    DocsAndPositionsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (!fieldInfo.isIndexed()) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef bb = terms.getMin();\n      assert bb.isValid();\n      final BytesRef minTerm = bb == null ? null : BytesRef.deepCopyOf(bb);\n      \n      bb = terms.getMax();\n      assert bb.isValid();\n      final BytesRef maxTerm = bb == null ? null : BytesRef.deepCopyOf(bb);\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n      \n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRef lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = BytesRef.deepCopyOf(term);\n        } else {\n          if (lastTerm.compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n        \n        if (term.compareTo(minTerm) < 0) {\n          throw new RuntimeException(\"invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(maxTerm) > 0) {\n          throw new RuntimeException(\"invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.docs(liveDocs, docs);\n        postings = termsEnum.docsAndPositions(liveDocs, postings);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final DocsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (docs2.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.docsAndPositions(liveDocs, postings);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        }\n      }\n      \n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        if (fieldTerms instanceof BlockTreeTermsReader.FieldReader) {\n          final BlockTreeTermsReader.Stats stats = ((BlockTreeTermsReader.FieldReader) fieldTerms).computeStats();\n          assert stats != null;\n          if (status.blockTreeStats == null) {\n            status.blockTreeStats = new HashMap<>();\n          }\n          status.blockTreeStats.put(field, stats);\n        }\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          DocsEnum d = termsEnum.docs(null, null, DocsEnum.FLAG_NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, \"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String,BlockTreeTermsReader.Stats> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":["6b64ceb507ba9aa71920c0bfad91032e2c03d42f","6b64ceb507ba9aa71920c0bfad91032e2c03d42f","6b64ceb507ba9aa71920c0bfad91032e2c03d42f","6b64ceb507ba9aa71920c0bfad91032e2c03d42f","6b64ceb507ba9aa71920c0bfad91032e2c03d42f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c0cd85fde84cb318b4dc97710dcf15e2959a1bbe","date":1398844771,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","sourceNew":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    if (fields == null) {\n      msg(infoStream, \"OK [no fields/terms]\");\n      return status;\n    }\n    \n    DocsEnum docs = null;\n    DocsEnum docsAndFreqs = null;\n    DocsAndPositionsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (!fieldInfo.isIndexed()) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef bb = terms.getMin();\n      BytesRef minTerm;\n      if (bb != null) {\n        assert bb.isValid();\n        minTerm = BytesRef.deepCopyOf(bb);\n      } else {\n        minTerm = null;\n      }\n\n      BytesRef maxTerm;\n      bb = terms.getMax();\n      if (bb != null) {\n        assert bb.isValid();\n        maxTerm = BytesRef.deepCopyOf(bb);\n        if (minTerm == null) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n        }\n      } else {\n        maxTerm = null;\n        if (minTerm != null) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n      \n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRef lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = BytesRef.deepCopyOf(term);\n        } else {\n          if (lastTerm.compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n        \n        if (minTerm == null) {\n          // We checked this above:\n          assert maxTerm == null;\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(minTerm) < 0) {\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(maxTerm) > 0) {\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.docs(liveDocs, docs);\n        postings = termsEnum.docsAndPositions(liveDocs, postings);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final DocsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (docs2.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.docsAndPositions(liveDocs, postings);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        if (fieldTerms instanceof BlockTreeTermsReader.FieldReader) {\n          final BlockTreeTermsReader.Stats stats = ((BlockTreeTermsReader.FieldReader) fieldTerms).computeStats();\n          assert stats != null;\n          if (status.blockTreeStats == null) {\n            status.blockTreeStats = new HashMap<>();\n          }\n          status.blockTreeStats.put(field, stats);\n        }\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          DocsEnum d = termsEnum.docs(null, null, DocsEnum.FLAG_NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, \"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String,BlockTreeTermsReader.Stats> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    if (fields == null) {\n      msg(infoStream, \"OK [no fields/terms]\");\n      return status;\n    }\n    \n    DocsEnum docs = null;\n    DocsEnum docsAndFreqs = null;\n    DocsAndPositionsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (!fieldInfo.isIndexed()) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n      \n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRef lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = BytesRef.deepCopyOf(term);\n        } else {\n          if (lastTerm.compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.docs(liveDocs, docs);\n        postings = termsEnum.docsAndPositions(liveDocs, postings);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final DocsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (docs2.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.docsAndPositions(liveDocs, postings);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        }\n      }\n      \n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        if (fieldTerms instanceof BlockTreeTermsReader.FieldReader) {\n          final BlockTreeTermsReader.Stats stats = ((BlockTreeTermsReader.FieldReader) fieldTerms).computeStats();\n          assert stats != null;\n          if (status.blockTreeStats == null) {\n            status.blockTreeStats = new HashMap<>();\n          }\n          status.blockTreeStats.put(field, stats);\n        }\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          DocsEnum d = termsEnum.docs(null, null, DocsEnum.FLAG_NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, \"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String,BlockTreeTermsReader.Stats> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5ad80176d91a6f70fe93880e43dfd697dc4e63ed","date":1400176913,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","sourceNew":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    if (fields == null) {\n      msg(infoStream, \"OK [no fields/terms]\");\n      return status;\n    }\n    \n    DocsEnum docs = null;\n    DocsEnum docsAndFreqs = null;\n    DocsAndPositionsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (!fieldInfo.isIndexed()) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef bb = terms.getMin();\n      BytesRef minTerm;\n      if (bb != null) {\n        assert bb.isValid();\n        minTerm = BytesRef.deepCopyOf(bb);\n      } else {\n        minTerm = null;\n      }\n\n      BytesRef maxTerm;\n      bb = terms.getMax();\n      if (bb != null) {\n        assert bb.isValid();\n        maxTerm = BytesRef.deepCopyOf(bb);\n        if (minTerm == null) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n        }\n      } else {\n        maxTerm = null;\n        if (minTerm != null) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n      \n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRef lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = BytesRef.deepCopyOf(term);\n        } else {\n          if (lastTerm.compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n        \n        if (minTerm == null) {\n          // We checked this above:\n          assert maxTerm == null;\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(minTerm) < 0) {\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(maxTerm) > 0) {\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.docs(liveDocs, docs);\n        postings = termsEnum.docsAndPositions(liveDocs, postings);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final DocsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (docs2.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.docsAndPositions(liveDocs, postings);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        if (fieldTerms instanceof BlockTreeTermsReader.FieldReader) {\n          final Stats stats = ((BlockTreeTermsReader.FieldReader) fieldTerms).computeStats();\n          assert stats != null;\n          if (status.blockTreeStats == null) {\n            status.blockTreeStats = new HashMap<>();\n          }\n          status.blockTreeStats.put(field, stats);\n        }\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          DocsEnum d = termsEnum.docs(null, null, DocsEnum.FLAG_NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, \"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String,Stats> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    if (fields == null) {\n      msg(infoStream, \"OK [no fields/terms]\");\n      return status;\n    }\n    \n    DocsEnum docs = null;\n    DocsEnum docsAndFreqs = null;\n    DocsAndPositionsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (!fieldInfo.isIndexed()) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef bb = terms.getMin();\n      BytesRef minTerm;\n      if (bb != null) {\n        assert bb.isValid();\n        minTerm = BytesRef.deepCopyOf(bb);\n      } else {\n        minTerm = null;\n      }\n\n      BytesRef maxTerm;\n      bb = terms.getMax();\n      if (bb != null) {\n        assert bb.isValid();\n        maxTerm = BytesRef.deepCopyOf(bb);\n        if (minTerm == null) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n        }\n      } else {\n        maxTerm = null;\n        if (minTerm != null) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n      \n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRef lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = BytesRef.deepCopyOf(term);\n        } else {\n          if (lastTerm.compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n        \n        if (minTerm == null) {\n          // We checked this above:\n          assert maxTerm == null;\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(minTerm) < 0) {\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(maxTerm) > 0) {\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.docs(liveDocs, docs);\n        postings = termsEnum.docsAndPositions(liveDocs, postings);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final DocsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (docs2.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.docsAndPositions(liveDocs, postings);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        if (fieldTerms instanceof BlockTreeTermsReader.FieldReader) {\n          final BlockTreeTermsReader.Stats stats = ((BlockTreeTermsReader.FieldReader) fieldTerms).computeStats();\n          assert stats != null;\n          if (status.blockTreeStats == null) {\n            status.blockTreeStats = new HashMap<>();\n          }\n          status.blockTreeStats.put(field, stats);\n        }\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          DocsEnum d = termsEnum.docs(null, null, DocsEnum.FLAG_NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, \"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String,BlockTreeTermsReader.Stats> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"47d9d581b0b317125672636196fa3c73bbcabc56","date":1400178129,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","sourceNew":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    if (fields == null) {\n      msg(infoStream, \"OK [no fields/terms]\");\n      return status;\n    }\n    \n    DocsEnum docs = null;\n    DocsEnum docsAndFreqs = null;\n    DocsAndPositionsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (!fieldInfo.isIndexed()) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef bb = terms.getMin();\n      BytesRef minTerm;\n      if (bb != null) {\n        assert bb.isValid();\n        minTerm = BytesRef.deepCopyOf(bb);\n      } else {\n        minTerm = null;\n      }\n\n      BytesRef maxTerm;\n      bb = terms.getMax();\n      if (bb != null) {\n        assert bb.isValid();\n        maxTerm = BytesRef.deepCopyOf(bb);\n        if (minTerm == null) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n        }\n      } else {\n        maxTerm = null;\n        if (minTerm != null) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n      \n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRef lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = BytesRef.deepCopyOf(term);\n        } else {\n          if (lastTerm.compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n        \n        if (minTerm == null) {\n          // We checked this above:\n          assert maxTerm == null;\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(minTerm) < 0) {\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(maxTerm) > 0) {\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.docs(liveDocs, docs);\n        postings = termsEnum.docsAndPositions(liveDocs, postings);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final DocsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (docs2.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.docsAndPositions(liveDocs, postings);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        if (fieldTerms instanceof FieldReader) {\n          final Stats stats = ((FieldReader) fieldTerms).computeStats();\n          assert stats != null;\n          if (status.blockTreeStats == null) {\n            status.blockTreeStats = new HashMap<>();\n          }\n          status.blockTreeStats.put(field, stats);\n        }\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          DocsEnum d = termsEnum.docs(null, null, DocsEnum.FLAG_NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, \"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String,Stats> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    if (fields == null) {\n      msg(infoStream, \"OK [no fields/terms]\");\n      return status;\n    }\n    \n    DocsEnum docs = null;\n    DocsEnum docsAndFreqs = null;\n    DocsAndPositionsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (!fieldInfo.isIndexed()) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef bb = terms.getMin();\n      BytesRef minTerm;\n      if (bb != null) {\n        assert bb.isValid();\n        minTerm = BytesRef.deepCopyOf(bb);\n      } else {\n        minTerm = null;\n      }\n\n      BytesRef maxTerm;\n      bb = terms.getMax();\n      if (bb != null) {\n        assert bb.isValid();\n        maxTerm = BytesRef.deepCopyOf(bb);\n        if (minTerm == null) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n        }\n      } else {\n        maxTerm = null;\n        if (minTerm != null) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n      \n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRef lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = BytesRef.deepCopyOf(term);\n        } else {\n          if (lastTerm.compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n        \n        if (minTerm == null) {\n          // We checked this above:\n          assert maxTerm == null;\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(minTerm) < 0) {\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(maxTerm) > 0) {\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.docs(liveDocs, docs);\n        postings = termsEnum.docsAndPositions(liveDocs, postings);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final DocsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (docs2.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.docsAndPositions(liveDocs, postings);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        if (fieldTerms instanceof BlockTreeTermsReader.FieldReader) {\n          final Stats stats = ((BlockTreeTermsReader.FieldReader) fieldTerms).computeStats();\n          assert stats != null;\n          if (status.blockTreeStats == null) {\n            status.blockTreeStats = new HashMap<>();\n          }\n          status.blockTreeStats.put(field, stats);\n        }\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          DocsEnum d = termsEnum.docs(null, null, DocsEnum.FLAG_NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, \"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String,Stats> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4d637064d608752565d4f9f41b2497dfdfdde50e","date":1400798123,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","sourceNew":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    if (fields == null) {\n      msg(infoStream, \"OK [no fields/terms]\");\n      return status;\n    }\n    \n    DocsEnum docs = null;\n    DocsEnum docsAndFreqs = null;\n    DocsAndPositionsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (!fieldInfo.isIndexed()) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef bb = terms.getMin();\n      BytesRef minTerm;\n      if (bb != null) {\n        assert bb.isValid();\n        minTerm = BytesRef.deepCopyOf(bb);\n      } else {\n        minTerm = null;\n      }\n\n      BytesRef maxTerm;\n      bb = terms.getMax();\n      if (bb != null) {\n        assert bb.isValid();\n        maxTerm = BytesRef.deepCopyOf(bb);\n        if (minTerm == null) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n        }\n      } else {\n        maxTerm = null;\n        if (minTerm != null) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n      \n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRef lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = BytesRef.deepCopyOf(term);\n        } else {\n          if (lastTerm.compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n        \n        if (minTerm == null) {\n          // We checked this above:\n          assert maxTerm == null;\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(minTerm) < 0) {\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(maxTerm) > 0) {\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.docs(liveDocs, docs);\n        postings = termsEnum.docsAndPositions(liveDocs, postings);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final DocsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (docs2.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.docsAndPositions(liveDocs, postings);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        if (fieldTerms instanceof FieldReader) {\n          final Stats stats = ((FieldReader) fieldTerms).computeStats();\n          assert stats != null;\n          if (status.blockTreeStats == null) {\n            status.blockTreeStats = new HashMap<>();\n          }\n          status.blockTreeStats.put(field, stats);\n        }\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          DocsEnum d = termsEnum.docs(null, null, DocsEnum.FLAG_NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, \"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String,Stats> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    if (fields == null) {\n      msg(infoStream, \"OK [no fields/terms]\");\n      return status;\n    }\n    \n    DocsEnum docs = null;\n    DocsEnum docsAndFreqs = null;\n    DocsAndPositionsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (!fieldInfo.isIndexed()) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef bb = terms.getMin();\n      BytesRef minTerm;\n      if (bb != null) {\n        assert bb.isValid();\n        minTerm = BytesRef.deepCopyOf(bb);\n      } else {\n        minTerm = null;\n      }\n\n      BytesRef maxTerm;\n      bb = terms.getMax();\n      if (bb != null) {\n        assert bb.isValid();\n        maxTerm = BytesRef.deepCopyOf(bb);\n        if (minTerm == null) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n        }\n      } else {\n        maxTerm = null;\n        if (minTerm != null) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n      \n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRef lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = BytesRef.deepCopyOf(term);\n        } else {\n          if (lastTerm.compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n        \n        if (minTerm == null) {\n          // We checked this above:\n          assert maxTerm == null;\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(minTerm) < 0) {\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(maxTerm) > 0) {\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.docs(liveDocs, docs);\n        postings = termsEnum.docsAndPositions(liveDocs, postings);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final DocsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (docs2.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.docsAndPositions(liveDocs, postings);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        if (fieldTerms instanceof BlockTreeTermsReader.FieldReader) {\n          final BlockTreeTermsReader.Stats stats = ((BlockTreeTermsReader.FieldReader) fieldTerms).computeStats();\n          assert stats != null;\n          if (status.blockTreeStats == null) {\n            status.blockTreeStats = new HashMap<>();\n          }\n          status.blockTreeStats.put(field, stats);\n        }\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          DocsEnum d = termsEnum.docs(null, null, DocsEnum.FLAG_NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, \"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String,BlockTreeTermsReader.Stats> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0cdf9cc6702d60334a616bd7db3ae91501d1dce7","date":1405858112,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","sourceNew":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    if (fields == null) {\n      msg(infoStream, \"OK [no fields/terms]\");\n      return status;\n    }\n    \n    DocsEnum docs = null;\n    DocsEnum docsAndFreqs = null;\n    DocsAndPositionsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (!fieldInfo.isIndexed()) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef bb = terms.getMin();\n      BytesRef minTerm;\n      if (bb != null) {\n        assert bb.isValid();\n        minTerm = BytesRef.deepCopyOf(bb);\n      } else {\n        minTerm = null;\n      }\n\n      BytesRef maxTerm;\n      bb = terms.getMax();\n      if (bb != null) {\n        assert bb.isValid();\n        maxTerm = BytesRef.deepCopyOf(bb);\n        if (minTerm == null) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n        }\n      } else {\n        maxTerm = null;\n        if (minTerm != null) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n      \n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRef lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      long upto = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n\n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = BytesRef.deepCopyOf(term);\n        } else {\n          if (lastTerm.compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n        \n        if (minTerm == null) {\n          // We checked this above:\n          assert maxTerm == null;\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(minTerm) < 0) {\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(maxTerm) > 0) {\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.docs(liveDocs, docs);\n        postings = termsEnum.docsAndPositions(liveDocs, postings);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final DocsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (docs2.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.docsAndPositions(liveDocs, postings);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        if (fieldTerms instanceof FieldReader) {\n          final Stats stats = ((FieldReader) fieldTerms).computeStats();\n          assert stats != null;\n          if (status.blockTreeStats == null) {\n            status.blockTreeStats = new HashMap<>();\n          }\n          status.blockTreeStats.put(field, stats);\n        }\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          DocsEnum d = termsEnum.docs(null, null, DocsEnum.FLAG_NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, \"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String,Stats> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    if (fields == null) {\n      msg(infoStream, \"OK [no fields/terms]\");\n      return status;\n    }\n    \n    DocsEnum docs = null;\n    DocsEnum docsAndFreqs = null;\n    DocsAndPositionsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (!fieldInfo.isIndexed()) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef bb = terms.getMin();\n      BytesRef minTerm;\n      if (bb != null) {\n        assert bb.isValid();\n        minTerm = BytesRef.deepCopyOf(bb);\n      } else {\n        minTerm = null;\n      }\n\n      BytesRef maxTerm;\n      bb = terms.getMax();\n      if (bb != null) {\n        assert bb.isValid();\n        maxTerm = BytesRef.deepCopyOf(bb);\n        if (minTerm == null) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n        }\n      } else {\n        maxTerm = null;\n        if (minTerm != null) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n      \n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRef lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = BytesRef.deepCopyOf(term);\n        } else {\n          if (lastTerm.compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n        \n        if (minTerm == null) {\n          // We checked this above:\n          assert maxTerm == null;\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(minTerm) < 0) {\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(maxTerm) > 0) {\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.docs(liveDocs, docs);\n        postings = termsEnum.docsAndPositions(liveDocs, postings);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final DocsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (docs2.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.docsAndPositions(liveDocs, postings);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        if (fieldTerms instanceof FieldReader) {\n          final Stats stats = ((FieldReader) fieldTerms).computeStats();\n          assert stats != null;\n          if (status.blockTreeStats == null) {\n            status.blockTreeStats = new HashMap<>();\n          }\n          status.blockTreeStats.put(field, stats);\n        }\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          DocsEnum d = termsEnum.docs(null, null, DocsEnum.FLAG_NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, \"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String,Stats> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50","date":1407854805,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","sourceNew":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    if (fields == null) {\n      msg(infoStream, \"OK [no fields/terms]\");\n      return status;\n    }\n    \n    DocsEnum docs = null;\n    DocsEnum docsAndFreqs = null;\n    DocsAndPositionsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (!fieldInfo.isIndexed()) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef bb = terms.getMin();\n      BytesRef minTerm;\n      if (bb != null) {\n        assert bb.isValid();\n        minTerm = BytesRef.deepCopyOf(bb);\n      } else {\n        minTerm = null;\n      }\n\n      BytesRef maxTerm;\n      bb = terms.getMax();\n      if (bb != null) {\n        assert bb.isValid();\n        maxTerm = BytesRef.deepCopyOf(bb);\n        if (minTerm == null) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n        }\n      } else {\n        maxTerm = null;\n        if (minTerm != null) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n      \n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      long upto = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n\n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n        \n        if (minTerm == null) {\n          // We checked this above:\n          assert maxTerm == null;\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(minTerm) < 0) {\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(maxTerm) > 0) {\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.docs(liveDocs, docs);\n        postings = termsEnum.docsAndPositions(liveDocs, postings);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final DocsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (docs2.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.docsAndPositions(liveDocs, postings);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        if (fieldTerms instanceof FieldReader) {\n          final Stats stats = ((FieldReader) fieldTerms).computeStats();\n          assert stats != null;\n          if (status.blockTreeStats == null) {\n            status.blockTreeStats = new HashMap<>();\n          }\n          status.blockTreeStats.put(field, stats);\n        }\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          DocsEnum d = termsEnum.docs(null, null, DocsEnum.FLAG_NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, \"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String,Stats> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    if (fields == null) {\n      msg(infoStream, \"OK [no fields/terms]\");\n      return status;\n    }\n    \n    DocsEnum docs = null;\n    DocsEnum docsAndFreqs = null;\n    DocsAndPositionsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (!fieldInfo.isIndexed()) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef bb = terms.getMin();\n      BytesRef minTerm;\n      if (bb != null) {\n        assert bb.isValid();\n        minTerm = BytesRef.deepCopyOf(bb);\n      } else {\n        minTerm = null;\n      }\n\n      BytesRef maxTerm;\n      bb = terms.getMax();\n      if (bb != null) {\n        assert bb.isValid();\n        maxTerm = BytesRef.deepCopyOf(bb);\n        if (minTerm == null) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n        }\n      } else {\n        maxTerm = null;\n        if (minTerm != null) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n      \n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRef lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      long upto = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n\n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = BytesRef.deepCopyOf(term);\n        } else {\n          if (lastTerm.compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n        \n        if (minTerm == null) {\n          // We checked this above:\n          assert maxTerm == null;\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(minTerm) < 0) {\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(maxTerm) > 0) {\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.docs(liveDocs, docs);\n        postings = termsEnum.docsAndPositions(liveDocs, postings);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final DocsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (docs2.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.docsAndPositions(liveDocs, postings);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        if (fieldTerms instanceof FieldReader) {\n          final Stats stats = ((FieldReader) fieldTerms).computeStats();\n          assert stats != null;\n          if (status.blockTreeStats == null) {\n            status.blockTreeStats = new HashMap<>();\n          }\n          status.blockTreeStats.put(field, stats);\n        }\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          DocsEnum d = termsEnum.docs(null, null, DocsEnum.FLAG_NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, \"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String,Stats> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":["519bac5f6a2dc1779d2fe8e51d9e1762ec94b4a5","b13ebda0f2c83525d118f4859e46eb3bd87ced36"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0628077afea69a2955260949478afabab8e500d8","date":1413915332,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","sourceNew":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    if (fields == null) {\n      msg(infoStream, \"OK [no fields/terms]\");\n      return status;\n    }\n    \n    DocsEnum docs = null;\n    DocsEnum docsAndFreqs = null;\n    DocsAndPositionsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (!fieldInfo.isIndexed()) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef bb = terms.getMin();\n      BytesRef minTerm;\n      if (bb != null) {\n        assert bb.isValid();\n        minTerm = BytesRef.deepCopyOf(bb);\n      } else {\n        minTerm = null;\n      }\n\n      BytesRef maxTerm;\n      bb = terms.getMax();\n      if (bb != null) {\n        assert bb.isValid();\n        maxTerm = BytesRef.deepCopyOf(bb);\n        if (minTerm == null) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n        }\n      } else {\n        maxTerm = null;\n        if (minTerm != null) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n      \n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      long upto = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n\n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n        \n        if (minTerm == null) {\n          // We checked this above:\n          assert maxTerm == null;\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(minTerm) < 0) {\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(maxTerm) > 0) {\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.docs(liveDocs, docs);\n        postings = termsEnum.docsAndPositions(liveDocs, postings);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final DocsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (docs2.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.docsAndPositions(liveDocs, postings);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          DocsEnum d = termsEnum.docs(null, null, DocsEnum.FLAG_NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, \"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    if (fields == null) {\n      msg(infoStream, \"OK [no fields/terms]\");\n      return status;\n    }\n    \n    DocsEnum docs = null;\n    DocsEnum docsAndFreqs = null;\n    DocsAndPositionsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (!fieldInfo.isIndexed()) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef bb = terms.getMin();\n      BytesRef minTerm;\n      if (bb != null) {\n        assert bb.isValid();\n        minTerm = BytesRef.deepCopyOf(bb);\n      } else {\n        minTerm = null;\n      }\n\n      BytesRef maxTerm;\n      bb = terms.getMax();\n      if (bb != null) {\n        assert bb.isValid();\n        maxTerm = BytesRef.deepCopyOf(bb);\n        if (minTerm == null) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n        }\n      } else {\n        maxTerm = null;\n        if (minTerm != null) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n      \n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      long upto = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n\n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n        \n        if (minTerm == null) {\n          // We checked this above:\n          assert maxTerm == null;\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(minTerm) < 0) {\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(maxTerm) > 0) {\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.docs(liveDocs, docs);\n        postings = termsEnum.docsAndPositions(liveDocs, postings);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final DocsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (docs2.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.docsAndPositions(liveDocs, postings);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        if (fieldTerms instanceof FieldReader) {\n          final Stats stats = ((FieldReader) fieldTerms).computeStats();\n          assert stats != null;\n          if (status.blockTreeStats == null) {\n            status.blockTreeStats = new HashMap<>();\n          }\n          status.blockTreeStats.put(field, stats);\n        }\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          DocsEnum d = termsEnum.docs(null, null, DocsEnum.FLAG_NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, \"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String,Stats> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"db68c63cbfaa8698b9c4475f75ed2b9c9696d238","date":1414118621,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","sourceNew":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    if (fields == null) {\n      msg(infoStream, \"OK [no fields/terms]\");\n      return status;\n    }\n    \n    DocsEnum docs = null;\n    DocsEnum docsAndFreqs = null;\n    DocsAndPositionsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (!fieldInfo.isIndexed()) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef bb = terms.getMin();\n      BytesRef minTerm;\n      if (bb != null) {\n        assert bb.isValid();\n        minTerm = BytesRef.deepCopyOf(bb);\n      } else {\n        minTerm = null;\n      }\n\n      BytesRef maxTerm;\n      bb = terms.getMax();\n      if (bb != null) {\n        assert bb.isValid();\n        maxTerm = BytesRef.deepCopyOf(bb);\n        if (minTerm == null) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n        }\n      } else {\n        maxTerm = null;\n        if (minTerm != null) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n      \n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      long upto = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n\n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n        \n        if (minTerm == null) {\n          // We checked this above:\n          assert maxTerm == null;\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(minTerm) < 0) {\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(maxTerm) > 0) {\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.docs(liveDocs, docs);\n        postings = termsEnum.docsAndPositions(liveDocs, postings);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final DocsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (docs2.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.docsAndPositions(liveDocs, postings);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          DocsEnum d = termsEnum.docs(null, null, DocsEnum.FLAG_NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, \"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    if (fields == null) {\n      msg(infoStream, \"OK [no fields/terms]\");\n      return status;\n    }\n    \n    DocsEnum docs = null;\n    DocsEnum docsAndFreqs = null;\n    DocsAndPositionsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (!fieldInfo.isIndexed()) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef bb = terms.getMin();\n      BytesRef minTerm;\n      if (bb != null) {\n        assert bb.isValid();\n        minTerm = BytesRef.deepCopyOf(bb);\n      } else {\n        minTerm = null;\n      }\n\n      BytesRef maxTerm;\n      bb = terms.getMax();\n      if (bb != null) {\n        assert bb.isValid();\n        maxTerm = BytesRef.deepCopyOf(bb);\n        if (minTerm == null) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n        }\n      } else {\n        maxTerm = null;\n        if (minTerm != null) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n      \n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      long upto = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n\n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n        \n        if (minTerm == null) {\n          // We checked this above:\n          assert maxTerm == null;\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(minTerm) < 0) {\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(maxTerm) > 0) {\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.docs(liveDocs, docs);\n        postings = termsEnum.docsAndPositions(liveDocs, postings);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final DocsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (docs2.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.docsAndPositions(liveDocs, postings);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        if (fieldTerms instanceof FieldReader) {\n          final Stats stats = ((FieldReader) fieldTerms).computeStats();\n          assert stats != null;\n          if (status.blockTreeStats == null) {\n            status.blockTreeStats = new HashMap<>();\n          }\n          status.blockTreeStats.put(field, stats);\n        }\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          DocsEnum d = termsEnum.docs(null, null, DocsEnum.FLAG_NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, \"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String,Stats> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"556a4aab886d75371b2af129d87be3c2795cea76","date":1414954991,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","sourceNew":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    if (fields == null) {\n      msg(infoStream, \"OK [no fields/terms]\");\n      return status;\n    }\n    \n    DocsEnum docs = null;\n    DocsEnum docsAndFreqs = null;\n    DocsAndPositionsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef bb = terms.getMin();\n      BytesRef minTerm;\n      if (bb != null) {\n        assert bb.isValid();\n        minTerm = BytesRef.deepCopyOf(bb);\n      } else {\n        minTerm = null;\n      }\n\n      BytesRef maxTerm;\n      bb = terms.getMax();\n      if (bb != null) {\n        assert bb.isValid();\n        maxTerm = BytesRef.deepCopyOf(bb);\n        if (minTerm == null) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n        }\n      } else {\n        maxTerm = null;\n        if (minTerm != null) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n      \n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      long upto = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n\n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n        \n        if (minTerm == null) {\n          // We checked this above:\n          assert maxTerm == null;\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(minTerm) < 0) {\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(maxTerm) > 0) {\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.docs(liveDocs, docs);\n        postings = termsEnum.docsAndPositions(liveDocs, postings);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final DocsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (docs2.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.docsAndPositions(liveDocs, postings);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          DocsEnum d = termsEnum.docs(null, null, DocsEnum.FLAG_NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, \"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    if (fields == null) {\n      msg(infoStream, \"OK [no fields/terms]\");\n      return status;\n    }\n    \n    DocsEnum docs = null;\n    DocsEnum docsAndFreqs = null;\n    DocsAndPositionsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (!fieldInfo.isIndexed()) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef bb = terms.getMin();\n      BytesRef minTerm;\n      if (bb != null) {\n        assert bb.isValid();\n        minTerm = BytesRef.deepCopyOf(bb);\n      } else {\n        minTerm = null;\n      }\n\n      BytesRef maxTerm;\n      bb = terms.getMax();\n      if (bb != null) {\n        assert bb.isValid();\n        maxTerm = BytesRef.deepCopyOf(bb);\n        if (minTerm == null) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n        }\n      } else {\n        maxTerm = null;\n        if (minTerm != null) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n      \n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      long upto = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n\n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n        \n        if (minTerm == null) {\n          // We checked this above:\n          assert maxTerm == null;\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(minTerm) < 0) {\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(maxTerm) > 0) {\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.docs(liveDocs, docs);\n        postings = termsEnum.docsAndPositions(liveDocs, postings);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final DocsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (docs2.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.docsAndPositions(liveDocs, postings);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          DocsEnum d = termsEnum.docs(null, null, DocsEnum.FLAG_NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, \"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8028ab7a24273833d53d35eb160dba5b57283cf5","date":1416767720,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","sourceNew":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    DocsEnum docs = null;\n    DocsEnum docsAndFreqs = null;\n    DocsAndPositionsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef bb = terms.getMin();\n      BytesRef minTerm;\n      if (bb != null) {\n        assert bb.isValid();\n        minTerm = BytesRef.deepCopyOf(bb);\n      } else {\n        minTerm = null;\n      }\n\n      BytesRef maxTerm;\n      bb = terms.getMax();\n      if (bb != null) {\n        assert bb.isValid();\n        maxTerm = BytesRef.deepCopyOf(bb);\n        if (minTerm == null) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n        }\n      } else {\n        maxTerm = null;\n        if (minTerm != null) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n      \n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      long upto = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n\n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n        \n        if (minTerm == null) {\n          // We checked this above:\n          assert maxTerm == null;\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(minTerm) < 0) {\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(maxTerm) > 0) {\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.docs(liveDocs, docs);\n        postings = termsEnum.docsAndPositions(liveDocs, postings);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final DocsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (docs2.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.docsAndPositions(liveDocs, postings);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          DocsEnum d = termsEnum.docs(null, null, DocsEnum.FLAG_NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, \"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    if (fields == null) {\n      msg(infoStream, \"OK [no fields/terms]\");\n      return status;\n    }\n    \n    DocsEnum docs = null;\n    DocsEnum docsAndFreqs = null;\n    DocsAndPositionsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef bb = terms.getMin();\n      BytesRef minTerm;\n      if (bb != null) {\n        assert bb.isValid();\n        minTerm = BytesRef.deepCopyOf(bb);\n      } else {\n        minTerm = null;\n      }\n\n      BytesRef maxTerm;\n      bb = terms.getMax();\n      if (bb != null) {\n        assert bb.isValid();\n        maxTerm = BytesRef.deepCopyOf(bb);\n        if (minTerm == null) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n        }\n      } else {\n        maxTerm = null;\n        if (minTerm != null) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n      \n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      long upto = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n\n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n        \n        if (minTerm == null) {\n          // We checked this above:\n          assert maxTerm == null;\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(minTerm) < 0) {\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(maxTerm) > 0) {\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.docs(liveDocs, docs);\n        postings = termsEnum.docsAndPositions(liveDocs, postings);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final DocsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (docs2.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.docsAndPositions(liveDocs, postings);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          DocsEnum d = termsEnum.docs(null, null, DocsEnum.FLAG_NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, \"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":["e99275efa2c9c9ae3bdba986218af82f2bf3dc30","b13ebda0f2c83525d118f4859e46eb3bd87ced36"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"51f5280f31484820499077f41fcdfe92d527d9dc","date":1423229122,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","sourceNew":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    PostingsEnum docs = null;\n    PostingsEnum docsAndFreqs = null;\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef bb = terms.getMin();\n      BytesRef minTerm;\n      if (bb != null) {\n        assert bb.isValid();\n        minTerm = BytesRef.deepCopyOf(bb);\n      } else {\n        minTerm = null;\n      }\n\n      BytesRef maxTerm;\n      bb = terms.getMax();\n      if (bb != null) {\n        assert bb.isValid();\n        maxTerm = BytesRef.deepCopyOf(bb);\n        if (minTerm == null) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n        }\n      } else {\n        maxTerm = null;\n        if (minTerm != null) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n      \n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      long upto = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n\n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n        \n        if (minTerm == null) {\n          // We checked this above:\n          assert maxTerm == null;\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(minTerm) < 0) {\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(maxTerm) > 0) {\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.postings(liveDocs, docs);\n        postings = termsEnum.postings(liveDocs, postings, PostingsEnum.FLAG_ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final PostingsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (docs2.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final PostingsEnum docsNoDel = termsEnum.postings(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final PostingsEnum docsNoDel = termsEnum.postings(null, docs, PostingsEnum.FLAG_NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(liveDocs, postings, PostingsEnum.FLAG_ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.postings(liveDocs, docs, PostingsEnum.FLAG_NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, null, PostingsEnum.FLAG_NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.postings(liveDocs, docs, PostingsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.postings(null, docs, PostingsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, \"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    DocsEnum docs = null;\n    DocsEnum docsAndFreqs = null;\n    DocsAndPositionsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef bb = terms.getMin();\n      BytesRef minTerm;\n      if (bb != null) {\n        assert bb.isValid();\n        minTerm = BytesRef.deepCopyOf(bb);\n      } else {\n        minTerm = null;\n      }\n\n      BytesRef maxTerm;\n      bb = terms.getMax();\n      if (bb != null) {\n        assert bb.isValid();\n        maxTerm = BytesRef.deepCopyOf(bb);\n        if (minTerm == null) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n        }\n      } else {\n        maxTerm = null;\n        if (minTerm != null) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n      \n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      long upto = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n\n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n        \n        if (minTerm == null) {\n          // We checked this above:\n          assert maxTerm == null;\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(minTerm) < 0) {\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(maxTerm) > 0) {\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.docs(liveDocs, docs);\n        postings = termsEnum.docsAndPositions(liveDocs, postings);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final DocsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (docs2.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final DocsEnum docsNoDel = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.docsAndPositions(liveDocs, postings);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          DocsEnum d = termsEnum.docs(null, null, DocsEnum.FLAG_NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.docs(liveDocs, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, \"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":["8eb2b2b0fce1c4d4ca3b6c6eaa30498066be47d6","8eb2b2b0fce1c4d4ca3b6c6eaa30498066be47d6","8eb2b2b0fce1c4d4ca3b6c6eaa30498066be47d6","8eb2b2b0fce1c4d4ca3b6c6eaa30498066be47d6","8eb2b2b0fce1c4d4ca3b6c6eaa30498066be47d6"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6b64ceb507ba9aa71920c0bfad91032e2c03d42f","date":1423608862,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","sourceNew":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    long startNS;\n    if (doPrint) {\n      startNS = System.nanoTime();\n    } else {\n      startNS = 0;\n    }\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    PostingsEnum docs = null;\n    PostingsEnum docsAndFreqs = null;\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef maxTerm;\n      BytesRef minTerm;\n      if (isVectors) {\n        // Term vectors impls can be very slow for getMax\n        maxTerm = null;\n        minTerm = null;\n      } else {\n        BytesRef bb = terms.getMin();\n        if (bb != null) {\n          assert bb.isValid();\n          minTerm = BytesRef.deepCopyOf(bb);\n        } else {\n          minTerm = null;\n        }\n\n        bb = terms.getMax();\n        if (bb != null) {\n          assert bb.isValid();\n          maxTerm = BytesRef.deepCopyOf(bb);\n          if (minTerm == null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n          }\n        } else {\n          maxTerm = null;\n          if (minTerm != null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n          }\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n\n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      long upto = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n\n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n\n        if (isVectors == false) {\n          if (minTerm == null) {\n            // We checked this above:\n            assert maxTerm == null;\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(minTerm) < 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(maxTerm) > 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n          }\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.postings(liveDocs, docs);\n        postings = termsEnum.postings(liveDocs, postings, PostingsEnum.FLAG_ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final PostingsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (docs2.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final PostingsEnum docsNoDel = termsEnum.postings(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final PostingsEnum docsNoDel = termsEnum.postings(null, docs, PostingsEnum.FLAG_NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(liveDocs, postings, PostingsEnum.FLAG_ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.postings(liveDocs, docs, PostingsEnum.FLAG_NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, null, PostingsEnum.FLAG_NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.postings(liveDocs, docs, PostingsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.postings(null, docs, PostingsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, String.format(Locale.ROOT, \"OK [%d terms; %d terms/docs pairs; %d tokens] [took %.3f sec]\",\n                                    status.termCount, status.totFreq, status.totPos, nsToSec(System.nanoTime()-startNS)));\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    PostingsEnum docs = null;\n    PostingsEnum docsAndFreqs = null;\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef bb = terms.getMin();\n      BytesRef minTerm;\n      if (bb != null) {\n        assert bb.isValid();\n        minTerm = BytesRef.deepCopyOf(bb);\n      } else {\n        minTerm = null;\n      }\n\n      BytesRef maxTerm;\n      bb = terms.getMax();\n      if (bb != null) {\n        assert bb.isValid();\n        maxTerm = BytesRef.deepCopyOf(bb);\n        if (minTerm == null) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n        }\n      } else {\n        maxTerm = null;\n        if (minTerm != null) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n      \n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      long upto = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n\n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n        \n        if (minTerm == null) {\n          // We checked this above:\n          assert maxTerm == null;\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(minTerm) < 0) {\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n        }\n        \n        if (term.compareTo(maxTerm) > 0) {\n          throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.postings(liveDocs, docs);\n        postings = termsEnum.postings(liveDocs, postings, PostingsEnum.FLAG_ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final PostingsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (docs2.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final PostingsEnum docsNoDel = termsEnum.postings(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final PostingsEnum docsNoDel = termsEnum.postings(null, docs, PostingsEnum.FLAG_NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(liveDocs, postings, PostingsEnum.FLAG_ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.postings(liveDocs, docs, PostingsEnum.FLAG_NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, null, PostingsEnum.FLAG_NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.postings(liveDocs, docs, PostingsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.postings(null, docs, PostingsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, \"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":["e99275efa2c9c9ae3bdba986218af82f2bf3dc30","0974f33be0e2189e71f36b67f1017f4072b1a126","b13ebda0f2c83525d118f4859e46eb3bd87ced36","f890447ef156e598bffbdc5aab15a68b458c3612"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e73063b92d958076ef4ae8beb5f493e8ccdcecb4","date":1424177215,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","sourceNew":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    long startNS;\n    if (doPrint) {\n      startNS = System.nanoTime();\n    } else {\n      startNS = 0;\n    }\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    PostingsEnum docs = null;\n    PostingsEnum docsAndFreqs = null;\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef maxTerm;\n      BytesRef minTerm;\n      if (isVectors) {\n        // Term vectors impls can be very slow for getMax\n        maxTerm = null;\n        minTerm = null;\n      } else {\n        BytesRef bb = terms.getMin();\n        if (bb != null) {\n          assert bb.isValid();\n          minTerm = BytesRef.deepCopyOf(bb);\n        } else {\n          minTerm = null;\n        }\n\n        bb = terms.getMax();\n        if (bb != null) {\n          assert bb.isValid();\n          maxTerm = BytesRef.deepCopyOf(bb);\n          if (minTerm == null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n          }\n        } else {\n          maxTerm = null;\n          if (minTerm != null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n          }\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n\n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      long upto = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n\n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n\n        if (isVectors == false) {\n          if (minTerm == null) {\n            // We checked this above:\n            assert maxTerm == null;\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(minTerm) < 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(maxTerm) > 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n          }\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.postings(liveDocs, docs);\n        postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final PostingsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (docs2.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final PostingsEnum docsNoDel = termsEnum.postings(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final PostingsEnum docsNoDel = termsEnum.postings(null, docs, PostingsEnum.NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.postings(liveDocs, docs, PostingsEnum.NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, null, PostingsEnum.NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.postings(liveDocs, docs, PostingsEnum.NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.postings(null, docs, PostingsEnum.NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, String.format(Locale.ROOT, \"OK [%d terms; %d terms/docs pairs; %d tokens] [took %.3f sec]\",\n                                    status.termCount, status.totFreq, status.totPos, nsToSec(System.nanoTime()-startNS)));\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    long startNS;\n    if (doPrint) {\n      startNS = System.nanoTime();\n    } else {\n      startNS = 0;\n    }\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    PostingsEnum docs = null;\n    PostingsEnum docsAndFreqs = null;\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef maxTerm;\n      BytesRef minTerm;\n      if (isVectors) {\n        // Term vectors impls can be very slow for getMax\n        maxTerm = null;\n        minTerm = null;\n      } else {\n        BytesRef bb = terms.getMin();\n        if (bb != null) {\n          assert bb.isValid();\n          minTerm = BytesRef.deepCopyOf(bb);\n        } else {\n          minTerm = null;\n        }\n\n        bb = terms.getMax();\n        if (bb != null) {\n          assert bb.isValid();\n          maxTerm = BytesRef.deepCopyOf(bb);\n          if (minTerm == null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n          }\n        } else {\n          maxTerm = null;\n          if (minTerm != null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n          }\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n\n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      long upto = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n\n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n\n        if (isVectors == false) {\n          if (minTerm == null) {\n            // We checked this above:\n            assert maxTerm == null;\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(minTerm) < 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(maxTerm) > 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n          }\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.postings(liveDocs, docs);\n        postings = termsEnum.postings(liveDocs, postings, PostingsEnum.FLAG_ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final PostingsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (docs2.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final PostingsEnum docsNoDel = termsEnum.postings(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final PostingsEnum docsNoDel = termsEnum.postings(null, docs, PostingsEnum.FLAG_NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(liveDocs, postings, PostingsEnum.FLAG_ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.postings(liveDocs, docs, PostingsEnum.FLAG_NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, null, PostingsEnum.FLAG_NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.postings(liveDocs, docs, PostingsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.postings(null, docs, PostingsEnum.FLAG_NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, String.format(Locale.ROOT, \"OK [%d terms; %d terms/docs pairs; %d tokens] [took %.3f sec]\",\n                                    status.termCount, status.totFreq, status.totPos, nsToSec(System.nanoTime()-startNS)));\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":["8eb2b2b0fce1c4d4ca3b6c6eaa30498066be47d6","8eb2b2b0fce1c4d4ca3b6c6eaa30498066be47d6","8eb2b2b0fce1c4d4ca3b6c6eaa30498066be47d6","8eb2b2b0fce1c4d4ca3b6c6eaa30498066be47d6","8eb2b2b0fce1c4d4ca3b6c6eaa30498066be47d6"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"cb5311f0bff57ce15a23909f4cfb953773630534","date":1424827033,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","sourceNew":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    long startNS;\n    if (doPrint) {\n      startNS = System.nanoTime();\n    } else {\n      startNS = 0;\n    }\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    PostingsEnum docs = null;\n    PostingsEnum docsAndFreqs = null;\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef maxTerm;\n      BytesRef minTerm;\n      if (isVectors) {\n        // Term vectors impls can be very slow for getMax\n        maxTerm = null;\n        minTerm = null;\n      } else {\n        BytesRef bb = terms.getMin();\n        if (bb != null) {\n          assert bb.isValid();\n          minTerm = BytesRef.deepCopyOf(bb);\n        } else {\n          minTerm = null;\n        }\n\n        bb = terms.getMax();\n        if (bb != null) {\n          assert bb.isValid();\n          maxTerm = BytesRef.deepCopyOf(bb);\n          if (minTerm == null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n          }\n        } else {\n          maxTerm = null;\n          if (minTerm != null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n          }\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n\n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      long upto = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n\n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n\n        if (isVectors == false) {\n          if (minTerm == null) {\n            // We checked this above:\n            assert maxTerm == null;\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(minTerm) < 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(maxTerm) > 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n          }\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.postings(liveDocs, docs);\n        // nocommit: check null\n        postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final PostingsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (docs2.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final PostingsEnum docsNoDel = termsEnum.postings(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final PostingsEnum docsNoDel = termsEnum.postings(null, docs, PostingsEnum.NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.postings(liveDocs, docs, PostingsEnum.NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, null, PostingsEnum.NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.postings(liveDocs, docs, PostingsEnum.NONE);\n              // nocommit: null check still needed? how to replace?\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.postings(null, docs, PostingsEnum.NONE);\n              // nocommit: null check still needed? how to replace?\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, String.format(Locale.ROOT, \"OK [%d terms; %d terms/docs pairs; %d tokens] [took %.3f sec]\",\n                                    status.termCount, status.totFreq, status.totPos, nsToSec(System.nanoTime()-startNS)));\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    long startNS;\n    if (doPrint) {\n      startNS = System.nanoTime();\n    } else {\n      startNS = 0;\n    }\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    PostingsEnum docs = null;\n    PostingsEnum docsAndFreqs = null;\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef maxTerm;\n      BytesRef minTerm;\n      if (isVectors) {\n        // Term vectors impls can be very slow for getMax\n        maxTerm = null;\n        minTerm = null;\n      } else {\n        BytesRef bb = terms.getMin();\n        if (bb != null) {\n          assert bb.isValid();\n          minTerm = BytesRef.deepCopyOf(bb);\n        } else {\n          minTerm = null;\n        }\n\n        bb = terms.getMax();\n        if (bb != null) {\n          assert bb.isValid();\n          maxTerm = BytesRef.deepCopyOf(bb);\n          if (minTerm == null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n          }\n        } else {\n          maxTerm = null;\n          if (minTerm != null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n          }\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n\n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      long upto = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n\n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n\n        if (isVectors == false) {\n          if (minTerm == null) {\n            // We checked this above:\n            assert maxTerm == null;\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(minTerm) < 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(maxTerm) > 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n          }\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.postings(liveDocs, docs);\n        postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final PostingsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (docs2.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final PostingsEnum docsNoDel = termsEnum.postings(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final PostingsEnum docsNoDel = termsEnum.postings(null, docs, PostingsEnum.NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.postings(liveDocs, docs, PostingsEnum.NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, null, PostingsEnum.NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.postings(liveDocs, docs, PostingsEnum.NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.postings(null, docs, PostingsEnum.NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, String.format(Locale.ROOT, \"OK [%d terms; %d terms/docs pairs; %d tokens] [took %.3f sec]\",\n                                    status.termCount, status.totFreq, status.totPos, nsToSec(System.nanoTime()-startNS)));\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8eb2b2b0fce1c4d4ca3b6c6eaa30498066be47d6","date":1425345513,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","sourceNew":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    long startNS;\n    if (doPrint) {\n      startNS = System.nanoTime();\n    } else {\n      startNS = 0;\n    }\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    PostingsEnum docs = null;\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef maxTerm;\n      BytesRef minTerm;\n      if (isVectors) {\n        // Term vectors impls can be very slow for getMax\n        maxTerm = null;\n        minTerm = null;\n      } else {\n        BytesRef bb = terms.getMin();\n        if (bb != null) {\n          assert bb.isValid();\n          minTerm = BytesRef.deepCopyOf(bb);\n        } else {\n          minTerm = null;\n        }\n\n        bb = terms.getMax();\n        if (bb != null) {\n          assert bb.isValid();\n          maxTerm = BytesRef.deepCopyOf(bb);\n          if (minTerm == null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n          }\n        } else {\n          maxTerm = null;\n          if (minTerm != null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n          }\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n\n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      long upto = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n\n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n\n        if (isVectors == false) {\n          if (minTerm == null) {\n            // We checked this above:\n            assert maxTerm == null;\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(minTerm) < 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(maxTerm) > 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n          }\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.postings(liveDocs, docs);\n        postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final PostingsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (docs2.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            docs = termsEnum.postings(null, docs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docs.docID());\n              docCount++;\n              totalTermFreq += docs.freq();\n            }\n          } else {\n            docs = termsEnum.postings(null, docs, PostingsEnum.NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docs.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.postings(liveDocs, docs, PostingsEnum.NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, null, PostingsEnum.NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.postings(liveDocs, docs, PostingsEnum.NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.postings(null, docs, PostingsEnum.NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, String.format(Locale.ROOT, \"OK [%d terms; %d terms/docs pairs; %d tokens] [took %.3f sec]\",\n                                    status.termCount, status.totFreq, status.totPos, nsToSec(System.nanoTime()-startNS)));\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    long startNS;\n    if (doPrint) {\n      startNS = System.nanoTime();\n    } else {\n      startNS = 0;\n    }\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    PostingsEnum docs = null;\n    PostingsEnum docsAndFreqs = null;\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef maxTerm;\n      BytesRef minTerm;\n      if (isVectors) {\n        // Term vectors impls can be very slow for getMax\n        maxTerm = null;\n        minTerm = null;\n      } else {\n        BytesRef bb = terms.getMin();\n        if (bb != null) {\n          assert bb.isValid();\n          minTerm = BytesRef.deepCopyOf(bb);\n        } else {\n          minTerm = null;\n        }\n\n        bb = terms.getMax();\n        if (bb != null) {\n          assert bb.isValid();\n          maxTerm = BytesRef.deepCopyOf(bb);\n          if (minTerm == null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n          }\n        } else {\n          maxTerm = null;\n          if (minTerm != null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n          }\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n\n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      long upto = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n\n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n\n        if (isVectors == false) {\n          if (minTerm == null) {\n            // We checked this above:\n            assert maxTerm == null;\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(minTerm) < 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(maxTerm) > 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n          }\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.postings(liveDocs, docs);\n        postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final PostingsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (docs2.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final PostingsEnum docsNoDel = termsEnum.postings(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final PostingsEnum docsNoDel = termsEnum.postings(null, docs, PostingsEnum.NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.postings(liveDocs, docs, PostingsEnum.NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, null, PostingsEnum.NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.postings(liveDocs, docs, PostingsEnum.NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.postings(null, docs, PostingsEnum.NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, String.format(Locale.ROOT, \"OK [%d terms; %d terms/docs pairs; %d tokens] [took %.3f sec]\",\n                                    status.termCount, status.totFreq, status.totPos, nsToSec(System.nanoTime()-startNS)));\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":["e73063b92d958076ef4ae8beb5f493e8ccdcecb4","51f5280f31484820499077f41fcdfe92d527d9dc","b13ebda0f2c83525d118f4859e46eb3bd87ced36"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":3,"author":"Ryan Ernst","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","sourceNew":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    long startNS;\n    if (doPrint) {\n      startNS = System.nanoTime();\n    } else {\n      startNS = 0;\n    }\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    PostingsEnum docs = null;\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef maxTerm;\n      BytesRef minTerm;\n      if (isVectors) {\n        // Term vectors impls can be very slow for getMax\n        maxTerm = null;\n        minTerm = null;\n      } else {\n        BytesRef bb = terms.getMin();\n        if (bb != null) {\n          assert bb.isValid();\n          minTerm = BytesRef.deepCopyOf(bb);\n        } else {\n          minTerm = null;\n        }\n\n        bb = terms.getMax();\n        if (bb != null) {\n          assert bb.isValid();\n          maxTerm = BytesRef.deepCopyOf(bb);\n          if (minTerm == null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n          }\n        } else {\n          maxTerm = null;\n          if (minTerm != null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n          }\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n\n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      long upto = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n\n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n\n        if (isVectors == false) {\n          if (minTerm == null) {\n            // We checked this above:\n            assert maxTerm == null;\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(minTerm) < 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(maxTerm) > 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n          }\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.postings(liveDocs, docs);\n        // nocommit: check null\n        postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final PostingsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (docs2.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            docs = termsEnum.postings(null, docs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docs.docID());\n              docCount++;\n              totalTermFreq += docs.freq();\n            }\n          } else {\n            docs = termsEnum.postings(null, docs, PostingsEnum.NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docs.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.postings(liveDocs, docs, PostingsEnum.NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, null, PostingsEnum.NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.postings(liveDocs, docs, PostingsEnum.NONE);\n              // nocommit: null check still needed? how to replace?\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.postings(null, docs, PostingsEnum.NONE);\n              // nocommit: null check still needed? how to replace?\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, String.format(Locale.ROOT, \"OK [%d terms; %d terms/docs pairs; %d tokens] [took %.3f sec]\",\n                                    status.termCount, status.totFreq, status.totPos, nsToSec(System.nanoTime()-startNS)));\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    long startNS;\n    if (doPrint) {\n      startNS = System.nanoTime();\n    } else {\n      startNS = 0;\n    }\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    PostingsEnum docs = null;\n    PostingsEnum docsAndFreqs = null;\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef maxTerm;\n      BytesRef minTerm;\n      if (isVectors) {\n        // Term vectors impls can be very slow for getMax\n        maxTerm = null;\n        minTerm = null;\n      } else {\n        BytesRef bb = terms.getMin();\n        if (bb != null) {\n          assert bb.isValid();\n          minTerm = BytesRef.deepCopyOf(bb);\n        } else {\n          minTerm = null;\n        }\n\n        bb = terms.getMax();\n        if (bb != null) {\n          assert bb.isValid();\n          maxTerm = BytesRef.deepCopyOf(bb);\n          if (minTerm == null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n          }\n        } else {\n          maxTerm = null;\n          if (minTerm != null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n          }\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n\n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      long upto = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n\n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n\n        if (isVectors == false) {\n          if (minTerm == null) {\n            // We checked this above:\n            assert maxTerm == null;\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(minTerm) < 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(maxTerm) > 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n          }\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.postings(liveDocs, docs);\n        // nocommit: check null\n        postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final PostingsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (docs2.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            final PostingsEnum docsNoDel = termsEnum.postings(null, docsAndFreqs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n              totalTermFreq += docsNoDel.freq();\n            }\n          } else {\n            final PostingsEnum docsNoDel = termsEnum.postings(null, docs, PostingsEnum.NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docsNoDel.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.postings(liveDocs, docs, PostingsEnum.NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, null, PostingsEnum.NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.postings(liveDocs, docs, PostingsEnum.NONE);\n              // nocommit: null check still needed? how to replace?\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.postings(null, docs, PostingsEnum.NONE);\n              // nocommit: null check still needed? how to replace?\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, String.format(Locale.ROOT, \"OK [%d terms; %d terms/docs pairs; %d tokens] [took %.3f sec]\",\n                                    status.termCount, status.totFreq, status.totPos, nsToSec(System.nanoTime()-startNS)));\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"65acee44746098674ec238c7116956b3bf3bd13f","date":1427818292,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","sourceNew":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    long startNS;\n    if (doPrint) {\n      startNS = System.nanoTime();\n    } else {\n      startNS = 0;\n    }\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef maxTerm;\n      BytesRef minTerm;\n      if (isVectors) {\n        // Term vectors impls can be very slow for getMax\n        maxTerm = null;\n        minTerm = null;\n      } else {\n        BytesRef bb = terms.getMin();\n        if (bb != null) {\n          assert bb.isValid();\n          minTerm = BytesRef.deepCopyOf(bb);\n        } else {\n          minTerm = null;\n        }\n\n        bb = terms.getMax();\n        if (bb != null) {\n          assert bb.isValid();\n          maxTerm = BytesRef.deepCopyOf(bb);\n          if (minTerm == null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n          }\n        } else {\n          maxTerm = null;\n          if (minTerm != null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n          }\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n\n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      long upto = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n\n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n\n        if (isVectors == false) {\n          if (minTerm == null) {\n            // We checked this above:\n            assert maxTerm == null;\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(minTerm) < 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(maxTerm) > 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n          }\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n\n        postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = postings.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = postings.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (postings.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            postings = termsEnum.postings(null, postings);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(postings.docID());\n              docCount++;\n              totalTermFreq += postings.freq();\n            }\n          } else {\n            postings = termsEnum.postings(null, postings, PostingsEnum.NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(postings.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(liveDocs, postings, PostingsEnum.NONE);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, null, PostingsEnum.NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              postings = termsEnum.postings(liveDocs, postings, PostingsEnum.NONE);\n              if (postings == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n\n              while (postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              postings = termsEnum.postings(null, postings, PostingsEnum.NONE);\n              if (postings == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, String.format(Locale.ROOT, \"OK [%d terms; %d terms/docs pairs; %d tokens] [took %.3f sec]\",\n                                    status.termCount, status.totFreq, status.totPos, nsToSec(System.nanoTime()-startNS)));\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    long startNS;\n    if (doPrint) {\n      startNS = System.nanoTime();\n    } else {\n      startNS = 0;\n    }\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    PostingsEnum docs = null;\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef maxTerm;\n      BytesRef minTerm;\n      if (isVectors) {\n        // Term vectors impls can be very slow for getMax\n        maxTerm = null;\n        minTerm = null;\n      } else {\n        BytesRef bb = terms.getMin();\n        if (bb != null) {\n          assert bb.isValid();\n          minTerm = BytesRef.deepCopyOf(bb);\n        } else {\n          minTerm = null;\n        }\n\n        bb = terms.getMax();\n        if (bb != null) {\n          assert bb.isValid();\n          maxTerm = BytesRef.deepCopyOf(bb);\n          if (minTerm == null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n          }\n        } else {\n          maxTerm = null;\n          if (minTerm != null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n          }\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n\n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      long upto = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n\n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n\n        if (isVectors == false) {\n          if (minTerm == null) {\n            // We checked this above:\n            assert maxTerm == null;\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(minTerm) < 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(maxTerm) > 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n          }\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.postings(liveDocs, docs);\n        // nocommit: check null\n        postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final PostingsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (docs2.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            docs = termsEnum.postings(null, docs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docs.docID());\n              docCount++;\n              totalTermFreq += docs.freq();\n            }\n          } else {\n            docs = termsEnum.postings(null, docs, PostingsEnum.NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docs.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.postings(liveDocs, docs, PostingsEnum.NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, null, PostingsEnum.NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.postings(liveDocs, docs, PostingsEnum.NONE);\n              // nocommit: null check still needed? how to replace?\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.postings(null, docs, PostingsEnum.NONE);\n              // nocommit: null check still needed? how to replace?\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, String.format(Locale.ROOT, \"OK [%d terms; %d terms/docs pairs; %d tokens] [took %.3f sec]\",\n                                    status.termCount, status.totFreq, status.totPos, nsToSec(System.nanoTime()-startNS)));\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3e8715d826e588419327562287d5d6a8040d63d6","date":1427987148,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","sourceNew":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    long startNS;\n    if (doPrint) {\n      startNS = System.nanoTime();\n    } else {\n      startNS = 0;\n    }\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    PostingsEnum docs = null;\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef maxTerm;\n      BytesRef minTerm;\n      if (isVectors) {\n        // Term vectors impls can be very slow for getMax\n        maxTerm = null;\n        minTerm = null;\n      } else {\n        BytesRef bb = terms.getMin();\n        if (bb != null) {\n          assert bb.isValid();\n          minTerm = BytesRef.deepCopyOf(bb);\n        } else {\n          minTerm = null;\n        }\n\n        bb = terms.getMax();\n        if (bb != null) {\n          assert bb.isValid();\n          maxTerm = BytesRef.deepCopyOf(bb);\n          if (minTerm == null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n          }\n        } else {\n          maxTerm = null;\n          if (minTerm != null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n          }\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n\n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      long upto = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        // System.out.println(\"CI: field=\" + field + \" check term=\" + term + \" docFreq=\" + termsEnum.docFreq());\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n\n        if (isVectors == false) {\n          if (minTerm == null) {\n            // We checked this above:\n            assert maxTerm == null;\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(minTerm) < 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(maxTerm) > 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n          }\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.postings(liveDocs, docs);\n        postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final PostingsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (docs2.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            docs = termsEnum.postings(null, docs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docs.docID());\n              docCount++;\n              totalTermFreq += docs.freq();\n            }\n          } else {\n            docs = termsEnum.postings(null, docs, PostingsEnum.NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docs.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.postings(liveDocs, docs, PostingsEnum.NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n\n        long fieldTermCount = (status.delTermCount+status.termCount)-termCountStart;\n\n        if (hasFreqs == false) {\n          // For DOCS_ONLY fields we recursively test term ranges:\n          checkTermRanges(field, maxDoc, fieldTerms, fieldTermCount);\n        }\n\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n\n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        final int v = fieldTerms.getDocCount();\n        if (v != -1 && visitedDocs.cardinality() != v) {\n          throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          if (termsEnum.term().equals(lastTerm.get()) == false) {\n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, null, PostingsEnum.NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm.toBytesRef() + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if (fieldTermCount > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != fieldTermCount) {\n            throw new RuntimeException(\"termCount mismatch \" + termCount + \" vs \" + fieldTermCount);\n          }\n        }\n\n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              if (termsEnum.term().equals(seekTerms[i]) == false) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n              }\n              \n              docs = termsEnum.postings(liveDocs, docs, PostingsEnum.NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.postings(null, docs, PostingsEnum.NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, String.format(Locale.ROOT, \"OK [%d terms; %d terms/docs pairs; %d tokens] [took %.3f sec]\",\n                                    status.termCount, status.totFreq, status.totPos, nsToSec(System.nanoTime()-startNS)));\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    long startNS;\n    if (doPrint) {\n      startNS = System.nanoTime();\n    } else {\n      startNS = 0;\n    }\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    PostingsEnum docs = null;\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef maxTerm;\n      BytesRef minTerm;\n      if (isVectors) {\n        // Term vectors impls can be very slow for getMax\n        maxTerm = null;\n        minTerm = null;\n      } else {\n        BytesRef bb = terms.getMin();\n        if (bb != null) {\n          assert bb.isValid();\n          minTerm = BytesRef.deepCopyOf(bb);\n        } else {\n          minTerm = null;\n        }\n\n        bb = terms.getMax();\n        if (bb != null) {\n          assert bb.isValid();\n          maxTerm = BytesRef.deepCopyOf(bb);\n          if (minTerm == null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n          }\n        } else {\n          maxTerm = null;\n          if (minTerm != null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n          }\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n\n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      long upto = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n\n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n\n        if (isVectors == false) {\n          if (minTerm == null) {\n            // We checked this above:\n            assert maxTerm == null;\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(minTerm) < 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(maxTerm) > 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n          }\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.postings(liveDocs, docs);\n        postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final PostingsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (docs2.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            docs = termsEnum.postings(null, docs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docs.docID());\n              docCount++;\n              totalTermFreq += docs.freq();\n            }\n          } else {\n            docs = termsEnum.postings(null, docs, PostingsEnum.NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docs.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.postings(liveDocs, docs, PostingsEnum.NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, null, PostingsEnum.NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              docs = termsEnum.postings(liveDocs, docs, PostingsEnum.NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.postings(null, docs, PostingsEnum.NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, String.format(Locale.ROOT, \"OK [%d terms; %d terms/docs pairs; %d tokens] [took %.3f sec]\",\n                                    status.termCount, status.totFreq, status.totPos, nsToSec(System.nanoTime()-startNS)));\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d2638f781be724518ff6c2263d14a48cf6e68017","date":1427989059,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","sourceNew":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    long startNS;\n    if (doPrint) {\n      startNS = System.nanoTime();\n    } else {\n      startNS = 0;\n    }\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef maxTerm;\n      BytesRef minTerm;\n      if (isVectors) {\n        // Term vectors impls can be very slow for getMax\n        maxTerm = null;\n        minTerm = null;\n      } else {\n        BytesRef bb = terms.getMin();\n        if (bb != null) {\n          assert bb.isValid();\n          minTerm = BytesRef.deepCopyOf(bb);\n        } else {\n          minTerm = null;\n        }\n\n        bb = terms.getMax();\n        if (bb != null) {\n          assert bb.isValid();\n          maxTerm = BytesRef.deepCopyOf(bb);\n          if (minTerm == null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n          }\n        } else {\n          maxTerm = null;\n          if (minTerm != null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n          }\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n\n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      long upto = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        // System.out.println(\"CI: field=\" + field + \" check term=\" + term + \" docFreq=\" + termsEnum.docFreq());\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n\n        if (isVectors == false) {\n          if (minTerm == null) {\n            // We checked this above:\n            assert maxTerm == null;\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(minTerm) < 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(maxTerm) > 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n          }\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n\n        postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = postings.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = postings.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (postings.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            postings = termsEnum.postings(null, postings);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(postings.docID());\n              docCount++;\n              totalTermFreq += postings.freq();\n            }\n          } else {\n            postings = termsEnum.postings(null, postings, PostingsEnum.NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(postings.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(liveDocs, postings, PostingsEnum.NONE);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n\n        long fieldTermCount = (status.delTermCount+status.termCount)-termCountStart;\n\n        if (hasFreqs == false) {\n          // For DOCS_ONLY fields we recursively test term ranges:\n          checkTermRanges(field, maxDoc, fieldTerms, fieldTermCount);\n        }\n\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n\n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        final int v = fieldTerms.getDocCount();\n        if (v != -1 && visitedDocs.cardinality() != v) {\n          throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          if (termsEnum.term().equals(lastTerm.get()) == false) {\n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, null, PostingsEnum.NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm.toBytesRef() + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if (fieldTermCount > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != fieldTermCount) {\n            throw new RuntimeException(\"termCount mismatch \" + termCount + \" vs \" + fieldTermCount);\n          }\n        }\n\n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              if (termsEnum.term().equals(seekTerms[i]) == false) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n              }\n              \n              postings = termsEnum.postings(liveDocs, postings, PostingsEnum.NONE);\n              if (postings == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n\n              while (postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              postings = termsEnum.postings(null, postings, PostingsEnum.NONE);\n              if (postings == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, String.format(Locale.ROOT, \"OK [%d terms; %d terms/docs pairs; %d tokens] [took %.3f sec]\",\n                                    status.termCount, status.totFreq, status.totPos, nsToSec(System.nanoTime()-startNS)));\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    long startNS;\n    if (doPrint) {\n      startNS = System.nanoTime();\n    } else {\n      startNS = 0;\n    }\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef maxTerm;\n      BytesRef minTerm;\n      if (isVectors) {\n        // Term vectors impls can be very slow for getMax\n        maxTerm = null;\n        minTerm = null;\n      } else {\n        BytesRef bb = terms.getMin();\n        if (bb != null) {\n          assert bb.isValid();\n          minTerm = BytesRef.deepCopyOf(bb);\n        } else {\n          minTerm = null;\n        }\n\n        bb = terms.getMax();\n        if (bb != null) {\n          assert bb.isValid();\n          maxTerm = BytesRef.deepCopyOf(bb);\n          if (minTerm == null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n          }\n        } else {\n          maxTerm = null;\n          if (minTerm != null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n          }\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n\n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      long upto = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n\n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n\n        if (isVectors == false) {\n          if (minTerm == null) {\n            // We checked this above:\n            assert maxTerm == null;\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(minTerm) < 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(maxTerm) > 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n          }\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n\n        postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = postings.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = postings.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (postings.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            postings = termsEnum.postings(null, postings);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(postings.docID());\n              docCount++;\n              totalTermFreq += postings.freq();\n            }\n          } else {\n            postings = termsEnum.postings(null, postings, PostingsEnum.NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(postings.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(liveDocs, postings, PostingsEnum.NONE);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n        \n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        if (fieldTerms != null) {\n          final int v = fieldTerms.getDocCount();\n          if (v != -1 && visitedDocs.cardinality() != v) {\n            throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n          }\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, null, PostingsEnum.NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if ((status.delTermCount+status.termCount)-termCountStart > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != status.delTermCount + status.termCount - termCountStart) {\n            throw new RuntimeException(\"termCount mismatch \" + (status.delTermCount + termCount) + \" vs \" + (status.termCount - termCountStart));\n          }\n        }\n        \n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              postings = termsEnum.postings(liveDocs, postings, PostingsEnum.NONE);\n              if (postings == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n\n              while (postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              postings = termsEnum.postings(null, postings, PostingsEnum.NONE);\n              if (postings == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, String.format(Locale.ROOT, \"OK [%d terms; %d terms/docs pairs; %d tokens] [took %.3f sec]\",\n                                    status.termCount, status.totFreq, status.totPos, nsToSec(System.nanoTime()-startNS)));\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6b4e3cd382d0d075a0f1725649c084bb6510c483","date":1428096423,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","sourceNew":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    long startNS;\n    if (doPrint) {\n      startNS = System.nanoTime();\n    } else {\n      startNS = 0;\n    }\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef maxTerm;\n      BytesRef minTerm;\n      if (isVectors) {\n        // Term vectors impls can be very slow for getMax\n        maxTerm = null;\n        minTerm = null;\n      } else {\n        BytesRef bb = terms.getMin();\n        if (bb != null) {\n          assert bb.isValid();\n          minTerm = BytesRef.deepCopyOf(bb);\n        } else {\n          minTerm = null;\n        }\n\n        bb = terms.getMax();\n        if (bb != null) {\n          assert bb.isValid();\n          maxTerm = BytesRef.deepCopyOf(bb);\n          if (minTerm == null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n          }\n        } else {\n          maxTerm = null;\n          if (minTerm != null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n          }\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n\n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      long upto = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        // System.out.println(\"CI: field=\" + field + \" check term=\" + term + \" docFreq=\" + termsEnum.docFreq());\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n\n        if (isVectors == false) {\n          if (minTerm == null) {\n            // We checked this above:\n            assert maxTerm == null;\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(minTerm) < 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(maxTerm) > 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n          }\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n\n        postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = postings.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = postings.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (postings.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            postings = termsEnum.postings(null, postings);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(postings.docID());\n              docCount++;\n              totalTermFreq += postings.freq();\n            }\n          } else {\n            postings = termsEnum.postings(null, postings, PostingsEnum.NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(postings.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(liveDocs, postings, PostingsEnum.NONE);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n\n        long fieldTermCount = (status.delTermCount+status.termCount)-termCountStart;\n\n        if (hasFreqs == false) {\n          // For DOCS_ONLY fields we recursively test term ranges:\n          checkTermRanges(field, maxDoc, fieldTerms, fieldTermCount);\n        }\n\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n\n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        final int v = fieldTerms.getDocCount();\n        if (v != -1 && visitedDocs.cardinality() != v) {\n          throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          if (termsEnum.term().equals(lastTerm.get()) == false) {\n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, null, PostingsEnum.NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm.toBytesRef() + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if (fieldTermCount > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != fieldTermCount) {\n            throw new RuntimeException(\"termCount mismatch \" + termCount + \" vs \" + fieldTermCount);\n          }\n        }\n\n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              if (termsEnum.term().equals(seekTerms[i]) == false) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n              }\n              \n              postings = termsEnum.postings(liveDocs, postings, PostingsEnum.NONE);\n              if (postings == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n\n              while (postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              postings = termsEnum.postings(null, postings, PostingsEnum.NONE);\n              if (postings == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, String.format(Locale.ROOT, \"OK [%d terms; %d terms/docs pairs; %d tokens] [took %.3f sec]\",\n                                    status.termCount, status.totFreq, status.totPos, nsToSec(System.nanoTime()-startNS)));\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    long startNS;\n    if (doPrint) {\n      startNS = System.nanoTime();\n    } else {\n      startNS = 0;\n    }\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n    \n    PostingsEnum docs = null;\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef maxTerm;\n      BytesRef minTerm;\n      if (isVectors) {\n        // Term vectors impls can be very slow for getMax\n        maxTerm = null;\n        minTerm = null;\n      } else {\n        BytesRef bb = terms.getMin();\n        if (bb != null) {\n          assert bb.isValid();\n          minTerm = BytesRef.deepCopyOf(bb);\n        } else {\n          minTerm = null;\n        }\n\n        bb = terms.getMax();\n        if (bb != null) {\n          assert bb.isValid();\n          maxTerm = BytesRef.deepCopyOf(bb);\n          if (minTerm == null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n          }\n        } else {\n          maxTerm = null;\n          if (minTerm != null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n          }\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n\n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      long upto = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        // System.out.println(\"CI: field=\" + field + \" check term=\" + term + \" docFreq=\" + termsEnum.docFreq());\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n\n        if (isVectors == false) {\n          if (minTerm == null) {\n            // We checked this above:\n            assert maxTerm == null;\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(minTerm) < 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(maxTerm) > 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n          }\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n        \n        docs = termsEnum.postings(liveDocs, docs);\n        postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        final PostingsEnum docs2;\n        if (postings != null) {\n          docs2 = postings;\n        } else {\n          docs2 = docs;\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = docs2.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = docs2.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (docs2.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            docs = termsEnum.postings(null, docs);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docs.docID());\n              docCount++;\n              totalTermFreq += docs.freq();\n            }\n          } else {\n            docs = termsEnum.postings(null, docs, PostingsEnum.NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(docs.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            docs = termsEnum.postings(liveDocs, docs, PostingsEnum.NONE);\n            final int docID = docs.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = docs.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n\n        long fieldTermCount = (status.delTermCount+status.termCount)-termCountStart;\n\n        if (hasFreqs == false) {\n          // For DOCS_ONLY fields we recursively test term ranges:\n          checkTermRanges(field, maxDoc, fieldTerms, fieldTermCount);\n        }\n\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n\n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        final int v = fieldTerms.getDocCount();\n        if (v != -1 && visitedDocs.cardinality() != v) {\n          throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          if (termsEnum.term().equals(lastTerm.get()) == false) {\n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, null, PostingsEnum.NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm.toBytesRef() + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if (fieldTermCount > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != fieldTermCount) {\n            throw new RuntimeException(\"termCount mismatch \" + termCount + \" vs \" + fieldTermCount);\n          }\n        }\n\n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              if (termsEnum.term().equals(seekTerms[i]) == false) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n              }\n              \n              docs = termsEnum.postings(liveDocs, docs, PostingsEnum.NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              docs = termsEnum.postings(null, docs, PostingsEnum.NONE);\n              if (docs == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, String.format(Locale.ROOT, \"OK [%d terms; %d terms/docs pairs; %d tokens] [took %.3f sec]\",\n                                    status.termCount, status.totFreq, status.totPos, nsToSec(System.nanoTime()-startNS)));\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"372b4e16bc7ce0e14dccdc44b8cb31888f7402ab","date":1428224042,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","sourceNew":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    long startNS;\n    if (doPrint) {\n      startNS = System.nanoTime();\n    } else {\n      startNS = 0;\n    }\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef maxTerm;\n      BytesRef minTerm;\n      if (isVectors) {\n        // Term vectors impls can be very slow for getMax\n        maxTerm = null;\n        minTerm = null;\n      } else {\n        BytesRef bb = terms.getMin();\n        if (bb != null) {\n          assert bb.isValid();\n          minTerm = BytesRef.deepCopyOf(bb);\n        } else {\n          minTerm = null;\n        }\n\n        bb = terms.getMax();\n        if (bb != null) {\n          assert bb.isValid();\n          maxTerm = BytesRef.deepCopyOf(bb);\n          if (minTerm == null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n          }\n        } else {\n          maxTerm = null;\n          if (minTerm != null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n          }\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n\n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      long upto = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        // System.out.println(\"CI: field=\" + field + \" check term=\" + term + \" docFreq=\" + termsEnum.docFreq());\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n\n        if (isVectors == false) {\n          if (minTerm == null) {\n            // We checked this above:\n            assert maxTerm == null;\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(minTerm) < 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(maxTerm) > 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n          }\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n\n        postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = postings.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = postings.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (postings.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            postings = termsEnum.postings(null, postings);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(postings.docID());\n              docCount++;\n              totalTermFreq += postings.freq();\n            }\n          } else {\n            postings = termsEnum.postings(null, postings, PostingsEnum.NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(postings.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(liveDocs, postings, PostingsEnum.NONE);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n\n        long fieldTermCount = (status.delTermCount+status.termCount)-termCountStart;\n\n        // LUCENE-5879: this is just too slow for now:\n        if (false && hasFreqs == false) {\n          // For DOCS_ONLY fields we recursively test term ranges:\n          checkTermRanges(field, maxDoc, fieldTerms, fieldTermCount);\n        }\n\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n\n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        final int v = fieldTerms.getDocCount();\n        if (v != -1 && visitedDocs.cardinality() != v) {\n          throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          if (termsEnum.term().equals(lastTerm.get()) == false) {\n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, null, PostingsEnum.NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm.toBytesRef() + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if (fieldTermCount > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != fieldTermCount) {\n            throw new RuntimeException(\"termCount mismatch \" + termCount + \" vs \" + fieldTermCount);\n          }\n        }\n\n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              if (termsEnum.term().equals(seekTerms[i]) == false) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n              }\n              \n              postings = termsEnum.postings(liveDocs, postings, PostingsEnum.NONE);\n              if (postings == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n\n              while (postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              postings = termsEnum.postings(null, postings, PostingsEnum.NONE);\n              if (postings == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, String.format(Locale.ROOT, \"OK [%d terms; %d terms/docs pairs; %d tokens] [took %.3f sec]\",\n                                    status.termCount, status.totFreq, status.totPos, nsToSec(System.nanoTime()-startNS)));\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    long startNS;\n    if (doPrint) {\n      startNS = System.nanoTime();\n    } else {\n      startNS = 0;\n    }\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef maxTerm;\n      BytesRef minTerm;\n      if (isVectors) {\n        // Term vectors impls can be very slow for getMax\n        maxTerm = null;\n        minTerm = null;\n      } else {\n        BytesRef bb = terms.getMin();\n        if (bb != null) {\n          assert bb.isValid();\n          minTerm = BytesRef.deepCopyOf(bb);\n        } else {\n          minTerm = null;\n        }\n\n        bb = terms.getMax();\n        if (bb != null) {\n          assert bb.isValid();\n          maxTerm = BytesRef.deepCopyOf(bb);\n          if (minTerm == null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n          }\n        } else {\n          maxTerm = null;\n          if (minTerm != null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n          }\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n\n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      long upto = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        // System.out.println(\"CI: field=\" + field + \" check term=\" + term + \" docFreq=\" + termsEnum.docFreq());\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n\n        if (isVectors == false) {\n          if (minTerm == null) {\n            // We checked this above:\n            assert maxTerm == null;\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(minTerm) < 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(maxTerm) > 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n          }\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n\n        postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = postings.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = postings.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (postings.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            postings = termsEnum.postings(null, postings);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(postings.docID());\n              docCount++;\n              totalTermFreq += postings.freq();\n            }\n          } else {\n            postings = termsEnum.postings(null, postings, PostingsEnum.NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(postings.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(liveDocs, postings, PostingsEnum.NONE);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n\n        long fieldTermCount = (status.delTermCount+status.termCount)-termCountStart;\n\n        if (hasFreqs == false) {\n          // For DOCS_ONLY fields we recursively test term ranges:\n          checkTermRanges(field, maxDoc, fieldTerms, fieldTermCount);\n        }\n\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n\n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        final int v = fieldTerms.getDocCount();\n        if (v != -1 && visitedDocs.cardinality() != v) {\n          throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          if (termsEnum.term().equals(lastTerm.get()) == false) {\n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, null, PostingsEnum.NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm.toBytesRef() + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if (fieldTermCount > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != fieldTermCount) {\n            throw new RuntimeException(\"termCount mismatch \" + termCount + \" vs \" + fieldTermCount);\n          }\n        }\n\n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              if (termsEnum.term().equals(seekTerms[i]) == false) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n              }\n              \n              postings = termsEnum.postings(liveDocs, postings, PostingsEnum.NONE);\n              if (postings == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n\n              while (postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              postings = termsEnum.postings(null, postings, PostingsEnum.NONE);\n              if (postings == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, String.format(Locale.ROOT, \"OK [%d terms; %d terms/docs pairs; %d tokens] [took %.3f sec]\",\n                                    status.termCount, status.totFreq, status.totPos, nsToSec(System.nanoTime()-startNS)));\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82","date":1428522487,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","sourceNew":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    long startNS;\n    if (doPrint) {\n      startNS = System.nanoTime();\n    } else {\n      startNS = 0;\n    }\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef maxTerm;\n      BytesRef minTerm;\n      if (isVectors) {\n        // Term vectors impls can be very slow for getMax\n        maxTerm = null;\n        minTerm = null;\n      } else {\n        BytesRef bb = terms.getMin();\n        if (bb != null) {\n          assert bb.isValid();\n          minTerm = BytesRef.deepCopyOf(bb);\n        } else {\n          minTerm = null;\n        }\n\n        bb = terms.getMax();\n        if (bb != null) {\n          assert bb.isValid();\n          maxTerm = BytesRef.deepCopyOf(bb);\n          if (minTerm == null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n          }\n        } else {\n          maxTerm = null;\n          if (minTerm != null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n          }\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator();\n\n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      long upto = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        // System.out.println(\"CI: field=\" + field + \" check term=\" + term + \" docFreq=\" + termsEnum.docFreq());\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n\n        if (isVectors == false) {\n          if (minTerm == null) {\n            // We checked this above:\n            assert maxTerm == null;\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(minTerm) < 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(maxTerm) > 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n          }\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n\n        postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = postings.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = postings.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (postings.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            postings = termsEnum.postings(null, postings);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(postings.docID());\n              docCount++;\n              totalTermFreq += postings.freq();\n            }\n          } else {\n            postings = termsEnum.postings(null, postings, PostingsEnum.NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(postings.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(liveDocs, postings, PostingsEnum.NONE);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n\n        long fieldTermCount = (status.delTermCount+status.termCount)-termCountStart;\n\n        // LUCENE-5879: this is just too slow for now:\n        if (false && hasFreqs == false) {\n          // For DOCS_ONLY fields we recursively test term ranges:\n          checkTermRanges(field, maxDoc, fieldTerms, fieldTermCount);\n        }\n\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n\n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        final int v = fieldTerms.getDocCount();\n        if (v != -1 && visitedDocs.cardinality() != v) {\n          throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          if (termsEnum.term().equals(lastTerm.get()) == false) {\n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, null, PostingsEnum.NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm.toBytesRef() + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if (fieldTermCount > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != fieldTermCount) {\n            throw new RuntimeException(\"termCount mismatch \" + termCount + \" vs \" + fieldTermCount);\n          }\n        }\n\n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              if (termsEnum.term().equals(seekTerms[i]) == false) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n              }\n              \n              postings = termsEnum.postings(liveDocs, postings, PostingsEnum.NONE);\n              if (postings == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n\n              while (postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              postings = termsEnum.postings(null, postings, PostingsEnum.NONE);\n              if (postings == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, String.format(Locale.ROOT, \"OK [%d terms; %d terms/docs pairs; %d tokens] [took %.3f sec]\",\n                                    status.termCount, status.totFreq, status.totPos, nsToSec(System.nanoTime()-startNS)));\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    long startNS;\n    if (doPrint) {\n      startNS = System.nanoTime();\n    } else {\n      startNS = 0;\n    }\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef maxTerm;\n      BytesRef minTerm;\n      if (isVectors) {\n        // Term vectors impls can be very slow for getMax\n        maxTerm = null;\n        minTerm = null;\n      } else {\n        BytesRef bb = terms.getMin();\n        if (bb != null) {\n          assert bb.isValid();\n          minTerm = BytesRef.deepCopyOf(bb);\n        } else {\n          minTerm = null;\n        }\n\n        bb = terms.getMax();\n        if (bb != null) {\n          assert bb.isValid();\n          maxTerm = BytesRef.deepCopyOf(bb);\n          if (minTerm == null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n          }\n        } else {\n          maxTerm = null;\n          if (minTerm != null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n          }\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator(null);\n\n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      long upto = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        // System.out.println(\"CI: field=\" + field + \" check term=\" + term + \" docFreq=\" + termsEnum.docFreq());\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n\n        if (isVectors == false) {\n          if (minTerm == null) {\n            // We checked this above:\n            assert maxTerm == null;\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(minTerm) < 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(maxTerm) > 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n          }\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n\n        postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = postings.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = postings.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (postings.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            postings = termsEnum.postings(null, postings);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(postings.docID());\n              docCount++;\n              totalTermFreq += postings.freq();\n            }\n          } else {\n            postings = termsEnum.postings(null, postings, PostingsEnum.NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(postings.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(liveDocs, postings, PostingsEnum.NONE);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n\n        long fieldTermCount = (status.delTermCount+status.termCount)-termCountStart;\n\n        // LUCENE-5879: this is just too slow for now:\n        if (false && hasFreqs == false) {\n          // For DOCS_ONLY fields we recursively test term ranges:\n          checkTermRanges(field, maxDoc, fieldTerms, fieldTermCount);\n        }\n\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n\n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        final int v = fieldTerms.getDocCount();\n        if (v != -1 && visitedDocs.cardinality() != v) {\n          throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          if (termsEnum.term().equals(lastTerm.get()) == false) {\n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, null, PostingsEnum.NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm.toBytesRef() + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if (fieldTermCount > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != fieldTermCount) {\n            throw new RuntimeException(\"termCount mismatch \" + termCount + \" vs \" + fieldTermCount);\n          }\n        }\n\n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              if (termsEnum.term().equals(seekTerms[i]) == false) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n              }\n              \n              postings = termsEnum.postings(liveDocs, postings, PostingsEnum.NONE);\n              if (postings == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n\n              while (postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              postings = termsEnum.postings(null, postings, PostingsEnum.NONE);\n              if (postings == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, String.format(Locale.ROOT, \"OK [%d terms; %d terms/docs pairs; %d tokens] [took %.3f sec]\",\n                                    status.termCount, status.totFreq, status.totPos, nsToSec(System.nanoTime()-startNS)));\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"35fb92999b9df7df2ce2b35b83a044cbede61f45","date":1429037650,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","sourceNew":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    long startNS;\n    if (doPrint) {\n      startNS = System.nanoTime();\n    } else {\n      startNS = 0;\n    }\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef maxTerm;\n      BytesRef minTerm;\n      if (isVectors) {\n        // Term vectors impls can be very slow for getMax\n        maxTerm = null;\n        minTerm = null;\n      } else {\n        BytesRef bb = terms.getMin();\n        if (bb != null) {\n          assert bb.isValid();\n          minTerm = BytesRef.deepCopyOf(bb);\n        } else {\n          minTerm = null;\n        }\n\n        bb = terms.getMax();\n        if (bb != null) {\n          assert bb.isValid();\n          maxTerm = BytesRef.deepCopyOf(bb);\n          if (minTerm == null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n          }\n        } else {\n          maxTerm = null;\n          if (minTerm != null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n          }\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator();\n\n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      long upto = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        // System.out.println(\"CI: field=\" + field + \" check term=\" + term + \" docFreq=\" + termsEnum.docFreq());\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n\n        if (isVectors == false) {\n          if (minTerm == null) {\n            // We checked this above:\n            assert maxTerm == null;\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(minTerm) < 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(maxTerm) > 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n          }\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n\n        postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = postings.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = postings.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (postings.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos > IndexWriter.MAX_POSITION) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" > IndexWriter.MAX_POSITION=\" + IndexWriter.MAX_POSITION);\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            postings = termsEnum.postings(null, postings);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(postings.docID());\n              docCount++;\n              totalTermFreq += postings.freq();\n            }\n          } else {\n            postings = termsEnum.postings(null, postings, PostingsEnum.NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(postings.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(liveDocs, postings, PostingsEnum.NONE);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n\n        long fieldTermCount = (status.delTermCount+status.termCount)-termCountStart;\n\n        // LUCENE-5879: this is just too slow for now:\n        if (false && hasFreqs == false) {\n          // For DOCS_ONLY fields we recursively test term ranges:\n          checkTermRanges(field, maxDoc, fieldTerms, fieldTermCount);\n        }\n\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n\n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        final int v = fieldTerms.getDocCount();\n        if (v != -1 && visitedDocs.cardinality() != v) {\n          throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          if (termsEnum.term().equals(lastTerm.get()) == false) {\n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, null, PostingsEnum.NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm.toBytesRef() + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if (fieldTermCount > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != fieldTermCount) {\n            throw new RuntimeException(\"termCount mismatch \" + termCount + \" vs \" + fieldTermCount);\n          }\n        }\n\n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              if (termsEnum.term().equals(seekTerms[i]) == false) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n              }\n              \n              postings = termsEnum.postings(liveDocs, postings, PostingsEnum.NONE);\n              if (postings == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n\n              while (postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              postings = termsEnum.postings(null, postings, PostingsEnum.NONE);\n              if (postings == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, String.format(Locale.ROOT, \"OK [%d terms; %d terms/docs pairs; %d tokens] [took %.3f sec]\",\n                                    status.termCount, status.totFreq, status.totPos, nsToSec(System.nanoTime()-startNS)));\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    long startNS;\n    if (doPrint) {\n      startNS = System.nanoTime();\n    } else {\n      startNS = 0;\n    }\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef maxTerm;\n      BytesRef minTerm;\n      if (isVectors) {\n        // Term vectors impls can be very slow for getMax\n        maxTerm = null;\n        minTerm = null;\n      } else {\n        BytesRef bb = terms.getMin();\n        if (bb != null) {\n          assert bb.isValid();\n          minTerm = BytesRef.deepCopyOf(bb);\n        } else {\n          minTerm = null;\n        }\n\n        bb = terms.getMax();\n        if (bb != null) {\n          assert bb.isValid();\n          maxTerm = BytesRef.deepCopyOf(bb);\n          if (minTerm == null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n          }\n        } else {\n          maxTerm = null;\n          if (minTerm != null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n          }\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator();\n\n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      long upto = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        // System.out.println(\"CI: field=\" + field + \" check term=\" + term + \" docFreq=\" + termsEnum.docFreq());\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n\n        if (isVectors == false) {\n          if (minTerm == null) {\n            // We checked this above:\n            assert maxTerm == null;\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(minTerm) < 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(maxTerm) > 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n          }\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n\n        postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = postings.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = postings.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (postings.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            postings = termsEnum.postings(null, postings);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(postings.docID());\n              docCount++;\n              totalTermFreq += postings.freq();\n            }\n          } else {\n            postings = termsEnum.postings(null, postings, PostingsEnum.NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(postings.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(liveDocs, postings, PostingsEnum.NONE);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n\n        long fieldTermCount = (status.delTermCount+status.termCount)-termCountStart;\n\n        // LUCENE-5879: this is just too slow for now:\n        if (false && hasFreqs == false) {\n          // For DOCS_ONLY fields we recursively test term ranges:\n          checkTermRanges(field, maxDoc, fieldTerms, fieldTermCount);\n        }\n\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n\n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        final int v = fieldTerms.getDocCount();\n        if (v != -1 && visitedDocs.cardinality() != v) {\n          throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          if (termsEnum.term().equals(lastTerm.get()) == false) {\n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, null, PostingsEnum.NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm.toBytesRef() + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if (fieldTermCount > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != fieldTermCount) {\n            throw new RuntimeException(\"termCount mismatch \" + termCount + \" vs \" + fieldTermCount);\n          }\n        }\n\n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              if (termsEnum.term().equals(seekTerms[i]) == false) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n              }\n              \n              postings = termsEnum.postings(liveDocs, postings, PostingsEnum.NONE);\n              if (postings == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n\n              while (postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              postings = termsEnum.postings(null, postings, PostingsEnum.NONE);\n              if (postings == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, String.format(Locale.ROOT, \"OK [%d terms; %d terms/docs pairs; %d tokens] [took %.3f sec]\",\n                                    status.termCount, status.totFreq, status.totPos, nsToSec(System.nanoTime()-startNS)));\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"69d0e71914d75d0016babdee88927593bca21993","date":1433598760,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","sourceNew":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    long startNS;\n    if (doPrint) {\n      startNS = System.nanoTime();\n    } else {\n      startNS = 0;\n    }\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef maxTerm;\n      BytesRef minTerm;\n      if (isVectors) {\n        // Term vectors impls can be very slow for getMax\n        maxTerm = null;\n        minTerm = null;\n      } else {\n        BytesRef bb = terms.getMin();\n        if (bb != null) {\n          assert bb.isValid();\n          minTerm = BytesRef.deepCopyOf(bb);\n        } else {\n          minTerm = null;\n        }\n\n        bb = terms.getMax();\n        if (bb != null) {\n          assert bb.isValid();\n          maxTerm = BytesRef.deepCopyOf(bb);\n          if (minTerm == null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n          }\n        } else {\n          maxTerm = null;\n          if (minTerm != null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n          }\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator();\n\n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      long upto = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        // System.out.println(\"CI: field=\" + field + \" check term=\" + term + \" docFreq=\" + termsEnum.docFreq());\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n\n        if (isVectors == false) {\n          if (minTerm == null) {\n            // We checked this above:\n            assert maxTerm == null;\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(minTerm) < 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(maxTerm) > 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n          }\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n\n        postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = postings.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = postings.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (postings.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos > IndexWriter.MAX_POSITION) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" > IndexWriter.MAX_POSITION=\" + IndexWriter.MAX_POSITION);\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            postings = termsEnum.postings(null, postings);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(postings.docID());\n              docCount++;\n              totalTermFreq += postings.freq();\n            }\n          } else {\n            postings = termsEnum.postings(null, postings, PostingsEnum.NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(postings.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(liveDocs, postings, PostingsEnum.NONE);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n\n        long fieldTermCount = (status.delTermCount+status.termCount)-termCountStart;\n\n        // LUCENE-5879: this is just too slow for now:\n        if (false && hasFreqs == false) {\n          // For DOCS_ONLY fields we recursively test term ranges:\n          checkTermRanges(field, maxDoc, fieldTerms, fieldTermCount);\n        }\n\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n\n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        final int v = fieldTerms.getDocCount();\n        if (v != -1 && visitedDocs.cardinality() != v) {\n          throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          if (termsEnum.term().equals(lastTerm.get()) == false) {\n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, null, PostingsEnum.NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm.toBytesRef() + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if (fieldTermCount > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != fieldTermCount) {\n            throw new RuntimeException(\"termCount mismatch \" + termCount + \" vs \" + fieldTermCount);\n          }\n        }\n\n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              long actualOrd = termsEnum.ord();\n              if (actualOrd != ord) {\n                throw new RuntimeException(\"seek to ord \" + ord + \" returned ord \" + actualOrd);\n              }\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              if (termsEnum.term().equals(seekTerms[i]) == false) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n              }\n              \n              postings = termsEnum.postings(liveDocs, postings, PostingsEnum.NONE);\n              if (postings == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n\n              while (postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              postings = termsEnum.postings(null, postings, PostingsEnum.NONE);\n              if (postings == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, String.format(Locale.ROOT, \"OK [%d terms; %d terms/docs pairs; %d tokens] [took %.3f sec]\",\n                                    status.termCount, status.totFreq, status.totPos, nsToSec(System.nanoTime()-startNS)));\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    long startNS;\n    if (doPrint) {\n      startNS = System.nanoTime();\n    } else {\n      startNS = 0;\n    }\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef maxTerm;\n      BytesRef minTerm;\n      if (isVectors) {\n        // Term vectors impls can be very slow for getMax\n        maxTerm = null;\n        minTerm = null;\n      } else {\n        BytesRef bb = terms.getMin();\n        if (bb != null) {\n          assert bb.isValid();\n          minTerm = BytesRef.deepCopyOf(bb);\n        } else {\n          minTerm = null;\n        }\n\n        bb = terms.getMax();\n        if (bb != null) {\n          assert bb.isValid();\n          maxTerm = BytesRef.deepCopyOf(bb);\n          if (minTerm == null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n          }\n        } else {\n          maxTerm = null;\n          if (minTerm != null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n          }\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator();\n\n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      long upto = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        // System.out.println(\"CI: field=\" + field + \" check term=\" + term + \" docFreq=\" + termsEnum.docFreq());\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n\n        if (isVectors == false) {\n          if (minTerm == null) {\n            // We checked this above:\n            assert maxTerm == null;\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(minTerm) < 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(maxTerm) > 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n          }\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n\n        postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = postings.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = postings.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (postings.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos > IndexWriter.MAX_POSITION) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" > IndexWriter.MAX_POSITION=\" + IndexWriter.MAX_POSITION);\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            postings = termsEnum.postings(null, postings);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(postings.docID());\n              docCount++;\n              totalTermFreq += postings.freq();\n            }\n          } else {\n            postings = termsEnum.postings(null, postings, PostingsEnum.NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(postings.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(liveDocs, postings, PostingsEnum.NONE);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n\n        long fieldTermCount = (status.delTermCount+status.termCount)-termCountStart;\n\n        // LUCENE-5879: this is just too slow for now:\n        if (false && hasFreqs == false) {\n          // For DOCS_ONLY fields we recursively test term ranges:\n          checkTermRanges(field, maxDoc, fieldTerms, fieldTermCount);\n        }\n\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n\n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        final int v = fieldTerms.getDocCount();\n        if (v != -1 && visitedDocs.cardinality() != v) {\n          throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          if (termsEnum.term().equals(lastTerm.get()) == false) {\n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, null, PostingsEnum.NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm.toBytesRef() + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if (fieldTermCount > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != fieldTermCount) {\n            throw new RuntimeException(\"termCount mismatch \" + termCount + \" vs \" + fieldTermCount);\n          }\n        }\n\n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              if (termsEnum.term().equals(seekTerms[i]) == false) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n              }\n              \n              postings = termsEnum.postings(liveDocs, postings, PostingsEnum.NONE);\n              if (postings == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n\n              while (postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              postings = termsEnum.postings(null, postings, PostingsEnum.NONE);\n              if (postings == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, String.format(Locale.ROOT, \"OK [%d terms; %d terms/docs pairs; %d tokens] [took %.3f sec]\",\n                                    status.termCount, status.totFreq, status.totPos, nsToSec(System.nanoTime()-startNS)));\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0f4464508ee83288c8c4585b533f9faaa93aa314","date":1435240759,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","sourceNew":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    long startNS;\n    if (doPrint) {\n      startNS = System.nanoTime();\n    } else {\n      startNS = 0;\n    }\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef maxTerm;\n      BytesRef minTerm;\n      if (isVectors) {\n        // Term vectors impls can be very slow for getMax\n        maxTerm = null;\n        minTerm = null;\n      } else {\n        BytesRef bb = terms.getMin();\n        if (bb != null) {\n          assert bb.isValid();\n          minTerm = BytesRef.deepCopyOf(bb);\n        } else {\n          minTerm = null;\n        }\n\n        bb = terms.getMax();\n        if (bb != null) {\n          assert bb.isValid();\n          maxTerm = BytesRef.deepCopyOf(bb);\n          if (minTerm == null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n          }\n        } else {\n          maxTerm = null;\n          if (minTerm != null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n          }\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator();\n\n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        // System.out.println(\"CI: field=\" + field + \" check term=\" + term + \" docFreq=\" + termsEnum.docFreq());\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n\n        if (isVectors == false) {\n          if (minTerm == null) {\n            // We checked this above:\n            assert maxTerm == null;\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(minTerm) < 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(maxTerm) > 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n          }\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n\n        postings = termsEnum.postings(postings, PostingsEnum.ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        boolean hasNonDeletedDocs = false;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = postings.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = postings.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (postings.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          if (liveDocs == null || liveDocs.get(doc)) {\n            hasNonDeletedDocs = true;\n            status.totFreq++;\n            if (freq >= 0) {\n              status.totPos += freq;\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos > IndexWriter.MAX_POSITION) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" > IndexWriter.MAX_POSITION=\" + IndexWriter.MAX_POSITION);\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (hasNonDeletedDocs) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(postings, PostingsEnum.ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(postings, PostingsEnum.NONE);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n\n        long fieldTermCount = (status.delTermCount+status.termCount)-termCountStart;\n\n        // LUCENE-5879: this is just too slow for now:\n        if (false && hasFreqs == false) {\n          // For DOCS_ONLY fields we recursively test term ranges:\n          checkTermRanges(field, maxDoc, fieldTerms, fieldTermCount);\n        }\n\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n\n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        final int v = fieldTerms.getDocCount();\n        if (v != -1 && visitedDocs.cardinality() != v) {\n          throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          if (termsEnum.term().equals(lastTerm.get()) == false) {\n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, PostingsEnum.NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm.toBytesRef() + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if (fieldTermCount > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != fieldTermCount) {\n            throw new RuntimeException(\"termCount mismatch \" + termCount + \" vs \" + fieldTermCount);\n          }\n        }\n\n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              long actualOrd = termsEnum.ord();\n              if (actualOrd != ord) {\n                throw new RuntimeException(\"seek to ord \" + ord + \" returned ord \" + actualOrd);\n              }\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              if (termsEnum.term().equals(seekTerms[i]) == false) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n              }\n              \n              postings = termsEnum.postings(postings, PostingsEnum.NONE);\n              if (postings == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, String.format(Locale.ROOT, \"OK [%d terms; %d terms/docs pairs; %d tokens] [took %.3f sec]\",\n                                    status.termCount, status.totFreq, status.totPos, nsToSec(System.nanoTime()-startNS)));\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    long startNS;\n    if (doPrint) {\n      startNS = System.nanoTime();\n    } else {\n      startNS = 0;\n    }\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef maxTerm;\n      BytesRef minTerm;\n      if (isVectors) {\n        // Term vectors impls can be very slow for getMax\n        maxTerm = null;\n        minTerm = null;\n      } else {\n        BytesRef bb = terms.getMin();\n        if (bb != null) {\n          assert bb.isValid();\n          minTerm = BytesRef.deepCopyOf(bb);\n        } else {\n          minTerm = null;\n        }\n\n        bb = terms.getMax();\n        if (bb != null) {\n          assert bb.isValid();\n          maxTerm = BytesRef.deepCopyOf(bb);\n          if (minTerm == null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n          }\n        } else {\n          maxTerm = null;\n          if (minTerm != null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n          }\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator();\n\n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      long upto = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        // System.out.println(\"CI: field=\" + field + \" check term=\" + term + \" docFreq=\" + termsEnum.docFreq());\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n\n        if (isVectors == false) {\n          if (minTerm == null) {\n            // We checked this above:\n            assert maxTerm == null;\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(minTerm) < 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(maxTerm) > 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n          }\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n\n        postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = postings.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          status.totFreq++;\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = postings.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            status.totPos += freq;\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (postings.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos > IndexWriter.MAX_POSITION) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" > IndexWriter.MAX_POSITION=\" + IndexWriter.MAX_POSITION);\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (docCount != 0) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        // Re-count if there are deleted docs:\n        if (liveDocs != null) {\n          if (hasFreqs) {\n            postings = termsEnum.postings(null, postings);\n            docCount = 0;\n            totalTermFreq = 0;\n            while(postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(postings.docID());\n              docCount++;\n              totalTermFreq += postings.freq();\n            }\n          } else {\n            postings = termsEnum.postings(null, postings, PostingsEnum.NONE);\n            docCount = 0;\n            totalTermFreq = -1;\n            while(postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              visitedDocs.set(postings.docID());\n              docCount++;\n            }\n          }\n        }\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(liveDocs, postings, PostingsEnum.NONE);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n\n        long fieldTermCount = (status.delTermCount+status.termCount)-termCountStart;\n\n        // LUCENE-5879: this is just too slow for now:\n        if (false && hasFreqs == false) {\n          // For DOCS_ONLY fields we recursively test term ranges:\n          checkTermRanges(field, maxDoc, fieldTerms, fieldTermCount);\n        }\n\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n\n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        final int v = fieldTerms.getDocCount();\n        if (v != -1 && visitedDocs.cardinality() != v) {\n          throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          if (termsEnum.term().equals(lastTerm.get()) == false) {\n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, null, PostingsEnum.NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm.toBytesRef() + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if (fieldTermCount > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != fieldTermCount) {\n            throw new RuntimeException(\"termCount mismatch \" + termCount + \" vs \" + fieldTermCount);\n          }\n        }\n\n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              long actualOrd = termsEnum.ord();\n              if (actualOrd != ord) {\n                throw new RuntimeException(\"seek to ord \" + ord + \" returned ord \" + actualOrd);\n              }\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            long totDocCount = 0;\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              if (termsEnum.term().equals(seekTerms[i]) == false) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n              }\n              \n              postings = termsEnum.postings(liveDocs, postings, PostingsEnum.NONE);\n              if (postings == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n\n              while (postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCount++;\n              }\n            }\n            \n            long totDocCountNoDeletes = 0;\n            long totDocFreq = 0;\n            for(int i=0;i<seekCount;i++) {\n              if (!termsEnum.seekExact(seekTerms[i])) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              \n              totDocFreq += termsEnum.docFreq();\n              postings = termsEnum.postings(null, postings, PostingsEnum.NONE);\n              if (postings == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n              \n              while(postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                totDocCountNoDeletes++;\n              }\n            }\n            \n            if (totDocCount > totDocCountNoDeletes) {\n              throw new RuntimeException(\"more postings with deletes=\" + totDocCount + \" than without=\" + totDocCountNoDeletes);\n            }\n            \n            if (totDocCountNoDeletes != totDocFreq) {\n              throw new RuntimeException(\"docfreqs=\" + totDocFreq + \" != recomputed docfreqs=\" + totDocCountNoDeletes);\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, String.format(Locale.ROOT, \"OK [%d terms; %d terms/docs pairs; %d tokens] [took %.3f sec]\",\n                                    status.termCount, status.totFreq, status.totPos, nsToSec(System.nanoTime()-startNS)));\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"158039752283f0c5acd00ec298d83fad2a0a1971","date":1456478848,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","sourceNew":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    long startNS;\n    if (doPrint) {\n      startNS = System.nanoTime();\n    } else {\n      startNS = 0;\n    }\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef maxTerm;\n      BytesRef minTerm;\n      if (isVectors) {\n        // Term vectors impls can be very slow for getMax\n        maxTerm = null;\n        minTerm = null;\n      } else {\n        BytesRef bb = terms.getMin();\n        if (bb != null) {\n          assert bb.isValid();\n          minTerm = BytesRef.deepCopyOf(bb);\n        } else {\n          minTerm = null;\n        }\n\n        bb = terms.getMax();\n        if (bb != null) {\n          assert bb.isValid();\n          maxTerm = BytesRef.deepCopyOf(bb);\n          if (minTerm == null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n          }\n        } else {\n          maxTerm = null;\n          if (minTerm != null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n          }\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator();\n\n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        // System.out.println(\"CI: field=\" + field + \" check term=\" + term + \" docFreq=\" + termsEnum.docFreq());\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm.get() + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n\n        if (isVectors == false) {\n          if (minTerm == null) {\n            // We checked this above:\n            assert maxTerm == null;\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(minTerm) < 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(maxTerm) > 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n          }\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n\n        postings = termsEnum.postings(postings, PostingsEnum.ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        boolean hasNonDeletedDocs = false;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = postings.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = postings.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (postings.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          if (liveDocs == null || liveDocs.get(doc)) {\n            hasNonDeletedDocs = true;\n            status.totFreq++;\n            if (freq >= 0) {\n              status.totPos += freq;\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos > IndexWriter.MAX_POSITION) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" > IndexWriter.MAX_POSITION=\" + IndexWriter.MAX_POSITION);\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (hasNonDeletedDocs) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(postings, PostingsEnum.ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(postings, PostingsEnum.NONE);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n\n        long fieldTermCount = (status.delTermCount+status.termCount)-termCountStart;\n\n        // LUCENE-5879: this is just too slow for now:\n        if (false && hasFreqs == false) {\n          // For DOCS_ONLY fields we recursively test term ranges:\n          checkTermRanges(field, maxDoc, fieldTerms, fieldTermCount);\n        }\n\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n\n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        final int v = fieldTerms.getDocCount();\n        if (v != -1 && visitedDocs.cardinality() != v) {\n          throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" failed\");\n          }\n          if (termsEnum.term().equals(lastTerm.get()) == false) {\n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, PostingsEnum.NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm.get() + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if (fieldTermCount > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != fieldTermCount) {\n            throw new RuntimeException(\"termCount mismatch \" + termCount + \" vs \" + fieldTermCount);\n          }\n        }\n\n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              long actualOrd = termsEnum.ord();\n              if (actualOrd != ord) {\n                throw new RuntimeException(\"seek to ord \" + ord + \" returned ord \" + actualOrd);\n              }\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              if (termsEnum.term().equals(seekTerms[i]) == false) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n              }\n              \n              postings = termsEnum.postings(postings, PostingsEnum.NONE);\n              if (postings == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, String.format(Locale.ROOT, \"OK [%d terms; %d terms/docs pairs; %d tokens] [took %.3f sec]\",\n                                    status.termCount, status.totFreq, status.totPos, nsToSec(System.nanoTime()-startNS)));\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    long startNS;\n    if (doPrint) {\n      startNS = System.nanoTime();\n    } else {\n      startNS = 0;\n    }\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef maxTerm;\n      BytesRef minTerm;\n      if (isVectors) {\n        // Term vectors impls can be very slow for getMax\n        maxTerm = null;\n        minTerm = null;\n      } else {\n        BytesRef bb = terms.getMin();\n        if (bb != null) {\n          assert bb.isValid();\n          minTerm = BytesRef.deepCopyOf(bb);\n        } else {\n          minTerm = null;\n        }\n\n        bb = terms.getMax();\n        if (bb != null) {\n          assert bb.isValid();\n          maxTerm = BytesRef.deepCopyOf(bb);\n          if (minTerm == null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n          }\n        } else {\n          maxTerm = null;\n          if (minTerm != null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n          }\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator();\n\n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        // System.out.println(\"CI: field=\" + field + \" check term=\" + term + \" docFreq=\" + termsEnum.docFreq());\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n\n        if (isVectors == false) {\n          if (minTerm == null) {\n            // We checked this above:\n            assert maxTerm == null;\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(minTerm) < 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(maxTerm) > 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n          }\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n\n        postings = termsEnum.postings(postings, PostingsEnum.ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        boolean hasNonDeletedDocs = false;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = postings.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = postings.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (postings.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          if (liveDocs == null || liveDocs.get(doc)) {\n            hasNonDeletedDocs = true;\n            status.totFreq++;\n            if (freq >= 0) {\n              status.totPos += freq;\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos > IndexWriter.MAX_POSITION) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" > IndexWriter.MAX_POSITION=\" + IndexWriter.MAX_POSITION);\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (hasNonDeletedDocs) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(postings, PostingsEnum.ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(postings, PostingsEnum.NONE);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n\n        long fieldTermCount = (status.delTermCount+status.termCount)-termCountStart;\n\n        // LUCENE-5879: this is just too slow for now:\n        if (false && hasFreqs == false) {\n          // For DOCS_ONLY fields we recursively test term ranges:\n          checkTermRanges(field, maxDoc, fieldTerms, fieldTermCount);\n        }\n\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n\n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        final int v = fieldTerms.getDocCount();\n        if (v != -1 && visitedDocs.cardinality() != v) {\n          throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n          }\n          if (termsEnum.term().equals(lastTerm.get()) == false) {\n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, PostingsEnum.NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm.toBytesRef() + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if (fieldTermCount > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != fieldTermCount) {\n            throw new RuntimeException(\"termCount mismatch \" + termCount + \" vs \" + fieldTermCount);\n          }\n        }\n\n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              long actualOrd = termsEnum.ord();\n              if (actualOrd != ord) {\n                throw new RuntimeException(\"seek to ord \" + ord + \" returned ord \" + actualOrd);\n              }\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              if (termsEnum.term().equals(seekTerms[i]) == false) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n              }\n              \n              postings = termsEnum.postings(postings, PostingsEnum.NONE);\n              if (postings == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, String.format(Locale.ROOT, \"OK [%d terms; %d terms/docs pairs; %d tokens] [took %.3f sec]\",\n                                    status.termCount, status.totFreq, status.totPos, nsToSec(System.nanoTime()-startNS)));\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"762c80e29fe0c3bb83aabe2e64af6379273cec7b","date":1484347562,"type":5,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean,Version).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","sourceNew":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose, Version version) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    long startNS;\n    if (doPrint) {\n      startNS = System.nanoTime();\n    } else {\n      startNS = 0;\n    }\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef maxTerm;\n      BytesRef minTerm;\n      if (isVectors) {\n        // Term vectors impls can be very slow for getMax\n        maxTerm = null;\n        minTerm = null;\n      } else {\n        BytesRef bb = terms.getMin();\n        if (bb != null) {\n          assert bb.isValid();\n          minTerm = BytesRef.deepCopyOf(bb);\n        } else {\n          minTerm = null;\n        }\n\n        bb = terms.getMax();\n        if (bb != null) {\n          assert bb.isValid();\n          maxTerm = BytesRef.deepCopyOf(bb);\n          if (minTerm == null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n          }\n        } else {\n          maxTerm = null;\n          if (minTerm != null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n          }\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator();\n\n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        // System.out.println(\"CI: field=\" + field + \" check term=\" + term + \" docFreq=\" + termsEnum.docFreq());\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm.get() + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n\n        if (isVectors == false) {\n          if (minTerm == null) {\n            // We checked this above:\n            assert maxTerm == null;\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(minTerm) < 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(maxTerm) > 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n          }\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n\n        postings = termsEnum.postings(postings, PostingsEnum.ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        boolean hasNonDeletedDocs = false;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = postings.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = postings.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (postings.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          if (liveDocs == null || liveDocs.get(doc)) {\n            hasNonDeletedDocs = true;\n            status.totFreq++;\n            if (freq >= 0) {\n              status.totPos += freq;\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos > IndexWriter.MAX_POSITION) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" > IndexWriter.MAX_POSITION=\" + IndexWriter.MAX_POSITION);\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // In Lucene 7 we fixed IndexWriter to also enforce term vector offsets\n                if (isVectors == false || version.onOrAfter(Version.LUCENE_7_0_0)) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset + \"; consider using the FixBrokenOffsets tool in Lucene's backward-codecs module to correct your index\");\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (hasNonDeletedDocs) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(postings, PostingsEnum.ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(postings, PostingsEnum.NONE);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n\n        long fieldTermCount = (status.delTermCount+status.termCount)-termCountStart;\n\n        // LUCENE-5879: this is just too slow for now:\n        if (false && hasFreqs == false) {\n          // For DOCS_ONLY fields we recursively test term ranges:\n          checkTermRanges(field, maxDoc, fieldTerms, fieldTermCount);\n        }\n\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n\n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        final int v = fieldTerms.getDocCount();\n        if (v != -1 && visitedDocs.cardinality() != v) {\n          throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" failed\");\n          }\n          if (termsEnum.term().equals(lastTerm.get()) == false) {\n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, PostingsEnum.NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm.get() + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if (fieldTermCount > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != fieldTermCount) {\n            throw new RuntimeException(\"termCount mismatch \" + termCount + \" vs \" + fieldTermCount);\n          }\n        }\n\n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              long actualOrd = termsEnum.ord();\n              if (actualOrd != ord) {\n                throw new RuntimeException(\"seek to ord \" + ord + \" returned ord \" + actualOrd);\n              }\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              if (termsEnum.term().equals(seekTerms[i]) == false) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n              }\n              \n              postings = termsEnum.postings(postings, PostingsEnum.NONE);\n              if (postings == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, String.format(Locale.ROOT, \"OK [%d terms; %d terms/docs pairs; %d tokens] [took %.3f sec]\",\n                                    status.termCount, status.totFreq, status.totPos, nsToSec(System.nanoTime()-startNS)));\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    long startNS;\n    if (doPrint) {\n      startNS = System.nanoTime();\n    } else {\n      startNS = 0;\n    }\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef maxTerm;\n      BytesRef minTerm;\n      if (isVectors) {\n        // Term vectors impls can be very slow for getMax\n        maxTerm = null;\n        minTerm = null;\n      } else {\n        BytesRef bb = terms.getMin();\n        if (bb != null) {\n          assert bb.isValid();\n          minTerm = BytesRef.deepCopyOf(bb);\n        } else {\n          minTerm = null;\n        }\n\n        bb = terms.getMax();\n        if (bb != null) {\n          assert bb.isValid();\n          maxTerm = BytesRef.deepCopyOf(bb);\n          if (minTerm == null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n          }\n        } else {\n          maxTerm = null;\n          if (minTerm != null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n          }\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator();\n\n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        // System.out.println(\"CI: field=\" + field + \" check term=\" + term + \" docFreq=\" + termsEnum.docFreq());\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm.get() + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n\n        if (isVectors == false) {\n          if (minTerm == null) {\n            // We checked this above:\n            assert maxTerm == null;\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(minTerm) < 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(maxTerm) > 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n          }\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n\n        postings = termsEnum.postings(postings, PostingsEnum.ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        boolean hasNonDeletedDocs = false;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = postings.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = postings.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (postings.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          if (liveDocs == null || liveDocs.get(doc)) {\n            hasNonDeletedDocs = true;\n            status.totFreq++;\n            if (freq >= 0) {\n              status.totPos += freq;\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos > IndexWriter.MAX_POSITION) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" > IndexWriter.MAX_POSITION=\" + IndexWriter.MAX_POSITION);\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (hasNonDeletedDocs) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(postings, PostingsEnum.ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(postings, PostingsEnum.NONE);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n\n        long fieldTermCount = (status.delTermCount+status.termCount)-termCountStart;\n\n        // LUCENE-5879: this is just too slow for now:\n        if (false && hasFreqs == false) {\n          // For DOCS_ONLY fields we recursively test term ranges:\n          checkTermRanges(field, maxDoc, fieldTerms, fieldTermCount);\n        }\n\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n\n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        final int v = fieldTerms.getDocCount();\n        if (v != -1 && visitedDocs.cardinality() != v) {\n          throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" failed\");\n          }\n          if (termsEnum.term().equals(lastTerm.get()) == false) {\n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, PostingsEnum.NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm.get() + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if (fieldTermCount > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != fieldTermCount) {\n            throw new RuntimeException(\"termCount mismatch \" + termCount + \" vs \" + fieldTermCount);\n          }\n        }\n\n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              long actualOrd = termsEnum.ord();\n              if (actualOrd != ord) {\n                throw new RuntimeException(\"seek to ord \" + ord + \" returned ord \" + actualOrd);\n              }\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              if (termsEnum.term().equals(seekTerms[i]) == false) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n              }\n              \n              postings = termsEnum.postings(postings, PostingsEnum.NONE);\n              if (postings == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, String.format(Locale.ROOT, \"OK [%d terms; %d terms/docs pairs; %d tokens] [took %.3f sec]\",\n                                    status.termCount, status.totFreq, status.totPos, nsToSec(System.nanoTime()-startNS)));\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"507e7decdf00981d09a74632ea30299a4ce6ba72","date":1484600874,"type":5,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean,Version).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","sourceNew":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose, Version version) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    long startNS;\n    if (doPrint) {\n      startNS = System.nanoTime();\n    } else {\n      startNS = 0;\n    }\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef maxTerm;\n      BytesRef minTerm;\n      if (isVectors) {\n        // Term vectors impls can be very slow for getMax\n        maxTerm = null;\n        minTerm = null;\n      } else {\n        BytesRef bb = terms.getMin();\n        if (bb != null) {\n          assert bb.isValid();\n          minTerm = BytesRef.deepCopyOf(bb);\n        } else {\n          minTerm = null;\n        }\n\n        bb = terms.getMax();\n        if (bb != null) {\n          assert bb.isValid();\n          maxTerm = BytesRef.deepCopyOf(bb);\n          if (minTerm == null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n          }\n        } else {\n          maxTerm = null;\n          if (minTerm != null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n          }\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator();\n\n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        // System.out.println(\"CI: field=\" + field + \" check term=\" + term + \" docFreq=\" + termsEnum.docFreq());\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm.get() + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n\n        if (isVectors == false) {\n          if (minTerm == null) {\n            // We checked this above:\n            assert maxTerm == null;\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(minTerm) < 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(maxTerm) > 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n          }\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n\n        postings = termsEnum.postings(postings, PostingsEnum.ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        boolean hasNonDeletedDocs = false;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = postings.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = postings.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (postings.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          if (liveDocs == null || liveDocs.get(doc)) {\n            hasNonDeletedDocs = true;\n            status.totFreq++;\n            if (freq >= 0) {\n              status.totPos += freq;\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos > IndexWriter.MAX_POSITION) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" > IndexWriter.MAX_POSITION=\" + IndexWriter.MAX_POSITION);\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // In Lucene 7 we fixed IndexWriter to also enforce term vector offsets\n                if (isVectors == false || version.onOrAfter(Version.LUCENE_7_0_0)) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset + \"; consider using the FixBrokenOffsets tool in Lucene's backward-codecs module to correct your index\");\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (hasNonDeletedDocs) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(postings, PostingsEnum.ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(postings, PostingsEnum.NONE);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n\n        long fieldTermCount = (status.delTermCount+status.termCount)-termCountStart;\n\n        // LUCENE-5879: this is just too slow for now:\n        if (false && hasFreqs == false) {\n          // For DOCS_ONLY fields we recursively test term ranges:\n          checkTermRanges(field, maxDoc, fieldTerms, fieldTermCount);\n        }\n\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n\n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        final int v = fieldTerms.getDocCount();\n        if (v != -1 && visitedDocs.cardinality() != v) {\n          throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" failed\");\n          }\n          if (termsEnum.term().equals(lastTerm.get()) == false) {\n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, PostingsEnum.NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm.get() + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if (fieldTermCount > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != fieldTermCount) {\n            throw new RuntimeException(\"termCount mismatch \" + termCount + \" vs \" + fieldTermCount);\n          }\n        }\n\n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              long actualOrd = termsEnum.ord();\n              if (actualOrd != ord) {\n                throw new RuntimeException(\"seek to ord \" + ord + \" returned ord \" + actualOrd);\n              }\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              if (termsEnum.term().equals(seekTerms[i]) == false) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n              }\n              \n              postings = termsEnum.postings(postings, PostingsEnum.NONE);\n              if (postings == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, String.format(Locale.ROOT, \"OK [%d terms; %d terms/docs pairs; %d tokens] [took %.3f sec]\",\n                                    status.termCount, status.totFreq, status.totPos, nsToSec(System.nanoTime()-startNS)));\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    long startNS;\n    if (doPrint) {\n      startNS = System.nanoTime();\n    } else {\n      startNS = 0;\n    }\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef maxTerm;\n      BytesRef minTerm;\n      if (isVectors) {\n        // Term vectors impls can be very slow for getMax\n        maxTerm = null;\n        minTerm = null;\n      } else {\n        BytesRef bb = terms.getMin();\n        if (bb != null) {\n          assert bb.isValid();\n          minTerm = BytesRef.deepCopyOf(bb);\n        } else {\n          minTerm = null;\n        }\n\n        bb = terms.getMax();\n        if (bb != null) {\n          assert bb.isValid();\n          maxTerm = BytesRef.deepCopyOf(bb);\n          if (minTerm == null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n          }\n        } else {\n          maxTerm = null;\n          if (minTerm != null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n          }\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator();\n\n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        // System.out.println(\"CI: field=\" + field + \" check term=\" + term + \" docFreq=\" + termsEnum.docFreq());\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm.get() + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n\n        if (isVectors == false) {\n          if (minTerm == null) {\n            // We checked this above:\n            assert maxTerm == null;\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(minTerm) < 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(maxTerm) > 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n          }\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n\n        postings = termsEnum.postings(postings, PostingsEnum.ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        boolean hasNonDeletedDocs = false;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = postings.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = postings.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (postings.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          if (liveDocs == null || liveDocs.get(doc)) {\n            hasNonDeletedDocs = true;\n            status.totFreq++;\n            if (freq >= 0) {\n              status.totPos += freq;\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos > IndexWriter.MAX_POSITION) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" > IndexWriter.MAX_POSITION=\" + IndexWriter.MAX_POSITION);\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                if (!isVectors) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (hasNonDeletedDocs) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(postings, PostingsEnum.ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(postings, PostingsEnum.NONE);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n\n        long fieldTermCount = (status.delTermCount+status.termCount)-termCountStart;\n\n        // LUCENE-5879: this is just too slow for now:\n        if (false && hasFreqs == false) {\n          // For DOCS_ONLY fields we recursively test term ranges:\n          checkTermRanges(field, maxDoc, fieldTerms, fieldTermCount);\n        }\n\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n\n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        final int v = fieldTerms.getDocCount();\n        if (v != -1 && visitedDocs.cardinality() != v) {\n          throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" failed\");\n          }\n          if (termsEnum.term().equals(lastTerm.get()) == false) {\n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, PostingsEnum.NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm.get() + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if (fieldTermCount > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != fieldTermCount) {\n            throw new RuntimeException(\"termCount mismatch \" + termCount + \" vs \" + fieldTermCount);\n          }\n        }\n\n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              long actualOrd = termsEnum.ord();\n              if (actualOrd != ord) {\n                throw new RuntimeException(\"seek to ord \" + ord + \" returned ord \" + actualOrd);\n              }\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              if (termsEnum.term().equals(seekTerms[i]) == false) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n              }\n              \n              postings = termsEnum.postings(postings, PostingsEnum.NONE);\n              if (postings == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, String.format(Locale.ROOT, \"OK [%d terms; %d terms/docs pairs; %d tokens] [took %.3f sec]\",\n                                    status.termCount, status.totFreq, status.totPos, nsToSec(System.nanoTime()-startNS)));\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cd7538cbbd9c304bc5396980e9802cd3a5bcf8e4","date":1499084229,"type":1,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean,Version).mjava","sourceNew":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    long startNS;\n    if (doPrint) {\n      startNS = System.nanoTime();\n    } else {\n      startNS = 0;\n    }\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef maxTerm;\n      BytesRef minTerm;\n      if (isVectors) {\n        // Term vectors impls can be very slow for getMax\n        maxTerm = null;\n        minTerm = null;\n      } else {\n        BytesRef bb = terms.getMin();\n        if (bb != null) {\n          assert bb.isValid();\n          minTerm = BytesRef.deepCopyOf(bb);\n        } else {\n          minTerm = null;\n        }\n\n        bb = terms.getMax();\n        if (bb != null) {\n          assert bb.isValid();\n          maxTerm = BytesRef.deepCopyOf(bb);\n          if (minTerm == null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n          }\n        } else {\n          maxTerm = null;\n          if (minTerm != null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n          }\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator();\n\n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        // System.out.println(\"CI: field=\" + field + \" check term=\" + term + \" docFreq=\" + termsEnum.docFreq());\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm.get() + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n\n        if (isVectors == false) {\n          if (minTerm == null) {\n            // We checked this above:\n            assert maxTerm == null;\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(minTerm) < 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(maxTerm) > 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n          }\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n\n        postings = termsEnum.postings(postings, PostingsEnum.ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        boolean hasNonDeletedDocs = false;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = postings.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = postings.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (postings.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          if (liveDocs == null || liveDocs.get(doc)) {\n            hasNonDeletedDocs = true;\n            status.totFreq++;\n            if (freq >= 0) {\n              status.totPos += freq;\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos > IndexWriter.MAX_POSITION) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" > IndexWriter.MAX_POSITION=\" + IndexWriter.MAX_POSITION);\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                if (startOffset < 0) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                }\n                if (startOffset < lastOffset) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset + \"; consider using the FixBrokenOffsets tool in Lucene's backward-codecs module to correct your index\");\n                }\n                if (endOffset < 0) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                }\n                if (endOffset < startOffset) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (hasNonDeletedDocs) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(postings, PostingsEnum.ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(postings, PostingsEnum.NONE);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n\n        long fieldTermCount = (status.delTermCount+status.termCount)-termCountStart;\n\n        // LUCENE-5879: this is just too slow for now:\n        if (false && hasFreqs == false) {\n          // For DOCS_ONLY fields we recursively test term ranges:\n          checkTermRanges(field, maxDoc, fieldTerms, fieldTermCount);\n        }\n\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n\n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        final int v = fieldTerms.getDocCount();\n        if (v != -1 && visitedDocs.cardinality() != v) {\n          throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" failed\");\n          }\n          if (termsEnum.term().equals(lastTerm.get()) == false) {\n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, PostingsEnum.NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm.get() + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if (fieldTermCount > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != fieldTermCount) {\n            throw new RuntimeException(\"termCount mismatch \" + termCount + \" vs \" + fieldTermCount);\n          }\n        }\n\n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              long actualOrd = termsEnum.ord();\n              if (actualOrd != ord) {\n                throw new RuntimeException(\"seek to ord \" + ord + \" returned ord \" + actualOrd);\n              }\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              if (termsEnum.term().equals(seekTerms[i]) == false) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n              }\n              \n              postings = termsEnum.postings(postings, PostingsEnum.NONE);\n              if (postings == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, String.format(Locale.ROOT, \"OK [%d terms; %d terms/docs pairs; %d tokens] [took %.3f sec]\",\n                                    status.termCount, status.totFreq, status.totPos, nsToSec(System.nanoTime()-startNS)));\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose, Version version) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    long startNS;\n    if (doPrint) {\n      startNS = System.nanoTime();\n    } else {\n      startNS = 0;\n    }\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef maxTerm;\n      BytesRef minTerm;\n      if (isVectors) {\n        // Term vectors impls can be very slow for getMax\n        maxTerm = null;\n        minTerm = null;\n      } else {\n        BytesRef bb = terms.getMin();\n        if (bb != null) {\n          assert bb.isValid();\n          minTerm = BytesRef.deepCopyOf(bb);\n        } else {\n          minTerm = null;\n        }\n\n        bb = terms.getMax();\n        if (bb != null) {\n          assert bb.isValid();\n          maxTerm = BytesRef.deepCopyOf(bb);\n          if (minTerm == null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n          }\n        } else {\n          maxTerm = null;\n          if (minTerm != null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n          }\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator();\n\n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        // System.out.println(\"CI: field=\" + field + \" check term=\" + term + \" docFreq=\" + termsEnum.docFreq());\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm.get() + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n\n        if (isVectors == false) {\n          if (minTerm == null) {\n            // We checked this above:\n            assert maxTerm == null;\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(minTerm) < 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(maxTerm) > 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n          }\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n\n        postings = termsEnum.postings(postings, PostingsEnum.ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        boolean hasNonDeletedDocs = false;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = postings.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = postings.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (postings.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          if (liveDocs == null || liveDocs.get(doc)) {\n            hasNonDeletedDocs = true;\n            status.totFreq++;\n            if (freq >= 0) {\n              status.totPos += freq;\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos > IndexWriter.MAX_POSITION) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" > IndexWriter.MAX_POSITION=\" + IndexWriter.MAX_POSITION);\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // In Lucene 7 we fixed IndexWriter to also enforce term vector offsets\n                if (isVectors == false || version.onOrAfter(Version.LUCENE_7_0_0)) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset + \"; consider using the FixBrokenOffsets tool in Lucene's backward-codecs module to correct your index\");\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (hasNonDeletedDocs) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(postings, PostingsEnum.ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(postings, PostingsEnum.NONE);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n\n        long fieldTermCount = (status.delTermCount+status.termCount)-termCountStart;\n\n        // LUCENE-5879: this is just too slow for now:\n        if (false && hasFreqs == false) {\n          // For DOCS_ONLY fields we recursively test term ranges:\n          checkTermRanges(field, maxDoc, fieldTerms, fieldTermCount);\n        }\n\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n\n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        final int v = fieldTerms.getDocCount();\n        if (v != -1 && visitedDocs.cardinality() != v) {\n          throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" failed\");\n          }\n          if (termsEnum.term().equals(lastTerm.get()) == false) {\n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, PostingsEnum.NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm.get() + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if (fieldTermCount > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != fieldTermCount) {\n            throw new RuntimeException(\"termCount mismatch \" + termCount + \" vs \" + fieldTermCount);\n          }\n        }\n\n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              long actualOrd = termsEnum.ord();\n              if (actualOrd != ord) {\n                throw new RuntimeException(\"seek to ord \" + ord + \" returned ord \" + actualOrd);\n              }\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              if (termsEnum.term().equals(seekTerms[i]) == false) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n              }\n              \n              postings = termsEnum.postings(postings, PostingsEnum.NONE);\n              if (postings == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, String.format(Locale.ROOT, \"OK [%d terms; %d terms/docs pairs; %d tokens] [took %.3f sec]\",\n                                    status.termCount, status.totFreq, status.totPos, nsToSec(System.nanoTime()-startNS)));\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cc018b79379c67835b40b1259cd3dc931df60944","date":1499109112,"type":1,"author":"Anshum Gupta","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean,Version).mjava","sourceNew":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    long startNS;\n    if (doPrint) {\n      startNS = System.nanoTime();\n    } else {\n      startNS = 0;\n    }\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef maxTerm;\n      BytesRef minTerm;\n      if (isVectors) {\n        // Term vectors impls can be very slow for getMax\n        maxTerm = null;\n        minTerm = null;\n      } else {\n        BytesRef bb = terms.getMin();\n        if (bb != null) {\n          assert bb.isValid();\n          minTerm = BytesRef.deepCopyOf(bb);\n        } else {\n          minTerm = null;\n        }\n\n        bb = terms.getMax();\n        if (bb != null) {\n          assert bb.isValid();\n          maxTerm = BytesRef.deepCopyOf(bb);\n          if (minTerm == null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n          }\n        } else {\n          maxTerm = null;\n          if (minTerm != null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n          }\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator();\n\n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        // System.out.println(\"CI: field=\" + field + \" check term=\" + term + \" docFreq=\" + termsEnum.docFreq());\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm.get() + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n\n        if (isVectors == false) {\n          if (minTerm == null) {\n            // We checked this above:\n            assert maxTerm == null;\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(minTerm) < 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(maxTerm) > 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n          }\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n\n        postings = termsEnum.postings(postings, PostingsEnum.ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        boolean hasNonDeletedDocs = false;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = postings.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = postings.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (postings.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          if (liveDocs == null || liveDocs.get(doc)) {\n            hasNonDeletedDocs = true;\n            status.totFreq++;\n            if (freq >= 0) {\n              status.totPos += freq;\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos > IndexWriter.MAX_POSITION) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" > IndexWriter.MAX_POSITION=\" + IndexWriter.MAX_POSITION);\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                if (startOffset < 0) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                }\n                if (startOffset < lastOffset) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset + \"; consider using the FixBrokenOffsets tool in Lucene's backward-codecs module to correct your index\");\n                }\n                if (endOffset < 0) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                }\n                if (endOffset < startOffset) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (hasNonDeletedDocs) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(postings, PostingsEnum.ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(postings, PostingsEnum.NONE);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n\n        long fieldTermCount = (status.delTermCount+status.termCount)-termCountStart;\n\n        // LUCENE-5879: this is just too slow for now:\n        if (false && hasFreqs == false) {\n          // For DOCS_ONLY fields we recursively test term ranges:\n          checkTermRanges(field, maxDoc, fieldTerms, fieldTermCount);\n        }\n\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n\n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        final int v = fieldTerms.getDocCount();\n        if (v != -1 && visitedDocs.cardinality() != v) {\n          throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" failed\");\n          }\n          if (termsEnum.term().equals(lastTerm.get()) == false) {\n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, PostingsEnum.NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm.get() + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if (fieldTermCount > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != fieldTermCount) {\n            throw new RuntimeException(\"termCount mismatch \" + termCount + \" vs \" + fieldTermCount);\n          }\n        }\n\n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              long actualOrd = termsEnum.ord();\n              if (actualOrd != ord) {\n                throw new RuntimeException(\"seek to ord \" + ord + \" returned ord \" + actualOrd);\n              }\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              if (termsEnum.term().equals(seekTerms[i]) == false) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n              }\n              \n              postings = termsEnum.postings(postings, PostingsEnum.NONE);\n              if (postings == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, String.format(Locale.ROOT, \"OK [%d terms; %d terms/docs pairs; %d tokens] [took %.3f sec]\",\n                                    status.termCount, status.totFreq, status.totPos, nsToSec(System.nanoTime()-startNS)));\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose, Version version) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    long startNS;\n    if (doPrint) {\n      startNS = System.nanoTime();\n    } else {\n      startNS = 0;\n    }\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef maxTerm;\n      BytesRef minTerm;\n      if (isVectors) {\n        // Term vectors impls can be very slow for getMax\n        maxTerm = null;\n        minTerm = null;\n      } else {\n        BytesRef bb = terms.getMin();\n        if (bb != null) {\n          assert bb.isValid();\n          minTerm = BytesRef.deepCopyOf(bb);\n        } else {\n          minTerm = null;\n        }\n\n        bb = terms.getMax();\n        if (bb != null) {\n          assert bb.isValid();\n          maxTerm = BytesRef.deepCopyOf(bb);\n          if (minTerm == null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n          }\n        } else {\n          maxTerm = null;\n          if (minTerm != null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n          }\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator();\n\n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        // System.out.println(\"CI: field=\" + field + \" check term=\" + term + \" docFreq=\" + termsEnum.docFreq());\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm.get() + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n\n        if (isVectors == false) {\n          if (minTerm == null) {\n            // We checked this above:\n            assert maxTerm == null;\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(minTerm) < 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(maxTerm) > 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n          }\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n\n        postings = termsEnum.postings(postings, PostingsEnum.ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        boolean hasNonDeletedDocs = false;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = postings.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = postings.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (postings.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          if (liveDocs == null || liveDocs.get(doc)) {\n            hasNonDeletedDocs = true;\n            status.totFreq++;\n            if (freq >= 0) {\n              status.totPos += freq;\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos > IndexWriter.MAX_POSITION) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" > IndexWriter.MAX_POSITION=\" + IndexWriter.MAX_POSITION);\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                // In Lucene 7 we fixed IndexWriter to also enforce term vector offsets\n                if (isVectors == false || version.onOrAfter(Version.LUCENE_7_0_0)) {\n                  if (startOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                  }\n                  if (startOffset < lastOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset + \"; consider using the FixBrokenOffsets tool in Lucene's backward-codecs module to correct your index\");\n                  }\n                  if (endOffset < 0) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                  }\n                  if (endOffset < startOffset) {\n                    throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                  }\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (hasNonDeletedDocs) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(postings, PostingsEnum.ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(postings, PostingsEnum.NONE);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n\n        long fieldTermCount = (status.delTermCount+status.termCount)-termCountStart;\n\n        // LUCENE-5879: this is just too slow for now:\n        if (false && hasFreqs == false) {\n          // For DOCS_ONLY fields we recursively test term ranges:\n          checkTermRanges(field, maxDoc, fieldTerms, fieldTermCount);\n        }\n\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n\n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        final int v = fieldTerms.getDocCount();\n        if (v != -1 && visitedDocs.cardinality() != v) {\n          throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" failed\");\n          }\n          if (termsEnum.term().equals(lastTerm.get()) == false) {\n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, PostingsEnum.NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm.get() + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if (fieldTermCount > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != fieldTermCount) {\n            throw new RuntimeException(\"termCount mismatch \" + termCount + \" vs \" + fieldTermCount);\n          }\n        }\n\n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              long actualOrd = termsEnum.ord();\n              if (actualOrd != ord) {\n                throw new RuntimeException(\"seek to ord \" + ord + \" returned ord \" + actualOrd);\n              }\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              if (termsEnum.term().equals(seekTerms[i]) == false) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n              }\n              \n              postings = termsEnum.postings(postings, PostingsEnum.NONE);\n              if (postings == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, String.format(Locale.ROOT, \"OK [%d terms; %d terms/docs pairs; %d tokens] [took %.3f sec]\",\n                                    status.termCount, status.totFreq, status.totPos, nsToSec(System.nanoTime()-startNS)));\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"30c8e5574b55d57947e989443dfde611646530ee","date":1499131153,"type":0,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    long startNS;\n    if (doPrint) {\n      startNS = System.nanoTime();\n    } else {\n      startNS = 0;\n    }\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef maxTerm;\n      BytesRef minTerm;\n      if (isVectors) {\n        // Term vectors impls can be very slow for getMax\n        maxTerm = null;\n        minTerm = null;\n      } else {\n        BytesRef bb = terms.getMin();\n        if (bb != null) {\n          assert bb.isValid();\n          minTerm = BytesRef.deepCopyOf(bb);\n        } else {\n          minTerm = null;\n        }\n\n        bb = terms.getMax();\n        if (bb != null) {\n          assert bb.isValid();\n          maxTerm = BytesRef.deepCopyOf(bb);\n          if (minTerm == null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n          }\n        } else {\n          maxTerm = null;\n          if (minTerm != null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n          }\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator();\n\n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        // System.out.println(\"CI: field=\" + field + \" check term=\" + term + \" docFreq=\" + termsEnum.docFreq());\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm.get() + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n\n        if (isVectors == false) {\n          if (minTerm == null) {\n            // We checked this above:\n            assert maxTerm == null;\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(minTerm) < 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(maxTerm) > 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n          }\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n\n        postings = termsEnum.postings(postings, PostingsEnum.ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        boolean hasNonDeletedDocs = false;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = postings.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = postings.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (postings.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          if (liveDocs == null || liveDocs.get(doc)) {\n            hasNonDeletedDocs = true;\n            status.totFreq++;\n            if (freq >= 0) {\n              status.totPos += freq;\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos > IndexWriter.MAX_POSITION) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" > IndexWriter.MAX_POSITION=\" + IndexWriter.MAX_POSITION);\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                if (startOffset < 0) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                }\n                if (startOffset < lastOffset) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset + \"; consider using the FixBrokenOffsets tool in Lucene's backward-codecs module to correct your index\");\n                }\n                if (endOffset < 0) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                }\n                if (endOffset < startOffset) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (hasNonDeletedDocs) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(postings, PostingsEnum.ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(postings, PostingsEnum.NONE);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n\n        long fieldTermCount = (status.delTermCount+status.termCount)-termCountStart;\n\n        // LUCENE-5879: this is just too slow for now:\n        if (false && hasFreqs == false) {\n          // For DOCS_ONLY fields we recursively test term ranges:\n          checkTermRanges(field, maxDoc, fieldTerms, fieldTermCount);\n        }\n\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n\n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        final int v = fieldTerms.getDocCount();\n        if (v != -1 && visitedDocs.cardinality() != v) {\n          throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" failed\");\n          }\n          if (termsEnum.term().equals(lastTerm.get()) == false) {\n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, PostingsEnum.NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm.get() + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if (fieldTermCount > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != fieldTermCount) {\n            throw new RuntimeException(\"termCount mismatch \" + termCount + \" vs \" + fieldTermCount);\n          }\n        }\n\n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              long actualOrd = termsEnum.ord();\n              if (actualOrd != ord) {\n                throw new RuntimeException(\"seek to ord \" + ord + \" returned ord \" + actualOrd);\n              }\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              if (termsEnum.term().equals(seekTerms[i]) == false) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n              }\n              \n              postings = termsEnum.postings(postings, PostingsEnum.NONE);\n              if (postings == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, String.format(Locale.ROOT, \"OK [%d terms; %d terms/docs pairs; %d tokens] [took %.3f sec]\",\n                                    status.termCount, status.totFreq, status.totPos, nsToSec(System.nanoTime()-startNS)));\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"086ffe31d8fba0110227db122974163709ecc1b4","date":1509678141,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","sourceNew":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    long startNS;\n    if (doPrint) {\n      startNS = System.nanoTime();\n    } else {\n      startNS = 0;\n    }\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      if (terms.getDocCount() > maxDoc) {\n        throw new RuntimeException(\"docCount > maxDoc for field: \" + field + \", docCount=\" + terms.getDocCount() + \", maxDoc=\" + maxDoc);\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef maxTerm;\n      BytesRef minTerm;\n      if (isVectors) {\n        // Term vectors impls can be very slow for getMax\n        maxTerm = null;\n        minTerm = null;\n      } else {\n        BytesRef bb = terms.getMin();\n        if (bb != null) {\n          assert bb.isValid();\n          minTerm = BytesRef.deepCopyOf(bb);\n        } else {\n          minTerm = null;\n        }\n\n        bb = terms.getMax();\n        if (bb != null) {\n          assert bb.isValid();\n          maxTerm = BytesRef.deepCopyOf(bb);\n          if (minTerm == null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n          }\n        } else {\n          maxTerm = null;\n          if (minTerm != null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n          }\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator();\n\n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        // System.out.println(\"CI: field=\" + field + \" check term=\" + term + \" docFreq=\" + termsEnum.docFreq());\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm.get() + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n\n        if (isVectors == false) {\n          if (minTerm == null) {\n            // We checked this above:\n            assert maxTerm == null;\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(minTerm) < 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(maxTerm) > 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n          }\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n\n        postings = termsEnum.postings(postings, PostingsEnum.ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != termsEnum.docFreq()) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be \" + termsEnum.docFreq() + \")\");\n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        boolean hasNonDeletedDocs = false;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = postings.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          visitedDocs.set(doc);\n          int freq = postings.freq();\n          if (freq <= 0) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n          }\n          if (hasFreqs == false) {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (postings.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          totalTermFreq += freq;\n\n          if (liveDocs == null || liveDocs.get(doc)) {\n            hasNonDeletedDocs = true;\n            status.totFreq++;\n            if (freq >= 0) {\n              status.totPos += freq;\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos > IndexWriter.MAX_POSITION) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" > IndexWriter.MAX_POSITION=\" + IndexWriter.MAX_POSITION);\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                if (startOffset < 0) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                }\n                if (startOffset < lastOffset) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset + \"; consider using the FixBrokenOffsets tool in Lucene's backward-codecs module to correct your index\");\n                }\n                if (endOffset < 0) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                }\n                if (endOffset < startOffset) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (hasNonDeletedDocs) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (docFreq > terms.getDocCount()) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" > docCount=\" + terms.getDocCount());\n        }\n        if (totalTermFreq2 <= 0) {\n          throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n        }\n        sumTotalTermFreq += totalTermFreq;\n        if (totalTermFreq != totalTermFreq2) {\n          throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n        }\n        if (totalTermFreq2 < docFreq) {\n          throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds, docFreq=\" + docFreq);\n        }\n        if (hasFreqs == false && totalTermFreq != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq + \" !=  docFreq=\" + docFreq);\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(postings, PostingsEnum.ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(postings, PostingsEnum.NONE);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n\n        long fieldTermCount = (status.delTermCount+status.termCount)-termCountStart;\n\n        // LUCENE-5879: this is just too slow for now:\n        if (false && hasFreqs == false) {\n          // For DOCS_ONLY fields we recursively test term ranges:\n          checkTermRanges(field, maxDoc, fieldTerms, fieldTermCount);\n        }\n\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n\n        final long actualSumDocFreq = fields.terms(field).getSumDocFreq();\n        if (sumDocFreq != actualSumDocFreq) {\n          throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + actualSumDocFreq + \" != recomputed sumDocFreq=\" + sumDocFreq);\n        }\n\n        final long actualSumTotalTermFreq = fields.terms(field).getSumTotalTermFreq();\n        if (sumTotalTermFreq != actualSumTotalTermFreq) {\n          throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + actualSumTotalTermFreq + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n        } \n        \n        if (hasFreqs == false && sumTotalTermFreq != sumDocFreq) {\n          throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \" should be \" + sumDocFreq + \", got sumTotalTermFreq=\" + sumTotalTermFreq);\n        }\n        \n        final int v = fieldTerms.getDocCount();\n        if (visitedDocs.cardinality() != v) {\n          throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" failed\");\n          }\n          if (termsEnum.term().equals(lastTerm.get()) == false) {\n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, PostingsEnum.NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm.get() + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if (fieldTermCount > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != fieldTermCount) {\n            throw new RuntimeException(\"termCount mismatch \" + termCount + \" vs \" + fieldTermCount);\n          }\n        }\n\n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              long actualOrd = termsEnum.ord();\n              if (actualOrd != ord) {\n                throw new RuntimeException(\"seek to ord \" + ord + \" returned ord \" + actualOrd);\n              }\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              if (termsEnum.term().equals(seekTerms[i]) == false) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n              }\n              \n              postings = termsEnum.postings(postings, PostingsEnum.NONE);\n              if (postings == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, String.format(Locale.ROOT, \"OK [%d terms; %d terms/docs pairs; %d tokens] [took %.3f sec]\",\n                                    status.termCount, status.totFreq, status.totPos, nsToSec(System.nanoTime()-startNS)));\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    long startNS;\n    if (doPrint) {\n      startNS = System.nanoTime();\n    } else {\n      startNS = 0;\n    }\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef maxTerm;\n      BytesRef minTerm;\n      if (isVectors) {\n        // Term vectors impls can be very slow for getMax\n        maxTerm = null;\n        minTerm = null;\n      } else {\n        BytesRef bb = terms.getMin();\n        if (bb != null) {\n          assert bb.isValid();\n          minTerm = BytesRef.deepCopyOf(bb);\n        } else {\n          minTerm = null;\n        }\n\n        bb = terms.getMax();\n        if (bb != null) {\n          assert bb.isValid();\n          maxTerm = BytesRef.deepCopyOf(bb);\n          if (minTerm == null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n          }\n        } else {\n          maxTerm = null;\n          if (minTerm != null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n          }\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator();\n\n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        // System.out.println(\"CI: field=\" + field + \" check term=\" + term + \" docFreq=\" + termsEnum.docFreq());\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm.get() + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n\n        if (isVectors == false) {\n          if (minTerm == null) {\n            // We checked this above:\n            assert maxTerm == null;\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(minTerm) < 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(maxTerm) > 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n          }\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n\n        postings = termsEnum.postings(postings, PostingsEnum.ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        boolean hasNonDeletedDocs = false;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = postings.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = postings.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (postings.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          if (liveDocs == null || liveDocs.get(doc)) {\n            hasNonDeletedDocs = true;\n            status.totFreq++;\n            if (freq >= 0) {\n              status.totPos += freq;\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos > IndexWriter.MAX_POSITION) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" > IndexWriter.MAX_POSITION=\" + IndexWriter.MAX_POSITION);\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                if (startOffset < 0) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                }\n                if (startOffset < lastOffset) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset + \"; consider using the FixBrokenOffsets tool in Lucene's backward-codecs module to correct your index\");\n                }\n                if (endOffset < 0) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                }\n                if (endOffset < startOffset) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (hasNonDeletedDocs) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(postings, PostingsEnum.ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(postings, PostingsEnum.NONE);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n\n        long fieldTermCount = (status.delTermCount+status.termCount)-termCountStart;\n\n        // LUCENE-5879: this is just too slow for now:\n        if (false && hasFreqs == false) {\n          // For DOCS_ONLY fields we recursively test term ranges:\n          checkTermRanges(field, maxDoc, fieldTerms, fieldTermCount);\n        }\n\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n\n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        final int v = fieldTerms.getDocCount();\n        if (v != -1 && visitedDocs.cardinality() != v) {\n          throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" failed\");\n          }\n          if (termsEnum.term().equals(lastTerm.get()) == false) {\n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, PostingsEnum.NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm.get() + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if (fieldTermCount > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != fieldTermCount) {\n            throw new RuntimeException(\"termCount mismatch \" + termCount + \" vs \" + fieldTermCount);\n          }\n        }\n\n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              long actualOrd = termsEnum.ord();\n              if (actualOrd != ord) {\n                throw new RuntimeException(\"seek to ord \" + ord + \" returned ord \" + actualOrd);\n              }\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              if (termsEnum.term().equals(seekTerms[i]) == false) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n              }\n              \n              postings = termsEnum.postings(postings, PostingsEnum.NONE);\n              if (postings == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, String.format(Locale.ROOT, \"OK [%d terms; %d terms/docs pairs; %d tokens] [took %.3f sec]\",\n                                    status.termCount, status.totFreq, status.totPos, nsToSec(System.nanoTime()-startNS)));\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d523b8189b211dd1630166aa77b8c88bb48b3fcc","date":1510144168,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","sourceNew":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    long startNS;\n    if (doPrint) {\n      startNS = System.nanoTime();\n    } else {\n      startNS = 0;\n    }\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      if (terms.getDocCount() > maxDoc) {\n        throw new RuntimeException(\"docCount > maxDoc for field: \" + field + \", docCount=\" + terms.getDocCount() + \", maxDoc=\" + maxDoc);\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef maxTerm;\n      BytesRef minTerm;\n      if (isVectors) {\n        // Term vectors impls can be very slow for getMax\n        maxTerm = null;\n        minTerm = null;\n      } else {\n        BytesRef bb = terms.getMin();\n        if (bb != null) {\n          assert bb.isValid();\n          minTerm = BytesRef.deepCopyOf(bb);\n        } else {\n          minTerm = null;\n        }\n\n        bb = terms.getMax();\n        if (bb != null) {\n          assert bb.isValid();\n          maxTerm = BytesRef.deepCopyOf(bb);\n          if (minTerm == null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n          }\n        } else {\n          maxTerm = null;\n          if (minTerm != null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n          }\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator();\n\n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        // System.out.println(\"CI: field=\" + field + \" check term=\" + term + \" docFreq=\" + termsEnum.docFreq());\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm.get() + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n\n        if (isVectors == false) {\n          if (minTerm == null) {\n            // We checked this above:\n            assert maxTerm == null;\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(minTerm) < 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(maxTerm) > 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n          }\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n\n        postings = termsEnum.postings(postings, PostingsEnum.ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != termsEnum.docFreq()) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be \" + termsEnum.docFreq() + \")\");\n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        boolean hasNonDeletedDocs = false;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = postings.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          visitedDocs.set(doc);\n          int freq = postings.freq();\n          if (freq <= 0) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n          }\n          if (hasFreqs == false) {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (postings.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          totalTermFreq += freq;\n\n          if (liveDocs == null || liveDocs.get(doc)) {\n            hasNonDeletedDocs = true;\n            status.totFreq++;\n            if (freq >= 0) {\n              status.totPos += freq;\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos > IndexWriter.MAX_POSITION) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" > IndexWriter.MAX_POSITION=\" + IndexWriter.MAX_POSITION);\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                if (startOffset < 0) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                }\n                if (startOffset < lastOffset) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset + \"; consider using the FixBrokenOffsets tool in Lucene's backward-codecs module to correct your index\");\n                }\n                if (endOffset < 0) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                }\n                if (endOffset < startOffset) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (hasNonDeletedDocs) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (docFreq > terms.getDocCount()) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" > docCount=\" + terms.getDocCount());\n        }\n        if (totalTermFreq2 <= 0) {\n          throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n        }\n        sumTotalTermFreq += totalTermFreq;\n        if (totalTermFreq != totalTermFreq2) {\n          throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n        }\n        if (totalTermFreq2 < docFreq) {\n          throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds, docFreq=\" + docFreq);\n        }\n        if (hasFreqs == false && totalTermFreq != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq + \" !=  docFreq=\" + docFreq);\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(postings, PostingsEnum.ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(postings, PostingsEnum.NONE);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n\n        long fieldTermCount = (status.delTermCount+status.termCount)-termCountStart;\n\n        // LUCENE-5879: this is just too slow for now:\n        if (false && hasFreqs == false) {\n          // For DOCS_ONLY fields we recursively test term ranges:\n          checkTermRanges(field, maxDoc, fieldTerms, fieldTermCount);\n        }\n\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n\n        final long actualSumDocFreq = fields.terms(field).getSumDocFreq();\n        if (sumDocFreq != actualSumDocFreq) {\n          throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + actualSumDocFreq + \" != recomputed sumDocFreq=\" + sumDocFreq);\n        }\n\n        final long actualSumTotalTermFreq = fields.terms(field).getSumTotalTermFreq();\n        if (sumTotalTermFreq != actualSumTotalTermFreq) {\n          throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + actualSumTotalTermFreq + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n        } \n        \n        if (hasFreqs == false && sumTotalTermFreq != sumDocFreq) {\n          throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \" should be \" + sumDocFreq + \", got sumTotalTermFreq=\" + sumTotalTermFreq);\n        }\n        \n        final int v = fieldTerms.getDocCount();\n        if (visitedDocs.cardinality() != v) {\n          throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" failed\");\n          }\n          if (termsEnum.term().equals(lastTerm.get()) == false) {\n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, PostingsEnum.NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm.get() + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if (fieldTermCount > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != fieldTermCount) {\n            throw new RuntimeException(\"termCount mismatch \" + termCount + \" vs \" + fieldTermCount);\n          }\n        }\n\n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              long actualOrd = termsEnum.ord();\n              if (actualOrd != ord) {\n                throw new RuntimeException(\"seek to ord \" + ord + \" returned ord \" + actualOrd);\n              }\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              if (termsEnum.term().equals(seekTerms[i]) == false) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n              }\n              \n              postings = termsEnum.postings(postings, PostingsEnum.NONE);\n              if (postings == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, String.format(Locale.ROOT, \"OK [%d terms; %d terms/docs pairs; %d tokens] [took %.3f sec]\",\n                                    status.termCount, status.totFreq, status.totPos, nsToSec(System.nanoTime()-startNS)));\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    long startNS;\n    if (doPrint) {\n      startNS = System.nanoTime();\n    } else {\n      startNS = 0;\n    }\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef maxTerm;\n      BytesRef minTerm;\n      if (isVectors) {\n        // Term vectors impls can be very slow for getMax\n        maxTerm = null;\n        minTerm = null;\n      } else {\n        BytesRef bb = terms.getMin();\n        if (bb != null) {\n          assert bb.isValid();\n          minTerm = BytesRef.deepCopyOf(bb);\n        } else {\n          minTerm = null;\n        }\n\n        bb = terms.getMax();\n        if (bb != null) {\n          assert bb.isValid();\n          maxTerm = BytesRef.deepCopyOf(bb);\n          if (minTerm == null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n          }\n        } else {\n          maxTerm = null;\n          if (minTerm != null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n          }\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (hasFreqs == false) {\n        if (terms.getSumTotalTermFreq() != -1) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but Terms.getSumTotalTermFreq()=\" + terms.getSumTotalTermFreq() + \" (should be -1)\");\n        }\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator();\n\n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        // System.out.println(\"CI: field=\" + field + \" check term=\" + term + \" docFreq=\" + termsEnum.docFreq());\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm.get() + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n\n        if (isVectors == false) {\n          if (minTerm == null) {\n            // We checked this above:\n            assert maxTerm == null;\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(minTerm) < 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(maxTerm) > 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n          }\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n\n        postings = termsEnum.postings(postings, PostingsEnum.ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != -1) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be -1)\");   \n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        boolean hasNonDeletedDocs = false;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = postings.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          visitedDocs.set(doc);\n          int freq = -1;\n          if (hasFreqs) {\n            freq = postings.freq();\n            if (freq <= 0) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            }\n            totalTermFreq += freq;\n          } else {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (postings.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          if (liveDocs == null || liveDocs.get(doc)) {\n            hasNonDeletedDocs = true;\n            status.totFreq++;\n            if (freq >= 0) {\n              status.totPos += freq;\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos > IndexWriter.MAX_POSITION) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" > IndexWriter.MAX_POSITION=\" + IndexWriter.MAX_POSITION);\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                if (startOffset < 0) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                }\n                if (startOffset < lastOffset) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset + \"; consider using the FixBrokenOffsets tool in Lucene's backward-codecs module to correct your index\");\n                }\n                if (endOffset < 0) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                }\n                if (endOffset < startOffset) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (hasNonDeletedDocs) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (hasTotalTermFreq) {\n          if (totalTermFreq2 <= 0) {\n            throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n          }\n          sumTotalTermFreq += totalTermFreq;\n          if (totalTermFreq != totalTermFreq2) {\n            throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n          }\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(postings, PostingsEnum.ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(postings, PostingsEnum.NONE);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n\n        long fieldTermCount = (status.delTermCount+status.termCount)-termCountStart;\n\n        // LUCENE-5879: this is just too slow for now:\n        if (false && hasFreqs == false) {\n          // For DOCS_ONLY fields we recursively test term ranges:\n          checkTermRanges(field, maxDoc, fieldTerms, fieldTermCount);\n        }\n\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n\n        if (sumTotalTermFreq != 0) {\n          final long v = fields.terms(field).getSumTotalTermFreq();\n          if (v != -1 && sumTotalTermFreq != v) {\n            throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n          }\n        }\n        \n        if (sumDocFreq != 0) {\n          final long v = fields.terms(field).getSumDocFreq();\n          if (v != -1 && sumDocFreq != v) {\n            throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n          }\n        }\n        \n        final int v = fieldTerms.getDocCount();\n        if (v != -1 && visitedDocs.cardinality() != v) {\n          throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" failed\");\n          }\n          if (termsEnum.term().equals(lastTerm.get()) == false) {\n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, PostingsEnum.NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm.get() + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if (fieldTermCount > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != fieldTermCount) {\n            throw new RuntimeException(\"termCount mismatch \" + termCount + \" vs \" + fieldTermCount);\n          }\n        }\n\n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              long actualOrd = termsEnum.ord();\n              if (actualOrd != ord) {\n                throw new RuntimeException(\"seek to ord \" + ord + \" returned ord \" + actualOrd);\n              }\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              if (termsEnum.term().equals(seekTerms[i]) == false) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n              }\n              \n              postings = termsEnum.postings(postings, PostingsEnum.NONE);\n              if (postings == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, String.format(Locale.ROOT, \"OK [%d terms; %d terms/docs pairs; %d tokens] [took %.3f sec]\",\n                                    status.termCount, status.totFreq, status.totPos, nsToSec(System.nanoTime()-startNS)));\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"622a708571e534680618b3c5e0c28ac539a47776","date":1517406892,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","sourceNew":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    long startNS;\n    if (doPrint) {\n      startNS = System.nanoTime();\n    } else {\n      startNS = 0;\n    }\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      if (terms.getDocCount() > maxDoc) {\n        throw new RuntimeException(\"docCount > maxDoc for field: \" + field + \", docCount=\" + terms.getDocCount() + \", maxDoc=\" + maxDoc);\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef maxTerm;\n      BytesRef minTerm;\n      if (isVectors) {\n        // Term vectors impls can be very slow for getMax\n        maxTerm = null;\n        minTerm = null;\n      } else {\n        BytesRef bb = terms.getMin();\n        if (bb != null) {\n          assert bb.isValid();\n          minTerm = BytesRef.deepCopyOf(bb);\n        } else {\n          minTerm = null;\n        }\n\n        bb = terms.getMax();\n        if (bb != null) {\n          assert bb.isValid();\n          maxTerm = BytesRef.deepCopyOf(bb);\n          if (minTerm == null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n          }\n        } else {\n          maxTerm = null;\n          if (minTerm != null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n          }\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator();\n\n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        // System.out.println(\"CI: field=\" + field + \" check term=\" + term + \" docFreq=\" + termsEnum.docFreq());\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm.get() + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n\n        if (isVectors == false) {\n          if (minTerm == null) {\n            // We checked this above:\n            assert maxTerm == null;\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(minTerm) < 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(maxTerm) > 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n          }\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n\n        postings = termsEnum.postings(postings, PostingsEnum.ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != termsEnum.docFreq()) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be \" + termsEnum.docFreq() + \")\");\n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        boolean hasNonDeletedDocs = false;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = postings.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          visitedDocs.set(doc);\n          int freq = postings.freq();\n          if (freq <= 0) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n          }\n          if (hasFreqs == false) {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (postings.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          totalTermFreq += freq;\n\n          if (liveDocs == null || liveDocs.get(doc)) {\n            hasNonDeletedDocs = true;\n            status.totFreq++;\n            if (freq >= 0) {\n              status.totPos += freq;\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos > IndexWriter.MAX_POSITION) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" > IndexWriter.MAX_POSITION=\" + IndexWriter.MAX_POSITION);\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                if (startOffset < 0) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                }\n                if (startOffset < lastOffset) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset + \"; consider using the FixBrokenOffsets tool in Lucene's backward-codecs module to correct your index\");\n                }\n                if (endOffset < 0) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                }\n                if (endOffset < startOffset) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (hasNonDeletedDocs) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (docFreq > terms.getDocCount()) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" > docCount=\" + terms.getDocCount());\n        }\n        if (totalTermFreq2 <= 0) {\n          throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n        }\n        sumTotalTermFreq += totalTermFreq;\n        if (totalTermFreq != totalTermFreq2) {\n          throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n        }\n        if (totalTermFreq2 < docFreq) {\n          throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds, docFreq=\" + docFreq);\n        }\n        if (hasFreqs == false && totalTermFreq != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq + \" !=  docFreq=\" + docFreq);\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(postings, PostingsEnum.ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(postings, PostingsEnum.NONE);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        }\n\n        // Test score blocks\n        // We only score on freq to keep things simple and not pull norms\n        SimScorer scorer = new SimScorer(field) {\n          @Override\n          public float score(float freq, long norm) {\n            return freq;\n          }\n        };\n\n        // First check max scores and block uptos\n        int max = -1;\n        float maxScore = 0;\n        ImpactsEnum impacts = termsEnum.impacts(scorer, PostingsEnum.FREQS);\n        postings = termsEnum.postings(postings, PostingsEnum.FREQS);\n        for (int doc = impacts.nextDoc(); ; doc = impacts.nextDoc()) {\n          if (postings.nextDoc() != doc) {\n            throw new RuntimeException(\"Wrong next doc: \" + doc + \", expected \" + postings.docID());\n          }\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          if (postings.freq() != impacts.freq()) {\n            throw new RuntimeException(\"Wrong freq, expected \" + postings.freq() + \", but got \" + impacts.freq());\n          }\n          if (doc > max) {\n            max = impacts.advanceShallow(doc);\n            if (max < doc) {\n              throw new RuntimeException(\"max block doc id \" + max + \" must be greater than the target: \" + doc);\n            }\n            maxScore = impacts.getMaxScore(max);\n          }\n          int max2 = impacts.advanceShallow(doc);\n          if (max != max2) {\n            throw new RuntimeException(\"max is not stable, initially had \" + max + \" but now \" + max2);\n          }\n          float score = scorer.score(impacts.freq(), 1);\n          if (score > maxScore) {\n            throw new RuntimeException(\"score \" + score + \" is greater than the max score \" + maxScore);\n          }\n        }\n\n        // Now check advancing\n        impacts = termsEnum.impacts(scorer, PostingsEnum.FREQS);\n        postings = termsEnum.postings(postings, PostingsEnum.FREQS);\n\n        max = -1;\n        while (true) {\n          int doc = impacts.docID();\n          boolean advance;\n          int target;\n          if (((field.hashCode() + doc) & 1) == 1) {\n            advance = false;\n            target = doc + 1;\n          } else {\n            advance = true;\n            int delta = Math.min(1 + ((31 * field.hashCode() + doc) & 0x1ff), DocIdSetIterator.NO_MORE_DOCS - doc);\n            target = impacts.docID() + delta;\n          }\n\n          if (target > max && target % 2 == 1) {\n            int delta = Math.min((31 * field.hashCode() + target) & 0x1ff, DocIdSetIterator.NO_MORE_DOCS - target);\n            max = target + delta;\n            int m = impacts.advanceShallow(target);\n            if (m < target) {\n              throw new RuntimeException(\"Block max doc: \" + m + \" is less than the target \" + target);\n            }\n            maxScore = impacts.getMaxScore(max);\n          }\n\n          if (advance) {\n            doc = impacts.advance(target);\n          } else {\n            doc = impacts.nextDoc();\n          }\n\n          if (postings.advance(target) != doc) {\n            throw new RuntimeException(\"Impacts do not advance to the same document as postings for target \" + target + \", postings: \" + postings.docID() + \", impacts: \" + doc);\n          }\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          if (postings.freq() != impacts.freq()) {\n            throw new RuntimeException(\"Wrong freq, expected \" + postings.freq() + \", but got \" + impacts.freq());\n          }\n\n          if (doc >= max) {\n            int delta = Math.min((31 * field.hashCode() + target & 0x1ff), DocIdSetIterator.NO_MORE_DOCS - doc);\n            max = doc + delta;\n            int m = impacts.advanceShallow(doc);\n            if (m < doc) {\n              throw new RuntimeException(\"Block max doc: \" + m + \" is less than the target \" + doc);\n            }\n            maxScore = impacts.getMaxScore(max);\n          }\n\n          float score = scorer.score(impacts.freq(), 1);\n          if (score > maxScore) {\n            throw new RuntimeException(\"score \" + score + \" is greater than the max score \" + maxScore);\n          }\n        }\n      }\n\n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n\n        long fieldTermCount = (status.delTermCount+status.termCount)-termCountStart;\n\n        // LUCENE-5879: this is just too slow for now:\n        if (false && hasFreqs == false) {\n          // For DOCS_ONLY fields we recursively test term ranges:\n          checkTermRanges(field, maxDoc, fieldTerms, fieldTermCount);\n        }\n\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n\n        final long actualSumDocFreq = fields.terms(field).getSumDocFreq();\n        if (sumDocFreq != actualSumDocFreq) {\n          throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + actualSumDocFreq + \" != recomputed sumDocFreq=\" + sumDocFreq);\n        }\n\n        final long actualSumTotalTermFreq = fields.terms(field).getSumTotalTermFreq();\n        if (sumTotalTermFreq != actualSumTotalTermFreq) {\n          throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + actualSumTotalTermFreq + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n        } \n        \n        if (hasFreqs == false && sumTotalTermFreq != sumDocFreq) {\n          throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \" should be \" + sumDocFreq + \", got sumTotalTermFreq=\" + sumTotalTermFreq);\n        }\n        \n        final int v = fieldTerms.getDocCount();\n        if (visitedDocs.cardinality() != v) {\n          throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" failed\");\n          }\n          if (termsEnum.term().equals(lastTerm.get()) == false) {\n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, PostingsEnum.NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm.get() + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if (fieldTermCount > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != fieldTermCount) {\n            throw new RuntimeException(\"termCount mismatch \" + termCount + \" vs \" + fieldTermCount);\n          }\n        }\n\n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              long actualOrd = termsEnum.ord();\n              if (actualOrd != ord) {\n                throw new RuntimeException(\"seek to ord \" + ord + \" returned ord \" + actualOrd);\n              }\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              if (termsEnum.term().equals(seekTerms[i]) == false) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n              }\n              \n              postings = termsEnum.postings(postings, PostingsEnum.NONE);\n              if (postings == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, String.format(Locale.ROOT, \"OK [%d terms; %d terms/docs pairs; %d tokens] [took %.3f sec]\",\n                                    status.termCount, status.totFreq, status.totPos, nsToSec(System.nanoTime()-startNS)));\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    long startNS;\n    if (doPrint) {\n      startNS = System.nanoTime();\n    } else {\n      startNS = 0;\n    }\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      if (terms.getDocCount() > maxDoc) {\n        throw new RuntimeException(\"docCount > maxDoc for field: \" + field + \", docCount=\" + terms.getDocCount() + \", maxDoc=\" + maxDoc);\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef maxTerm;\n      BytesRef minTerm;\n      if (isVectors) {\n        // Term vectors impls can be very slow for getMax\n        maxTerm = null;\n        minTerm = null;\n      } else {\n        BytesRef bb = terms.getMin();\n        if (bb != null) {\n          assert bb.isValid();\n          minTerm = BytesRef.deepCopyOf(bb);\n        } else {\n          minTerm = null;\n        }\n\n        bb = terms.getMax();\n        if (bb != null) {\n          assert bb.isValid();\n          maxTerm = BytesRef.deepCopyOf(bb);\n          if (minTerm == null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n          }\n        } else {\n          maxTerm = null;\n          if (minTerm != null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n          }\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator();\n\n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        // System.out.println(\"CI: field=\" + field + \" check term=\" + term + \" docFreq=\" + termsEnum.docFreq());\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm.get() + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n\n        if (isVectors == false) {\n          if (minTerm == null) {\n            // We checked this above:\n            assert maxTerm == null;\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(minTerm) < 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(maxTerm) > 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n          }\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n\n        postings = termsEnum.postings(postings, PostingsEnum.ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != termsEnum.docFreq()) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be \" + termsEnum.docFreq() + \")\");\n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        boolean hasNonDeletedDocs = false;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = postings.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          visitedDocs.set(doc);\n          int freq = postings.freq();\n          if (freq <= 0) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n          }\n          if (hasFreqs == false) {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (postings.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          totalTermFreq += freq;\n\n          if (liveDocs == null || liveDocs.get(doc)) {\n            hasNonDeletedDocs = true;\n            status.totFreq++;\n            if (freq >= 0) {\n              status.totPos += freq;\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos > IndexWriter.MAX_POSITION) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" > IndexWriter.MAX_POSITION=\" + IndexWriter.MAX_POSITION);\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                if (startOffset < 0) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                }\n                if (startOffset < lastOffset) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset + \"; consider using the FixBrokenOffsets tool in Lucene's backward-codecs module to correct your index\");\n                }\n                if (endOffset < 0) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                }\n                if (endOffset < startOffset) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (hasNonDeletedDocs) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (docFreq > terms.getDocCount()) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" > docCount=\" + terms.getDocCount());\n        }\n        if (totalTermFreq2 <= 0) {\n          throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n        }\n        sumTotalTermFreq += totalTermFreq;\n        if (totalTermFreq != totalTermFreq2) {\n          throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n        }\n        if (totalTermFreq2 < docFreq) {\n          throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds, docFreq=\" + docFreq);\n        }\n        if (hasFreqs == false && totalTermFreq != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq + \" !=  docFreq=\" + docFreq);\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(postings, PostingsEnum.ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(postings, PostingsEnum.NONE);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        }\n      }\n      \n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n\n        long fieldTermCount = (status.delTermCount+status.termCount)-termCountStart;\n\n        // LUCENE-5879: this is just too slow for now:\n        if (false && hasFreqs == false) {\n          // For DOCS_ONLY fields we recursively test term ranges:\n          checkTermRanges(field, maxDoc, fieldTerms, fieldTermCount);\n        }\n\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n\n        final long actualSumDocFreq = fields.terms(field).getSumDocFreq();\n        if (sumDocFreq != actualSumDocFreq) {\n          throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + actualSumDocFreq + \" != recomputed sumDocFreq=\" + sumDocFreq);\n        }\n\n        final long actualSumTotalTermFreq = fields.terms(field).getSumTotalTermFreq();\n        if (sumTotalTermFreq != actualSumTotalTermFreq) {\n          throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + actualSumTotalTermFreq + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n        } \n        \n        if (hasFreqs == false && sumTotalTermFreq != sumDocFreq) {\n          throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \" should be \" + sumDocFreq + \", got sumTotalTermFreq=\" + sumTotalTermFreq);\n        }\n        \n        final int v = fieldTerms.getDocCount();\n        if (visitedDocs.cardinality() != v) {\n          throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" failed\");\n          }\n          if (termsEnum.term().equals(lastTerm.get()) == false) {\n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, PostingsEnum.NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm.get() + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if (fieldTermCount > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != fieldTermCount) {\n            throw new RuntimeException(\"termCount mismatch \" + termCount + \" vs \" + fieldTermCount);\n          }\n        }\n\n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              long actualOrd = termsEnum.ord();\n              if (actualOrd != ord) {\n                throw new RuntimeException(\"seek to ord \" + ord + \" returned ord \" + actualOrd);\n              }\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              if (termsEnum.term().equals(seekTerms[i]) == false) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n              }\n              \n              postings = termsEnum.postings(postings, PostingsEnum.NONE);\n              if (postings == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, String.format(Locale.ROOT, \"OK [%d terms; %d terms/docs pairs; %d tokens] [took %.3f sec]\",\n                                    status.termCount, status.totFreq, status.totPos, nsToSec(System.nanoTime()-startNS)));\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9a0e5953a07337cd41bcde610503024c07073b26","date":1519143251,"type":5,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkFields(Fields,Bits,int,FieldInfos,boolean,boolean,PrintStream,boolean).mjava","sourceNew":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose, boolean doSlowChecks) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    long startNS;\n    if (doPrint) {\n      startNS = System.nanoTime();\n    } else {\n      startNS = 0;\n    }\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      if (terms.getDocCount() > maxDoc) {\n        throw new RuntimeException(\"docCount > maxDoc for field: \" + field + \", docCount=\" + terms.getDocCount() + \", maxDoc=\" + maxDoc);\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef maxTerm;\n      BytesRef minTerm;\n      if (isVectors) {\n        // Term vectors impls can be very slow for getMax\n        maxTerm = null;\n        minTerm = null;\n      } else {\n        BytesRef bb = terms.getMin();\n        if (bb != null) {\n          assert bb.isValid();\n          minTerm = BytesRef.deepCopyOf(bb);\n        } else {\n          minTerm = null;\n        }\n\n        bb = terms.getMax();\n        if (bb != null) {\n          assert bb.isValid();\n          maxTerm = BytesRef.deepCopyOf(bb);\n          if (minTerm == null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n          }\n        } else {\n          maxTerm = null;\n          if (minTerm != null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n          }\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator();\n\n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        // System.out.println(\"CI: field=\" + field + \" check term=\" + term + \" docFreq=\" + termsEnum.docFreq());\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm.get() + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n\n        if (isVectors == false) {\n          if (minTerm == null) {\n            // We checked this above:\n            assert maxTerm == null;\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(minTerm) < 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(maxTerm) > 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n          }\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n\n        postings = termsEnum.postings(postings, PostingsEnum.ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != termsEnum.docFreq()) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be \" + termsEnum.docFreq() + \")\");\n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        boolean hasNonDeletedDocs = false;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = postings.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          visitedDocs.set(doc);\n          int freq = postings.freq();\n          if (freq <= 0) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n          }\n          if (hasFreqs == false) {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (postings.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          totalTermFreq += freq;\n\n          if (liveDocs == null || liveDocs.get(doc)) {\n            hasNonDeletedDocs = true;\n            status.totFreq++;\n            if (freq >= 0) {\n              status.totPos += freq;\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos > IndexWriter.MAX_POSITION) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" > IndexWriter.MAX_POSITION=\" + IndexWriter.MAX_POSITION);\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                if (startOffset < 0) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                }\n                if (startOffset < lastOffset) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset + \"; consider using the FixBrokenOffsets tool in Lucene's backward-codecs module to correct your index\");\n                }\n                if (endOffset < 0) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                }\n                if (endOffset < startOffset) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (hasNonDeletedDocs) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (docFreq > terms.getDocCount()) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" > docCount=\" + terms.getDocCount());\n        }\n        if (totalTermFreq2 <= 0) {\n          throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n        }\n        sumTotalTermFreq += totalTermFreq;\n        if (totalTermFreq != totalTermFreq2) {\n          throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n        }\n        if (totalTermFreq2 < docFreq) {\n          throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds, docFreq=\" + docFreq);\n        }\n        if (hasFreqs == false && totalTermFreq != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq + \" !=  docFreq=\" + docFreq);\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(postings, PostingsEnum.ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(postings, PostingsEnum.NONE);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        }\n\n        // Checking score blocks is heavy, we only do it on long postings lists, on every 1024th term\n        // or if slow checks are enabled.\n        if (doSlowChecks || docFreq > 1024 || (status.termCount + status.delTermCount) % 1024 == 0) {\n          // Test score blocks\n          // We only score on freq to keep things simple and not pull norms\n          SimScorer scorer = new SimScorer(field) {\n            @Override\n            public float score(float freq, long norm) {\n              return freq;\n            }\n          };\n\n          // First check max scores and block uptos\n          // But only if slok checks are enabled since we visit all docs\n          if (doSlowChecks) {\n            int max = -1;\n            float maxScore = 0;\n            ImpactsEnum impacts = termsEnum.impacts(scorer, PostingsEnum.FREQS);\n            postings = termsEnum.postings(postings, PostingsEnum.FREQS);\n            for (int doc = impacts.nextDoc(); ; doc = impacts.nextDoc()) {\n              if (postings.nextDoc() != doc) {\n                throw new RuntimeException(\"Wrong next doc: \" + doc + \", expected \" + postings.docID());\n              }\n              if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (postings.freq() != impacts.freq()) {\n                throw new RuntimeException(\"Wrong freq, expected \" + postings.freq() + \", but got \" + impacts.freq());\n              }\n              if (doc > max) {\n                max = impacts.advanceShallow(doc);\n                if (max < doc) {\n                  throw new RuntimeException(\"max block doc id \" + max + \" must be greater than the target: \" + doc);\n                }\n                maxScore = impacts.getMaxScore(max);\n              }\n              int max2 = impacts.advanceShallow(doc);\n              if (max != max2) {\n                throw new RuntimeException(\"max is not stable, initially had \" + max + \" but now \" + max2);\n              }\n              float score = scorer.score(impacts.freq(), 1);\n              if (score > maxScore) {\n                throw new RuntimeException(\"score \" + score + \" is greater than the max score \" + maxScore);\n              }\n            }\n          }\n\n          // Now check advancing\n          ImpactsEnum impacts = termsEnum.impacts(scorer, PostingsEnum.FREQS);\n          postings = termsEnum.postings(postings, PostingsEnum.FREQS);\n\n          int max = -1;\n          float maxScore = 0;\n          while (true) {\n            int doc = impacts.docID();\n            boolean advance;\n            int target;\n            if (((field.hashCode() + doc) & 1) == 1) {\n              advance = false;\n              target = doc + 1;\n            } else {\n              advance = true;\n              int delta = Math.min(1 + ((31 * field.hashCode() + doc) & 0x1ff), DocIdSetIterator.NO_MORE_DOCS - doc);\n              target = impacts.docID() + delta;\n            }\n\n            if (target > max && target % 2 == 1) {\n              int delta = Math.min((31 * field.hashCode() + target) & 0x1ff, DocIdSetIterator.NO_MORE_DOCS - target);\n              max = target + delta;\n              int m = impacts.advanceShallow(target);\n              if (m < target) {\n                throw new RuntimeException(\"Block max doc: \" + m + \" is less than the target \" + target);\n              }\n              maxScore = impacts.getMaxScore(max);\n            }\n\n            if (advance) {\n              doc = impacts.advance(target);\n            } else {\n              doc = impacts.nextDoc();\n            }\n\n            if (postings.advance(target) != doc) {\n              throw new RuntimeException(\"Impacts do not advance to the same document as postings for target \" + target + \", postings: \" + postings.docID() + \", impacts: \" + doc);\n            }\n            if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            }\n            if (postings.freq() != impacts.freq()) {\n              throw new RuntimeException(\"Wrong freq, expected \" + postings.freq() + \", but got \" + impacts.freq());\n            }\n  \n            if (doc >= max) {\n              int delta = Math.min((31 * field.hashCode() + target & 0x1ff), DocIdSetIterator.NO_MORE_DOCS - doc);\n              max = doc + delta;\n              int m = impacts.advanceShallow(doc);\n              if (m < doc) {\n                throw new RuntimeException(\"Block max doc: \" + m + \" is less than the target \" + doc);\n              }\n              maxScore = impacts.getMaxScore(max);\n            }\n\n            float score = scorer.score(impacts.freq(), 1);\n            if (score > maxScore) {\n              throw new RuntimeException(\"score \" + score + \" is greater than the max score \" + maxScore);\n            }\n          }\n        }\n      }\n\n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n\n        long fieldTermCount = (status.delTermCount+status.termCount)-termCountStart;\n\n        // LUCENE-5879: this is just too slow for now:\n        if (false && hasFreqs == false) {\n          // For DOCS_ONLY fields we recursively test term ranges:\n          checkTermRanges(field, maxDoc, fieldTerms, fieldTermCount);\n        }\n\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n\n        final long actualSumDocFreq = fields.terms(field).getSumDocFreq();\n        if (sumDocFreq != actualSumDocFreq) {\n          throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + actualSumDocFreq + \" != recomputed sumDocFreq=\" + sumDocFreq);\n        }\n\n        final long actualSumTotalTermFreq = fields.terms(field).getSumTotalTermFreq();\n        if (sumTotalTermFreq != actualSumTotalTermFreq) {\n          throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + actualSumTotalTermFreq + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n        } \n        \n        if (hasFreqs == false && sumTotalTermFreq != sumDocFreq) {\n          throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \" should be \" + sumDocFreq + \", got sumTotalTermFreq=\" + sumTotalTermFreq);\n        }\n        \n        final int v = fieldTerms.getDocCount();\n        if (visitedDocs.cardinality() != v) {\n          throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" failed\");\n          }\n          if (termsEnum.term().equals(lastTerm.get()) == false) {\n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, PostingsEnum.NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm.get() + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if (fieldTermCount > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != fieldTermCount) {\n            throw new RuntimeException(\"termCount mismatch \" + termCount + \" vs \" + fieldTermCount);\n          }\n        }\n\n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              long actualOrd = termsEnum.ord();\n              if (actualOrd != ord) {\n                throw new RuntimeException(\"seek to ord \" + ord + \" returned ord \" + actualOrd);\n              }\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              if (termsEnum.term().equals(seekTerms[i]) == false) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n              }\n              \n              postings = termsEnum.postings(postings, PostingsEnum.NONE);\n              if (postings == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, String.format(Locale.ROOT, \"OK [%d terms; %d terms/docs pairs; %d tokens] [took %.3f sec]\",\n                                    status.termCount, status.totFreq, status.totPos, nsToSec(System.nanoTime()-startNS)));\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * checks Fields api is consistent with itself.\n   * searcher is optional, to verify with queries. Can be null.\n   */\n  private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {\n    // TODO: we should probably return our own stats thing...?!\n    long startNS;\n    if (doPrint) {\n      startNS = System.nanoTime();\n    } else {\n      startNS = 0;\n    }\n    \n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n    int computedFieldCount = 0;\n\n    PostingsEnum postings = null;\n    \n    String lastField = null;\n    for (String field : fields) {\n\n      // MultiFieldsEnum relies upon this order...\n      if (lastField != null && field.compareTo(lastField) <= 0) {\n        throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n      }\n      lastField = field;\n      \n      // check that the field is in fieldinfos, and is indexed.\n      // TODO: add a separate test to check this for different reader impls\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      if (fieldInfo == null) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n      }\n      if (fieldInfo.getIndexOptions() == IndexOptions.NONE) {\n        throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n      }\n      \n      // TODO: really the codec should not return a field\n      // from FieldsEnum if it has no Terms... but we do\n      // this today:\n      // assert fields.terms(field) != null;\n      computedFieldCount++;\n      \n      final Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      \n      if (terms.getDocCount() > maxDoc) {\n        throw new RuntimeException(\"docCount > maxDoc for field: \" + field + \", docCount=\" + terms.getDocCount() + \", maxDoc=\" + maxDoc);\n      }\n      \n      final boolean hasFreqs = terms.hasFreqs();\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasPayloads = terms.hasPayloads();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      BytesRef maxTerm;\n      BytesRef minTerm;\n      if (isVectors) {\n        // Term vectors impls can be very slow for getMax\n        maxTerm = null;\n        minTerm = null;\n      } else {\n        BytesRef bb = terms.getMin();\n        if (bb != null) {\n          assert bb.isValid();\n          minTerm = BytesRef.deepCopyOf(bb);\n        } else {\n          minTerm = null;\n        }\n\n        bb = terms.getMax();\n        if (bb != null) {\n          assert bb.isValid();\n          maxTerm = BytesRef.deepCopyOf(bb);\n          if (minTerm == null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has null minTerm but non-null maxTerm\");\n          }\n        } else {\n          maxTerm = null;\n          if (minTerm != null) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" has non-null minTerm but null maxTerm\");\n          }\n        }\n      }\n\n      // term vectors cannot omit TF:\n      final boolean expectedHasFreqs = (isVectors || fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0);\n\n      if (hasFreqs != expectedHasFreqs) {\n        throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasFreqs=\" + expectedHasFreqs + \" but got \" + hasFreqs);\n      }\n\n      if (!isVectors) {\n        final boolean expectedHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        if (hasPositions != expectedHasPositions) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPositions=\" + expectedHasPositions + \" but got \" + hasPositions);\n        }\n\n        final boolean expectedHasPayloads = fieldInfo.hasPayloads();\n        if (hasPayloads != expectedHasPayloads) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasPayloads=\" + expectedHasPayloads + \" but got \" + hasPayloads);\n        }\n\n        final boolean expectedHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n        if (hasOffsets != expectedHasOffsets) {\n          throw new RuntimeException(\"field \\\"\" + field + \"\\\" should have hasOffsets=\" + expectedHasOffsets + \" but got \" + hasOffsets);\n        }\n      }\n\n      final TermsEnum termsEnum = terms.iterator();\n\n      boolean hasOrd = true;\n      final long termCountStart = status.delTermCount + status.termCount;\n      \n      BytesRefBuilder lastTerm = null;\n      \n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet visitedDocs = new FixedBitSet(maxDoc);\n      while(true) {\n        \n        final BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        // System.out.println(\"CI: field=\" + field + \" check term=\" + term + \" docFreq=\" + termsEnum.docFreq());\n        \n        assert term.isValid();\n        \n        // make sure terms arrive in order according to\n        // the comp\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm.get() + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n\n        if (isVectors == false) {\n          if (minTerm == null) {\n            // We checked this above:\n            assert maxTerm == null;\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(minTerm) < 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", minTerm=\" + minTerm);\n          }\n        \n          if (term.compareTo(maxTerm) > 0) {\n            throw new RuntimeException(\"field=\\\"\" + field + \"\\\": invalid term: term=\" + term + \", maxTerm=\" + maxTerm);\n          }\n        }\n        \n        final int docFreq = termsEnum.docFreq();\n        if (docFreq <= 0) {\n          throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n        }\n        sumDocFreq += docFreq;\n\n        postings = termsEnum.postings(postings, PostingsEnum.ALL);\n\n        if (hasFreqs == false) {\n          if (termsEnum.totalTermFreq() != termsEnum.docFreq()) {\n            throw new RuntimeException(\"field \\\"\" + field + \"\\\" hasFreqs is false, but TermsEnum.totalTermFreq()=\" + termsEnum.totalTermFreq() + \" (should be \" + termsEnum.docFreq() + \")\");\n          }\n        }\n        \n        if (hasOrd) {\n          long ord = -1;\n          try {\n            ord = termsEnum.ord();\n          } catch (UnsupportedOperationException uoe) {\n            hasOrd = false;\n          }\n          \n          if (hasOrd) {\n            final long ordExpected = status.delTermCount + status.termCount - termCountStart;\n            if (ord != ordExpected) {\n              throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n            }\n          }\n        }\n        \n        int lastDoc = -1;\n        int docCount = 0;\n        boolean hasNonDeletedDocs = false;\n        long totalTermFreq = 0;\n        while(true) {\n          final int doc = postings.nextDoc();\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          visitedDocs.set(doc);\n          int freq = postings.freq();\n          if (freq <= 0) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n          }\n          if (hasFreqs == false) {\n            // When a field didn't index freq, it must\n            // consistently \"lie\" and pretend that freq was\n            // 1:\n            if (postings.freq() != 1) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" != 1 when Terms.hasFreqs() is false\");\n            }\n          }\n          totalTermFreq += freq;\n\n          if (liveDocs == null || liveDocs.get(doc)) {\n            hasNonDeletedDocs = true;\n            status.totFreq++;\n            if (freq >= 0) {\n              status.totPos += freq;\n            }\n          }\n          docCount++;\n          \n          if (doc <= lastDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n          }\n          if (doc >= maxDoc) {\n            throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n          }\n          \n          lastDoc = doc;\n          \n          int lastPos = -1;\n          int lastOffset = 0;\n          if (hasPositions) {\n            for(int j=0;j<freq;j++) {\n              final int pos = postings.nextPosition();\n\n              if (pos < 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              }\n              if (pos > IndexWriter.MAX_POSITION) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" > IndexWriter.MAX_POSITION=\" + IndexWriter.MAX_POSITION);\n              }\n              if (pos < lastPos) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n              }\n              lastPos = pos;\n              BytesRef payload = postings.getPayload();\n              if (payload != null) {\n                assert payload.isValid();\n              }\n              if (payload != null && payload.length < 1) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" payload length is out of bounds \" + payload.length);\n              }\n              if (hasOffsets) {\n                int startOffset = postings.startOffset();\n                int endOffset = postings.endOffset();\n                if (startOffset < 0) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                }\n                if (startOffset < lastOffset) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset + \"; consider using the FixBrokenOffsets tool in Lucene's backward-codecs module to correct your index\");\n                }\n                if (endOffset < 0) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                }\n                if (endOffset < startOffset) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                }\n                lastOffset = startOffset;\n              }\n            }\n          }\n        }\n        \n        if (hasNonDeletedDocs) {\n          status.termCount++;\n        } else {\n          status.delTermCount++;\n        }\n        \n        final long totalTermFreq2 = termsEnum.totalTermFreq();\n        \n        if (docCount != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n        }\n        if (docFreq > terms.getDocCount()) {\n          throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" > docCount=\" + terms.getDocCount());\n        }\n        if (totalTermFreq2 <= 0) {\n          throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n        }\n        sumTotalTermFreq += totalTermFreq;\n        if (totalTermFreq != totalTermFreq2) {\n          throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n        }\n        if (totalTermFreq2 < docFreq) {\n          throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds, docFreq=\" + docFreq);\n        }\n        if (hasFreqs == false && totalTermFreq != docFreq) {\n          throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq + \" !=  docFreq=\" + docFreq);\n        }\n        \n        // Test skipping\n        if (hasPositions) {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(postings, PostingsEnum.ALL);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int freq = postings.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n              }\n              int lastPosition = -1;\n              int lastOffset = 0;\n              for(int posUpto=0;posUpto<freq;posUpto++) {\n                final int pos = postings.nextPosition();\n\n                if (pos < 0) {\n                  throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPosition) {\n                  throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                }\n                lastPosition = pos;\n                if (hasOffsets) {\n                  int startOffset = postings.startOffset();\n                  int endOffset = postings.endOffset();\n                  // NOTE: we cannot enforce any bounds whatsoever on vectors... they were a free-for-all before?\n                  // but for offsets in the postings lists these checks are fine: they were always enforced by IndexWriter\n                  if (!isVectors) {\n                    if (startOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" is out of bounds\");\n                    }\n                    if (startOffset < lastOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": startOffset \" + startOffset + \" < lastStartOffset \" + lastOffset);\n                    }\n                    if (endOffset < 0) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" is out of bounds\");\n                    }\n                    if (endOffset < startOffset) {\n                      throw new RuntimeException(\"term \" + term + \": doc \" + docID + \": pos \" + pos + \": endOffset \" + endOffset + \" < startOffset \" + startOffset);\n                    }\n                  }\n                  lastOffset = startOffset;\n                }\n              } \n              \n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        } else {\n          for(int idx=0;idx<7;idx++) {\n            final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n            postings = termsEnum.postings(postings, PostingsEnum.NONE);\n            final int docID = postings.advance(skipDocID);\n            if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            } else {\n              if (docID < skipDocID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n              }\n              final int nextDocID = postings.nextDoc();\n              if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              }\n              if (nextDocID <= docID) {\n                throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n              }\n            }\n            if (isVectors) {\n              // Only 1 doc in the postings for term vectors, so we only test 1 advance:\n              break;\n            }\n          }\n        }\n\n        // Test score blocks\n        // We only score on freq to keep things simple and not pull norms\n        SimScorer scorer = new SimScorer(field) {\n          @Override\n          public float score(float freq, long norm) {\n            return freq;\n          }\n        };\n\n        // First check max scores and block uptos\n        int max = -1;\n        float maxScore = 0;\n        ImpactsEnum impacts = termsEnum.impacts(scorer, PostingsEnum.FREQS);\n        postings = termsEnum.postings(postings, PostingsEnum.FREQS);\n        for (int doc = impacts.nextDoc(); ; doc = impacts.nextDoc()) {\n          if (postings.nextDoc() != doc) {\n            throw new RuntimeException(\"Wrong next doc: \" + doc + \", expected \" + postings.docID());\n          }\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          if (postings.freq() != impacts.freq()) {\n            throw new RuntimeException(\"Wrong freq, expected \" + postings.freq() + \", but got \" + impacts.freq());\n          }\n          if (doc > max) {\n            max = impacts.advanceShallow(doc);\n            if (max < doc) {\n              throw new RuntimeException(\"max block doc id \" + max + \" must be greater than the target: \" + doc);\n            }\n            maxScore = impacts.getMaxScore(max);\n          }\n          int max2 = impacts.advanceShallow(doc);\n          if (max != max2) {\n            throw new RuntimeException(\"max is not stable, initially had \" + max + \" but now \" + max2);\n          }\n          float score = scorer.score(impacts.freq(), 1);\n          if (score > maxScore) {\n            throw new RuntimeException(\"score \" + score + \" is greater than the max score \" + maxScore);\n          }\n        }\n\n        // Now check advancing\n        impacts = termsEnum.impacts(scorer, PostingsEnum.FREQS);\n        postings = termsEnum.postings(postings, PostingsEnum.FREQS);\n\n        max = -1;\n        while (true) {\n          int doc = impacts.docID();\n          boolean advance;\n          int target;\n          if (((field.hashCode() + doc) & 1) == 1) {\n            advance = false;\n            target = doc + 1;\n          } else {\n            advance = true;\n            int delta = Math.min(1 + ((31 * field.hashCode() + doc) & 0x1ff), DocIdSetIterator.NO_MORE_DOCS - doc);\n            target = impacts.docID() + delta;\n          }\n\n          if (target > max && target % 2 == 1) {\n            int delta = Math.min((31 * field.hashCode() + target) & 0x1ff, DocIdSetIterator.NO_MORE_DOCS - target);\n            max = target + delta;\n            int m = impacts.advanceShallow(target);\n            if (m < target) {\n              throw new RuntimeException(\"Block max doc: \" + m + \" is less than the target \" + target);\n            }\n            maxScore = impacts.getMaxScore(max);\n          }\n\n          if (advance) {\n            doc = impacts.advance(target);\n          } else {\n            doc = impacts.nextDoc();\n          }\n\n          if (postings.advance(target) != doc) {\n            throw new RuntimeException(\"Impacts do not advance to the same document as postings for target \" + target + \", postings: \" + postings.docID() + \", impacts: \" + doc);\n          }\n          if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n            break;\n          }\n          if (postings.freq() != impacts.freq()) {\n            throw new RuntimeException(\"Wrong freq, expected \" + postings.freq() + \", but got \" + impacts.freq());\n          }\n\n          if (doc >= max) {\n            int delta = Math.min((31 * field.hashCode() + target & 0x1ff), DocIdSetIterator.NO_MORE_DOCS - doc);\n            max = doc + delta;\n            int m = impacts.advanceShallow(doc);\n            if (m < doc) {\n              throw new RuntimeException(\"Block max doc: \" + m + \" is less than the target \" + doc);\n            }\n            maxScore = impacts.getMaxScore(max);\n          }\n\n          float score = scorer.score(impacts.freq(), 1);\n          if (score > maxScore) {\n            throw new RuntimeException(\"score \" + score + \" is greater than the max score \" + maxScore);\n          }\n        }\n      }\n\n      if (minTerm != null && status.termCount + status.delTermCount == 0) {\n        throw new RuntimeException(\"field=\\\"\" + field + \"\\\": minTerm is non-null yet we saw no terms: \" + minTerm);\n      }\n\n      final Terms fieldTerms = fields.terms(field);\n      if (fieldTerms == null) {\n        // Unusual: the FieldsEnum returned a field but\n        // the Terms for that field is null; this should\n        // only happen if it's a ghost field (field with\n        // no terms, eg there used to be terms but all\n        // docs got deleted and then merged away):\n        \n      } else {\n\n        long fieldTermCount = (status.delTermCount+status.termCount)-termCountStart;\n\n        // LUCENE-5879: this is just too slow for now:\n        if (false && hasFreqs == false) {\n          // For DOCS_ONLY fields we recursively test term ranges:\n          checkTermRanges(field, maxDoc, fieldTerms, fieldTermCount);\n        }\n\n        final Object stats = fieldTerms.getStats();\n        assert stats != null;\n        if (status.blockTreeStats == null) {\n          status.blockTreeStats = new HashMap<>();\n        }\n        status.blockTreeStats.put(field, stats);\n\n        final long actualSumDocFreq = fields.terms(field).getSumDocFreq();\n        if (sumDocFreq != actualSumDocFreq) {\n          throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + actualSumDocFreq + \" != recomputed sumDocFreq=\" + sumDocFreq);\n        }\n\n        final long actualSumTotalTermFreq = fields.terms(field).getSumTotalTermFreq();\n        if (sumTotalTermFreq != actualSumTotalTermFreq) {\n          throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + actualSumTotalTermFreq + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n        } \n        \n        if (hasFreqs == false && sumTotalTermFreq != sumDocFreq) {\n          throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \" should be \" + sumDocFreq + \", got sumTotalTermFreq=\" + sumTotalTermFreq);\n        }\n        \n        final int v = fieldTerms.getDocCount();\n        if (visitedDocs.cardinality() != v) {\n          throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n        }\n        \n        // Test seek to last term:\n        if (lastTerm != null) {\n          if (termsEnum.seekCeil(lastTerm.get()) != TermsEnum.SeekStatus.FOUND) { \n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" failed\");\n          }\n          if (termsEnum.term().equals(lastTerm.get()) == false) {\n            throw new RuntimeException(\"seek to last term \" + lastTerm.get() + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n          }\n          \n          int expectedDocFreq = termsEnum.docFreq();\n          PostingsEnum d = termsEnum.postings(null, PostingsEnum.NONE);\n          int docFreq = 0;\n          while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            docFreq++;\n          }\n          if (docFreq != expectedDocFreq) {\n            throw new RuntimeException(\"docFreq for last term \" + lastTerm.get() + \"=\" + expectedDocFreq + \" != recomputed docFreq=\" + docFreq);\n          }\n        }\n        \n        // check unique term count\n        long termCount = -1;\n        \n        if (fieldTermCount > 0) {\n          termCount = fields.terms(field).size();\n          \n          if (termCount != -1 && termCount != fieldTermCount) {\n            throw new RuntimeException(\"termCount mismatch \" + termCount + \" vs \" + fieldTermCount);\n          }\n        }\n\n        // Test seeking by ord\n        if (hasOrd && status.termCount-termCountStart > 0) {\n          int seekCount = (int) Math.min(10000L, termCount);\n          if (seekCount > 0) {\n            BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n            // Seek by ord\n            for(int i=seekCount-1;i>=0;i--) {\n              long ord = i*(termCount/seekCount);\n              termsEnum.seekExact(ord);\n              long actualOrd = termsEnum.ord();\n              if (actualOrd != ord) {\n                throw new RuntimeException(\"seek to ord \" + ord + \" returned ord \" + actualOrd);\n              }\n              seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n            }\n            \n            // Seek by term\n            for(int i=seekCount-1;i>=0;i--) {\n              if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n              }\n              if (termsEnum.term().equals(seekTerms[i]) == false) {\n                throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" returned FOUND but seeked to the wrong term \" + termsEnum.term());\n              }\n              \n              postings = termsEnum.postings(postings, PostingsEnum.NONE);\n              if (postings == null) {\n                throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n              }\n            }\n          }\n        }\n      }\n    }\n    \n    int fieldCount = fields.size();\n    \n    if (fieldCount != -1) {\n      if (fieldCount < 0) {\n        throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n      }\n      if (fieldCount != computedFieldCount) {\n        throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n      }\n    }\n\n    if (doPrint) {\n      msg(infoStream, String.format(Locale.ROOT, \"OK [%d terms; %d terms/docs pairs; %d tokens] [took %.3f sec]\",\n                                    status.termCount, status.totFreq, status.totPos, nsToSec(System.nanoTime()-startNS)));\n    }\n    \n    if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n      for(Map.Entry<String, Object> ent : status.blockTreeStats.entrySet()) {\n        infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n        infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82":["372b4e16bc7ce0e14dccdc44b8cb31888f7402ab"],"6b64ceb507ba9aa71920c0bfad91032e2c03d42f":["51f5280f31484820499077f41fcdfe92d527d9dc"],"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50":["0cdf9cc6702d60334a616bd7db3ae91501d1dce7"],"cb5311f0bff57ce15a23909f4cfb953773630534":["e73063b92d958076ef4ae8beb5f493e8ccdcecb4"],"086ffe31d8fba0110227db122974163709ecc1b4":["cc018b79379c67835b40b1259cd3dc931df60944"],"35fb92999b9df7df2ce2b35b83a044cbede61f45":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82"],"6b4e3cd382d0d075a0f1725649c084bb6510c483":["3e8715d826e588419327562287d5d6a8040d63d6","d2638f781be724518ff6c2263d14a48cf6e68017"],"d2638f781be724518ff6c2263d14a48cf6e68017":["65acee44746098674ec238c7116956b3bf3bd13f","3e8715d826e588419327562287d5d6a8040d63d6"],"622a708571e534680618b3c5e0c28ac539a47776":["d523b8189b211dd1630166aa77b8c88bb48b3fcc"],"9a0e5953a07337cd41bcde610503024c07073b26":["622a708571e534680618b3c5e0c28ac539a47776"],"0cdf9cc6702d60334a616bd7db3ae91501d1dce7":["4d637064d608752565d4f9f41b2497dfdfdde50e"],"47d9d581b0b317125672636196fa3c73bbcabc56":["5ad80176d91a6f70fe93880e43dfd697dc4e63ed"],"30c8e5574b55d57947e989443dfde611646530ee":["762c80e29fe0c3bb83aabe2e64af6379273cec7b","cc018b79379c67835b40b1259cd3dc931df60944"],"556a4aab886d75371b2af129d87be3c2795cea76":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"0628077afea69a2955260949478afabab8e500d8":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"51f5280f31484820499077f41fcdfe92d527d9dc":["8028ab7a24273833d53d35eb160dba5b57283cf5"],"8eb2b2b0fce1c4d4ca3b6c6eaa30498066be47d6":["e73063b92d958076ef4ae8beb5f493e8ccdcecb4"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["69d0e71914d75d0016babdee88927593bca21993"],"e73063b92d958076ef4ae8beb5f493e8ccdcecb4":["6b64ceb507ba9aa71920c0bfad91032e2c03d42f"],"8028ab7a24273833d53d35eb160dba5b57283cf5":["556a4aab886d75371b2af129d87be3c2795cea76"],"d4d69c535930b5cce125cff868d40f6373dc27d4":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","59d00acb12c9809438e21de7c24f016356973d46"],"519bac5f6a2dc1779d2fe8e51d9e1762ec94b4a5":["eee5f2a24465d2c9a5f86ab84b7c35041a30fda8"],"3e8715d826e588419327562287d5d6a8040d63d6":["8eb2b2b0fce1c4d4ca3b6c6eaa30498066be47d6"],"f890447ef156e598bffbdc5aab15a68b458c3612":["0974f33be0e2189e71f36b67f1017f4072b1a126"],"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["e99275efa2c9c9ae3bdba986218af82f2bf3dc30","a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"d523b8189b211dd1630166aa77b8c88bb48b3fcc":["cc018b79379c67835b40b1259cd3dc931df60944","086ffe31d8fba0110227db122974163709ecc1b4"],"69d0e71914d75d0016babdee88927593bca21993":["35fb92999b9df7df2ce2b35b83a044cbede61f45"],"e99275efa2c9c9ae3bdba986218af82f2bf3dc30":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"34bbd0c9efc37fd35a3ffdb47172aaebf7ab06db":["519bac5f6a2dc1779d2fe8e51d9e1762ec94b4a5"],"cd7538cbbd9c304bc5396980e9802cd3a5bcf8e4":["762c80e29fe0c3bb83aabe2e64af6379273cec7b"],"0974f33be0e2189e71f36b67f1017f4072b1a126":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["cb5311f0bff57ce15a23909f4cfb953773630534","8eb2b2b0fce1c4d4ca3b6c6eaa30498066be47d6"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cc018b79379c67835b40b1259cd3dc931df60944":["762c80e29fe0c3bb83aabe2e64af6379273cec7b","cd7538cbbd9c304bc5396980e9802cd3a5bcf8e4"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"e93b477a465bb7b012eb16214d6fe0214003e3ab":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064"],"158039752283f0c5acd00ec298d83fad2a0a1971":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"59d00acb12c9809438e21de7c24f016356973d46":["e93b477a465bb7b012eb16214d6fe0214003e3ab"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["34bbd0c9efc37fd35a3ffdb47172aaebf7ab06db"],"5ad80176d91a6f70fe93880e43dfd697dc4e63ed":["f890447ef156e598bffbdc5aab15a68b458c3612"],"c0cd85fde84cb318b4dc97710dcf15e2959a1bbe":["634f330c54fd3f9f491d52036dc3f40b4f4d8934","f890447ef156e598bffbdc5aab15a68b458c3612"],"65acee44746098674ec238c7116956b3bf3bd13f":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae"],"372b4e16bc7ce0e14dccdc44b8cb31888f7402ab":["6b4e3cd382d0d075a0f1725649c084bb6510c483"],"507e7decdf00981d09a74632ea30299a4ce6ba72":["158039752283f0c5acd00ec298d83fad2a0a1971","762c80e29fe0c3bb83aabe2e64af6379273cec7b"],"4d637064d608752565d4f9f41b2497dfdfdde50e":["f890447ef156e598bffbdc5aab15a68b458c3612","47d9d581b0b317125672636196fa3c73bbcabc56"],"762c80e29fe0c3bb83aabe2e64af6379273cec7b":["158039752283f0c5acd00ec298d83fad2a0a1971"],"db68c63cbfaa8698b9c4475f75ed2b9c9696d238":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50","0628077afea69a2955260949478afabab8e500d8"],"eee5f2a24465d2c9a5f86ab84b7c35041a30fda8":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9a0e5953a07337cd41bcde610503024c07073b26"]},"commit2Childs":{"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82":["35fb92999b9df7df2ce2b35b83a044cbede61f45"],"6b64ceb507ba9aa71920c0bfad91032e2c03d42f":["e73063b92d958076ef4ae8beb5f493e8ccdcecb4"],"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50":["0628077afea69a2955260949478afabab8e500d8","db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"cb5311f0bff57ce15a23909f4cfb953773630534":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae"],"086ffe31d8fba0110227db122974163709ecc1b4":["d523b8189b211dd1630166aa77b8c88bb48b3fcc"],"35fb92999b9df7df2ce2b35b83a044cbede61f45":["69d0e71914d75d0016babdee88927593bca21993"],"6b4e3cd382d0d075a0f1725649c084bb6510c483":["372b4e16bc7ce0e14dccdc44b8cb31888f7402ab"],"d2638f781be724518ff6c2263d14a48cf6e68017":["6b4e3cd382d0d075a0f1725649c084bb6510c483"],"622a708571e534680618b3c5e0c28ac539a47776":["9a0e5953a07337cd41bcde610503024c07073b26"],"9a0e5953a07337cd41bcde610503024c07073b26":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"0cdf9cc6702d60334a616bd7db3ae91501d1dce7":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"47d9d581b0b317125672636196fa3c73bbcabc56":["4d637064d608752565d4f9f41b2497dfdfdde50e"],"30c8e5574b55d57947e989443dfde611646530ee":[],"556a4aab886d75371b2af129d87be3c2795cea76":["8028ab7a24273833d53d35eb160dba5b57283cf5"],"0628077afea69a2955260949478afabab8e500d8":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"51f5280f31484820499077f41fcdfe92d527d9dc":["6b64ceb507ba9aa71920c0bfad91032e2c03d42f"],"8eb2b2b0fce1c4d4ca3b6c6eaa30498066be47d6":["3e8715d826e588419327562287d5d6a8040d63d6","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae"],"e73063b92d958076ef4ae8beb5f493e8ccdcecb4":["cb5311f0bff57ce15a23909f4cfb953773630534","8eb2b2b0fce1c4d4ca3b6c6eaa30498066be47d6"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["158039752283f0c5acd00ec298d83fad2a0a1971"],"8028ab7a24273833d53d35eb160dba5b57283cf5":["51f5280f31484820499077f41fcdfe92d527d9dc"],"d4d69c535930b5cce125cff868d40f6373dc27d4":["8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","eee5f2a24465d2c9a5f86ab84b7c35041a30fda8"],"519bac5f6a2dc1779d2fe8e51d9e1762ec94b4a5":["34bbd0c9efc37fd35a3ffdb47172aaebf7ab06db"],"3e8715d826e588419327562287d5d6a8040d63d6":["6b4e3cd382d0d075a0f1725649c084bb6510c483","d2638f781be724518ff6c2263d14a48cf6e68017"],"f890447ef156e598bffbdc5aab15a68b458c3612":["5ad80176d91a6f70fe93880e43dfd697dc4e63ed","c0cd85fde84cb318b4dc97710dcf15e2959a1bbe","4d637064d608752565d4f9f41b2497dfdfdde50e"],"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["e93b477a465bb7b012eb16214d6fe0214003e3ab"],"d523b8189b211dd1630166aa77b8c88bb48b3fcc":["622a708571e534680618b3c5e0c28ac539a47776"],"69d0e71914d75d0016babdee88927593bca21993":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"e99275efa2c9c9ae3bdba986218af82f2bf3dc30":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064"],"34bbd0c9efc37fd35a3ffdb47172aaebf7ab06db":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"cd7538cbbd9c304bc5396980e9802cd3a5bcf8e4":["cc018b79379c67835b40b1259cd3dc931df60944"],"0974f33be0e2189e71f36b67f1017f4072b1a126":["f890447ef156e598bffbdc5aab15a68b458c3612"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["65acee44746098674ec238c7116956b3bf3bd13f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["d4d69c535930b5cce125cff868d40f6373dc27d4","d3fcb70cf561547c7bb1506e0cf32ca7b1287064","e99275efa2c9c9ae3bdba986218af82f2bf3dc30"],"cc018b79379c67835b40b1259cd3dc931df60944":["086ffe31d8fba0110227db122974163709ecc1b4","30c8e5574b55d57947e989443dfde611646530ee","d523b8189b211dd1630166aa77b8c88bb48b3fcc"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":[],"e93b477a465bb7b012eb16214d6fe0214003e3ab":["59d00acb12c9809438e21de7c24f016356973d46"],"158039752283f0c5acd00ec298d83fad2a0a1971":["507e7decdf00981d09a74632ea30299a4ce6ba72","762c80e29fe0c3bb83aabe2e64af6379273cec7b"],"59d00acb12c9809438e21de7c24f016356973d46":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"5ad80176d91a6f70fe93880e43dfd697dc4e63ed":["47d9d581b0b317125672636196fa3c73bbcabc56"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["0974f33be0e2189e71f36b67f1017f4072b1a126","c0cd85fde84cb318b4dc97710dcf15e2959a1bbe"],"c0cd85fde84cb318b4dc97710dcf15e2959a1bbe":[],"65acee44746098674ec238c7116956b3bf3bd13f":["d2638f781be724518ff6c2263d14a48cf6e68017"],"372b4e16bc7ce0e14dccdc44b8cb31888f7402ab":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82"],"507e7decdf00981d09a74632ea30299a4ce6ba72":[],"4d637064d608752565d4f9f41b2497dfdfdde50e":["0cdf9cc6702d60334a616bd7db3ae91501d1dce7"],"762c80e29fe0c3bb83aabe2e64af6379273cec7b":["30c8e5574b55d57947e989443dfde611646530ee","cd7538cbbd9c304bc5396980e9802cd3a5bcf8e4","cc018b79379c67835b40b1259cd3dc931df60944","507e7decdf00981d09a74632ea30299a4ce6ba72"],"db68c63cbfaa8698b9c4475f75ed2b9c9696d238":["556a4aab886d75371b2af129d87be3c2795cea76"],"eee5f2a24465d2c9a5f86ab84b7c35041a30fda8":["519bac5f6a2dc1779d2fe8e51d9e1762ec94b4a5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["30c8e5574b55d57947e989443dfde611646530ee","8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","c0cd85fde84cb318b4dc97710dcf15e2959a1bbe","507e7decdf00981d09a74632ea30299a4ce6ba72","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}