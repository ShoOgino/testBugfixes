{"path":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnVMError#doTest(MockDirectoryWrapper.Failure).mjava","commits":[{"id":"c48871ed951104729f5e17a8ee1091b43fa18980","date":1446564542,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnVMError#doTest(MockDirectoryWrapper.Failure).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfMemory#doTest(MockDirectoryWrapper.Failure).mjava","sourceNew":"  // just one thread, serial merge policy, hopefully debuggable\n  private void doTest(MockDirectoryWrapper.Failure failOn) throws Exception {   \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    final long analyzerSeed = random().nextLong();\n    final Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); // we are gonna make it angry\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    MockDirectoryWrapper dir = null;\n    \n    final int numIterations = TEST_NIGHTLY ? atLeast(100) : atLeast(5);\n    \n    STARTOVER:\n    for (int iter = 0; iter < numIterations; iter++) {\n      try {\n        // close from last run\n        if (dir != null) {\n          dir.close();\n        }\n        // disable slow things: we don't rely upon sleeps here.\n        dir = newMockDirectory();\n        dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n        dir.setUseSlowOpenClosers(false);\n      \n        IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n        // just for now, try to keep this test reproducible\n        conf.setMergeScheduler(new SerialMergeScheduler());\n      \n        // test never makes it this far...\n        int numDocs = atLeast(2000);\n      \n        IndexWriter iw = new IndexWriter(dir, conf);\n        iw.commit(); // ensure there is always a commit\n\n        dir.failOn(failOn);\n        \n        for (int i = 0; i < numDocs; i++) {\n          Document doc = new Document();\n          doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n          doc.add(new NumericDocValuesField(\"dv\", i));\n          doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n          doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          // ensure we store something\n          doc.add(new StoredField(\"stored1\", \"foo\"));\n          doc.add(new StoredField(\"stored1\", \"bar\"));    \n          // ensure we get some payloads\n          doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n          // ensure we get some vectors\n          FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n          ft.setStoreTermVectors(true);\n          doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          if (random().nextInt(10) > 0) {\n            // single doc\n            try {\n              iw.addDocument(doc);\n              // we made it, sometimes delete our doc, or update a dv\n              int thingToDo = random().nextInt(4);\n              if (thingToDo == 0) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n              } else if (thingToDo == 1) {\n                iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n              } else if (thingToDo == 2) {\n                iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n              }\n            } catch (VirtualMachineError | AlreadyClosedException disaster) {\n              getTragedy(disaster, iw, exceptionStream);\n              continue STARTOVER;\n            }\n          } else {\n            // block docs\n            Document doc2 = new Document();\n            doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n            doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n            doc2.add(new StoredField(\"stored1\", \"foo\"));\n            doc2.add(new StoredField(\"stored1\", \"bar\"));\n            doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n            \n            try {\n              iw.addDocuments(Arrays.asList(doc, doc2));\n              // we made it, sometimes delete our docs\n              if (random().nextBoolean()) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n              }\n            } catch (VirtualMachineError | AlreadyClosedException disaster) {\n              getTragedy(disaster, iw, exceptionStream);\n              continue STARTOVER;\n            }\n          }\n          \n          if (random().nextInt(10) == 0) {\n            // trigger flush:\n            try {\n              if (random().nextBoolean()) {\n                DirectoryReader ir = null;\n                try {\n                  ir = DirectoryReader.open(iw, random().nextBoolean());\n                  TestUtil.checkReader(ir);\n                } finally {\n                  IOUtils.closeWhileHandlingException(ir);\n                }\n              } else {\n                iw.commit();\n              }\n              if (DirectoryReader.indexExists(dir)) {\n                TestUtil.checkIndex(dir);\n              }\n            } catch (VirtualMachineError | AlreadyClosedException disaster) {\n              getTragedy(disaster, iw, exceptionStream);\n              continue STARTOVER;\n            }\n          }\n        }\n        \n        try {\n          iw.close();\n        } catch (VirtualMachineError | AlreadyClosedException disaster) {\n          getTragedy(disaster, iw, exceptionStream);\n          continue STARTOVER;\n        }\n      } catch (Throwable t) {\n        System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n        exceptionStream.flush();\n        System.out.println(exceptionLog.toString(\"UTF-8\"));\n        System.out.flush();\n        Rethrow.rethrow(t);\n      }\n    }\n    dir.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","sourceOld":"  // just one thread, serial merge policy, hopefully debuggable\n  private void doTest(MockDirectoryWrapper.Failure failOn) throws Exception {   \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    final long analyzerSeed = random().nextLong();\n    final Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); // we are gonna make it angry\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    MockDirectoryWrapper dir = null;\n    \n    final int numIterations = TEST_NIGHTLY ? atLeast(100) : atLeast(5);\n    \n    STARTOVER:\n    for (int iter = 0; iter < numIterations; iter++) {\n      try {\n        // close from last run\n        if (dir != null) {\n          dir.close();\n        }\n        // disable slow things: we don't rely upon sleeps here.\n        dir = newMockDirectory();\n        dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n        dir.setUseSlowOpenClosers(false);\n      \n        IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n        // just for now, try to keep this test reproducible\n        conf.setMergeScheduler(new SerialMergeScheduler());\n      \n        // test never makes it this far...\n        int numDocs = atLeast(2000);\n      \n        IndexWriter iw = new IndexWriter(dir, conf);\n        iw.commit(); // ensure there is always a commit\n\n        dir.failOn(failOn);\n        \n        for (int i = 0; i < numDocs; i++) {\n          Document doc = new Document();\n          doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n          doc.add(new NumericDocValuesField(\"dv\", i));\n          doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n          doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          // ensure we store something\n          doc.add(new StoredField(\"stored1\", \"foo\"));\n          doc.add(new StoredField(\"stored1\", \"bar\"));    \n          // ensure we get some payloads\n          doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n          // ensure we get some vectors\n          FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n          ft.setStoreTermVectors(true);\n          doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          if (random().nextInt(10) > 0) {\n            // single doc\n            try {\n              iw.addDocument(doc);\n              // we made it, sometimes delete our doc, or update a dv\n              int thingToDo = random().nextInt(4);\n              if (thingToDo == 0) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n              } else if (thingToDo == 1) {\n                iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n              } else if (thingToDo == 2) {\n                iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n              }\n            } catch (OutOfMemoryError | AlreadyClosedException disaster) {\n              getOOM(disaster, iw, exceptionStream);\n              continue STARTOVER;\n            }\n          } else {\n            // block docs\n            Document doc2 = new Document();\n            doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n            doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n            doc2.add(new StoredField(\"stored1\", \"foo\"));\n            doc2.add(new StoredField(\"stored1\", \"bar\"));\n            doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n            \n            try {\n              iw.addDocuments(Arrays.asList(doc, doc2));\n              // we made it, sometimes delete our docs\n              if (random().nextBoolean()) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n              }\n            } catch (OutOfMemoryError | AlreadyClosedException disaster) {\n              getOOM(disaster, iw, exceptionStream);\n              continue STARTOVER;\n            }\n          }\n          \n          if (random().nextInt(10) == 0) {\n            // trigger flush:\n            try {\n              if (random().nextBoolean()) {\n                DirectoryReader ir = null;\n                try {\n                  ir = DirectoryReader.open(iw, random().nextBoolean());\n                  TestUtil.checkReader(ir);\n                } finally {\n                  IOUtils.closeWhileHandlingException(ir);\n                }\n              } else {\n                iw.commit();\n              }\n              if (DirectoryReader.indexExists(dir)) {\n                TestUtil.checkIndex(dir);\n              }\n            } catch (OutOfMemoryError | AlreadyClosedException disaster) {\n              getOOM(disaster, iw, exceptionStream);\n              continue STARTOVER;\n            }\n          }\n        }\n        \n        try {\n          iw.close();\n        } catch (OutOfMemoryError | AlreadyClosedException disaster) {\n          getOOM(disaster, iw, exceptionStream);\n          continue STARTOVER;\n        }\n      } catch (Throwable t) {\n        System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n        exceptionStream.flush();\n        System.out.println(exceptionLog.toString(\"UTF-8\"));\n        System.out.flush();\n        Rethrow.rethrow(t);\n      }\n    }\n    dir.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0d49a158012a8ff48f328a4558e4bfcffbaed16f","date":1453677440,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnVMError#doTest(MockDirectoryWrapper.Failure).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnVMError#doTest(MockDirectoryWrapper.Failure).mjava","sourceNew":"  // just one thread, serial merge policy, hopefully debuggable\n  private void doTest(MockDirectoryWrapper.Failure failOn) throws Exception {   \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    final long analyzerSeed = random().nextLong();\n    final Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); // we are gonna make it angry\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    MockDirectoryWrapper dir = null;\n    \n    final int numIterations = TEST_NIGHTLY ? atLeast(100) : atLeast(5);\n    \n    STARTOVER:\n    for (int iter = 0; iter < numIterations; iter++) {\n      try {\n        // close from last run\n        if (dir != null) {\n          dir.close();\n        }\n        // disable slow things: we don't rely upon sleeps here.\n        dir = newMockDirectory();\n        dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n        dir.setUseSlowOpenClosers(false);\n      \n        IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n        // just for now, try to keep this test reproducible\n        conf.setMergeScheduler(new SerialMergeScheduler());\n      \n        // test never makes it this far...\n        int numDocs = atLeast(2000);\n      \n        IndexWriter iw = new IndexWriter(dir, conf);\n        iw.commit(); // ensure there is always a commit\n\n        dir.failOn(failOn);\n        \n        for (int i = 0; i < numDocs; i++) {\n          Document doc = new Document();\n          doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n          doc.add(new NumericDocValuesField(\"dv\", i));\n          doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n          doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          // ensure we store something\n          doc.add(new StoredField(\"stored1\", \"foo\"));\n          doc.add(new StoredField(\"stored1\", \"bar\"));    \n          // ensure we get some payloads\n          doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n          // ensure we get some vectors\n          FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n          ft.setStoreTermVectors(true);\n          doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          if (random().nextInt(10) > 0) {\n            // single doc\n            try {\n              iw.addDocument(doc);\n              // we made it, sometimes delete our doc, or update a dv\n              int thingToDo = random().nextInt(4);\n              if (thingToDo == 0) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n              } else if (thingToDo == 1) {\n                iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n              } else if (thingToDo == 2) {\n                iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n              }\n            } catch (VirtualMachineError | AlreadyClosedException disaster) {\n              getTragedy(disaster, iw, exceptionStream);\n              continue STARTOVER;\n            }\n          } else {\n            // block docs\n            Document doc2 = new Document();\n            doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n            doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n            doc2.add(new StoredField(\"stored1\", \"foo\"));\n            doc2.add(new StoredField(\"stored1\", \"bar\"));\n            doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n            \n            try {\n              iw.addDocuments(Arrays.asList(doc, doc2));\n              // we made it, sometimes delete our docs\n              if (random().nextBoolean()) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n              }\n            } catch (VirtualMachineError | AlreadyClosedException disaster) {\n              getTragedy(disaster, iw, exceptionStream);\n              continue STARTOVER;\n            }\n          }\n          \n          if (random().nextInt(10) == 0) {\n            // trigger flush:\n            try {\n              if (random().nextBoolean()) {\n                DirectoryReader ir = null;\n                try {\n                  ir = DirectoryReader.open(iw, random().nextBoolean(), false);\n                  TestUtil.checkReader(ir);\n                } finally {\n                  IOUtils.closeWhileHandlingException(ir);\n                }\n              } else {\n                iw.commit();\n              }\n              if (DirectoryReader.indexExists(dir)) {\n                TestUtil.checkIndex(dir);\n              }\n            } catch (VirtualMachineError | AlreadyClosedException disaster) {\n              getTragedy(disaster, iw, exceptionStream);\n              continue STARTOVER;\n            }\n          }\n        }\n        \n        try {\n          iw.close();\n        } catch (VirtualMachineError | AlreadyClosedException disaster) {\n          getTragedy(disaster, iw, exceptionStream);\n          continue STARTOVER;\n        }\n      } catch (Throwable t) {\n        System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n        exceptionStream.flush();\n        System.out.println(exceptionLog.toString(\"UTF-8\"));\n        System.out.flush();\n        Rethrow.rethrow(t);\n      }\n    }\n    dir.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","sourceOld":"  // just one thread, serial merge policy, hopefully debuggable\n  private void doTest(MockDirectoryWrapper.Failure failOn) throws Exception {   \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    final long analyzerSeed = random().nextLong();\n    final Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); // we are gonna make it angry\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    MockDirectoryWrapper dir = null;\n    \n    final int numIterations = TEST_NIGHTLY ? atLeast(100) : atLeast(5);\n    \n    STARTOVER:\n    for (int iter = 0; iter < numIterations; iter++) {\n      try {\n        // close from last run\n        if (dir != null) {\n          dir.close();\n        }\n        // disable slow things: we don't rely upon sleeps here.\n        dir = newMockDirectory();\n        dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n        dir.setUseSlowOpenClosers(false);\n      \n        IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n        // just for now, try to keep this test reproducible\n        conf.setMergeScheduler(new SerialMergeScheduler());\n      \n        // test never makes it this far...\n        int numDocs = atLeast(2000);\n      \n        IndexWriter iw = new IndexWriter(dir, conf);\n        iw.commit(); // ensure there is always a commit\n\n        dir.failOn(failOn);\n        \n        for (int i = 0; i < numDocs; i++) {\n          Document doc = new Document();\n          doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n          doc.add(new NumericDocValuesField(\"dv\", i));\n          doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n          doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          // ensure we store something\n          doc.add(new StoredField(\"stored1\", \"foo\"));\n          doc.add(new StoredField(\"stored1\", \"bar\"));    \n          // ensure we get some payloads\n          doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n          // ensure we get some vectors\n          FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n          ft.setStoreTermVectors(true);\n          doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          if (random().nextInt(10) > 0) {\n            // single doc\n            try {\n              iw.addDocument(doc);\n              // we made it, sometimes delete our doc, or update a dv\n              int thingToDo = random().nextInt(4);\n              if (thingToDo == 0) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n              } else if (thingToDo == 1) {\n                iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n              } else if (thingToDo == 2) {\n                iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n              }\n            } catch (VirtualMachineError | AlreadyClosedException disaster) {\n              getTragedy(disaster, iw, exceptionStream);\n              continue STARTOVER;\n            }\n          } else {\n            // block docs\n            Document doc2 = new Document();\n            doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n            doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n            doc2.add(new StoredField(\"stored1\", \"foo\"));\n            doc2.add(new StoredField(\"stored1\", \"bar\"));\n            doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n            \n            try {\n              iw.addDocuments(Arrays.asList(doc, doc2));\n              // we made it, sometimes delete our docs\n              if (random().nextBoolean()) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n              }\n            } catch (VirtualMachineError | AlreadyClosedException disaster) {\n              getTragedy(disaster, iw, exceptionStream);\n              continue STARTOVER;\n            }\n          }\n          \n          if (random().nextInt(10) == 0) {\n            // trigger flush:\n            try {\n              if (random().nextBoolean()) {\n                DirectoryReader ir = null;\n                try {\n                  ir = DirectoryReader.open(iw, random().nextBoolean());\n                  TestUtil.checkReader(ir);\n                } finally {\n                  IOUtils.closeWhileHandlingException(ir);\n                }\n              } else {\n                iw.commit();\n              }\n              if (DirectoryReader.indexExists(dir)) {\n                TestUtil.checkIndex(dir);\n              }\n            } catch (VirtualMachineError | AlreadyClosedException disaster) {\n              getTragedy(disaster, iw, exceptionStream);\n              continue STARTOVER;\n            }\n          }\n        }\n        \n        try {\n          iw.close();\n        } catch (VirtualMachineError | AlreadyClosedException disaster) {\n          getTragedy(disaster, iw, exceptionStream);\n          continue STARTOVER;\n        }\n      } catch (Throwable t) {\n        System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n        exceptionStream.flush();\n        System.out.println(exceptionLog.toString(\"UTF-8\"));\n        System.out.flush();\n        Rethrow.rethrow(t);\n      }\n    }\n    dir.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"85ca0e073c286ebb2c89364ada6dd2740fc18880","date":1453996944,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnVMError#doTest(MockDirectoryWrapper.Failure).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnVMError#doTest(MockDirectoryWrapper.Failure).mjava","sourceNew":"  // just one thread, serial merge policy, hopefully debuggable\n  private void doTest(MockDirectoryWrapper.Failure failOn) throws Exception {   \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    final long analyzerSeed = random().nextLong();\n    final Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); // we are gonna make it angry\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    MockDirectoryWrapper dir = null;\n    \n    final int numIterations = TEST_NIGHTLY ? atLeast(100) : atLeast(5);\n    \n    STARTOVER:\n    for (int iter = 0; iter < numIterations; iter++) {\n      try {\n        // close from last run\n        if (dir != null) {\n          dir.close();\n        }\n        // disable slow things: we don't rely upon sleeps here.\n        dir = newMockDirectory();\n        dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n        dir.setUseSlowOpenClosers(false);\n      \n        IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n        // just for now, try to keep this test reproducible\n        conf.setMergeScheduler(new SerialMergeScheduler());\n      \n        // test never makes it this far...\n        int numDocs = atLeast(2000);\n      \n        IndexWriter iw = new IndexWriter(dir, conf);\n        iw.commit(); // ensure there is always a commit\n\n        dir.failOn(failOn);\n        \n        for (int i = 0; i < numDocs; i++) {\n          Document doc = new Document();\n          doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n          doc.add(new NumericDocValuesField(\"dv\", i));\n          doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n          doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          // ensure we store something\n          doc.add(new StoredField(\"stored1\", \"foo\"));\n          doc.add(new StoredField(\"stored1\", \"bar\"));    \n          // ensure we get some payloads\n          doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n          // ensure we get some vectors\n          FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n          ft.setStoreTermVectors(true);\n          doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          doc.add(new IntPoint(\"point\", random().nextInt()));\n          \n          if (random().nextInt(10) > 0) {\n            // single doc\n            try {\n              iw.addDocument(doc);\n              // we made it, sometimes delete our doc, or update a dv\n              int thingToDo = random().nextInt(4);\n              if (thingToDo == 0) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n              } else if (thingToDo == 1) {\n                iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n              } else if (thingToDo == 2) {\n                iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n              }\n            } catch (VirtualMachineError | AlreadyClosedException disaster) {\n              getTragedy(disaster, iw, exceptionStream);\n              continue STARTOVER;\n            }\n          } else {\n            // block docs\n            Document doc2 = new Document();\n            doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n            doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n            doc2.add(new StoredField(\"stored1\", \"foo\"));\n            doc2.add(new StoredField(\"stored1\", \"bar\"));\n            doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n            \n            try {\n              iw.addDocuments(Arrays.asList(doc, doc2));\n              // we made it, sometimes delete our docs\n              if (random().nextBoolean()) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n              }\n            } catch (VirtualMachineError | AlreadyClosedException disaster) {\n              getTragedy(disaster, iw, exceptionStream);\n              continue STARTOVER;\n            }\n          }\n          \n          if (random().nextInt(10) == 0) {\n            // trigger flush:\n            try {\n              if (random().nextBoolean()) {\n                DirectoryReader ir = null;\n                try {\n                  ir = DirectoryReader.open(iw, random().nextBoolean());\n                  TestUtil.checkReader(ir);\n                } finally {\n                  IOUtils.closeWhileHandlingException(ir);\n                }\n              } else {\n                iw.commit();\n              }\n              if (DirectoryReader.indexExists(dir)) {\n                TestUtil.checkIndex(dir);\n              }\n            } catch (VirtualMachineError | AlreadyClosedException disaster) {\n              getTragedy(disaster, iw, exceptionStream);\n              continue STARTOVER;\n            }\n          }\n        }\n        \n        try {\n          iw.close();\n        } catch (VirtualMachineError | AlreadyClosedException disaster) {\n          getTragedy(disaster, iw, exceptionStream);\n          continue STARTOVER;\n        }\n      } catch (Throwable t) {\n        System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n        exceptionStream.flush();\n        System.out.println(exceptionLog.toString(\"UTF-8\"));\n        System.out.flush();\n        Rethrow.rethrow(t);\n      }\n    }\n    dir.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","sourceOld":"  // just one thread, serial merge policy, hopefully debuggable\n  private void doTest(MockDirectoryWrapper.Failure failOn) throws Exception {   \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    final long analyzerSeed = random().nextLong();\n    final Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); // we are gonna make it angry\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    MockDirectoryWrapper dir = null;\n    \n    final int numIterations = TEST_NIGHTLY ? atLeast(100) : atLeast(5);\n    \n    STARTOVER:\n    for (int iter = 0; iter < numIterations; iter++) {\n      try {\n        // close from last run\n        if (dir != null) {\n          dir.close();\n        }\n        // disable slow things: we don't rely upon sleeps here.\n        dir = newMockDirectory();\n        dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n        dir.setUseSlowOpenClosers(false);\n      \n        IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n        // just for now, try to keep this test reproducible\n        conf.setMergeScheduler(new SerialMergeScheduler());\n      \n        // test never makes it this far...\n        int numDocs = atLeast(2000);\n      \n        IndexWriter iw = new IndexWriter(dir, conf);\n        iw.commit(); // ensure there is always a commit\n\n        dir.failOn(failOn);\n        \n        for (int i = 0; i < numDocs; i++) {\n          Document doc = new Document();\n          doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n          doc.add(new NumericDocValuesField(\"dv\", i));\n          doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n          doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          // ensure we store something\n          doc.add(new StoredField(\"stored1\", \"foo\"));\n          doc.add(new StoredField(\"stored1\", \"bar\"));    \n          // ensure we get some payloads\n          doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n          // ensure we get some vectors\n          FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n          ft.setStoreTermVectors(true);\n          doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          if (random().nextInt(10) > 0) {\n            // single doc\n            try {\n              iw.addDocument(doc);\n              // we made it, sometimes delete our doc, or update a dv\n              int thingToDo = random().nextInt(4);\n              if (thingToDo == 0) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n              } else if (thingToDo == 1) {\n                iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n              } else if (thingToDo == 2) {\n                iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n              }\n            } catch (VirtualMachineError | AlreadyClosedException disaster) {\n              getTragedy(disaster, iw, exceptionStream);\n              continue STARTOVER;\n            }\n          } else {\n            // block docs\n            Document doc2 = new Document();\n            doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n            doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n            doc2.add(new StoredField(\"stored1\", \"foo\"));\n            doc2.add(new StoredField(\"stored1\", \"bar\"));\n            doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n            \n            try {\n              iw.addDocuments(Arrays.asList(doc, doc2));\n              // we made it, sometimes delete our docs\n              if (random().nextBoolean()) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n              }\n            } catch (VirtualMachineError | AlreadyClosedException disaster) {\n              getTragedy(disaster, iw, exceptionStream);\n              continue STARTOVER;\n            }\n          }\n          \n          if (random().nextInt(10) == 0) {\n            // trigger flush:\n            try {\n              if (random().nextBoolean()) {\n                DirectoryReader ir = null;\n                try {\n                  ir = DirectoryReader.open(iw, random().nextBoolean());\n                  TestUtil.checkReader(ir);\n                } finally {\n                  IOUtils.closeWhileHandlingException(ir);\n                }\n              } else {\n                iw.commit();\n              }\n              if (DirectoryReader.indexExists(dir)) {\n                TestUtil.checkIndex(dir);\n              }\n            } catch (VirtualMachineError | AlreadyClosedException disaster) {\n              getTragedy(disaster, iw, exceptionStream);\n              continue STARTOVER;\n            }\n          }\n        }\n        \n        try {\n          iw.close();\n        } catch (VirtualMachineError | AlreadyClosedException disaster) {\n          getTragedy(disaster, iw, exceptionStream);\n          continue STARTOVER;\n        }\n      } catch (Throwable t) {\n        System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n        exceptionStream.flush();\n        System.out.println(exceptionLog.toString(\"UTF-8\"));\n        System.out.flush();\n        Rethrow.rethrow(t);\n      }\n    }\n    dir.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8de18786ea000fc5fbc7214d571cc7f41d597ee3","date":1454085819,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnVMError#doTest(MockDirectoryWrapper.Failure).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnVMError#doTest(MockDirectoryWrapper.Failure).mjava","sourceNew":"  // just one thread, serial merge policy, hopefully debuggable\n  private void doTest(MockDirectoryWrapper.Failure failOn) throws Exception {   \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    final long analyzerSeed = random().nextLong();\n    final Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); // we are gonna make it angry\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    MockDirectoryWrapper dir = null;\n    \n    final int numIterations = TEST_NIGHTLY ? atLeast(100) : atLeast(5);\n    \n    STARTOVER:\n    for (int iter = 0; iter < numIterations; iter++) {\n      try {\n        // close from last run\n        if (dir != null) {\n          dir.close();\n        }\n        // disable slow things: we don't rely upon sleeps here.\n        dir = newMockDirectory();\n        dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n        dir.setUseSlowOpenClosers(false);\n      \n        IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n        // just for now, try to keep this test reproducible\n        conf.setMergeScheduler(new SerialMergeScheduler());\n      \n        // test never makes it this far...\n        int numDocs = atLeast(2000);\n      \n        IndexWriter iw = new IndexWriter(dir, conf);\n        iw.commit(); // ensure there is always a commit\n\n        dir.failOn(failOn);\n        \n        for (int i = 0; i < numDocs; i++) {\n          Document doc = new Document();\n          doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n          doc.add(new NumericDocValuesField(\"dv\", i));\n          doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n          doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          // ensure we store something\n          doc.add(new StoredField(\"stored1\", \"foo\"));\n          doc.add(new StoredField(\"stored1\", \"bar\"));    \n          // ensure we get some payloads\n          doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n          // ensure we get some vectors\n          FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n          ft.setStoreTermVectors(true);\n          doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          doc.add(new IntPoint(\"point\", random().nextInt()));\n          doc.add(new IntPoint(\"point2d\", random().nextInt(), random().nextInt()));\n          \n          if (random().nextInt(10) > 0) {\n            // single doc\n            try {\n              iw.addDocument(doc);\n              // we made it, sometimes delete our doc, or update a dv\n              int thingToDo = random().nextInt(4);\n              if (thingToDo == 0) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n              } else if (thingToDo == 1) {\n                iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n              } else if (thingToDo == 2) {\n                iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n              }\n            } catch (VirtualMachineError | AlreadyClosedException disaster) {\n              getTragedy(disaster, iw, exceptionStream);\n              continue STARTOVER;\n            }\n          } else {\n            // block docs\n            Document doc2 = new Document();\n            doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n            doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n            doc2.add(new StoredField(\"stored1\", \"foo\"));\n            doc2.add(new StoredField(\"stored1\", \"bar\"));\n            doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n            \n            try {\n              iw.addDocuments(Arrays.asList(doc, doc2));\n              // we made it, sometimes delete our docs\n              if (random().nextBoolean()) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n              }\n            } catch (VirtualMachineError | AlreadyClosedException disaster) {\n              getTragedy(disaster, iw, exceptionStream);\n              continue STARTOVER;\n            }\n          }\n          \n          if (random().nextInt(10) == 0) {\n            // trigger flush:\n            try {\n              if (random().nextBoolean()) {\n                DirectoryReader ir = null;\n                try {\n                  ir = DirectoryReader.open(iw, random().nextBoolean());\n                  TestUtil.checkReader(ir);\n                } finally {\n                  IOUtils.closeWhileHandlingException(ir);\n                }\n              } else {\n                iw.commit();\n              }\n              if (DirectoryReader.indexExists(dir)) {\n                TestUtil.checkIndex(dir);\n              }\n            } catch (VirtualMachineError | AlreadyClosedException disaster) {\n              getTragedy(disaster, iw, exceptionStream);\n              continue STARTOVER;\n            }\n          }\n        }\n        \n        try {\n          iw.close();\n        } catch (VirtualMachineError | AlreadyClosedException disaster) {\n          getTragedy(disaster, iw, exceptionStream);\n          continue STARTOVER;\n        }\n      } catch (Throwable t) {\n        System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n        exceptionStream.flush();\n        System.out.println(exceptionLog.toString(\"UTF-8\"));\n        System.out.flush();\n        Rethrow.rethrow(t);\n      }\n    }\n    dir.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","sourceOld":"  // just one thread, serial merge policy, hopefully debuggable\n  private void doTest(MockDirectoryWrapper.Failure failOn) throws Exception {   \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    final long analyzerSeed = random().nextLong();\n    final Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); // we are gonna make it angry\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    MockDirectoryWrapper dir = null;\n    \n    final int numIterations = TEST_NIGHTLY ? atLeast(100) : atLeast(5);\n    \n    STARTOVER:\n    for (int iter = 0; iter < numIterations; iter++) {\n      try {\n        // close from last run\n        if (dir != null) {\n          dir.close();\n        }\n        // disable slow things: we don't rely upon sleeps here.\n        dir = newMockDirectory();\n        dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n        dir.setUseSlowOpenClosers(false);\n      \n        IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n        // just for now, try to keep this test reproducible\n        conf.setMergeScheduler(new SerialMergeScheduler());\n      \n        // test never makes it this far...\n        int numDocs = atLeast(2000);\n      \n        IndexWriter iw = new IndexWriter(dir, conf);\n        iw.commit(); // ensure there is always a commit\n\n        dir.failOn(failOn);\n        \n        for (int i = 0; i < numDocs; i++) {\n          Document doc = new Document();\n          doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n          doc.add(new NumericDocValuesField(\"dv\", i));\n          doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n          doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          // ensure we store something\n          doc.add(new StoredField(\"stored1\", \"foo\"));\n          doc.add(new StoredField(\"stored1\", \"bar\"));    \n          // ensure we get some payloads\n          doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n          // ensure we get some vectors\n          FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n          ft.setStoreTermVectors(true);\n          doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          doc.add(new IntPoint(\"point\", random().nextInt()));\n          \n          if (random().nextInt(10) > 0) {\n            // single doc\n            try {\n              iw.addDocument(doc);\n              // we made it, sometimes delete our doc, or update a dv\n              int thingToDo = random().nextInt(4);\n              if (thingToDo == 0) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n              } else if (thingToDo == 1) {\n                iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n              } else if (thingToDo == 2) {\n                iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n              }\n            } catch (VirtualMachineError | AlreadyClosedException disaster) {\n              getTragedy(disaster, iw, exceptionStream);\n              continue STARTOVER;\n            }\n          } else {\n            // block docs\n            Document doc2 = new Document();\n            doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n            doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n            doc2.add(new StoredField(\"stored1\", \"foo\"));\n            doc2.add(new StoredField(\"stored1\", \"bar\"));\n            doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n            \n            try {\n              iw.addDocuments(Arrays.asList(doc, doc2));\n              // we made it, sometimes delete our docs\n              if (random().nextBoolean()) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n              }\n            } catch (VirtualMachineError | AlreadyClosedException disaster) {\n              getTragedy(disaster, iw, exceptionStream);\n              continue STARTOVER;\n            }\n          }\n          \n          if (random().nextInt(10) == 0) {\n            // trigger flush:\n            try {\n              if (random().nextBoolean()) {\n                DirectoryReader ir = null;\n                try {\n                  ir = DirectoryReader.open(iw, random().nextBoolean());\n                  TestUtil.checkReader(ir);\n                } finally {\n                  IOUtils.closeWhileHandlingException(ir);\n                }\n              } else {\n                iw.commit();\n              }\n              if (DirectoryReader.indexExists(dir)) {\n                TestUtil.checkIndex(dir);\n              }\n            } catch (VirtualMachineError | AlreadyClosedException disaster) {\n              getTragedy(disaster, iw, exceptionStream);\n              continue STARTOVER;\n            }\n          }\n        }\n        \n        try {\n          iw.close();\n        } catch (VirtualMachineError | AlreadyClosedException disaster) {\n          getTragedy(disaster, iw, exceptionStream);\n          continue STARTOVER;\n        }\n      } catch (Throwable t) {\n        System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n        exceptionStream.flush();\n        System.out.println(exceptionLog.toString(\"UTF-8\"));\n        System.out.flush();\n        Rethrow.rethrow(t);\n      }\n    }\n    dir.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8d15e34266d75e4e8b95da046cd0afc812367b38","date":1454246129,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnVMError#doTest(MockDirectoryWrapper.Failure).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnVMError#doTest(MockDirectoryWrapper.Failure).mjava","sourceNew":"  // just one thread, serial merge policy, hopefully debuggable\n  private void doTest(MockDirectoryWrapper.Failure failOn) throws Exception {   \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    final long analyzerSeed = random().nextLong();\n    final Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); // we are gonna make it angry\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    MockDirectoryWrapper dir = null;\n    \n    final int numIterations = TEST_NIGHTLY ? atLeast(100) : atLeast(5);\n    \n    STARTOVER:\n    for (int iter = 0; iter < numIterations; iter++) {\n      try {\n        // close from last run\n        if (dir != null) {\n          dir.close();\n        }\n        // disable slow things: we don't rely upon sleeps here.\n        dir = newMockDirectory();\n        dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n        dir.setUseSlowOpenClosers(false);\n      \n        IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n        // just for now, try to keep this test reproducible\n        conf.setMergeScheduler(new SerialMergeScheduler());\n      \n        // test never makes it this far...\n        int numDocs = atLeast(2000);\n      \n        IndexWriter iw = new IndexWriter(dir, conf);\n        iw.commit(); // ensure there is always a commit\n\n        dir.failOn(failOn);\n        \n        for (int i = 0; i < numDocs; i++) {\n          Document doc = new Document();\n          doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n          doc.add(new NumericDocValuesField(\"dv\", i));\n          doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n          doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          // ensure we store something\n          doc.add(new StoredField(\"stored1\", \"foo\"));\n          doc.add(new StoredField(\"stored1\", \"bar\"));    \n          // ensure we get some payloads\n          doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n          // ensure we get some vectors\n          FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n          ft.setStoreTermVectors(true);\n          doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          doc.add(new IntPoint(\"point\", random().nextInt()));\n          doc.add(new IntPoint(\"point2d\", random().nextInt(), random().nextInt()));\n          \n          if (random().nextInt(10) > 0) {\n            // single doc\n            try {\n              iw.addDocument(doc);\n              // we made it, sometimes delete our doc, or update a dv\n              int thingToDo = random().nextInt(4);\n              if (thingToDo == 0) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n              } else if (thingToDo == 1) {\n                iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n              } else if (thingToDo == 2) {\n                iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n              }\n            } catch (VirtualMachineError | AlreadyClosedException disaster) {\n              getTragedy(disaster, iw, exceptionStream);\n              continue STARTOVER;\n            }\n          } else {\n            // block docs\n            Document doc2 = new Document();\n            doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n            doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n            doc2.add(new StoredField(\"stored1\", \"foo\"));\n            doc2.add(new StoredField(\"stored1\", \"bar\"));\n            doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n            \n            try {\n              iw.addDocuments(Arrays.asList(doc, doc2));\n              // we made it, sometimes delete our docs\n              if (random().nextBoolean()) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n              }\n            } catch (VirtualMachineError | AlreadyClosedException disaster) {\n              getTragedy(disaster, iw, exceptionStream);\n              continue STARTOVER;\n            }\n          }\n          \n          if (random().nextInt(10) == 0) {\n            // trigger flush:\n            try {\n              if (random().nextBoolean()) {\n                DirectoryReader ir = null;\n                try {\n                  ir = DirectoryReader.open(iw, random().nextBoolean());\n                  TestUtil.checkReader(ir);\n                } finally {\n                  IOUtils.closeWhileHandlingException(ir);\n                }\n              } else {\n                iw.commit();\n              }\n              if (DirectoryReader.indexExists(dir)) {\n                TestUtil.checkIndex(dir);\n              }\n            } catch (VirtualMachineError | AlreadyClosedException disaster) {\n              getTragedy(disaster, iw, exceptionStream);\n              continue STARTOVER;\n            }\n          }\n        }\n        \n        try {\n          iw.close();\n        } catch (VirtualMachineError | AlreadyClosedException disaster) {\n          getTragedy(disaster, iw, exceptionStream);\n          continue STARTOVER;\n        }\n      } catch (Throwable t) {\n        System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n        exceptionStream.flush();\n        System.out.println(exceptionLog.toString(\"UTF-8\"));\n        System.out.flush();\n        Rethrow.rethrow(t);\n      }\n    }\n    dir.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","sourceOld":"  // just one thread, serial merge policy, hopefully debuggable\n  private void doTest(MockDirectoryWrapper.Failure failOn) throws Exception {   \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    final long analyzerSeed = random().nextLong();\n    final Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); // we are gonna make it angry\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    MockDirectoryWrapper dir = null;\n    \n    final int numIterations = TEST_NIGHTLY ? atLeast(100) : atLeast(5);\n    \n    STARTOVER:\n    for (int iter = 0; iter < numIterations; iter++) {\n      try {\n        // close from last run\n        if (dir != null) {\n          dir.close();\n        }\n        // disable slow things: we don't rely upon sleeps here.\n        dir = newMockDirectory();\n        dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n        dir.setUseSlowOpenClosers(false);\n      \n        IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n        // just for now, try to keep this test reproducible\n        conf.setMergeScheduler(new SerialMergeScheduler());\n      \n        // test never makes it this far...\n        int numDocs = atLeast(2000);\n      \n        IndexWriter iw = new IndexWriter(dir, conf);\n        iw.commit(); // ensure there is always a commit\n\n        dir.failOn(failOn);\n        \n        for (int i = 0; i < numDocs; i++) {\n          Document doc = new Document();\n          doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n          doc.add(new NumericDocValuesField(\"dv\", i));\n          doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n          doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          // ensure we store something\n          doc.add(new StoredField(\"stored1\", \"foo\"));\n          doc.add(new StoredField(\"stored1\", \"bar\"));    \n          // ensure we get some payloads\n          doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n          // ensure we get some vectors\n          FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n          ft.setStoreTermVectors(true);\n          doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          if (random().nextInt(10) > 0) {\n            // single doc\n            try {\n              iw.addDocument(doc);\n              // we made it, sometimes delete our doc, or update a dv\n              int thingToDo = random().nextInt(4);\n              if (thingToDo == 0) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n              } else if (thingToDo == 1) {\n                iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n              } else if (thingToDo == 2) {\n                iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n              }\n            } catch (VirtualMachineError | AlreadyClosedException disaster) {\n              getTragedy(disaster, iw, exceptionStream);\n              continue STARTOVER;\n            }\n          } else {\n            // block docs\n            Document doc2 = new Document();\n            doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n            doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n            doc2.add(new StoredField(\"stored1\", \"foo\"));\n            doc2.add(new StoredField(\"stored1\", \"bar\"));\n            doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n            \n            try {\n              iw.addDocuments(Arrays.asList(doc, doc2));\n              // we made it, sometimes delete our docs\n              if (random().nextBoolean()) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n              }\n            } catch (VirtualMachineError | AlreadyClosedException disaster) {\n              getTragedy(disaster, iw, exceptionStream);\n              continue STARTOVER;\n            }\n          }\n          \n          if (random().nextInt(10) == 0) {\n            // trigger flush:\n            try {\n              if (random().nextBoolean()) {\n                DirectoryReader ir = null;\n                try {\n                  ir = DirectoryReader.open(iw, random().nextBoolean());\n                  TestUtil.checkReader(ir);\n                } finally {\n                  IOUtils.closeWhileHandlingException(ir);\n                }\n              } else {\n                iw.commit();\n              }\n              if (DirectoryReader.indexExists(dir)) {\n                TestUtil.checkIndex(dir);\n              }\n            } catch (VirtualMachineError | AlreadyClosedException disaster) {\n              getTragedy(disaster, iw, exceptionStream);\n              continue STARTOVER;\n            }\n          }\n        }\n        \n        try {\n          iw.close();\n        } catch (VirtualMachineError | AlreadyClosedException disaster) {\n          getTragedy(disaster, iw, exceptionStream);\n          continue STARTOVER;\n        }\n      } catch (Throwable t) {\n        System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n        exceptionStream.flush();\n        System.out.println(exceptionLog.toString(\"UTF-8\"));\n        System.out.flush();\n        Rethrow.rethrow(t);\n      }\n    }\n    dir.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1e6acbaae7af722f17204ceccf0f7db5753eccf3","date":1454775255,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnVMError#doTest(MockDirectoryWrapper.Failure).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnVMError#doTest(MockDirectoryWrapper.Failure).mjava","sourceNew":"  // just one thread, serial merge policy, hopefully debuggable\n  private void doTest(MockDirectoryWrapper.Failure failOn) throws Exception {   \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    final long analyzerSeed = random().nextLong();\n    final Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); // we are gonna make it angry\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    MockDirectoryWrapper dir = null;\n    \n    final int numIterations = TEST_NIGHTLY ? atLeast(100) : atLeast(5);\n    \n    STARTOVER:\n    for (int iter = 0; iter < numIterations; iter++) {\n      try {\n        // close from last run\n        if (dir != null) {\n          dir.close();\n        }\n        // disable slow things: we don't rely upon sleeps here.\n        dir = newMockDirectory();\n        dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n        dir.setUseSlowOpenClosers(false);\n      \n        IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n        // just for now, try to keep this test reproducible\n        conf.setMergeScheduler(new SerialMergeScheduler());\n      \n        // test never makes it this far...\n        int numDocs = atLeast(2000);\n      \n        IndexWriter iw = new IndexWriter(dir, conf);\n        iw.commit(); // ensure there is always a commit\n\n        dir.failOn(failOn);\n        \n        for (int i = 0; i < numDocs; i++) {\n          Document doc = new Document();\n          doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n          doc.add(new NumericDocValuesField(\"dv\", i));\n          doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n          doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          // ensure we store something\n          doc.add(new StoredField(\"stored1\", \"foo\"));\n          doc.add(new StoredField(\"stored1\", \"bar\"));    \n          // ensure we get some payloads\n          doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n          // ensure we get some vectors\n          FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n          ft.setStoreTermVectors(true);\n          doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          doc.add(new IntPoint(\"point\", random().nextInt()));\n          doc.add(new IntPoint(\"point2d\", random().nextInt(), random().nextInt()));\n          \n          if (random().nextInt(10) > 0) {\n            // single doc\n            try {\n              iw.addDocument(doc);\n              // we made it, sometimes delete our doc, or update a dv\n              int thingToDo = random().nextInt(4);\n              if (thingToDo == 0) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n              } else if (thingToDo == 1) {\n                iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n              } else if (thingToDo == 2) {\n                iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n              }\n            } catch (VirtualMachineError | AlreadyClosedException disaster) {\n              getTragedy(disaster, iw, exceptionStream);\n              continue STARTOVER;\n            }\n          } else {\n            // block docs\n            Document doc2 = new Document();\n            doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n            doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n            doc2.add(new StoredField(\"stored1\", \"foo\"));\n            doc2.add(new StoredField(\"stored1\", \"bar\"));\n            doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n            \n            try {\n              iw.addDocuments(Arrays.asList(doc, doc2));\n              // we made it, sometimes delete our docs\n              if (random().nextBoolean()) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n              }\n            } catch (VirtualMachineError | AlreadyClosedException disaster) {\n              getTragedy(disaster, iw, exceptionStream);\n              continue STARTOVER;\n            }\n          }\n          \n          if (random().nextInt(10) == 0) {\n            // trigger flush:\n            try {\n              if (random().nextBoolean()) {\n                DirectoryReader ir = null;\n                try {\n                  ir = DirectoryReader.open(iw, random().nextBoolean(), false);\n                  TestUtil.checkReader(ir);\n                } finally {\n                  IOUtils.closeWhileHandlingException(ir);\n                }\n              } else {\n                iw.commit();\n              }\n              if (DirectoryReader.indexExists(dir)) {\n                TestUtil.checkIndex(dir);\n              }\n            } catch (VirtualMachineError | AlreadyClosedException disaster) {\n              getTragedy(disaster, iw, exceptionStream);\n              continue STARTOVER;\n            }\n          }\n        }\n        \n        try {\n          iw.close();\n        } catch (VirtualMachineError | AlreadyClosedException disaster) {\n          getTragedy(disaster, iw, exceptionStream);\n          continue STARTOVER;\n        }\n      } catch (Throwable t) {\n        System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n        exceptionStream.flush();\n        System.out.println(exceptionLog.toString(\"UTF-8\"));\n        System.out.flush();\n        Rethrow.rethrow(t);\n      }\n    }\n    dir.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","sourceOld":"  // just one thread, serial merge policy, hopefully debuggable\n  private void doTest(MockDirectoryWrapper.Failure failOn) throws Exception {   \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    final long analyzerSeed = random().nextLong();\n    final Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); // we are gonna make it angry\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    MockDirectoryWrapper dir = null;\n    \n    final int numIterations = TEST_NIGHTLY ? atLeast(100) : atLeast(5);\n    \n    STARTOVER:\n    for (int iter = 0; iter < numIterations; iter++) {\n      try {\n        // close from last run\n        if (dir != null) {\n          dir.close();\n        }\n        // disable slow things: we don't rely upon sleeps here.\n        dir = newMockDirectory();\n        dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n        dir.setUseSlowOpenClosers(false);\n      \n        IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n        // just for now, try to keep this test reproducible\n        conf.setMergeScheduler(new SerialMergeScheduler());\n      \n        // test never makes it this far...\n        int numDocs = atLeast(2000);\n      \n        IndexWriter iw = new IndexWriter(dir, conf);\n        iw.commit(); // ensure there is always a commit\n\n        dir.failOn(failOn);\n        \n        for (int i = 0; i < numDocs; i++) {\n          Document doc = new Document();\n          doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n          doc.add(new NumericDocValuesField(\"dv\", i));\n          doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n          doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          // ensure we store something\n          doc.add(new StoredField(\"stored1\", \"foo\"));\n          doc.add(new StoredField(\"stored1\", \"bar\"));    \n          // ensure we get some payloads\n          doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n          // ensure we get some vectors\n          FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n          ft.setStoreTermVectors(true);\n          doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          if (random().nextInt(10) > 0) {\n            // single doc\n            try {\n              iw.addDocument(doc);\n              // we made it, sometimes delete our doc, or update a dv\n              int thingToDo = random().nextInt(4);\n              if (thingToDo == 0) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n              } else if (thingToDo == 1) {\n                iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n              } else if (thingToDo == 2) {\n                iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n              }\n            } catch (VirtualMachineError | AlreadyClosedException disaster) {\n              getTragedy(disaster, iw, exceptionStream);\n              continue STARTOVER;\n            }\n          } else {\n            // block docs\n            Document doc2 = new Document();\n            doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n            doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n            doc2.add(new StoredField(\"stored1\", \"foo\"));\n            doc2.add(new StoredField(\"stored1\", \"bar\"));\n            doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n            \n            try {\n              iw.addDocuments(Arrays.asList(doc, doc2));\n              // we made it, sometimes delete our docs\n              if (random().nextBoolean()) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n              }\n            } catch (VirtualMachineError | AlreadyClosedException disaster) {\n              getTragedy(disaster, iw, exceptionStream);\n              continue STARTOVER;\n            }\n          }\n          \n          if (random().nextInt(10) == 0) {\n            // trigger flush:\n            try {\n              if (random().nextBoolean()) {\n                DirectoryReader ir = null;\n                try {\n                  ir = DirectoryReader.open(iw, random().nextBoolean(), false);\n                  TestUtil.checkReader(ir);\n                } finally {\n                  IOUtils.closeWhileHandlingException(ir);\n                }\n              } else {\n                iw.commit();\n              }\n              if (DirectoryReader.indexExists(dir)) {\n                TestUtil.checkIndex(dir);\n              }\n            } catch (VirtualMachineError | AlreadyClosedException disaster) {\n              getTragedy(disaster, iw, exceptionStream);\n              continue STARTOVER;\n            }\n          }\n        }\n        \n        try {\n          iw.close();\n        } catch (VirtualMachineError | AlreadyClosedException disaster) {\n          getTragedy(disaster, iw, exceptionStream);\n          continue STARTOVER;\n        }\n      } catch (Throwable t) {\n        System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n        exceptionStream.flush();\n        System.out.println(exceptionLog.toString(\"UTF-8\"));\n        System.out.flush();\n        Rethrow.rethrow(t);\n      }\n    }\n    dir.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"68496c2200e559fb7802f7575427b7a482659afb","date":1455207618,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnVMError#doTest(MockDirectoryWrapper.Failure).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnVMError#doTest(MockDirectoryWrapper.Failure).mjava","sourceNew":"  // just one thread, serial merge policy, hopefully debuggable\n  private void doTest(MockDirectoryWrapper.Failure failOn) throws Exception {   \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    final long analyzerSeed = random().nextLong();\n    final Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); // we are gonna make it angry\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    MockDirectoryWrapper dir = null;\n    \n    final int numIterations = TEST_NIGHTLY ? atLeast(100) : atLeast(5);\n    \n    STARTOVER:\n    for (int iter = 0; iter < numIterations; iter++) {\n      try {\n        // close from last run\n        if (dir != null) {\n          dir.close();\n        }\n        // disable slow things: we don't rely upon sleeps here.\n        dir = newMockDirectory();\n        dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n        dir.setUseSlowOpenClosers(false);\n      \n        IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n        // just for now, try to keep this test reproducible\n        conf.setMergeScheduler(new SerialMergeScheduler());\n      \n        // test never makes it this far...\n        int numDocs = atLeast(2000);\n      \n        IndexWriter iw = new IndexWriter(dir, conf);\n        iw.commit(); // ensure there is always a commit\n\n        dir.failOn(failOn);\n        \n        for (int i = 0; i < numDocs; i++) {\n          Document doc = new Document();\n          doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n          doc.add(new NumericDocValuesField(\"dv\", i));\n          doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n          doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          // ensure we store something\n          doc.add(new StoredField(\"stored1\", \"foo\"));\n          doc.add(new StoredField(\"stored1\", \"bar\"));    \n          // ensure we get some payloads\n          doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n          // ensure we get some vectors\n          FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n          ft.setStoreTermVectors(true);\n          doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          doc.add(new IntPoint(\"point\", random().nextInt()));\n          doc.add(new IntPoint(\"point2d\", random().nextInt(), random().nextInt()));\n          \n          if (random().nextInt(10) > 0) {\n            // single doc\n            try {\n              iw.addDocument(doc);\n              // we made it, sometimes delete our doc, or update a dv\n              int thingToDo = random().nextInt(4);\n              if (thingToDo == 0) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n              } else if (thingToDo == 1) {\n                iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n              } else if (thingToDo == 2) {\n                iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n              }\n            } catch (VirtualMachineError | AlreadyClosedException disaster) {\n              getTragedy(disaster, iw, exceptionStream);\n              continue STARTOVER;\n            }\n          } else {\n            // block docs\n            Document doc2 = new Document();\n            doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n            doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n            doc2.add(new StoredField(\"stored1\", \"foo\"));\n            doc2.add(new StoredField(\"stored1\", \"bar\"));\n            doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n            \n            try {\n              iw.addDocuments(Arrays.asList(doc, doc2));\n              // we made it, sometimes delete our docs\n              if (random().nextBoolean()) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n              }\n            } catch (VirtualMachineError | AlreadyClosedException disaster) {\n              getTragedy(disaster, iw, exceptionStream);\n              continue STARTOVER;\n            }\n          }\n          \n          if (random().nextInt(10) == 0) {\n            // trigger flush:\n            try {\n              if (random().nextBoolean()) {\n                DirectoryReader ir = null;\n                try {\n                  ir = DirectoryReader.open(iw, random().nextBoolean(), false);\n                  TestUtil.checkReader(ir);\n                } finally {\n                  IOUtils.closeWhileHandlingException(ir);\n                }\n              } else {\n                iw.commit();\n              }\n              if (DirectoryReader.indexExists(dir)) {\n                TestUtil.checkIndex(dir);\n              }\n            } catch (VirtualMachineError | AlreadyClosedException disaster) {\n              getTragedy(disaster, iw, exceptionStream);\n              continue STARTOVER;\n            }\n          }\n        }\n        \n        try {\n          iw.close();\n        } catch (VirtualMachineError | AlreadyClosedException disaster) {\n          getTragedy(disaster, iw, exceptionStream);\n          continue STARTOVER;\n        }\n      } catch (Throwable t) {\n        System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n        exceptionStream.flush();\n        System.out.println(exceptionLog.toString(\"UTF-8\"));\n        System.out.flush();\n        Rethrow.rethrow(t);\n      }\n    }\n    dir.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","sourceOld":"  // just one thread, serial merge policy, hopefully debuggable\n  private void doTest(MockDirectoryWrapper.Failure failOn) throws Exception {   \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    final long analyzerSeed = random().nextLong();\n    final Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); // we are gonna make it angry\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    MockDirectoryWrapper dir = null;\n    \n    final int numIterations = TEST_NIGHTLY ? atLeast(100) : atLeast(5);\n    \n    STARTOVER:\n    for (int iter = 0; iter < numIterations; iter++) {\n      try {\n        // close from last run\n        if (dir != null) {\n          dir.close();\n        }\n        // disable slow things: we don't rely upon sleeps here.\n        dir = newMockDirectory();\n        dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n        dir.setUseSlowOpenClosers(false);\n      \n        IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n        // just for now, try to keep this test reproducible\n        conf.setMergeScheduler(new SerialMergeScheduler());\n      \n        // test never makes it this far...\n        int numDocs = atLeast(2000);\n      \n        IndexWriter iw = new IndexWriter(dir, conf);\n        iw.commit(); // ensure there is always a commit\n\n        dir.failOn(failOn);\n        \n        for (int i = 0; i < numDocs; i++) {\n          Document doc = new Document();\n          doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n          doc.add(new NumericDocValuesField(\"dv\", i));\n          doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n          doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          // ensure we store something\n          doc.add(new StoredField(\"stored1\", \"foo\"));\n          doc.add(new StoredField(\"stored1\", \"bar\"));    \n          // ensure we get some payloads\n          doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n          // ensure we get some vectors\n          FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n          ft.setStoreTermVectors(true);\n          doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          doc.add(new IntPoint(\"point\", random().nextInt()));\n          doc.add(new IntPoint(\"point2d\", random().nextInt(), random().nextInt()));\n          \n          if (random().nextInt(10) > 0) {\n            // single doc\n            try {\n              iw.addDocument(doc);\n              // we made it, sometimes delete our doc, or update a dv\n              int thingToDo = random().nextInt(4);\n              if (thingToDo == 0) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n              } else if (thingToDo == 1) {\n                iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n              } else if (thingToDo == 2) {\n                iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n              }\n            } catch (VirtualMachineError | AlreadyClosedException disaster) {\n              getTragedy(disaster, iw, exceptionStream);\n              continue STARTOVER;\n            }\n          } else {\n            // block docs\n            Document doc2 = new Document();\n            doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n            doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n            doc2.add(new StoredField(\"stored1\", \"foo\"));\n            doc2.add(new StoredField(\"stored1\", \"bar\"));\n            doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n            \n            try {\n              iw.addDocuments(Arrays.asList(doc, doc2));\n              // we made it, sometimes delete our docs\n              if (random().nextBoolean()) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n              }\n            } catch (VirtualMachineError | AlreadyClosedException disaster) {\n              getTragedy(disaster, iw, exceptionStream);\n              continue STARTOVER;\n            }\n          }\n          \n          if (random().nextInt(10) == 0) {\n            // trigger flush:\n            try {\n              if (random().nextBoolean()) {\n                DirectoryReader ir = null;\n                try {\n                  ir = DirectoryReader.open(iw, random().nextBoolean());\n                  TestUtil.checkReader(ir);\n                } finally {\n                  IOUtils.closeWhileHandlingException(ir);\n                }\n              } else {\n                iw.commit();\n              }\n              if (DirectoryReader.indexExists(dir)) {\n                TestUtil.checkIndex(dir);\n              }\n            } catch (VirtualMachineError | AlreadyClosedException disaster) {\n              getTragedy(disaster, iw, exceptionStream);\n              continue STARTOVER;\n            }\n          }\n        }\n        \n        try {\n          iw.close();\n        } catch (VirtualMachineError | AlreadyClosedException disaster) {\n          getTragedy(disaster, iw, exceptionStream);\n          continue STARTOVER;\n        }\n      } catch (Throwable t) {\n        System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n        exceptionStream.flush();\n        System.out.println(exceptionLog.toString(\"UTF-8\"));\n        System.out.flush();\n        Rethrow.rethrow(t);\n      }\n    }\n    dir.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"8de18786ea000fc5fbc7214d571cc7f41d597ee3":["85ca0e073c286ebb2c89364ada6dd2740fc18880"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"1e6acbaae7af722f17204ceccf0f7db5753eccf3":["0d49a158012a8ff48f328a4558e4bfcffbaed16f","8d15e34266d75e4e8b95da046cd0afc812367b38"],"68496c2200e559fb7802f7575427b7a482659afb":["8d15e34266d75e4e8b95da046cd0afc812367b38","1e6acbaae7af722f17204ceccf0f7db5753eccf3"],"85ca0e073c286ebb2c89364ada6dd2740fc18880":["c48871ed951104729f5e17a8ee1091b43fa18980"],"8d15e34266d75e4e8b95da046cd0afc812367b38":["c48871ed951104729f5e17a8ee1091b43fa18980","8de18786ea000fc5fbc7214d571cc7f41d597ee3"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["68496c2200e559fb7802f7575427b7a482659afb"],"c48871ed951104729f5e17a8ee1091b43fa18980":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"0d49a158012a8ff48f328a4558e4bfcffbaed16f":["c48871ed951104729f5e17a8ee1091b43fa18980"]},"commit2Childs":{"8de18786ea000fc5fbc7214d571cc7f41d597ee3":["8d15e34266d75e4e8b95da046cd0afc812367b38"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c48871ed951104729f5e17a8ee1091b43fa18980"],"1e6acbaae7af722f17204ceccf0f7db5753eccf3":["68496c2200e559fb7802f7575427b7a482659afb"],"68496c2200e559fb7802f7575427b7a482659afb":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"85ca0e073c286ebb2c89364ada6dd2740fc18880":["8de18786ea000fc5fbc7214d571cc7f41d597ee3"],"8d15e34266d75e4e8b95da046cd0afc812367b38":["1e6acbaae7af722f17204ceccf0f7db5753eccf3","68496c2200e559fb7802f7575427b7a482659afb"],"0d49a158012a8ff48f328a4558e4bfcffbaed16f":["1e6acbaae7af722f17204ceccf0f7db5753eccf3"],"c48871ed951104729f5e17a8ee1091b43fa18980":["85ca0e073c286ebb2c89364ada6dd2740fc18880","8d15e34266d75e4e8b95da046cd0afc812367b38","0d49a158012a8ff48f328a4558e4bfcffbaed16f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}