{"path":"lucene/src/test-framework/java/org/apache/lucene/search/ShardSearchingTestBase.NodeState.ShardIndexSearcher#collectionStatistics(String).mjava","commits":[{"id":"226aae72c0326f4299c16280195bade4530de537","date":1324221898,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test-framework/java/org/apache/lucene/search/ShardSearchingTestBase.NodeState.ShardIndexSearcher#collectionStatistics(String).mjava","pathOld":"/dev/null","sourceNew":"      @Override\n      public CollectionStatistics collectionStatistics(String field) throws IOException {\n        // TODO: we could compute this on init and cache,\n        // since we are re-inited whenever any nodes have a\n        // new reader\n        int docCount = 0;\n        long sumTotalTermFreq = 0;\n        long sumDocFreq = 0;\n        int maxDoc = 0;\n\n        for(int nodeID=0;nodeID<nodeVersions.length;nodeID++) {\n          final FieldAndShardVersion key = new FieldAndShardVersion(nodeID, nodeVersions[nodeID], field);\n          final CollectionStatistics nodeStats;\n          if (nodeID == myNodeID) {\n            nodeStats = super.collectionStatistics(field);\n          } else {\n            nodeStats = collectionStatsCache.get(key);\n          }\n          if (nodeStats == null) {\n            System.out.println(\"coll stats myNodeID=\" + myNodeID + \": \" + collectionStatsCache.keySet());\n          }\n          // Collection stats are pre-shared on reopen, so,\n          // we better not have a cache miss:\n          assert nodeStats != null: \"myNodeID=\" + myNodeID + \" nodeID=\" + nodeID + \" version=\" + nodeVersions[nodeID] + \" field=\" + field;\n          docCount += nodeStats.docCount();\n          sumTotalTermFreq += nodeStats.sumTotalTermFreq();\n          sumDocFreq += nodeStats.sumDocFreq();\n          maxDoc += nodeStats.maxDoc();\n        }\n\n        return new CollectionStatistics(field, maxDoc, docCount, sumTotalTermFreq, sumDocFreq);\n      }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["c3119ed4143b91eaf5ac74a4dc4625f5036d472c"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e461dc186cc6b97e0a85c6f5acb27c190eb3f335","date":1327502597,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test-framework/java/org/apache/lucene/search/ShardSearchingTestBase.NodeState.ShardIndexSearcher#collectionStatistics(String).mjava","pathOld":"lucene/src/test-framework/java/org/apache/lucene/search/ShardSearchingTestBase.NodeState.ShardIndexSearcher#collectionStatistics(String).mjava","sourceNew":"      @Override\n      public CollectionStatistics collectionStatistics(String field) throws IOException {\n        // TODO: we could compute this on init and cache,\n        // since we are re-inited whenever any nodes have a\n        // new reader\n        int docCount = 0;\n        long sumTotalTermFreq = 0;\n        long sumDocFreq = 0;\n        int maxDoc = 0;\n\n        for(int nodeID=0;nodeID<nodeVersions.length;nodeID++) {\n          final FieldAndShardVersion key = new FieldAndShardVersion(nodeID, nodeVersions[nodeID], field);\n          final CollectionStatistics nodeStats;\n          if (nodeID == myNodeID) {\n            nodeStats = super.collectionStatistics(field);\n          } else {\n            nodeStats = collectionStatsCache.get(key);\n          }\n          if (nodeStats == null) {\n            System.out.println(\"coll stats myNodeID=\" + myNodeID + \": \" + collectionStatsCache.keySet());\n          }\n          // Collection stats are pre-shared on reopen, so,\n          // we better not have a cache miss:\n          assert nodeStats != null: \"myNodeID=\" + myNodeID + \" nodeID=\" + nodeID + \" version=\" + nodeVersions[nodeID] + \" field=\" + field;\n          \n          int nodeDocCount = nodeStats.docCount();\n          if (docCount >= 0 && nodeDocCount >= 0) {\n            docCount += nodeDocCount;\n          } else {\n            docCount = -1;\n          }\n          \n          long nodeSumTotalTermFreq = nodeStats.sumTotalTermFreq();\n          if (sumTotalTermFreq >= 0 && nodeSumTotalTermFreq >= 0) {\n            sumTotalTermFreq += nodeSumTotalTermFreq;\n          } else {\n            sumTotalTermFreq = -1;\n          }\n          \n          long nodeSumDocFreq = nodeStats.sumDocFreq();\n          if (sumDocFreq >= 0 && nodeSumDocFreq >= 0) {\n            sumDocFreq += nodeSumDocFreq;\n          } else {\n            sumDocFreq = -1;\n          }\n          \n          assert nodeStats.maxDoc() >= 0;\n          maxDoc += nodeStats.maxDoc();\n        }\n\n        return new CollectionStatistics(field, maxDoc, docCount, sumTotalTermFreq, sumDocFreq);\n      }\n\n","sourceOld":"      @Override\n      public CollectionStatistics collectionStatistics(String field) throws IOException {\n        // TODO: we could compute this on init and cache,\n        // since we are re-inited whenever any nodes have a\n        // new reader\n        int docCount = 0;\n        long sumTotalTermFreq = 0;\n        long sumDocFreq = 0;\n        int maxDoc = 0;\n\n        for(int nodeID=0;nodeID<nodeVersions.length;nodeID++) {\n          final FieldAndShardVersion key = new FieldAndShardVersion(nodeID, nodeVersions[nodeID], field);\n          final CollectionStatistics nodeStats;\n          if (nodeID == myNodeID) {\n            nodeStats = super.collectionStatistics(field);\n          } else {\n            nodeStats = collectionStatsCache.get(key);\n          }\n          if (nodeStats == null) {\n            System.out.println(\"coll stats myNodeID=\" + myNodeID + \": \" + collectionStatsCache.keySet());\n          }\n          // Collection stats are pre-shared on reopen, so,\n          // we better not have a cache miss:\n          assert nodeStats != null: \"myNodeID=\" + myNodeID + \" nodeID=\" + nodeID + \" version=\" + nodeVersions[nodeID] + \" field=\" + field;\n          docCount += nodeStats.docCount();\n          sumTotalTermFreq += nodeStats.sumTotalTermFreq();\n          sumDocFreq += nodeStats.sumDocFreq();\n          maxDoc += nodeStats.maxDoc();\n        }\n\n        return new CollectionStatistics(field, maxDoc, docCount, sumTotalTermFreq, sumDocFreq);\n      }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d","date":1327523564,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/test-framework/java/org/apache/lucene/search/ShardSearchingTestBase.NodeState.ShardIndexSearcher#collectionStatistics(String).mjava","pathOld":"lucene/src/test-framework/java/org/apache/lucene/search/ShardSearchingTestBase.NodeState.ShardIndexSearcher#collectionStatistics(String).mjava","sourceNew":"      @Override\n      public CollectionStatistics collectionStatistics(String field) throws IOException {\n        // TODO: we could compute this on init and cache,\n        // since we are re-inited whenever any nodes have a\n        // new reader\n        int docCount = 0;\n        long sumTotalTermFreq = 0;\n        long sumDocFreq = 0;\n        int maxDoc = 0;\n\n        for(int nodeID=0;nodeID<nodeVersions.length;nodeID++) {\n          final FieldAndShardVersion key = new FieldAndShardVersion(nodeID, nodeVersions[nodeID], field);\n          final CollectionStatistics nodeStats;\n          if (nodeID == myNodeID) {\n            nodeStats = super.collectionStatistics(field);\n          } else {\n            nodeStats = collectionStatsCache.get(key);\n          }\n          if (nodeStats == null) {\n            System.out.println(\"coll stats myNodeID=\" + myNodeID + \": \" + collectionStatsCache.keySet());\n          }\n          // Collection stats are pre-shared on reopen, so,\n          // we better not have a cache miss:\n          assert nodeStats != null: \"myNodeID=\" + myNodeID + \" nodeID=\" + nodeID + \" version=\" + nodeVersions[nodeID] + \" field=\" + field;\n          \n          int nodeDocCount = nodeStats.docCount();\n          if (docCount >= 0 && nodeDocCount >= 0) {\n            docCount += nodeDocCount;\n          } else {\n            docCount = -1;\n          }\n          \n          long nodeSumTotalTermFreq = nodeStats.sumTotalTermFreq();\n          if (sumTotalTermFreq >= 0 && nodeSumTotalTermFreq >= 0) {\n            sumTotalTermFreq += nodeSumTotalTermFreq;\n          } else {\n            sumTotalTermFreq = -1;\n          }\n          \n          long nodeSumDocFreq = nodeStats.sumDocFreq();\n          if (sumDocFreq >= 0 && nodeSumDocFreq >= 0) {\n            sumDocFreq += nodeSumDocFreq;\n          } else {\n            sumDocFreq = -1;\n          }\n          \n          assert nodeStats.maxDoc() >= 0;\n          maxDoc += nodeStats.maxDoc();\n        }\n\n        return new CollectionStatistics(field, maxDoc, docCount, sumTotalTermFreq, sumDocFreq);\n      }\n\n","sourceOld":"      @Override\n      public CollectionStatistics collectionStatistics(String field) throws IOException {\n        // TODO: we could compute this on init and cache,\n        // since we are re-inited whenever any nodes have a\n        // new reader\n        int docCount = 0;\n        long sumTotalTermFreq = 0;\n        long sumDocFreq = 0;\n        int maxDoc = 0;\n\n        for(int nodeID=0;nodeID<nodeVersions.length;nodeID++) {\n          final FieldAndShardVersion key = new FieldAndShardVersion(nodeID, nodeVersions[nodeID], field);\n          final CollectionStatistics nodeStats;\n          if (nodeID == myNodeID) {\n            nodeStats = super.collectionStatistics(field);\n          } else {\n            nodeStats = collectionStatsCache.get(key);\n          }\n          if (nodeStats == null) {\n            System.out.println(\"coll stats myNodeID=\" + myNodeID + \": \" + collectionStatsCache.keySet());\n          }\n          // Collection stats are pre-shared on reopen, so,\n          // we better not have a cache miss:\n          assert nodeStats != null: \"myNodeID=\" + myNodeID + \" nodeID=\" + nodeID + \" version=\" + nodeVersions[nodeID] + \" field=\" + field;\n          docCount += nodeStats.docCount();\n          sumTotalTermFreq += nodeStats.sumTotalTermFreq();\n          sumDocFreq += nodeStats.sumDocFreq();\n          maxDoc += nodeStats.maxDoc();\n        }\n\n        return new CollectionStatistics(field, maxDoc, docCount, sumTotalTermFreq, sumDocFreq);\n      }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0d22ac6a4146774c1bc8400160fc0b6150294e92","date":1327528604,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/test-framework/java/org/apache/lucene/search/ShardSearchingTestBase.NodeState.ShardIndexSearcher#collectionStatistics(String).mjava","pathOld":"lucene/src/test-framework/java/org/apache/lucene/search/ShardSearchingTestBase.NodeState.ShardIndexSearcher#collectionStatistics(String).mjava","sourceNew":"      @Override\n      public CollectionStatistics collectionStatistics(String field) throws IOException {\n        // TODO: we could compute this on init and cache,\n        // since we are re-inited whenever any nodes have a\n        // new reader\n        int docCount = 0;\n        long sumTotalTermFreq = 0;\n        long sumDocFreq = 0;\n        int maxDoc = 0;\n\n        for(int nodeID=0;nodeID<nodeVersions.length;nodeID++) {\n          final FieldAndShardVersion key = new FieldAndShardVersion(nodeID, nodeVersions[nodeID], field);\n          final CollectionStatistics nodeStats;\n          if (nodeID == myNodeID) {\n            nodeStats = super.collectionStatistics(field);\n          } else {\n            nodeStats = collectionStatsCache.get(key);\n          }\n          if (nodeStats == null) {\n            System.out.println(\"coll stats myNodeID=\" + myNodeID + \": \" + collectionStatsCache.keySet());\n          }\n          // Collection stats are pre-shared on reopen, so,\n          // we better not have a cache miss:\n          assert nodeStats != null: \"myNodeID=\" + myNodeID + \" nodeID=\" + nodeID + \" version=\" + nodeVersions[nodeID] + \" field=\" + field;\n          \n          int nodeDocCount = nodeStats.docCount();\n          if (docCount >= 0 && nodeDocCount >= 0) {\n            docCount += nodeDocCount;\n          } else {\n            docCount = -1;\n          }\n          \n          long nodeSumTotalTermFreq = nodeStats.sumTotalTermFreq();\n          if (sumTotalTermFreq >= 0 && nodeSumTotalTermFreq >= 0) {\n            sumTotalTermFreq += nodeSumTotalTermFreq;\n          } else {\n            sumTotalTermFreq = -1;\n          }\n          \n          long nodeSumDocFreq = nodeStats.sumDocFreq();\n          if (sumDocFreq >= 0 && nodeSumDocFreq >= 0) {\n            sumDocFreq += nodeSumDocFreq;\n          } else {\n            sumDocFreq = -1;\n          }\n          \n          assert nodeStats.maxDoc() >= 0;\n          maxDoc += nodeStats.maxDoc();\n        }\n\n        return new CollectionStatistics(field, maxDoc, docCount, sumTotalTermFreq, sumDocFreq);\n      }\n\n","sourceOld":"      @Override\n      public CollectionStatistics collectionStatistics(String field) throws IOException {\n        // TODO: we could compute this on init and cache,\n        // since we are re-inited whenever any nodes have a\n        // new reader\n        int docCount = 0;\n        long sumTotalTermFreq = 0;\n        long sumDocFreq = 0;\n        int maxDoc = 0;\n\n        for(int nodeID=0;nodeID<nodeVersions.length;nodeID++) {\n          final FieldAndShardVersion key = new FieldAndShardVersion(nodeID, nodeVersions[nodeID], field);\n          final CollectionStatistics nodeStats;\n          if (nodeID == myNodeID) {\n            nodeStats = super.collectionStatistics(field);\n          } else {\n            nodeStats = collectionStatsCache.get(key);\n          }\n          if (nodeStats == null) {\n            System.out.println(\"coll stats myNodeID=\" + myNodeID + \": \" + collectionStatsCache.keySet());\n          }\n          // Collection stats are pre-shared on reopen, so,\n          // we better not have a cache miss:\n          assert nodeStats != null: \"myNodeID=\" + myNodeID + \" nodeID=\" + nodeID + \" version=\" + nodeVersions[nodeID] + \" field=\" + field;\n          docCount += nodeStats.docCount();\n          sumTotalTermFreq += nodeStats.sumTotalTermFreq();\n          sumDocFreq += nodeStats.sumDocFreq();\n          maxDoc += nodeStats.maxDoc();\n        }\n\n        return new CollectionStatistics(field, maxDoc, docCount, sumTotalTermFreq, sumDocFreq);\n      }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"64aaeb7d6606aeec15dd381453d66caedda7888b","date":1327669445,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test-framework/java/org/apache/lucene/search/ShardSearchingTestBase.NodeState.ShardIndexSearcher#collectionStatistics(String).mjava","pathOld":"lucene/src/test-framework/java/org/apache/lucene/search/ShardSearchingTestBase.NodeState.ShardIndexSearcher#collectionStatistics(String).mjava","sourceNew":"      @Override\n      public CollectionStatistics collectionStatistics(String field) throws IOException {\n        // TODO: we could compute this on init and cache,\n        // since we are re-inited whenever any nodes have a\n        // new reader\n        long docCount = 0;\n        long sumTotalTermFreq = 0;\n        long sumDocFreq = 0;\n        long maxDoc = 0;\n\n        for(int nodeID=0;nodeID<nodeVersions.length;nodeID++) {\n          final FieldAndShardVersion key = new FieldAndShardVersion(nodeID, nodeVersions[nodeID], field);\n          final CollectionStatistics nodeStats;\n          if (nodeID == myNodeID) {\n            nodeStats = super.collectionStatistics(field);\n          } else {\n            nodeStats = collectionStatsCache.get(key);\n          }\n          if (nodeStats == null) {\n            System.out.println(\"coll stats myNodeID=\" + myNodeID + \": \" + collectionStatsCache.keySet());\n          }\n          // Collection stats are pre-shared on reopen, so,\n          // we better not have a cache miss:\n          assert nodeStats != null: \"myNodeID=\" + myNodeID + \" nodeID=\" + nodeID + \" version=\" + nodeVersions[nodeID] + \" field=\" + field;\n          \n          long nodeDocCount = nodeStats.docCount();\n          if (docCount >= 0 && nodeDocCount >= 0) {\n            docCount += nodeDocCount;\n          } else {\n            docCount = -1;\n          }\n          \n          long nodeSumTotalTermFreq = nodeStats.sumTotalTermFreq();\n          if (sumTotalTermFreq >= 0 && nodeSumTotalTermFreq >= 0) {\n            sumTotalTermFreq += nodeSumTotalTermFreq;\n          } else {\n            sumTotalTermFreq = -1;\n          }\n          \n          long nodeSumDocFreq = nodeStats.sumDocFreq();\n          if (sumDocFreq >= 0 && nodeSumDocFreq >= 0) {\n            sumDocFreq += nodeSumDocFreq;\n          } else {\n            sumDocFreq = -1;\n          }\n          \n          assert nodeStats.maxDoc() >= 0;\n          maxDoc += nodeStats.maxDoc();\n        }\n\n        return new CollectionStatistics(field, maxDoc, docCount, sumTotalTermFreq, sumDocFreq);\n      }\n\n","sourceOld":"      @Override\n      public CollectionStatistics collectionStatistics(String field) throws IOException {\n        // TODO: we could compute this on init and cache,\n        // since we are re-inited whenever any nodes have a\n        // new reader\n        int docCount = 0;\n        long sumTotalTermFreq = 0;\n        long sumDocFreq = 0;\n        int maxDoc = 0;\n\n        for(int nodeID=0;nodeID<nodeVersions.length;nodeID++) {\n          final FieldAndShardVersion key = new FieldAndShardVersion(nodeID, nodeVersions[nodeID], field);\n          final CollectionStatistics nodeStats;\n          if (nodeID == myNodeID) {\n            nodeStats = super.collectionStatistics(field);\n          } else {\n            nodeStats = collectionStatsCache.get(key);\n          }\n          if (nodeStats == null) {\n            System.out.println(\"coll stats myNodeID=\" + myNodeID + \": \" + collectionStatsCache.keySet());\n          }\n          // Collection stats are pre-shared on reopen, so,\n          // we better not have a cache miss:\n          assert nodeStats != null: \"myNodeID=\" + myNodeID + \" nodeID=\" + nodeID + \" version=\" + nodeVersions[nodeID] + \" field=\" + field;\n          \n          int nodeDocCount = nodeStats.docCount();\n          if (docCount >= 0 && nodeDocCount >= 0) {\n            docCount += nodeDocCount;\n          } else {\n            docCount = -1;\n          }\n          \n          long nodeSumTotalTermFreq = nodeStats.sumTotalTermFreq();\n          if (sumTotalTermFreq >= 0 && nodeSumTotalTermFreq >= 0) {\n            sumTotalTermFreq += nodeSumTotalTermFreq;\n          } else {\n            sumTotalTermFreq = -1;\n          }\n          \n          long nodeSumDocFreq = nodeStats.sumDocFreq();\n          if (sumDocFreq >= 0 && nodeSumDocFreq >= 0) {\n            sumDocFreq += nodeSumDocFreq;\n          } else {\n            sumDocFreq = -1;\n          }\n          \n          assert nodeStats.maxDoc() >= 0;\n          maxDoc += nodeStats.maxDoc();\n        }\n\n        return new CollectionStatistics(field, maxDoc, docCount, sumTotalTermFreq, sumDocFreq);\n      }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"78a55f24d9b493c2a1cecf79f1d78279062b545b","date":1327688152,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/test-framework/java/org/apache/lucene/search/ShardSearchingTestBase.NodeState.ShardIndexSearcher#collectionStatistics(String).mjava","pathOld":"lucene/src/test-framework/java/org/apache/lucene/search/ShardSearchingTestBase.NodeState.ShardIndexSearcher#collectionStatistics(String).mjava","sourceNew":"      @Override\n      public CollectionStatistics collectionStatistics(String field) throws IOException {\n        // TODO: we could compute this on init and cache,\n        // since we are re-inited whenever any nodes have a\n        // new reader\n        long docCount = 0;\n        long sumTotalTermFreq = 0;\n        long sumDocFreq = 0;\n        long maxDoc = 0;\n\n        for(int nodeID=0;nodeID<nodeVersions.length;nodeID++) {\n          final FieldAndShardVersion key = new FieldAndShardVersion(nodeID, nodeVersions[nodeID], field);\n          final CollectionStatistics nodeStats;\n          if (nodeID == myNodeID) {\n            nodeStats = super.collectionStatistics(field);\n          } else {\n            nodeStats = collectionStatsCache.get(key);\n          }\n          if (nodeStats == null) {\n            System.out.println(\"coll stats myNodeID=\" + myNodeID + \": \" + collectionStatsCache.keySet());\n          }\n          // Collection stats are pre-shared on reopen, so,\n          // we better not have a cache miss:\n          assert nodeStats != null: \"myNodeID=\" + myNodeID + \" nodeID=\" + nodeID + \" version=\" + nodeVersions[nodeID] + \" field=\" + field;\n          \n          long nodeDocCount = nodeStats.docCount();\n          if (docCount >= 0 && nodeDocCount >= 0) {\n            docCount += nodeDocCount;\n          } else {\n            docCount = -1;\n          }\n          \n          long nodeSumTotalTermFreq = nodeStats.sumTotalTermFreq();\n          if (sumTotalTermFreq >= 0 && nodeSumTotalTermFreq >= 0) {\n            sumTotalTermFreq += nodeSumTotalTermFreq;\n          } else {\n            sumTotalTermFreq = -1;\n          }\n          \n          long nodeSumDocFreq = nodeStats.sumDocFreq();\n          if (sumDocFreq >= 0 && nodeSumDocFreq >= 0) {\n            sumDocFreq += nodeSumDocFreq;\n          } else {\n            sumDocFreq = -1;\n          }\n          \n          assert nodeStats.maxDoc() >= 0;\n          maxDoc += nodeStats.maxDoc();\n        }\n\n        return new CollectionStatistics(field, maxDoc, docCount, sumTotalTermFreq, sumDocFreq);\n      }\n\n","sourceOld":"      @Override\n      public CollectionStatistics collectionStatistics(String field) throws IOException {\n        // TODO: we could compute this on init and cache,\n        // since we are re-inited whenever any nodes have a\n        // new reader\n        int docCount = 0;\n        long sumTotalTermFreq = 0;\n        long sumDocFreq = 0;\n        int maxDoc = 0;\n\n        for(int nodeID=0;nodeID<nodeVersions.length;nodeID++) {\n          final FieldAndShardVersion key = new FieldAndShardVersion(nodeID, nodeVersions[nodeID], field);\n          final CollectionStatistics nodeStats;\n          if (nodeID == myNodeID) {\n            nodeStats = super.collectionStatistics(field);\n          } else {\n            nodeStats = collectionStatsCache.get(key);\n          }\n          if (nodeStats == null) {\n            System.out.println(\"coll stats myNodeID=\" + myNodeID + \": \" + collectionStatsCache.keySet());\n          }\n          // Collection stats are pre-shared on reopen, so,\n          // we better not have a cache miss:\n          assert nodeStats != null: \"myNodeID=\" + myNodeID + \" nodeID=\" + nodeID + \" version=\" + nodeVersions[nodeID] + \" field=\" + field;\n          \n          int nodeDocCount = nodeStats.docCount();\n          if (docCount >= 0 && nodeDocCount >= 0) {\n            docCount += nodeDocCount;\n          } else {\n            docCount = -1;\n          }\n          \n          long nodeSumTotalTermFreq = nodeStats.sumTotalTermFreq();\n          if (sumTotalTermFreq >= 0 && nodeSumTotalTermFreq >= 0) {\n            sumTotalTermFreq += nodeSumTotalTermFreq;\n          } else {\n            sumTotalTermFreq = -1;\n          }\n          \n          long nodeSumDocFreq = nodeStats.sumDocFreq();\n          if (sumDocFreq >= 0 && nodeSumDocFreq >= 0) {\n            sumDocFreq += nodeSumDocFreq;\n          } else {\n            sumDocFreq = -1;\n          }\n          \n          assert nodeStats.maxDoc() >= 0;\n          maxDoc += nodeStats.maxDoc();\n        }\n\n        return new CollectionStatistics(field, maxDoc, docCount, sumTotalTermFreq, sumDocFreq);\n      }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fd92b8bcc88e969302510acf77bd6970da3994c4","date":1327839530,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/test-framework/java/org/apache/lucene/search/ShardSearchingTestBase.NodeState.ShardIndexSearcher#collectionStatistics(String).mjava","pathOld":"lucene/src/test-framework/java/org/apache/lucene/search/ShardSearchingTestBase.NodeState.ShardIndexSearcher#collectionStatistics(String).mjava","sourceNew":"      @Override\n      public CollectionStatistics collectionStatistics(String field) throws IOException {\n        // TODO: we could compute this on init and cache,\n        // since we are re-inited whenever any nodes have a\n        // new reader\n        long docCount = 0;\n        long sumTotalTermFreq = 0;\n        long sumDocFreq = 0;\n        long maxDoc = 0;\n\n        for(int nodeID=0;nodeID<nodeVersions.length;nodeID++) {\n          final FieldAndShardVersion key = new FieldAndShardVersion(nodeID, nodeVersions[nodeID], field);\n          final CollectionStatistics nodeStats;\n          if (nodeID == myNodeID) {\n            nodeStats = super.collectionStatistics(field);\n          } else {\n            nodeStats = collectionStatsCache.get(key);\n          }\n          if (nodeStats == null) {\n            System.out.println(\"coll stats myNodeID=\" + myNodeID + \": \" + collectionStatsCache.keySet());\n          }\n          // Collection stats are pre-shared on reopen, so,\n          // we better not have a cache miss:\n          assert nodeStats != null: \"myNodeID=\" + myNodeID + \" nodeID=\" + nodeID + \" version=\" + nodeVersions[nodeID] + \" field=\" + field;\n          \n          long nodeDocCount = nodeStats.docCount();\n          if (docCount >= 0 && nodeDocCount >= 0) {\n            docCount += nodeDocCount;\n          } else {\n            docCount = -1;\n          }\n          \n          long nodeSumTotalTermFreq = nodeStats.sumTotalTermFreq();\n          if (sumTotalTermFreq >= 0 && nodeSumTotalTermFreq >= 0) {\n            sumTotalTermFreq += nodeSumTotalTermFreq;\n          } else {\n            sumTotalTermFreq = -1;\n          }\n          \n          long nodeSumDocFreq = nodeStats.sumDocFreq();\n          if (sumDocFreq >= 0 && nodeSumDocFreq >= 0) {\n            sumDocFreq += nodeSumDocFreq;\n          } else {\n            sumDocFreq = -1;\n          }\n          \n          assert nodeStats.maxDoc() >= 0;\n          maxDoc += nodeStats.maxDoc();\n        }\n\n        return new CollectionStatistics(field, maxDoc, docCount, sumTotalTermFreq, sumDocFreq);\n      }\n\n","sourceOld":"      @Override\n      public CollectionStatistics collectionStatistics(String field) throws IOException {\n        // TODO: we could compute this on init and cache,\n        // since we are re-inited whenever any nodes have a\n        // new reader\n        int docCount = 0;\n        long sumTotalTermFreq = 0;\n        long sumDocFreq = 0;\n        int maxDoc = 0;\n\n        for(int nodeID=0;nodeID<nodeVersions.length;nodeID++) {\n          final FieldAndShardVersion key = new FieldAndShardVersion(nodeID, nodeVersions[nodeID], field);\n          final CollectionStatistics nodeStats;\n          if (nodeID == myNodeID) {\n            nodeStats = super.collectionStatistics(field);\n          } else {\n            nodeStats = collectionStatsCache.get(key);\n          }\n          if (nodeStats == null) {\n            System.out.println(\"coll stats myNodeID=\" + myNodeID + \": \" + collectionStatsCache.keySet());\n          }\n          // Collection stats are pre-shared on reopen, so,\n          // we better not have a cache miss:\n          assert nodeStats != null: \"myNodeID=\" + myNodeID + \" nodeID=\" + nodeID + \" version=\" + nodeVersions[nodeID] + \" field=\" + field;\n          \n          int nodeDocCount = nodeStats.docCount();\n          if (docCount >= 0 && nodeDocCount >= 0) {\n            docCount += nodeDocCount;\n          } else {\n            docCount = -1;\n          }\n          \n          long nodeSumTotalTermFreq = nodeStats.sumTotalTermFreq();\n          if (sumTotalTermFreq >= 0 && nodeSumTotalTermFreq >= 0) {\n            sumTotalTermFreq += nodeSumTotalTermFreq;\n          } else {\n            sumTotalTermFreq = -1;\n          }\n          \n          long nodeSumDocFreq = nodeStats.sumDocFreq();\n          if (sumDocFreq >= 0 && nodeSumDocFreq >= 0) {\n            sumDocFreq += nodeSumDocFreq;\n          } else {\n            sumDocFreq = -1;\n          }\n          \n          assert nodeStats.maxDoc() >= 0;\n          maxDoc += nodeStats.maxDoc();\n        }\n\n        return new CollectionStatistics(field, maxDoc, docCount, sumTotalTermFreq, sumDocFreq);\n      }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/search/ShardSearchingTestBase.NodeState.ShardIndexSearcher#collectionStatistics(String).mjava","pathOld":"lucene/src/test-framework/java/org/apache/lucene/search/ShardSearchingTestBase.NodeState.ShardIndexSearcher#collectionStatistics(String).mjava","sourceNew":"      @Override\n      public CollectionStatistics collectionStatistics(String field) throws IOException {\n        // TODO: we could compute this on init and cache,\n        // since we are re-inited whenever any nodes have a\n        // new reader\n        long docCount = 0;\n        long sumTotalTermFreq = 0;\n        long sumDocFreq = 0;\n        long maxDoc = 0;\n\n        for(int nodeID=0;nodeID<nodeVersions.length;nodeID++) {\n          final FieldAndShardVersion key = new FieldAndShardVersion(nodeID, nodeVersions[nodeID], field);\n          final CollectionStatistics nodeStats;\n          if (nodeID == myNodeID) {\n            nodeStats = super.collectionStatistics(field);\n          } else {\n            nodeStats = collectionStatsCache.get(key);\n          }\n          if (nodeStats == null) {\n            System.out.println(\"coll stats myNodeID=\" + myNodeID + \": \" + collectionStatsCache.keySet());\n          }\n          // Collection stats are pre-shared on reopen, so,\n          // we better not have a cache miss:\n          assert nodeStats != null: \"myNodeID=\" + myNodeID + \" nodeID=\" + nodeID + \" version=\" + nodeVersions[nodeID] + \" field=\" + field;\n          \n          long nodeDocCount = nodeStats.docCount();\n          if (docCount >= 0 && nodeDocCount >= 0) {\n            docCount += nodeDocCount;\n          } else {\n            docCount = -1;\n          }\n          \n          long nodeSumTotalTermFreq = nodeStats.sumTotalTermFreq();\n          if (sumTotalTermFreq >= 0 && nodeSumTotalTermFreq >= 0) {\n            sumTotalTermFreq += nodeSumTotalTermFreq;\n          } else {\n            sumTotalTermFreq = -1;\n          }\n          \n          long nodeSumDocFreq = nodeStats.sumDocFreq();\n          if (sumDocFreq >= 0 && nodeSumDocFreq >= 0) {\n            sumDocFreq += nodeSumDocFreq;\n          } else {\n            sumDocFreq = -1;\n          }\n          \n          assert nodeStats.maxDoc() >= 0;\n          maxDoc += nodeStats.maxDoc();\n        }\n\n        return new CollectionStatistics(field, maxDoc, docCount, sumTotalTermFreq, sumDocFreq);\n      }\n\n","sourceOld":"      @Override\n      public CollectionStatistics collectionStatistics(String field) throws IOException {\n        // TODO: we could compute this on init and cache,\n        // since we are re-inited whenever any nodes have a\n        // new reader\n        long docCount = 0;\n        long sumTotalTermFreq = 0;\n        long sumDocFreq = 0;\n        long maxDoc = 0;\n\n        for(int nodeID=0;nodeID<nodeVersions.length;nodeID++) {\n          final FieldAndShardVersion key = new FieldAndShardVersion(nodeID, nodeVersions[nodeID], field);\n          final CollectionStatistics nodeStats;\n          if (nodeID == myNodeID) {\n            nodeStats = super.collectionStatistics(field);\n          } else {\n            nodeStats = collectionStatsCache.get(key);\n          }\n          if (nodeStats == null) {\n            System.out.println(\"coll stats myNodeID=\" + myNodeID + \": \" + collectionStatsCache.keySet());\n          }\n          // Collection stats are pre-shared on reopen, so,\n          // we better not have a cache miss:\n          assert nodeStats != null: \"myNodeID=\" + myNodeID + \" nodeID=\" + nodeID + \" version=\" + nodeVersions[nodeID] + \" field=\" + field;\n          \n          long nodeDocCount = nodeStats.docCount();\n          if (docCount >= 0 && nodeDocCount >= 0) {\n            docCount += nodeDocCount;\n          } else {\n            docCount = -1;\n          }\n          \n          long nodeSumTotalTermFreq = nodeStats.sumTotalTermFreq();\n          if (sumTotalTermFreq >= 0 && nodeSumTotalTermFreq >= 0) {\n            sumTotalTermFreq += nodeSumTotalTermFreq;\n          } else {\n            sumTotalTermFreq = -1;\n          }\n          \n          long nodeSumDocFreq = nodeStats.sumDocFreq();\n          if (sumDocFreq >= 0 && nodeSumDocFreq >= 0) {\n            sumDocFreq += nodeSumDocFreq;\n          } else {\n            sumDocFreq = -1;\n          }\n          \n          assert nodeStats.maxDoc() >= 0;\n          maxDoc += nodeStats.maxDoc();\n        }\n\n        return new CollectionStatistics(field, maxDoc, docCount, sumTotalTermFreq, sumDocFreq);\n      }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"78a55f24d9b493c2a1cecf79f1d78279062b545b":["a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d","64aaeb7d6606aeec15dd381453d66caedda7888b"],"64aaeb7d6606aeec15dd381453d66caedda7888b":["e461dc186cc6b97e0a85c6f5acb27c190eb3f335"],"0d22ac6a4146774c1bc8400160fc0b6150294e92":["226aae72c0326f4299c16280195bade4530de537","e461dc186cc6b97e0a85c6f5acb27c190eb3f335"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["64aaeb7d6606aeec15dd381453d66caedda7888b"],"226aae72c0326f4299c16280195bade4530de537":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"fd92b8bcc88e969302510acf77bd6970da3994c4":["0d22ac6a4146774c1bc8400160fc0b6150294e92","64aaeb7d6606aeec15dd381453d66caedda7888b"],"a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d":["226aae72c0326f4299c16280195bade4530de537","e461dc186cc6b97e0a85c6f5acb27c190eb3f335"],"e461dc186cc6b97e0a85c6f5acb27c190eb3f335":["226aae72c0326f4299c16280195bade4530de537"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"78a55f24d9b493c2a1cecf79f1d78279062b545b":[],"64aaeb7d6606aeec15dd381453d66caedda7888b":["78a55f24d9b493c2a1cecf79f1d78279062b545b","3a119bbc8703c10faa329ec201c654b3a35a1e3e","fd92b8bcc88e969302510acf77bd6970da3994c4"],"0d22ac6a4146774c1bc8400160fc0b6150294e92":["fd92b8bcc88e969302510acf77bd6970da3994c4"],"226aae72c0326f4299c16280195bade4530de537":["0d22ac6a4146774c1bc8400160fc0b6150294e92","a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d","e461dc186cc6b97e0a85c6f5acb27c190eb3f335"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["226aae72c0326f4299c16280195bade4530de537"],"a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d":["78a55f24d9b493c2a1cecf79f1d78279062b545b"],"fd92b8bcc88e969302510acf77bd6970da3994c4":[],"e461dc186cc6b97e0a85c6f5acb27c190eb3f335":["64aaeb7d6606aeec15dd381453d66caedda7888b","0d22ac6a4146774c1bc8400160fc0b6150294e92","a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["78a55f24d9b493c2a1cecf79f1d78279062b545b","fd92b8bcc88e969302510acf77bd6970da3994c4","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}