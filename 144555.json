{"path":"lucene/classification/src/java/org/apache/lucene/classification/document/SimpleNaiveBayesDocumentClassifier#calculateLogLikelihood(String[],String,Term,int).mjava","commits":[{"id":"38b5bd3ae837751f57f363e9a41b833794222814","date":1445342257,"type":1,"author":"Tommaso Teofili","isMerge":false,"pathNew":"lucene/classification/src/java/org/apache/lucene/classification/document/SimpleNaiveBayesDocumentClassifier#calculateLogLikelihood(String[],String,Term,int).mjava","pathOld":"lucene/classification/src/java/org/apache/lucene/classification/document/SimpleNaiveBayesDocumentClassifier#calculateLogLikelihood(String[],String,BytesRef,int).mjava","sourceNew":"  /**\n   * @param tokenizedText the tokenized content of a field\n   * @param fieldName     the input field name\n   * @param term          the {@link Term} referring to the class to calculate the score of\n   * @param docsWithClass the total number of docs that have a class\n   * @return a normalized score for the class\n   * @throws IOException If there is a low-level I/O error\n   */\n  private double calculateLogLikelihood(String[] tokenizedText, String fieldName, Term term, int docsWithClass) throws IOException {\n    // for each word\n    double result = 0d;\n    for (String word : tokenizedText) {\n      // search with text:word AND class:c\n      int hits = getWordFreqForClass(word, fieldName, term);\n\n      // num : count the no of times the word appears in documents of class c (+1)\n      double num = hits + 1; // +1 is added because of add 1 smoothing\n\n      // den : for the whole dictionary, count the no of times a word appears in documents of class c (+|V|)\n      double den = getTextTermFreqForClass(term, fieldName) + docsWithClass;\n\n      // P(w|c) = num/den\n      double wordProbability = num / den;\n      result += Math.log(wordProbability);\n    }\n\n    // log(P(d|c)) = log(P(w1|c))+...+log(P(wn|c))\n    double normScore = result / (tokenizedText.length); // this is normalized because if not, long text fields will always be more important than short fields\n    return normScore;\n  }\n\n","sourceOld":"  /**\n   * @param tokenizedText the tokenized content of a field\n   * @param fieldName     the input field name\n   * @param c             the class to calculate the score of\n   * @param docsWithClass the total number of docs that have a class\n   * @return a normalized score for the class\n   * @throws IOException If there is a low-level I/O error\n   */\n  private double calculateLogLikelihood(String[] tokenizedText, String fieldName, BytesRef c, int docsWithClass) throws IOException {\n    // for each word\n    double result = 0d;\n    for (String word : tokenizedText) {\n      // search with text:word AND class:c\n      int hits = getWordFreqForClass(word, fieldName, c);\n\n      // num : count the no of times the word appears in documents of class c (+1)\n      double num = hits + 1; // +1 is added because of add 1 smoothing\n\n      // den : for the whole dictionary, count the no of times a word appears in documents of class c (+|V|)\n      double den = getTextTermFreqForClass(c, fieldName) + docsWithClass;\n\n      // P(w|c) = num/den\n      double wordProbability = num / den;\n      result += Math.log(wordProbability);\n    }\n\n    // log(P(d|c)) = log(P(w1|c))+...+log(P(wn|c))\n    double normScore = result / (tokenizedText.length); // this is normalized because if not, long text fields will always be more important than short fields\n    return normScore;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"33bfee30277584028170135002def66f9d57732b","date":1547842233,"type":3,"author":"Tommaso Teofili","isMerge":false,"pathNew":"lucene/classification/src/java/org/apache/lucene/classification/document/SimpleNaiveBayesDocumentClassifier#calculateLogLikelihood(String[],String,Term,int).mjava","pathOld":"lucene/classification/src/java/org/apache/lucene/classification/document/SimpleNaiveBayesDocumentClassifier#calculateLogLikelihood(String[],String,Term,int).mjava","sourceNew":"  /**\n   * @param tokenizedText the tokenized content of a field\n   * @param fieldName     the input field name\n   * @param term          the {@link Term} referring to the class to calculate the score of\n   * @param docsWithClass the total number of docs that have a class\n   * @return a normalized score for the class\n   * @throws IOException If there is a low-level I/O error\n   */\n  private double calculateLogLikelihood(String[] tokenizedText, String fieldName, Term term, int docsWithClass) throws IOException {\n    // for each word\n    double result = 0d;\n    for (String word : tokenizedText) {\n      // search with text:word AND class:c\n      int hits = getWordFreqForClass(word, fieldName, term);\n\n      // num : count the no of times the word appears in documents of class c (+1)\n      double num = hits + 1; // +1 is added because of add 1 smoothing\n\n      // den : for the whole dictionary, count the no of times a word appears in documents of class c (+|V|)\n      double den = getTextTermFreqForClass(term, fieldName) + docsWithClass;\n\n      // P(w|c) = num/den\n      double wordProbability = num / den;\n      result += Math.log(wordProbability);\n    }\n\n    // log(P(d|c)) = log(P(w1|c))+...+log(P(wn|c))\n    return result / (tokenizedText.length);\n  }\n\n","sourceOld":"  /**\n   * @param tokenizedText the tokenized content of a field\n   * @param fieldName     the input field name\n   * @param term          the {@link Term} referring to the class to calculate the score of\n   * @param docsWithClass the total number of docs that have a class\n   * @return a normalized score for the class\n   * @throws IOException If there is a low-level I/O error\n   */\n  private double calculateLogLikelihood(String[] tokenizedText, String fieldName, Term term, int docsWithClass) throws IOException {\n    // for each word\n    double result = 0d;\n    for (String word : tokenizedText) {\n      // search with text:word AND class:c\n      int hits = getWordFreqForClass(word, fieldName, term);\n\n      // num : count the no of times the word appears in documents of class c (+1)\n      double num = hits + 1; // +1 is added because of add 1 smoothing\n\n      // den : for the whole dictionary, count the no of times a word appears in documents of class c (+|V|)\n      double den = getTextTermFreqForClass(term, fieldName) + docsWithClass;\n\n      // P(w|c) = num/den\n      double wordProbability = num / den;\n      result += Math.log(wordProbability);\n    }\n\n    // log(P(d|c)) = log(P(w1|c))+...+log(P(wn|c))\n    double normScore = result / (tokenizedText.length); // this is normalized because if not, long text fields will always be more important than short fields\n    return normScore;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"52ec154a31cf63bc47d2cc0b49e171a4e75aa99d","date":1548322018,"type":3,"author":"Tommaso Teofili","isMerge":true,"pathNew":"lucene/classification/src/java/org/apache/lucene/classification/document/SimpleNaiveBayesDocumentClassifier#calculateLogLikelihood(String[],String,Term,int).mjava","pathOld":"lucene/classification/src/java/org/apache/lucene/classification/document/SimpleNaiveBayesDocumentClassifier#calculateLogLikelihood(String[],String,Term,int).mjava","sourceNew":"  /**\n   * @param tokenizedText the tokenized content of a field\n   * @param fieldName     the input field name\n   * @param term          the {@link Term} referring to the class to calculate the score of\n   * @param docsWithClass the total number of docs that have a class\n   * @return a normalized score for the class\n   * @throws IOException If there is a low-level I/O error\n   */\n  private double calculateLogLikelihood(String[] tokenizedText, String fieldName, Term term, int docsWithClass) throws IOException {\n    // for each word\n    double result = 0d;\n    for (String word : tokenizedText) {\n      // search with text:word AND class:c\n      int hits = getWordFreqForClass(word, fieldName, term);\n\n      // num : count the no of times the word appears in documents of class c (+1)\n      double num = hits + 1; // +1 is added because of add 1 smoothing\n\n      // den : for the whole dictionary, count the no of times a word appears in documents of class c (+|V|)\n      double den = getTextTermFreqForClass(term, fieldName) + docsWithClass;\n\n      // P(w|c) = num/den\n      double wordProbability = num / den;\n      result += Math.log(wordProbability);\n    }\n\n    // log(P(d|c)) = log(P(w1|c))+...+log(P(wn|c))\n    return result / (tokenizedText.length);\n  }\n\n","sourceOld":"  /**\n   * @param tokenizedText the tokenized content of a field\n   * @param fieldName     the input field name\n   * @param term          the {@link Term} referring to the class to calculate the score of\n   * @param docsWithClass the total number of docs that have a class\n   * @return a normalized score for the class\n   * @throws IOException If there is a low-level I/O error\n   */\n  private double calculateLogLikelihood(String[] tokenizedText, String fieldName, Term term, int docsWithClass) throws IOException {\n    // for each word\n    double result = 0d;\n    for (String word : tokenizedText) {\n      // search with text:word AND class:c\n      int hits = getWordFreqForClass(word, fieldName, term);\n\n      // num : count the no of times the word appears in documents of class c (+1)\n      double num = hits + 1; // +1 is added because of add 1 smoothing\n\n      // den : for the whole dictionary, count the no of times a word appears in documents of class c (+|V|)\n      double den = getTextTermFreqForClass(term, fieldName) + docsWithClass;\n\n      // P(w|c) = num/den\n      double wordProbability = num / den;\n      result += Math.log(wordProbability);\n    }\n\n    // log(P(d|c)) = log(P(w1|c))+...+log(P(wn|c))\n    double normScore = result / (tokenizedText.length); // this is normalized because if not, long text fields will always be more important than short fields\n    return normScore;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"52ec154a31cf63bc47d2cc0b49e171a4e75aa99d":["38b5bd3ae837751f57f363e9a41b833794222814","33bfee30277584028170135002def66f9d57732b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"38b5bd3ae837751f57f363e9a41b833794222814":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"33bfee30277584028170135002def66f9d57732b":["38b5bd3ae837751f57f363e9a41b833794222814"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["52ec154a31cf63bc47d2cc0b49e171a4e75aa99d"]},"commit2Childs":{"52ec154a31cf63bc47d2cc0b49e171a4e75aa99d":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["38b5bd3ae837751f57f363e9a41b833794222814"],"38b5bd3ae837751f57f363e9a41b833794222814":["52ec154a31cf63bc47d2cc0b49e171a4e75aa99d","33bfee30277584028170135002def66f9d57732b"],"33bfee30277584028170135002def66f9d57732b":["52ec154a31cf63bc47d2cc0b49e171a4e75aa99d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}