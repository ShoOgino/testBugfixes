{"path":"lucene/core/src/test/org/apache/lucene/search/TestSameScoresWithThreads#test().mjava","commits":[{"id":"485a1f8ad4bcc0abb22a65e9f7fa57946ee03202","date":1354578860,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestSameScoresWithThreads#test().mjava","pathOld":"/dev/null","sourceNew":"  public void test() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    LineFileDocs docs = new LineFileDocs(random());\n    int bytesToIndex = atLeast(100000);\n    int bytesIndexed = 0;\n    while(bytesIndexed < bytesToIndex) {\n      Document doc = docs.nextDoc();\n      bytesIndexed += RamUsageEstimator.sizeOf(doc);\n      w.addDocument(doc);\n    }\n    IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    Terms terms = MultiFields.getFields(r).terms(\"body\");\n    long termCount = terms.size();\n    assertTrue(termCount > 0);\n    \n    // Target ~10 terms to search:\n    double chance = 10.0 / termCount;\n    TermsEnum termsEnum = terms.iterator(null);\n    final Map<BytesRef,TopDocs> answers = new HashMap<BytesRef,TopDocs>();\n    while(termsEnum.next() != null) {\n      if (random().nextDouble() <= chance) {\n        BytesRef term = BytesRef.deepCopyOf(termsEnum.term());\n        answers.put(term,\n                    s.search(new TermQuery(new Term(\"body\", term)), 100));\n      }\n    }\n\n    if (!answers.isEmpty()) {\n      final CountDownLatch startingGun = new CountDownLatch(1);\n      int numThreads = _TestUtil.nextInt(random(), 2, 5);\n      Thread[] threads = new Thread[numThreads];\n      for(int threadID=0;threadID<numThreads;threadID++) {\n        Thread thread = new Thread() {\n            @Override\n            public void run() {\n              try {\n                startingGun.await();\n                for(int i=0;i<20;i++) {\n                  List<Map.Entry<BytesRef,TopDocs>> shuffled = new ArrayList<Map.Entry<BytesRef,TopDocs>>(answers.entrySet());\n                  Collections.shuffle(shuffled);\n                  for(Map.Entry<BytesRef,TopDocs> ent : shuffled) {\n                    TopDocs actual = s.search(new TermQuery(new Term(\"body\", ent.getKey())), 10);\n                    TopDocs expected = ent.getValue();\n                    assertEquals(expected.totalHits, actual.totalHits);\n                    assertEquals(expected.scoreDocs.length, actual.scoreDocs.length);\n                    for(int hit=0;hit<expected.scoreDocs.length;hit++) {\n                      assertEquals(expected.scoreDocs[hit].doc, actual.scoreDocs[hit].doc);\n                      // Floats really should be identical:\n                      assertTrue(expected.scoreDocs[hit].score == actual.scoreDocs[hit].score);\n                    }\n                  }\n                }\n              } catch (Exception e) {\n                throw new RuntimeException(e);\n              }\n            }\n          };\n        threads[threadID] = thread;\n        thread.start();\n      }\n      startingGun.countDown();\n      for(Thread thread : threads) {\n        thread.join();\n      }\n      r.close();\n    }\n\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["103857ec20f79f31c7a00310a91ed001b9a6ef17"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2899ae5069a2533466ac842042478e67263e1f43","date":1354624628,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestSameScoresWithThreads#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestSameScoresWithThreads#test().mjava","sourceNew":"  public void test() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    LineFileDocs docs = new LineFileDocs(random());\n    int charsToIndex = atLeast(100000);\n    int charsIndexed = 0;\n    //System.out.println(\"bytesToIndex=\" + charsToIndex);\n    while(charsIndexed < charsToIndex) {\n      Document doc = docs.nextDoc();\n      charsIndexed += doc.get(\"body\").length();\n      w.addDocument(doc);\n      //System.out.println(\"  bytes=\" + charsIndexed + \" add: \" + doc);\n    }\n    IndexReader r = w.getReader();\n    //System.out.println(\"numDocs=\" + r.numDocs());\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    Terms terms = MultiFields.getFields(r).terms(\"body\");\n    int termCount = 0;\n    TermsEnum termsEnum = terms.iterator(null);\n    while(termsEnum.next() != null) {\n      termCount++;\n    }\n    assertTrue(termCount > 0);\n    \n    // Target ~10 terms to search:\n    double chance = 10.0 / termCount;\n    termsEnum = terms.iterator(termsEnum);\n    final Map<BytesRef,TopDocs> answers = new HashMap<BytesRef,TopDocs>();\n    while(termsEnum.next() != null) {\n      if (random().nextDouble() <= chance) {\n        BytesRef term = BytesRef.deepCopyOf(termsEnum.term());\n        answers.put(term,\n                    s.search(new TermQuery(new Term(\"body\", term)), 100));\n      }\n    }\n\n    if (!answers.isEmpty()) {\n      final CountDownLatch startingGun = new CountDownLatch(1);\n      int numThreads = _TestUtil.nextInt(random(), 2, 5);\n      Thread[] threads = new Thread[numThreads];\n      for(int threadID=0;threadID<numThreads;threadID++) {\n        Thread thread = new Thread() {\n            @Override\n            public void run() {\n              try {\n                startingGun.await();\n                for(int i=0;i<20;i++) {\n                  List<Map.Entry<BytesRef,TopDocs>> shuffled = new ArrayList<Map.Entry<BytesRef,TopDocs>>(answers.entrySet());\n                  Collections.shuffle(shuffled);\n                  for(Map.Entry<BytesRef,TopDocs> ent : shuffled) {\n                    TopDocs actual = s.search(new TermQuery(new Term(\"body\", ent.getKey())), 100);\n                    TopDocs expected = ent.getValue();\n                    assertEquals(expected.totalHits, actual.totalHits);\n                    assertEquals(\"query=\" + ent.getKey().utf8ToString(), expected.scoreDocs.length, actual.scoreDocs.length);\n                    for(int hit=0;hit<expected.scoreDocs.length;hit++) {\n                      assertEquals(expected.scoreDocs[hit].doc, actual.scoreDocs[hit].doc);\n                      // Floats really should be identical:\n                      assertTrue(expected.scoreDocs[hit].score == actual.scoreDocs[hit].score);\n                    }\n                  }\n                }\n              } catch (Exception e) {\n                throw new RuntimeException(e);\n              }\n            }\n          };\n        threads[threadID] = thread;\n        thread.start();\n      }\n      startingGun.countDown();\n      for(Thread thread : threads) {\n        thread.join();\n      }\n      r.close();\n    }\n\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    LineFileDocs docs = new LineFileDocs(random());\n    int bytesToIndex = atLeast(100000);\n    int bytesIndexed = 0;\n    while(bytesIndexed < bytesToIndex) {\n      Document doc = docs.nextDoc();\n      bytesIndexed += RamUsageEstimator.sizeOf(doc);\n      w.addDocument(doc);\n    }\n    IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    Terms terms = MultiFields.getFields(r).terms(\"body\");\n    long termCount = terms.size();\n    assertTrue(termCount > 0);\n    \n    // Target ~10 terms to search:\n    double chance = 10.0 / termCount;\n    TermsEnum termsEnum = terms.iterator(null);\n    final Map<BytesRef,TopDocs> answers = new HashMap<BytesRef,TopDocs>();\n    while(termsEnum.next() != null) {\n      if (random().nextDouble() <= chance) {\n        BytesRef term = BytesRef.deepCopyOf(termsEnum.term());\n        answers.put(term,\n                    s.search(new TermQuery(new Term(\"body\", term)), 100));\n      }\n    }\n\n    if (!answers.isEmpty()) {\n      final CountDownLatch startingGun = new CountDownLatch(1);\n      int numThreads = _TestUtil.nextInt(random(), 2, 5);\n      Thread[] threads = new Thread[numThreads];\n      for(int threadID=0;threadID<numThreads;threadID++) {\n        Thread thread = new Thread() {\n            @Override\n            public void run() {\n              try {\n                startingGun.await();\n                for(int i=0;i<20;i++) {\n                  List<Map.Entry<BytesRef,TopDocs>> shuffled = new ArrayList<Map.Entry<BytesRef,TopDocs>>(answers.entrySet());\n                  Collections.shuffle(shuffled);\n                  for(Map.Entry<BytesRef,TopDocs> ent : shuffled) {\n                    TopDocs actual = s.search(new TermQuery(new Term(\"body\", ent.getKey())), 10);\n                    TopDocs expected = ent.getValue();\n                    assertEquals(expected.totalHits, actual.totalHits);\n                    assertEquals(expected.scoreDocs.length, actual.scoreDocs.length);\n                    for(int hit=0;hit<expected.scoreDocs.length;hit++) {\n                      assertEquals(expected.scoreDocs[hit].doc, actual.scoreDocs[hit].doc);\n                      // Floats really should be identical:\n                      assertTrue(expected.scoreDocs[hit].score == actual.scoreDocs[hit].score);\n                    }\n                  }\n                }\n              } catch (Exception e) {\n                throw new RuntimeException(e);\n              }\n            }\n          };\n        threads[threadID] = thread;\n        thread.start();\n      }\n      startingGun.countDown();\n      for(Thread thread : threads) {\n        thread.join();\n      }\n      r.close();\n    }\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d4d69c535930b5cce125cff868d40f6373dc27d4","date":1360270101,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestSameScoresWithThreads#test().mjava","pathOld":"/dev/null","sourceNew":"  public void test() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    LineFileDocs docs = new LineFileDocs(random());\n    int charsToIndex = atLeast(100000);\n    int charsIndexed = 0;\n    //System.out.println(\"bytesToIndex=\" + charsToIndex);\n    while(charsIndexed < charsToIndex) {\n      Document doc = docs.nextDoc();\n      charsIndexed += doc.get(\"body\").length();\n      w.addDocument(doc);\n      //System.out.println(\"  bytes=\" + charsIndexed + \" add: \" + doc);\n    }\n    IndexReader r = w.getReader();\n    //System.out.println(\"numDocs=\" + r.numDocs());\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    Terms terms = MultiFields.getFields(r).terms(\"body\");\n    int termCount = 0;\n    TermsEnum termsEnum = terms.iterator(null);\n    while(termsEnum.next() != null) {\n      termCount++;\n    }\n    assertTrue(termCount > 0);\n    \n    // Target ~10 terms to search:\n    double chance = 10.0 / termCount;\n    termsEnum = terms.iterator(termsEnum);\n    final Map<BytesRef,TopDocs> answers = new HashMap<BytesRef,TopDocs>();\n    while(termsEnum.next() != null) {\n      if (random().nextDouble() <= chance) {\n        BytesRef term = BytesRef.deepCopyOf(termsEnum.term());\n        answers.put(term,\n                    s.search(new TermQuery(new Term(\"body\", term)), 100));\n      }\n    }\n\n    if (!answers.isEmpty()) {\n      final CountDownLatch startingGun = new CountDownLatch(1);\n      int numThreads = _TestUtil.nextInt(random(), 2, 5);\n      Thread[] threads = new Thread[numThreads];\n      for(int threadID=0;threadID<numThreads;threadID++) {\n        Thread thread = new Thread() {\n            @Override\n            public void run() {\n              try {\n                startingGun.await();\n                for(int i=0;i<20;i++) {\n                  List<Map.Entry<BytesRef,TopDocs>> shuffled = new ArrayList<Map.Entry<BytesRef,TopDocs>>(answers.entrySet());\n                  Collections.shuffle(shuffled);\n                  for(Map.Entry<BytesRef,TopDocs> ent : shuffled) {\n                    TopDocs actual = s.search(new TermQuery(new Term(\"body\", ent.getKey())), 100);\n                    TopDocs expected = ent.getValue();\n                    assertEquals(expected.totalHits, actual.totalHits);\n                    assertEquals(\"query=\" + ent.getKey().utf8ToString(), expected.scoreDocs.length, actual.scoreDocs.length);\n                    for(int hit=0;hit<expected.scoreDocs.length;hit++) {\n                      assertEquals(expected.scoreDocs[hit].doc, actual.scoreDocs[hit].doc);\n                      // Floats really should be identical:\n                      assertTrue(expected.scoreDocs[hit].score == actual.scoreDocs[hit].score);\n                    }\n                  }\n                }\n              } catch (Exception e) {\n                throw new RuntimeException(e);\n              }\n            }\n          };\n        threads[threadID] = thread;\n        thread.start();\n      }\n      startingGun.countDown();\n      for(Thread thread : threads) {\n        thread.join();\n      }\n      r.close();\n    }\n\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b2f69248e793a250662f39e914e1a57fd8b2bfb3","date":1361879976,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestSameScoresWithThreads#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestSameScoresWithThreads#test().mjava","sourceNew":"  public void test() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    LineFileDocs docs = new LineFileDocs(random());\n    int charsToIndex = atLeast(100000);\n    int charsIndexed = 0;\n    //System.out.println(\"bytesToIndex=\" + charsToIndex);\n    while(charsIndexed < charsToIndex) {\n      Document doc = docs.nextDoc();\n      charsIndexed += doc.get(\"body\").length();\n      w.addDocument(doc);\n      //System.out.println(\"  bytes=\" + charsIndexed + \" add: \" + doc);\n    }\n    IndexReader r = w.getReader();\n    //System.out.println(\"numDocs=\" + r.numDocs());\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    Terms terms = MultiFields.getFields(r).terms(\"body\");\n    int termCount = 0;\n    TermsEnum termsEnum = terms.iterator(null);\n    while(termsEnum.next() != null) {\n      termCount++;\n    }\n    assertTrue(termCount > 0);\n    \n    // Target ~10 terms to search:\n    double chance = 10.0 / termCount;\n    termsEnum = terms.iterator(termsEnum);\n    final Map<BytesRef,TopDocs> answers = new HashMap<BytesRef,TopDocs>();\n    while(termsEnum.next() != null) {\n      if (random().nextDouble() <= chance) {\n        BytesRef term = BytesRef.deepCopyOf(termsEnum.term());\n        answers.put(term,\n                    s.search(new TermQuery(new Term(\"body\", term)), 100));\n      }\n    }\n\n    if (!answers.isEmpty()) {\n      final CountDownLatch startingGun = new CountDownLatch(1);\n      int numThreads = _TestUtil.nextInt(random(), 2, 5);\n      Thread[] threads = new Thread[numThreads];\n      for(int threadID=0;threadID<numThreads;threadID++) {\n        Thread thread = new Thread() {\n            @Override\n            public void run() {\n              try {\n                startingGun.await();\n                for(int i=0;i<20;i++) {\n                  List<Map.Entry<BytesRef,TopDocs>> shuffled = new ArrayList<Map.Entry<BytesRef,TopDocs>>(answers.entrySet());\n                  Collections.shuffle(shuffled);\n                  for(Map.Entry<BytesRef,TopDocs> ent : shuffled) {\n                    TopDocs actual = s.search(new TermQuery(new Term(\"body\", ent.getKey())), 100);\n                    TopDocs expected = ent.getValue();\n                    assertEquals(expected.totalHits, actual.totalHits);\n                    assertEquals(\"query=\" + ent.getKey().utf8ToString(), expected.scoreDocs.length, actual.scoreDocs.length);\n                    for(int hit=0;hit<expected.scoreDocs.length;hit++) {\n                      assertEquals(expected.scoreDocs[hit].doc, actual.scoreDocs[hit].doc);\n                      // Floats really should be identical:\n                      assertTrue(expected.scoreDocs[hit].score == actual.scoreDocs[hit].score);\n                    }\n                  }\n                }\n              } catch (Exception e) {\n                throw new RuntimeException(e);\n              }\n            }\n          };\n        threads[threadID] = thread;\n        thread.start();\n      }\n      startingGun.countDown();\n      for(Thread thread : threads) {\n        thread.join();\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    LineFileDocs docs = new LineFileDocs(random());\n    int charsToIndex = atLeast(100000);\n    int charsIndexed = 0;\n    //System.out.println(\"bytesToIndex=\" + charsToIndex);\n    while(charsIndexed < charsToIndex) {\n      Document doc = docs.nextDoc();\n      charsIndexed += doc.get(\"body\").length();\n      w.addDocument(doc);\n      //System.out.println(\"  bytes=\" + charsIndexed + \" add: \" + doc);\n    }\n    IndexReader r = w.getReader();\n    //System.out.println(\"numDocs=\" + r.numDocs());\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    Terms terms = MultiFields.getFields(r).terms(\"body\");\n    int termCount = 0;\n    TermsEnum termsEnum = terms.iterator(null);\n    while(termsEnum.next() != null) {\n      termCount++;\n    }\n    assertTrue(termCount > 0);\n    \n    // Target ~10 terms to search:\n    double chance = 10.0 / termCount;\n    termsEnum = terms.iterator(termsEnum);\n    final Map<BytesRef,TopDocs> answers = new HashMap<BytesRef,TopDocs>();\n    while(termsEnum.next() != null) {\n      if (random().nextDouble() <= chance) {\n        BytesRef term = BytesRef.deepCopyOf(termsEnum.term());\n        answers.put(term,\n                    s.search(new TermQuery(new Term(\"body\", term)), 100));\n      }\n    }\n\n    if (!answers.isEmpty()) {\n      final CountDownLatch startingGun = new CountDownLatch(1);\n      int numThreads = _TestUtil.nextInt(random(), 2, 5);\n      Thread[] threads = new Thread[numThreads];\n      for(int threadID=0;threadID<numThreads;threadID++) {\n        Thread thread = new Thread() {\n            @Override\n            public void run() {\n              try {\n                startingGun.await();\n                for(int i=0;i<20;i++) {\n                  List<Map.Entry<BytesRef,TopDocs>> shuffled = new ArrayList<Map.Entry<BytesRef,TopDocs>>(answers.entrySet());\n                  Collections.shuffle(shuffled);\n                  for(Map.Entry<BytesRef,TopDocs> ent : shuffled) {\n                    TopDocs actual = s.search(new TermQuery(new Term(\"body\", ent.getKey())), 100);\n                    TopDocs expected = ent.getValue();\n                    assertEquals(expected.totalHits, actual.totalHits);\n                    assertEquals(\"query=\" + ent.getKey().utf8ToString(), expected.scoreDocs.length, actual.scoreDocs.length);\n                    for(int hit=0;hit<expected.scoreDocs.length;hit++) {\n                      assertEquals(expected.scoreDocs[hit].doc, actual.scoreDocs[hit].doc);\n                      // Floats really should be identical:\n                      assertTrue(expected.scoreDocs[hit].score == actual.scoreDocs[hit].score);\n                    }\n                  }\n                }\n              } catch (Exception e) {\n                throw new RuntimeException(e);\n              }\n            }\n          };\n        threads[threadID] = thread;\n        thread.start();\n      }\n      startingGun.countDown();\n      for(Thread thread : threads) {\n        thread.join();\n      }\n      r.close();\n    }\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3b0e8c39ca08b5a02de6edcd33d6f3b90b865173","date":1365631993,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestSameScoresWithThreads#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestSameScoresWithThreads#test().mjava","sourceNew":"  public void test() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    LineFileDocs docs = new LineFileDocs(random());\n    int charsToIndex = atLeast(100000);\n    int charsIndexed = 0;\n    //System.out.println(\"bytesToIndex=\" + charsToIndex);\n    while(charsIndexed < charsToIndex) {\n      Document doc = docs.nextDoc();\n      charsIndexed += doc.get(\"body\").length();\n      w.addDocument(doc);\n      //System.out.println(\"  bytes=\" + charsIndexed + \" add: \" + doc);\n    }\n    IndexReader r = w.getReader();\n    //System.out.println(\"numDocs=\" + r.numDocs());\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    Terms terms = MultiFields.getFields(r).terms(\"body\");\n    int termCount = 0;\n    TermsEnum termsEnum = terms.iterator(null);\n    while(termsEnum.next() != null) {\n      termCount++;\n    }\n    assertTrue(termCount > 0);\n    \n    // Target ~10 terms to search:\n    double chance = 10.0 / termCount;\n    termsEnum = terms.iterator(termsEnum);\n    final Map<BytesRef,TopDocs> answers = new HashMap<BytesRef,TopDocs>();\n    while(termsEnum.next() != null) {\n      if (random().nextDouble() <= chance) {\n        BytesRef term = BytesRef.deepCopyOf(termsEnum.term());\n        answers.put(term,\n                    s.search(new TermQuery(new Term(\"body\", term)), 100));\n      }\n    }\n\n    if (!answers.isEmpty()) {\n      final CountDownLatch startingGun = new CountDownLatch(1);\n      int numThreads = _TestUtil.nextInt(random(), 2, 5);\n      Thread[] threads = new Thread[numThreads];\n      for(int threadID=0;threadID<numThreads;threadID++) {\n        Thread thread = new Thread() {\n            @Override\n            public void run() {\n              try {\n                startingGun.await();\n                for(int i=0;i<20;i++) {\n                  List<Map.Entry<BytesRef,TopDocs>> shuffled = new ArrayList<Map.Entry<BytesRef,TopDocs>>(answers.entrySet());\n                  Collections.shuffle(shuffled);\n                  for(Map.Entry<BytesRef,TopDocs> ent : shuffled) {\n                    TopDocs actual = s.search(new TermQuery(new Term(\"body\", ent.getKey())), 100);\n                    TopDocs expected = ent.getValue();\n                    assertEquals(expected.totalHits, actual.totalHits);\n                    assertEquals(\"query=\" + ent.getKey().utf8ToString(), expected.scoreDocs.length, actual.scoreDocs.length);\n                    for(int hit=0;hit<expected.scoreDocs.length;hit++) {\n                      assertEquals(expected.scoreDocs[hit].doc, actual.scoreDocs[hit].doc);\n                      // Floats really should be identical:\n                      assertTrue(expected.scoreDocs[hit].score == actual.scoreDocs[hit].score);\n                    }\n                  }\n                }\n              } catch (Exception e) {\n                throw new RuntimeException(e);\n              }\n            }\n          };\n        threads[threadID] = thread;\n        thread.start();\n      }\n      startingGun.countDown();\n      for(Thread thread : threads) {\n        thread.join();\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    LineFileDocs docs = new LineFileDocs(random());\n    int charsToIndex = atLeast(100000);\n    int charsIndexed = 0;\n    //System.out.println(\"bytesToIndex=\" + charsToIndex);\n    while(charsIndexed < charsToIndex) {\n      Document doc = docs.nextDoc();\n      charsIndexed += doc.get(\"body\").length();\n      w.addDocument(doc);\n      //System.out.println(\"  bytes=\" + charsIndexed + \" add: \" + doc);\n    }\n    IndexReader r = w.getReader();\n    //System.out.println(\"numDocs=\" + r.numDocs());\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    Terms terms = MultiFields.getFields(r).terms(\"body\");\n    int termCount = 0;\n    TermsEnum termsEnum = terms.iterator(null);\n    while(termsEnum.next() != null) {\n      termCount++;\n    }\n    assertTrue(termCount > 0);\n    \n    // Target ~10 terms to search:\n    double chance = 10.0 / termCount;\n    termsEnum = terms.iterator(termsEnum);\n    final Map<BytesRef,TopDocs> answers = new HashMap<BytesRef,TopDocs>();\n    while(termsEnum.next() != null) {\n      if (random().nextDouble() <= chance) {\n        BytesRef term = BytesRef.deepCopyOf(termsEnum.term());\n        answers.put(term,\n                    s.search(new TermQuery(new Term(\"body\", term)), 100));\n      }\n    }\n\n    if (!answers.isEmpty()) {\n      final CountDownLatch startingGun = new CountDownLatch(1);\n      int numThreads = _TestUtil.nextInt(random(), 2, 5);\n      Thread[] threads = new Thread[numThreads];\n      for(int threadID=0;threadID<numThreads;threadID++) {\n        Thread thread = new Thread() {\n            @Override\n            public void run() {\n              try {\n                startingGun.await();\n                for(int i=0;i<20;i++) {\n                  List<Map.Entry<BytesRef,TopDocs>> shuffled = new ArrayList<Map.Entry<BytesRef,TopDocs>>(answers.entrySet());\n                  Collections.shuffle(shuffled);\n                  for(Map.Entry<BytesRef,TopDocs> ent : shuffled) {\n                    TopDocs actual = s.search(new TermQuery(new Term(\"body\", ent.getKey())), 100);\n                    TopDocs expected = ent.getValue();\n                    assertEquals(expected.totalHits, actual.totalHits);\n                    assertEquals(\"query=\" + ent.getKey().utf8ToString(), expected.scoreDocs.length, actual.scoreDocs.length);\n                    for(int hit=0;hit<expected.scoreDocs.length;hit++) {\n                      assertEquals(expected.scoreDocs[hit].doc, actual.scoreDocs[hit].doc);\n                      // Floats really should be identical:\n                      assertTrue(expected.scoreDocs[hit].score == actual.scoreDocs[hit].score);\n                    }\n                  }\n                }\n              } catch (Exception e) {\n                throw new RuntimeException(e);\n              }\n            }\n          };\n        threads[threadID] = thread;\n        thread.start();\n      }\n      startingGun.countDown();\n      for(Thread thread : threads) {\n        thread.join();\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6613659748fe4411a7dcf85266e55db1f95f7315","date":1392773913,"type":3,"author":"Benson Margulies","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestSameScoresWithThreads#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestSameScoresWithThreads#test().mjava","sourceNew":"  public void test() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    LineFileDocs docs = new LineFileDocs(random());\n    int charsToIndex = atLeast(100000);\n    int charsIndexed = 0;\n    //System.out.println(\"bytesToIndex=\" + charsToIndex);\n    while(charsIndexed < charsToIndex) {\n      Document doc = docs.nextDoc();\n      charsIndexed += doc.get(\"body\").length();\n      w.addDocument(doc);\n      //System.out.println(\"  bytes=\" + charsIndexed + \" add: \" + doc);\n    }\n    IndexReader r = w.getReader();\n    //System.out.println(\"numDocs=\" + r.numDocs());\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    Terms terms = MultiFields.getFields(r).terms(\"body\");\n    int termCount = 0;\n    TermsEnum termsEnum = terms.iterator(null);\n    while(termsEnum.next() != null) {\n      termCount++;\n    }\n    assertTrue(termCount > 0);\n    \n    // Target ~10 terms to search:\n    double chance = 10.0 / termCount;\n    termsEnum = terms.iterator(termsEnum);\n    final Map<BytesRef,TopDocs> answers = new HashMap<BytesRef,TopDocs>();\n    while(termsEnum.next() != null) {\n      if (random().nextDouble() <= chance) {\n        BytesRef term = BytesRef.deepCopyOf(termsEnum.term());\n        answers.put(term,\n                    s.search(new TermQuery(new Term(\"body\", term)), 100));\n      }\n    }\n\n    if (!answers.isEmpty()) {\n      final CountDownLatch startingGun = new CountDownLatch(1);\n      int numThreads = TestUtil.nextInt(random(), 2, 5);\n      Thread[] threads = new Thread[numThreads];\n      for(int threadID=0;threadID<numThreads;threadID++) {\n        Thread thread = new Thread() {\n            @Override\n            public void run() {\n              try {\n                startingGun.await();\n                for(int i=0;i<20;i++) {\n                  List<Map.Entry<BytesRef,TopDocs>> shuffled = new ArrayList<Map.Entry<BytesRef,TopDocs>>(answers.entrySet());\n                  Collections.shuffle(shuffled);\n                  for(Map.Entry<BytesRef,TopDocs> ent : shuffled) {\n                    TopDocs actual = s.search(new TermQuery(new Term(\"body\", ent.getKey())), 100);\n                    TopDocs expected = ent.getValue();\n                    assertEquals(expected.totalHits, actual.totalHits);\n                    assertEquals(\"query=\" + ent.getKey().utf8ToString(), expected.scoreDocs.length, actual.scoreDocs.length);\n                    for(int hit=0;hit<expected.scoreDocs.length;hit++) {\n                      assertEquals(expected.scoreDocs[hit].doc, actual.scoreDocs[hit].doc);\n                      // Floats really should be identical:\n                      assertTrue(expected.scoreDocs[hit].score == actual.scoreDocs[hit].score);\n                    }\n                  }\n                }\n              } catch (Exception e) {\n                throw new RuntimeException(e);\n              }\n            }\n          };\n        threads[threadID] = thread;\n        thread.start();\n      }\n      startingGun.countDown();\n      for(Thread thread : threads) {\n        thread.join();\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    LineFileDocs docs = new LineFileDocs(random());\n    int charsToIndex = atLeast(100000);\n    int charsIndexed = 0;\n    //System.out.println(\"bytesToIndex=\" + charsToIndex);\n    while(charsIndexed < charsToIndex) {\n      Document doc = docs.nextDoc();\n      charsIndexed += doc.get(\"body\").length();\n      w.addDocument(doc);\n      //System.out.println(\"  bytes=\" + charsIndexed + \" add: \" + doc);\n    }\n    IndexReader r = w.getReader();\n    //System.out.println(\"numDocs=\" + r.numDocs());\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    Terms terms = MultiFields.getFields(r).terms(\"body\");\n    int termCount = 0;\n    TermsEnum termsEnum = terms.iterator(null);\n    while(termsEnum.next() != null) {\n      termCount++;\n    }\n    assertTrue(termCount > 0);\n    \n    // Target ~10 terms to search:\n    double chance = 10.0 / termCount;\n    termsEnum = terms.iterator(termsEnum);\n    final Map<BytesRef,TopDocs> answers = new HashMap<BytesRef,TopDocs>();\n    while(termsEnum.next() != null) {\n      if (random().nextDouble() <= chance) {\n        BytesRef term = BytesRef.deepCopyOf(termsEnum.term());\n        answers.put(term,\n                    s.search(new TermQuery(new Term(\"body\", term)), 100));\n      }\n    }\n\n    if (!answers.isEmpty()) {\n      final CountDownLatch startingGun = new CountDownLatch(1);\n      int numThreads = _TestUtil.nextInt(random(), 2, 5);\n      Thread[] threads = new Thread[numThreads];\n      for(int threadID=0;threadID<numThreads;threadID++) {\n        Thread thread = new Thread() {\n            @Override\n            public void run() {\n              try {\n                startingGun.await();\n                for(int i=0;i<20;i++) {\n                  List<Map.Entry<BytesRef,TopDocs>> shuffled = new ArrayList<Map.Entry<BytesRef,TopDocs>>(answers.entrySet());\n                  Collections.shuffle(shuffled);\n                  for(Map.Entry<BytesRef,TopDocs> ent : shuffled) {\n                    TopDocs actual = s.search(new TermQuery(new Term(\"body\", ent.getKey())), 100);\n                    TopDocs expected = ent.getValue();\n                    assertEquals(expected.totalHits, actual.totalHits);\n                    assertEquals(\"query=\" + ent.getKey().utf8ToString(), expected.scoreDocs.length, actual.scoreDocs.length);\n                    for(int hit=0;hit<expected.scoreDocs.length;hit++) {\n                      assertEquals(expected.scoreDocs[hit].doc, actual.scoreDocs[hit].doc);\n                      // Floats really should be identical:\n                      assertTrue(expected.scoreDocs[hit].score == actual.scoreDocs[hit].score);\n                    }\n                  }\n                }\n              } catch (Exception e) {\n                throw new RuntimeException(e);\n              }\n            }\n          };\n        threads[threadID] = thread;\n        thread.start();\n      }\n      startingGun.countDown();\n      for(Thread thread : threads) {\n        thread.join();\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e1151ecb4798f5c31137aec032c241638018ed20","date":1394284367,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestSameScoresWithThreads#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestSameScoresWithThreads#test().mjava","sourceNew":"  public void test() throws Exception {\n    final Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir, analyzer);\n    LineFileDocs docs = new LineFileDocs(random());\n    int charsToIndex = atLeast(100000);\n    int charsIndexed = 0;\n    //System.out.println(\"bytesToIndex=\" + charsToIndex);\n    while(charsIndexed < charsToIndex) {\n      Document doc = docs.nextDoc();\n      charsIndexed += doc.get(\"body\").length();\n      w.addDocument(doc);\n      //System.out.println(\"  bytes=\" + charsIndexed + \" add: \" + doc);\n    }\n    IndexReader r = w.getReader();\n    //System.out.println(\"numDocs=\" + r.numDocs());\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    Terms terms = MultiFields.getFields(r).terms(\"body\");\n    int termCount = 0;\n    TermsEnum termsEnum = terms.iterator(null);\n    while(termsEnum.next() != null) {\n      termCount++;\n    }\n    assertTrue(termCount > 0);\n    \n    // Target ~10 terms to search:\n    double chance = 10.0 / termCount;\n    termsEnum = terms.iterator(termsEnum);\n    final Map<BytesRef,TopDocs> answers = new HashMap<BytesRef,TopDocs>();\n    while(termsEnum.next() != null) {\n      if (random().nextDouble() <= chance) {\n        BytesRef term = BytesRef.deepCopyOf(termsEnum.term());\n        answers.put(term,\n                    s.search(new TermQuery(new Term(\"body\", term)), 100));\n      }\n    }\n\n    if (!answers.isEmpty()) {\n      final CountDownLatch startingGun = new CountDownLatch(1);\n      int numThreads = TestUtil.nextInt(random(), 2, 5);\n      Thread[] threads = new Thread[numThreads];\n      for(int threadID=0;threadID<numThreads;threadID++) {\n        Thread thread = new Thread() {\n            @Override\n            public void run() {\n              try {\n                startingGun.await();\n                for(int i=0;i<20;i++) {\n                  List<Map.Entry<BytesRef,TopDocs>> shuffled = new ArrayList<Map.Entry<BytesRef,TopDocs>>(answers.entrySet());\n                  Collections.shuffle(shuffled);\n                  for(Map.Entry<BytesRef,TopDocs> ent : shuffled) {\n                    TopDocs actual = s.search(new TermQuery(new Term(\"body\", ent.getKey())), 100);\n                    TopDocs expected = ent.getValue();\n                    assertEquals(expected.totalHits, actual.totalHits);\n                    assertEquals(\"query=\" + ent.getKey().utf8ToString(), expected.scoreDocs.length, actual.scoreDocs.length);\n                    for(int hit=0;hit<expected.scoreDocs.length;hit++) {\n                      assertEquals(expected.scoreDocs[hit].doc, actual.scoreDocs[hit].doc);\n                      // Floats really should be identical:\n                      assertTrue(expected.scoreDocs[hit].score == actual.scoreDocs[hit].score);\n                    }\n                  }\n                }\n              } catch (Exception e) {\n                throw new RuntimeException(e);\n              }\n            }\n          };\n        threads[threadID] = thread;\n        thread.start();\n      }\n      startingGun.countDown();\n      for(Thread thread : threads) {\n        thread.join();\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    LineFileDocs docs = new LineFileDocs(random());\n    int charsToIndex = atLeast(100000);\n    int charsIndexed = 0;\n    //System.out.println(\"bytesToIndex=\" + charsToIndex);\n    while(charsIndexed < charsToIndex) {\n      Document doc = docs.nextDoc();\n      charsIndexed += doc.get(\"body\").length();\n      w.addDocument(doc);\n      //System.out.println(\"  bytes=\" + charsIndexed + \" add: \" + doc);\n    }\n    IndexReader r = w.getReader();\n    //System.out.println(\"numDocs=\" + r.numDocs());\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    Terms terms = MultiFields.getFields(r).terms(\"body\");\n    int termCount = 0;\n    TermsEnum termsEnum = terms.iterator(null);\n    while(termsEnum.next() != null) {\n      termCount++;\n    }\n    assertTrue(termCount > 0);\n    \n    // Target ~10 terms to search:\n    double chance = 10.0 / termCount;\n    termsEnum = terms.iterator(termsEnum);\n    final Map<BytesRef,TopDocs> answers = new HashMap<BytesRef,TopDocs>();\n    while(termsEnum.next() != null) {\n      if (random().nextDouble() <= chance) {\n        BytesRef term = BytesRef.deepCopyOf(termsEnum.term());\n        answers.put(term,\n                    s.search(new TermQuery(new Term(\"body\", term)), 100));\n      }\n    }\n\n    if (!answers.isEmpty()) {\n      final CountDownLatch startingGun = new CountDownLatch(1);\n      int numThreads = TestUtil.nextInt(random(), 2, 5);\n      Thread[] threads = new Thread[numThreads];\n      for(int threadID=0;threadID<numThreads;threadID++) {\n        Thread thread = new Thread() {\n            @Override\n            public void run() {\n              try {\n                startingGun.await();\n                for(int i=0;i<20;i++) {\n                  List<Map.Entry<BytesRef,TopDocs>> shuffled = new ArrayList<Map.Entry<BytesRef,TopDocs>>(answers.entrySet());\n                  Collections.shuffle(shuffled);\n                  for(Map.Entry<BytesRef,TopDocs> ent : shuffled) {\n                    TopDocs actual = s.search(new TermQuery(new Term(\"body\", ent.getKey())), 100);\n                    TopDocs expected = ent.getValue();\n                    assertEquals(expected.totalHits, actual.totalHits);\n                    assertEquals(\"query=\" + ent.getKey().utf8ToString(), expected.scoreDocs.length, actual.scoreDocs.length);\n                    for(int hit=0;hit<expected.scoreDocs.length;hit++) {\n                      assertEquals(expected.scoreDocs[hit].doc, actual.scoreDocs[hit].doc);\n                      // Floats really should be identical:\n                      assertTrue(expected.scoreDocs[hit].score == actual.scoreDocs[hit].score);\n                    }\n                  }\n                }\n              } catch (Exception e) {\n                throw new RuntimeException(e);\n              }\n            }\n          };\n        threads[threadID] = thread;\n        thread.start();\n      }\n      startingGun.countDown();\n      for(Thread thread : threads) {\n        thread.join();\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a58bbbe1c866963764d3f15d3a26a6a85f6c6af4","date":1394564625,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestSameScoresWithThreads#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestSameScoresWithThreads#test().mjava","sourceNew":"  public void test() throws Exception {\n    final Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir, analyzer);\n    LineFileDocs docs = new LineFileDocs(random());\n    int charsToIndex = atLeast(100000);\n    int charsIndexed = 0;\n    //System.out.println(\"bytesToIndex=\" + charsToIndex);\n    while(charsIndexed < charsToIndex) {\n      Document doc = docs.nextDoc();\n      charsIndexed += doc.get(\"body\").length();\n      w.addDocument(doc);\n      //System.out.println(\"  bytes=\" + charsIndexed + \" add: \" + doc);\n    }\n    IndexReader r = w.getReader();\n    //System.out.println(\"numDocs=\" + r.numDocs());\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    Terms terms = MultiFields.getFields(r).terms(\"body\");\n    int termCount = 0;\n    TermsEnum termsEnum = terms.iterator(null);\n    while(termsEnum.next() != null) {\n      termCount++;\n    }\n    assertTrue(termCount > 0);\n    \n    // Target ~10 terms to search:\n    double chance = 10.0 / termCount;\n    termsEnum = terms.iterator(termsEnum);\n    final Map<BytesRef,TopDocs> answers = new HashMap<BytesRef,TopDocs>();\n    while(termsEnum.next() != null) {\n      if (random().nextDouble() <= chance) {\n        BytesRef term = BytesRef.deepCopyOf(termsEnum.term());\n        answers.put(term,\n                    s.search(new TermQuery(new Term(\"body\", term)), 100));\n      }\n    }\n\n    if (!answers.isEmpty()) {\n      final CountDownLatch startingGun = new CountDownLatch(1);\n      int numThreads = TestUtil.nextInt(random(), 2, 5);\n      Thread[] threads = new Thread[numThreads];\n      for(int threadID=0;threadID<numThreads;threadID++) {\n        Thread thread = new Thread() {\n            @Override\n            public void run() {\n              try {\n                startingGun.await();\n                for(int i=0;i<20;i++) {\n                  List<Map.Entry<BytesRef,TopDocs>> shuffled = new ArrayList<Map.Entry<BytesRef,TopDocs>>(answers.entrySet());\n                  Collections.shuffle(shuffled);\n                  for(Map.Entry<BytesRef,TopDocs> ent : shuffled) {\n                    TopDocs actual = s.search(new TermQuery(new Term(\"body\", ent.getKey())), 100);\n                    TopDocs expected = ent.getValue();\n                    assertEquals(expected.totalHits, actual.totalHits);\n                    assertEquals(\"query=\" + ent.getKey().utf8ToString(), expected.scoreDocs.length, actual.scoreDocs.length);\n                    for(int hit=0;hit<expected.scoreDocs.length;hit++) {\n                      assertEquals(expected.scoreDocs[hit].doc, actual.scoreDocs[hit].doc);\n                      // Floats really should be identical:\n                      assertTrue(expected.scoreDocs[hit].score == actual.scoreDocs[hit].score);\n                    }\n                  }\n                }\n              } catch (Exception e) {\n                throw new RuntimeException(e);\n              }\n            }\n          };\n        threads[threadID] = thread;\n        thread.start();\n      }\n      startingGun.countDown();\n      for(Thread thread : threads) {\n        thread.join();\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    LineFileDocs docs = new LineFileDocs(random());\n    int charsToIndex = atLeast(100000);\n    int charsIndexed = 0;\n    //System.out.println(\"bytesToIndex=\" + charsToIndex);\n    while(charsIndexed < charsToIndex) {\n      Document doc = docs.nextDoc();\n      charsIndexed += doc.get(\"body\").length();\n      w.addDocument(doc);\n      //System.out.println(\"  bytes=\" + charsIndexed + \" add: \" + doc);\n    }\n    IndexReader r = w.getReader();\n    //System.out.println(\"numDocs=\" + r.numDocs());\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    Terms terms = MultiFields.getFields(r).terms(\"body\");\n    int termCount = 0;\n    TermsEnum termsEnum = terms.iterator(null);\n    while(termsEnum.next() != null) {\n      termCount++;\n    }\n    assertTrue(termCount > 0);\n    \n    // Target ~10 terms to search:\n    double chance = 10.0 / termCount;\n    termsEnum = terms.iterator(termsEnum);\n    final Map<BytesRef,TopDocs> answers = new HashMap<BytesRef,TopDocs>();\n    while(termsEnum.next() != null) {\n      if (random().nextDouble() <= chance) {\n        BytesRef term = BytesRef.deepCopyOf(termsEnum.term());\n        answers.put(term,\n                    s.search(new TermQuery(new Term(\"body\", term)), 100));\n      }\n    }\n\n    if (!answers.isEmpty()) {\n      final CountDownLatch startingGun = new CountDownLatch(1);\n      int numThreads = TestUtil.nextInt(random(), 2, 5);\n      Thread[] threads = new Thread[numThreads];\n      for(int threadID=0;threadID<numThreads;threadID++) {\n        Thread thread = new Thread() {\n            @Override\n            public void run() {\n              try {\n                startingGun.await();\n                for(int i=0;i<20;i++) {\n                  List<Map.Entry<BytesRef,TopDocs>> shuffled = new ArrayList<Map.Entry<BytesRef,TopDocs>>(answers.entrySet());\n                  Collections.shuffle(shuffled);\n                  for(Map.Entry<BytesRef,TopDocs> ent : shuffled) {\n                    TopDocs actual = s.search(new TermQuery(new Term(\"body\", ent.getKey())), 100);\n                    TopDocs expected = ent.getValue();\n                    assertEquals(expected.totalHits, actual.totalHits);\n                    assertEquals(\"query=\" + ent.getKey().utf8ToString(), expected.scoreDocs.length, actual.scoreDocs.length);\n                    for(int hit=0;hit<expected.scoreDocs.length;hit++) {\n                      assertEquals(expected.scoreDocs[hit].doc, actual.scoreDocs[hit].doc);\n                      // Floats really should be identical:\n                      assertTrue(expected.scoreDocs[hit].score == actual.scoreDocs[hit].score);\n                    }\n                  }\n                }\n              } catch (Exception e) {\n                throw new RuntimeException(e);\n              }\n            }\n          };\n        threads[threadID] = thread;\n        thread.start();\n      }\n      startingGun.countDown();\n      for(Thread thread : threads) {\n        thread.join();\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestSameScoresWithThreads#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestSameScoresWithThreads#test().mjava","sourceNew":"  public void test() throws Exception {\n    final Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir, analyzer);\n    LineFileDocs docs = new LineFileDocs(random());\n    int charsToIndex = atLeast(100000);\n    int charsIndexed = 0;\n    //System.out.println(\"bytesToIndex=\" + charsToIndex);\n    while(charsIndexed < charsToIndex) {\n      Document doc = docs.nextDoc();\n      charsIndexed += doc.get(\"body\").length();\n      w.addDocument(doc);\n      //System.out.println(\"  bytes=\" + charsIndexed + \" add: \" + doc);\n    }\n    IndexReader r = w.getReader();\n    //System.out.println(\"numDocs=\" + r.numDocs());\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    Terms terms = MultiFields.getFields(r).terms(\"body\");\n    int termCount = 0;\n    TermsEnum termsEnum = terms.iterator(null);\n    while(termsEnum.next() != null) {\n      termCount++;\n    }\n    assertTrue(termCount > 0);\n    \n    // Target ~10 terms to search:\n    double chance = 10.0 / termCount;\n    termsEnum = terms.iterator(termsEnum);\n    final Map<BytesRef,TopDocs> answers = new HashMap<>();\n    while(termsEnum.next() != null) {\n      if (random().nextDouble() <= chance) {\n        BytesRef term = BytesRef.deepCopyOf(termsEnum.term());\n        answers.put(term,\n                    s.search(new TermQuery(new Term(\"body\", term)), 100));\n      }\n    }\n\n    if (!answers.isEmpty()) {\n      final CountDownLatch startingGun = new CountDownLatch(1);\n      int numThreads = TestUtil.nextInt(random(), 2, 5);\n      Thread[] threads = new Thread[numThreads];\n      for(int threadID=0;threadID<numThreads;threadID++) {\n        Thread thread = new Thread() {\n            @Override\n            public void run() {\n              try {\n                startingGun.await();\n                for(int i=0;i<20;i++) {\n                  List<Map.Entry<BytesRef,TopDocs>> shuffled = new ArrayList<>(answers.entrySet());\n                  Collections.shuffle(shuffled);\n                  for(Map.Entry<BytesRef,TopDocs> ent : shuffled) {\n                    TopDocs actual = s.search(new TermQuery(new Term(\"body\", ent.getKey())), 100);\n                    TopDocs expected = ent.getValue();\n                    assertEquals(expected.totalHits, actual.totalHits);\n                    assertEquals(\"query=\" + ent.getKey().utf8ToString(), expected.scoreDocs.length, actual.scoreDocs.length);\n                    for(int hit=0;hit<expected.scoreDocs.length;hit++) {\n                      assertEquals(expected.scoreDocs[hit].doc, actual.scoreDocs[hit].doc);\n                      // Floats really should be identical:\n                      assertTrue(expected.scoreDocs[hit].score == actual.scoreDocs[hit].score);\n                    }\n                  }\n                }\n              } catch (Exception e) {\n                throw new RuntimeException(e);\n              }\n            }\n          };\n        threads[threadID] = thread;\n        thread.start();\n      }\n      startingGun.countDown();\n      for(Thread thread : threads) {\n        thread.join();\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    final Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir, analyzer);\n    LineFileDocs docs = new LineFileDocs(random());\n    int charsToIndex = atLeast(100000);\n    int charsIndexed = 0;\n    //System.out.println(\"bytesToIndex=\" + charsToIndex);\n    while(charsIndexed < charsToIndex) {\n      Document doc = docs.nextDoc();\n      charsIndexed += doc.get(\"body\").length();\n      w.addDocument(doc);\n      //System.out.println(\"  bytes=\" + charsIndexed + \" add: \" + doc);\n    }\n    IndexReader r = w.getReader();\n    //System.out.println(\"numDocs=\" + r.numDocs());\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    Terms terms = MultiFields.getFields(r).terms(\"body\");\n    int termCount = 0;\n    TermsEnum termsEnum = terms.iterator(null);\n    while(termsEnum.next() != null) {\n      termCount++;\n    }\n    assertTrue(termCount > 0);\n    \n    // Target ~10 terms to search:\n    double chance = 10.0 / termCount;\n    termsEnum = terms.iterator(termsEnum);\n    final Map<BytesRef,TopDocs> answers = new HashMap<BytesRef,TopDocs>();\n    while(termsEnum.next() != null) {\n      if (random().nextDouble() <= chance) {\n        BytesRef term = BytesRef.deepCopyOf(termsEnum.term());\n        answers.put(term,\n                    s.search(new TermQuery(new Term(\"body\", term)), 100));\n      }\n    }\n\n    if (!answers.isEmpty()) {\n      final CountDownLatch startingGun = new CountDownLatch(1);\n      int numThreads = TestUtil.nextInt(random(), 2, 5);\n      Thread[] threads = new Thread[numThreads];\n      for(int threadID=0;threadID<numThreads;threadID++) {\n        Thread thread = new Thread() {\n            @Override\n            public void run() {\n              try {\n                startingGun.await();\n                for(int i=0;i<20;i++) {\n                  List<Map.Entry<BytesRef,TopDocs>> shuffled = new ArrayList<Map.Entry<BytesRef,TopDocs>>(answers.entrySet());\n                  Collections.shuffle(shuffled);\n                  for(Map.Entry<BytesRef,TopDocs> ent : shuffled) {\n                    TopDocs actual = s.search(new TermQuery(new Term(\"body\", ent.getKey())), 100);\n                    TopDocs expected = ent.getValue();\n                    assertEquals(expected.totalHits, actual.totalHits);\n                    assertEquals(\"query=\" + ent.getKey().utf8ToString(), expected.scoreDocs.length, actual.scoreDocs.length);\n                    for(int hit=0;hit<expected.scoreDocs.length;hit++) {\n                      assertEquals(expected.scoreDocs[hit].doc, actual.scoreDocs[hit].doc);\n                      // Floats really should be identical:\n                      assertTrue(expected.scoreDocs[hit].score == actual.scoreDocs[hit].score);\n                    }\n                  }\n                }\n              } catch (Exception e) {\n                throw new RuntimeException(e);\n              }\n            }\n          };\n        threads[threadID] = thread;\n        thread.start();\n      }\n      startingGun.countDown();\n      for(Thread thread : threads) {\n        thread.join();\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestSameScoresWithThreads#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestSameScoresWithThreads#test().mjava","sourceNew":"  public void test() throws Exception {\n    final Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir, analyzer);\n    LineFileDocs docs = new LineFileDocs(random());\n    int charsToIndex = atLeast(100000);\n    int charsIndexed = 0;\n    //System.out.println(\"bytesToIndex=\" + charsToIndex);\n    while(charsIndexed < charsToIndex) {\n      Document doc = docs.nextDoc();\n      charsIndexed += doc.get(\"body\").length();\n      w.addDocument(doc);\n      //System.out.println(\"  bytes=\" + charsIndexed + \" add: \" + doc);\n    }\n    IndexReader r = w.getReader();\n    //System.out.println(\"numDocs=\" + r.numDocs());\n    w.shutdown();\n\n    final IndexSearcher s = newSearcher(r);\n    Terms terms = MultiFields.getFields(r).terms(\"body\");\n    int termCount = 0;\n    TermsEnum termsEnum = terms.iterator(null);\n    while(termsEnum.next() != null) {\n      termCount++;\n    }\n    assertTrue(termCount > 0);\n    \n    // Target ~10 terms to search:\n    double chance = 10.0 / termCount;\n    termsEnum = terms.iterator(termsEnum);\n    final Map<BytesRef,TopDocs> answers = new HashMap<>();\n    while(termsEnum.next() != null) {\n      if (random().nextDouble() <= chance) {\n        BytesRef term = BytesRef.deepCopyOf(termsEnum.term());\n        answers.put(term,\n                    s.search(new TermQuery(new Term(\"body\", term)), 100));\n      }\n    }\n\n    if (!answers.isEmpty()) {\n      final CountDownLatch startingGun = new CountDownLatch(1);\n      int numThreads = TestUtil.nextInt(random(), 2, 5);\n      Thread[] threads = new Thread[numThreads];\n      for(int threadID=0;threadID<numThreads;threadID++) {\n        Thread thread = new Thread() {\n            @Override\n            public void run() {\n              try {\n                startingGun.await();\n                for(int i=0;i<20;i++) {\n                  List<Map.Entry<BytesRef,TopDocs>> shuffled = new ArrayList<>(answers.entrySet());\n                  Collections.shuffle(shuffled);\n                  for(Map.Entry<BytesRef,TopDocs> ent : shuffled) {\n                    TopDocs actual = s.search(new TermQuery(new Term(\"body\", ent.getKey())), 100);\n                    TopDocs expected = ent.getValue();\n                    assertEquals(expected.totalHits, actual.totalHits);\n                    assertEquals(\"query=\" + ent.getKey().utf8ToString(), expected.scoreDocs.length, actual.scoreDocs.length);\n                    for(int hit=0;hit<expected.scoreDocs.length;hit++) {\n                      assertEquals(expected.scoreDocs[hit].doc, actual.scoreDocs[hit].doc);\n                      // Floats really should be identical:\n                      assertTrue(expected.scoreDocs[hit].score == actual.scoreDocs[hit].score);\n                    }\n                  }\n                }\n              } catch (Exception e) {\n                throw new RuntimeException(e);\n              }\n            }\n          };\n        threads[threadID] = thread;\n        thread.start();\n      }\n      startingGun.countDown();\n      for(Thread thread : threads) {\n        thread.join();\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    final Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir, analyzer);\n    LineFileDocs docs = new LineFileDocs(random());\n    int charsToIndex = atLeast(100000);\n    int charsIndexed = 0;\n    //System.out.println(\"bytesToIndex=\" + charsToIndex);\n    while(charsIndexed < charsToIndex) {\n      Document doc = docs.nextDoc();\n      charsIndexed += doc.get(\"body\").length();\n      w.addDocument(doc);\n      //System.out.println(\"  bytes=\" + charsIndexed + \" add: \" + doc);\n    }\n    IndexReader r = w.getReader();\n    //System.out.println(\"numDocs=\" + r.numDocs());\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    Terms terms = MultiFields.getFields(r).terms(\"body\");\n    int termCount = 0;\n    TermsEnum termsEnum = terms.iterator(null);\n    while(termsEnum.next() != null) {\n      termCount++;\n    }\n    assertTrue(termCount > 0);\n    \n    // Target ~10 terms to search:\n    double chance = 10.0 / termCount;\n    termsEnum = terms.iterator(termsEnum);\n    final Map<BytesRef,TopDocs> answers = new HashMap<>();\n    while(termsEnum.next() != null) {\n      if (random().nextDouble() <= chance) {\n        BytesRef term = BytesRef.deepCopyOf(termsEnum.term());\n        answers.put(term,\n                    s.search(new TermQuery(new Term(\"body\", term)), 100));\n      }\n    }\n\n    if (!answers.isEmpty()) {\n      final CountDownLatch startingGun = new CountDownLatch(1);\n      int numThreads = TestUtil.nextInt(random(), 2, 5);\n      Thread[] threads = new Thread[numThreads];\n      for(int threadID=0;threadID<numThreads;threadID++) {\n        Thread thread = new Thread() {\n            @Override\n            public void run() {\n              try {\n                startingGun.await();\n                for(int i=0;i<20;i++) {\n                  List<Map.Entry<BytesRef,TopDocs>> shuffled = new ArrayList<>(answers.entrySet());\n                  Collections.shuffle(shuffled);\n                  for(Map.Entry<BytesRef,TopDocs> ent : shuffled) {\n                    TopDocs actual = s.search(new TermQuery(new Term(\"body\", ent.getKey())), 100);\n                    TopDocs expected = ent.getValue();\n                    assertEquals(expected.totalHits, actual.totalHits);\n                    assertEquals(\"query=\" + ent.getKey().utf8ToString(), expected.scoreDocs.length, actual.scoreDocs.length);\n                    for(int hit=0;hit<expected.scoreDocs.length;hit++) {\n                      assertEquals(expected.scoreDocs[hit].doc, actual.scoreDocs[hit].doc);\n                      // Floats really should be identical:\n                      assertTrue(expected.scoreDocs[hit].score == actual.scoreDocs[hit].score);\n                    }\n                  }\n                }\n              } catch (Exception e) {\n                throw new RuntimeException(e);\n              }\n            }\n          };\n        threads[threadID] = thread;\n        thread.start();\n      }\n      startingGun.countDown();\n      for(Thread thread : threads) {\n        thread.join();\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestSameScoresWithThreads#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestSameScoresWithThreads#test().mjava","sourceNew":"  public void test() throws Exception {\n    final Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir, analyzer);\n    LineFileDocs docs = new LineFileDocs(random());\n    int charsToIndex = atLeast(100000);\n    int charsIndexed = 0;\n    //System.out.println(\"bytesToIndex=\" + charsToIndex);\n    while(charsIndexed < charsToIndex) {\n      Document doc = docs.nextDoc();\n      charsIndexed += doc.get(\"body\").length();\n      w.addDocument(doc);\n      //System.out.println(\"  bytes=\" + charsIndexed + \" add: \" + doc);\n    }\n    IndexReader r = w.getReader();\n    //System.out.println(\"numDocs=\" + r.numDocs());\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    Terms terms = MultiFields.getFields(r).terms(\"body\");\n    int termCount = 0;\n    TermsEnum termsEnum = terms.iterator(null);\n    while(termsEnum.next() != null) {\n      termCount++;\n    }\n    assertTrue(termCount > 0);\n    \n    // Target ~10 terms to search:\n    double chance = 10.0 / termCount;\n    termsEnum = terms.iterator(termsEnum);\n    final Map<BytesRef,TopDocs> answers = new HashMap<>();\n    while(termsEnum.next() != null) {\n      if (random().nextDouble() <= chance) {\n        BytesRef term = BytesRef.deepCopyOf(termsEnum.term());\n        answers.put(term,\n                    s.search(new TermQuery(new Term(\"body\", term)), 100));\n      }\n    }\n\n    if (!answers.isEmpty()) {\n      final CountDownLatch startingGun = new CountDownLatch(1);\n      int numThreads = TestUtil.nextInt(random(), 2, 5);\n      Thread[] threads = new Thread[numThreads];\n      for(int threadID=0;threadID<numThreads;threadID++) {\n        Thread thread = new Thread() {\n            @Override\n            public void run() {\n              try {\n                startingGun.await();\n                for(int i=0;i<20;i++) {\n                  List<Map.Entry<BytesRef,TopDocs>> shuffled = new ArrayList<>(answers.entrySet());\n                  Collections.shuffle(shuffled);\n                  for(Map.Entry<BytesRef,TopDocs> ent : shuffled) {\n                    TopDocs actual = s.search(new TermQuery(new Term(\"body\", ent.getKey())), 100);\n                    TopDocs expected = ent.getValue();\n                    assertEquals(expected.totalHits, actual.totalHits);\n                    assertEquals(\"query=\" + ent.getKey().utf8ToString(), expected.scoreDocs.length, actual.scoreDocs.length);\n                    for(int hit=0;hit<expected.scoreDocs.length;hit++) {\n                      assertEquals(expected.scoreDocs[hit].doc, actual.scoreDocs[hit].doc);\n                      // Floats really should be identical:\n                      assertTrue(expected.scoreDocs[hit].score == actual.scoreDocs[hit].score);\n                    }\n                  }\n                }\n              } catch (Exception e) {\n                throw new RuntimeException(e);\n              }\n            }\n          };\n        threads[threadID] = thread;\n        thread.start();\n      }\n      startingGun.countDown();\n      for(Thread thread : threads) {\n        thread.join();\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    final Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir, analyzer);\n    LineFileDocs docs = new LineFileDocs(random());\n    int charsToIndex = atLeast(100000);\n    int charsIndexed = 0;\n    //System.out.println(\"bytesToIndex=\" + charsToIndex);\n    while(charsIndexed < charsToIndex) {\n      Document doc = docs.nextDoc();\n      charsIndexed += doc.get(\"body\").length();\n      w.addDocument(doc);\n      //System.out.println(\"  bytes=\" + charsIndexed + \" add: \" + doc);\n    }\n    IndexReader r = w.getReader();\n    //System.out.println(\"numDocs=\" + r.numDocs());\n    w.shutdown();\n\n    final IndexSearcher s = newSearcher(r);\n    Terms terms = MultiFields.getFields(r).terms(\"body\");\n    int termCount = 0;\n    TermsEnum termsEnum = terms.iterator(null);\n    while(termsEnum.next() != null) {\n      termCount++;\n    }\n    assertTrue(termCount > 0);\n    \n    // Target ~10 terms to search:\n    double chance = 10.0 / termCount;\n    termsEnum = terms.iterator(termsEnum);\n    final Map<BytesRef,TopDocs> answers = new HashMap<>();\n    while(termsEnum.next() != null) {\n      if (random().nextDouble() <= chance) {\n        BytesRef term = BytesRef.deepCopyOf(termsEnum.term());\n        answers.put(term,\n                    s.search(new TermQuery(new Term(\"body\", term)), 100));\n      }\n    }\n\n    if (!answers.isEmpty()) {\n      final CountDownLatch startingGun = new CountDownLatch(1);\n      int numThreads = TestUtil.nextInt(random(), 2, 5);\n      Thread[] threads = new Thread[numThreads];\n      for(int threadID=0;threadID<numThreads;threadID++) {\n        Thread thread = new Thread() {\n            @Override\n            public void run() {\n              try {\n                startingGun.await();\n                for(int i=0;i<20;i++) {\n                  List<Map.Entry<BytesRef,TopDocs>> shuffled = new ArrayList<>(answers.entrySet());\n                  Collections.shuffle(shuffled);\n                  for(Map.Entry<BytesRef,TopDocs> ent : shuffled) {\n                    TopDocs actual = s.search(new TermQuery(new Term(\"body\", ent.getKey())), 100);\n                    TopDocs expected = ent.getValue();\n                    assertEquals(expected.totalHits, actual.totalHits);\n                    assertEquals(\"query=\" + ent.getKey().utf8ToString(), expected.scoreDocs.length, actual.scoreDocs.length);\n                    for(int hit=0;hit<expected.scoreDocs.length;hit++) {\n                      assertEquals(expected.scoreDocs[hit].doc, actual.scoreDocs[hit].doc);\n                      // Floats really should be identical:\n                      assertTrue(expected.scoreDocs[hit].score == actual.scoreDocs[hit].score);\n                    }\n                  }\n                }\n              } catch (Exception e) {\n                throw new RuntimeException(e);\n              }\n            }\n          };\n        threads[threadID] = thread;\n        thread.start();\n      }\n      startingGun.countDown();\n      for(Thread thread : threads) {\n        thread.join();\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"103857ec20f79f31c7a00310a91ed001b9a6ef17","date":1412698959,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestSameScoresWithThreads#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestSameScoresWithThreads#test().mjava","sourceNew":"  public void test() throws Exception {\n    final Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir, analyzer);\n    LineFileDocs docs = new LineFileDocs(random());\n    int charsToIndex = atLeast(100000);\n    int charsIndexed = 0;\n    //System.out.println(\"bytesToIndex=\" + charsToIndex);\n    while(charsIndexed < charsToIndex) {\n      Document doc = docs.nextDoc();\n      charsIndexed += doc.get(\"body\").length();\n      w.addDocument(doc);\n      //System.out.println(\"  bytes=\" + charsIndexed + \" add: \" + doc);\n    }\n    IndexReader r = w.getReader();\n    //System.out.println(\"numDocs=\" + r.numDocs());\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    Terms terms = MultiFields.getFields(r).terms(\"body\");\n    int termCount = 0;\n    TermsEnum termsEnum = terms.iterator(null);\n    while(termsEnum.next() != null) {\n      termCount++;\n    }\n    assertTrue(termCount > 0);\n    \n    // Target ~10 terms to search:\n    double chance = 10.0 / termCount;\n    termsEnum = terms.iterator(termsEnum);\n    final Map<BytesRef,TopDocs> answers = new HashMap<>();\n    while(termsEnum.next() != null) {\n      if (random().nextDouble() <= chance) {\n        BytesRef term = BytesRef.deepCopyOf(termsEnum.term());\n        answers.put(term,\n                    s.search(new TermQuery(new Term(\"body\", term)), 100));\n      }\n    }\n\n    if (!answers.isEmpty()) {\n      final CountDownLatch startingGun = new CountDownLatch(1);\n      int numThreads = TestUtil.nextInt(random(), 2, 5);\n      Thread[] threads = new Thread[numThreads];\n      for(int threadID=0;threadID<numThreads;threadID++) {\n        Thread thread = new Thread() {\n            @Override\n            public void run() {\n              try {\n                startingGun.await();\n                for(int i=0;i<20;i++) {\n                  List<Map.Entry<BytesRef,TopDocs>> shuffled = new ArrayList<>(answers.entrySet());\n                  Collections.shuffle(shuffled, random());\n                  for(Map.Entry<BytesRef,TopDocs> ent : shuffled) {\n                    TopDocs actual = s.search(new TermQuery(new Term(\"body\", ent.getKey())), 100);\n                    TopDocs expected = ent.getValue();\n                    assertEquals(expected.totalHits, actual.totalHits);\n                    assertEquals(\"query=\" + ent.getKey().utf8ToString(), expected.scoreDocs.length, actual.scoreDocs.length);\n                    for(int hit=0;hit<expected.scoreDocs.length;hit++) {\n                      assertEquals(expected.scoreDocs[hit].doc, actual.scoreDocs[hit].doc);\n                      // Floats really should be identical:\n                      assertTrue(expected.scoreDocs[hit].score == actual.scoreDocs[hit].score);\n                    }\n                  }\n                }\n              } catch (Exception e) {\n                throw new RuntimeException(e);\n              }\n            }\n          };\n        threads[threadID] = thread;\n        thread.start();\n      }\n      startingGun.countDown();\n      for(Thread thread : threads) {\n        thread.join();\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    final Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir, analyzer);\n    LineFileDocs docs = new LineFileDocs(random());\n    int charsToIndex = atLeast(100000);\n    int charsIndexed = 0;\n    //System.out.println(\"bytesToIndex=\" + charsToIndex);\n    while(charsIndexed < charsToIndex) {\n      Document doc = docs.nextDoc();\n      charsIndexed += doc.get(\"body\").length();\n      w.addDocument(doc);\n      //System.out.println(\"  bytes=\" + charsIndexed + \" add: \" + doc);\n    }\n    IndexReader r = w.getReader();\n    //System.out.println(\"numDocs=\" + r.numDocs());\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    Terms terms = MultiFields.getFields(r).terms(\"body\");\n    int termCount = 0;\n    TermsEnum termsEnum = terms.iterator(null);\n    while(termsEnum.next() != null) {\n      termCount++;\n    }\n    assertTrue(termCount > 0);\n    \n    // Target ~10 terms to search:\n    double chance = 10.0 / termCount;\n    termsEnum = terms.iterator(termsEnum);\n    final Map<BytesRef,TopDocs> answers = new HashMap<>();\n    while(termsEnum.next() != null) {\n      if (random().nextDouble() <= chance) {\n        BytesRef term = BytesRef.deepCopyOf(termsEnum.term());\n        answers.put(term,\n                    s.search(new TermQuery(new Term(\"body\", term)), 100));\n      }\n    }\n\n    if (!answers.isEmpty()) {\n      final CountDownLatch startingGun = new CountDownLatch(1);\n      int numThreads = TestUtil.nextInt(random(), 2, 5);\n      Thread[] threads = new Thread[numThreads];\n      for(int threadID=0;threadID<numThreads;threadID++) {\n        Thread thread = new Thread() {\n            @Override\n            public void run() {\n              try {\n                startingGun.await();\n                for(int i=0;i<20;i++) {\n                  List<Map.Entry<BytesRef,TopDocs>> shuffled = new ArrayList<>(answers.entrySet());\n                  Collections.shuffle(shuffled);\n                  for(Map.Entry<BytesRef,TopDocs> ent : shuffled) {\n                    TopDocs actual = s.search(new TermQuery(new Term(\"body\", ent.getKey())), 100);\n                    TopDocs expected = ent.getValue();\n                    assertEquals(expected.totalHits, actual.totalHits);\n                    assertEquals(\"query=\" + ent.getKey().utf8ToString(), expected.scoreDocs.length, actual.scoreDocs.length);\n                    for(int hit=0;hit<expected.scoreDocs.length;hit++) {\n                      assertEquals(expected.scoreDocs[hit].doc, actual.scoreDocs[hit].doc);\n                      // Floats really should be identical:\n                      assertTrue(expected.scoreDocs[hit].score == actual.scoreDocs[hit].score);\n                    }\n                  }\n                }\n              } catch (Exception e) {\n                throw new RuntimeException(e);\n              }\n            }\n          };\n        threads[threadID] = thread;\n        thread.start();\n      }\n      startingGun.countDown();\n      for(Thread thread : threads) {\n        thread.join();\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","bugFix":["485a1f8ad4bcc0abb22a65e9f7fa57946ee03202"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"55980207f1977bd1463465de1659b821347e2fa8","date":1413336386,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestSameScoresWithThreads#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestSameScoresWithThreads#test().mjava","sourceNew":"  public void test() throws Exception {\n    final Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir, analyzer);\n    LineFileDocs docs = new LineFileDocs(random());\n    int charsToIndex = atLeast(100000);\n    int charsIndexed = 0;\n    //System.out.println(\"bytesToIndex=\" + charsToIndex);\n    while(charsIndexed < charsToIndex) {\n      Document doc = docs.nextDoc();\n      charsIndexed += doc.get(\"body\").length();\n      w.addDocument(doc);\n      //System.out.println(\"  bytes=\" + charsIndexed + \" add: \" + doc);\n    }\n    IndexReader r = w.getReader();\n    //System.out.println(\"numDocs=\" + r.numDocs());\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    Terms terms = MultiFields.getFields(r).terms(\"body\");\n    int termCount = 0;\n    TermsEnum termsEnum = terms.iterator(null);\n    while(termsEnum.next() != null) {\n      termCount++;\n    }\n    assertTrue(termCount > 0);\n    \n    // Target ~10 terms to search:\n    double chance = 10.0 / termCount;\n    termsEnum = terms.iterator(termsEnum);\n    final Map<BytesRef,TopDocs> answers = new HashMap<>();\n    while(termsEnum.next() != null) {\n      if (random().nextDouble() <= chance) {\n        BytesRef term = BytesRef.deepCopyOf(termsEnum.term());\n        answers.put(term,\n                    s.search(new TermQuery(new Term(\"body\", term)), 100));\n      }\n    }\n\n    if (!answers.isEmpty()) {\n      final CountDownLatch startingGun = new CountDownLatch(1);\n      int numThreads = TestUtil.nextInt(random(), 2, 5);\n      Thread[] threads = new Thread[numThreads];\n      for(int threadID=0;threadID<numThreads;threadID++) {\n        Thread thread = new Thread() {\n            @Override\n            public void run() {\n              try {\n                startingGun.await();\n                for(int i=0;i<20;i++) {\n                  List<Map.Entry<BytesRef,TopDocs>> shuffled = new ArrayList<>(answers.entrySet());\n                  Collections.shuffle(shuffled, random());\n                  for(Map.Entry<BytesRef,TopDocs> ent : shuffled) {\n                    TopDocs actual = s.search(new TermQuery(new Term(\"body\", ent.getKey())), 100);\n                    TopDocs expected = ent.getValue();\n                    assertEquals(expected.totalHits, actual.totalHits);\n                    assertEquals(\"query=\" + ent.getKey().utf8ToString(), expected.scoreDocs.length, actual.scoreDocs.length);\n                    for(int hit=0;hit<expected.scoreDocs.length;hit++) {\n                      assertEquals(expected.scoreDocs[hit].doc, actual.scoreDocs[hit].doc);\n                      // Floats really should be identical:\n                      assertTrue(expected.scoreDocs[hit].score == actual.scoreDocs[hit].score);\n                    }\n                  }\n                }\n              } catch (Exception e) {\n                throw new RuntimeException(e);\n              }\n            }\n          };\n        threads[threadID] = thread;\n        thread.start();\n      }\n      startingGun.countDown();\n      for(Thread thread : threads) {\n        thread.join();\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    final Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir, analyzer);\n    LineFileDocs docs = new LineFileDocs(random());\n    int charsToIndex = atLeast(100000);\n    int charsIndexed = 0;\n    //System.out.println(\"bytesToIndex=\" + charsToIndex);\n    while(charsIndexed < charsToIndex) {\n      Document doc = docs.nextDoc();\n      charsIndexed += doc.get(\"body\").length();\n      w.addDocument(doc);\n      //System.out.println(\"  bytes=\" + charsIndexed + \" add: \" + doc);\n    }\n    IndexReader r = w.getReader();\n    //System.out.println(\"numDocs=\" + r.numDocs());\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    Terms terms = MultiFields.getFields(r).terms(\"body\");\n    int termCount = 0;\n    TermsEnum termsEnum = terms.iterator(null);\n    while(termsEnum.next() != null) {\n      termCount++;\n    }\n    assertTrue(termCount > 0);\n    \n    // Target ~10 terms to search:\n    double chance = 10.0 / termCount;\n    termsEnum = terms.iterator(termsEnum);\n    final Map<BytesRef,TopDocs> answers = new HashMap<>();\n    while(termsEnum.next() != null) {\n      if (random().nextDouble() <= chance) {\n        BytesRef term = BytesRef.deepCopyOf(termsEnum.term());\n        answers.put(term,\n                    s.search(new TermQuery(new Term(\"body\", term)), 100));\n      }\n    }\n\n    if (!answers.isEmpty()) {\n      final CountDownLatch startingGun = new CountDownLatch(1);\n      int numThreads = TestUtil.nextInt(random(), 2, 5);\n      Thread[] threads = new Thread[numThreads];\n      for(int threadID=0;threadID<numThreads;threadID++) {\n        Thread thread = new Thread() {\n            @Override\n            public void run() {\n              try {\n                startingGun.await();\n                for(int i=0;i<20;i++) {\n                  List<Map.Entry<BytesRef,TopDocs>> shuffled = new ArrayList<>(answers.entrySet());\n                  Collections.shuffle(shuffled);\n                  for(Map.Entry<BytesRef,TopDocs> ent : shuffled) {\n                    TopDocs actual = s.search(new TermQuery(new Term(\"body\", ent.getKey())), 100);\n                    TopDocs expected = ent.getValue();\n                    assertEquals(expected.totalHits, actual.totalHits);\n                    assertEquals(\"query=\" + ent.getKey().utf8ToString(), expected.scoreDocs.length, actual.scoreDocs.length);\n                    for(int hit=0;hit<expected.scoreDocs.length;hit++) {\n                      assertEquals(expected.scoreDocs[hit].doc, actual.scoreDocs[hit].doc);\n                      // Floats really should be identical:\n                      assertTrue(expected.scoreDocs[hit].score == actual.scoreDocs[hit].score);\n                    }\n                  }\n                }\n              } catch (Exception e) {\n                throw new RuntimeException(e);\n              }\n            }\n          };\n        threads[threadID] = thread;\n        thread.start();\n      }\n      startingGun.countDown();\n      for(Thread thread : threads) {\n        thread.join();\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82","date":1428522487,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestSameScoresWithThreads#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestSameScoresWithThreads#test().mjava","sourceNew":"  public void test() throws Exception {\n    final Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir, analyzer);\n    LineFileDocs docs = new LineFileDocs(random());\n    int charsToIndex = atLeast(100000);\n    int charsIndexed = 0;\n    //System.out.println(\"bytesToIndex=\" + charsToIndex);\n    while(charsIndexed < charsToIndex) {\n      Document doc = docs.nextDoc();\n      charsIndexed += doc.get(\"body\").length();\n      w.addDocument(doc);\n      //System.out.println(\"  bytes=\" + charsIndexed + \" add: \" + doc);\n    }\n    IndexReader r = w.getReader();\n    //System.out.println(\"numDocs=\" + r.numDocs());\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    Terms terms = MultiFields.getFields(r).terms(\"body\");\n    int termCount = 0;\n    TermsEnum termsEnum = terms.iterator();\n    while(termsEnum.next() != null) {\n      termCount++;\n    }\n    assertTrue(termCount > 0);\n    \n    // Target ~10 terms to search:\n    double chance = 10.0 / termCount;\n    termsEnum = terms.iterator();\n    final Map<BytesRef,TopDocs> answers = new HashMap<>();\n    while(termsEnum.next() != null) {\n      if (random().nextDouble() <= chance) {\n        BytesRef term = BytesRef.deepCopyOf(termsEnum.term());\n        answers.put(term,\n                    s.search(new TermQuery(new Term(\"body\", term)), 100));\n      }\n    }\n\n    if (!answers.isEmpty()) {\n      final CountDownLatch startingGun = new CountDownLatch(1);\n      int numThreads = TestUtil.nextInt(random(), 2, 5);\n      Thread[] threads = new Thread[numThreads];\n      for(int threadID=0;threadID<numThreads;threadID++) {\n        Thread thread = new Thread() {\n            @Override\n            public void run() {\n              try {\n                startingGun.await();\n                for(int i=0;i<20;i++) {\n                  List<Map.Entry<BytesRef,TopDocs>> shuffled = new ArrayList<>(answers.entrySet());\n                  Collections.shuffle(shuffled, random());\n                  for(Map.Entry<BytesRef,TopDocs> ent : shuffled) {\n                    TopDocs actual = s.search(new TermQuery(new Term(\"body\", ent.getKey())), 100);\n                    TopDocs expected = ent.getValue();\n                    assertEquals(expected.totalHits, actual.totalHits);\n                    assertEquals(\"query=\" + ent.getKey().utf8ToString(), expected.scoreDocs.length, actual.scoreDocs.length);\n                    for(int hit=0;hit<expected.scoreDocs.length;hit++) {\n                      assertEquals(expected.scoreDocs[hit].doc, actual.scoreDocs[hit].doc);\n                      // Floats really should be identical:\n                      assertTrue(expected.scoreDocs[hit].score == actual.scoreDocs[hit].score);\n                    }\n                  }\n                }\n              } catch (Exception e) {\n                throw new RuntimeException(e);\n              }\n            }\n          };\n        threads[threadID] = thread;\n        thread.start();\n      }\n      startingGun.countDown();\n      for(Thread thread : threads) {\n        thread.join();\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    final Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir, analyzer);\n    LineFileDocs docs = new LineFileDocs(random());\n    int charsToIndex = atLeast(100000);\n    int charsIndexed = 0;\n    //System.out.println(\"bytesToIndex=\" + charsToIndex);\n    while(charsIndexed < charsToIndex) {\n      Document doc = docs.nextDoc();\n      charsIndexed += doc.get(\"body\").length();\n      w.addDocument(doc);\n      //System.out.println(\"  bytes=\" + charsIndexed + \" add: \" + doc);\n    }\n    IndexReader r = w.getReader();\n    //System.out.println(\"numDocs=\" + r.numDocs());\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    Terms terms = MultiFields.getFields(r).terms(\"body\");\n    int termCount = 0;\n    TermsEnum termsEnum = terms.iterator(null);\n    while(termsEnum.next() != null) {\n      termCount++;\n    }\n    assertTrue(termCount > 0);\n    \n    // Target ~10 terms to search:\n    double chance = 10.0 / termCount;\n    termsEnum = terms.iterator(termsEnum);\n    final Map<BytesRef,TopDocs> answers = new HashMap<>();\n    while(termsEnum.next() != null) {\n      if (random().nextDouble() <= chance) {\n        BytesRef term = BytesRef.deepCopyOf(termsEnum.term());\n        answers.put(term,\n                    s.search(new TermQuery(new Term(\"body\", term)), 100));\n      }\n    }\n\n    if (!answers.isEmpty()) {\n      final CountDownLatch startingGun = new CountDownLatch(1);\n      int numThreads = TestUtil.nextInt(random(), 2, 5);\n      Thread[] threads = new Thread[numThreads];\n      for(int threadID=0;threadID<numThreads;threadID++) {\n        Thread thread = new Thread() {\n            @Override\n            public void run() {\n              try {\n                startingGun.await();\n                for(int i=0;i<20;i++) {\n                  List<Map.Entry<BytesRef,TopDocs>> shuffled = new ArrayList<>(answers.entrySet());\n                  Collections.shuffle(shuffled, random());\n                  for(Map.Entry<BytesRef,TopDocs> ent : shuffled) {\n                    TopDocs actual = s.search(new TermQuery(new Term(\"body\", ent.getKey())), 100);\n                    TopDocs expected = ent.getValue();\n                    assertEquals(expected.totalHits, actual.totalHits);\n                    assertEquals(\"query=\" + ent.getKey().utf8ToString(), expected.scoreDocs.length, actual.scoreDocs.length);\n                    for(int hit=0;hit<expected.scoreDocs.length;hit++) {\n                      assertEquals(expected.scoreDocs[hit].doc, actual.scoreDocs[hit].doc);\n                      // Floats really should be identical:\n                      assertTrue(expected.scoreDocs[hit].score == actual.scoreDocs[hit].score);\n                    }\n                  }\n                }\n              } catch (Exception e) {\n                throw new RuntimeException(e);\n              }\n            }\n          };\n        threads[threadID] = thread;\n        thread.start();\n      }\n      startingGun.countDown();\n      for(Thread thread : threads) {\n        thread.join();\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e588e8c82e32e29ef3837c0b06a2ad34f3c51a2b","date":1497408244,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestSameScoresWithThreads#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestSameScoresWithThreads#test().mjava","sourceNew":"  public void test() throws Exception {\n    final Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir, analyzer);\n    LineFileDocs docs = new LineFileDocs(random());\n    int charsToIndex = atLeast(100000);\n    int charsIndexed = 0;\n    //System.out.println(\"bytesToIndex=\" + charsToIndex);\n    while(charsIndexed < charsToIndex) {\n      Document doc = docs.nextDoc();\n      charsIndexed += doc.get(\"body\").length();\n      w.addDocument(doc);\n      //System.out.println(\"  bytes=\" + charsIndexed + \" add: \" + doc);\n    }\n    IndexReader r = w.getReader();\n    //System.out.println(\"numDocs=\" + r.numDocs());\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    Terms terms = MultiFields.getTerms(r, \"body\");\n    int termCount = 0;\n    TermsEnum termsEnum = terms.iterator();\n    while(termsEnum.next() != null) {\n      termCount++;\n    }\n    assertTrue(termCount > 0);\n    \n    // Target ~10 terms to search:\n    double chance = 10.0 / termCount;\n    termsEnum = terms.iterator();\n    final Map<BytesRef,TopDocs> answers = new HashMap<>();\n    while(termsEnum.next() != null) {\n      if (random().nextDouble() <= chance) {\n        BytesRef term = BytesRef.deepCopyOf(termsEnum.term());\n        answers.put(term,\n                    s.search(new TermQuery(new Term(\"body\", term)), 100));\n      }\n    }\n\n    if (!answers.isEmpty()) {\n      final CountDownLatch startingGun = new CountDownLatch(1);\n      int numThreads = TestUtil.nextInt(random(), 2, 5);\n      Thread[] threads = new Thread[numThreads];\n      for(int threadID=0;threadID<numThreads;threadID++) {\n        Thread thread = new Thread() {\n            @Override\n            public void run() {\n              try {\n                startingGun.await();\n                for(int i=0;i<20;i++) {\n                  List<Map.Entry<BytesRef,TopDocs>> shuffled = new ArrayList<>(answers.entrySet());\n                  Collections.shuffle(shuffled, random());\n                  for(Map.Entry<BytesRef,TopDocs> ent : shuffled) {\n                    TopDocs actual = s.search(new TermQuery(new Term(\"body\", ent.getKey())), 100);\n                    TopDocs expected = ent.getValue();\n                    assertEquals(expected.totalHits, actual.totalHits);\n                    assertEquals(\"query=\" + ent.getKey().utf8ToString(), expected.scoreDocs.length, actual.scoreDocs.length);\n                    for(int hit=0;hit<expected.scoreDocs.length;hit++) {\n                      assertEquals(expected.scoreDocs[hit].doc, actual.scoreDocs[hit].doc);\n                      // Floats really should be identical:\n                      assertTrue(expected.scoreDocs[hit].score == actual.scoreDocs[hit].score);\n                    }\n                  }\n                }\n              } catch (Exception e) {\n                throw new RuntimeException(e);\n              }\n            }\n          };\n        threads[threadID] = thread;\n        thread.start();\n      }\n      startingGun.countDown();\n      for(Thread thread : threads) {\n        thread.join();\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    final Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir, analyzer);\n    LineFileDocs docs = new LineFileDocs(random());\n    int charsToIndex = atLeast(100000);\n    int charsIndexed = 0;\n    //System.out.println(\"bytesToIndex=\" + charsToIndex);\n    while(charsIndexed < charsToIndex) {\n      Document doc = docs.nextDoc();\n      charsIndexed += doc.get(\"body\").length();\n      w.addDocument(doc);\n      //System.out.println(\"  bytes=\" + charsIndexed + \" add: \" + doc);\n    }\n    IndexReader r = w.getReader();\n    //System.out.println(\"numDocs=\" + r.numDocs());\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    Terms terms = MultiFields.getFields(r).terms(\"body\");\n    int termCount = 0;\n    TermsEnum termsEnum = terms.iterator();\n    while(termsEnum.next() != null) {\n      termCount++;\n    }\n    assertTrue(termCount > 0);\n    \n    // Target ~10 terms to search:\n    double chance = 10.0 / termCount;\n    termsEnum = terms.iterator();\n    final Map<BytesRef,TopDocs> answers = new HashMap<>();\n    while(termsEnum.next() != null) {\n      if (random().nextDouble() <= chance) {\n        BytesRef term = BytesRef.deepCopyOf(termsEnum.term());\n        answers.put(term,\n                    s.search(new TermQuery(new Term(\"body\", term)), 100));\n      }\n    }\n\n    if (!answers.isEmpty()) {\n      final CountDownLatch startingGun = new CountDownLatch(1);\n      int numThreads = TestUtil.nextInt(random(), 2, 5);\n      Thread[] threads = new Thread[numThreads];\n      for(int threadID=0;threadID<numThreads;threadID++) {\n        Thread thread = new Thread() {\n            @Override\n            public void run() {\n              try {\n                startingGun.await();\n                for(int i=0;i<20;i++) {\n                  List<Map.Entry<BytesRef,TopDocs>> shuffled = new ArrayList<>(answers.entrySet());\n                  Collections.shuffle(shuffled, random());\n                  for(Map.Entry<BytesRef,TopDocs> ent : shuffled) {\n                    TopDocs actual = s.search(new TermQuery(new Term(\"body\", ent.getKey())), 100);\n                    TopDocs expected = ent.getValue();\n                    assertEquals(expected.totalHits, actual.totalHits);\n                    assertEquals(\"query=\" + ent.getKey().utf8ToString(), expected.scoreDocs.length, actual.scoreDocs.length);\n                    for(int hit=0;hit<expected.scoreDocs.length;hit++) {\n                      assertEquals(expected.scoreDocs[hit].doc, actual.scoreDocs[hit].doc);\n                      // Floats really should be identical:\n                      assertTrue(expected.scoreDocs[hit].score == actual.scoreDocs[hit].score);\n                    }\n                  }\n                }\n              } catch (Exception e) {\n                throw new RuntimeException(e);\n              }\n            }\n          };\n        threads[threadID] = thread;\n        thread.start();\n      }\n      startingGun.countDown();\n      for(Thread thread : threads) {\n        thread.join();\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9","date":1498028748,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestSameScoresWithThreads#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestSameScoresWithThreads#test().mjava","sourceNew":"  public void test() throws Exception {\n    final Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir, analyzer);\n    LineFileDocs docs = new LineFileDocs(random());\n    int charsToIndex = atLeast(100000);\n    int charsIndexed = 0;\n    //System.out.println(\"bytesToIndex=\" + charsToIndex);\n    while(charsIndexed < charsToIndex) {\n      Document doc = docs.nextDoc();\n      charsIndexed += doc.get(\"body\").length();\n      w.addDocument(doc);\n      //System.out.println(\"  bytes=\" + charsIndexed + \" add: \" + doc);\n    }\n    IndexReader r = w.getReader();\n    //System.out.println(\"numDocs=\" + r.numDocs());\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    Terms terms = MultiFields.getTerms(r, \"body\");\n    int termCount = 0;\n    TermsEnum termsEnum = terms.iterator();\n    while(termsEnum.next() != null) {\n      termCount++;\n    }\n    assertTrue(termCount > 0);\n    \n    // Target ~10 terms to search:\n    double chance = 10.0 / termCount;\n    termsEnum = terms.iterator();\n    final Map<BytesRef,TopDocs> answers = new HashMap<>();\n    while(termsEnum.next() != null) {\n      if (random().nextDouble() <= chance) {\n        BytesRef term = BytesRef.deepCopyOf(termsEnum.term());\n        answers.put(term,\n                    s.search(new TermQuery(new Term(\"body\", term)), 100));\n      }\n    }\n\n    if (!answers.isEmpty()) {\n      final CountDownLatch startingGun = new CountDownLatch(1);\n      int numThreads = TestUtil.nextInt(random(), 2, 5);\n      Thread[] threads = new Thread[numThreads];\n      for(int threadID=0;threadID<numThreads;threadID++) {\n        Thread thread = new Thread() {\n            @Override\n            public void run() {\n              try {\n                startingGun.await();\n                for(int i=0;i<20;i++) {\n                  List<Map.Entry<BytesRef,TopDocs>> shuffled = new ArrayList<>(answers.entrySet());\n                  Collections.shuffle(shuffled, random());\n                  for(Map.Entry<BytesRef,TopDocs> ent : shuffled) {\n                    TopDocs actual = s.search(new TermQuery(new Term(\"body\", ent.getKey())), 100);\n                    TopDocs expected = ent.getValue();\n                    assertEquals(expected.totalHits, actual.totalHits);\n                    assertEquals(\"query=\" + ent.getKey().utf8ToString(), expected.scoreDocs.length, actual.scoreDocs.length);\n                    for(int hit=0;hit<expected.scoreDocs.length;hit++) {\n                      assertEquals(expected.scoreDocs[hit].doc, actual.scoreDocs[hit].doc);\n                      // Floats really should be identical:\n                      assertTrue(expected.scoreDocs[hit].score == actual.scoreDocs[hit].score);\n                    }\n                  }\n                }\n              } catch (Exception e) {\n                throw new RuntimeException(e);\n              }\n            }\n          };\n        threads[threadID] = thread;\n        thread.start();\n      }\n      startingGun.countDown();\n      for(Thread thread : threads) {\n        thread.join();\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    final Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir, analyzer);\n    LineFileDocs docs = new LineFileDocs(random());\n    int charsToIndex = atLeast(100000);\n    int charsIndexed = 0;\n    //System.out.println(\"bytesToIndex=\" + charsToIndex);\n    while(charsIndexed < charsToIndex) {\n      Document doc = docs.nextDoc();\n      charsIndexed += doc.get(\"body\").length();\n      w.addDocument(doc);\n      //System.out.println(\"  bytes=\" + charsIndexed + \" add: \" + doc);\n    }\n    IndexReader r = w.getReader();\n    //System.out.println(\"numDocs=\" + r.numDocs());\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    Terms terms = MultiFields.getFields(r).terms(\"body\");\n    int termCount = 0;\n    TermsEnum termsEnum = terms.iterator();\n    while(termsEnum.next() != null) {\n      termCount++;\n    }\n    assertTrue(termCount > 0);\n    \n    // Target ~10 terms to search:\n    double chance = 10.0 / termCount;\n    termsEnum = terms.iterator();\n    final Map<BytesRef,TopDocs> answers = new HashMap<>();\n    while(termsEnum.next() != null) {\n      if (random().nextDouble() <= chance) {\n        BytesRef term = BytesRef.deepCopyOf(termsEnum.term());\n        answers.put(term,\n                    s.search(new TermQuery(new Term(\"body\", term)), 100));\n      }\n    }\n\n    if (!answers.isEmpty()) {\n      final CountDownLatch startingGun = new CountDownLatch(1);\n      int numThreads = TestUtil.nextInt(random(), 2, 5);\n      Thread[] threads = new Thread[numThreads];\n      for(int threadID=0;threadID<numThreads;threadID++) {\n        Thread thread = new Thread() {\n            @Override\n            public void run() {\n              try {\n                startingGun.await();\n                for(int i=0;i<20;i++) {\n                  List<Map.Entry<BytesRef,TopDocs>> shuffled = new ArrayList<>(answers.entrySet());\n                  Collections.shuffle(shuffled, random());\n                  for(Map.Entry<BytesRef,TopDocs> ent : shuffled) {\n                    TopDocs actual = s.search(new TermQuery(new Term(\"body\", ent.getKey())), 100);\n                    TopDocs expected = ent.getValue();\n                    assertEquals(expected.totalHits, actual.totalHits);\n                    assertEquals(\"query=\" + ent.getKey().utf8ToString(), expected.scoreDocs.length, actual.scoreDocs.length);\n                    for(int hit=0;hit<expected.scoreDocs.length;hit++) {\n                      assertEquals(expected.scoreDocs[hit].doc, actual.scoreDocs[hit].doc);\n                      // Floats really should be identical:\n                      assertTrue(expected.scoreDocs[hit].score == actual.scoreDocs[hit].score);\n                    }\n                  }\n                }\n              } catch (Exception e) {\n                throw new RuntimeException(e);\n              }\n            }\n          };\n        threads[threadID] = thread;\n        thread.start();\n      }\n      startingGun.countDown();\n      for(Thread thread : threads) {\n        thread.join();\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"28288370235ed02234a64753cdbf0c6ec096304a","date":1498726817,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestSameScoresWithThreads#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestSameScoresWithThreads#test().mjava","sourceNew":"  public void test() throws Exception {\n    final Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir, analyzer);\n    LineFileDocs docs = new LineFileDocs(random());\n    int charsToIndex = atLeast(100000);\n    int charsIndexed = 0;\n    //System.out.println(\"bytesToIndex=\" + charsToIndex);\n    while(charsIndexed < charsToIndex) {\n      Document doc = docs.nextDoc();\n      charsIndexed += doc.get(\"body\").length();\n      w.addDocument(doc);\n      //System.out.println(\"  bytes=\" + charsIndexed + \" add: \" + doc);\n    }\n    IndexReader r = w.getReader();\n    //System.out.println(\"numDocs=\" + r.numDocs());\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    Terms terms = MultiFields.getTerms(r, \"body\");\n    int termCount = 0;\n    TermsEnum termsEnum = terms.iterator();\n    while(termsEnum.next() != null) {\n      termCount++;\n    }\n    assertTrue(termCount > 0);\n    \n    // Target ~10 terms to search:\n    double chance = 10.0 / termCount;\n    termsEnum = terms.iterator();\n    final Map<BytesRef,TopDocs> answers = new HashMap<>();\n    while(termsEnum.next() != null) {\n      if (random().nextDouble() <= chance) {\n        BytesRef term = BytesRef.deepCopyOf(termsEnum.term());\n        answers.put(term,\n                    s.search(new TermQuery(new Term(\"body\", term)), 100));\n      }\n    }\n\n    if (!answers.isEmpty()) {\n      final CountDownLatch startingGun = new CountDownLatch(1);\n      int numThreads = TestUtil.nextInt(random(), 2, 5);\n      Thread[] threads = new Thread[numThreads];\n      for(int threadID=0;threadID<numThreads;threadID++) {\n        Thread thread = new Thread() {\n            @Override\n            public void run() {\n              try {\n                startingGun.await();\n                for(int i=0;i<20;i++) {\n                  List<Map.Entry<BytesRef,TopDocs>> shuffled = new ArrayList<>(answers.entrySet());\n                  Collections.shuffle(shuffled, random());\n                  for(Map.Entry<BytesRef,TopDocs> ent : shuffled) {\n                    TopDocs actual = s.search(new TermQuery(new Term(\"body\", ent.getKey())), 100);\n                    TopDocs expected = ent.getValue();\n                    assertEquals(expected.totalHits, actual.totalHits);\n                    assertEquals(\"query=\" + ent.getKey().utf8ToString(), expected.scoreDocs.length, actual.scoreDocs.length);\n                    for(int hit=0;hit<expected.scoreDocs.length;hit++) {\n                      assertEquals(expected.scoreDocs[hit].doc, actual.scoreDocs[hit].doc);\n                      // Floats really should be identical:\n                      assertTrue(expected.scoreDocs[hit].score == actual.scoreDocs[hit].score);\n                    }\n                  }\n                }\n              } catch (Exception e) {\n                throw new RuntimeException(e);\n              }\n            }\n          };\n        threads[threadID] = thread;\n        thread.start();\n      }\n      startingGun.countDown();\n      for(Thread thread : threads) {\n        thread.join();\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    final Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir, analyzer);\n    LineFileDocs docs = new LineFileDocs(random());\n    int charsToIndex = atLeast(100000);\n    int charsIndexed = 0;\n    //System.out.println(\"bytesToIndex=\" + charsToIndex);\n    while(charsIndexed < charsToIndex) {\n      Document doc = docs.nextDoc();\n      charsIndexed += doc.get(\"body\").length();\n      w.addDocument(doc);\n      //System.out.println(\"  bytes=\" + charsIndexed + \" add: \" + doc);\n    }\n    IndexReader r = w.getReader();\n    //System.out.println(\"numDocs=\" + r.numDocs());\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    Terms terms = MultiFields.getFields(r).terms(\"body\");\n    int termCount = 0;\n    TermsEnum termsEnum = terms.iterator();\n    while(termsEnum.next() != null) {\n      termCount++;\n    }\n    assertTrue(termCount > 0);\n    \n    // Target ~10 terms to search:\n    double chance = 10.0 / termCount;\n    termsEnum = terms.iterator();\n    final Map<BytesRef,TopDocs> answers = new HashMap<>();\n    while(termsEnum.next() != null) {\n      if (random().nextDouble() <= chance) {\n        BytesRef term = BytesRef.deepCopyOf(termsEnum.term());\n        answers.put(term,\n                    s.search(new TermQuery(new Term(\"body\", term)), 100));\n      }\n    }\n\n    if (!answers.isEmpty()) {\n      final CountDownLatch startingGun = new CountDownLatch(1);\n      int numThreads = TestUtil.nextInt(random(), 2, 5);\n      Thread[] threads = new Thread[numThreads];\n      for(int threadID=0;threadID<numThreads;threadID++) {\n        Thread thread = new Thread() {\n            @Override\n            public void run() {\n              try {\n                startingGun.await();\n                for(int i=0;i<20;i++) {\n                  List<Map.Entry<BytesRef,TopDocs>> shuffled = new ArrayList<>(answers.entrySet());\n                  Collections.shuffle(shuffled, random());\n                  for(Map.Entry<BytesRef,TopDocs> ent : shuffled) {\n                    TopDocs actual = s.search(new TermQuery(new Term(\"body\", ent.getKey())), 100);\n                    TopDocs expected = ent.getValue();\n                    assertEquals(expected.totalHits, actual.totalHits);\n                    assertEquals(\"query=\" + ent.getKey().utf8ToString(), expected.scoreDocs.length, actual.scoreDocs.length);\n                    for(int hit=0;hit<expected.scoreDocs.length;hit++) {\n                      assertEquals(expected.scoreDocs[hit].doc, actual.scoreDocs[hit].doc);\n                      // Floats really should be identical:\n                      assertTrue(expected.scoreDocs[hit].score == actual.scoreDocs[hit].score);\n                    }\n                  }\n                }\n              } catch (Exception e) {\n                throw new RuntimeException(e);\n              }\n            }\n          };\n        threads[threadID] = thread;\n        thread.start();\n      }\n      startingGun.countDown();\n      for(Thread thread : threads) {\n        thread.join();\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"83788ad129a5154d5c6562c4e8ce3db48793aada","date":1532961485,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestSameScoresWithThreads#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestSameScoresWithThreads#test().mjava","sourceNew":"  public void test() throws Exception {\n    final Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir, analyzer);\n    LineFileDocs docs = new LineFileDocs(random());\n    int charsToIndex = atLeast(100000);\n    int charsIndexed = 0;\n    //System.out.println(\"bytesToIndex=\" + charsToIndex);\n    while(charsIndexed < charsToIndex) {\n      Document doc = docs.nextDoc();\n      charsIndexed += doc.get(\"body\").length();\n      w.addDocument(doc);\n      //System.out.println(\"  bytes=\" + charsIndexed + \" add: \" + doc);\n    }\n    IndexReader r = w.getReader();\n    //System.out.println(\"numDocs=\" + r.numDocs());\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    Terms terms = MultiFields.getTerms(r, \"body\");\n    int termCount = 0;\n    TermsEnum termsEnum = terms.iterator();\n    while(termsEnum.next() != null) {\n      termCount++;\n    }\n    assertTrue(termCount > 0);\n    \n    // Target ~10 terms to search:\n    double chance = 10.0 / termCount;\n    termsEnum = terms.iterator();\n    final Map<BytesRef,TopDocs> answers = new HashMap<>();\n    while(termsEnum.next() != null) {\n      if (random().nextDouble() <= chance) {\n        BytesRef term = BytesRef.deepCopyOf(termsEnum.term());\n        answers.put(term,\n                    s.search(new TermQuery(new Term(\"body\", term)), 100));\n      }\n    }\n\n    if (!answers.isEmpty()) {\n      final CountDownLatch startingGun = new CountDownLatch(1);\n      int numThreads = TestUtil.nextInt(random(), 2, 5);\n      Thread[] threads = new Thread[numThreads];\n      for(int threadID=0;threadID<numThreads;threadID++) {\n        Thread thread = new Thread() {\n            @Override\n            public void run() {\n              try {\n                startingGun.await();\n                for(int i=0;i<20;i++) {\n                  List<Map.Entry<BytesRef,TopDocs>> shuffled = new ArrayList<>(answers.entrySet());\n                  Collections.shuffle(shuffled, random());\n                  for(Map.Entry<BytesRef,TopDocs> ent : shuffled) {\n                    TopDocs actual = s.search(new TermQuery(new Term(\"body\", ent.getKey())), 100);\n                    TopDocs expected = ent.getValue();\n                    assertEquals(expected.totalHits.value, actual.totalHits.value);\n                    assertEquals(\"query=\" + ent.getKey().utf8ToString(), expected.scoreDocs.length, actual.scoreDocs.length);\n                    for(int hit=0;hit<expected.scoreDocs.length;hit++) {\n                      assertEquals(expected.scoreDocs[hit].doc, actual.scoreDocs[hit].doc);\n                      // Floats really should be identical:\n                      assertTrue(expected.scoreDocs[hit].score == actual.scoreDocs[hit].score);\n                    }\n                  }\n                }\n              } catch (Exception e) {\n                throw new RuntimeException(e);\n              }\n            }\n          };\n        threads[threadID] = thread;\n        thread.start();\n      }\n      startingGun.countDown();\n      for(Thread thread : threads) {\n        thread.join();\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    final Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir, analyzer);\n    LineFileDocs docs = new LineFileDocs(random());\n    int charsToIndex = atLeast(100000);\n    int charsIndexed = 0;\n    //System.out.println(\"bytesToIndex=\" + charsToIndex);\n    while(charsIndexed < charsToIndex) {\n      Document doc = docs.nextDoc();\n      charsIndexed += doc.get(\"body\").length();\n      w.addDocument(doc);\n      //System.out.println(\"  bytes=\" + charsIndexed + \" add: \" + doc);\n    }\n    IndexReader r = w.getReader();\n    //System.out.println(\"numDocs=\" + r.numDocs());\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    Terms terms = MultiFields.getTerms(r, \"body\");\n    int termCount = 0;\n    TermsEnum termsEnum = terms.iterator();\n    while(termsEnum.next() != null) {\n      termCount++;\n    }\n    assertTrue(termCount > 0);\n    \n    // Target ~10 terms to search:\n    double chance = 10.0 / termCount;\n    termsEnum = terms.iterator();\n    final Map<BytesRef,TopDocs> answers = new HashMap<>();\n    while(termsEnum.next() != null) {\n      if (random().nextDouble() <= chance) {\n        BytesRef term = BytesRef.deepCopyOf(termsEnum.term());\n        answers.put(term,\n                    s.search(new TermQuery(new Term(\"body\", term)), 100));\n      }\n    }\n\n    if (!answers.isEmpty()) {\n      final CountDownLatch startingGun = new CountDownLatch(1);\n      int numThreads = TestUtil.nextInt(random(), 2, 5);\n      Thread[] threads = new Thread[numThreads];\n      for(int threadID=0;threadID<numThreads;threadID++) {\n        Thread thread = new Thread() {\n            @Override\n            public void run() {\n              try {\n                startingGun.await();\n                for(int i=0;i<20;i++) {\n                  List<Map.Entry<BytesRef,TopDocs>> shuffled = new ArrayList<>(answers.entrySet());\n                  Collections.shuffle(shuffled, random());\n                  for(Map.Entry<BytesRef,TopDocs> ent : shuffled) {\n                    TopDocs actual = s.search(new TermQuery(new Term(\"body\", ent.getKey())), 100);\n                    TopDocs expected = ent.getValue();\n                    assertEquals(expected.totalHits, actual.totalHits);\n                    assertEquals(\"query=\" + ent.getKey().utf8ToString(), expected.scoreDocs.length, actual.scoreDocs.length);\n                    for(int hit=0;hit<expected.scoreDocs.length;hit++) {\n                      assertEquals(expected.scoreDocs[hit].doc, actual.scoreDocs[hit].doc);\n                      // Floats really should be identical:\n                      assertTrue(expected.scoreDocs[hit].score == actual.scoreDocs[hit].score);\n                    }\n                  }\n                }\n              } catch (Exception e) {\n                throw new RuntimeException(e);\n              }\n            }\n          };\n        threads[threadID] = thread;\n        thread.start();\n      }\n      startingGun.countDown();\n      for(Thread thread : threads) {\n        thread.join();\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"04e775de416dd2d8067b10db1c8af975a1d5017e","date":1539906554,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestSameScoresWithThreads#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestSameScoresWithThreads#test().mjava","sourceNew":"  public void test() throws Exception {\n    final Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir, analyzer);\n    LineFileDocs docs = new LineFileDocs(random());\n    int charsToIndex = atLeast(100000);\n    int charsIndexed = 0;\n    //System.out.println(\"bytesToIndex=\" + charsToIndex);\n    while(charsIndexed < charsToIndex) {\n      Document doc = docs.nextDoc();\n      charsIndexed += doc.get(\"body\").length();\n      w.addDocument(doc);\n      //System.out.println(\"  bytes=\" + charsIndexed + \" add: \" + doc);\n    }\n    IndexReader r = w.getReader();\n    //System.out.println(\"numDocs=\" + r.numDocs());\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    Terms terms = MultiTerms.getTerms(r, \"body\");\n    int termCount = 0;\n    TermsEnum termsEnum = terms.iterator();\n    while(termsEnum.next() != null) {\n      termCount++;\n    }\n    assertTrue(termCount > 0);\n    \n    // Target ~10 terms to search:\n    double chance = 10.0 / termCount;\n    termsEnum = terms.iterator();\n    final Map<BytesRef,TopDocs> answers = new HashMap<>();\n    while(termsEnum.next() != null) {\n      if (random().nextDouble() <= chance) {\n        BytesRef term = BytesRef.deepCopyOf(termsEnum.term());\n        answers.put(term,\n                    s.search(new TermQuery(new Term(\"body\", term)), 100));\n      }\n    }\n\n    if (!answers.isEmpty()) {\n      final CountDownLatch startingGun = new CountDownLatch(1);\n      int numThreads = TestUtil.nextInt(random(), 2, 5);\n      Thread[] threads = new Thread[numThreads];\n      for(int threadID=0;threadID<numThreads;threadID++) {\n        Thread thread = new Thread() {\n            @Override\n            public void run() {\n              try {\n                startingGun.await();\n                for(int i=0;i<20;i++) {\n                  List<Map.Entry<BytesRef,TopDocs>> shuffled = new ArrayList<>(answers.entrySet());\n                  Collections.shuffle(shuffled, random());\n                  for(Map.Entry<BytesRef,TopDocs> ent : shuffled) {\n                    TopDocs actual = s.search(new TermQuery(new Term(\"body\", ent.getKey())), 100);\n                    TopDocs expected = ent.getValue();\n                    assertEquals(expected.totalHits.value, actual.totalHits.value);\n                    assertEquals(\"query=\" + ent.getKey().utf8ToString(), expected.scoreDocs.length, actual.scoreDocs.length);\n                    for(int hit=0;hit<expected.scoreDocs.length;hit++) {\n                      assertEquals(expected.scoreDocs[hit].doc, actual.scoreDocs[hit].doc);\n                      // Floats really should be identical:\n                      assertTrue(expected.scoreDocs[hit].score == actual.scoreDocs[hit].score);\n                    }\n                  }\n                }\n              } catch (Exception e) {\n                throw new RuntimeException(e);\n              }\n            }\n          };\n        threads[threadID] = thread;\n        thread.start();\n      }\n      startingGun.countDown();\n      for(Thread thread : threads) {\n        thread.join();\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    final Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir, analyzer);\n    LineFileDocs docs = new LineFileDocs(random());\n    int charsToIndex = atLeast(100000);\n    int charsIndexed = 0;\n    //System.out.println(\"bytesToIndex=\" + charsToIndex);\n    while(charsIndexed < charsToIndex) {\n      Document doc = docs.nextDoc();\n      charsIndexed += doc.get(\"body\").length();\n      w.addDocument(doc);\n      //System.out.println(\"  bytes=\" + charsIndexed + \" add: \" + doc);\n    }\n    IndexReader r = w.getReader();\n    //System.out.println(\"numDocs=\" + r.numDocs());\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    Terms terms = MultiFields.getTerms(r, \"body\");\n    int termCount = 0;\n    TermsEnum termsEnum = terms.iterator();\n    while(termsEnum.next() != null) {\n      termCount++;\n    }\n    assertTrue(termCount > 0);\n    \n    // Target ~10 terms to search:\n    double chance = 10.0 / termCount;\n    termsEnum = terms.iterator();\n    final Map<BytesRef,TopDocs> answers = new HashMap<>();\n    while(termsEnum.next() != null) {\n      if (random().nextDouble() <= chance) {\n        BytesRef term = BytesRef.deepCopyOf(termsEnum.term());\n        answers.put(term,\n                    s.search(new TermQuery(new Term(\"body\", term)), 100));\n      }\n    }\n\n    if (!answers.isEmpty()) {\n      final CountDownLatch startingGun = new CountDownLatch(1);\n      int numThreads = TestUtil.nextInt(random(), 2, 5);\n      Thread[] threads = new Thread[numThreads];\n      for(int threadID=0;threadID<numThreads;threadID++) {\n        Thread thread = new Thread() {\n            @Override\n            public void run() {\n              try {\n                startingGun.await();\n                for(int i=0;i<20;i++) {\n                  List<Map.Entry<BytesRef,TopDocs>> shuffled = new ArrayList<>(answers.entrySet());\n                  Collections.shuffle(shuffled, random());\n                  for(Map.Entry<BytesRef,TopDocs> ent : shuffled) {\n                    TopDocs actual = s.search(new TermQuery(new Term(\"body\", ent.getKey())), 100);\n                    TopDocs expected = ent.getValue();\n                    assertEquals(expected.totalHits.value, actual.totalHits.value);\n                    assertEquals(\"query=\" + ent.getKey().utf8ToString(), expected.scoreDocs.length, actual.scoreDocs.length);\n                    for(int hit=0;hit<expected.scoreDocs.length;hit++) {\n                      assertEquals(expected.scoreDocs[hit].doc, actual.scoreDocs[hit].doc);\n                      // Floats really should be identical:\n                      assertTrue(expected.scoreDocs[hit].score == actual.scoreDocs[hit].score);\n                    }\n                  }\n                }\n              } catch (Exception e) {\n                throw new RuntimeException(e);\n              }\n            }\n          };\n        threads[threadID] = thread;\n        thread.start();\n      }\n      startingGun.countDown();\n      for(Thread thread : threads) {\n        thread.join();\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4208ed8e426ae5f75a41d8b4ae53f4587e413061","date":1580475454,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestSameScoresWithThreads#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestSameScoresWithThreads#test().mjava","sourceNew":"  public void test() throws Exception {\n    final Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir, analyzer);\n    LineFileDocs docs = new LineFileDocs(random());\n    int charsToIndex = atLeast(100000);\n    int charsIndexed = 0;\n    //System.out.println(\"bytesToIndex=\" + charsToIndex);\n    while(charsIndexed < charsToIndex) {\n      Document doc = docs.nextDoc();\n      charsIndexed += doc.get(\"body\").length();\n      w.addDocument(doc);\n      //System.out.println(\"  bytes=\" + charsIndexed + \" add: \" + doc);\n    }\n    IndexReader r = w.getReader();\n    //System.out.println(\"numDocs=\" + r.numDocs());\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    Terms terms = MultiTerms.getTerms(r, \"body\");\n    int termCount = 0;\n    TermsEnum termsEnum = terms.iterator();\n    while(termsEnum.next() != null) {\n      termCount++;\n    }\n    assertTrue(termCount > 0);\n    \n    // Target ~10 terms to search:\n    double chance = 10.0 / termCount;\n    termsEnum = terms.iterator();\n    final Map<BytesRef,TopDocs> answers = new HashMap<>();\n    while(termsEnum.next() != null) {\n      if (random().nextDouble() <= chance) {\n        BytesRef term = BytesRef.deepCopyOf(termsEnum.term());\n        answers.put(term,\n                    s.search(new TermQuery(new Term(\"body\", term)), 100));\n      }\n    }\n\n    if (!answers.isEmpty()) {\n      final CountDownLatch startingGun = new CountDownLatch(1);\n      int numThreads = TEST_NIGHTLY ? TestUtil.nextInt(random(), 2, 5) : 2;\n      Thread[] threads = new Thread[numThreads];\n      for(int threadID=0;threadID<numThreads;threadID++) {\n        Thread thread = new Thread() {\n            @Override\n            public void run() {\n              try {\n                startingGun.await();\n                for(int i=0;i<20;i++) {\n                  List<Map.Entry<BytesRef,TopDocs>> shuffled = new ArrayList<>(answers.entrySet());\n                  Collections.shuffle(shuffled, random());\n                  for(Map.Entry<BytesRef,TopDocs> ent : shuffled) {\n                    TopDocs actual = s.search(new TermQuery(new Term(\"body\", ent.getKey())), 100);\n                    TopDocs expected = ent.getValue();\n                    assertEquals(expected.totalHits.value, actual.totalHits.value);\n                    assertEquals(\"query=\" + ent.getKey().utf8ToString(), expected.scoreDocs.length, actual.scoreDocs.length);\n                    for(int hit=0;hit<expected.scoreDocs.length;hit++) {\n                      assertEquals(expected.scoreDocs[hit].doc, actual.scoreDocs[hit].doc);\n                      // Floats really should be identical:\n                      assertTrue(expected.scoreDocs[hit].score == actual.scoreDocs[hit].score);\n                    }\n                  }\n                }\n              } catch (Exception e) {\n                throw new RuntimeException(e);\n              }\n            }\n          };\n        threads[threadID] = thread;\n        thread.start();\n      }\n      startingGun.countDown();\n      for(Thread thread : threads) {\n        thread.join();\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    final Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir, analyzer);\n    LineFileDocs docs = new LineFileDocs(random());\n    int charsToIndex = atLeast(100000);\n    int charsIndexed = 0;\n    //System.out.println(\"bytesToIndex=\" + charsToIndex);\n    while(charsIndexed < charsToIndex) {\n      Document doc = docs.nextDoc();\n      charsIndexed += doc.get(\"body\").length();\n      w.addDocument(doc);\n      //System.out.println(\"  bytes=\" + charsIndexed + \" add: \" + doc);\n    }\n    IndexReader r = w.getReader();\n    //System.out.println(\"numDocs=\" + r.numDocs());\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    Terms terms = MultiTerms.getTerms(r, \"body\");\n    int termCount = 0;\n    TermsEnum termsEnum = terms.iterator();\n    while(termsEnum.next() != null) {\n      termCount++;\n    }\n    assertTrue(termCount > 0);\n    \n    // Target ~10 terms to search:\n    double chance = 10.0 / termCount;\n    termsEnum = terms.iterator();\n    final Map<BytesRef,TopDocs> answers = new HashMap<>();\n    while(termsEnum.next() != null) {\n      if (random().nextDouble() <= chance) {\n        BytesRef term = BytesRef.deepCopyOf(termsEnum.term());\n        answers.put(term,\n                    s.search(new TermQuery(new Term(\"body\", term)), 100));\n      }\n    }\n\n    if (!answers.isEmpty()) {\n      final CountDownLatch startingGun = new CountDownLatch(1);\n      int numThreads = TestUtil.nextInt(random(), 2, 5);\n      Thread[] threads = new Thread[numThreads];\n      for(int threadID=0;threadID<numThreads;threadID++) {\n        Thread thread = new Thread() {\n            @Override\n            public void run() {\n              try {\n                startingGun.await();\n                for(int i=0;i<20;i++) {\n                  List<Map.Entry<BytesRef,TopDocs>> shuffled = new ArrayList<>(answers.entrySet());\n                  Collections.shuffle(shuffled, random());\n                  for(Map.Entry<BytesRef,TopDocs> ent : shuffled) {\n                    TopDocs actual = s.search(new TermQuery(new Term(\"body\", ent.getKey())), 100);\n                    TopDocs expected = ent.getValue();\n                    assertEquals(expected.totalHits.value, actual.totalHits.value);\n                    assertEquals(\"query=\" + ent.getKey().utf8ToString(), expected.scoreDocs.length, actual.scoreDocs.length);\n                    for(int hit=0;hit<expected.scoreDocs.length;hit++) {\n                      assertEquals(expected.scoreDocs[hit].doc, actual.scoreDocs[hit].doc);\n                      // Floats really should be identical:\n                      assertTrue(expected.scoreDocs[hit].score == actual.scoreDocs[hit].score);\n                    }\n                  }\n                }\n              } catch (Exception e) {\n                throw new RuntimeException(e);\n              }\n            }\n          };\n        threads[threadID] = thread;\n        thread.start();\n      }\n      startingGun.countDown();\n      for(Thread thread : threads) {\n        thread.join();\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c37ab80ad12b466f3dc92e4baa7b0cbf9aded429","date":1590107358,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestSameScoresWithThreads#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestSameScoresWithThreads#test().mjava","sourceNew":"  public void test() throws Exception {\n    final Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir, analyzer);\n    LineFileDocs docs = new LineFileDocs(random());\n    int charsToIndex = atLeast(100000);\n    int charsIndexed = 0;\n    //System.out.println(\"bytesToIndex=\" + charsToIndex);\n    while(charsIndexed < charsToIndex) {\n      Document doc = docs.nextDoc();\n      charsIndexed += doc.get(\"body\").length();\n      w.addDocument(doc);\n      //System.out.println(\"  bytes=\" + charsIndexed + \" add: \" + doc);\n    }\n    IndexReader r = w.getReader();\n    //System.out.println(\"numDocs=\" + r.numDocs());\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    Terms terms = MultiTerms.getTerms(r, \"body\");\n    int termCount = 0;\n    TermsEnum termsEnum = terms.iterator();\n    while(termsEnum.next() != null) {\n      termCount++;\n    }\n    assertTrue(termCount > 0);\n    \n    // Target ~10 terms to search:\n    double chance = 10.0 / termCount;\n    termsEnum = terms.iterator();\n    final Map<BytesRef,TopDocs> answers = new HashMap<>();\n    while(termsEnum.next() != null) {\n      if (random().nextDouble() <= chance) {\n        BytesRef term = BytesRef.deepCopyOf(termsEnum.term());\n        answers.put(term,\n                    s.search(new TermQuery(new Term(\"body\", term)), 100));\n      }\n    }\n\n    if (!answers.isEmpty()) {\n      final CountDownLatch startingGun = new CountDownLatch(1);\n      int numThreads = TEST_NIGHTLY ? TestUtil.nextInt(random(), 2, 5) : 2;\n      Thread[] threads = new Thread[numThreads];\n      for(int threadID=0;threadID<numThreads;threadID++) {\n        Thread thread = new Thread() {\n            @Override\n            public void run() {\n              try {\n                startingGun.await();\n                for(int i=0;i<20;i++) {\n                  List<Map.Entry<BytesRef,TopDocs>> shuffled = new ArrayList<>(answers.entrySet());\n                  Collections.shuffle(shuffled, random());\n                  for(Map.Entry<BytesRef,TopDocs> ent : shuffled) {\n                    TopDocs actual = s.search(new TermQuery(new Term(\"body\", ent.getKey())), 100);\n                    TopDocs expected = ent.getValue();\n                    assertEquals(expected.totalHits.value, actual.totalHits.value);\n                    assertEquals(\"query=\" + ent.getKey().utf8ToString(), expected.scoreDocs.length, actual.scoreDocs.length);\n                    for(int hit=0;hit<expected.scoreDocs.length;hit++) {\n                      assertEquals(expected.scoreDocs[hit].doc, actual.scoreDocs[hit].doc);\n                      // Floats really should be identical:\n                      assertTrue(expected.scoreDocs[hit].score == actual.scoreDocs[hit].score);\n                    }\n                  }\n                }\n              } catch (Exception e) {\n                throw new RuntimeException(e);\n              }\n            }\n          };\n        threads[threadID] = thread;\n        thread.start();\n      }\n      startingGun.countDown();\n      for(Thread thread : threads) {\n        thread.join();\n      }\n    }\n    docs.close();\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    final Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir, analyzer);\n    LineFileDocs docs = new LineFileDocs(random());\n    int charsToIndex = atLeast(100000);\n    int charsIndexed = 0;\n    //System.out.println(\"bytesToIndex=\" + charsToIndex);\n    while(charsIndexed < charsToIndex) {\n      Document doc = docs.nextDoc();\n      charsIndexed += doc.get(\"body\").length();\n      w.addDocument(doc);\n      //System.out.println(\"  bytes=\" + charsIndexed + \" add: \" + doc);\n    }\n    IndexReader r = w.getReader();\n    //System.out.println(\"numDocs=\" + r.numDocs());\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    Terms terms = MultiTerms.getTerms(r, \"body\");\n    int termCount = 0;\n    TermsEnum termsEnum = terms.iterator();\n    while(termsEnum.next() != null) {\n      termCount++;\n    }\n    assertTrue(termCount > 0);\n    \n    // Target ~10 terms to search:\n    double chance = 10.0 / termCount;\n    termsEnum = terms.iterator();\n    final Map<BytesRef,TopDocs> answers = new HashMap<>();\n    while(termsEnum.next() != null) {\n      if (random().nextDouble() <= chance) {\n        BytesRef term = BytesRef.deepCopyOf(termsEnum.term());\n        answers.put(term,\n                    s.search(new TermQuery(new Term(\"body\", term)), 100));\n      }\n    }\n\n    if (!answers.isEmpty()) {\n      final CountDownLatch startingGun = new CountDownLatch(1);\n      int numThreads = TEST_NIGHTLY ? TestUtil.nextInt(random(), 2, 5) : 2;\n      Thread[] threads = new Thread[numThreads];\n      for(int threadID=0;threadID<numThreads;threadID++) {\n        Thread thread = new Thread() {\n            @Override\n            public void run() {\n              try {\n                startingGun.await();\n                for(int i=0;i<20;i++) {\n                  List<Map.Entry<BytesRef,TopDocs>> shuffled = new ArrayList<>(answers.entrySet());\n                  Collections.shuffle(shuffled, random());\n                  for(Map.Entry<BytesRef,TopDocs> ent : shuffled) {\n                    TopDocs actual = s.search(new TermQuery(new Term(\"body\", ent.getKey())), 100);\n                    TopDocs expected = ent.getValue();\n                    assertEquals(expected.totalHits.value, actual.totalHits.value);\n                    assertEquals(\"query=\" + ent.getKey().utf8ToString(), expected.scoreDocs.length, actual.scoreDocs.length);\n                    for(int hit=0;hit<expected.scoreDocs.length;hit++) {\n                      assertEquals(expected.scoreDocs[hit].doc, actual.scoreDocs[hit].doc);\n                      // Floats really should be identical:\n                      assertTrue(expected.scoreDocs[hit].score == actual.scoreDocs[hit].score);\n                    }\n                  }\n                }\n              } catch (Exception e) {\n                throw new RuntimeException(e);\n              }\n            }\n          };\n        threads[threadID] = thread;\n        thread.start();\n      }\n      startingGun.countDown();\n      for(Thread thread : threads) {\n        thread.join();\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82":["103857ec20f79f31c7a00310a91ed001b9a6ef17"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["e1151ecb4798f5c31137aec032c241638018ed20"],"b2f69248e793a250662f39e914e1a57fd8b2bfb3":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"55980207f1977bd1463465de1659b821347e2fa8":["d0ef034a4f10871667ae75181537775ddcf8ade4","103857ec20f79f31c7a00310a91ed001b9a6ef17"],"e588e8c82e32e29ef3837c0b06a2ad34f3c51a2b":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82"],"a58bbbe1c866963764d3f15d3a26a6a85f6c6af4":["6613659748fe4411a7dcf85266e55db1f95f7315","e1151ecb4798f5c31137aec032c241638018ed20"],"6613659748fe4411a7dcf85266e55db1f95f7315":["3b0e8c39ca08b5a02de6edcd33d6f3b90b865173"],"2899ae5069a2533466ac842042478e67263e1f43":["485a1f8ad4bcc0abb22a65e9f7fa57946ee03202"],"485a1f8ad4bcc0abb22a65e9f7fa57946ee03202":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"3b0e8c39ca08b5a02de6edcd33d6f3b90b865173":["b2f69248e793a250662f39e914e1a57fd8b2bfb3"],"28288370235ed02234a64753cdbf0c6ec096304a":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82","e588e8c82e32e29ef3837c0b06a2ad34f3c51a2b"],"c37ab80ad12b466f3dc92e4baa7b0cbf9aded429":["4208ed8e426ae5f75a41d8b4ae53f4587e413061"],"e1151ecb4798f5c31137aec032c241638018ed20":["6613659748fe4411a7dcf85266e55db1f95f7315"],"d4d69c535930b5cce125cff868d40f6373dc27d4":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","2899ae5069a2533466ac842042478e67263e1f43"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"4208ed8e426ae5f75a41d8b4ae53f4587e413061":["04e775de416dd2d8067b10db1c8af975a1d5017e"],"103857ec20f79f31c7a00310a91ed001b9a6ef17":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"04e775de416dd2d8067b10db1c8af975a1d5017e":["83788ad129a5154d5c6562c4e8ce3db48793aada"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"83788ad129a5154d5c6562c4e8ce3db48793aada":["28288370235ed02234a64753cdbf0c6ec096304a"],"2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82","e588e8c82e32e29ef3837c0b06a2ad34f3c51a2b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c37ab80ad12b466f3dc92e4baa7b0cbf9aded429"]},"commit2Childs":{"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82":["e588e8c82e32e29ef3837c0b06a2ad34f3c51a2b","28288370235ed02234a64753cdbf0c6ec096304a","2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"b2f69248e793a250662f39e914e1a57fd8b2bfb3":["3b0e8c39ca08b5a02de6edcd33d6f3b90b865173"],"55980207f1977bd1463465de1659b821347e2fa8":[],"e588e8c82e32e29ef3837c0b06a2ad34f3c51a2b":["28288370235ed02234a64753cdbf0c6ec096304a","2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9"],"a58bbbe1c866963764d3f15d3a26a6a85f6c6af4":[],"6613659748fe4411a7dcf85266e55db1f95f7315":["a58bbbe1c866963764d3f15d3a26a6a85f6c6af4","e1151ecb4798f5c31137aec032c241638018ed20"],"2899ae5069a2533466ac842042478e67263e1f43":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"485a1f8ad4bcc0abb22a65e9f7fa57946ee03202":["2899ae5069a2533466ac842042478e67263e1f43"],"3b0e8c39ca08b5a02de6edcd33d6f3b90b865173":["6613659748fe4411a7dcf85266e55db1f95f7315"],"28288370235ed02234a64753cdbf0c6ec096304a":["83788ad129a5154d5c6562c4e8ce3db48793aada"],"c37ab80ad12b466f3dc92e4baa7b0cbf9aded429":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"e1151ecb4798f5c31137aec032c241638018ed20":["634f330c54fd3f9f491d52036dc3f40b4f4d8934","a58bbbe1c866963764d3f15d3a26a6a85f6c6af4"],"d4d69c535930b5cce125cff868d40f6373dc27d4":["b2f69248e793a250662f39e914e1a57fd8b2bfb3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["485a1f8ad4bcc0abb22a65e9f7fa57946ee03202","d4d69c535930b5cce125cff868d40f6373dc27d4"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["55980207f1977bd1463465de1659b821347e2fa8","103857ec20f79f31c7a00310a91ed001b9a6ef17"],"103857ec20f79f31c7a00310a91ed001b9a6ef17":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82","55980207f1977bd1463465de1659b821347e2fa8"],"4208ed8e426ae5f75a41d8b4ae53f4587e413061":["c37ab80ad12b466f3dc92e4baa7b0cbf9aded429"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"04e775de416dd2d8067b10db1c8af975a1d5017e":["4208ed8e426ae5f75a41d8b4ae53f4587e413061"],"83788ad129a5154d5c6562c4e8ce3db48793aada":["04e775de416dd2d8067b10db1c8af975a1d5017e"],"2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["55980207f1977bd1463465de1659b821347e2fa8","a58bbbe1c866963764d3f15d3a26a6a85f6c6af4","2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}