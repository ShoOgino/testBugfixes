{"path":"src/java/org/apache/solr/search/SortedIntDocSet#getTopFilter().mjava","commits":[{"id":"1919b234a992d6438a59ccbb02bd0656162e602e","date":1242941438,"type":0,"author":"Yonik Seeley","isMerge":false,"pathNew":"src/java/org/apache/solr/search/SortedIntDocSet#getTopFilter().mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public Filter getTopFilter() {\n    return new Filter() {\n      int lastEndIdx = 0;\n\n      @Override\n      public DocIdSet getDocIdSet(IndexReader reader) throws IOException {\n        int offset = 0;\n        SolrIndexReader r = (SolrIndexReader)reader;\n        while (r.getParent() != null) {\n          offset += r.getBase();\n          r = r.getParent();\n        }\n        final int base = offset;\n        final int maxDoc = reader.maxDoc();\n        final int max = base + maxDoc;   // one past the max doc in this segment.\n        int sidx = Math.max(0,lastEndIdx);\n\n        if (sidx > 0 && docs[sidx-1] >= base) {\n          // oops, the lastEndIdx isn't correct... we must have been used\n          // in a multi-threaded context, or the indexreaders are being\n          // used out-of-order.  start at 0.\n          sidx = 0;\n        }\n        if (sidx < docs.length && docs[sidx] < base) {\n          // if docs[sidx] is < base, we need to seek to find the real start.\n          sidx = findIndex(docs, base, sidx, docs.length-1);\n        }\n\n        final int startIdx = sidx;\n\n        // Largest possible end index is limited to the start index\n        // plus the number of docs contained in the segment.  Subtract 1 since\n        // the end index is inclusive.\n        int eidx = Math.min(docs.length, startIdx + maxDoc) - 1;\n\n        // find the real end\n        eidx = findIndex(docs, max, startIdx, eidx) - 1;\n\n        final int endIdx = eidx;\n        lastEndIdx = endIdx;\n\n\n        return new DocIdSet() {\n          public DocIdSetIterator iterator() throws IOException {\n            return new DocIdSetIterator() {\n              int idx = startIdx;\n              int doc;\n              public int doc() {\n                return doc - base;\n              }\n\n              public boolean next() throws IOException {\n                if (idx > endIdx) return false;\n                doc = docs[idx++];\n                return true;\n              }\n\n              public boolean skipTo(int target) throws IOException {\n                if (idx > endIdx) return false;\n                target += base;\n\n                // probe next\n                doc = docs[idx++];\n                if (doc >= target) return true;\n\n                int high = endIdx;\n\n                // TODO: probe more before resorting to binary search?\n\n                // binary search\n                while (idx <= high) {\n                  int mid = (idx+high) >>> 1;\n                  doc = docs[mid];\n\n                  if (doc < target) {\n                    idx = mid+1;\n                  }\n                  else if (doc > target) {\n                    high = mid-1;\n                  }\n                  else {\n                    idx=mid+1;\n                    return true;\n                  }\n                }\n\n                // low is on the insertion point...\n                if (idx <= endIdx) {\n                  doc = docs[idx++];\n                  return true;\n                } else {\n                  return false;\n                }\n              }\n            };\n          }\n        };\n      }\n    };\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["4d3e8520fd031bab31fd0e4d480e55958bc45efe","4d3e8520fd031bab31fd0e4d480e55958bc45efe","4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"19a6a2b00bd8d0dbd9684de00bb3018e4664a1e5","date":1247703137,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"src/java/org/apache/solr/search/SortedIntDocSet#getTopFilter().mjava","pathOld":"src/java/org/apache/solr/search/SortedIntDocSet#getTopFilter().mjava","sourceNew":"  @Override\n  public Filter getTopFilter() {\n    return new Filter() {\n      int lastEndIdx = 0;\n\n      @Override\n      public DocIdSet getDocIdSet(IndexReader reader) throws IOException {\n        int offset = 0;\n        SolrIndexReader r = (SolrIndexReader)reader;\n        while (r.getParent() != null) {\n          offset += r.getBase();\n          r = r.getParent();\n        }\n        final int base = offset;\n        final int maxDoc = reader.maxDoc();\n        final int max = base + maxDoc;   // one past the max doc in this segment.\n        int sidx = Math.max(0,lastEndIdx);\n\n        if (sidx > 0 && docs[sidx-1] >= base) {\n          // oops, the lastEndIdx isn't correct... we must have been used\n          // in a multi-threaded context, or the indexreaders are being\n          // used out-of-order.  start at 0.\n          sidx = 0;\n        }\n        if (sidx < docs.length && docs[sidx] < base) {\n          // if docs[sidx] is < base, we need to seek to find the real start.\n          sidx = findIndex(docs, base, sidx, docs.length-1);\n        }\n\n        final int startIdx = sidx;\n\n        // Largest possible end index is limited to the start index\n        // plus the number of docs contained in the segment.  Subtract 1 since\n        // the end index is inclusive.\n        int eidx = Math.min(docs.length, startIdx + maxDoc) - 1;\n\n        // find the real end\n        eidx = findIndex(docs, max, startIdx, eidx) - 1;\n\n        final int endIdx = eidx;\n        lastEndIdx = endIdx;\n\n\n        return new DocIdSet() {\n          public DocIdSetIterator iterator() throws IOException {\n            return new DocIdSetIterator() {\n              int idx = startIdx;\n              int adjustedDoc;\n\n              public int doc() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() throws IOException {\n                return adjustedDoc = (idx > endIdx) ? NO_MORE_DOCS : (docs[idx++] - base);\n              }\n\n              @Override\n              public int advance(int target) throws IOException {\n                if (idx > endIdx || target==NO_MORE_DOCS) return adjustedDoc=NO_MORE_DOCS;\n                target += base;\n\n                // probe next\n                int rawDoc = docs[idx++];\n                if (rawDoc >= target) return adjustedDoc=rawDoc-base;\n\n                int high = endIdx;\n\n                // TODO: probe more before resorting to binary search?\n\n                // binary search\n                while (idx <= high) {\n                  int mid = (idx+high) >>> 1;\n                  rawDoc = docs[mid];\n\n                  if (rawDoc < target) {\n                    idx = mid+1;\n                  }\n                  else if (rawDoc > target) {\n                    high = mid-1;\n                  }\n                  else {\n                    idx=mid+1;\n                    return adjustedDoc=rawDoc - base;\n                  }\n                }\n\n                // low is on the insertion point...\n                if (idx <= endIdx) {\n                  return adjustedDoc = docs[idx++] - base;\n                } else {\n                  return adjustedDoc=NO_MORE_DOCS;\n                }\n              }\n\n            };\n          }\n        };\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Filter getTopFilter() {\n    return new Filter() {\n      int lastEndIdx = 0;\n\n      @Override\n      public DocIdSet getDocIdSet(IndexReader reader) throws IOException {\n        int offset = 0;\n        SolrIndexReader r = (SolrIndexReader)reader;\n        while (r.getParent() != null) {\n          offset += r.getBase();\n          r = r.getParent();\n        }\n        final int base = offset;\n        final int maxDoc = reader.maxDoc();\n        final int max = base + maxDoc;   // one past the max doc in this segment.\n        int sidx = Math.max(0,lastEndIdx);\n\n        if (sidx > 0 && docs[sidx-1] >= base) {\n          // oops, the lastEndIdx isn't correct... we must have been used\n          // in a multi-threaded context, or the indexreaders are being\n          // used out-of-order.  start at 0.\n          sidx = 0;\n        }\n        if (sidx < docs.length && docs[sidx] < base) {\n          // if docs[sidx] is < base, we need to seek to find the real start.\n          sidx = findIndex(docs, base, sidx, docs.length-1);\n        }\n\n        final int startIdx = sidx;\n\n        // Largest possible end index is limited to the start index\n        // plus the number of docs contained in the segment.  Subtract 1 since\n        // the end index is inclusive.\n        int eidx = Math.min(docs.length, startIdx + maxDoc) - 1;\n\n        // find the real end\n        eidx = findIndex(docs, max, startIdx, eidx) - 1;\n\n        final int endIdx = eidx;\n        lastEndIdx = endIdx;\n\n\n        return new DocIdSet() {\n          public DocIdSetIterator iterator() throws IOException {\n            return new DocIdSetIterator() {\n              int idx = startIdx;\n              int doc;\n              public int doc() {\n                return doc - base;\n              }\n\n              public boolean next() throws IOException {\n                if (idx > endIdx) return false;\n                doc = docs[idx++];\n                return true;\n              }\n\n              public boolean skipTo(int target) throws IOException {\n                if (idx > endIdx) return false;\n                target += base;\n\n                // probe next\n                doc = docs[idx++];\n                if (doc >= target) return true;\n\n                int high = endIdx;\n\n                // TODO: probe more before resorting to binary search?\n\n                // binary search\n                while (idx <= high) {\n                  int mid = (idx+high) >>> 1;\n                  doc = docs[mid];\n\n                  if (doc < target) {\n                    idx = mid+1;\n                  }\n                  else if (doc > target) {\n                    high = mid-1;\n                  }\n                  else {\n                    idx=mid+1;\n                    return true;\n                  }\n                }\n\n                // low is on the insertion point...\n                if (idx <= endIdx) {\n                  doc = docs[idx++];\n                  return true;\n                } else {\n                  return false;\n                }\n              }\n            };\n          }\n        };\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":["4d3e8520fd031bab31fd0e4d480e55958bc45efe","4d3e8520fd031bab31fd0e4d480e55958bc45efe","4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6df145a9ad024b694ddfd993d30b88d100ce7ca5","date":1247757750,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"src/java/org/apache/solr/search/SortedIntDocSet#getTopFilter().mjava","pathOld":"src/java/org/apache/solr/search/SortedIntDocSet#getTopFilter().mjava","sourceNew":"  @Override\n  public Filter getTopFilter() {\n    return new Filter() {\n      int lastEndIdx = 0;\n\n      @Override\n      public DocIdSet getDocIdSet(IndexReader reader) throws IOException {\n        int offset = 0;\n        SolrIndexReader r = (SolrIndexReader)reader;\n        while (r.getParent() != null) {\n          offset += r.getBase();\n          r = r.getParent();\n        }\n        final int base = offset;\n        final int maxDoc = reader.maxDoc();\n        final int max = base + maxDoc;   // one past the max doc in this segment.\n        int sidx = Math.max(0,lastEndIdx);\n\n        if (sidx > 0 && docs[sidx-1] >= base) {\n          // oops, the lastEndIdx isn't correct... we must have been used\n          // in a multi-threaded context, or the indexreaders are being\n          // used out-of-order.  start at 0.\n          sidx = 0;\n        }\n        if (sidx < docs.length && docs[sidx] < base) {\n          // if docs[sidx] is < base, we need to seek to find the real start.\n          sidx = findIndex(docs, base, sidx, docs.length-1);\n        }\n\n        final int startIdx = sidx;\n\n        // Largest possible end index is limited to the start index\n        // plus the number of docs contained in the segment.  Subtract 1 since\n        // the end index is inclusive.\n        int eidx = Math.min(docs.length, startIdx + maxDoc) - 1;\n\n        // find the real end\n        eidx = findIndex(docs, max, startIdx, eidx) - 1;\n\n        final int endIdx = eidx;\n        lastEndIdx = endIdx;\n\n\n        return new DocIdSet() {\n          public DocIdSetIterator iterator() throws IOException {\n            return new DocIdSetIterator() {\n              int idx = startIdx;\n              int adjustedDoc = -1;\n\n              public int doc() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() throws IOException {\n                return adjustedDoc = (idx > endIdx) ? NO_MORE_DOCS : (docs[idx++] - base);\n              }\n\n              @Override\n              public int advance(int target) throws IOException {\n                if (idx > endIdx || target==NO_MORE_DOCS) return adjustedDoc=NO_MORE_DOCS;\n                target += base;\n\n                // probe next\n                int rawDoc = docs[idx++];\n                if (rawDoc >= target) return adjustedDoc=rawDoc-base;\n\n                int high = endIdx;\n\n                // TODO: probe more before resorting to binary search?\n\n                // binary search\n                while (idx <= high) {\n                  int mid = (idx+high) >>> 1;\n                  rawDoc = docs[mid];\n\n                  if (rawDoc < target) {\n                    idx = mid+1;\n                  }\n                  else if (rawDoc > target) {\n                    high = mid-1;\n                  }\n                  else {\n                    idx=mid+1;\n                    return adjustedDoc=rawDoc - base;\n                  }\n                }\n\n                // low is on the insertion point...\n                if (idx <= endIdx) {\n                  return adjustedDoc = docs[idx++] - base;\n                } else {\n                  return adjustedDoc=NO_MORE_DOCS;\n                }\n              }\n\n            };\n          }\n        };\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Filter getTopFilter() {\n    return new Filter() {\n      int lastEndIdx = 0;\n\n      @Override\n      public DocIdSet getDocIdSet(IndexReader reader) throws IOException {\n        int offset = 0;\n        SolrIndexReader r = (SolrIndexReader)reader;\n        while (r.getParent() != null) {\n          offset += r.getBase();\n          r = r.getParent();\n        }\n        final int base = offset;\n        final int maxDoc = reader.maxDoc();\n        final int max = base + maxDoc;   // one past the max doc in this segment.\n        int sidx = Math.max(0,lastEndIdx);\n\n        if (sidx > 0 && docs[sidx-1] >= base) {\n          // oops, the lastEndIdx isn't correct... we must have been used\n          // in a multi-threaded context, or the indexreaders are being\n          // used out-of-order.  start at 0.\n          sidx = 0;\n        }\n        if (sidx < docs.length && docs[sidx] < base) {\n          // if docs[sidx] is < base, we need to seek to find the real start.\n          sidx = findIndex(docs, base, sidx, docs.length-1);\n        }\n\n        final int startIdx = sidx;\n\n        // Largest possible end index is limited to the start index\n        // plus the number of docs contained in the segment.  Subtract 1 since\n        // the end index is inclusive.\n        int eidx = Math.min(docs.length, startIdx + maxDoc) - 1;\n\n        // find the real end\n        eidx = findIndex(docs, max, startIdx, eidx) - 1;\n\n        final int endIdx = eidx;\n        lastEndIdx = endIdx;\n\n\n        return new DocIdSet() {\n          public DocIdSetIterator iterator() throws IOException {\n            return new DocIdSetIterator() {\n              int idx = startIdx;\n              int adjustedDoc;\n\n              public int doc() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() throws IOException {\n                return adjustedDoc = (idx > endIdx) ? NO_MORE_DOCS : (docs[idx++] - base);\n              }\n\n              @Override\n              public int advance(int target) throws IOException {\n                if (idx > endIdx || target==NO_MORE_DOCS) return adjustedDoc=NO_MORE_DOCS;\n                target += base;\n\n                // probe next\n                int rawDoc = docs[idx++];\n                if (rawDoc >= target) return adjustedDoc=rawDoc-base;\n\n                int high = endIdx;\n\n                // TODO: probe more before resorting to binary search?\n\n                // binary search\n                while (idx <= high) {\n                  int mid = (idx+high) >>> 1;\n                  rawDoc = docs[mid];\n\n                  if (rawDoc < target) {\n                    idx = mid+1;\n                  }\n                  else if (rawDoc > target) {\n                    high = mid-1;\n                  }\n                  else {\n                    idx=mid+1;\n                    return adjustedDoc=rawDoc - base;\n                  }\n                }\n\n                // low is on the insertion point...\n                if (idx <= endIdx) {\n                  return adjustedDoc = docs[idx++] - base;\n                } else {\n                  return adjustedDoc=NO_MORE_DOCS;\n                }\n              }\n\n            };\n          }\n        };\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0a923408680bb84f7886ffc3fc1ee74a426bc493","date":1253320441,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"src/java/org/apache/solr/search/SortedIntDocSet#getTopFilter().mjava","pathOld":"src/java/org/apache/solr/search/SortedIntDocSet#getTopFilter().mjava","sourceNew":"  @Override\n  public Filter getTopFilter() {\n    return new Filter() {\n      int lastEndIdx = 0;\n\n      @Override\n      public DocIdSet getDocIdSet(IndexReader reader) throws IOException {\n        int offset = 0;\n        SolrIndexReader r = (SolrIndexReader)reader;\n        while (r.getParent() != null) {\n          offset += r.getBase();\n          r = r.getParent();\n        }\n        final int base = offset;\n        final int maxDoc = reader.maxDoc();\n        final int max = base + maxDoc;   // one past the max doc in this segment.\n        int sidx = Math.max(0,lastEndIdx);\n\n        if (sidx > 0 && docs[sidx-1] >= base) {\n          // oops, the lastEndIdx isn't correct... we must have been used\n          // in a multi-threaded context, or the indexreaders are being\n          // used out-of-order.  start at 0.\n          sidx = 0;\n        }\n        if (sidx < docs.length && docs[sidx] < base) {\n          // if docs[sidx] is < base, we need to seek to find the real start.\n          sidx = findIndex(docs, base, sidx, docs.length-1);\n        }\n\n        final int startIdx = sidx;\n\n        // Largest possible end index is limited to the start index\n        // plus the number of docs contained in the segment.  Subtract 1 since\n        // the end index is inclusive.\n        int eidx = Math.min(docs.length, startIdx + maxDoc) - 1;\n\n        // find the real end\n        eidx = findIndex(docs, max, startIdx, eidx) - 1;\n\n        final int endIdx = eidx;\n        lastEndIdx = endIdx;\n\n\n        return new DocIdSet() {\n          public DocIdSetIterator iterator() throws IOException {\n            return new DocIdSetIterator() {\n              int idx = startIdx;\n              int adjustedDoc = -1;\n\n              public int doc() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() throws IOException {\n                return adjustedDoc = (idx > endIdx) ? NO_MORE_DOCS : (docs[idx++] - base);\n              }\n\n              @Override\n              public int advance(int target) throws IOException {\n                if (idx > endIdx || target==NO_MORE_DOCS) return adjustedDoc=NO_MORE_DOCS;\n                target += base;\n\n                // probe next\n                int rawDoc = docs[idx++];\n                if (rawDoc >= target) return adjustedDoc=rawDoc-base;\n\n                int high = endIdx;\n\n                // TODO: probe more before resorting to binary search?\n\n                // binary search\n                while (idx <= high) {\n                  int mid = (idx+high) >>> 1;\n                  rawDoc = docs[mid];\n\n                  if (rawDoc < target) {\n                    idx = mid+1;\n                  }\n                  else if (rawDoc > target) {\n                    high = mid-1;\n                  }\n                  else {\n                    idx=mid+1;\n                    return adjustedDoc=rawDoc - base;\n                  }\n                }\n\n                // low is on the insertion point...\n                if (idx <= endIdx) {\n                  return adjustedDoc = docs[idx++] - base;\n                } else {\n                  return adjustedDoc=NO_MORE_DOCS;\n                }\n              }\n\n            };\n          }\n\n          @Override\n          public boolean isCacheable() {\n            return true;\n          }\n\n        };\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Filter getTopFilter() {\n    return new Filter() {\n      int lastEndIdx = 0;\n\n      @Override\n      public DocIdSet getDocIdSet(IndexReader reader) throws IOException {\n        int offset = 0;\n        SolrIndexReader r = (SolrIndexReader)reader;\n        while (r.getParent() != null) {\n          offset += r.getBase();\n          r = r.getParent();\n        }\n        final int base = offset;\n        final int maxDoc = reader.maxDoc();\n        final int max = base + maxDoc;   // one past the max doc in this segment.\n        int sidx = Math.max(0,lastEndIdx);\n\n        if (sidx > 0 && docs[sidx-1] >= base) {\n          // oops, the lastEndIdx isn't correct... we must have been used\n          // in a multi-threaded context, or the indexreaders are being\n          // used out-of-order.  start at 0.\n          sidx = 0;\n        }\n        if (sidx < docs.length && docs[sidx] < base) {\n          // if docs[sidx] is < base, we need to seek to find the real start.\n          sidx = findIndex(docs, base, sidx, docs.length-1);\n        }\n\n        final int startIdx = sidx;\n\n        // Largest possible end index is limited to the start index\n        // plus the number of docs contained in the segment.  Subtract 1 since\n        // the end index is inclusive.\n        int eidx = Math.min(docs.length, startIdx + maxDoc) - 1;\n\n        // find the real end\n        eidx = findIndex(docs, max, startIdx, eidx) - 1;\n\n        final int endIdx = eidx;\n        lastEndIdx = endIdx;\n\n\n        return new DocIdSet() {\n          public DocIdSetIterator iterator() throws IOException {\n            return new DocIdSetIterator() {\n              int idx = startIdx;\n              int adjustedDoc = -1;\n\n              public int doc() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() throws IOException {\n                return adjustedDoc = (idx > endIdx) ? NO_MORE_DOCS : (docs[idx++] - base);\n              }\n\n              @Override\n              public int advance(int target) throws IOException {\n                if (idx > endIdx || target==NO_MORE_DOCS) return adjustedDoc=NO_MORE_DOCS;\n                target += base;\n\n                // probe next\n                int rawDoc = docs[idx++];\n                if (rawDoc >= target) return adjustedDoc=rawDoc-base;\n\n                int high = endIdx;\n\n                // TODO: probe more before resorting to binary search?\n\n                // binary search\n                while (idx <= high) {\n                  int mid = (idx+high) >>> 1;\n                  rawDoc = docs[mid];\n\n                  if (rawDoc < target) {\n                    idx = mid+1;\n                  }\n                  else if (rawDoc > target) {\n                    high = mid-1;\n                  }\n                  else {\n                    idx=mid+1;\n                    return adjustedDoc=rawDoc - base;\n                  }\n                }\n\n                // low is on the insertion point...\n                if (idx <= endIdx) {\n                  return adjustedDoc = docs[idx++] - base;\n                } else {\n                  return adjustedDoc=NO_MORE_DOCS;\n                }\n              }\n\n            };\n          }\n        };\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ad94625fb8d088209f46650c8097196fec67f00c","date":1453508319,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/search/SortedIntDocSet#getTopFilter().mjava","pathOld":"src/java/org/apache/solr/search/SortedIntDocSet#getTopFilter().mjava","sourceNew":"  @Override\n  public Filter getTopFilter() {\n    return new Filter() {\n      int lastEndIdx = 0;\n\n      @Override\n      public DocIdSet getDocIdSet(IndexReader reader) throws IOException {\n        int offset = 0;\n        SolrIndexReader r = (SolrIndexReader)reader;\n        while (r.getParent() != null) {\n          offset += r.getBase();\n          r = r.getParent();\n        }\n        final int base = offset;\n        final int maxDoc = reader.maxDoc();\n        final int max = base + maxDoc;   // one past the max doc in this segment.\n        int sidx = Math.max(0,lastEndIdx);\n\n        if (sidx > 0 && docs[sidx-1] >= base) {\n          // oops, the lastEndIdx isn't correct... we must have been used\n          // in a multi-threaded context, or the indexreaders are being\n          // used out-of-order.  start at 0.\n          sidx = 0;\n        }\n        if (sidx < docs.length && docs[sidx] < base) {\n          // if docs[sidx] is < base, we need to seek to find the real start.\n          sidx = findIndex(docs, base, sidx, docs.length-1);\n        }\n\n        final int startIdx = sidx;\n\n        // Largest possible end index is limited to the start index\n        // plus the number of docs contained in the segment.  Subtract 1 since\n        // the end index is inclusive.\n        int eidx = Math.min(docs.length, startIdx + maxDoc) - 1;\n\n        // find the real end\n        eidx = findIndex(docs, max, startIdx, eidx) - 1;\n\n        final int endIdx = eidx;\n        lastEndIdx = endIdx;\n\n\n        return new DocIdSet() {\n          public DocIdSetIterator iterator() throws IOException {\n            return new DocIdSetIterator() {\n              int idx = startIdx;\n              int adjustedDoc = -1;\n\n              public int doc() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() throws IOException {\n                return adjustedDoc = (idx > endIdx) ? NO_MORE_DOCS : (docs[idx++] - base);\n              }\n\n              @Override\n              public int advance(int target) throws IOException {\n                if (idx > endIdx || target==NO_MORE_DOCS) return adjustedDoc=NO_MORE_DOCS;\n                target += base;\n\n                // probe next\n                int rawDoc = docs[idx++];\n                if (rawDoc >= target) return adjustedDoc=rawDoc-base;\n\n                int high = endIdx;\n\n                // TODO: probe more before resorting to binary search?\n\n                // binary search\n                while (idx <= high) {\n                  int mid = (idx+high) >>> 1;\n                  rawDoc = docs[mid];\n\n                  if (rawDoc < target) {\n                    idx = mid+1;\n                  }\n                  else if (rawDoc > target) {\n                    high = mid-1;\n                  }\n                  else {\n                    idx=mid+1;\n                    return adjustedDoc=rawDoc - base;\n                  }\n                }\n\n                // low is on the insertion point...\n                if (idx <= endIdx) {\n                  return adjustedDoc = docs[idx++] - base;\n                } else {\n                  return adjustedDoc=NO_MORE_DOCS;\n                }\n              }\n\n            };\n          }\n\n          @Override\n          public boolean isCacheable() {\n            return true;\n          }\n\n        };\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Filter getTopFilter() {\n    return new Filter() {\n      int lastEndIdx = 0;\n\n      @Override\n      public DocIdSet getDocIdSet(IndexReader reader) throws IOException {\n        int offset = 0;\n        SolrIndexReader r = (SolrIndexReader)reader;\n        while (r.getParent() != null) {\n          offset += r.getBase();\n          r = r.getParent();\n        }\n        final int base = offset;\n        final int maxDoc = reader.maxDoc();\n        final int max = base + maxDoc;   // one past the max doc in this segment.\n        int sidx = Math.max(0,lastEndIdx);\n\n        if (sidx > 0 && docs[sidx-1] >= base) {\n          // oops, the lastEndIdx isn't correct... we must have been used\n          // in a multi-threaded context, or the indexreaders are being\n          // used out-of-order.  start at 0.\n          sidx = 0;\n        }\n        if (sidx < docs.length && docs[sidx] < base) {\n          // if docs[sidx] is < base, we need to seek to find the real start.\n          sidx = findIndex(docs, base, sidx, docs.length-1);\n        }\n\n        final int startIdx = sidx;\n\n        // Largest possible end index is limited to the start index\n        // plus the number of docs contained in the segment.  Subtract 1 since\n        // the end index is inclusive.\n        int eidx = Math.min(docs.length, startIdx + maxDoc) - 1;\n\n        // find the real end\n        eidx = findIndex(docs, max, startIdx, eidx) - 1;\n\n        final int endIdx = eidx;\n        lastEndIdx = endIdx;\n\n\n        return new DocIdSet() {\n          public DocIdSetIterator iterator() throws IOException {\n            return new DocIdSetIterator() {\n              int idx = startIdx;\n              int adjustedDoc = -1;\n\n              public int doc() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() throws IOException {\n                return adjustedDoc = (idx > endIdx) ? NO_MORE_DOCS : (docs[idx++] - base);\n              }\n\n              @Override\n              public int advance(int target) throws IOException {\n                if (idx > endIdx || target==NO_MORE_DOCS) return adjustedDoc=NO_MORE_DOCS;\n                target += base;\n\n                // probe next\n                int rawDoc = docs[idx++];\n                if (rawDoc >= target) return adjustedDoc=rawDoc-base;\n\n                int high = endIdx;\n\n                // TODO: probe more before resorting to binary search?\n\n                // binary search\n                while (idx <= high) {\n                  int mid = (idx+high) >>> 1;\n                  rawDoc = docs[mid];\n\n                  if (rawDoc < target) {\n                    idx = mid+1;\n                  }\n                  else if (rawDoc > target) {\n                    high = mid-1;\n                  }\n                  else {\n                    idx=mid+1;\n                    return adjustedDoc=rawDoc - base;\n                  }\n                }\n\n                // low is on the insertion point...\n                if (idx <= endIdx) {\n                  return adjustedDoc = docs[idx++] - base;\n                } else {\n                  return adjustedDoc=NO_MORE_DOCS;\n                }\n              }\n\n            };\n          }\n\n          @Override\n          public boolean isCacheable() {\n            return true;\n          }\n\n        };\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"6df145a9ad024b694ddfd993d30b88d100ce7ca5":["19a6a2b00bd8d0dbd9684de00bb3018e4664a1e5"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"1919b234a992d6438a59ccbb02bd0656162e602e":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"ad94625fb8d088209f46650c8097196fec67f00c":["0a923408680bb84f7886ffc3fc1ee74a426bc493"],"0a923408680bb84f7886ffc3fc1ee74a426bc493":["6df145a9ad024b694ddfd993d30b88d100ce7ca5"],"19a6a2b00bd8d0dbd9684de00bb3018e4664a1e5":["1919b234a992d6438a59ccbb02bd0656162e602e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"6df145a9ad024b694ddfd993d30b88d100ce7ca5":["0a923408680bb84f7886ffc3fc1ee74a426bc493"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"1919b234a992d6438a59ccbb02bd0656162e602e":["19a6a2b00bd8d0dbd9684de00bb3018e4664a1e5"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["1919b234a992d6438a59ccbb02bd0656162e602e"],"ad94625fb8d088209f46650c8097196fec67f00c":[],"0a923408680bb84f7886ffc3fc1ee74a426bc493":["ad94625fb8d088209f46650c8097196fec67f00c"],"19a6a2b00bd8d0dbd9684de00bb3018e4664a1e5":["6df145a9ad024b694ddfd993d30b88d100ce7ca5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["ad94625fb8d088209f46650c8097196fec67f00c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"pathCommit":null}