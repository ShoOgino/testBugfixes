{"path":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomPositons().mjava","commits":[{"id":"9d7606b7ab7992bc238d10c3bddfe82a639d212a","date":1295971955,"type":0,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomPositons().mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * this test indexes random numbers within a range into a field and checks\n   * their occurrences by searching for a number from that range selected at\n   * random. All positions for that number are saved up front and compared to\n   * the enums positions.\n   */\n  public void testRandomPositons() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(\n            MockTokenizer.WHITESPACE, true, usePayload)));\n    int numDocs = 131;\n    int max = 1051;\n    int term = random.nextInt(max);\n    Integer[][] positionsInDoc = new Integer[numDocs][];\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      ArrayList<Integer> positions = new ArrayList<Integer>();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 3049; j++) {\n        int nextInt = random.nextInt(max);\n        builder.append(nextInt).append(\" \");\n        if (nextInt == term) {\n          positions.add(Integer.valueOf(j));\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), Field.Store.YES,\n          Field.Index.ANALYZED));\n      positionsInDoc[i] = positions.toArray(new Integer[0]);\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    for (int i = 0; i < 39 * RANDOM_MULTIPLIER; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      ReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = ReaderUtil.leaves(topReaderContext);\n      for (AtomicReaderContext atomicReaderContext : leaves) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader, bytes, null);\n        assertNotNull(docsAndPosEnum);\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader.maxDoc();\n        // initially advance or do next doc\n        if (random.nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random.nextInt(maxDoc));\n        }\n        // now run through the scorer and check if all positions are there...\n        do {\n          int docID = docsAndPosEnum.docID();\n          if (docID == DocsAndPositionsEnum.NO_MORE_DOCS) {\n            break;\n          }\n          Integer[] pos = positionsInDoc[atomicReaderContext.docBase + docID];\n          assertEquals(pos.length, docsAndPosEnum.freq());\n          // number of positions read should be random - don't read all of them\n          // allways\n          final int howMany = random.nextInt(20) == 0 ? pos.length\n              - random.nextInt(pos.length) : pos.length;\n          for (int j = 0; j < howMany; j++) {\n            assertEquals(\"iteration: \" + i + \" initDoc: \" + initDoc + \" doc: \"\n                + docID + \" base: \" + atomicReaderContext.docBase\n                + \" positions: \" + Arrays.toString(pos) + \" usePayloads: \"\n                + usePayload, pos[j].intValue(), docsAndPosEnum.nextPosition());\n          }\n\n          if (random.nextInt(10) == 0) { // once is a while advance\n            docsAndPosEnum\n                .advance(docID + 1 + random.nextInt((maxDoc - docID)));\n          }\n\n        } while (docsAndPosEnum.nextDoc() != DocsAndPositionsEnum.NO_MORE_DOCS);\n      }\n\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a05ba0a6bd886c85c738ed2529954ff8c3ba5c06","date":1296256368,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomPositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomPositons().mjava","sourceNew":"  /**\n   * this test indexes random numbers within a range into a field and checks\n   * their occurrences by searching for a number from that range selected at\n   * random. All positions for that number are saved up front and compared to\n   * the enums positions.\n   */\n  public void testRandomPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(\n            MockTokenizer.WHITESPACE, true, usePayload)));\n    int numDocs = 131;\n    int max = 1051;\n    int term = random.nextInt(max);\n    Integer[][] positionsInDoc = new Integer[numDocs][];\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      ArrayList<Integer> positions = new ArrayList<Integer>();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 3049; j++) {\n        int nextInt = random.nextInt(max);\n        builder.append(nextInt).append(\" \");\n        if (nextInt == term) {\n          positions.add(Integer.valueOf(j));\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), Field.Store.YES,\n          Field.Index.ANALYZED));\n      positionsInDoc[i] = positions.toArray(new Integer[0]);\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    for (int i = 0; i < 39 * RANDOM_MULTIPLIER; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      ReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = ReaderUtil.leaves(topReaderContext);\n      for (AtomicReaderContext atomicReaderContext : leaves) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader, bytes, null);\n        assertNotNull(docsAndPosEnum);\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader.maxDoc();\n        // initially advance or do next doc\n        if (random.nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random.nextInt(maxDoc));\n        }\n        // now run through the scorer and check if all positions are there...\n        do {\n          int docID = docsAndPosEnum.docID();\n          if (docID == DocsAndPositionsEnum.NO_MORE_DOCS) {\n            break;\n          }\n          Integer[] pos = positionsInDoc[atomicReaderContext.docBase + docID];\n          assertEquals(pos.length, docsAndPosEnum.freq());\n          // number of positions read should be random - don't read all of them\n          // allways\n          final int howMany = random.nextInt(20) == 0 ? pos.length\n              - random.nextInt(pos.length) : pos.length;\n          for (int j = 0; j < howMany; j++) {\n            assertEquals(\"iteration: \" + i + \" initDoc: \" + initDoc + \" doc: \"\n                + docID + \" base: \" + atomicReaderContext.docBase\n                + \" positions: \" + Arrays.toString(pos) + \" usePayloads: \"\n                + usePayload, pos[j].intValue(), docsAndPosEnum.nextPosition());\n          }\n\n          if (random.nextInt(10) == 0) { // once is a while advance\n            docsAndPosEnum\n                .advance(docID + 1 + random.nextInt((maxDoc - docID)));\n          }\n\n        } while (docsAndPosEnum.nextDoc() != DocsAndPositionsEnum.NO_MORE_DOCS);\n      }\n\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * this test indexes random numbers within a range into a field and checks\n   * their occurrences by searching for a number from that range selected at\n   * random. All positions for that number are saved up front and compared to\n   * the enums positions.\n   */\n  public void testRandomPositons() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(\n            MockTokenizer.WHITESPACE, true, usePayload)));\n    int numDocs = 131;\n    int max = 1051;\n    int term = random.nextInt(max);\n    Integer[][] positionsInDoc = new Integer[numDocs][];\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      ArrayList<Integer> positions = new ArrayList<Integer>();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 3049; j++) {\n        int nextInt = random.nextInt(max);\n        builder.append(nextInt).append(\" \");\n        if (nextInt == term) {\n          positions.add(Integer.valueOf(j));\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), Field.Store.YES,\n          Field.Index.ANALYZED));\n      positionsInDoc[i] = positions.toArray(new Integer[0]);\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    for (int i = 0; i < 39 * RANDOM_MULTIPLIER; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      ReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = ReaderUtil.leaves(topReaderContext);\n      for (AtomicReaderContext atomicReaderContext : leaves) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader, bytes, null);\n        assertNotNull(docsAndPosEnum);\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader.maxDoc();\n        // initially advance or do next doc\n        if (random.nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random.nextInt(maxDoc));\n        }\n        // now run through the scorer and check if all positions are there...\n        do {\n          int docID = docsAndPosEnum.docID();\n          if (docID == DocsAndPositionsEnum.NO_MORE_DOCS) {\n            break;\n          }\n          Integer[] pos = positionsInDoc[atomicReaderContext.docBase + docID];\n          assertEquals(pos.length, docsAndPosEnum.freq());\n          // number of positions read should be random - don't read all of them\n          // allways\n          final int howMany = random.nextInt(20) == 0 ? pos.length\n              - random.nextInt(pos.length) : pos.length;\n          for (int j = 0; j < howMany; j++) {\n            assertEquals(\"iteration: \" + i + \" initDoc: \" + initDoc + \" doc: \"\n                + docID + \" base: \" + atomicReaderContext.docBase\n                + \" positions: \" + Arrays.toString(pos) + \" usePayloads: \"\n                + usePayload, pos[j].intValue(), docsAndPosEnum.nextPosition());\n          }\n\n          if (random.nextInt(10) == 0) { // once is a while advance\n            docsAndPosEnum\n                .advance(docID + 1 + random.nextInt((maxDoc - docID)));\n          }\n\n        } while (docsAndPosEnum.nextDoc() != DocsAndPositionsEnum.NO_MORE_DOCS);\n      }\n\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"9d7606b7ab7992bc238d10c3bddfe82a639d212a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a05ba0a6bd886c85c738ed2529954ff8c3ba5c06":["9d7606b7ab7992bc238d10c3bddfe82a639d212a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a05ba0a6bd886c85c738ed2529954ff8c3ba5c06"]},"commit2Childs":{"9d7606b7ab7992bc238d10c3bddfe82a639d212a":["a05ba0a6bd886c85c738ed2529954ff8c3ba5c06"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9d7606b7ab7992bc238d10c3bddfe82a639d212a"],"a05ba0a6bd886c85c738ed2529954ff8c3ba5c06":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}