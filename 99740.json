{"path":"lucene/core/src/java/org/apache/lucene/search/ExactPhraseMatcher#mergeImpacts(ImpactsEnum[]).mjava","commits":[{"id":"f8dd25829321d66cd54ea7d40a4130e0d2a29bec","date":1562680889,"type":0,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/ExactPhraseMatcher#mergeImpacts(ImpactsEnum[]).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Merge impacts for multiple terms of an exact phrase.\n   */\n  static ImpactsSource mergeImpacts(ImpactsEnum[] impactsEnums) {\n    // Iteration of block boundaries uses the impacts enum with the lower cost.\n    // This is consistent with BlockMaxConjunctionScorer.\n    int tmpLeadIndex = -1;\n    for (int i = 0; i < impactsEnums.length; ++i) {\n      if (tmpLeadIndex == -1 || impactsEnums[i].cost() < impactsEnums[tmpLeadIndex].cost()) {\n        tmpLeadIndex = i;\n      }\n    }\n    final int leadIndex = tmpLeadIndex;\n\n    return new ImpactsSource() {\n\n      class SubIterator {\n        final Iterator<Impact> iterator;\n        Impact current;\n\n        SubIterator(List<Impact> impacts) {\n          this.iterator = impacts.iterator();\n          this.current = iterator.next();\n        }\n\n        boolean next() {\n          if (iterator.hasNext() == false) {\n            current = null;\n            return false;\n          } else {\n            current = iterator.next();\n            return true;\n          }\n        }\n      }\n\n      @Override\n      public Impacts getImpacts() throws IOException {\n        final Impacts[] impacts = new Impacts[impactsEnums.length];\n        for (int i = 0; i < impactsEnums.length; ++i) {\n          impacts[i] = impactsEnums[i].getImpacts();\n        }\n        final Impacts lead = impacts[leadIndex];\n        return new Impacts() {\n\n          @Override\n          public int numLevels() {\n            // Delegate to the lead\n            return lead.numLevels();\n          }\n\n          @Override\n          public int getDocIdUpTo(int level) {\n            // Delegate to the lead\n            return lead.getDocIdUpTo(level);\n          }\n\n          /**\n           * Return the minimum level whose impacts are valid up to {@code docIdUpTo},\n           * or {@code -1} if there is no such level.\n           */\n          private int getLevel(Impacts impacts, int docIdUpTo) {\n            for (int level = 0, numLevels = impacts.numLevels(); level < numLevels; ++level) {\n              if (impacts.getDocIdUpTo(level) >= docIdUpTo) {\n                return level;\n              }\n            }\n            return -1;\n          }\n\n          @Override\n          public List<Impact> getImpacts(int level) {\n            final int docIdUpTo = getDocIdUpTo(level);\n\n            PriorityQueue<SubIterator> pq = new PriorityQueue<SubIterator>(impacts.length) {\n              @Override\n              protected boolean lessThan(SubIterator a, SubIterator b) {\n                return a.current.freq < b.current.freq;\n              }\n            };\n\n            boolean hasImpacts = false;\n            List<Impact> onlyImpactList = null;\n            for (int i = 0; i < impacts.length; ++i) {\n              int impactsLevel = getLevel(impacts[i], docIdUpTo);\n              if (impactsLevel == -1) {\n                // This instance doesn't have useful impacts, ignore it: this is safe.\n                continue;\n              }\n\n              List<Impact> impactList = impacts[i].getImpacts(impactsLevel);\n              Impact firstImpact = impactList.get(0);\n              if (firstImpact.freq == Integer.MAX_VALUE && firstImpact.norm == 1L) {\n                // Dummy impacts, ignore it too.\n                continue;\n              }\n\n              SubIterator subIterator = new SubIterator(impactList);\n              pq.add(subIterator);\n              if (hasImpacts == false) {\n                hasImpacts = true;\n                onlyImpactList = impactList;\n              } else {\n                onlyImpactList = null; // there are multiple impacts\n              }\n            }\n\n            if (hasImpacts == false) {\n              return Collections.singletonList(new Impact(Integer.MAX_VALUE, 1L));\n            } else if (onlyImpactList != null) {\n              return onlyImpactList;\n            }\n\n            // Idea: merge impacts by freq. The tricky thing is that we need to\n            // consider freq values that are not in the impacts too. For\n            // instance if the list of impacts is [{freq=2,norm=10}, {freq=4,norm=12}],\n            // there might well be a document that has a freq of 2 and a length of 11,\n            // which was just not added to the list of impacts because {freq=2,norm=10}\n            // is more competitive.\n            // We walk impacts in parallel through a PQ ordered by freq. At any time,\n            // the competitive impact consists of the lowest freq among all entries of\n            // the PQ (the top) and the highest norm (tracked separately).\n            List<Impact> mergedImpacts = new ArrayList<>();\n            SubIterator top = pq.top();\n            int currentFreq = top.current.freq;\n            long currentNorm = 0;\n            for (SubIterator it : pq) {\n              if (Long.compareUnsigned(it.current.norm, currentNorm) > 0) {\n                currentNorm = it.current.norm;\n              }\n            }\n\n            outer: while (true) {\n              if (mergedImpacts.size() > 0 && mergedImpacts.get(mergedImpacts.size() - 1).norm == currentNorm) {\n                mergedImpacts.get(mergedImpacts.size() - 1).freq = currentFreq;\n              } else {\n                mergedImpacts.add(new Impact(currentFreq, currentNorm));\n              }\n\n              do {\n                if (top.next() == false) {\n                  // At least one clause doesn't have any more documents below the current norm,\n                  // so we can safely ignore further clauses. The only reason why they have more\n                  // impacts is because they cover more documents that we are not interested in.\n                  break outer;\n                }\n                if (Long.compareUnsigned(top.current.norm, currentNorm) > 0) {\n                  currentNorm = top.current.norm;\n                }\n                top = pq.updateTop();\n              } while (top.current.freq == currentFreq);\n\n              currentFreq = top.current.freq;\n            }\n\n            return mergedImpacts;\n          }\n        };\n      }\n\n      @Override\n      public void advanceShallow(int target) throws IOException {\n        for (ImpactsEnum impactsEnum : impactsEnums) {\n          impactsEnum.advanceShallow(target);\n        }\n      }\n    };\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"f8dd25829321d66cd54ea7d40a4130e0d2a29bec":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["f8dd25829321d66cd54ea7d40a4130e0d2a29bec"]},"commit2Childs":{"f8dd25829321d66cd54ea7d40a4130e0d2a29bec":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["f8dd25829321d66cd54ea7d40a4130e0d2a29bec"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}