{"path":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfoPerCommit,IOContext).mjava","commits":[{"id":"a45bec74b98f6fc05f52770cfb425739e6563960","date":1375119292,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfoPerCommit,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfoPerCommit,IOContext,int).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfoPerCommit si, IOContext context) throws IOException {\n    \n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.info.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      fieldInfos = codec.fieldInfosFormat().getFieldInfosReader().read(cfsDir, si.info.name, IOContext.READONCE);\n\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, fieldInfos, context);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n\n      if (fieldInfos.hasDocValues()) {\n        dvProducer = codec.docValuesFormat().fieldsProducer(segmentReadState);\n        assert dvProducer != null;\n      } else {\n        dvProducer = null;\n      }\n\n      if (fieldInfos.hasNorms()) {\n        normsProducer = codec.normsFormat().normsProducer(segmentReadState);\n        assert normsProducer != null;\n      } else {\n        normsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, fieldInfos, context);\n\n      if (fieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfoPerCommit si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.info.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      fieldInfos = codec.fieldInfosFormat().getFieldInfosReader().read(cfsDir, si.info.name, IOContext.READONCE);\n\n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n\n      if (fieldInfos.hasDocValues()) {\n        dvProducer = codec.docValuesFormat().fieldsProducer(segmentReadState);\n        assert dvProducer != null;\n      } else {\n        dvProducer = null;\n      }\n\n      if (fieldInfos.hasNorms()) {\n        normsProducer = codec.normsFormat().normsProducer(segmentReadState);\n        assert normsProducer != null;\n      } else {\n        normsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, fieldInfos, context);\n\n      if (fieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","date":1376366778,"type":1,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfoPerCommit,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfoPerCommit,IOContext,int).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfoPerCommit si, IOContext context) throws IOException {\n    \n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.info.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      fieldInfos = codec.fieldInfosFormat().getFieldInfosReader().read(cfsDir, si.info.name, IOContext.READONCE);\n\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, fieldInfos, context);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n\n      if (fieldInfos.hasDocValues()) {\n        dvProducer = codec.docValuesFormat().fieldsProducer(segmentReadState);\n        assert dvProducer != null;\n      } else {\n        dvProducer = null;\n      }\n\n      if (fieldInfos.hasNorms()) {\n        normsProducer = codec.normsFormat().normsProducer(segmentReadState);\n        assert normsProducer != null;\n      } else {\n        normsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, fieldInfos, context);\n\n      if (fieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfoPerCommit si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.info.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      fieldInfos = codec.fieldInfosFormat().getFieldInfosReader().read(cfsDir, si.info.name, IOContext.READONCE);\n\n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n\n      if (fieldInfos.hasDocValues()) {\n        dvProducer = codec.docValuesFormat().fieldsProducer(segmentReadState);\n        assert dvProducer != null;\n      } else {\n        dvProducer = null;\n      }\n\n      if (fieldInfos.hasNorms()) {\n        normsProducer = codec.normsFormat().normsProducer(segmentReadState);\n        assert normsProducer != null;\n      } else {\n        normsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, fieldInfos, context);\n\n      if (fieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e072d0b1fc19e0533d8ce432eed245196bca6fde","date":1379265112,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfoPerCommit,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfoPerCommit,IOContext).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfoPerCommit si, IOContext context) throws IOException {\n    \n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.info.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n\n      fieldInfos = codec.fieldInfosFormat().getFieldInfosReader().read(cfsDir, si.info.name, IOContext.READONCE);\n      \n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, fieldInfos, context);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n\n      if (fieldInfos.hasNorms()) {\n        normsProducer = codec.normsFormat().normsProducer(segmentReadState);\n        assert normsProducer != null;\n      } else {\n        normsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, fieldInfos, context);\n\n      if (fieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfoPerCommit si, IOContext context) throws IOException {\n    \n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.info.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      fieldInfos = codec.fieldInfosFormat().getFieldInfosReader().read(cfsDir, si.info.name, IOContext.READONCE);\n\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, fieldInfos, context);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n\n      if (fieldInfos.hasDocValues()) {\n        dvProducer = codec.docValuesFormat().fieldsProducer(segmentReadState);\n        assert dvProducer != null;\n      } else {\n        dvProducer = null;\n      }\n\n      if (fieldInfos.hasNorms()) {\n        normsProducer = codec.normsFormat().normsProducer(segmentReadState);\n        assert normsProducer != null;\n      } else {\n        normsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, fieldInfos, context);\n\n      if (fieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8435160e9702b19398118ddf76b61c846612b6a4","date":1380349140,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfoPerCommit,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfoPerCommit,IOContext).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfoPerCommit si, IOContext context) throws IOException {\n    \n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.info.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n\n      final FieldInfos fieldInfos = owner.fieldInfos;\n      \n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, fieldInfos, context);\n      final PostingsFormat format = codec.postingsFormat();\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n\n      if (fieldInfos.hasNorms()) {\n        normsProducer = codec.normsFormat().normsProducer(segmentReadState);\n        assert normsProducer != null;\n      } else {\n        normsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, fieldInfos, context);\n\n      if (fieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfoPerCommit si, IOContext context) throws IOException {\n    \n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.info.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n\n      fieldInfos = codec.fieldInfosFormat().getFieldInfosReader().read(cfsDir, si.info.name, IOContext.READONCE);\n      \n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, fieldInfos, context);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n\n      if (fieldInfos.hasNorms()) {\n        normsProducer = codec.normsFormat().normsProducer(segmentReadState);\n        assert normsProducer != null;\n      } else {\n        normsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, fieldInfos, context);\n\n      if (fieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d2dcffe8fc78b093a5f4207f492bbae185740f6a","date":1380887572,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfoPerCommit,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfoPerCommit,IOContext).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfoPerCommit si, IOContext context) throws IOException {\n\n    // SegmentReader uses us as the coreCacheKey; we cannot\n    // call owner.getCoreCacheKey() because that will return\n    // null!:\n    this.ownerCoreCacheKey = this;\n\n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.info.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n\n      final FieldInfos fieldInfos = owner.fieldInfos;\n      \n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, fieldInfos, context);\n      final PostingsFormat format = codec.postingsFormat();\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n\n      if (fieldInfos.hasNorms()) {\n        normsProducer = codec.normsFormat().normsProducer(segmentReadState);\n        assert normsProducer != null;\n      } else {\n        normsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, fieldInfos, context);\n\n      if (fieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfoPerCommit si, IOContext context) throws IOException {\n    \n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.info.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n\n      final FieldInfos fieldInfos = owner.fieldInfos;\n      \n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, fieldInfos, context);\n      final PostingsFormat format = codec.postingsFormat();\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n\n      if (fieldInfos.hasNorms()) {\n        normsProducer = codec.normsFormat().normsProducer(segmentReadState);\n        assert normsProducer != null;\n      } else {\n        normsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, fieldInfos, context);\n\n      if (fieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":["e088904f43a479ba66abab8576fc76f8e080583d"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e088904f43a479ba66abab8576fc76f8e080583d","date":1380889210,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfoPerCommit,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfoPerCommit,IOContext).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfoPerCommit si, IOContext context) throws IOException {\n\n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.info.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n\n      final FieldInfos fieldInfos = owner.fieldInfos;\n      \n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, fieldInfos, context);\n      final PostingsFormat format = codec.postingsFormat();\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n\n      if (fieldInfos.hasNorms()) {\n        normsProducer = codec.normsFormat().normsProducer(segmentReadState);\n        assert normsProducer != null;\n      } else {\n        normsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, fieldInfos, context);\n\n      if (fieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfoPerCommit si, IOContext context) throws IOException {\n\n    // SegmentReader uses us as the coreCacheKey; we cannot\n    // call owner.getCoreCacheKey() because that will return\n    // null!:\n    this.ownerCoreCacheKey = this;\n\n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.info.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n\n      final FieldInfos fieldInfos = owner.fieldInfos;\n      \n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, fieldInfos, context);\n      final PostingsFormat format = codec.postingsFormat();\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n\n      if (fieldInfos.hasNorms()) {\n        normsProducer = codec.normsFormat().normsProducer(segmentReadState);\n        assert normsProducer != null;\n      } else {\n        normsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, fieldInfos, context);\n\n      if (fieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n  }\n\n","bugFix":["d2dcffe8fc78b093a5f4207f492bbae185740f6a"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0","date":1383367127,"type":5,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentCommitInfo,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfoPerCommit,IOContext).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentCommitInfo si, IOContext context) throws IOException {\n\n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.info.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n\n      final FieldInfos fieldInfos = owner.fieldInfos;\n      \n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, fieldInfos, context);\n      final PostingsFormat format = codec.postingsFormat();\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n\n      if (fieldInfos.hasNorms()) {\n        normsProducer = codec.normsFormat().normsProducer(segmentReadState);\n        assert normsProducer != null;\n      } else {\n        normsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, fieldInfos, context);\n\n      if (fieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfoPerCommit si, IOContext context) throws IOException {\n\n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.info.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n\n      final FieldInfos fieldInfos = owner.fieldInfos;\n      \n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, fieldInfos, context);\n      final PostingsFormat format = codec.postingsFormat();\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n\n      if (fieldInfos.hasNorms()) {\n        normsProducer = codec.normsFormat().normsProducer(segmentReadState);\n        assert normsProducer != null;\n      } else {\n        normsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, fieldInfos, context);\n\n      if (fieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"e072d0b1fc19e0533d8ce432eed245196bca6fde":["a45bec74b98f6fc05f52770cfb425739e6563960"],"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0":["e088904f43a479ba66abab8576fc76f8e080583d"],"e088904f43a479ba66abab8576fc76f8e080583d":["d2dcffe8fc78b093a5f4207f492bbae185740f6a"],"a45bec74b98f6fc05f52770cfb425739e6563960":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"d2dcffe8fc78b093a5f4207f492bbae185740f6a":["8435160e9702b19398118ddf76b61c846612b6a4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"8435160e9702b19398118ddf76b61c846612b6a4":["e072d0b1fc19e0533d8ce432eed245196bca6fde"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0"]},"commit2Childs":{"e072d0b1fc19e0533d8ce432eed245196bca6fde":["8435160e9702b19398118ddf76b61c846612b6a4"],"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"e088904f43a479ba66abab8576fc76f8e080583d":["73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0"],"a45bec74b98f6fc05f52770cfb425739e6563960":["e072d0b1fc19e0533d8ce432eed245196bca6fde"],"d2dcffe8fc78b093a5f4207f492bbae185740f6a":["e088904f43a479ba66abab8576fc76f8e080583d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a45bec74b98f6fc05f52770cfb425739e6563960","8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee"],"8435160e9702b19398118ddf76b61c846612b6a4":["d2dcffe8fc78b093a5f4207f492bbae185740f6a"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}