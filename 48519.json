{"path":"lucene/contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter#split(IndexReader,Directory[],boolean).mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter#split(IndexReader,Directory[],boolean).mjava","pathOld":"contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter#split(IndexReader,Directory[],boolean).mjava","sourceNew":"  /**\n   * Split source index into multiple parts.\n   * @param input source index, can be read-only, can have deletions, can have\n   * multiple segments (or multiple readers).\n   * @param outputs list of directories where the output parts will be stored.\n   * @param seq if true, then the source index will be split into equal\n   * increasing ranges of document id-s. If false, source document id-s will be\n   * assigned in a deterministic round-robin fashion to one of the output splits.\n   * @throws IOException\n   */\n  public void split(IndexReader input, Directory[] outputs, boolean seq) throws IOException {\n    if (outputs == null || outputs.length < 2) {\n      throw new IOException(\"Invalid number of outputs.\");\n    }\n    if (input == null || input.numDocs() < 2) {\n      throw new IOException(\"Not enough documents for splitting\");\n    }\n    int numParts = outputs.length;\n    // wrap a potentially read-only input\n    // this way we don't have to preserve original deletions because neither\n    // deleteDocument(int) or undeleteAll() is applied to the wrapped input index.\n    input = new FakeDeleteIndexReader(input);\n    int maxDoc = input.maxDoc();\n    int partLen = maxDoc / numParts;\n    for (int i = 0; i < numParts; i++) {\n      input.undeleteAll();\n      if (seq) { // sequential range\n        int lo = partLen * i;\n        int hi = lo + partLen;\n        // below range\n        for (int j = 0; j < lo; j++) {\n          input.deleteDocument(j);\n        }\n        // above range - last part collects all id-s that remained due to\n        // integer rounding errors\n        if (i < numParts - 1) {\n          for (int j = hi; j < maxDoc; j++) {\n            input.deleteDocument(j);\n          }\n        }\n      } else {\n        // round-robin\n        for (int j = 0; j < maxDoc; j++) {\n          if ((j + numParts - i) % numParts != 0) {\n            input.deleteDocument(j);\n          }\n        }\n      }\n      IndexWriter w = new IndexWriter(outputs[i], new IndexWriterConfig(\n          Version.LUCENE_CURRENT,\n          new WhitespaceAnalyzer(Version.LUCENE_CURRENT))\n          .setOpenMode(OpenMode.CREATE));\n      System.err.println(\"Writing part \" + (i + 1) + \" ...\");\n      w.addIndexes(new IndexReader[]{input});\n      w.close();\n    }\n    System.err.println(\"Done.\");\n  }\n\n","sourceOld":"  /**\n   * Split source index into multiple parts.\n   * @param input source index, can be read-only, can have deletions, can have\n   * multiple segments (or multiple readers).\n   * @param outputs list of directories where the output parts will be stored.\n   * @param seq if true, then the source index will be split into equal\n   * increasing ranges of document id-s. If false, source document id-s will be\n   * assigned in a deterministic round-robin fashion to one of the output splits.\n   * @throws IOException\n   */\n  public void split(IndexReader input, Directory[] outputs, boolean seq) throws IOException {\n    if (outputs == null || outputs.length < 2) {\n      throw new IOException(\"Invalid number of outputs.\");\n    }\n    if (input == null || input.numDocs() < 2) {\n      throw new IOException(\"Not enough documents for splitting\");\n    }\n    int numParts = outputs.length;\n    // wrap a potentially read-only input\n    // this way we don't have to preserve original deletions because neither\n    // deleteDocument(int) or undeleteAll() is applied to the wrapped input index.\n    input = new FakeDeleteIndexReader(input);\n    int maxDoc = input.maxDoc();\n    int partLen = maxDoc / numParts;\n    for (int i = 0; i < numParts; i++) {\n      input.undeleteAll();\n      if (seq) { // sequential range\n        int lo = partLen * i;\n        int hi = lo + partLen;\n        // below range\n        for (int j = 0; j < lo; j++) {\n          input.deleteDocument(j);\n        }\n        // above range - last part collects all id-s that remained due to\n        // integer rounding errors\n        if (i < numParts - 1) {\n          for (int j = hi; j < maxDoc; j++) {\n            input.deleteDocument(j);\n          }\n        }\n      } else {\n        // round-robin\n        for (int j = 0; j < maxDoc; j++) {\n          if ((j + numParts - i) % numParts != 0) {\n            input.deleteDocument(j);\n          }\n        }\n      }\n      IndexWriter w = new IndexWriter(outputs[i], new IndexWriterConfig(\n          Version.LUCENE_CURRENT,\n          new WhitespaceAnalyzer(Version.LUCENE_CURRENT))\n          .setOpenMode(OpenMode.CREATE));\n      System.err.println(\"Writing part \" + (i + 1) + \" ...\");\n      w.addIndexes(new IndexReader[]{input});\n      w.close();\n    }\n    System.err.println(\"Done.\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4e8cc373c801e54cec75daf9f52792cb4b17f536","date":1291116159,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter#split(IndexReader,Directory[],boolean).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter#split(IndexReader,Directory[],boolean).mjava","sourceNew":"  /**\n   * Split source index into multiple parts.\n   * @param input source index, can be read-only, can have deletions, can have\n   * multiple segments (or multiple readers).\n   * @param outputs list of directories where the output parts will be stored.\n   * @param seq if true, then the source index will be split into equal\n   * increasing ranges of document id-s. If false, source document id-s will be\n   * assigned in a deterministic round-robin fashion to one of the output splits.\n   * @throws IOException\n   */\n  public void split(IndexReader input, Directory[] outputs, boolean seq) throws IOException {\n    if (outputs == null || outputs.length < 2) {\n      throw new IOException(\"Invalid number of outputs.\");\n    }\n    if (input == null || input.numDocs() < 2) {\n      throw new IOException(\"Not enough documents for splitting\");\n    }\n    int numParts = outputs.length;\n    // wrap a potentially read-only input\n    // this way we don't have to preserve original deletions because neither\n    // deleteDocument(int) or undeleteAll() is applied to the wrapped input index.\n    input = new FakeDeleteIndexReader(input);\n    int maxDoc = input.maxDoc();\n    int partLen = maxDoc / numParts;\n    for (int i = 0; i < numParts; i++) {\n      input.undeleteAll();\n      if (seq) { // sequential range\n        int lo = partLen * i;\n        int hi = lo + partLen;\n        // below range\n        for (int j = 0; j < lo; j++) {\n          input.deleteDocument(j);\n        }\n        // above range - last part collects all id-s that remained due to\n        // integer rounding errors\n        if (i < numParts - 1) {\n          for (int j = hi; j < maxDoc; j++) {\n            input.deleteDocument(j);\n          }\n        }\n      } else {\n        // round-robin\n        for (int j = 0; j < maxDoc; j++) {\n          if ((j + numParts - i) % numParts != 0) {\n            input.deleteDocument(j);\n          }\n        }\n      }\n      IndexWriter w = new IndexWriter(outputs[i], new IndexWriterConfig(\n          Version.LUCENE_CURRENT,\n          new WhitespaceAnalyzer(Version.LUCENE_CURRENT))\n          .setOpenMode(OpenMode.CREATE));\n      System.err.println(\"Writing part \" + (i + 1) + \" ...\");\n      w.addIndexes(input);\n      w.close();\n    }\n    System.err.println(\"Done.\");\n  }\n\n","sourceOld":"  /**\n   * Split source index into multiple parts.\n   * @param input source index, can be read-only, can have deletions, can have\n   * multiple segments (or multiple readers).\n   * @param outputs list of directories where the output parts will be stored.\n   * @param seq if true, then the source index will be split into equal\n   * increasing ranges of document id-s. If false, source document id-s will be\n   * assigned in a deterministic round-robin fashion to one of the output splits.\n   * @throws IOException\n   */\n  public void split(IndexReader input, Directory[] outputs, boolean seq) throws IOException {\n    if (outputs == null || outputs.length < 2) {\n      throw new IOException(\"Invalid number of outputs.\");\n    }\n    if (input == null || input.numDocs() < 2) {\n      throw new IOException(\"Not enough documents for splitting\");\n    }\n    int numParts = outputs.length;\n    // wrap a potentially read-only input\n    // this way we don't have to preserve original deletions because neither\n    // deleteDocument(int) or undeleteAll() is applied to the wrapped input index.\n    input = new FakeDeleteIndexReader(input);\n    int maxDoc = input.maxDoc();\n    int partLen = maxDoc / numParts;\n    for (int i = 0; i < numParts; i++) {\n      input.undeleteAll();\n      if (seq) { // sequential range\n        int lo = partLen * i;\n        int hi = lo + partLen;\n        // below range\n        for (int j = 0; j < lo; j++) {\n          input.deleteDocument(j);\n        }\n        // above range - last part collects all id-s that remained due to\n        // integer rounding errors\n        if (i < numParts - 1) {\n          for (int j = hi; j < maxDoc; j++) {\n            input.deleteDocument(j);\n          }\n        }\n      } else {\n        // round-robin\n        for (int j = 0; j < maxDoc; j++) {\n          if ((j + numParts - i) % numParts != 0) {\n            input.deleteDocument(j);\n          }\n        }\n      }\n      IndexWriter w = new IndexWriter(outputs[i], new IndexWriterConfig(\n          Version.LUCENE_CURRENT,\n          new WhitespaceAnalyzer(Version.LUCENE_CURRENT))\n          .setOpenMode(OpenMode.CREATE));\n      System.err.println(\"Writing part \" + (i + 1) + \" ...\");\n      w.addIndexes(new IndexReader[]{input});\n      w.close();\n    }\n    System.err.println(\"Done.\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3bb13258feba31ab676502787ab2e1779f129b7a","date":1291596436,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter#split(IndexReader,Directory[],boolean).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter#split(IndexReader,Directory[],boolean).mjava","sourceNew":"  /**\n   * Split source index into multiple parts.\n   * @param input source index, can be read-only, can have deletions, can have\n   * multiple segments (or multiple readers).\n   * @param outputs list of directories where the output parts will be stored.\n   * @param seq if true, then the source index will be split into equal\n   * increasing ranges of document id-s. If false, source document id-s will be\n   * assigned in a deterministic round-robin fashion to one of the output splits.\n   * @throws IOException\n   */\n  public void split(IndexReader input, Directory[] outputs, boolean seq) throws IOException {\n    if (outputs == null || outputs.length < 2) {\n      throw new IOException(\"Invalid number of outputs.\");\n    }\n    if (input == null || input.numDocs() < 2) {\n      throw new IOException(\"Not enough documents for splitting\");\n    }\n    int numParts = outputs.length;\n    // wrap a potentially read-only input\n    // this way we don't have to preserve original deletions because neither\n    // deleteDocument(int) or undeleteAll() is applied to the wrapped input index.\n    input = new FakeDeleteIndexReader(input);\n    int maxDoc = input.maxDoc();\n    int partLen = maxDoc / numParts;\n    for (int i = 0; i < numParts; i++) {\n      input.undeleteAll();\n      if (seq) { // sequential range\n        int lo = partLen * i;\n        int hi = lo + partLen;\n        // below range\n        for (int j = 0; j < lo; j++) {\n          input.deleteDocument(j);\n        }\n        // above range - last part collects all id-s that remained due to\n        // integer rounding errors\n        if (i < numParts - 1) {\n          for (int j = hi; j < maxDoc; j++) {\n            input.deleteDocument(j);\n          }\n        }\n      } else {\n        // round-robin\n        for (int j = 0; j < maxDoc; j++) {\n          if ((j + numParts - i) % numParts != 0) {\n            input.deleteDocument(j);\n          }\n        }\n      }\n      IndexWriter w = new IndexWriter(outputs[i], new IndexWriterConfig(\n          Version.LUCENE_CURRENT,\n          new WhitespaceAnalyzer(Version.LUCENE_CURRENT))\n          .setOpenMode(OpenMode.CREATE));\n      System.err.println(\"Writing part \" + (i + 1) + \" ...\");\n      w.addIndexes(input);\n      w.close();\n    }\n    System.err.println(\"Done.\");\n  }\n\n","sourceOld":"  /**\n   * Split source index into multiple parts.\n   * @param input source index, can be read-only, can have deletions, can have\n   * multiple segments (or multiple readers).\n   * @param outputs list of directories where the output parts will be stored.\n   * @param seq if true, then the source index will be split into equal\n   * increasing ranges of document id-s. If false, source document id-s will be\n   * assigned in a deterministic round-robin fashion to one of the output splits.\n   * @throws IOException\n   */\n  public void split(IndexReader input, Directory[] outputs, boolean seq) throws IOException {\n    if (outputs == null || outputs.length < 2) {\n      throw new IOException(\"Invalid number of outputs.\");\n    }\n    if (input == null || input.numDocs() < 2) {\n      throw new IOException(\"Not enough documents for splitting\");\n    }\n    int numParts = outputs.length;\n    // wrap a potentially read-only input\n    // this way we don't have to preserve original deletions because neither\n    // deleteDocument(int) or undeleteAll() is applied to the wrapped input index.\n    input = new FakeDeleteIndexReader(input);\n    int maxDoc = input.maxDoc();\n    int partLen = maxDoc / numParts;\n    for (int i = 0; i < numParts; i++) {\n      input.undeleteAll();\n      if (seq) { // sequential range\n        int lo = partLen * i;\n        int hi = lo + partLen;\n        // below range\n        for (int j = 0; j < lo; j++) {\n          input.deleteDocument(j);\n        }\n        // above range - last part collects all id-s that remained due to\n        // integer rounding errors\n        if (i < numParts - 1) {\n          for (int j = hi; j < maxDoc; j++) {\n            input.deleteDocument(j);\n          }\n        }\n      } else {\n        // round-robin\n        for (int j = 0; j < maxDoc; j++) {\n          if ((j + numParts - i) % numParts != 0) {\n            input.deleteDocument(j);\n          }\n        }\n      }\n      IndexWriter w = new IndexWriter(outputs[i], new IndexWriterConfig(\n          Version.LUCENE_CURRENT,\n          new WhitespaceAnalyzer(Version.LUCENE_CURRENT))\n          .setOpenMode(OpenMode.CREATE));\n      System.err.println(\"Writing part \" + (i + 1) + \" ...\");\n      w.addIndexes(new IndexReader[]{input});\n      w.close();\n    }\n    System.err.println(\"Done.\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter#split(IndexReader,Directory[],boolean).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter#split(IndexReader,Directory[],boolean).mjava","sourceNew":"  /**\n   * Split source index into multiple parts.\n   * @param input source index, can be read-only, can have deletions, can have\n   * multiple segments (or multiple readers).\n   * @param outputs list of directories where the output parts will be stored.\n   * @param seq if true, then the source index will be split into equal\n   * increasing ranges of document id-s. If false, source document id-s will be\n   * assigned in a deterministic round-robin fashion to one of the output splits.\n   * @throws IOException\n   */\n  public void split(IndexReader input, Directory[] outputs, boolean seq) throws IOException {\n    if (outputs == null || outputs.length < 2) {\n      throw new IOException(\"Invalid number of outputs.\");\n    }\n    if (input == null || input.numDocs() < 2) {\n      throw new IOException(\"Not enough documents for splitting\");\n    }\n    int numParts = outputs.length;\n    // wrap a potentially read-only input\n    // this way we don't have to preserve original deletions because neither\n    // deleteDocument(int) or undeleteAll() is applied to the wrapped input index.\n    input = new FakeDeleteIndexReader(input);\n    int maxDoc = input.maxDoc();\n    int partLen = maxDoc / numParts;\n    for (int i = 0; i < numParts; i++) {\n      input.undeleteAll();\n      if (seq) { // sequential range\n        int lo = partLen * i;\n        int hi = lo + partLen;\n        // below range\n        for (int j = 0; j < lo; j++) {\n          input.deleteDocument(j);\n        }\n        // above range - last part collects all id-s that remained due to\n        // integer rounding errors\n        if (i < numParts - 1) {\n          for (int j = hi; j < maxDoc; j++) {\n            input.deleteDocument(j);\n          }\n        }\n      } else {\n        // round-robin\n        for (int j = 0; j < maxDoc; j++) {\n          if ((j + numParts - i) % numParts != 0) {\n            input.deleteDocument(j);\n          }\n        }\n      }\n      IndexWriter w = new IndexWriter(outputs[i], new IndexWriterConfig(\n          Version.LUCENE_CURRENT,\n          new WhitespaceAnalyzer(Version.LUCENE_CURRENT))\n          .setOpenMode(OpenMode.CREATE));\n      System.err.println(\"Writing part \" + (i + 1) + \" ...\");\n      w.addIndexes(input);\n      w.close();\n    }\n    System.err.println(\"Done.\");\n  }\n\n","sourceOld":"  /**\n   * Split source index into multiple parts.\n   * @param input source index, can be read-only, can have deletions, can have\n   * multiple segments (or multiple readers).\n   * @param outputs list of directories where the output parts will be stored.\n   * @param seq if true, then the source index will be split into equal\n   * increasing ranges of document id-s. If false, source document id-s will be\n   * assigned in a deterministic round-robin fashion to one of the output splits.\n   * @throws IOException\n   */\n  public void split(IndexReader input, Directory[] outputs, boolean seq) throws IOException {\n    if (outputs == null || outputs.length < 2) {\n      throw new IOException(\"Invalid number of outputs.\");\n    }\n    if (input == null || input.numDocs() < 2) {\n      throw new IOException(\"Not enough documents for splitting\");\n    }\n    int numParts = outputs.length;\n    // wrap a potentially read-only input\n    // this way we don't have to preserve original deletions because neither\n    // deleteDocument(int) or undeleteAll() is applied to the wrapped input index.\n    input = new FakeDeleteIndexReader(input);\n    int maxDoc = input.maxDoc();\n    int partLen = maxDoc / numParts;\n    for (int i = 0; i < numParts; i++) {\n      input.undeleteAll();\n      if (seq) { // sequential range\n        int lo = partLen * i;\n        int hi = lo + partLen;\n        // below range\n        for (int j = 0; j < lo; j++) {\n          input.deleteDocument(j);\n        }\n        // above range - last part collects all id-s that remained due to\n        // integer rounding errors\n        if (i < numParts - 1) {\n          for (int j = hi; j < maxDoc; j++) {\n            input.deleteDocument(j);\n          }\n        }\n      } else {\n        // round-robin\n        for (int j = 0; j < maxDoc; j++) {\n          if ((j + numParts - i) % numParts != 0) {\n            input.deleteDocument(j);\n          }\n        }\n      }\n      IndexWriter w = new IndexWriter(outputs[i], new IndexWriterConfig(\n          Version.LUCENE_CURRENT,\n          new WhitespaceAnalyzer(Version.LUCENE_CURRENT))\n          .setOpenMode(OpenMode.CREATE));\n      System.err.println(\"Writing part \" + (i + 1) + \" ...\");\n      w.addIndexes(new IndexReader[]{input});\n      w.close();\n    }\n    System.err.println(\"Done.\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"31fd188d5e34d3af6691f8428fecc2d4665e2d56","date":1309225455,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter#split(IndexReader,Directory[],boolean).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter#split(IndexReader,Directory[],boolean).mjava","sourceNew":"  /**\n   * Split source index into multiple parts.\n   * @param input source index, can be read-only, can have deletions, can have\n   * multiple segments (or multiple readers).\n   * @param outputs list of directories where the output parts will be stored.\n   * @param seq if true, then the source index will be split into equal\n   * increasing ranges of document id-s. If false, source document id-s will be\n   * assigned in a deterministic round-robin fashion to one of the output splits.\n   * @throws IOException\n   */\n  public void split(IndexReader input, Directory[] outputs, boolean seq) throws IOException {\n    if (outputs == null || outputs.length < 2) {\n      throw new IOException(\"Invalid number of outputs.\");\n    }\n    if (input == null || input.numDocs() < 2) {\n      throw new IOException(\"Not enough documents for splitting\");\n    }\n    int numParts = outputs.length;\n    // wrap a potentially read-only input\n    // this way we don't have to preserve original deletions because neither\n    // deleteDocument(int) or undeleteAll() is applied to the wrapped input index.\n    input = new FakeDeleteIndexReader(input);\n    int maxDoc = input.maxDoc();\n    int partLen = maxDoc / numParts;\n    for (int i = 0; i < numParts; i++) {\n      input.undeleteAll();\n      if (seq) { // sequential range\n        int lo = partLen * i;\n        int hi = lo + partLen;\n        // below range\n        for (int j = 0; j < lo; j++) {\n          input.deleteDocument(j);\n        }\n        // above range - last part collects all id-s that remained due to\n        // integer rounding errors\n        if (i < numParts - 1) {\n          for (int j = hi; j < maxDoc; j++) {\n            input.deleteDocument(j);\n          }\n        }\n      } else {\n        // round-robin\n        for (int j = 0; j < maxDoc; j++) {\n          if ((j + numParts - i) % numParts != 0) {\n            input.deleteDocument(j);\n          }\n        }\n      }\n      IndexWriter w = new IndexWriter(outputs[i], new IndexWriterConfig(\n          Version.LUCENE_CURRENT,\n          null)\n          .setOpenMode(OpenMode.CREATE));\n      System.err.println(\"Writing part \" + (i + 1) + \" ...\");\n      w.addIndexes(input);\n      w.close();\n    }\n    System.err.println(\"Done.\");\n  }\n\n","sourceOld":"  /**\n   * Split source index into multiple parts.\n   * @param input source index, can be read-only, can have deletions, can have\n   * multiple segments (or multiple readers).\n   * @param outputs list of directories where the output parts will be stored.\n   * @param seq if true, then the source index will be split into equal\n   * increasing ranges of document id-s. If false, source document id-s will be\n   * assigned in a deterministic round-robin fashion to one of the output splits.\n   * @throws IOException\n   */\n  public void split(IndexReader input, Directory[] outputs, boolean seq) throws IOException {\n    if (outputs == null || outputs.length < 2) {\n      throw new IOException(\"Invalid number of outputs.\");\n    }\n    if (input == null || input.numDocs() < 2) {\n      throw new IOException(\"Not enough documents for splitting\");\n    }\n    int numParts = outputs.length;\n    // wrap a potentially read-only input\n    // this way we don't have to preserve original deletions because neither\n    // deleteDocument(int) or undeleteAll() is applied to the wrapped input index.\n    input = new FakeDeleteIndexReader(input);\n    int maxDoc = input.maxDoc();\n    int partLen = maxDoc / numParts;\n    for (int i = 0; i < numParts; i++) {\n      input.undeleteAll();\n      if (seq) { // sequential range\n        int lo = partLen * i;\n        int hi = lo + partLen;\n        // below range\n        for (int j = 0; j < lo; j++) {\n          input.deleteDocument(j);\n        }\n        // above range - last part collects all id-s that remained due to\n        // integer rounding errors\n        if (i < numParts - 1) {\n          for (int j = hi; j < maxDoc; j++) {\n            input.deleteDocument(j);\n          }\n        }\n      } else {\n        // round-robin\n        for (int j = 0; j < maxDoc; j++) {\n          if ((j + numParts - i) % numParts != 0) {\n            input.deleteDocument(j);\n          }\n        }\n      }\n      IndexWriter w = new IndexWriter(outputs[i], new IndexWriterConfig(\n          Version.LUCENE_CURRENT,\n          new WhitespaceAnalyzer(Version.LUCENE_CURRENT))\n          .setOpenMode(OpenMode.CREATE));\n      System.err.println(\"Writing part \" + (i + 1) + \" ...\");\n      w.addIndexes(input);\n      w.close();\n    }\n    System.err.println(\"Done.\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2553b00f699380c64959ccb27991289aae87be2e","date":1309290151,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter#split(IndexReader,Directory[],boolean).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter#split(IndexReader,Directory[],boolean).mjava","sourceNew":"  /**\n   * Split source index into multiple parts.\n   * @param input source index, can be read-only, can have deletions, can have\n   * multiple segments (or multiple readers).\n   * @param outputs list of directories where the output parts will be stored.\n   * @param seq if true, then the source index will be split into equal\n   * increasing ranges of document id-s. If false, source document id-s will be\n   * assigned in a deterministic round-robin fashion to one of the output splits.\n   * @throws IOException\n   */\n  public void split(IndexReader input, Directory[] outputs, boolean seq) throws IOException {\n    if (outputs == null || outputs.length < 2) {\n      throw new IOException(\"Invalid number of outputs.\");\n    }\n    if (input == null || input.numDocs() < 2) {\n      throw new IOException(\"Not enough documents for splitting\");\n    }\n    int numParts = outputs.length;\n    // wrap a potentially read-only input\n    // this way we don't have to preserve original deletions because neither\n    // deleteDocument(int) or undeleteAll() is applied to the wrapped input index.\n    input = new FakeDeleteIndexReader(input);\n    int maxDoc = input.maxDoc();\n    int partLen = maxDoc / numParts;\n    for (int i = 0; i < numParts; i++) {\n      input.undeleteAll();\n      if (seq) { // sequential range\n        int lo = partLen * i;\n        int hi = lo + partLen;\n        // below range\n        for (int j = 0; j < lo; j++) {\n          input.deleteDocument(j);\n        }\n        // above range - last part collects all id-s that remained due to\n        // integer rounding errors\n        if (i < numParts - 1) {\n          for (int j = hi; j < maxDoc; j++) {\n            input.deleteDocument(j);\n          }\n        }\n      } else {\n        // round-robin\n        for (int j = 0; j < maxDoc; j++) {\n          if ((j + numParts - i) % numParts != 0) {\n            input.deleteDocument(j);\n          }\n        }\n      }\n      IndexWriter w = new IndexWriter(outputs[i], new IndexWriterConfig(\n          Version.LUCENE_CURRENT,\n          null)\n          .setOpenMode(OpenMode.CREATE));\n      System.err.println(\"Writing part \" + (i + 1) + \" ...\");\n      w.addIndexes(input);\n      w.close();\n    }\n    System.err.println(\"Done.\");\n  }\n\n","sourceOld":"  /**\n   * Split source index into multiple parts.\n   * @param input source index, can be read-only, can have deletions, can have\n   * multiple segments (or multiple readers).\n   * @param outputs list of directories where the output parts will be stored.\n   * @param seq if true, then the source index will be split into equal\n   * increasing ranges of document id-s. If false, source document id-s will be\n   * assigned in a deterministic round-robin fashion to one of the output splits.\n   * @throws IOException\n   */\n  public void split(IndexReader input, Directory[] outputs, boolean seq) throws IOException {\n    if (outputs == null || outputs.length < 2) {\n      throw new IOException(\"Invalid number of outputs.\");\n    }\n    if (input == null || input.numDocs() < 2) {\n      throw new IOException(\"Not enough documents for splitting\");\n    }\n    int numParts = outputs.length;\n    // wrap a potentially read-only input\n    // this way we don't have to preserve original deletions because neither\n    // deleteDocument(int) or undeleteAll() is applied to the wrapped input index.\n    input = new FakeDeleteIndexReader(input);\n    int maxDoc = input.maxDoc();\n    int partLen = maxDoc / numParts;\n    for (int i = 0; i < numParts; i++) {\n      input.undeleteAll();\n      if (seq) { // sequential range\n        int lo = partLen * i;\n        int hi = lo + partLen;\n        // below range\n        for (int j = 0; j < lo; j++) {\n          input.deleteDocument(j);\n        }\n        // above range - last part collects all id-s that remained due to\n        // integer rounding errors\n        if (i < numParts - 1) {\n          for (int j = hi; j < maxDoc; j++) {\n            input.deleteDocument(j);\n          }\n        }\n      } else {\n        // round-robin\n        for (int j = 0; j < maxDoc; j++) {\n          if ((j + numParts - i) % numParts != 0) {\n            input.deleteDocument(j);\n          }\n        }\n      }\n      IndexWriter w = new IndexWriter(outputs[i], new IndexWriterConfig(\n          Version.LUCENE_CURRENT,\n          new WhitespaceAnalyzer(Version.LUCENE_CURRENT))\n          .setOpenMode(OpenMode.CREATE));\n      System.err.println(\"Writing part \" + (i + 1) + \" ...\");\n      w.addIndexes(input);\n      w.close();\n    }\n    System.err.println(\"Done.\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d083e83f225b11e5fdd900e83d26ddb385b6955c","date":1310029438,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter#split(IndexReader,Directory[],boolean).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter#split(IndexReader,Directory[],boolean).mjava","sourceNew":"  /**\n   * Split source index into multiple parts.\n   * @param input source index, can be read-only, can have deletions, can have\n   * multiple segments (or multiple readers).\n   * @param outputs list of directories where the output parts will be stored.\n   * @param seq if true, then the source index will be split into equal\n   * increasing ranges of document id-s. If false, source document id-s will be\n   * assigned in a deterministic round-robin fashion to one of the output splits.\n   * @throws IOException\n   */\n  public void split(IndexReader input, Directory[] outputs, boolean seq) throws IOException {\n    if (outputs == null || outputs.length < 2) {\n      throw new IOException(\"Invalid number of outputs.\");\n    }\n    if (input == null || input.numDocs() < 2) {\n      throw new IOException(\"Not enough documents for splitting\");\n    }\n    int numParts = outputs.length;\n    // wrap a potentially read-only input\n    // this way we don't have to preserve original deletions because neither\n    // deleteDocument(int) or undeleteAll() is applied to the wrapped input index.\n    input = new FakeDeleteIndexReader(input);\n    int maxDoc = input.maxDoc();\n    int partLen = maxDoc / numParts;\n    for (int i = 0; i < numParts; i++) {\n      input.undeleteAll();\n      if (seq) { // sequential range\n        int lo = partLen * i;\n        int hi = lo + partLen;\n        // below range\n        for (int j = 0; j < lo; j++) {\n          input.deleteDocument(j);\n        }\n        // above range - last part collects all id-s that remained due to\n        // integer rounding errors\n        if (i < numParts - 1) {\n          for (int j = hi; j < maxDoc; j++) {\n            input.deleteDocument(j);\n          }\n        }\n      } else {\n        // round-robin\n        for (int j = 0; j < maxDoc; j++) {\n          if ((j + numParts - i) % numParts != 0) {\n            input.deleteDocument(j);\n          }\n        }\n      }\n      IndexWriter w = new IndexWriter(outputs[i], new IndexWriterConfig(\n          Version.LUCENE_CURRENT,\n          null)\n          .setOpenMode(OpenMode.CREATE));\n      System.err.println(\"Writing part \" + (i + 1) + \" ...\");\n      w.addIndexes(input);\n      w.close();\n    }\n    System.err.println(\"Done.\");\n  }\n\n","sourceOld":"  /**\n   * Split source index into multiple parts.\n   * @param input source index, can be read-only, can have deletions, can have\n   * multiple segments (or multiple readers).\n   * @param outputs list of directories where the output parts will be stored.\n   * @param seq if true, then the source index will be split into equal\n   * increasing ranges of document id-s. If false, source document id-s will be\n   * assigned in a deterministic round-robin fashion to one of the output splits.\n   * @throws IOException\n   */\n  public void split(IndexReader input, Directory[] outputs, boolean seq) throws IOException {\n    if (outputs == null || outputs.length < 2) {\n      throw new IOException(\"Invalid number of outputs.\");\n    }\n    if (input == null || input.numDocs() < 2) {\n      throw new IOException(\"Not enough documents for splitting\");\n    }\n    int numParts = outputs.length;\n    // wrap a potentially read-only input\n    // this way we don't have to preserve original deletions because neither\n    // deleteDocument(int) or undeleteAll() is applied to the wrapped input index.\n    input = new FakeDeleteIndexReader(input);\n    int maxDoc = input.maxDoc();\n    int partLen = maxDoc / numParts;\n    for (int i = 0; i < numParts; i++) {\n      input.undeleteAll();\n      if (seq) { // sequential range\n        int lo = partLen * i;\n        int hi = lo + partLen;\n        // below range\n        for (int j = 0; j < lo; j++) {\n          input.deleteDocument(j);\n        }\n        // above range - last part collects all id-s that remained due to\n        // integer rounding errors\n        if (i < numParts - 1) {\n          for (int j = hi; j < maxDoc; j++) {\n            input.deleteDocument(j);\n          }\n        }\n      } else {\n        // round-robin\n        for (int j = 0; j < maxDoc; j++) {\n          if ((j + numParts - i) % numParts != 0) {\n            input.deleteDocument(j);\n          }\n        }\n      }\n      IndexWriter w = new IndexWriter(outputs[i], new IndexWriterConfig(\n          Version.LUCENE_CURRENT,\n          new WhitespaceAnalyzer(Version.LUCENE_CURRENT))\n          .setOpenMode(OpenMode.CREATE));\n      System.err.println(\"Writing part \" + (i + 1) + \" ...\");\n      w.addIndexes(input);\n      w.close();\n    }\n    System.err.println(\"Done.\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"edfbc64812ce67598712702d2e4c81bfefccdd57","date":1310457524,"type":5,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter#split(Version,IndexReader,Directory[],boolean).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter#split(IndexReader,Directory[],boolean).mjava","sourceNew":"  /**\n   * Split source index into multiple parts.\n   * @param input source index, can be read-only, can have deletions, can have\n   * multiple segments (or multiple readers).\n   * @param outputs list of directories where the output parts will be stored.\n   * @param seq if true, then the source index will be split into equal\n   * increasing ranges of document id-s. If false, source document id-s will be\n   * assigned in a deterministic round-robin fashion to one of the output splits.\n   * @throws IOException\n   */\n  public void split(Version version, IndexReader input, Directory[] outputs, boolean seq) throws IOException {\n    if (outputs == null || outputs.length < 2) {\n      throw new IOException(\"Invalid number of outputs.\");\n    }\n    if (input == null || input.numDocs() < 2) {\n      throw new IOException(\"Not enough documents for splitting\");\n    }\n    int numParts = outputs.length;\n    // wrap a potentially read-only input\n    // this way we don't have to preserve original deletions because neither\n    // deleteDocument(int) or undeleteAll() is applied to the wrapped input index.\n    input = new FakeDeleteIndexReader(input);\n    int maxDoc = input.maxDoc();\n    int partLen = maxDoc / numParts;\n    for (int i = 0; i < numParts; i++) {\n      input.undeleteAll();\n      if (seq) { // sequential range\n        int lo = partLen * i;\n        int hi = lo + partLen;\n        // below range\n        for (int j = 0; j < lo; j++) {\n          input.deleteDocument(j);\n        }\n        // above range - last part collects all id-s that remained due to\n        // integer rounding errors\n        if (i < numParts - 1) {\n          for (int j = hi; j < maxDoc; j++) {\n            input.deleteDocument(j);\n          }\n        }\n      } else {\n        // round-robin\n        for (int j = 0; j < maxDoc; j++) {\n          if ((j + numParts - i) % numParts != 0) {\n            input.deleteDocument(j);\n          }\n        }\n      }\n      IndexWriter w = new IndexWriter(outputs[i], new IndexWriterConfig(\n          version,\n          null)\n          .setOpenMode(OpenMode.CREATE));\n      System.err.println(\"Writing part \" + (i + 1) + \" ...\");\n      w.addIndexes(input);\n      w.close();\n    }\n    System.err.println(\"Done.\");\n  }\n\n","sourceOld":"  /**\n   * Split source index into multiple parts.\n   * @param input source index, can be read-only, can have deletions, can have\n   * multiple segments (or multiple readers).\n   * @param outputs list of directories where the output parts will be stored.\n   * @param seq if true, then the source index will be split into equal\n   * increasing ranges of document id-s. If false, source document id-s will be\n   * assigned in a deterministic round-robin fashion to one of the output splits.\n   * @throws IOException\n   */\n  public void split(IndexReader input, Directory[] outputs, boolean seq) throws IOException {\n    if (outputs == null || outputs.length < 2) {\n      throw new IOException(\"Invalid number of outputs.\");\n    }\n    if (input == null || input.numDocs() < 2) {\n      throw new IOException(\"Not enough documents for splitting\");\n    }\n    int numParts = outputs.length;\n    // wrap a potentially read-only input\n    // this way we don't have to preserve original deletions because neither\n    // deleteDocument(int) or undeleteAll() is applied to the wrapped input index.\n    input = new FakeDeleteIndexReader(input);\n    int maxDoc = input.maxDoc();\n    int partLen = maxDoc / numParts;\n    for (int i = 0; i < numParts; i++) {\n      input.undeleteAll();\n      if (seq) { // sequential range\n        int lo = partLen * i;\n        int hi = lo + partLen;\n        // below range\n        for (int j = 0; j < lo; j++) {\n          input.deleteDocument(j);\n        }\n        // above range - last part collects all id-s that remained due to\n        // integer rounding errors\n        if (i < numParts - 1) {\n          for (int j = hi; j < maxDoc; j++) {\n            input.deleteDocument(j);\n          }\n        }\n      } else {\n        // round-robin\n        for (int j = 0; j < maxDoc; j++) {\n          if ((j + numParts - i) % numParts != 0) {\n            input.deleteDocument(j);\n          }\n        }\n      }\n      IndexWriter w = new IndexWriter(outputs[i], new IndexWriterConfig(\n          Version.LUCENE_CURRENT,\n          null)\n          .setOpenMode(OpenMode.CREATE));\n      System.err.println(\"Writing part \" + (i + 1) + \" ...\");\n      w.addIndexes(input);\n      w.close();\n    }\n    System.err.println(\"Done.\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"31fd188d5e34d3af6691f8428fecc2d4665e2d56":["4e8cc373c801e54cec75daf9f52792cb4b17f536"],"edfbc64812ce67598712702d2e4c81bfefccdd57":["31fd188d5e34d3af6691f8428fecc2d4665e2d56"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"2553b00f699380c64959ccb27991289aae87be2e":["4e8cc373c801e54cec75daf9f52792cb4b17f536","31fd188d5e34d3af6691f8428fecc2d4665e2d56"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["9454a6510e2db155fb01faa5c049b06ece95fab9","4e8cc373c801e54cec75daf9f52792cb4b17f536"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["4e8cc373c801e54cec75daf9f52792cb4b17f536","31fd188d5e34d3af6691f8428fecc2d4665e2d56"],"3bb13258feba31ab676502787ab2e1779f129b7a":["9454a6510e2db155fb01faa5c049b06ece95fab9","4e8cc373c801e54cec75daf9f52792cb4b17f536"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["edfbc64812ce67598712702d2e4c81bfefccdd57"],"4e8cc373c801e54cec75daf9f52792cb4b17f536":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"31fd188d5e34d3af6691f8428fecc2d4665e2d56":["edfbc64812ce67598712702d2e4c81bfefccdd57","2553b00f699380c64959ccb27991289aae87be2e","d083e83f225b11e5fdd900e83d26ddb385b6955c"],"edfbc64812ce67598712702d2e4c81bfefccdd57":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"2553b00f699380c64959ccb27991289aae87be2e":[],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":[],"d083e83f225b11e5fdd900e83d26ddb385b6955c":[],"3bb13258feba31ab676502787ab2e1779f129b7a":[],"4e8cc373c801e54cec75daf9f52792cb4b17f536":["31fd188d5e34d3af6691f8428fecc2d4665e2d56","2553b00f699380c64959ccb27991289aae87be2e","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","d083e83f225b11e5fdd900e83d26ddb385b6955c","3bb13258feba31ab676502787ab2e1779f129b7a"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","3bb13258feba31ab676502787ab2e1779f129b7a","4e8cc373c801e54cec75daf9f52792cb4b17f536"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["2553b00f699380c64959ccb27991289aae87be2e","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","d083e83f225b11e5fdd900e83d26ddb385b6955c","3bb13258feba31ab676502787ab2e1779f129b7a","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}