{"path":"solr/core/src/test/org/apache/solr/core/ResourceLoaderTest#testCacheWrongType().mjava","commits":[{"id":"4786eec79a4a669f3272f3a918bc98d63ff01490","date":1570052154,"type":0,"author":"Mike Drob","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/core/ResourceLoaderTest#testCacheWrongType().mjava","pathOld":"/dev/null","sourceNew":"  public void testCacheWrongType() {\n    clearCache();\n\n    SolrResourceLoader loader = new SolrResourceLoader();\n    Class[] params = { Map.class };\n    Map<String,String> args = Map.of(\"minGramSize\", \"1\", \"maxGramSize\", \"2\");\n    final String className = \"solr.NGramTokenizerFactory\";\n\n    // We could fail here since the class name and expected type don't match, but instead we try to infer what the user actually meant\n    TokenFilterFactory tff = loader.newInstance(className, TokenFilterFactory.class, new String[0], params, new Object[]{new HashMap<>(args)});\n    assertNotNull(\"Did not load TokenFilter when asking for corresponding Tokenizer\", tff);\n\n    // This should work, but won't if earlier call succeeding corrupting the cache\n    TokenizerFactory tf = loader.newInstance(className, TokenizerFactory.class, new String[0], params, new Object[]{new HashMap<>(args)});\n    assertNotNull(\"Did not load Tokenizer after bad call earlier\", tf);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b0b597c65628ca9e73913a07e81691f8229bae35","date":1571224353,"type":0,"author":"jimczi","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/core/ResourceLoaderTest#testCacheWrongType().mjava","pathOld":"/dev/null","sourceNew":"  public void testCacheWrongType() {\n    clearCache();\n\n    SolrResourceLoader loader = new SolrResourceLoader();\n    Class[] params = { Map.class };\n    Map<String,String> args = Map.of(\"minGramSize\", \"1\", \"maxGramSize\", \"2\");\n    final String className = \"solr.NGramTokenizerFactory\";\n\n    // We could fail here since the class name and expected type don't match, but instead we try to infer what the user actually meant\n    TokenFilterFactory tff = loader.newInstance(className, TokenFilterFactory.class, new String[0], params, new Object[]{new HashMap<>(args)});\n    assertNotNull(\"Did not load TokenFilter when asking for corresponding Tokenizer\", tff);\n\n    // This should work, but won't if earlier call succeeding corrupting the cache\n    TokenizerFactory tf = loader.newInstance(className, TokenizerFactory.class, new String[0], params, new Object[]{new HashMap<>(args)});\n    assertNotNull(\"Did not load Tokenizer after bad call earlier\", tf);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"576125e6a2121b67122c3ad3176f170e1905367b","date":1589248529,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/core/ResourceLoaderTest#testCacheWrongType().mjava","pathOld":"solr/core/src/test/org/apache/solr/core/ResourceLoaderTest#testCacheWrongType().mjava","sourceNew":"  public void testCacheWrongType() throws Exception {\n    clearCache();\n\n    SolrResourceLoader loader = new SolrResourceLoader();\n    Class[] params = { Map.class };\n    Map<String,String> args = Map.of(\"minGramSize\", \"1\", \"maxGramSize\", \"2\");\n    final String className = \"solr.NGramTokenizerFactory\";\n\n    // We could fail here since the class name and expected type don't match, but instead we try to infer what the user actually meant\n    TokenFilterFactory tff = loader.newInstance(className, TokenFilterFactory.class, new String[0], params, new Object[]{new HashMap<>(args)});\n    assertNotNull(\"Did not load TokenFilter when asking for corresponding Tokenizer\", tff);\n\n    // This should work, but won't if earlier call succeeding corrupting the cache\n    TokenizerFactory tf = loader.newInstance(className, TokenizerFactory.class, new String[0], params, new Object[]{new HashMap<>(args)});\n    assertNotNull(\"Did not load Tokenizer after bad call earlier\", tf);\n    loader.close();\n  }\n\n","sourceOld":"  public void testCacheWrongType() {\n    clearCache();\n\n    SolrResourceLoader loader = new SolrResourceLoader();\n    Class[] params = { Map.class };\n    Map<String,String> args = Map.of(\"minGramSize\", \"1\", \"maxGramSize\", \"2\");\n    final String className = \"solr.NGramTokenizerFactory\";\n\n    // We could fail here since the class name and expected type don't match, but instead we try to infer what the user actually meant\n    TokenFilterFactory tff = loader.newInstance(className, TokenFilterFactory.class, new String[0], params, new Object[]{new HashMap<>(args)});\n    assertNotNull(\"Did not load TokenFilter when asking for corresponding Tokenizer\", tff);\n\n    // This should work, but won't if earlier call succeeding corrupting the cache\n    TokenizerFactory tf = loader.newInstance(className, TokenizerFactory.class, new String[0], params, new Object[]{new HashMap<>(args)});\n    assertNotNull(\"Did not load Tokenizer after bad call earlier\", tf);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e98520789adb1d5ad05afb4956eca0944a929688","date":1592430701,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/core/ResourceLoaderTest#testCacheWrongType().mjava","pathOld":"solr/core/src/test/org/apache/solr/core/ResourceLoaderTest#testCacheWrongType().mjava","sourceNew":"  public void testCacheWrongType() throws Exception {\n    clearCache();\n\n    SolrResourceLoader loader = new SolrResourceLoader();\n    @SuppressWarnings({\"rawtypes\"})\n    Class[] params = { Map.class };\n    Map<String,String> args = Map.of(\"minGramSize\", \"1\", \"maxGramSize\", \"2\");\n    final String className = \"solr.NGramTokenizerFactory\";\n\n    // We could fail here since the class name and expected type don't match, but instead we try to infer what the user actually meant\n    TokenFilterFactory tff = loader.newInstance(className, TokenFilterFactory.class, new String[0], params, new Object[]{new HashMap<>(args)});\n    assertNotNull(\"Did not load TokenFilter when asking for corresponding Tokenizer\", tff);\n\n    // This should work, but won't if earlier call succeeding corrupting the cache\n    TokenizerFactory tf = loader.newInstance(className, TokenizerFactory.class, new String[0], params, new Object[]{new HashMap<>(args)});\n    assertNotNull(\"Did not load Tokenizer after bad call earlier\", tf);\n    loader.close();\n  }\n\n","sourceOld":"  public void testCacheWrongType() throws Exception {\n    clearCache();\n\n    SolrResourceLoader loader = new SolrResourceLoader();\n    Class[] params = { Map.class };\n    Map<String,String> args = Map.of(\"minGramSize\", \"1\", \"maxGramSize\", \"2\");\n    final String className = \"solr.NGramTokenizerFactory\";\n\n    // We could fail here since the class name and expected type don't match, but instead we try to infer what the user actually meant\n    TokenFilterFactory tff = loader.newInstance(className, TokenFilterFactory.class, new String[0], params, new Object[]{new HashMap<>(args)});\n    assertNotNull(\"Did not load TokenFilter when asking for corresponding Tokenizer\", tff);\n\n    // This should work, but won't if earlier call succeeding corrupting the cache\n    TokenizerFactory tf = loader.newInstance(className, TokenizerFactory.class, new String[0], params, new Object[]{new HashMap<>(args)});\n    assertNotNull(\"Did not load Tokenizer after bad call earlier\", tf);\n    loader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4786eec79a4a669f3272f3a918bc98d63ff01490":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["e98520789adb1d5ad05afb4956eca0944a929688"],"e98520789adb1d5ad05afb4956eca0944a929688":["576125e6a2121b67122c3ad3176f170e1905367b"],"576125e6a2121b67122c3ad3176f170e1905367b":["4786eec79a4a669f3272f3a918bc98d63ff01490"],"b0b597c65628ca9e73913a07e81691f8229bae35":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","4786eec79a4a669f3272f3a918bc98d63ff01490"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["4786eec79a4a669f3272f3a918bc98d63ff01490","b0b597c65628ca9e73913a07e81691f8229bae35"],"4786eec79a4a669f3272f3a918bc98d63ff01490":["576125e6a2121b67122c3ad3176f170e1905367b","b0b597c65628ca9e73913a07e81691f8229bae35"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"e98520789adb1d5ad05afb4956eca0944a929688":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"576125e6a2121b67122c3ad3176f170e1905367b":["e98520789adb1d5ad05afb4956eca0944a929688"],"b0b597c65628ca9e73913a07e81691f8229bae35":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817","b0b597c65628ca9e73913a07e81691f8229bae35"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}