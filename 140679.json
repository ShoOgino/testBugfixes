{"path":"src/java/org/apache/lucene/analysis/ru/RussianAnalyzer#tokenStream(String,Reader).mjava","commits":[{"id":"70aa49bffe8257a0135ed4eea2633937e92e99a6","date":1032144718,"type":0,"author":"Otis Gospodnetic","isMerge":false,"pathNew":"src/java/org/apache/lucene/analysis/ru/RussianAnalyzer#tokenStream(String,Reader).mjava","pathOld":"/dev/null","sourceNew":"    /**\n     * Creates a TokenStream which tokenizes all the text in the provided Reader.\n     *\n     * @return  A TokenStream build from a RussianLetterTokenizer filtered with\n     *                  RussianLowerCaseFilter, StopFilter, and RussianStemFilter\n     */\n    public final TokenStream tokenStream(String fieldName, Reader reader)\n    {\n        TokenStream result = new RussianLetterTokenizer(reader, charset);\n        result = new RussianLowerCaseFilter(result, charset);\n        result = new StopFilter(result, stoptable);\n        result = new RussianStemFilter(result, charset);\n        return result;\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0498299bf8a98518151ca8e5e727f34dbfde0030","date":1039460541,"type":3,"author":"Doug Cutting","isMerge":false,"pathNew":"src/java/org/apache/lucene/analysis/ru/RussianAnalyzer#tokenStream(String,Reader).mjava","pathOld":"src/java/org/apache/lucene/analysis/ru/RussianAnalyzer#tokenStream(String,Reader).mjava","sourceNew":"    /**\n     * Creates a TokenStream which tokenizes all the text in the provided Reader.\n     *\n     * @return  A TokenStream build from a RussianLetterTokenizer filtered with\n     *                  RussianLowerCaseFilter, StopFilter, and RussianStemFilter\n     */\n    public TokenStream tokenStream(String fieldName, Reader reader)\n    {\n        TokenStream result = new RussianLetterTokenizer(reader, charset);\n        result = new RussianLowerCaseFilter(result, charset);\n        result = new StopFilter(result, stoptable);\n        result = new RussianStemFilter(result, charset);\n        return result;\n    }\n\n","sourceOld":"    /**\n     * Creates a TokenStream which tokenizes all the text in the provided Reader.\n     *\n     * @return  A TokenStream build from a RussianLetterTokenizer filtered with\n     *                  RussianLowerCaseFilter, StopFilter, and RussianStemFilter\n     */\n    public final TokenStream tokenStream(String fieldName, Reader reader)\n    {\n        TokenStream result = new RussianLetterTokenizer(reader, charset);\n        result = new RussianLowerCaseFilter(result, charset);\n        result = new StopFilter(result, stoptable);\n        result = new RussianStemFilter(result, charset);\n        return result;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d14dd1f81165dd4704a95f7427639ada7c3047f7","date":1079084628,"type":3,"author":"Erik Hatcher","isMerge":false,"pathNew":"src/java/org/apache/lucene/analysis/ru/RussianAnalyzer#tokenStream(String,Reader).mjava","pathOld":"src/java/org/apache/lucene/analysis/ru/RussianAnalyzer#tokenStream(String,Reader).mjava","sourceNew":"    /**\n     * Creates a TokenStream which tokenizes all the text in the provided Reader.\n     *\n     * @return  A TokenStream build from a RussianLetterTokenizer filtered with\n     *                  RussianLowerCaseFilter, StopFilter, and RussianStemFilter\n     */\n    public TokenStream tokenStream(String fieldName, Reader reader)\n    {\n        TokenStream result = new RussianLetterTokenizer(reader, charset);\n        result = new RussianLowerCaseFilter(result, charset);\n        result = new StopFilter(result, stopSet);\n        result = new RussianStemFilter(result, charset);\n        return result;\n    }\n\n","sourceOld":"    /**\n     * Creates a TokenStream which tokenizes all the text in the provided Reader.\n     *\n     * @return  A TokenStream build from a RussianLetterTokenizer filtered with\n     *                  RussianLowerCaseFilter, StopFilter, and RussianStemFilter\n     */\n    public TokenStream tokenStream(String fieldName, Reader reader)\n    {\n        TokenStream result = new RussianLetterTokenizer(reader, charset);\n        result = new RussianLowerCaseFilter(result, charset);\n        result = new StopFilter(result, stoptable);\n        result = new RussianStemFilter(result, charset);\n        return result;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"eb502dc71e908fb2c30e64b73e1f7e7b6238f5a2","date":1092688309,"type":4,"author":"Daniel Naber","isMerge":false,"pathNew":"/dev/null","pathOld":"src/java/org/apache/lucene/analysis/ru/RussianAnalyzer#tokenStream(String,Reader).mjava","sourceNew":null,"sourceOld":"    /**\n     * Creates a TokenStream which tokenizes all the text in the provided Reader.\n     *\n     * @return  A TokenStream build from a RussianLetterTokenizer filtered with\n     *                  RussianLowerCaseFilter, StopFilter, and RussianStemFilter\n     */\n    public TokenStream tokenStream(String fieldName, Reader reader)\n    {\n        TokenStream result = new RussianLetterTokenizer(reader, charset);\n        result = new RussianLowerCaseFilter(result, charset);\n        result = new StopFilter(result, stopSet);\n        result = new RussianStemFilter(result, charset);\n        return result;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"0498299bf8a98518151ca8e5e727f34dbfde0030":["70aa49bffe8257a0135ed4eea2633937e92e99a6"],"eb502dc71e908fb2c30e64b73e1f7e7b6238f5a2":["d14dd1f81165dd4704a95f7427639ada7c3047f7"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d14dd1f81165dd4704a95f7427639ada7c3047f7":["0498299bf8a98518151ca8e5e727f34dbfde0030"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["eb502dc71e908fb2c30e64b73e1f7e7b6238f5a2"],"70aa49bffe8257a0135ed4eea2633937e92e99a6":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"0498299bf8a98518151ca8e5e727f34dbfde0030":["d14dd1f81165dd4704a95f7427639ada7c3047f7"],"eb502dc71e908fb2c30e64b73e1f7e7b6238f5a2":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["70aa49bffe8257a0135ed4eea2633937e92e99a6"],"d14dd1f81165dd4704a95f7427639ada7c3047f7":["eb502dc71e908fb2c30e64b73e1f7e7b6238f5a2"],"70aa49bffe8257a0135ed4eea2633937e92e99a6":["0498299bf8a98518151ca8e5e727f34dbfde0030"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}