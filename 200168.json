{"path":"solr/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","commits":[{"id":"893269407f5c988a4b2ee13c7ffc01ec43136c1d","date":1268598046,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    Collection<Token> result = new HashSet<Token>();\n    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer();\n    TokenStream ts = analyzer.tokenStream(\"\", new StringReader(origQuery));\n    Token tok = null;\n    try {\n      while ((tok = ts.next()) != null){\n        result.add(tok);\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    return result;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8","date":1268599006,"type":4,"author":"Mark Robert Miller","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","sourceNew":null,"sourceOld":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    Collection<Token> result = new HashSet<Token>();\n    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer();\n    TokenStream ts = analyzer.tokenStream(\"\", new StringReader(origQuery));\n    Token tok = null;\n    try {\n      while ((tok = ts.next()) != null){\n        result.add(tok);\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ad94625fb8d088209f46650c8097196fec67f00c","date":1453508319,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","pathOld":"src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","sourceNew":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    Collection<Token> result = new HashSet<Token>();\n    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer();\n    TokenStream ts = analyzer.tokenStream(\"\", new StringReader(origQuery));\n    // TODO: support custom attributes\n    TermAttribute termAtt = (TermAttribute) ts.addAttribute(TermAttribute.class);\n    OffsetAttribute offsetAtt = (OffsetAttribute) ts.addAttribute(OffsetAttribute.class);\n    TypeAttribute typeAtt = (TypeAttribute) ts.addAttribute(TypeAttribute.class);\n    FlagsAttribute flagsAtt = (FlagsAttribute) ts.addAttribute(FlagsAttribute.class);\n    PayloadAttribute payloadAtt = (PayloadAttribute) ts.addAttribute(PayloadAttribute.class);\n    PositionIncrementAttribute posIncAtt = (PositionIncrementAttribute) ts.addAttribute(PositionIncrementAttribute.class);\n    \n    try {\n      ts.reset();\n      while (ts.incrementToken()){\n        Token tok = new Token();\n        tok.setTermBuffer(termAtt.termBuffer(), 0, termAtt.termLength());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    return result;\n  }\n\n","sourceOld":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    Collection<Token> result = new HashSet<Token>();\n    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer();\n    TokenStream ts = analyzer.tokenStream(\"\", new StringReader(origQuery));\n    // TODO: support custom attributes\n    TermAttribute termAtt = (TermAttribute) ts.addAttribute(TermAttribute.class);\n    OffsetAttribute offsetAtt = (OffsetAttribute) ts.addAttribute(OffsetAttribute.class);\n    TypeAttribute typeAtt = (TypeAttribute) ts.addAttribute(TypeAttribute.class);\n    FlagsAttribute flagsAtt = (FlagsAttribute) ts.addAttribute(FlagsAttribute.class);\n    PayloadAttribute payloadAtt = (PayloadAttribute) ts.addAttribute(PayloadAttribute.class);\n    PositionIncrementAttribute posIncAtt = (PositionIncrementAttribute) ts.addAttribute(PositionIncrementAttribute.class);\n    \n    try {\n      ts.reset();\n      while (ts.incrementToken()){\n        Token tok = new Token();\n        tok.setTermBuffer(termAtt.termBuffer(), 0, termAtt.termLength());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1da8d55113b689b06716246649de6f62430f15c0","date":1453508340,"type":0,"author":"Dawid Weiss","isMerge":true,"pathNew":"solr/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    Collection<Token> result = new HashSet<Token>();\n    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer();\n    TokenStream ts = analyzer.tokenStream(\"\", new StringReader(origQuery));\n    // TODO: support custom attributes\n    TermAttribute termAtt = (TermAttribute) ts.addAttribute(TermAttribute.class);\n    OffsetAttribute offsetAtt = (OffsetAttribute) ts.addAttribute(OffsetAttribute.class);\n    TypeAttribute typeAtt = (TypeAttribute) ts.addAttribute(TypeAttribute.class);\n    FlagsAttribute flagsAtt = (FlagsAttribute) ts.addAttribute(FlagsAttribute.class);\n    PayloadAttribute payloadAtt = (PayloadAttribute) ts.addAttribute(PayloadAttribute.class);\n    PositionIncrementAttribute posIncAtt = (PositionIncrementAttribute) ts.addAttribute(PositionIncrementAttribute.class);\n    \n    try {\n      ts.reset();\n      while (ts.incrementToken()){\n        Token tok = new Token();\n        tok.setTermBuffer(termAtt.termBuffer(), 0, termAtt.termLength());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    return result;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d085fb336a7208eea2214e5ffcc803960819b60b","date":1270981894,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","pathOld":"solr/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","sourceNew":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    Collection<Token> result = new HashSet<Token>();\n    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer();\n    TokenStream ts = analyzer.tokenStream(\"\", new StringReader(origQuery));\n    // TODO: support custom attributes\n    CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n    OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n    TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n    FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n    PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n    PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n    \n    try {\n      ts.reset();\n      while (ts.incrementToken()){\n        Token tok = new Token();\n        tok.setTermBuffer(termAtt.buffer(), 0, termAtt.length());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    return result;\n  }\n\n","sourceOld":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    Collection<Token> result = new HashSet<Token>();\n    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer();\n    TokenStream ts = analyzer.tokenStream(\"\", new StringReader(origQuery));\n    // TODO: support custom attributes\n    TermAttribute termAtt = (TermAttribute) ts.addAttribute(TermAttribute.class);\n    OffsetAttribute offsetAtt = (OffsetAttribute) ts.addAttribute(OffsetAttribute.class);\n    TypeAttribute typeAtt = (TypeAttribute) ts.addAttribute(TypeAttribute.class);\n    FlagsAttribute flagsAtt = (FlagsAttribute) ts.addAttribute(FlagsAttribute.class);\n    PayloadAttribute payloadAtt = (PayloadAttribute) ts.addAttribute(PayloadAttribute.class);\n    PositionIncrementAttribute posIncAtt = (PositionIncrementAttribute) ts.addAttribute(PositionIncrementAttribute.class);\n    \n    try {\n      ts.reset();\n      while (ts.incrementToken()){\n        Token tok = new Token();\n        tok.setTermBuffer(termAtt.termBuffer(), 0, termAtt.termLength());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a7347509fad0711ac30cb15a746e9a3830a38ebd","date":1275388513,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","pathOld":"solr/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","sourceNew":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    Collection<Token> result = new HashSet<Token>();\n    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer();\n    TokenStream ts = analyzer.tokenStream(\"\", new StringReader(origQuery));\n    // TODO: support custom attributes\n    CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n    OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n    TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n    FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n    PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n    PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n    \n    try {\n      ts.reset();\n      while (ts.incrementToken()){\n        Token tok = new Token();\n        tok.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    return result;\n  }\n\n","sourceOld":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    Collection<Token> result = new HashSet<Token>();\n    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer();\n    TokenStream ts = analyzer.tokenStream(\"\", new StringReader(origQuery));\n    // TODO: support custom attributes\n    CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n    OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n    TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n    FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n    PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n    PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n    \n    try {\n      ts.reset();\n      while (ts.incrementToken()){\n        Token tok = new Token();\n        tok.setTermBuffer(termAtt.buffer(), 0, termAtt.length());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4e8cc373c801e54cec75daf9f52792cb4b17f536","date":1291116159,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","pathOld":"solr/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","sourceNew":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    Collection<Token> result = new HashSet<Token>();\n    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer(Version.LUCENE_40);\n    TokenStream ts = analyzer.tokenStream(\"\", new StringReader(origQuery));\n    // TODO: support custom attributes\n    CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n    OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n    TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n    FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n    PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n    PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n    \n    try {\n      ts.reset();\n      while (ts.incrementToken()){\n        Token tok = new Token();\n        tok.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    return result;\n  }\n\n","sourceOld":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    Collection<Token> result = new HashSet<Token>();\n    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer();\n    TokenStream ts = analyzer.tokenStream(\"\", new StringReader(origQuery));\n    // TODO: support custom attributes\n    CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n    OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n    TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n    FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n    PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n    PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n    \n    try {\n      ts.reset();\n      while (ts.incrementToken()){\n        Token tok = new Token();\n        tok.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3bb13258feba31ab676502787ab2e1779f129b7a","date":1291596436,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"solr/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","pathOld":"solr/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","sourceNew":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    Collection<Token> result = new HashSet<Token>();\n    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer(Version.LUCENE_40);\n    TokenStream ts = analyzer.tokenStream(\"\", new StringReader(origQuery));\n    // TODO: support custom attributes\n    CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n    OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n    TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n    FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n    PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n    PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n    \n    try {\n      ts.reset();\n      while (ts.incrementToken()){\n        Token tok = new Token();\n        tok.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    return result;\n  }\n\n","sourceOld":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    Collection<Token> result = new HashSet<Token>();\n    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer();\n    TokenStream ts = analyzer.tokenStream(\"\", new StringReader(origQuery));\n    // TODO: support custom attributes\n    CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n    OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n    TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n    FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n    PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n    PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n    \n    try {\n      ts.reset();\n      while (ts.incrementToken()){\n        Token tok = new Token();\n        tok.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"solr/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","pathOld":"solr/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","sourceNew":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    Collection<Token> result = new HashSet<Token>();\n    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer(Version.LUCENE_40);\n    TokenStream ts = analyzer.tokenStream(\"\", new StringReader(origQuery));\n    // TODO: support custom attributes\n    CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n    OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n    TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n    FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n    PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n    PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n    \n    try {\n      ts.reset();\n      while (ts.incrementToken()){\n        Token tok = new Token();\n        tok.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    return result;\n  }\n\n","sourceOld":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    Collection<Token> result = new HashSet<Token>();\n    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer();\n    TokenStream ts = analyzer.tokenStream(\"\", new StringReader(origQuery));\n    // TODO: support custom attributes\n    CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n    OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n    TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n    FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n    PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n    PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n    \n    try {\n      ts.reset();\n      while (ts.incrementToken()){\n        Token tok = new Token();\n        tok.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c903c3d15906a3da96b8c0c2fb704491005fdbdb","date":1453508227,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","pathOld":"solr/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","sourceNew":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    Collection<Token> result = new HashSet<Token>();\n    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer(Version.LUCENE_40);\n    TokenStream ts = analyzer.tokenStream(\"\", new StringReader(origQuery));\n    // TODO: support custom attributes\n    CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n    OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n    TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n    FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n    PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n    PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n    \n    try {\n      ts.reset();\n      while (ts.incrementToken()){\n        Token tok = new Token();\n        tok.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    return result;\n  }\n\n","sourceOld":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    Collection<Token> result = new HashSet<Token>();\n    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer(Version.LUCENE_40);\n    TokenStream ts = analyzer.tokenStream(\"\", new StringReader(origQuery));\n    // TODO: support custom attributes\n    CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n    OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n    TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n    FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n    PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n    PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n    \n    try {\n      ts.reset();\n      while (ts.incrementToken()){\n        Token tok = new Token();\n        tok.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a258fbb26824fd104ed795e5d9033d2d040049ee","date":1453508252,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","pathOld":"solr/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","sourceNew":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    Collection<Token> result = new HashSet<Token>();\n    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer(Version.LUCENE_40);\n    TokenStream ts = analyzer.tokenStream(\"\", new StringReader(origQuery));\n    // TODO: support custom attributes\n    CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n    OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n    TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n    FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n    PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n    PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n    \n    try {\n      ts.reset();\n      while (ts.incrementToken()){\n        Token tok = new Token();\n        tok.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    return result;\n  }\n\n","sourceOld":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    Collection<Token> result = new HashSet<Token>();\n    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer(Version.LUCENE_40);\n    TokenStream ts = analyzer.tokenStream(\"\", new StringReader(origQuery));\n    // TODO: support custom attributes\n    CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n    OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n    TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n    FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n    PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n    PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n    \n    try {\n      ts.reset();\n      while (ts.incrementToken()){\n        Token tok = new Token();\n        tok.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":5,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","pathOld":"solr/src/test/org/apache/solr/spelling/SimpleQueryConverter#convert(String).mjava","sourceNew":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    Collection<Token> result = new HashSet<Token>();\n    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer(Version.LUCENE_40);\n    TokenStream ts = analyzer.tokenStream(\"\", new StringReader(origQuery));\n    // TODO: support custom attributes\n    CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n    OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n    TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n    FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n    PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n    PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n    \n    try {\n      ts.reset();\n      while (ts.incrementToken()){\n        Token tok = new Token();\n        tok.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    return result;\n  }\n\n","sourceOld":"  @Override\n  public Collection<Token> convert(String origQuery) {\n    Collection<Token> result = new HashSet<Token>();\n    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer(Version.LUCENE_40);\n    TokenStream ts = analyzer.tokenStream(\"\", new StringReader(origQuery));\n    // TODO: support custom attributes\n    CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n    OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n    TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n    FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n    PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n    PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n    \n    try {\n      ts.reset();\n      while (ts.incrementToken()){\n        Token tok = new Token();\n        tok.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n        tok.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n        tok.setFlags(flagsAtt.getFlags());\n        tok.setPayload(payloadAtt.getPayload());\n        tok.setPositionIncrement(posIncAtt.getPositionIncrement());\n        tok.setType(typeAtt.type());\n        result.add(tok);\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"893269407f5c988a4b2ee13c7ffc01ec43136c1d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8":["893269407f5c988a4b2ee13c7ffc01ec43136c1d"],"c26f00b574427b55127e869b935845554afde1fa":["4e8cc373c801e54cec75daf9f52792cb4b17f536","c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["a7347509fad0711ac30cb15a746e9a3830a38ebd","4e8cc373c801e54cec75daf9f52792cb4b17f536"],"1da8d55113b689b06716246649de6f62430f15c0":["a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8","ad94625fb8d088209f46650c8097196fec67f00c"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["4e8cc373c801e54cec75daf9f52792cb4b17f536"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a258fbb26824fd104ed795e5d9033d2d040049ee":["4e8cc373c801e54cec75daf9f52792cb4b17f536"],"ad94625fb8d088209f46650c8097196fec67f00c":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"d085fb336a7208eea2214e5ffcc803960819b60b":["1da8d55113b689b06716246649de6f62430f15c0"],"a7347509fad0711ac30cb15a746e9a3830a38ebd":["d085fb336a7208eea2214e5ffcc803960819b60b"],"3bb13258feba31ab676502787ab2e1779f129b7a":["a7347509fad0711ac30cb15a746e9a3830a38ebd","4e8cc373c801e54cec75daf9f52792cb4b17f536"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c26f00b574427b55127e869b935845554afde1fa"],"4e8cc373c801e54cec75daf9f52792cb4b17f536":["a7347509fad0711ac30cb15a746e9a3830a38ebd"]},"commit2Childs":{"893269407f5c988a4b2ee13c7ffc01ec43136c1d":["a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8"],"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8":["1da8d55113b689b06716246649de6f62430f15c0"],"c26f00b574427b55127e869b935845554afde1fa":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["ad94625fb8d088209f46650c8097196fec67f00c"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":[],"1da8d55113b689b06716246649de6f62430f15c0":["d085fb336a7208eea2214e5ffcc803960819b60b"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["c26f00b574427b55127e869b935845554afde1fa"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["893269407f5c988a4b2ee13c7ffc01ec43136c1d"],"a258fbb26824fd104ed795e5d9033d2d040049ee":[],"ad94625fb8d088209f46650c8097196fec67f00c":["1da8d55113b689b06716246649de6f62430f15c0"],"d085fb336a7208eea2214e5ffcc803960819b60b":["a7347509fad0711ac30cb15a746e9a3830a38ebd"],"a7347509fad0711ac30cb15a746e9a3830a38ebd":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","3bb13258feba31ab676502787ab2e1779f129b7a","4e8cc373c801e54cec75daf9f52792cb4b17f536"],"3bb13258feba31ab676502787ab2e1779f129b7a":[],"4e8cc373c801e54cec75daf9f52792cb4b17f536":["c26f00b574427b55127e869b935845554afde1fa","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","c903c3d15906a3da96b8c0c2fb704491005fdbdb","a258fbb26824fd104ed795e5d9033d2d040049ee","3bb13258feba31ab676502787ab2e1779f129b7a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","a258fbb26824fd104ed795e5d9033d2d040049ee","3bb13258feba31ab676502787ab2e1779f129b7a","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b","a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}