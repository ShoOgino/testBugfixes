{"path":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","commits":[{"id":"3e8e2c32d41530c055e3a720bf58a736e9a07c94","date":1279796448,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  protected void setUp() throws Exception {\n    super.setUp();\n    random = newRandom();\n    dir = new MockRAMDirectory();\n    // TODO: fix mocktokenizer to not extend chartokenizer, so you can have an 'empty' keyword.\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.KEYWORD, false)));\n    \n    Document doc = new Document();\n    Field field = new Field(\"field\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(field);\n\n    for (int i = 0; i < 2000*_TestUtil.getRandomMultiplier(); i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = new IndexSearcher(reader);\n    writer.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["a78a90fc9701e511308346ea29f4f5e548bb39fe"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5f4e87790277826a2aea119328600dfb07761f32","date":1279827275,"type":0,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  protected void setUp() throws Exception {\n    super.setUp();\n    random = newRandom();\n    dir = new MockRAMDirectory();\n    // TODO: fix mocktokenizer to not extend chartokenizer, so you can have an 'empty' keyword.\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.KEYWORD, false)));\n    \n    Document doc = new Document();\n    Field field = new Field(\"field\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(field);\n\n    for (int i = 0; i < 2000*_TestUtil.getRandomMultiplier(); i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = new IndexSearcher(reader);\n    writer.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"15bbd254c1506df5299c4df8c148262c7bd6301e","date":1279913113,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","sourceNew":"  @Override\n  protected void setUp() throws Exception {\n    super.setUp();\n    random = newRandom();\n    dir = new MockRAMDirectory();\n    // TODO: fix mocktokenizer to not extend chartokenizer, so you can have an 'empty' keyword.\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(MockTokenizer.KEYWORD, false));\n    \n    Document doc = new Document();\n    Field field = new Field(\"field\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(field);\n\n    for (int i = 0; i < 2000*_TestUtil.getRandomMultiplier(); i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = new IndexSearcher(reader);\n    writer.close();\n  }\n\n","sourceOld":"  @Override\n  protected void setUp() throws Exception {\n    super.setUp();\n    random = newRandom();\n    dir = new MockRAMDirectory();\n    // TODO: fix mocktokenizer to not extend chartokenizer, so you can have an 'empty' keyword.\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.KEYWORD, false)));\n    \n    Document doc = new Document();\n    Field field = new Field(\"field\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(field);\n\n    for (int i = 0; i < 2000*_TestUtil.getRandomMultiplier(); i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = new IndexSearcher(reader);\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4b103252dee6afa1b6d7a622c773d178788eb85a","date":1280180143,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","sourceNew":"  @Override\n  protected void setUp() throws Exception {\n    super.setUp();\n    random = newRandom();\n    dir = new MockRAMDirectory();\n    // TODO: fix mocktokenizer to not extend chartokenizer, so you can have an 'empty' keyword.\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(MockTokenizer.KEYWORD, false));\n    \n    Document doc = new Document();\n    Field field = new Field(\"field\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(field);\n\n    for (int i = 0; i < 2000*_TestUtil.getRandomMultiplier(); i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = new IndexSearcher(reader);\n    writer.close();\n  }\n\n","sourceOld":"  @Override\n  protected void setUp() throws Exception {\n    super.setUp();\n    random = newRandom();\n    dir = new MockRAMDirectory();\n    // TODO: fix mocktokenizer to not extend chartokenizer, so you can have an 'empty' keyword.\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.KEYWORD, false)));\n    \n    Document doc = new Document();\n    Field field = new Field(\"field\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(field);\n\n    for (int i = 0; i < 2000*_TestUtil.getRandomMultiplier(); i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = new IndexSearcher(reader);\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a0e45742e10e8e3b98e854babe6dbb07a4197b71","date":1280230285,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","sourceNew":"  @Override\n  protected void setUp() throws Exception {\n    super.setUp();\n    random = newRandom();\n    dir = new MockRAMDirectory();\n    // TODO: fix mocktokenizer to not extend chartokenizer, so you can have an 'empty' keyword.\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(MockTokenizer.KEYWORD, false));\n    \n    Document doc = new Document();\n    Field field = new Field(\"field\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(field);\n\n    int num = 2000 * RANDOM_MULTIPLIER;\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = new IndexSearcher(reader);\n    writer.close();\n  }\n\n","sourceOld":"  @Override\n  protected void setUp() throws Exception {\n    super.setUp();\n    random = newRandom();\n    dir = new MockRAMDirectory();\n    // TODO: fix mocktokenizer to not extend chartokenizer, so you can have an 'empty' keyword.\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(MockTokenizer.KEYWORD, false));\n    \n    Document doc = new Document();\n    Field field = new Field(\"field\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(field);\n\n    for (int i = 0; i < 2000*_TestUtil.getRandomMultiplier(); i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = new IndexSearcher(reader);\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3242a09f703274d3b9283f2064a1a33064b53a1b","date":1280263474,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","sourceNew":"  @Override\n  protected void setUp() throws Exception {\n    super.setUp();\n    random = newRandom();\n    dir = new MockRAMDirectory();\n    // TODO: fix mocktokenizer to not extend chartokenizer, so you can have an 'empty' keyword.\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(MockTokenizer.KEYWORD, false));\n    \n    Document doc = new Document();\n    Field field = new Field(\"field\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(field);\n\n    int num = 2000 * RANDOM_MULTIPLIER;\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = new IndexSearcher(reader);\n    writer.close();\n  }\n\n","sourceOld":"  @Override\n  protected void setUp() throws Exception {\n    super.setUp();\n    random = newRandom();\n    dir = new MockRAMDirectory();\n    // TODO: fix mocktokenizer to not extend chartokenizer, so you can have an 'empty' keyword.\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.KEYWORD, false)));\n    \n    Document doc = new Document();\n    Field field = new Field(\"field\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(field);\n\n    for (int i = 0; i < 2000*_TestUtil.getRandomMultiplier(); i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = new IndexSearcher(reader);\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"90527e04096200f63999268b5d84d5530b191cf6","date":1281075048,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","sourceNew":"  @Override\n  protected void setUp() throws Exception {\n    super.setUp();\n    random = newRandom();\n    dir = new MockRAMDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(MockTokenizer.KEYWORD, false));\n    \n    Document doc = new Document();\n    Field field = new Field(\"field\", \"\", Field.Store.NO, Field.Index.NOT_ANALYZED);\n    doc.add(field);\n\n    int num = 2000 * RANDOM_MULTIPLIER;\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = new IndexSearcher(reader);\n    writer.close();\n  }\n\n","sourceOld":"  @Override\n  protected void setUp() throws Exception {\n    super.setUp();\n    random = newRandom();\n    dir = new MockRAMDirectory();\n    // TODO: fix mocktokenizer to not extend chartokenizer, so you can have an 'empty' keyword.\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(MockTokenizer.KEYWORD, false));\n    \n    Document doc = new Document();\n    Field field = new Field(\"field\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(field);\n\n    int num = 2000 * RANDOM_MULTIPLIER;\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = new IndexSearcher(reader);\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c","date":1281646583,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","sourceNew":"  @Override\n  protected void setUp() throws Exception {\n    super.setUp();\n    random = newRandom();\n    dir = newDirectory(random);\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(MockTokenizer.KEYWORD, false));\n    \n    Document doc = new Document();\n    Field field = new Field(\"field\", \"\", Field.Store.NO, Field.Index.NOT_ANALYZED);\n    doc.add(field);\n\n    int num = 2000 * RANDOM_MULTIPLIER;\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = new IndexSearcher(reader);\n    writer.close();\n  }\n\n","sourceOld":"  @Override\n  protected void setUp() throws Exception {\n    super.setUp();\n    random = newRandom();\n    dir = new MockRAMDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(MockTokenizer.KEYWORD, false));\n    \n    Document doc = new Document();\n    Field field = new Field(\"field\", \"\", Field.Store.NO, Field.Index.NOT_ANALYZED);\n    doc.add(field);\n\n    int num = 2000 * RANDOM_MULTIPLIER;\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = new IndexSearcher(reader);\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1f653cfcf159baeaafe5d01682a911e95bba4012","date":1284122058,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","sourceNew":"  @Override\n  protected void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(MockTokenizer.KEYWORD, false));\n    \n    Document doc = new Document();\n    Field field = new Field(\"field\", \"\", Field.Store.NO, Field.Index.NOT_ANALYZED);\n    doc.add(field);\n\n    int num = 2000 * RANDOM_MULTIPLIER;\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = new IndexSearcher(reader);\n    writer.close();\n  }\n\n","sourceOld":"  @Override\n  protected void setUp() throws Exception {\n    super.setUp();\n    random = newRandom();\n    dir = newDirectory(random);\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(MockTokenizer.KEYWORD, false));\n    \n    Document doc = new Document();\n    Field field = new Field(\"field\", \"\", Field.Store.NO, Field.Index.NOT_ANALYZED);\n    doc.add(field);\n\n    int num = 2000 * RANDOM_MULTIPLIER;\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = new IndexSearcher(reader);\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"132903c28af3aa6f67284b78de91c0f0a99488c2","date":1284282129,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","sourceNew":"  @Override\n  protected void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(MockTokenizer.KEYWORD, false));\n    \n    Document doc = new Document();\n    Field field = newField(\"field\", \"\", Field.Store.NO, Field.Index.NOT_ANALYZED);\n    doc.add(field);\n\n    int num = 2000 * RANDOM_MULTIPLIER;\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = new IndexSearcher(reader);\n    writer.close();\n  }\n\n","sourceOld":"  @Override\n  protected void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(MockTokenizer.KEYWORD, false));\n    \n    Document doc = new Document();\n    Field field = new Field(\"field\", \"\", Field.Store.NO, Field.Index.NOT_ANALYZED);\n    doc.add(field);\n\n    int num = 2000 * RANDOM_MULTIPLIER;\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = new IndexSearcher(reader);\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"150488c1317972164a9a824be05b1ba2ba0fc68c","date":1284316090,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","sourceNew":"  @Override\n  protected void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.KEYWORD, false))\n        .setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    \n    Document doc = new Document();\n    Field field = newField(\"field\", \"\", Field.Store.NO, Field.Index.NOT_ANALYZED);\n    doc.add(field);\n\n    // we generate aweful prefixes: good for testing.\n    // but for preflex codec, the test can be very slow, so use less iterations.\n    String codec = CodecProvider.getDefaultCodec();\n    int num = codec.equals(\"PreFlex\") ? 200 * RANDOM_MULTIPLIER : 2000 * RANDOM_MULTIPLIER;\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = new IndexSearcher(reader);\n    writer.close();\n  }\n\n","sourceOld":"  @Override\n  protected void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(MockTokenizer.KEYWORD, false));\n    \n    Document doc = new Document();\n    Field field = newField(\"field\", \"\", Field.Store.NO, Field.Index.NOT_ANALYZED);\n    doc.add(field);\n\n    int num = 2000 * RANDOM_MULTIPLIER;\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = new IndexSearcher(reader);\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"43b04c27924fe393e38e9f0986e32c634f261859","date":1284399440,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","sourceNew":"  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.KEYWORD, false))\n        .setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    \n    Document doc = new Document();\n    Field field = newField(\"field\", \"\", Field.Store.NO, Field.Index.NOT_ANALYZED);\n    doc.add(field);\n\n    // we generate aweful prefixes: good for testing.\n    // but for preflex codec, the test can be very slow, so use less iterations.\n    String codec = CodecProvider.getDefaultCodec();\n    int num = codec.equals(\"PreFlex\") ? 200 * RANDOM_MULTIPLIER : 2000 * RANDOM_MULTIPLIER;\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = new IndexSearcher(reader);\n    writer.close();\n  }\n\n","sourceOld":"  @Override\n  protected void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.KEYWORD, false))\n        .setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    \n    Document doc = new Document();\n    Field field = newField(\"field\", \"\", Field.Store.NO, Field.Index.NOT_ANALYZED);\n    doc.add(field);\n\n    // we generate aweful prefixes: good for testing.\n    // but for preflex codec, the test can be very slow, so use less iterations.\n    String codec = CodecProvider.getDefaultCodec();\n    int num = codec.equals(\"PreFlex\") ? 200 * RANDOM_MULTIPLIER : 2000 * RANDOM_MULTIPLIER;\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = new IndexSearcher(reader);\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"13452165d8bf3d45a72f572aaed3c679735d3af2","date":1290101307,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","sourceNew":"  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.KEYWORD, false))\n        .setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    \n    Document doc = new Document();\n    Field field = newField(\"field\", \"\", Field.Store.NO, Field.Index.NOT_ANALYZED);\n    doc.add(field);\n\n    // we generate aweful prefixes: good for testing.\n    // but for preflex codec, the test can be very slow, so use less iterations.\n    final String codec = getRandomFieldCodec(\"field\");\n    int num = codec.equals(\"PreFlex\") ? 200 * RANDOM_MULTIPLIER : 2000 * RANDOM_MULTIPLIER;\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = new IndexSearcher(reader);\n    writer.close();\n  }\n\n","sourceOld":"  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.KEYWORD, false))\n        .setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    \n    Document doc = new Document();\n    Field field = newField(\"field\", \"\", Field.Store.NO, Field.Index.NOT_ANALYZED);\n    doc.add(field);\n\n    // we generate aweful prefixes: good for testing.\n    // but for preflex codec, the test can be very slow, so use less iterations.\n    String codec = CodecProvider.getDefaultCodec();\n    int num = codec.equals(\"PreFlex\") ? 200 * RANDOM_MULTIPLIER : 2000 * RANDOM_MULTIPLIER;\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = new IndexSearcher(reader);\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bce89597a7c3a4535b5b7f8100c2078e520f6e57","date":1290106041,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","sourceNew":"  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.KEYWORD, false))\n        .setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    \n    Document doc = new Document();\n    Field field = newField(\"field\", \"\", Field.Store.NO, Field.Index.NOT_ANALYZED);\n    doc.add(field);\n\n    // we generate aweful prefixes: good for testing.\n    // but for preflex codec, the test can be very slow, so use less iterations.\n    String codec = CodecProvider.getDefaultCodec();\n    int num = codec.equals(\"PreFlex\") ? 200 * RANDOM_MULTIPLIER : 2000 * RANDOM_MULTIPLIER;\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = new IndexSearcher(reader);\n    writer.close();\n  }\n\n","sourceOld":"  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.KEYWORD, false))\n        .setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    \n    Document doc = new Document();\n    Field field = newField(\"field\", \"\", Field.Store.NO, Field.Index.NOT_ANALYZED);\n    doc.add(field);\n\n    // we generate aweful prefixes: good for testing.\n    // but for preflex codec, the test can be very slow, so use less iterations.\n    final String codec = getRandomFieldCodec(\"field\");\n    int num = codec.equals(\"PreFlex\") ? 200 * RANDOM_MULTIPLIER : 2000 * RANDOM_MULTIPLIER;\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = new IndexSearcher(reader);\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"eeebcf026b55d8ce3ac8165210782b26cc4efe30","date":1290108396,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","sourceNew":"  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.KEYWORD, false))\n        .setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    \n    Document doc = new Document();\n    Field field = newField(\"field\", \"\", Field.Store.NO, Field.Index.NOT_ANALYZED);\n    doc.add(field);\n\n    // we generate aweful prefixes: good for testing.\n    // but for preflex codec, the test can be very slow, so use less iterations.\n    final String codec = CodecProvider.getDefault().getFieldCodec(\"field\");\n    int num = codec.equals(\"PreFlex\") ? 200 * RANDOM_MULTIPLIER : 2000 * RANDOM_MULTIPLIER;\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = new IndexSearcher(reader);\n    writer.close();\n  }\n\n","sourceOld":"  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.KEYWORD, false))\n        .setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    \n    Document doc = new Document();\n    Field field = newField(\"field\", \"\", Field.Store.NO, Field.Index.NOT_ANALYZED);\n    doc.add(field);\n\n    // we generate aweful prefixes: good for testing.\n    // but for preflex codec, the test can be very slow, so use less iterations.\n    String codec = CodecProvider.getDefaultCodec();\n    int num = codec.equals(\"PreFlex\") ? 200 * RANDOM_MULTIPLIER : 2000 * RANDOM_MULTIPLIER;\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = new IndexSearcher(reader);\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3bb13258feba31ab676502787ab2e1779f129b7a","date":1291596436,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","sourceNew":"  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.KEYWORD, false))\n        .setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    \n    Document doc = new Document();\n    Field field = newField(\"field\", \"\", Field.Store.NO, Field.Index.NOT_ANALYZED);\n    doc.add(field);\n\n    // we generate aweful prefixes: good for testing.\n    // but for preflex codec, the test can be very slow, so use less iterations.\n    final String codec = CodecProvider.getDefault().getFieldCodec(\"field\");\n    int num = codec.equals(\"PreFlex\") ? 200 * RANDOM_MULTIPLIER : 2000 * RANDOM_MULTIPLIER;\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = new IndexSearcher(reader);\n    writer.close();\n  }\n\n","sourceOld":"  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.KEYWORD, false))\n        .setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    \n    Document doc = new Document();\n    Field field = newField(\"field\", \"\", Field.Store.NO, Field.Index.NOT_ANALYZED);\n    doc.add(field);\n\n    // we generate aweful prefixes: good for testing.\n    // but for preflex codec, the test can be very slow, so use less iterations.\n    String codec = CodecProvider.getDefaultCodec();\n    int num = codec.equals(\"PreFlex\") ? 200 * RANDOM_MULTIPLIER : 2000 * RANDOM_MULTIPLIER;\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = new IndexSearcher(reader);\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","sourceNew":"  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.KEYWORD, false))\n        .setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    \n    Document doc = new Document();\n    Field field = newField(\"field\", \"\", Field.Store.NO, Field.Index.NOT_ANALYZED);\n    doc.add(field);\n\n    // we generate aweful prefixes: good for testing.\n    // but for preflex codec, the test can be very slow, so use less iterations.\n    final String codec = CodecProvider.getDefault().getFieldCodec(\"field\");\n    int num = codec.equals(\"PreFlex\") ? 200 * RANDOM_MULTIPLIER : 2000 * RANDOM_MULTIPLIER;\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = new IndexSearcher(reader);\n    writer.close();\n  }\n\n","sourceOld":"  @Override\n  protected void setUp() throws Exception {\n    super.setUp();\n    random = newRandom();\n    dir = new MockRAMDirectory();\n    // TODO: fix mocktokenizer to not extend chartokenizer, so you can have an 'empty' keyword.\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(MockTokenizer.KEYWORD, false));\n    \n    Document doc = new Document();\n    Field field = new Field(\"field\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(field);\n\n    int num = 2000 * RANDOM_MULTIPLIER;\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = new IndexSearcher(reader);\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"790e1fde4caa765b3faaad3fbcd25c6973450336","date":1296689245,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","sourceNew":"  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.KEYWORD, false))\n        .setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    \n    Document doc = new Document();\n    Field field = newField(\"field\", \"\", Field.Store.NO, Field.Index.NOT_ANALYZED);\n    doc.add(field);\n\n    // we generate aweful prefixes: good for testing.\n    // but for preflex codec, the test can be very slow, so use less iterations.\n    final String codec = CodecProvider.getDefault().getFieldCodec(\"field\");\n    int num = codec.equals(\"PreFlex\") ? 200 * RANDOM_MULTIPLIER : 2000 * RANDOM_MULTIPLIER;\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = newSearcher(reader);\n    writer.close();\n  }\n\n","sourceOld":"  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.KEYWORD, false))\n        .setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    \n    Document doc = new Document();\n    Field field = newField(\"field\", \"\", Field.Store.NO, Field.Index.NOT_ANALYZED);\n    doc.add(field);\n\n    // we generate aweful prefixes: good for testing.\n    // but for preflex codec, the test can be very slow, so use less iterations.\n    final String codec = CodecProvider.getDefault().getFieldCodec(\"field\");\n    int num = codec.equals(\"PreFlex\") ? 200 * RANDOM_MULTIPLIER : 2000 * RANDOM_MULTIPLIER;\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = new IndexSearcher(reader);\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","sourceNew":"  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.KEYWORD, false))\n        .setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    \n    Document doc = new Document();\n    Field field = newField(\"field\", \"\", Field.Store.NO, Field.Index.NOT_ANALYZED);\n    doc.add(field);\n\n    // we generate aweful prefixes: good for testing.\n    // but for preflex codec, the test can be very slow, so use less iterations.\n    final String codec = CodecProvider.getDefault().getFieldCodec(\"field\");\n    int num = codec.equals(\"PreFlex\") ? 200 * RANDOM_MULTIPLIER : 2000 * RANDOM_MULTIPLIER;\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = newSearcher(reader);\n    writer.close();\n  }\n\n","sourceOld":"  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.KEYWORD, false))\n        .setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    \n    Document doc = new Document();\n    Field field = newField(\"field\", \"\", Field.Store.NO, Field.Index.NOT_ANALYZED);\n    doc.add(field);\n\n    // we generate aweful prefixes: good for testing.\n    // but for preflex codec, the test can be very slow, so use less iterations.\n    final String codec = CodecProvider.getDefault().getFieldCodec(\"field\");\n    int num = codec.equals(\"PreFlex\") ? 200 * RANDOM_MULTIPLIER : 2000 * RANDOM_MULTIPLIER;\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = new IndexSearcher(reader);\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bde51b089eb7f86171eb3406e38a274743f9b7ac","date":1298336439,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","sourceNew":"  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.KEYWORD, false))\n        .setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    \n    Document doc = new Document();\n    Field field = newField(\"field\", \"\", Field.Store.NO, Field.Index.NOT_ANALYZED);\n    doc.add(field);\n\n    // we generate aweful prefixes: good for testing.\n    // but for preflex codec, the test can be very slow, so use less iterations.\n    final String codec = CodecProvider.getDefault().getFieldCodec(\"field\");\n    int num = codec.equals(\"PreFlex\") ? 200 * RANDOM_MULTIPLIER : 2000 * RANDOM_MULTIPLIER;\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = newSearcher(reader);\n    writer.close();\n  }\n\n","sourceOld":"  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.KEYWORD, false))\n        .setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    \n    Document doc = new Document();\n    Field field = newField(\"field\", \"\", Field.Store.NO, Field.Index.NOT_ANALYZED);\n    doc.add(field);\n\n    // we generate aweful prefixes: good for testing.\n    // but for preflex codec, the test can be very slow, so use less iterations.\n    final String codec = CodecProvider.getDefault().getFieldCodec(\"field\");\n    int num = codec.equals(\"PreFlex\") ? 200 * RANDOM_MULTIPLIER : 2000 * RANDOM_MULTIPLIER;\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = new IndexSearcher(reader);\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f2c5f0cb44df114db4228c8f77861714b5cabaea","date":1302542431,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","sourceNew":"  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.KEYWORD, false))\n        .setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    \n    Document doc = new Document();\n    Field field = newField(\"field\", \"\", Field.Store.NO, Field.Index.NOT_ANALYZED);\n    doc.add(field);\n\n    // we generate aweful prefixes: good for testing.\n    // but for preflex codec, the test can be very slow, so use less iterations.\n    final String codec = CodecProvider.getDefault().getFieldCodec(\"field\");\n    int num = codec.equals(\"PreFlex\") ? 200 * RANDOM_MULTIPLIER : 2000 * RANDOM_MULTIPLIER;\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = newSearcher(reader);\n    writer.close();\n  }\n\n","sourceOld":"  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.KEYWORD, false))\n        .setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    \n    Document doc = new Document();\n    Field field = newField(\"field\", \"\", Field.Store.NO, Field.Index.NOT_ANALYZED);\n    doc.add(field);\n\n    // we generate aweful prefixes: good for testing.\n    // but for preflex codec, the test can be very slow, so use less iterations.\n    final String codec = CodecProvider.getDefault().getFieldCodec(\"field\");\n    int num = codec.equals(\"PreFlex\") ? 200 * RANDOM_MULTIPLIER : 2000 * RANDOM_MULTIPLIER;\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = newSearcher(reader);\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"962d04139994fce5193143ef35615499a9a96d78","date":1302693744,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","sourceNew":"  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.KEYWORD, false))\n        .setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    \n    Document doc = new Document();\n    Field field = newField(\"field\", \"\", Field.Store.NO, Field.Index.NOT_ANALYZED);\n    doc.add(field);\n\n    // we generate aweful prefixes: good for testing.\n    // but for preflex codec, the test can be very slow, so use less iterations.\n    final String codec = CodecProvider.getDefault().getFieldCodec(\"field\");\n    int num = codec.equals(\"PreFlex\") ? 200 * RANDOM_MULTIPLIER : 2000 * RANDOM_MULTIPLIER;\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = newSearcher(reader);\n    writer.close();\n  }\n\n","sourceOld":"  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.KEYWORD, false))\n        .setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    \n    Document doc = new Document();\n    Field field = newField(\"field\", \"\", Field.Store.NO, Field.Index.NOT_ANALYZED);\n    doc.add(field);\n\n    // we generate aweful prefixes: good for testing.\n    // but for preflex codec, the test can be very slow, so use less iterations.\n    final String codec = CodecProvider.getDefault().getFieldCodec(\"field\");\n    int num = codec.equals(\"PreFlex\") ? 200 * RANDOM_MULTIPLIER : 2000 * RANDOM_MULTIPLIER;\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = newSearcher(reader);\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","sourceNew":"  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.KEYWORD, false))\n        .setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    \n    Document doc = new Document();\n    Field field = newField(\"field\", \"\", Field.Store.NO, Field.Index.NOT_ANALYZED);\n    doc.add(field);\n\n    // we generate aweful prefixes: good for testing.\n    // but for preflex codec, the test can be very slow, so use less iterations.\n    final String codec = CodecProvider.getDefault().getFieldCodec(\"field\");\n    int num = codec.equals(\"PreFlex\") ? 200 * RANDOM_MULTIPLIER : 2000 * RANDOM_MULTIPLIER;\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = newSearcher(reader);\n    writer.close();\n  }\n\n","sourceOld":"  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.KEYWORD, false))\n        .setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    \n    Document doc = new Document();\n    Field field = newField(\"field\", \"\", Field.Store.NO, Field.Index.NOT_ANALYZED);\n    doc.add(field);\n\n    // we generate aweful prefixes: good for testing.\n    // but for preflex codec, the test can be very slow, so use less iterations.\n    final String codec = CodecProvider.getDefault().getFieldCodec(\"field\");\n    int num = codec.equals(\"PreFlex\") ? 200 * RANDOM_MULTIPLIER : 2000 * RANDOM_MULTIPLIER;\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = newSearcher(reader);\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","sourceNew":"  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.KEYWORD, false))\n        .setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    \n    Document doc = new Document();\n    Field field = newField(\"field\", \"\", Field.Store.NO, Field.Index.NOT_ANALYZED);\n    doc.add(field);\n\n    // we generate aweful prefixes: good for testing.\n    // but for preflex codec, the test can be very slow, so use less iterations.\n    final String codec = CodecProvider.getDefault().getFieldCodec(\"field\");\n    int num = codec.equals(\"PreFlex\") ? 200 * RANDOM_MULTIPLIER : 2000 * RANDOM_MULTIPLIER;\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = newSearcher(reader);\n    writer.close();\n  }\n\n","sourceOld":"  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.KEYWORD, false))\n        .setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    \n    Document doc = new Document();\n    Field field = newField(\"field\", \"\", Field.Store.NO, Field.Index.NOT_ANALYZED);\n    doc.add(field);\n\n    // we generate aweful prefixes: good for testing.\n    // but for preflex codec, the test can be very slow, so use less iterations.\n    final String codec = CodecProvider.getDefault().getFieldCodec(\"field\");\n    int num = codec.equals(\"PreFlex\") ? 200 * RANDOM_MULTIPLIER : 2000 * RANDOM_MULTIPLIER;\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = newSearcher(reader);\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f83af14a2a8131b14d7aee6274c740334e0363d3","date":1307579822,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","sourceNew":"  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.KEYWORD, false))\n        .setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    \n    Document doc = new Document();\n    Field field = newField(\"field\", \"\", Field.Store.NO, Field.Index.NOT_ANALYZED);\n    doc.add(field);\n\n    // we generate aweful prefixes: good for testing.\n    // but for preflex codec, the test can be very slow, so use less iterations.\n    final String codec = CodecProvider.getDefault().getFieldCodec(\"field\");\n    int num = codec.equals(\"PreFlex\") ? 200 * RANDOM_MULTIPLIER : atLeast(2000);\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = newSearcher(reader);\n    writer.close();\n  }\n\n","sourceOld":"  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.KEYWORD, false))\n        .setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    \n    Document doc = new Document();\n    Field field = newField(\"field\", \"\", Field.Store.NO, Field.Index.NOT_ANALYZED);\n    doc.add(field);\n\n    // we generate aweful prefixes: good for testing.\n    // but for preflex codec, the test can be very slow, so use less iterations.\n    final String codec = CodecProvider.getDefault().getFieldCodec(\"field\");\n    int num = codec.equals(\"PreFlex\") ? 200 * RANDOM_MULTIPLIER : 2000 * RANDOM_MULTIPLIER;\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = newSearcher(reader);\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"77cf4379b2824f6ea34b091c495d6e95c38ff9e2","date":1307610475,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","sourceNew":"  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.KEYWORD, false))\n        .setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    \n    Document doc = new Document();\n    Field field = newField(\"field\", \"\", Field.Store.NO, Field.Index.NOT_ANALYZED);\n    doc.add(field);\n\n    // we generate aweful prefixes: good for testing.\n    // but for preflex codec, the test can be very slow, so use less iterations.\n    final String codec = CodecProvider.getDefault().getFieldCodec(\"field\");\n    int num = codec.equals(\"PreFlex\") ? 200 * RANDOM_MULTIPLIER : atLeast(2000);\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = newSearcher(reader);\n    writer.close();\n  }\n\n","sourceOld":"  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.KEYWORD, false))\n        .setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    \n    Document doc = new Document();\n    Field field = newField(\"field\", \"\", Field.Store.NO, Field.Index.NOT_ANALYZED);\n    doc.add(field);\n\n    // we generate aweful prefixes: good for testing.\n    // but for preflex codec, the test can be very slow, so use less iterations.\n    final String codec = CodecProvider.getDefault().getFieldCodec(\"field\");\n    int num = codec.equals(\"PreFlex\") ? 200 * RANDOM_MULTIPLIER : 2000 * RANDOM_MULTIPLIER;\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = newSearcher(reader);\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","date":1307729864,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","sourceNew":"  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.KEYWORD, false))\n        .setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    \n    Document doc = new Document();\n    Field field = newField(\"field\", \"\", Field.Store.NO, Field.Index.NOT_ANALYZED);\n    doc.add(field);\n\n    // we generate aweful prefixes: good for testing.\n    // but for preflex codec, the test can be very slow, so use less iterations.\n    final String codec = CodecProvider.getDefault().getFieldCodec(\"field\");\n    int num = codec.equals(\"PreFlex\") ? 200 * RANDOM_MULTIPLIER : atLeast(2000);\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = newSearcher(reader);\n    writer.close();\n  }\n\n","sourceOld":"  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.KEYWORD, false))\n        .setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    \n    Document doc = new Document();\n    Field field = newField(\"field\", \"\", Field.Store.NO, Field.Index.NOT_ANALYZED);\n    doc.add(field);\n\n    // we generate aweful prefixes: good for testing.\n    // but for preflex codec, the test can be very slow, so use less iterations.\n    final String codec = CodecProvider.getDefault().getFieldCodec(\"field\");\n    int num = codec.equals(\"PreFlex\") ? 200 * RANDOM_MULTIPLIER : 2000 * RANDOM_MULTIPLIER;\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = newSearcher(reader);\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"459280d4c73660ea582f38afce7968563068fe49","date":1311128716,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","sourceNew":"  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.KEYWORD, false))\n        .setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    \n    Document doc = new Document();\n    Field field = newField(\"field\", \"\", Field.Store.NO, Field.Index.NOT_ANALYZED);\n    doc.add(field);\n\n    // we generate aweful prefixes: good for testing.\n    // but for preflex codec, the test can be very slow, so use less iterations.\n    final String codec = CodecProvider.getDefault().getFieldCodec(\"field\");\n    int num = codec.equals(\"PreFlex\") ? 200 * RANDOM_MULTIPLIER : atLeast(1000);\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = newSearcher(reader);\n    writer.close();\n  }\n\n","sourceOld":"  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.KEYWORD, false))\n        .setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    \n    Document doc = new Document();\n    Field field = newField(\"field\", \"\", Field.Store.NO, Field.Index.NOT_ANALYZED);\n    doc.add(field);\n\n    // we generate aweful prefixes: good for testing.\n    // but for preflex codec, the test can be very slow, so use less iterations.\n    final String codec = CodecProvider.getDefault().getFieldCodec(\"field\");\n    int num = codec.equals(\"PreFlex\") ? 200 * RANDOM_MULTIPLIER : atLeast(2000);\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = newSearcher(reader);\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1509f151d7692d84fae414b2b799ac06ba60fcb4","date":1314451621,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","sourceNew":"  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.KEYWORD, false))\n        .setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    \n    Document doc = new Document();\n    Field field = newField(\"field\", \"\", StringField.TYPE_UNSTORED);\n    doc.add(field);\n\n    // we generate aweful prefixes: good for testing.\n    // but for preflex codec, the test can be very slow, so use less iterations.\n    final String codec = CodecProvider.getDefault().getFieldCodec(\"field\");\n    int num = codec.equals(\"PreFlex\") ? 200 * RANDOM_MULTIPLIER : atLeast(1000);\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = newSearcher(reader);\n    writer.close();\n  }\n\n","sourceOld":"  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.KEYWORD, false))\n        .setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    \n    Document doc = new Document();\n    Field field = newField(\"field\", \"\", Field.Store.NO, Field.Index.NOT_ANALYZED);\n    doc.add(field);\n\n    // we generate aweful prefixes: good for testing.\n    // but for preflex codec, the test can be very slow, so use less iterations.\n    final String codec = CodecProvider.getDefault().getFieldCodec(\"field\");\n    int num = codec.equals(\"PreFlex\") ? 200 * RANDOM_MULTIPLIER : atLeast(1000);\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = newSearcher(reader);\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7b91922b55d15444d554721b352861d028eb8278","date":1320421415,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","sourceNew":"  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.KEYWORD, false))\n        .setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    \n    Document doc = new Document();\n    Field field = newField(\"field\", \"\", StringField.TYPE_UNSTORED);\n    doc.add(field);\n\n    // we generate aweful prefixes: good for testing.\n    // but for preflex codec, the test can be very slow, so use less iterations.\n    final String codec = Codec.getDefault().getName();\n    int num = codec.equals(\"Lucene3x\") ? 200 * RANDOM_MULTIPLIER : atLeast(1000);\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = newSearcher(reader);\n    writer.close();\n  }\n\n","sourceOld":"  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.KEYWORD, false))\n        .setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    \n    Document doc = new Document();\n    Field field = newField(\"field\", \"\", StringField.TYPE_UNSTORED);\n    doc.add(field);\n\n    // we generate aweful prefixes: good for testing.\n    // but for preflex codec, the test can be very slow, so use less iterations.\n    final String codec = CodecProvider.getDefault().getFieldCodec(\"field\");\n    int num = codec.equals(\"PreFlex\") ? 200 * RANDOM_MULTIPLIER : atLeast(1000);\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = newSearcher(reader);\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPrefixRandom#setUp().mjava","sourceNew":"  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.KEYWORD, false))\n        .setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    \n    Document doc = new Document();\n    Field field = newField(\"field\", \"\", StringField.TYPE_UNSTORED);\n    doc.add(field);\n\n    // we generate aweful prefixes: good for testing.\n    // but for preflex codec, the test can be very slow, so use less iterations.\n    final String codec = Codec.getDefault().getName();\n    int num = codec.equals(\"Lucene3x\") ? 200 * RANDOM_MULTIPLIER : atLeast(1000);\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = newSearcher(reader);\n    writer.close();\n  }\n\n","sourceOld":"  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.KEYWORD, false))\n        .setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    \n    Document doc = new Document();\n    Field field = newField(\"field\", \"\", StringField.TYPE_UNSTORED);\n    doc.add(field);\n\n    // we generate aweful prefixes: good for testing.\n    // but for preflex codec, the test can be very slow, so use less iterations.\n    final String codec = Codec.getDefault().getName();\n    int num = codec.equals(\"Lucene3x\") ? 200 * RANDOM_MULTIPLIER : atLeast(1000);\n    for (int i = 0; i < num; i++) {\n      field.setValue(_TestUtil.randomUnicodeString(random, 10));\n      writer.addDocument(doc);\n    }\n    reader = writer.getReader();\n    searcher = newSearcher(reader);\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e45742e10e8e3b98e854babe6dbb07a4197b71":["4b103252dee6afa1b6d7a622c773d178788eb85a"],"f83af14a2a8131b14d7aee6274c740334e0363d3":["f2c5f0cb44df114db4228c8f77861714b5cabaea"],"459280d4c73660ea582f38afce7968563068fe49":["f83af14a2a8131b14d7aee6274c740334e0363d3"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["7b91922b55d15444d554721b352861d028eb8278"],"15bbd254c1506df5299c4df8c148262c7bd6301e":["3e8e2c32d41530c055e3a720bf58a736e9a07c94"],"132903c28af3aa6f67284b78de91c0f0a99488c2":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["3242a09f703274d3b9283f2064a1a33064b53a1b","eeebcf026b55d8ce3ac8165210782b26cc4efe30"],"43b04c27924fe393e38e9f0986e32c634f261859":["150488c1317972164a9a824be05b1ba2ba0fc68c"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["790e1fde4caa765b3faaad3fbcd25c6973450336"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["3bb13258feba31ab676502787ab2e1779f129b7a","790e1fde4caa765b3faaad3fbcd25c6973450336"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"eeebcf026b55d8ce3ac8165210782b26cc4efe30":["bce89597a7c3a4535b5b7f8100c2078e520f6e57"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["459280d4c73660ea582f38afce7968563068fe49"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","790e1fde4caa765b3faaad3fbcd25c6973450336"],"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655":["a3776dccca01c11e7046323cfad46a3b4a471233","f83af14a2a8131b14d7aee6274c740334e0363d3"],"3242a09f703274d3b9283f2064a1a33064b53a1b":["5f4e87790277826a2aea119328600dfb07761f32","a0e45742e10e8e3b98e854babe6dbb07a4197b71"],"4b103252dee6afa1b6d7a622c773d178788eb85a":["3e8e2c32d41530c055e3a720bf58a736e9a07c94","15bbd254c1506df5299c4df8c148262c7bd6301e"],"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["90527e04096200f63999268b5d84d5530b191cf6"],"3e8e2c32d41530c055e3a720bf58a736e9a07c94":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["29ef99d61cda9641b6250bf9567329a6e65f901d","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"90527e04096200f63999268b5d84d5530b191cf6":["a0e45742e10e8e3b98e854babe6dbb07a4197b71"],"5f4e87790277826a2aea119328600dfb07761f32":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","3e8e2c32d41530c055e3a720bf58a736e9a07c94"],"962d04139994fce5193143ef35615499a9a96d78":["bde51b089eb7f86171eb3406e38a274743f9b7ac","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"790e1fde4caa765b3faaad3fbcd25c6973450336":["eeebcf026b55d8ce3ac8165210782b26cc4efe30"],"7b91922b55d15444d554721b352861d028eb8278":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"bce89597a7c3a4535b5b7f8100c2078e520f6e57":["13452165d8bf3d45a72f572aaed3c679735d3af2"],"13452165d8bf3d45a72f572aaed3c679735d3af2":["43b04c27924fe393e38e9f0986e32c634f261859"],"a3776dccca01c11e7046323cfad46a3b4a471233":["790e1fde4caa765b3faaad3fbcd25c6973450336","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"77cf4379b2824f6ea34b091c495d6e95c38ff9e2":["135621f3a0670a9394eb563224a3b76cc4dddc0f","f83af14a2a8131b14d7aee6274c740334e0363d3"],"150488c1317972164a9a824be05b1ba2ba0fc68c":["132903c28af3aa6f67284b78de91c0f0a99488c2"],"3bb13258feba31ab676502787ab2e1779f129b7a":["43b04c27924fe393e38e9f0986e32c634f261859","eeebcf026b55d8ce3ac8165210782b26cc4efe30"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"a0e45742e10e8e3b98e854babe6dbb07a4197b71":["3242a09f703274d3b9283f2064a1a33064b53a1b","90527e04096200f63999268b5d84d5530b191cf6"],"f83af14a2a8131b14d7aee6274c740334e0363d3":["459280d4c73660ea582f38afce7968563068fe49","a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","77cf4379b2824f6ea34b091c495d6e95c38ff9e2"],"459280d4c73660ea582f38afce7968563068fe49":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"15bbd254c1506df5299c4df8c148262c7bd6301e":["4b103252dee6afa1b6d7a622c773d178788eb85a"],"132903c28af3aa6f67284b78de91c0f0a99488c2":["150488c1317972164a9a824be05b1ba2ba0fc68c"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["bde51b089eb7f86171eb3406e38a274743f9b7ac"],"43b04c27924fe393e38e9f0986e32c634f261859":["13452165d8bf3d45a72f572aaed3c679735d3af2","3bb13258feba31ab676502787ab2e1779f129b7a"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["f83af14a2a8131b14d7aee6274c740334e0363d3","135621f3a0670a9394eb563224a3b76cc4dddc0f","962d04139994fce5193143ef35615499a9a96d78","a3776dccca01c11e7046323cfad46a3b4a471233"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["132903c28af3aa6f67284b78de91c0f0a99488c2"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["135621f3a0670a9394eb563224a3b76cc4dddc0f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3e8e2c32d41530c055e3a720bf58a736e9a07c94","5f4e87790277826a2aea119328600dfb07761f32"],"eeebcf026b55d8ce3ac8165210782b26cc4efe30":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","790e1fde4caa765b3faaad3fbcd25c6973450336","3bb13258feba31ab676502787ab2e1779f129b7a"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["7b91922b55d15444d554721b352861d028eb8278"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["962d04139994fce5193143ef35615499a9a96d78"],"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655":[],"3242a09f703274d3b9283f2064a1a33064b53a1b":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"4b103252dee6afa1b6d7a622c773d178788eb85a":["a0e45742e10e8e3b98e854babe6dbb07a4197b71"],"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"3e8e2c32d41530c055e3a720bf58a736e9a07c94":["15bbd254c1506df5299c4df8c148262c7bd6301e","4b103252dee6afa1b6d7a622c773d178788eb85a","5f4e87790277826a2aea119328600dfb07761f32"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["77cf4379b2824f6ea34b091c495d6e95c38ff9e2"],"90527e04096200f63999268b5d84d5530b191cf6":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"5f4e87790277826a2aea119328600dfb07761f32":["3242a09f703274d3b9283f2064a1a33064b53a1b"],"962d04139994fce5193143ef35615499a9a96d78":[],"790e1fde4caa765b3faaad3fbcd25c6973450336":["f2c5f0cb44df114db4228c8f77861714b5cabaea","29ef99d61cda9641b6250bf9567329a6e65f901d","bde51b089eb7f86171eb3406e38a274743f9b7ac","a3776dccca01c11e7046323cfad46a3b4a471233"],"7b91922b55d15444d554721b352861d028eb8278":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"bce89597a7c3a4535b5b7f8100c2078e520f6e57":["eeebcf026b55d8ce3ac8165210782b26cc4efe30"],"a3776dccca01c11e7046323cfad46a3b4a471233":["a02058e0eaba4bbd5d05e6b06b9522c0acfd1655"],"13452165d8bf3d45a72f572aaed3c679735d3af2":["bce89597a7c3a4535b5b7f8100c2078e520f6e57"],"77cf4379b2824f6ea34b091c495d6e95c38ff9e2":[],"150488c1317972164a9a824be05b1ba2ba0fc68c":["43b04c27924fe393e38e9f0986e32c634f261859"],"3bb13258feba31ab676502787ab2e1779f129b7a":["29ef99d61cda9641b6250bf9567329a6e65f901d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","962d04139994fce5193143ef35615499a9a96d78","77cf4379b2824f6ea34b091c495d6e95c38ff9e2","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}