{"path":"lucene/facet/src/java/org/apache/lucene/facet/taxonomy/writercache/cl2o/CompactLabelToOrdinal#open(File,float,int).mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/facet/src/java/org/apache/lucene/facet/taxonomy/writercache/cl2o/CompactLabelToOrdinal#open(File,float,int).mjava","pathOld":"modules/facet/src/java/org/apache/lucene/facet/taxonomy/writercache/cl2o/CompactLabelToOrdinal#open(File,float,int).mjava","sourceNew":"  /**\n   * Opens the file and reloads the CompactLabelToOrdinal. The file it expects\n   * is generated from the {@link #flush()} command.\n   */\n  static CompactLabelToOrdinal open(File file, float loadFactor,\n                                    int numHashArrays) throws IOException {\n    /**\n     * Part of the file is the labelRepository, which needs to be rehashed\n     * and label offsets re-added to the object. I am unsure as to why we\n     * can't just store these off in the file as well, but in keeping with\n     * the spirit of the original code, I did it this way. (ssuppe)\n     */\n    CompactLabelToOrdinal l2o = new CompactLabelToOrdinal();\n    l2o.loadFactor = loadFactor;\n    l2o.hashArrays = new HashArray[numHashArrays];\n\n    DataInputStream dis = null;\n    try {\n      dis = new DataInputStream(new BufferedInputStream(\n          new FileInputStream(file)));\n\n      // TaxiReader needs to load the \"counter\" or occupancy (L2O) to know\n      // the next unique facet. we used to load the delimiter too, but\n      // never used it.\n      l2o.counter = dis.readInt();\n\n      l2o.capacity = determineCapacity((int) Math.pow(2,\n          l2o.hashArrays.length), l2o.counter);\n      l2o.init();\n\n      // now read the chars\n      l2o.labelRepository = CharBlockArray.open(dis);\n\n      l2o.collisionMap = new CollisionMap(l2o.labelRepository);\n\n      // Calculate hash on the fly based on how CategoryPath hashes\n      // itself. Maybe in the future we can call some static based methods\n      // in CategoryPath so that this doesn't break again? I don't like\n      // having code in two different places...\n      int cid = 0;\n      // Skip the initial offset, it's the CategoryPath(0,0), which isn't\n      // a hashed value.\n      int offset = 1;\n      int lastStartOffset = offset;\n      // This loop really relies on a well-formed input (assumes pretty blindly\n      // that array offsets will work).  Since the initial file is machine \n      // generated, I think this should be OK.\n      while (offset < l2o.labelRepository.length()) {\n        // First component is numcomponents, so we initialize the hash\n        // to this\n        int ncomponents = l2o.labelRepository.charAt(offset++);\n        int hash = ncomponents;\n        // If ncomponents is 0, then we are done?\n        if (ncomponents != 0) {\n\n          // usedchars is always the last member of the 'ends' array\n          // in serialization. Rather than rebuild the entire array,\n          // assign usedchars to the last value we read in. This will\n          // be slightly more memory efficient.\n          int usedchars = 0;\n          for (int i = 0; i < ncomponents; i++) {\n            usedchars = l2o.labelRepository.charAt(offset++);\n            hash = hash * 31 + usedchars;\n          }\n          // Hash the usedchars for this label\n          for (int i = 0; i < usedchars; i++) {\n            hash = hash * 31 + l2o.labelRepository.charAt(offset++);\n          }\n        }\n        // Now that we've hashed the components of the label, do the\n        // final part of the hash algorithm.\n        hash = hash ^ ((hash >>> 20) ^ (hash >>> 12));\n        hash = hash ^ (hash >>> 7) ^ (hash >>> 4);\n        // Add the label, and let's keep going\n        l2o.addLabelOffset(hash, cid, lastStartOffset);\n        cid++;\n        lastStartOffset = offset;\n      }\n\n    } catch (ClassNotFoundException cnfe) {\n      throw new IOException(\"Invalid file format. Cannot deserialize.\");\n    } finally {\n      if (dis != null) {\n        dis.close();\n      }\n    }\n\n    l2o.threshold = (int) (l2o.loadFactor * l2o.capacity);\n    return l2o;\n\n  }\n\n","sourceOld":"  /**\n   * Opens the file and reloads the CompactLabelToOrdinal. The file it expects\n   * is generated from the {@link #flush()} command.\n   */\n  static CompactLabelToOrdinal open(File file, float loadFactor,\n                                    int numHashArrays) throws IOException {\n    /**\n     * Part of the file is the labelRepository, which needs to be rehashed\n     * and label offsets re-added to the object. I am unsure as to why we\n     * can't just store these off in the file as well, but in keeping with\n     * the spirit of the original code, I did it this way. (ssuppe)\n     */\n    CompactLabelToOrdinal l2o = new CompactLabelToOrdinal();\n    l2o.loadFactor = loadFactor;\n    l2o.hashArrays = new HashArray[numHashArrays];\n\n    DataInputStream dis = null;\n    try {\n      dis = new DataInputStream(new BufferedInputStream(\n          new FileInputStream(file)));\n\n      // TaxiReader needs to load the \"counter\" or occupancy (L2O) to know\n      // the next unique facet. we used to load the delimiter too, but\n      // never used it.\n      l2o.counter = dis.readInt();\n\n      l2o.capacity = determineCapacity((int) Math.pow(2,\n          l2o.hashArrays.length), l2o.counter);\n      l2o.init();\n\n      // now read the chars\n      l2o.labelRepository = CharBlockArray.open(dis);\n\n      l2o.collisionMap = new CollisionMap(l2o.labelRepository);\n\n      // Calculate hash on the fly based on how CategoryPath hashes\n      // itself. Maybe in the future we can call some static based methods\n      // in CategoryPath so that this doesn't break again? I don't like\n      // having code in two different places...\n      int cid = 0;\n      // Skip the initial offset, it's the CategoryPath(0,0), which isn't\n      // a hashed value.\n      int offset = 1;\n      int lastStartOffset = offset;\n      // This loop really relies on a well-formed input (assumes pretty blindly\n      // that array offsets will work).  Since the initial file is machine \n      // generated, I think this should be OK.\n      while (offset < l2o.labelRepository.length()) {\n        // First component is numcomponents, so we initialize the hash\n        // to this\n        int ncomponents = l2o.labelRepository.charAt(offset++);\n        int hash = ncomponents;\n        // If ncomponents is 0, then we are done?\n        if (ncomponents != 0) {\n\n          // usedchars is always the last member of the 'ends' array\n          // in serialization. Rather than rebuild the entire array,\n          // assign usedchars to the last value we read in. This will\n          // be slightly more memory efficient.\n          int usedchars = 0;\n          for (int i = 0; i < ncomponents; i++) {\n            usedchars = l2o.labelRepository.charAt(offset++);\n            hash = hash * 31 + usedchars;\n          }\n          // Hash the usedchars for this label\n          for (int i = 0; i < usedchars; i++) {\n            hash = hash * 31 + l2o.labelRepository.charAt(offset++);\n          }\n        }\n        // Now that we've hashed the components of the label, do the\n        // final part of the hash algorithm.\n        hash = hash ^ ((hash >>> 20) ^ (hash >>> 12));\n        hash = hash ^ (hash >>> 7) ^ (hash >>> 4);\n        // Add the label, and let's keep going\n        l2o.addLabelOffset(hash, cid, lastStartOffset);\n        cid++;\n        lastStartOffset = offset;\n      }\n\n    } catch (ClassNotFoundException cnfe) {\n      throw new IOException(\"Invalid file format. Cannot deserialize.\");\n    } finally {\n      if (dis != null) {\n        dis.close();\n      }\n    }\n\n    l2o.threshold = (int) (l2o.loadFactor * l2o.capacity);\n    return l2o;\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f9be242e584b2f40a71c1736de4cbdb36bcf08a5","date":1335144174,"type":3,"author":"Christopher John Male","isMerge":false,"pathNew":"lucene/facet/src/java/org/apache/lucene/facet/taxonomy/writercache/cl2o/CompactLabelToOrdinal#open(File,float,int).mjava","pathOld":"lucene/facet/src/java/org/apache/lucene/facet/taxonomy/writercache/cl2o/CompactLabelToOrdinal#open(File,float,int).mjava","sourceNew":"  /**\n   * Opens the file and reloads the CompactLabelToOrdinal. The file it expects\n   * is generated from the {@link #flush(File)} command.\n   */\n  static CompactLabelToOrdinal open(File file, float loadFactor,\n                                    int numHashArrays) throws IOException {\n    /**\n     * Part of the file is the labelRepository, which needs to be rehashed\n     * and label offsets re-added to the object. I am unsure as to why we\n     * can't just store these off in the file as well, but in keeping with\n     * the spirit of the original code, I did it this way. (ssuppe)\n     */\n    CompactLabelToOrdinal l2o = new CompactLabelToOrdinal();\n    l2o.loadFactor = loadFactor;\n    l2o.hashArrays = new HashArray[numHashArrays];\n\n    DataInputStream dis = null;\n    try {\n      dis = new DataInputStream(new BufferedInputStream(\n          new FileInputStream(file)));\n\n      // TaxiReader needs to load the \"counter\" or occupancy (L2O) to know\n      // the next unique facet. we used to load the delimiter too, but\n      // never used it.\n      l2o.counter = dis.readInt();\n\n      l2o.capacity = determineCapacity((int) Math.pow(2,\n          l2o.hashArrays.length), l2o.counter);\n      l2o.init();\n\n      // now read the chars\n      l2o.labelRepository = CharBlockArray.open(dis);\n\n      l2o.collisionMap = new CollisionMap(l2o.labelRepository);\n\n      // Calculate hash on the fly based on how CategoryPath hashes\n      // itself. Maybe in the future we can call some static based methods\n      // in CategoryPath so that this doesn't break again? I don't like\n      // having code in two different places...\n      int cid = 0;\n      // Skip the initial offset, it's the CategoryPath(0,0), which isn't\n      // a hashed value.\n      int offset = 1;\n      int lastStartOffset = offset;\n      // This loop really relies on a well-formed input (assumes pretty blindly\n      // that array offsets will work).  Since the initial file is machine \n      // generated, I think this should be OK.\n      while (offset < l2o.labelRepository.length()) {\n        // First component is numcomponents, so we initialize the hash\n        // to this\n        int ncomponents = l2o.labelRepository.charAt(offset++);\n        int hash = ncomponents;\n        // If ncomponents is 0, then we are done?\n        if (ncomponents != 0) {\n\n          // usedchars is always the last member of the 'ends' array\n          // in serialization. Rather than rebuild the entire array,\n          // assign usedchars to the last value we read in. This will\n          // be slightly more memory efficient.\n          int usedchars = 0;\n          for (int i = 0; i < ncomponents; i++) {\n            usedchars = l2o.labelRepository.charAt(offset++);\n            hash = hash * 31 + usedchars;\n          }\n          // Hash the usedchars for this label\n          for (int i = 0; i < usedchars; i++) {\n            hash = hash * 31 + l2o.labelRepository.charAt(offset++);\n          }\n        }\n        // Now that we've hashed the components of the label, do the\n        // final part of the hash algorithm.\n        hash = hash ^ ((hash >>> 20) ^ (hash >>> 12));\n        hash = hash ^ (hash >>> 7) ^ (hash >>> 4);\n        // Add the label, and let's keep going\n        l2o.addLabelOffset(hash, cid, lastStartOffset);\n        cid++;\n        lastStartOffset = offset;\n      }\n\n    } catch (ClassNotFoundException cnfe) {\n      throw new IOException(\"Invalid file format. Cannot deserialize.\");\n    } finally {\n      if (dis != null) {\n        dis.close();\n      }\n    }\n\n    l2o.threshold = (int) (l2o.loadFactor * l2o.capacity);\n    return l2o;\n\n  }\n\n","sourceOld":"  /**\n   * Opens the file and reloads the CompactLabelToOrdinal. The file it expects\n   * is generated from the {@link #flush()} command.\n   */\n  static CompactLabelToOrdinal open(File file, float loadFactor,\n                                    int numHashArrays) throws IOException {\n    /**\n     * Part of the file is the labelRepository, which needs to be rehashed\n     * and label offsets re-added to the object. I am unsure as to why we\n     * can't just store these off in the file as well, but in keeping with\n     * the spirit of the original code, I did it this way. (ssuppe)\n     */\n    CompactLabelToOrdinal l2o = new CompactLabelToOrdinal();\n    l2o.loadFactor = loadFactor;\n    l2o.hashArrays = new HashArray[numHashArrays];\n\n    DataInputStream dis = null;\n    try {\n      dis = new DataInputStream(new BufferedInputStream(\n          new FileInputStream(file)));\n\n      // TaxiReader needs to load the \"counter\" or occupancy (L2O) to know\n      // the next unique facet. we used to load the delimiter too, but\n      // never used it.\n      l2o.counter = dis.readInt();\n\n      l2o.capacity = determineCapacity((int) Math.pow(2,\n          l2o.hashArrays.length), l2o.counter);\n      l2o.init();\n\n      // now read the chars\n      l2o.labelRepository = CharBlockArray.open(dis);\n\n      l2o.collisionMap = new CollisionMap(l2o.labelRepository);\n\n      // Calculate hash on the fly based on how CategoryPath hashes\n      // itself. Maybe in the future we can call some static based methods\n      // in CategoryPath so that this doesn't break again? I don't like\n      // having code in two different places...\n      int cid = 0;\n      // Skip the initial offset, it's the CategoryPath(0,0), which isn't\n      // a hashed value.\n      int offset = 1;\n      int lastStartOffset = offset;\n      // This loop really relies on a well-formed input (assumes pretty blindly\n      // that array offsets will work).  Since the initial file is machine \n      // generated, I think this should be OK.\n      while (offset < l2o.labelRepository.length()) {\n        // First component is numcomponents, so we initialize the hash\n        // to this\n        int ncomponents = l2o.labelRepository.charAt(offset++);\n        int hash = ncomponents;\n        // If ncomponents is 0, then we are done?\n        if (ncomponents != 0) {\n\n          // usedchars is always the last member of the 'ends' array\n          // in serialization. Rather than rebuild the entire array,\n          // assign usedchars to the last value we read in. This will\n          // be slightly more memory efficient.\n          int usedchars = 0;\n          for (int i = 0; i < ncomponents; i++) {\n            usedchars = l2o.labelRepository.charAt(offset++);\n            hash = hash * 31 + usedchars;\n          }\n          // Hash the usedchars for this label\n          for (int i = 0; i < usedchars; i++) {\n            hash = hash * 31 + l2o.labelRepository.charAt(offset++);\n          }\n        }\n        // Now that we've hashed the components of the label, do the\n        // final part of the hash algorithm.\n        hash = hash ^ ((hash >>> 20) ^ (hash >>> 12));\n        hash = hash ^ (hash >>> 7) ^ (hash >>> 4);\n        // Add the label, and let's keep going\n        l2o.addLabelOffset(hash, cid, lastStartOffset);\n        cid++;\n        lastStartOffset = offset;\n      }\n\n    } catch (ClassNotFoundException cnfe) {\n      throw new IOException(\"Invalid file format. Cannot deserialize.\");\n    } finally {\n      if (dis != null) {\n        dis.close();\n      }\n    }\n\n    l2o.threshold = (int) (l2o.loadFactor * l2o.capacity);\n    return l2o;\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d90771c07d45c6ad884c5ef9cb3a6eeb257238d1","date":1357499264,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/facet/src/java/org/apache/lucene/facet/taxonomy/writercache/cl2o/CompactLabelToOrdinal#open(File,float,int).mjava","pathOld":"lucene/facet/src/java/org/apache/lucene/facet/taxonomy/writercache/cl2o/CompactLabelToOrdinal#open(File,float,int).mjava","sourceNew":"  /**\n   * Opens the file and reloads the CompactLabelToOrdinal. The file it expects\n   * is generated from the {@link #flush(File)} command.\n   */\n  static CompactLabelToOrdinal open(File file, float loadFactor,\n                                    int numHashArrays) throws IOException {\n    /**\n     * Part of the file is the labelRepository, which needs to be rehashed\n     * and label offsets re-added to the object. I am unsure as to why we\n     * can't just store these off in the file as well, but in keeping with\n     * the spirit of the original code, I did it this way. (ssuppe)\n     */\n    CompactLabelToOrdinal l2o = new CompactLabelToOrdinal();\n    l2o.loadFactor = loadFactor;\n    l2o.hashArrays = new HashArray[numHashArrays];\n\n    DataInputStream dis = null;\n    try {\n      dis = new DataInputStream(new BufferedInputStream(\n          new FileInputStream(file)));\n\n      // TaxiReader needs to load the \"counter\" or occupancy (L2O) to know\n      // the next unique facet. we used to load the delimiter too, but\n      // never used it.\n      l2o.counter = dis.readInt();\n\n      l2o.capacity = determineCapacity((int) Math.pow(2,\n          l2o.hashArrays.length), l2o.counter);\n      l2o.init();\n\n      // now read the chars\n      l2o.labelRepository = CharBlockArray.open(dis);\n\n      l2o.collisionMap = new CollisionMap(l2o.labelRepository);\n\n      // Calculate hash on the fly based on how CategoryPath hashes\n      // itself. Maybe in the future we can call some static based methods\n      // in CategoryPath so that this doesn't break again? I don't like\n      // having code in two different places...\n      int cid = 0;\n      // Skip the initial offset, it's the CategoryPath(0,0), which isn't\n      // a hashed value.\n      int offset = 1;\n      int lastStartOffset = offset;\n      // This loop really relies on a well-formed input (assumes pretty blindly\n      // that array offsets will work).  Since the initial file is machine \n      // generated, I think this should be OK.\n      while (offset < l2o.labelRepository.length()) {\n        // identical code to CategoryPath.hashFromSerialized. since we need to\n        // advance offset, we cannot call the method directly. perhaps if we\n        // could pass a mutable Integer or something...\n        int length = (short) l2o.labelRepository.charAt(offset++);\n        int hash = length;\n        if (length != 0) {\n          for (int i = 0; i < length; i++) {\n            int len = (short) l2o.labelRepository.charAt(offset++);\n            hash = hash * 31 + l2o.labelRepository.subSequence(offset, offset + len).hashCode();\n            offset += len;\n          }\n        }\n        // Now that we've hashed the components of the label, do the\n        // final part of the hash algorithm.\n        hash = hash ^ ((hash >>> 20) ^ (hash >>> 12));\n        hash = hash ^ (hash >>> 7) ^ (hash >>> 4);\n        // Add the label, and let's keep going\n        l2o.addLabelOffset(hash, cid, lastStartOffset);\n        cid++;\n        lastStartOffset = offset;\n      }\n\n    } catch (ClassNotFoundException cnfe) {\n      throw new IOException(\"Invalid file format. Cannot deserialize.\");\n    } finally {\n      if (dis != null) {\n        dis.close();\n      }\n    }\n\n    l2o.threshold = (int) (l2o.loadFactor * l2o.capacity);\n    return l2o;\n\n  }\n\n","sourceOld":"  /**\n   * Opens the file and reloads the CompactLabelToOrdinal. The file it expects\n   * is generated from the {@link #flush(File)} command.\n   */\n  static CompactLabelToOrdinal open(File file, float loadFactor,\n                                    int numHashArrays) throws IOException {\n    /**\n     * Part of the file is the labelRepository, which needs to be rehashed\n     * and label offsets re-added to the object. I am unsure as to why we\n     * can't just store these off in the file as well, but in keeping with\n     * the spirit of the original code, I did it this way. (ssuppe)\n     */\n    CompactLabelToOrdinal l2o = new CompactLabelToOrdinal();\n    l2o.loadFactor = loadFactor;\n    l2o.hashArrays = new HashArray[numHashArrays];\n\n    DataInputStream dis = null;\n    try {\n      dis = new DataInputStream(new BufferedInputStream(\n          new FileInputStream(file)));\n\n      // TaxiReader needs to load the \"counter\" or occupancy (L2O) to know\n      // the next unique facet. we used to load the delimiter too, but\n      // never used it.\n      l2o.counter = dis.readInt();\n\n      l2o.capacity = determineCapacity((int) Math.pow(2,\n          l2o.hashArrays.length), l2o.counter);\n      l2o.init();\n\n      // now read the chars\n      l2o.labelRepository = CharBlockArray.open(dis);\n\n      l2o.collisionMap = new CollisionMap(l2o.labelRepository);\n\n      // Calculate hash on the fly based on how CategoryPath hashes\n      // itself. Maybe in the future we can call some static based methods\n      // in CategoryPath so that this doesn't break again? I don't like\n      // having code in two different places...\n      int cid = 0;\n      // Skip the initial offset, it's the CategoryPath(0,0), which isn't\n      // a hashed value.\n      int offset = 1;\n      int lastStartOffset = offset;\n      // This loop really relies on a well-formed input (assumes pretty blindly\n      // that array offsets will work).  Since the initial file is machine \n      // generated, I think this should be OK.\n      while (offset < l2o.labelRepository.length()) {\n        // First component is numcomponents, so we initialize the hash\n        // to this\n        int ncomponents = l2o.labelRepository.charAt(offset++);\n        int hash = ncomponents;\n        // If ncomponents is 0, then we are done?\n        if (ncomponents != 0) {\n\n          // usedchars is always the last member of the 'ends' array\n          // in serialization. Rather than rebuild the entire array,\n          // assign usedchars to the last value we read in. This will\n          // be slightly more memory efficient.\n          int usedchars = 0;\n          for (int i = 0; i < ncomponents; i++) {\n            usedchars = l2o.labelRepository.charAt(offset++);\n            hash = hash * 31 + usedchars;\n          }\n          // Hash the usedchars for this label\n          for (int i = 0; i < usedchars; i++) {\n            hash = hash * 31 + l2o.labelRepository.charAt(offset++);\n          }\n        }\n        // Now that we've hashed the components of the label, do the\n        // final part of the hash algorithm.\n        hash = hash ^ ((hash >>> 20) ^ (hash >>> 12));\n        hash = hash ^ (hash >>> 7) ^ (hash >>> 4);\n        // Add the label, and let's keep going\n        l2o.addLabelOffset(hash, cid, lastStartOffset);\n        cid++;\n        lastStartOffset = offset;\n      }\n\n    } catch (ClassNotFoundException cnfe) {\n      throw new IOException(\"Invalid file format. Cannot deserialize.\");\n    } finally {\n      if (dis != null) {\n        dis.close();\n      }\n    }\n\n    l2o.threshold = (int) (l2o.loadFactor * l2o.capacity);\n    return l2o;\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d3fcb70cf561547c7bb1506e0cf32ca7b1287064","date":1357616416,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/facet/src/java/org/apache/lucene/facet/taxonomy/writercache/cl2o/CompactLabelToOrdinal#open(File,float,int).mjava","pathOld":"lucene/facet/src/java/org/apache/lucene/facet/taxonomy/writercache/cl2o/CompactLabelToOrdinal#open(File,float,int).mjava","sourceNew":"  /**\n   * Opens the file and reloads the CompactLabelToOrdinal. The file it expects\n   * is generated from the {@link #flush(File)} command.\n   */\n  static CompactLabelToOrdinal open(File file, float loadFactor,\n                                    int numHashArrays) throws IOException {\n    /**\n     * Part of the file is the labelRepository, which needs to be rehashed\n     * and label offsets re-added to the object. I am unsure as to why we\n     * can't just store these off in the file as well, but in keeping with\n     * the spirit of the original code, I did it this way. (ssuppe)\n     */\n    CompactLabelToOrdinal l2o = new CompactLabelToOrdinal();\n    l2o.loadFactor = loadFactor;\n    l2o.hashArrays = new HashArray[numHashArrays];\n\n    DataInputStream dis = null;\n    try {\n      dis = new DataInputStream(new BufferedInputStream(\n          new FileInputStream(file)));\n\n      // TaxiReader needs to load the \"counter\" or occupancy (L2O) to know\n      // the next unique facet. we used to load the delimiter too, but\n      // never used it.\n      l2o.counter = dis.readInt();\n\n      l2o.capacity = determineCapacity((int) Math.pow(2,\n          l2o.hashArrays.length), l2o.counter);\n      l2o.init();\n\n      // now read the chars\n      l2o.labelRepository = CharBlockArray.open(dis);\n\n      l2o.collisionMap = new CollisionMap(l2o.labelRepository);\n\n      // Calculate hash on the fly based on how CategoryPath hashes\n      // itself. Maybe in the future we can call some static based methods\n      // in CategoryPath so that this doesn't break again? I don't like\n      // having code in two different places...\n      int cid = 0;\n      // Skip the initial offset, it's the CategoryPath(0,0), which isn't\n      // a hashed value.\n      int offset = 1;\n      int lastStartOffset = offset;\n      // This loop really relies on a well-formed input (assumes pretty blindly\n      // that array offsets will work).  Since the initial file is machine \n      // generated, I think this should be OK.\n      while (offset < l2o.labelRepository.length()) {\n        // identical code to CategoryPath.hashFromSerialized. since we need to\n        // advance offset, we cannot call the method directly. perhaps if we\n        // could pass a mutable Integer or something...\n        int length = (short) l2o.labelRepository.charAt(offset++);\n        int hash = length;\n        if (length != 0) {\n          for (int i = 0; i < length; i++) {\n            int len = (short) l2o.labelRepository.charAt(offset++);\n            hash = hash * 31 + l2o.labelRepository.subSequence(offset, offset + len).hashCode();\n            offset += len;\n          }\n        }\n        // Now that we've hashed the components of the label, do the\n        // final part of the hash algorithm.\n        hash = hash ^ ((hash >>> 20) ^ (hash >>> 12));\n        hash = hash ^ (hash >>> 7) ^ (hash >>> 4);\n        // Add the label, and let's keep going\n        l2o.addLabelOffset(hash, cid, lastStartOffset);\n        cid++;\n        lastStartOffset = offset;\n      }\n\n    } catch (ClassNotFoundException cnfe) {\n      throw new IOException(\"Invalid file format. Cannot deserialize.\");\n    } finally {\n      if (dis != null) {\n        dis.close();\n      }\n    }\n\n    l2o.threshold = (int) (l2o.loadFactor * l2o.capacity);\n    return l2o;\n\n  }\n\n","sourceOld":"  /**\n   * Opens the file and reloads the CompactLabelToOrdinal. The file it expects\n   * is generated from the {@link #flush(File)} command.\n   */\n  static CompactLabelToOrdinal open(File file, float loadFactor,\n                                    int numHashArrays) throws IOException {\n    /**\n     * Part of the file is the labelRepository, which needs to be rehashed\n     * and label offsets re-added to the object. I am unsure as to why we\n     * can't just store these off in the file as well, but in keeping with\n     * the spirit of the original code, I did it this way. (ssuppe)\n     */\n    CompactLabelToOrdinal l2o = new CompactLabelToOrdinal();\n    l2o.loadFactor = loadFactor;\n    l2o.hashArrays = new HashArray[numHashArrays];\n\n    DataInputStream dis = null;\n    try {\n      dis = new DataInputStream(new BufferedInputStream(\n          new FileInputStream(file)));\n\n      // TaxiReader needs to load the \"counter\" or occupancy (L2O) to know\n      // the next unique facet. we used to load the delimiter too, but\n      // never used it.\n      l2o.counter = dis.readInt();\n\n      l2o.capacity = determineCapacity((int) Math.pow(2,\n          l2o.hashArrays.length), l2o.counter);\n      l2o.init();\n\n      // now read the chars\n      l2o.labelRepository = CharBlockArray.open(dis);\n\n      l2o.collisionMap = new CollisionMap(l2o.labelRepository);\n\n      // Calculate hash on the fly based on how CategoryPath hashes\n      // itself. Maybe in the future we can call some static based methods\n      // in CategoryPath so that this doesn't break again? I don't like\n      // having code in two different places...\n      int cid = 0;\n      // Skip the initial offset, it's the CategoryPath(0,0), which isn't\n      // a hashed value.\n      int offset = 1;\n      int lastStartOffset = offset;\n      // This loop really relies on a well-formed input (assumes pretty blindly\n      // that array offsets will work).  Since the initial file is machine \n      // generated, I think this should be OK.\n      while (offset < l2o.labelRepository.length()) {\n        // First component is numcomponents, so we initialize the hash\n        // to this\n        int ncomponents = l2o.labelRepository.charAt(offset++);\n        int hash = ncomponents;\n        // If ncomponents is 0, then we are done?\n        if (ncomponents != 0) {\n\n          // usedchars is always the last member of the 'ends' array\n          // in serialization. Rather than rebuild the entire array,\n          // assign usedchars to the last value we read in. This will\n          // be slightly more memory efficient.\n          int usedchars = 0;\n          for (int i = 0; i < ncomponents; i++) {\n            usedchars = l2o.labelRepository.charAt(offset++);\n            hash = hash * 31 + usedchars;\n          }\n          // Hash the usedchars for this label\n          for (int i = 0; i < usedchars; i++) {\n            hash = hash * 31 + l2o.labelRepository.charAt(offset++);\n          }\n        }\n        // Now that we've hashed the components of the label, do the\n        // final part of the hash algorithm.\n        hash = hash ^ ((hash >>> 20) ^ (hash >>> 12));\n        hash = hash ^ (hash >>> 7) ^ (hash >>> 4);\n        // Add the label, and let's keep going\n        l2o.addLabelOffset(hash, cid, lastStartOffset);\n        cid++;\n        lastStartOffset = offset;\n      }\n\n    } catch (ClassNotFoundException cnfe) {\n      throw new IOException(\"Invalid file format. Cannot deserialize.\");\n    } finally {\n      if (dis != null) {\n        dis.close();\n      }\n    }\n\n    l2o.threshold = (int) (l2o.loadFactor * l2o.capacity);\n    return l2o;\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5cad50ed6659649a0edef71b8cf56280b0bdadd7","date":1385496862,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/facet/src/java/org/apache/lucene/facet/taxonomy/writercache/CompactLabelToOrdinal#open(File,float,int).mjava","pathOld":"lucene/facet/src/java/org/apache/lucene/facet/taxonomy/writercache/cl2o/CompactLabelToOrdinal#open(File,float,int).mjava","sourceNew":"  /**\n   * Opens the file and reloads the CompactLabelToOrdinal. The file it expects\n   * is generated from the {@link #flush(File)} command.\n   */\n  static CompactLabelToOrdinal open(File file, float loadFactor,\n                                    int numHashArrays) throws IOException {\n    /**\n     * Part of the file is the labelRepository, which needs to be rehashed\n     * and label offsets re-added to the object. I am unsure as to why we\n     * can't just store these off in the file as well, but in keeping with\n     * the spirit of the original code, I did it this way. (ssuppe)\n     */\n    CompactLabelToOrdinal l2o = new CompactLabelToOrdinal();\n    l2o.loadFactor = loadFactor;\n    l2o.hashArrays = new HashArray[numHashArrays];\n\n    DataInputStream dis = null;\n    try {\n      dis = new DataInputStream(new BufferedInputStream(\n          new FileInputStream(file)));\n\n      // TaxiReader needs to load the \"counter\" or occupancy (L2O) to know\n      // the next unique facet. we used to load the delimiter too, but\n      // never used it.\n      l2o.counter = dis.readInt();\n\n      l2o.capacity = determineCapacity((int) Math.pow(2,\n          l2o.hashArrays.length), l2o.counter);\n      l2o.init();\n\n      // now read the chars\n      l2o.labelRepository = CharBlockArray.open(dis);\n\n      l2o.collisionMap = new CollisionMap(l2o.labelRepository);\n\n      // Calculate hash on the fly based on how CategoryPath hashes\n      // itself. Maybe in the future we can call some static based methods\n      // in CategoryPath so that this doesn't break again? I don't like\n      // having code in two different places...\n      int cid = 0;\n      // Skip the initial offset, it's the CategoryPath(0,0), which isn't\n      // a hashed value.\n      int offset = 1;\n      int lastStartOffset = offset;\n      // This loop really relies on a well-formed input (assumes pretty blindly\n      // that array offsets will work).  Since the initial file is machine \n      // generated, I think this should be OK.\n      while (offset < l2o.labelRepository.length()) {\n        // identical code to CategoryPath.hashFromSerialized. since we need to\n        // advance offset, we cannot call the method directly. perhaps if we\n        // could pass a mutable Integer or something...\n        int length = (short) l2o.labelRepository.charAt(offset++);\n        int hash = length;\n        if (length != 0) {\n          for (int i = 0; i < length; i++) {\n            int len = (short) l2o.labelRepository.charAt(offset++);\n            hash = hash * 31 + l2o.labelRepository.subSequence(offset, offset + len).hashCode();\n            offset += len;\n          }\n        }\n        // Now that we've hashed the components of the label, do the\n        // final part of the hash algorithm.\n        hash = hash ^ ((hash >>> 20) ^ (hash >>> 12));\n        hash = hash ^ (hash >>> 7) ^ (hash >>> 4);\n        // Add the label, and let's keep going\n        l2o.addLabelOffset(hash, cid, lastStartOffset);\n        cid++;\n        lastStartOffset = offset;\n      }\n\n    } catch (ClassNotFoundException cnfe) {\n      throw new IOException(\"Invalid file format. Cannot deserialize.\");\n    } finally {\n      if (dis != null) {\n        dis.close();\n      }\n    }\n\n    l2o.threshold = (int) (l2o.loadFactor * l2o.capacity);\n    return l2o;\n\n  }\n\n","sourceOld":"  /**\n   * Opens the file and reloads the CompactLabelToOrdinal. The file it expects\n   * is generated from the {@link #flush(File)} command.\n   */\n  static CompactLabelToOrdinal open(File file, float loadFactor,\n                                    int numHashArrays) throws IOException {\n    /**\n     * Part of the file is the labelRepository, which needs to be rehashed\n     * and label offsets re-added to the object. I am unsure as to why we\n     * can't just store these off in the file as well, but in keeping with\n     * the spirit of the original code, I did it this way. (ssuppe)\n     */\n    CompactLabelToOrdinal l2o = new CompactLabelToOrdinal();\n    l2o.loadFactor = loadFactor;\n    l2o.hashArrays = new HashArray[numHashArrays];\n\n    DataInputStream dis = null;\n    try {\n      dis = new DataInputStream(new BufferedInputStream(\n          new FileInputStream(file)));\n\n      // TaxiReader needs to load the \"counter\" or occupancy (L2O) to know\n      // the next unique facet. we used to load the delimiter too, but\n      // never used it.\n      l2o.counter = dis.readInt();\n\n      l2o.capacity = determineCapacity((int) Math.pow(2,\n          l2o.hashArrays.length), l2o.counter);\n      l2o.init();\n\n      // now read the chars\n      l2o.labelRepository = CharBlockArray.open(dis);\n\n      l2o.collisionMap = new CollisionMap(l2o.labelRepository);\n\n      // Calculate hash on the fly based on how CategoryPath hashes\n      // itself. Maybe in the future we can call some static based methods\n      // in CategoryPath so that this doesn't break again? I don't like\n      // having code in two different places...\n      int cid = 0;\n      // Skip the initial offset, it's the CategoryPath(0,0), which isn't\n      // a hashed value.\n      int offset = 1;\n      int lastStartOffset = offset;\n      // This loop really relies on a well-formed input (assumes pretty blindly\n      // that array offsets will work).  Since the initial file is machine \n      // generated, I think this should be OK.\n      while (offset < l2o.labelRepository.length()) {\n        // identical code to CategoryPath.hashFromSerialized. since we need to\n        // advance offset, we cannot call the method directly. perhaps if we\n        // could pass a mutable Integer or something...\n        int length = (short) l2o.labelRepository.charAt(offset++);\n        int hash = length;\n        if (length != 0) {\n          for (int i = 0; i < length; i++) {\n            int len = (short) l2o.labelRepository.charAt(offset++);\n            hash = hash * 31 + l2o.labelRepository.subSequence(offset, offset + len).hashCode();\n            offset += len;\n          }\n        }\n        // Now that we've hashed the components of the label, do the\n        // final part of the hash algorithm.\n        hash = hash ^ ((hash >>> 20) ^ (hash >>> 12));\n        hash = hash ^ (hash >>> 7) ^ (hash >>> 4);\n        // Add the label, and let's keep going\n        l2o.addLabelOffset(hash, cid, lastStartOffset);\n        cid++;\n        lastStartOffset = offset;\n      }\n\n    } catch (ClassNotFoundException cnfe) {\n      throw new IOException(\"Invalid file format. Cannot deserialize.\");\n    } finally {\n      if (dis != null) {\n        dis.close();\n      }\n    }\n\n    l2o.threshold = (int) (l2o.loadFactor * l2o.capacity);\n    return l2o;\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3cc728b07df73b197e6d940d27f9b08b63918f13","date":1388834348,"type":5,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/facet/src/java/org/apache/lucene/facet/taxonomy/writercache/CompactLabelToOrdinal#open(File,float,int).mjava","pathOld":"lucene/facet/src/java/org/apache/lucene/facet/taxonomy/writercache/cl2o/CompactLabelToOrdinal#open(File,float,int).mjava","sourceNew":"  /**\n   * Opens the file and reloads the CompactLabelToOrdinal. The file it expects\n   * is generated from the {@link #flush(File)} command.\n   */\n  static CompactLabelToOrdinal open(File file, float loadFactor,\n                                    int numHashArrays) throws IOException {\n    /**\n     * Part of the file is the labelRepository, which needs to be rehashed\n     * and label offsets re-added to the object. I am unsure as to why we\n     * can't just store these off in the file as well, but in keeping with\n     * the spirit of the original code, I did it this way. (ssuppe)\n     */\n    CompactLabelToOrdinal l2o = new CompactLabelToOrdinal();\n    l2o.loadFactor = loadFactor;\n    l2o.hashArrays = new HashArray[numHashArrays];\n\n    DataInputStream dis = null;\n    try {\n      dis = new DataInputStream(new BufferedInputStream(\n          new FileInputStream(file)));\n\n      // TaxiReader needs to load the \"counter\" or occupancy (L2O) to know\n      // the next unique facet. we used to load the delimiter too, but\n      // never used it.\n      l2o.counter = dis.readInt();\n\n      l2o.capacity = determineCapacity((int) Math.pow(2,\n          l2o.hashArrays.length), l2o.counter);\n      l2o.init();\n\n      // now read the chars\n      l2o.labelRepository = CharBlockArray.open(dis);\n\n      l2o.collisionMap = new CollisionMap(l2o.labelRepository);\n\n      // Calculate hash on the fly based on how CategoryPath hashes\n      // itself. Maybe in the future we can call some static based methods\n      // in CategoryPath so that this doesn't break again? I don't like\n      // having code in two different places...\n      int cid = 0;\n      // Skip the initial offset, it's the CategoryPath(0,0), which isn't\n      // a hashed value.\n      int offset = 1;\n      int lastStartOffset = offset;\n      // This loop really relies on a well-formed input (assumes pretty blindly\n      // that array offsets will work).  Since the initial file is machine \n      // generated, I think this should be OK.\n      while (offset < l2o.labelRepository.length()) {\n        // identical code to CategoryPath.hashFromSerialized. since we need to\n        // advance offset, we cannot call the method directly. perhaps if we\n        // could pass a mutable Integer or something...\n        int length = (short) l2o.labelRepository.charAt(offset++);\n        int hash = length;\n        if (length != 0) {\n          for (int i = 0; i < length; i++) {\n            int len = (short) l2o.labelRepository.charAt(offset++);\n            hash = hash * 31 + l2o.labelRepository.subSequence(offset, offset + len).hashCode();\n            offset += len;\n          }\n        }\n        // Now that we've hashed the components of the label, do the\n        // final part of the hash algorithm.\n        hash = hash ^ ((hash >>> 20) ^ (hash >>> 12));\n        hash = hash ^ (hash >>> 7) ^ (hash >>> 4);\n        // Add the label, and let's keep going\n        l2o.addLabelOffset(hash, cid, lastStartOffset);\n        cid++;\n        lastStartOffset = offset;\n      }\n\n    } catch (ClassNotFoundException cnfe) {\n      throw new IOException(\"Invalid file format. Cannot deserialize.\");\n    } finally {\n      if (dis != null) {\n        dis.close();\n      }\n    }\n\n    l2o.threshold = (int) (l2o.loadFactor * l2o.capacity);\n    return l2o;\n\n  }\n\n","sourceOld":"  /**\n   * Opens the file and reloads the CompactLabelToOrdinal. The file it expects\n   * is generated from the {@link #flush(File)} command.\n   */\n  static CompactLabelToOrdinal open(File file, float loadFactor,\n                                    int numHashArrays) throws IOException {\n    /**\n     * Part of the file is the labelRepository, which needs to be rehashed\n     * and label offsets re-added to the object. I am unsure as to why we\n     * can't just store these off in the file as well, but in keeping with\n     * the spirit of the original code, I did it this way. (ssuppe)\n     */\n    CompactLabelToOrdinal l2o = new CompactLabelToOrdinal();\n    l2o.loadFactor = loadFactor;\n    l2o.hashArrays = new HashArray[numHashArrays];\n\n    DataInputStream dis = null;\n    try {\n      dis = new DataInputStream(new BufferedInputStream(\n          new FileInputStream(file)));\n\n      // TaxiReader needs to load the \"counter\" or occupancy (L2O) to know\n      // the next unique facet. we used to load the delimiter too, but\n      // never used it.\n      l2o.counter = dis.readInt();\n\n      l2o.capacity = determineCapacity((int) Math.pow(2,\n          l2o.hashArrays.length), l2o.counter);\n      l2o.init();\n\n      // now read the chars\n      l2o.labelRepository = CharBlockArray.open(dis);\n\n      l2o.collisionMap = new CollisionMap(l2o.labelRepository);\n\n      // Calculate hash on the fly based on how CategoryPath hashes\n      // itself. Maybe in the future we can call some static based methods\n      // in CategoryPath so that this doesn't break again? I don't like\n      // having code in two different places...\n      int cid = 0;\n      // Skip the initial offset, it's the CategoryPath(0,0), which isn't\n      // a hashed value.\n      int offset = 1;\n      int lastStartOffset = offset;\n      // This loop really relies on a well-formed input (assumes pretty blindly\n      // that array offsets will work).  Since the initial file is machine \n      // generated, I think this should be OK.\n      while (offset < l2o.labelRepository.length()) {\n        // identical code to CategoryPath.hashFromSerialized. since we need to\n        // advance offset, we cannot call the method directly. perhaps if we\n        // could pass a mutable Integer or something...\n        int length = (short) l2o.labelRepository.charAt(offset++);\n        int hash = length;\n        if (length != 0) {\n          for (int i = 0; i < length; i++) {\n            int len = (short) l2o.labelRepository.charAt(offset++);\n            hash = hash * 31 + l2o.labelRepository.subSequence(offset, offset + len).hashCode();\n            offset += len;\n          }\n        }\n        // Now that we've hashed the components of the label, do the\n        // final part of the hash algorithm.\n        hash = hash ^ ((hash >>> 20) ^ (hash >>> 12));\n        hash = hash ^ (hash >>> 7) ^ (hash >>> 4);\n        // Add the label, and let's keep going\n        l2o.addLabelOffset(hash, cid, lastStartOffset);\n        cid++;\n        lastStartOffset = offset;\n      }\n\n    } catch (ClassNotFoundException cnfe) {\n      throw new IOException(\"Invalid file format. Cannot deserialize.\");\n    } finally {\n      if (dis != null) {\n        dis.close();\n      }\n    }\n\n    l2o.threshold = (int) (l2o.loadFactor * l2o.capacity);\n    return l2o;\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["f9be242e584b2f40a71c1736de4cbdb36bcf08a5","d90771c07d45c6ad884c5ef9cb3a6eeb257238d1"],"d90771c07d45c6ad884c5ef9cb3a6eeb257238d1":["f9be242e584b2f40a71c1736de4cbdb36bcf08a5"],"f9be242e584b2f40a71c1736de4cbdb36bcf08a5":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"5cad50ed6659649a0edef71b8cf56280b0bdadd7":["d90771c07d45c6ad884c5ef9cb3a6eeb257238d1"],"3cc728b07df73b197e6d940d27f9b08b63918f13":["d90771c07d45c6ad884c5ef9cb3a6eeb257238d1","5cad50ed6659649a0edef71b8cf56280b0bdadd7"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3cc728b07df73b197e6d940d27f9b08b63918f13"]},"commit2Childs":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":[],"f9be242e584b2f40a71c1736de4cbdb36bcf08a5":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","d90771c07d45c6ad884c5ef9cb3a6eeb257238d1"],"d90771c07d45c6ad884c5ef9cb3a6eeb257238d1":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","5cad50ed6659649a0edef71b8cf56280b0bdadd7","3cc728b07df73b197e6d940d27f9b08b63918f13"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["f9be242e584b2f40a71c1736de4cbdb36bcf08a5"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"5cad50ed6659649a0edef71b8cf56280b0bdadd7":["3cc728b07df73b197e6d940d27f9b08b63918f13"],"3cc728b07df73b197e6d940d27f9b08b63918f13":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}