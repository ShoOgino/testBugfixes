{"path":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter#getBestTextFragments(TokenStream,String,boolean,int).mjava","commits":[{"id":"043c298cb215f13ba7b9b81d20760704e8f93d66","date":1107566743,"type":1,"author":"Erik Hatcher","isMerge":false,"pathNew":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter#getBestTextFragments(TokenStream,String,boolean,int).mjava","pathOld":"sandbox/contributions/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter#getBestTextFragments(TokenStream,String,boolean,int).mjava","sourceNew":"\t/**\n\t * Low level api to get the most relevant (formatted) sections of the document.\n\t * This method has been made public to allow visibility of score information held in TextFragment objects.\n\t * Thanks to Jason Calabrese for help in redefining the interface.  \n\t * @param tokenStream\n\t * @param text\n\t * @param maxNumFragments\n\t * @param mergeContiguousFragments\n\t * @return \n\t * @throws IOException\n\t */\n\tpublic final TextFragment[] getBestTextFragments(\n\t\tTokenStream tokenStream,\t\n\t\tString text,\n\t\tboolean mergeContiguousFragments,\n\t\tint maxNumFragments)\n\t\tthrows IOException\n\t{\n\t\tArrayList docFrags = new ArrayList();\n\t\tStringBuffer newText=new StringBuffer();\n\n\t\tTextFragment currentFrag =\tnew TextFragment(newText,newText.length(), docFrags.size());\n\t\tfragmentScorer.startFragment(currentFrag);\n\t\tdocFrags.add(currentFrag);\n\t\n\t\tFragmentQueue fragQueue = new FragmentQueue(maxNumFragments);\n\n\t\ttry\n\t\t{\n\t\t\torg.apache.lucene.analysis.Token token;\n\t\t\tString tokenText;\n\t\t\tint startOffset;\n\t\t\tint endOffset;\n\t\t\tint lastEndOffset = 0;\n\t\t\ttextFragmenter.start(text);\n\t\t\n\t\t\tTokenGroup tokenGroup=new TokenGroup();\n\n\t\t\twhile ((token = tokenStream.next()) != null)\n\t\t\t{\n\t\t\t\tif((tokenGroup.numTokens>0)&&(tokenGroup.isDistinct(token)))\n\t\t\t\t{\n\t\t\t\t\t//the current token is distinct from previous tokens - \n\t\t\t\t\t// markup the cached token group info\n\t\t\t\t\tstartOffset = tokenGroup.startOffset;\n\t\t\t\t\tendOffset = tokenGroup.endOffset;\t\t\n\t\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\t\tString markedUpText=formatter.highlightTerm(tokenText, tokenGroup);\n\t\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\t\tnewText.append(text.substring(lastEndOffset, startOffset));\n\t\t\t\t\tnewText.append(markedUpText);\n\t\t\t\t\tlastEndOffset=endOffset;\n\t\t\t\t\ttokenGroup.clear();\n\n\t\t\t\t\t//check if current token marks the start of a new fragment\t\t\t\t\t\t\n\t\t\t\t\tif(textFragmenter.isNewFragment(token))\n\t\t\t\t\t{\n\t\t\t\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\t\t\t\t\t\t//record stats for a new fragment\n\t\t\t\t\t\tcurrentFrag.textEndPos = newText.length();\n\t\t\t\t\t\tcurrentFrag =new TextFragment(newText, newText.length(), docFrags.size());\n\t\t\t\t\t\tfragmentScorer.startFragment(currentFrag);\n\t\t\t\t\t\tdocFrags.add(currentFrag);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t\t\t\n\t\t\t\ttokenGroup.addToken(token,fragmentScorer.getTokenScore(token));\n\t\t\t\t\n\t\t\t\tif(lastEndOffset>maxDocBytesToAnalyze)\n\t\t\t\t{\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\t\n\t\t\tif(tokenGroup.numTokens>0)\n\t\t\t{\n\t\t\t\t//flush the accumulated text (same code as in above loop)\n\t\t\t\tstartOffset = tokenGroup.startOffset;\n\t\t\t\tendOffset = tokenGroup.endOffset;\t\t\n\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\tString markedUpText=formatter.highlightTerm(tokenText, tokenGroup);\n\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\tnewText.append(text.substring(lastEndOffset, startOffset));\n\t\t\t\tnewText.append(markedUpText);\n\t\t\t\tlastEndOffset=endOffset;\t\t\t\t\t\t\n\t\t\t}\n\n\t\t\t// append text after end of last token\n\t\t\tif (lastEndOffset < text.length())\n\t\t\t\tnewText.append(text.substring(lastEndOffset));\n\n\t\t\tcurrentFrag.textEndPos = newText.length();\n\n\t\t\t//sort the most relevant sections of the text\n\t\t\tint minScore = 0;\n\t\t\tfor (Iterator i = docFrags.iterator(); i.hasNext();)\n\t\t\t{\n\t\t\t\tcurrentFrag = (TextFragment) i.next();\n\n\t\t\t\t//If you are running with a version of Lucene before 11th Sept 03\n\t\t\t\t// you do not have PriorityQueue.insert() - so uncomment the code below\t\t\t\t\t\n\t\t\t\t/*\n\t\t\t\t\t\t\t\t\tif (currentFrag.getScore() >= minScore)\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tfragQueue.put(currentFrag);\n\t\t\t\t\t\t\t\t\t\tif (fragQueue.size() > maxNumFragments)\n\t\t\t\t\t\t\t\t\t\t{ // if hit queue overfull\n\t\t\t\t\t\t\t\t\t\t\tfragQueue.pop(); // remove lowest in hit queue\n\t\t\t\t\t\t\t\t\t\t\tminScore = ((TextFragment) fragQueue.top()).getScore(); // reset minScore\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t*/\n\t\t\t\t//The above code caused a problem as a result of Christoph Goller's 11th Sept 03\n\t\t\t\t//fix to PriorityQueue. The correct method to use here is the new \"insert\" method\n\t\t\t\t// USE ABOVE CODE IF THIS DOES NOT COMPILE!\n\t\t\t\tfragQueue.insert(currentFrag);\n\t\t\t}\n\n\t\t\t//return the most relevant fragments\n\t\t\tTextFragment frag[] = new TextFragment[fragQueue.size()];\n\t\t\tfor (int i = frag.length - 1; i >= 0; i--)\n\t\t\t{\n\t\t\t\tfrag[i] = (TextFragment) fragQueue.pop();\n\t\t\t}\n\t\t\t\n\t\t\t//merge any contiguous fragments to improve readability\n\t\t\tif(mergeContiguousFragments)\n\t\t\t{\n\t\t\t\tmergeContiguousFragments(frag);\n\t\t\t\tArrayList fragTexts = new ArrayList();\n\t\t\t\tfor (int i = 0; i < frag.length; i++)\n\t\t\t\t{\n\t\t\t\t\tif ((frag[i] != null) && (frag[i].getScore() > 0))\n\t\t\t\t\t{\n\t\t\t\t\t\tfragTexts.add(frag[i]);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfrag= (TextFragment[]) fragTexts.toArray(new TextFragment[0]);\t\t\t\t\n\t\t\t}\n\t\t\t\n\t\t\treturn frag;\n\n\t\t}\n\t\tfinally\n\t\t{\n\t\t\tif (tokenStream != null)\n\t\t\t{\n\t\t\t\ttry\n\t\t\t\t{\n\t\t\t\t\ttokenStream.close();\n\t\t\t\t}\n\t\t\t\tcatch (Exception e)\n\t\t\t\t{\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n","sourceOld":"\t/**\n\t * Low level api to get the most relevant (formatted) sections of the document.\n\t * This method has been made public to allow visibility of score information held in TextFragment objects.\n\t * Thanks to Jason Calabrese for help in redefining the interface.  \n\t * @param tokenStream\n\t * @param text\n\t * @param maxNumFragments\n\t * @param mergeContiguousFragments\n\t * @return \n\t * @throws IOException\n\t */\n\tpublic final TextFragment[] getBestTextFragments(\n\t\tTokenStream tokenStream,\t\n\t\tString text,\n\t\tboolean mergeContiguousFragments,\n\t\tint maxNumFragments)\n\t\tthrows IOException\n\t{\n\t\tArrayList docFrags = new ArrayList();\n\t\tStringBuffer newText=new StringBuffer();\n\n\t\tTextFragment currentFrag =\tnew TextFragment(newText,newText.length(), docFrags.size());\n\t\tfragmentScorer.startFragment(currentFrag);\n\t\tdocFrags.add(currentFrag);\n\t\n\t\tFragmentQueue fragQueue = new FragmentQueue(maxNumFragments);\n\n\t\ttry\n\t\t{\n\t\t\torg.apache.lucene.analysis.Token token;\n\t\t\tString tokenText;\n\t\t\tint startOffset;\n\t\t\tint endOffset;\n\t\t\tint lastEndOffset = 0;\n\t\t\ttextFragmenter.start(text);\n\t\t\n\t\t\tTokenGroup tokenGroup=new TokenGroup();\n\n\t\t\twhile ((token = tokenStream.next()) != null)\n\t\t\t{\n\t\t\t\tif((tokenGroup.numTokens>0)&&(tokenGroup.isDistinct(token)))\n\t\t\t\t{\n\t\t\t\t\t//the current token is distinct from previous tokens - \n\t\t\t\t\t// markup the cached token group info\n\t\t\t\t\tstartOffset = tokenGroup.startOffset;\n\t\t\t\t\tendOffset = tokenGroup.endOffset;\t\t\n\t\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\t\tString markedUpText=formatter.highlightTerm(tokenText, tokenGroup);\n\t\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\t\tnewText.append(text.substring(lastEndOffset, startOffset));\n\t\t\t\t\tnewText.append(markedUpText);\n\t\t\t\t\tlastEndOffset=endOffset;\n\t\t\t\t\ttokenGroup.clear();\n\n\t\t\t\t\t//check if current token marks the start of a new fragment\t\t\t\t\t\t\n\t\t\t\t\tif(textFragmenter.isNewFragment(token))\n\t\t\t\t\t{\n\t\t\t\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\t\t\t\t\t\t//record stats for a new fragment\n\t\t\t\t\t\tcurrentFrag.textEndPos = newText.length();\n\t\t\t\t\t\tcurrentFrag =new TextFragment(newText, newText.length(), docFrags.size());\n\t\t\t\t\t\tfragmentScorer.startFragment(currentFrag);\n\t\t\t\t\t\tdocFrags.add(currentFrag);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t\t\t\n\t\t\t\ttokenGroup.addToken(token,fragmentScorer.getTokenScore(token));\n\t\t\t\t\n\t\t\t\tif(lastEndOffset>maxDocBytesToAnalyze)\n\t\t\t\t{\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\t\n\t\t\tif(tokenGroup.numTokens>0)\n\t\t\t{\n\t\t\t\t//flush the accumulated text (same code as in above loop)\n\t\t\t\tstartOffset = tokenGroup.startOffset;\n\t\t\t\tendOffset = tokenGroup.endOffset;\t\t\n\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\tString markedUpText=formatter.highlightTerm(tokenText, tokenGroup);\n\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\tnewText.append(text.substring(lastEndOffset, startOffset));\n\t\t\t\tnewText.append(markedUpText);\n\t\t\t\tlastEndOffset=endOffset;\t\t\t\t\t\t\n\t\t\t}\n\n\t\t\t// append text after end of last token\n\t\t\tif (lastEndOffset < text.length())\n\t\t\t\tnewText.append(text.substring(lastEndOffset));\n\n\t\t\tcurrentFrag.textEndPos = newText.length();\n\n\t\t\t//sort the most relevant sections of the text\n\t\t\tint minScore = 0;\n\t\t\tfor (Iterator i = docFrags.iterator(); i.hasNext();)\n\t\t\t{\n\t\t\t\tcurrentFrag = (TextFragment) i.next();\n\n\t\t\t\t//If you are running with a version of Lucene before 11th Sept 03\n\t\t\t\t// you do not have PriorityQueue.insert() - so uncomment the code below\t\t\t\t\t\n\t\t\t\t/*\n\t\t\t\t\t\t\t\t\tif (currentFrag.getScore() >= minScore)\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tfragQueue.put(currentFrag);\n\t\t\t\t\t\t\t\t\t\tif (fragQueue.size() > maxNumFragments)\n\t\t\t\t\t\t\t\t\t\t{ // if hit queue overfull\n\t\t\t\t\t\t\t\t\t\t\tfragQueue.pop(); // remove lowest in hit queue\n\t\t\t\t\t\t\t\t\t\t\tminScore = ((TextFragment) fragQueue.top()).getScore(); // reset minScore\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t*/\n\t\t\t\t//The above code caused a problem as a result of Christoph Goller's 11th Sept 03\n\t\t\t\t//fix to PriorityQueue. The correct method to use here is the new \"insert\" method\n\t\t\t\t// USE ABOVE CODE IF THIS DOES NOT COMPILE!\n\t\t\t\tfragQueue.insert(currentFrag);\n\t\t\t}\n\n\t\t\t//return the most relevant fragments\n\t\t\tTextFragment frag[] = new TextFragment[fragQueue.size()];\n\t\t\tfor (int i = frag.length - 1; i >= 0; i--)\n\t\t\t{\n\t\t\t\tfrag[i] = (TextFragment) fragQueue.pop();\n\t\t\t}\n\t\t\t\n\t\t\t//merge any contiguous fragments to improve readability\n\t\t\tif(mergeContiguousFragments)\n\t\t\t{\n\t\t\t\tmergeContiguousFragments(frag);\n\t\t\t\tArrayList fragTexts = new ArrayList();\n\t\t\t\tfor (int i = 0; i < frag.length; i++)\n\t\t\t\t{\n\t\t\t\t\tif ((frag[i] != null) && (frag[i].getScore() > 0))\n\t\t\t\t\t{\n\t\t\t\t\t\tfragTexts.add(frag[i]);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfrag= (TextFragment[]) fragTexts.toArray(new TextFragment[0]);\t\t\t\t\n\t\t\t}\n\t\t\t\n\t\t\treturn frag;\n\n\t\t}\n\t\tfinally\n\t\t{\n\t\t\tif (tokenStream != null)\n\t\t\t{\n\t\t\t\ttry\n\t\t\t\t{\n\t\t\t\t\ttokenStream.close();\n\t\t\t\t}\n\t\t\t\tcatch (Exception e)\n\t\t\t\t{\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2fde44b2385ae1519002d7aa717f921b45b58276","date":1107725514,"type":3,"author":"Mark Harwood","isMerge":false,"pathNew":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter#getBestTextFragments(TokenStream,String,boolean,int).mjava","pathOld":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter#getBestTextFragments(TokenStream,String,boolean,int).mjava","sourceNew":"\t/**\n\t * Low level api to get the most relevant (formatted) sections of the document.\n\t * This method has been made public to allow visibility of score information held in TextFragment objects.\n\t * Thanks to Jason Calabrese for help in redefining the interface.  \n\t * @param tokenStream\n\t * @param text\n\t * @param maxNumFragments\n\t * @param mergeContiguousFragments\n\t * @return \n\t * @throws IOException\n\t */\n\tpublic final TextFragment[] getBestTextFragments(\n\t\tTokenStream tokenStream,\t\n\t\tString text,\n\t\tboolean mergeContiguousFragments,\n\t\tint maxNumFragments)\n\t\tthrows IOException\n\t{\n\t\tArrayList docFrags = new ArrayList();\n\t\tStringBuffer newText=new StringBuffer();\n\n\t\tTextFragment currentFrag =\tnew TextFragment(newText,newText.length(), docFrags.size());\n\t\tfragmentScorer.startFragment(currentFrag);\n\t\tdocFrags.add(currentFrag);\n\t\n\t\tFragmentQueue fragQueue = new FragmentQueue(maxNumFragments);\n\n\t\ttry\n\t\t{\n\t\t\torg.apache.lucene.analysis.Token token;\n\t\t\tString tokenText;\n\t\t\tint startOffset;\n\t\t\tint endOffset;\n\t\t\tint lastEndOffset = 0;\n\t\t\ttextFragmenter.start(text);\n\t\t\n\t\t\tTokenGroup tokenGroup=new TokenGroup();\n\n\t\t\twhile ((token = tokenStream.next()) != null)\n\t\t\t{\n\t\t\t\tif((tokenGroup.numTokens>0)&&(tokenGroup.isDistinct(token)))\n\t\t\t\t{\n\t\t\t\t\t//the current token is distinct from previous tokens - \n\t\t\t\t\t// markup the cached token group info\n\t\t\t\t\tstartOffset = tokenGroup.startOffset;\n\t\t\t\t\tendOffset = tokenGroup.endOffset;\t\t\n\t\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\t\tnewText.append(markedUpText);\n\t\t\t\t\tlastEndOffset=endOffset;\n\t\t\t\t\ttokenGroup.clear();\n\n\t\t\t\t\t//check if current token marks the start of a new fragment\t\t\t\t\t\t\n\t\t\t\t\tif(textFragmenter.isNewFragment(token))\n\t\t\t\t\t{\n\t\t\t\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\t\t\t\t\t\t//record stats for a new fragment\n\t\t\t\t\t\tcurrentFrag.textEndPos = newText.length();\n\t\t\t\t\t\tcurrentFrag =new TextFragment(newText, newText.length(), docFrags.size());\n\t\t\t\t\t\tfragmentScorer.startFragment(currentFrag);\n\t\t\t\t\t\tdocFrags.add(currentFrag);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t\t\t\n\t\t\t\ttokenGroup.addToken(token,fragmentScorer.getTokenScore(token));\n\t\t\t\t\n\t\t\t\tif(lastEndOffset>maxDocBytesToAnalyze)\n\t\t\t\t{\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\t\n\t\t\tif(tokenGroup.numTokens>0)\n\t\t\t{\n\t\t\t\t//flush the accumulated text (same code as in above loop)\n\t\t\t\tstartOffset = tokenGroup.startOffset;\n\t\t\t\tendOffset = tokenGroup.endOffset;\t\t\n\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\tnewText.append(markedUpText);\n\t\t\t\tlastEndOffset=endOffset;\t\t\t\t\t\t\n\t\t\t}\n\n\t\t\t// append text after end of last token\n\t\t\tif (lastEndOffset < text.length())\n\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset)));\n\n\t\t\tcurrentFrag.textEndPos = newText.length();\n\n\t\t\t//sort the most relevant sections of the text\n\t\t\tint minScore = 0;\n\t\t\tfor (Iterator i = docFrags.iterator(); i.hasNext();)\n\t\t\t{\n\t\t\t\tcurrentFrag = (TextFragment) i.next();\n\n\t\t\t\t//If you are running with a version of Lucene before 11th Sept 03\n\t\t\t\t// you do not have PriorityQueue.insert() - so uncomment the code below\t\t\t\t\t\n\t\t\t\t/*\n\t\t\t\t\t\t\t\t\tif (currentFrag.getScore() >= minScore)\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tfragQueue.put(currentFrag);\n\t\t\t\t\t\t\t\t\t\tif (fragQueue.size() > maxNumFragments)\n\t\t\t\t\t\t\t\t\t\t{ // if hit queue overfull\n\t\t\t\t\t\t\t\t\t\t\tfragQueue.pop(); // remove lowest in hit queue\n\t\t\t\t\t\t\t\t\t\t\tminScore = ((TextFragment) fragQueue.top()).getScore(); // reset minScore\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t*/\n\t\t\t\t//The above code caused a problem as a result of Christoph Goller's 11th Sept 03\n\t\t\t\t//fix to PriorityQueue. The correct method to use here is the new \"insert\" method\n\t\t\t\t// USE ABOVE CODE IF THIS DOES NOT COMPILE!\n\t\t\t\tfragQueue.insert(currentFrag);\n\t\t\t}\n\n\t\t\t//return the most relevant fragments\n\t\t\tTextFragment frag[] = new TextFragment[fragQueue.size()];\n\t\t\tfor (int i = frag.length - 1; i >= 0; i--)\n\t\t\t{\n\t\t\t\tfrag[i] = (TextFragment) fragQueue.pop();\n\t\t\t}\n\t\t\t\n\t\t\t//merge any contiguous fragments to improve readability\n\t\t\tif(mergeContiguousFragments)\n\t\t\t{\n\t\t\t\tmergeContiguousFragments(frag);\n\t\t\t\tArrayList fragTexts = new ArrayList();\n\t\t\t\tfor (int i = 0; i < frag.length; i++)\n\t\t\t\t{\n\t\t\t\t\tif ((frag[i] != null) && (frag[i].getScore() > 0))\n\t\t\t\t\t{\n\t\t\t\t\t\tfragTexts.add(frag[i]);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfrag= (TextFragment[]) fragTexts.toArray(new TextFragment[0]);\t\t\t\t\n\t\t\t}\n\t\t\t\n\t\t\treturn frag;\n\n\t\t}\n\t\tfinally\n\t\t{\n\t\t\tif (tokenStream != null)\n\t\t\t{\n\t\t\t\ttry\n\t\t\t\t{\n\t\t\t\t\ttokenStream.close();\n\t\t\t\t}\n\t\t\t\tcatch (Exception e)\n\t\t\t\t{\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n","sourceOld":"\t/**\n\t * Low level api to get the most relevant (formatted) sections of the document.\n\t * This method has been made public to allow visibility of score information held in TextFragment objects.\n\t * Thanks to Jason Calabrese for help in redefining the interface.  \n\t * @param tokenStream\n\t * @param text\n\t * @param maxNumFragments\n\t * @param mergeContiguousFragments\n\t * @return \n\t * @throws IOException\n\t */\n\tpublic final TextFragment[] getBestTextFragments(\n\t\tTokenStream tokenStream,\t\n\t\tString text,\n\t\tboolean mergeContiguousFragments,\n\t\tint maxNumFragments)\n\t\tthrows IOException\n\t{\n\t\tArrayList docFrags = new ArrayList();\n\t\tStringBuffer newText=new StringBuffer();\n\n\t\tTextFragment currentFrag =\tnew TextFragment(newText,newText.length(), docFrags.size());\n\t\tfragmentScorer.startFragment(currentFrag);\n\t\tdocFrags.add(currentFrag);\n\t\n\t\tFragmentQueue fragQueue = new FragmentQueue(maxNumFragments);\n\n\t\ttry\n\t\t{\n\t\t\torg.apache.lucene.analysis.Token token;\n\t\t\tString tokenText;\n\t\t\tint startOffset;\n\t\t\tint endOffset;\n\t\t\tint lastEndOffset = 0;\n\t\t\ttextFragmenter.start(text);\n\t\t\n\t\t\tTokenGroup tokenGroup=new TokenGroup();\n\n\t\t\twhile ((token = tokenStream.next()) != null)\n\t\t\t{\n\t\t\t\tif((tokenGroup.numTokens>0)&&(tokenGroup.isDistinct(token)))\n\t\t\t\t{\n\t\t\t\t\t//the current token is distinct from previous tokens - \n\t\t\t\t\t// markup the cached token group info\n\t\t\t\t\tstartOffset = tokenGroup.startOffset;\n\t\t\t\t\tendOffset = tokenGroup.endOffset;\t\t\n\t\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\t\tString markedUpText=formatter.highlightTerm(tokenText, tokenGroup);\n\t\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\t\tnewText.append(text.substring(lastEndOffset, startOffset));\n\t\t\t\t\tnewText.append(markedUpText);\n\t\t\t\t\tlastEndOffset=endOffset;\n\t\t\t\t\ttokenGroup.clear();\n\n\t\t\t\t\t//check if current token marks the start of a new fragment\t\t\t\t\t\t\n\t\t\t\t\tif(textFragmenter.isNewFragment(token))\n\t\t\t\t\t{\n\t\t\t\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\t\t\t\t\t\t//record stats for a new fragment\n\t\t\t\t\t\tcurrentFrag.textEndPos = newText.length();\n\t\t\t\t\t\tcurrentFrag =new TextFragment(newText, newText.length(), docFrags.size());\n\t\t\t\t\t\tfragmentScorer.startFragment(currentFrag);\n\t\t\t\t\t\tdocFrags.add(currentFrag);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t\t\t\n\t\t\t\ttokenGroup.addToken(token,fragmentScorer.getTokenScore(token));\n\t\t\t\t\n\t\t\t\tif(lastEndOffset>maxDocBytesToAnalyze)\n\t\t\t\t{\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\t\n\t\t\tif(tokenGroup.numTokens>0)\n\t\t\t{\n\t\t\t\t//flush the accumulated text (same code as in above loop)\n\t\t\t\tstartOffset = tokenGroup.startOffset;\n\t\t\t\tendOffset = tokenGroup.endOffset;\t\t\n\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\tString markedUpText=formatter.highlightTerm(tokenText, tokenGroup);\n\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\tnewText.append(text.substring(lastEndOffset, startOffset));\n\t\t\t\tnewText.append(markedUpText);\n\t\t\t\tlastEndOffset=endOffset;\t\t\t\t\t\t\n\t\t\t}\n\n\t\t\t// append text after end of last token\n\t\t\tif (lastEndOffset < text.length())\n\t\t\t\tnewText.append(text.substring(lastEndOffset));\n\n\t\t\tcurrentFrag.textEndPos = newText.length();\n\n\t\t\t//sort the most relevant sections of the text\n\t\t\tint minScore = 0;\n\t\t\tfor (Iterator i = docFrags.iterator(); i.hasNext();)\n\t\t\t{\n\t\t\t\tcurrentFrag = (TextFragment) i.next();\n\n\t\t\t\t//If you are running with a version of Lucene before 11th Sept 03\n\t\t\t\t// you do not have PriorityQueue.insert() - so uncomment the code below\t\t\t\t\t\n\t\t\t\t/*\n\t\t\t\t\t\t\t\t\tif (currentFrag.getScore() >= minScore)\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tfragQueue.put(currentFrag);\n\t\t\t\t\t\t\t\t\t\tif (fragQueue.size() > maxNumFragments)\n\t\t\t\t\t\t\t\t\t\t{ // if hit queue overfull\n\t\t\t\t\t\t\t\t\t\t\tfragQueue.pop(); // remove lowest in hit queue\n\t\t\t\t\t\t\t\t\t\t\tminScore = ((TextFragment) fragQueue.top()).getScore(); // reset minScore\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t*/\n\t\t\t\t//The above code caused a problem as a result of Christoph Goller's 11th Sept 03\n\t\t\t\t//fix to PriorityQueue. The correct method to use here is the new \"insert\" method\n\t\t\t\t// USE ABOVE CODE IF THIS DOES NOT COMPILE!\n\t\t\t\tfragQueue.insert(currentFrag);\n\t\t\t}\n\n\t\t\t//return the most relevant fragments\n\t\t\tTextFragment frag[] = new TextFragment[fragQueue.size()];\n\t\t\tfor (int i = frag.length - 1; i >= 0; i--)\n\t\t\t{\n\t\t\t\tfrag[i] = (TextFragment) fragQueue.pop();\n\t\t\t}\n\t\t\t\n\t\t\t//merge any contiguous fragments to improve readability\n\t\t\tif(mergeContiguousFragments)\n\t\t\t{\n\t\t\t\tmergeContiguousFragments(frag);\n\t\t\t\tArrayList fragTexts = new ArrayList();\n\t\t\t\tfor (int i = 0; i < frag.length; i++)\n\t\t\t\t{\n\t\t\t\t\tif ((frag[i] != null) && (frag[i].getScore() > 0))\n\t\t\t\t\t{\n\t\t\t\t\t\tfragTexts.add(frag[i]);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfrag= (TextFragment[]) fragTexts.toArray(new TextFragment[0]);\t\t\t\t\n\t\t\t}\n\t\t\t\n\t\t\treturn frag;\n\n\t\t}\n\t\tfinally\n\t\t{\n\t\t\tif (tokenStream != null)\n\t\t\t{\n\t\t\t\ttry\n\t\t\t\t{\n\t\t\t\t\ttokenStream.close();\n\t\t\t\t}\n\t\t\t\tcatch (Exception e)\n\t\t\t\t{\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e6ec63b41d741f5323f34c2820265518550b50dd","date":1108585215,"type":3,"author":"Daniel Naber","isMerge":false,"pathNew":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter#getBestTextFragments(TokenStream,String,boolean,int).mjava","pathOld":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter#getBestTextFragments(TokenStream,String,boolean,int).mjava","sourceNew":"\t/**\n\t * Low level api to get the most relevant (formatted) sections of the document.\n\t * This method has been made public to allow visibility of score information held in TextFragment objects.\n\t * Thanks to Jason Calabrese for help in redefining the interface.  \n\t * @param tokenStream\n\t * @param text\n\t * @param maxNumFragments\n\t * @param mergeContiguousFragments\n\t * @return \n\t * @throws IOException\n\t */\n\tpublic final TextFragment[] getBestTextFragments(\n\t\tTokenStream tokenStream,\t\n\t\tString text,\n\t\tboolean mergeContiguousFragments,\n\t\tint maxNumFragments)\n\t\tthrows IOException\n\t{\n\t\tArrayList docFrags = new ArrayList();\n\t\tStringBuffer newText=new StringBuffer();\n\n\t\tTextFragment currentFrag =\tnew TextFragment(newText,newText.length(), docFrags.size());\n\t\tfragmentScorer.startFragment(currentFrag);\n\t\tdocFrags.add(currentFrag);\n\t\n\t\tFragmentQueue fragQueue = new FragmentQueue(maxNumFragments);\n\n\t\ttry\n\t\t{\n\t\t\torg.apache.lucene.analysis.Token token;\n\t\t\tString tokenText;\n\t\t\tint startOffset;\n\t\t\tint endOffset;\n\t\t\tint lastEndOffset = 0;\n\t\t\ttextFragmenter.start(text);\n\t\t\n\t\t\tTokenGroup tokenGroup=new TokenGroup();\n\n\t\t\twhile ((token = tokenStream.next()) != null)\n\t\t\t{\n\t\t\t\tif((tokenGroup.numTokens>0)&&(tokenGroup.isDistinct(token)))\n\t\t\t\t{\n\t\t\t\t\t//the current token is distinct from previous tokens - \n\t\t\t\t\t// markup the cached token group info\n\t\t\t\t\tstartOffset = tokenGroup.startOffset;\n\t\t\t\t\tendOffset = tokenGroup.endOffset;\t\t\n\t\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\t\tnewText.append(markedUpText);\n\t\t\t\t\tlastEndOffset=endOffset;\n\t\t\t\t\ttokenGroup.clear();\n\n\t\t\t\t\t//check if current token marks the start of a new fragment\t\t\t\t\t\t\n\t\t\t\t\tif(textFragmenter.isNewFragment(token))\n\t\t\t\t\t{\n\t\t\t\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\t\t\t\t\t\t//record stats for a new fragment\n\t\t\t\t\t\tcurrentFrag.textEndPos = newText.length();\n\t\t\t\t\t\tcurrentFrag =new TextFragment(newText, newText.length(), docFrags.size());\n\t\t\t\t\t\tfragmentScorer.startFragment(currentFrag);\n\t\t\t\t\t\tdocFrags.add(currentFrag);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t\t\t\n\t\t\t\ttokenGroup.addToken(token,fragmentScorer.getTokenScore(token));\n\t\t\t\t\n\t\t\t\tif(lastEndOffset>maxDocBytesToAnalyze)\n\t\t\t\t{\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\t\n\t\t\tif(tokenGroup.numTokens>0)\n\t\t\t{\n\t\t\t\t//flush the accumulated text (same code as in above loop)\n\t\t\t\tstartOffset = tokenGroup.startOffset;\n\t\t\t\tendOffset = tokenGroup.endOffset;\t\t\n\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\tnewText.append(markedUpText);\n\t\t\t\tlastEndOffset=endOffset;\t\t\t\t\t\t\n\t\t\t}\n\n\t\t\t// append text after end of last token\n\t\t\tif (lastEndOffset < text.length())\n\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset)));\n\n\t\t\tcurrentFrag.textEndPos = newText.length();\n\n\t\t\t//sort the most relevant sections of the text\n\t\t\tfor (Iterator i = docFrags.iterator(); i.hasNext();)\n\t\t\t{\n\t\t\t\tcurrentFrag = (TextFragment) i.next();\n\n\t\t\t\t//If you are running with a version of Lucene before 11th Sept 03\n\t\t\t\t// you do not have PriorityQueue.insert() - so uncomment the code below\t\t\t\t\t\n\t\t\t\t/*\n\t\t\t\t\t\t\t\t\tif (currentFrag.getScore() >= minScore)\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tfragQueue.put(currentFrag);\n\t\t\t\t\t\t\t\t\t\tif (fragQueue.size() > maxNumFragments)\n\t\t\t\t\t\t\t\t\t\t{ // if hit queue overfull\n\t\t\t\t\t\t\t\t\t\t\tfragQueue.pop(); // remove lowest in hit queue\n\t\t\t\t\t\t\t\t\t\t\tminScore = ((TextFragment) fragQueue.top()).getScore(); // reset minScore\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t*/\n\t\t\t\t//The above code caused a problem as a result of Christoph Goller's 11th Sept 03\n\t\t\t\t//fix to PriorityQueue. The correct method to use here is the new \"insert\" method\n\t\t\t\t// USE ABOVE CODE IF THIS DOES NOT COMPILE!\n\t\t\t\tfragQueue.insert(currentFrag);\n\t\t\t}\n\n\t\t\t//return the most relevant fragments\n\t\t\tTextFragment frag[] = new TextFragment[fragQueue.size()];\n\t\t\tfor (int i = frag.length - 1; i >= 0; i--)\n\t\t\t{\n\t\t\t\tfrag[i] = (TextFragment) fragQueue.pop();\n\t\t\t}\n\t\t\t\n\t\t\t//merge any contiguous fragments to improve readability\n\t\t\tif(mergeContiguousFragments)\n\t\t\t{\n\t\t\t\tmergeContiguousFragments(frag);\n\t\t\t\tArrayList fragTexts = new ArrayList();\n\t\t\t\tfor (int i = 0; i < frag.length; i++)\n\t\t\t\t{\n\t\t\t\t\tif ((frag[i] != null) && (frag[i].getScore() > 0))\n\t\t\t\t\t{\n\t\t\t\t\t\tfragTexts.add(frag[i]);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfrag= (TextFragment[]) fragTexts.toArray(new TextFragment[0]);\t\t\t\t\n\t\t\t}\n\t\t\t\n\t\t\treturn frag;\n\n\t\t}\n\t\tfinally\n\t\t{\n\t\t\tif (tokenStream != null)\n\t\t\t{\n\t\t\t\ttry\n\t\t\t\t{\n\t\t\t\t\ttokenStream.close();\n\t\t\t\t}\n\t\t\t\tcatch (Exception e)\n\t\t\t\t{\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n","sourceOld":"\t/**\n\t * Low level api to get the most relevant (formatted) sections of the document.\n\t * This method has been made public to allow visibility of score information held in TextFragment objects.\n\t * Thanks to Jason Calabrese for help in redefining the interface.  \n\t * @param tokenStream\n\t * @param text\n\t * @param maxNumFragments\n\t * @param mergeContiguousFragments\n\t * @return \n\t * @throws IOException\n\t */\n\tpublic final TextFragment[] getBestTextFragments(\n\t\tTokenStream tokenStream,\t\n\t\tString text,\n\t\tboolean mergeContiguousFragments,\n\t\tint maxNumFragments)\n\t\tthrows IOException\n\t{\n\t\tArrayList docFrags = new ArrayList();\n\t\tStringBuffer newText=new StringBuffer();\n\n\t\tTextFragment currentFrag =\tnew TextFragment(newText,newText.length(), docFrags.size());\n\t\tfragmentScorer.startFragment(currentFrag);\n\t\tdocFrags.add(currentFrag);\n\t\n\t\tFragmentQueue fragQueue = new FragmentQueue(maxNumFragments);\n\n\t\ttry\n\t\t{\n\t\t\torg.apache.lucene.analysis.Token token;\n\t\t\tString tokenText;\n\t\t\tint startOffset;\n\t\t\tint endOffset;\n\t\t\tint lastEndOffset = 0;\n\t\t\ttextFragmenter.start(text);\n\t\t\n\t\t\tTokenGroup tokenGroup=new TokenGroup();\n\n\t\t\twhile ((token = tokenStream.next()) != null)\n\t\t\t{\n\t\t\t\tif((tokenGroup.numTokens>0)&&(tokenGroup.isDistinct(token)))\n\t\t\t\t{\n\t\t\t\t\t//the current token is distinct from previous tokens - \n\t\t\t\t\t// markup the cached token group info\n\t\t\t\t\tstartOffset = tokenGroup.startOffset;\n\t\t\t\t\tendOffset = tokenGroup.endOffset;\t\t\n\t\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\t\tnewText.append(markedUpText);\n\t\t\t\t\tlastEndOffset=endOffset;\n\t\t\t\t\ttokenGroup.clear();\n\n\t\t\t\t\t//check if current token marks the start of a new fragment\t\t\t\t\t\t\n\t\t\t\t\tif(textFragmenter.isNewFragment(token))\n\t\t\t\t\t{\n\t\t\t\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\t\t\t\t\t\t//record stats for a new fragment\n\t\t\t\t\t\tcurrentFrag.textEndPos = newText.length();\n\t\t\t\t\t\tcurrentFrag =new TextFragment(newText, newText.length(), docFrags.size());\n\t\t\t\t\t\tfragmentScorer.startFragment(currentFrag);\n\t\t\t\t\t\tdocFrags.add(currentFrag);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t\t\t\n\t\t\t\ttokenGroup.addToken(token,fragmentScorer.getTokenScore(token));\n\t\t\t\t\n\t\t\t\tif(lastEndOffset>maxDocBytesToAnalyze)\n\t\t\t\t{\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\t\n\t\t\tif(tokenGroup.numTokens>0)\n\t\t\t{\n\t\t\t\t//flush the accumulated text (same code as in above loop)\n\t\t\t\tstartOffset = tokenGroup.startOffset;\n\t\t\t\tendOffset = tokenGroup.endOffset;\t\t\n\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\tnewText.append(markedUpText);\n\t\t\t\tlastEndOffset=endOffset;\t\t\t\t\t\t\n\t\t\t}\n\n\t\t\t// append text after end of last token\n\t\t\tif (lastEndOffset < text.length())\n\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset)));\n\n\t\t\tcurrentFrag.textEndPos = newText.length();\n\n\t\t\t//sort the most relevant sections of the text\n\t\t\tint minScore = 0;\n\t\t\tfor (Iterator i = docFrags.iterator(); i.hasNext();)\n\t\t\t{\n\t\t\t\tcurrentFrag = (TextFragment) i.next();\n\n\t\t\t\t//If you are running with a version of Lucene before 11th Sept 03\n\t\t\t\t// you do not have PriorityQueue.insert() - so uncomment the code below\t\t\t\t\t\n\t\t\t\t/*\n\t\t\t\t\t\t\t\t\tif (currentFrag.getScore() >= minScore)\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tfragQueue.put(currentFrag);\n\t\t\t\t\t\t\t\t\t\tif (fragQueue.size() > maxNumFragments)\n\t\t\t\t\t\t\t\t\t\t{ // if hit queue overfull\n\t\t\t\t\t\t\t\t\t\t\tfragQueue.pop(); // remove lowest in hit queue\n\t\t\t\t\t\t\t\t\t\t\tminScore = ((TextFragment) fragQueue.top()).getScore(); // reset minScore\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t*/\n\t\t\t\t//The above code caused a problem as a result of Christoph Goller's 11th Sept 03\n\t\t\t\t//fix to PriorityQueue. The correct method to use here is the new \"insert\" method\n\t\t\t\t// USE ABOVE CODE IF THIS DOES NOT COMPILE!\n\t\t\t\tfragQueue.insert(currentFrag);\n\t\t\t}\n\n\t\t\t//return the most relevant fragments\n\t\t\tTextFragment frag[] = new TextFragment[fragQueue.size()];\n\t\t\tfor (int i = frag.length - 1; i >= 0; i--)\n\t\t\t{\n\t\t\t\tfrag[i] = (TextFragment) fragQueue.pop();\n\t\t\t}\n\t\t\t\n\t\t\t//merge any contiguous fragments to improve readability\n\t\t\tif(mergeContiguousFragments)\n\t\t\t{\n\t\t\t\tmergeContiguousFragments(frag);\n\t\t\t\tArrayList fragTexts = new ArrayList();\n\t\t\t\tfor (int i = 0; i < frag.length; i++)\n\t\t\t\t{\n\t\t\t\t\tif ((frag[i] != null) && (frag[i].getScore() > 0))\n\t\t\t\t\t{\n\t\t\t\t\t\tfragTexts.add(frag[i]);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfrag= (TextFragment[]) fragTexts.toArray(new TextFragment[0]);\t\t\t\t\n\t\t\t}\n\t\t\t\n\t\t\treturn frag;\n\n\t\t}\n\t\tfinally\n\t\t{\n\t\t\tif (tokenStream != null)\n\t\t\t{\n\t\t\t\ttry\n\t\t\t\t{\n\t\t\t\t\ttokenStream.close();\n\t\t\t\t}\n\t\t\t\tcatch (Exception e)\n\t\t\t\t{\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"78c79c829112a79287f8b7389502c7083d99c51b","date":1108586277,"type":3,"author":"Daniel Naber","isMerge":false,"pathNew":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter#getBestTextFragments(TokenStream,String,boolean,int).mjava","pathOld":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter#getBestTextFragments(TokenStream,String,boolean,int).mjava","sourceNew":"\t/**\n\t * Low level api to get the most relevant (formatted) sections of the document.\n\t * This method has been made public to allow visibility of score information held in TextFragment objects.\n\t * Thanks to Jason Calabrese for help in redefining the interface.  \n\t * @param tokenStream\n\t * @param text\n\t * @param maxNumFragments\n\t * @param mergeContiguousFragments\n\t * @throws IOException\n\t */\n\tpublic final TextFragment[] getBestTextFragments(\n\t\tTokenStream tokenStream,\t\n\t\tString text,\n\t\tboolean mergeContiguousFragments,\n\t\tint maxNumFragments)\n\t\tthrows IOException\n\t{\n\t\tArrayList docFrags = new ArrayList();\n\t\tStringBuffer newText=new StringBuffer();\n\n\t\tTextFragment currentFrag =\tnew TextFragment(newText,newText.length(), docFrags.size());\n\t\tfragmentScorer.startFragment(currentFrag);\n\t\tdocFrags.add(currentFrag);\n\t\n\t\tFragmentQueue fragQueue = new FragmentQueue(maxNumFragments);\n\n\t\ttry\n\t\t{\n\t\t\torg.apache.lucene.analysis.Token token;\n\t\t\tString tokenText;\n\t\t\tint startOffset;\n\t\t\tint endOffset;\n\t\t\tint lastEndOffset = 0;\n\t\t\ttextFragmenter.start(text);\n\t\t\n\t\t\tTokenGroup tokenGroup=new TokenGroup();\n\n\t\t\twhile ((token = tokenStream.next()) != null)\n\t\t\t{\n\t\t\t\tif((tokenGroup.numTokens>0)&&(tokenGroup.isDistinct(token)))\n\t\t\t\t{\n\t\t\t\t\t//the current token is distinct from previous tokens - \n\t\t\t\t\t// markup the cached token group info\n\t\t\t\t\tstartOffset = tokenGroup.startOffset;\n\t\t\t\t\tendOffset = tokenGroup.endOffset;\t\t\n\t\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\t\tnewText.append(markedUpText);\n\t\t\t\t\tlastEndOffset=endOffset;\n\t\t\t\t\ttokenGroup.clear();\n\n\t\t\t\t\t//check if current token marks the start of a new fragment\t\t\t\t\t\t\n\t\t\t\t\tif(textFragmenter.isNewFragment(token))\n\t\t\t\t\t{\n\t\t\t\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\t\t\t\t\t\t//record stats for a new fragment\n\t\t\t\t\t\tcurrentFrag.textEndPos = newText.length();\n\t\t\t\t\t\tcurrentFrag =new TextFragment(newText, newText.length(), docFrags.size());\n\t\t\t\t\t\tfragmentScorer.startFragment(currentFrag);\n\t\t\t\t\t\tdocFrags.add(currentFrag);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t\t\t\n\t\t\t\ttokenGroup.addToken(token,fragmentScorer.getTokenScore(token));\n\t\t\t\t\n\t\t\t\tif(lastEndOffset>maxDocBytesToAnalyze)\n\t\t\t\t{\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\t\n\t\t\tif(tokenGroup.numTokens>0)\n\t\t\t{\n\t\t\t\t//flush the accumulated text (same code as in above loop)\n\t\t\t\tstartOffset = tokenGroup.startOffset;\n\t\t\t\tendOffset = tokenGroup.endOffset;\t\t\n\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\tnewText.append(markedUpText);\n\t\t\t\tlastEndOffset=endOffset;\t\t\t\t\t\t\n\t\t\t}\n\n\t\t\t// append text after end of last token\n\t\t\tif (lastEndOffset < text.length())\n\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset)));\n\n\t\t\tcurrentFrag.textEndPos = newText.length();\n\n\t\t\t//sort the most relevant sections of the text\n\t\t\tfor (Iterator i = docFrags.iterator(); i.hasNext();)\n\t\t\t{\n\t\t\t\tcurrentFrag = (TextFragment) i.next();\n\n\t\t\t\t//If you are running with a version of Lucene before 11th Sept 03\n\t\t\t\t// you do not have PriorityQueue.insert() - so uncomment the code below\t\t\t\t\t\n\t\t\t\t/*\n\t\t\t\t\t\t\t\t\tif (currentFrag.getScore() >= minScore)\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tfragQueue.put(currentFrag);\n\t\t\t\t\t\t\t\t\t\tif (fragQueue.size() > maxNumFragments)\n\t\t\t\t\t\t\t\t\t\t{ // if hit queue overfull\n\t\t\t\t\t\t\t\t\t\t\tfragQueue.pop(); // remove lowest in hit queue\n\t\t\t\t\t\t\t\t\t\t\tminScore = ((TextFragment) fragQueue.top()).getScore(); // reset minScore\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t*/\n\t\t\t\t//The above code caused a problem as a result of Christoph Goller's 11th Sept 03\n\t\t\t\t//fix to PriorityQueue. The correct method to use here is the new \"insert\" method\n\t\t\t\t// USE ABOVE CODE IF THIS DOES NOT COMPILE!\n\t\t\t\tfragQueue.insert(currentFrag);\n\t\t\t}\n\n\t\t\t//return the most relevant fragments\n\t\t\tTextFragment frag[] = new TextFragment[fragQueue.size()];\n\t\t\tfor (int i = frag.length - 1; i >= 0; i--)\n\t\t\t{\n\t\t\t\tfrag[i] = (TextFragment) fragQueue.pop();\n\t\t\t}\n\t\t\t\n\t\t\t//merge any contiguous fragments to improve readability\n\t\t\tif(mergeContiguousFragments)\n\t\t\t{\n\t\t\t\tmergeContiguousFragments(frag);\n\t\t\t\tArrayList fragTexts = new ArrayList();\n\t\t\t\tfor (int i = 0; i < frag.length; i++)\n\t\t\t\t{\n\t\t\t\t\tif ((frag[i] != null) && (frag[i].getScore() > 0))\n\t\t\t\t\t{\n\t\t\t\t\t\tfragTexts.add(frag[i]);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfrag= (TextFragment[]) fragTexts.toArray(new TextFragment[0]);\t\t\t\t\n\t\t\t}\n\t\t\t\n\t\t\treturn frag;\n\n\t\t}\n\t\tfinally\n\t\t{\n\t\t\tif (tokenStream != null)\n\t\t\t{\n\t\t\t\ttry\n\t\t\t\t{\n\t\t\t\t\ttokenStream.close();\n\t\t\t\t}\n\t\t\t\tcatch (Exception e)\n\t\t\t\t{\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n","sourceOld":"\t/**\n\t * Low level api to get the most relevant (formatted) sections of the document.\n\t * This method has been made public to allow visibility of score information held in TextFragment objects.\n\t * Thanks to Jason Calabrese for help in redefining the interface.  \n\t * @param tokenStream\n\t * @param text\n\t * @param maxNumFragments\n\t * @param mergeContiguousFragments\n\t * @return \n\t * @throws IOException\n\t */\n\tpublic final TextFragment[] getBestTextFragments(\n\t\tTokenStream tokenStream,\t\n\t\tString text,\n\t\tboolean mergeContiguousFragments,\n\t\tint maxNumFragments)\n\t\tthrows IOException\n\t{\n\t\tArrayList docFrags = new ArrayList();\n\t\tStringBuffer newText=new StringBuffer();\n\n\t\tTextFragment currentFrag =\tnew TextFragment(newText,newText.length(), docFrags.size());\n\t\tfragmentScorer.startFragment(currentFrag);\n\t\tdocFrags.add(currentFrag);\n\t\n\t\tFragmentQueue fragQueue = new FragmentQueue(maxNumFragments);\n\n\t\ttry\n\t\t{\n\t\t\torg.apache.lucene.analysis.Token token;\n\t\t\tString tokenText;\n\t\t\tint startOffset;\n\t\t\tint endOffset;\n\t\t\tint lastEndOffset = 0;\n\t\t\ttextFragmenter.start(text);\n\t\t\n\t\t\tTokenGroup tokenGroup=new TokenGroup();\n\n\t\t\twhile ((token = tokenStream.next()) != null)\n\t\t\t{\n\t\t\t\tif((tokenGroup.numTokens>0)&&(tokenGroup.isDistinct(token)))\n\t\t\t\t{\n\t\t\t\t\t//the current token is distinct from previous tokens - \n\t\t\t\t\t// markup the cached token group info\n\t\t\t\t\tstartOffset = tokenGroup.startOffset;\n\t\t\t\t\tendOffset = tokenGroup.endOffset;\t\t\n\t\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\t\tnewText.append(markedUpText);\n\t\t\t\t\tlastEndOffset=endOffset;\n\t\t\t\t\ttokenGroup.clear();\n\n\t\t\t\t\t//check if current token marks the start of a new fragment\t\t\t\t\t\t\n\t\t\t\t\tif(textFragmenter.isNewFragment(token))\n\t\t\t\t\t{\n\t\t\t\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\t\t\t\t\t\t//record stats for a new fragment\n\t\t\t\t\t\tcurrentFrag.textEndPos = newText.length();\n\t\t\t\t\t\tcurrentFrag =new TextFragment(newText, newText.length(), docFrags.size());\n\t\t\t\t\t\tfragmentScorer.startFragment(currentFrag);\n\t\t\t\t\t\tdocFrags.add(currentFrag);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t\t\t\n\t\t\t\ttokenGroup.addToken(token,fragmentScorer.getTokenScore(token));\n\t\t\t\t\n\t\t\t\tif(lastEndOffset>maxDocBytesToAnalyze)\n\t\t\t\t{\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\t\n\t\t\tif(tokenGroup.numTokens>0)\n\t\t\t{\n\t\t\t\t//flush the accumulated text (same code as in above loop)\n\t\t\t\tstartOffset = tokenGroup.startOffset;\n\t\t\t\tendOffset = tokenGroup.endOffset;\t\t\n\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\tnewText.append(markedUpText);\n\t\t\t\tlastEndOffset=endOffset;\t\t\t\t\t\t\n\t\t\t}\n\n\t\t\t// append text after end of last token\n\t\t\tif (lastEndOffset < text.length())\n\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset)));\n\n\t\t\tcurrentFrag.textEndPos = newText.length();\n\n\t\t\t//sort the most relevant sections of the text\n\t\t\tfor (Iterator i = docFrags.iterator(); i.hasNext();)\n\t\t\t{\n\t\t\t\tcurrentFrag = (TextFragment) i.next();\n\n\t\t\t\t//If you are running with a version of Lucene before 11th Sept 03\n\t\t\t\t// you do not have PriorityQueue.insert() - so uncomment the code below\t\t\t\t\t\n\t\t\t\t/*\n\t\t\t\t\t\t\t\t\tif (currentFrag.getScore() >= minScore)\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tfragQueue.put(currentFrag);\n\t\t\t\t\t\t\t\t\t\tif (fragQueue.size() > maxNumFragments)\n\t\t\t\t\t\t\t\t\t\t{ // if hit queue overfull\n\t\t\t\t\t\t\t\t\t\t\tfragQueue.pop(); // remove lowest in hit queue\n\t\t\t\t\t\t\t\t\t\t\tminScore = ((TextFragment) fragQueue.top()).getScore(); // reset minScore\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t*/\n\t\t\t\t//The above code caused a problem as a result of Christoph Goller's 11th Sept 03\n\t\t\t\t//fix to PriorityQueue. The correct method to use here is the new \"insert\" method\n\t\t\t\t// USE ABOVE CODE IF THIS DOES NOT COMPILE!\n\t\t\t\tfragQueue.insert(currentFrag);\n\t\t\t}\n\n\t\t\t//return the most relevant fragments\n\t\t\tTextFragment frag[] = new TextFragment[fragQueue.size()];\n\t\t\tfor (int i = frag.length - 1; i >= 0; i--)\n\t\t\t{\n\t\t\t\tfrag[i] = (TextFragment) fragQueue.pop();\n\t\t\t}\n\t\t\t\n\t\t\t//merge any contiguous fragments to improve readability\n\t\t\tif(mergeContiguousFragments)\n\t\t\t{\n\t\t\t\tmergeContiguousFragments(frag);\n\t\t\t\tArrayList fragTexts = new ArrayList();\n\t\t\t\tfor (int i = 0; i < frag.length; i++)\n\t\t\t\t{\n\t\t\t\t\tif ((frag[i] != null) && (frag[i].getScore() > 0))\n\t\t\t\t\t{\n\t\t\t\t\t\tfragTexts.add(frag[i]);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfrag= (TextFragment[]) fragTexts.toArray(new TextFragment[0]);\t\t\t\t\n\t\t\t}\n\t\t\t\n\t\t\treturn frag;\n\n\t\t}\n\t\tfinally\n\t\t{\n\t\t\tif (tokenStream != null)\n\t\t\t{\n\t\t\t\ttry\n\t\t\t\t{\n\t\t\t\t\ttokenStream.close();\n\t\t\t\t}\n\t\t\t\tcatch (Exception e)\n\t\t\t\t{\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"923b43f6b9130def5724aebbdf0672c17a2d4fd9","date":1115332845,"type":3,"author":"Mark Harwood","isMerge":false,"pathNew":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter#getBestTextFragments(TokenStream,String,boolean,int).mjava","pathOld":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter#getBestTextFragments(TokenStream,String,boolean,int).mjava","sourceNew":"\t/**\n\t * Low level api to get the most relevant (formatted) sections of the document.\n\t * This method has been made public to allow visibility of score information held in TextFragment objects.\n\t * Thanks to Jason Calabrese for help in redefining the interface.  \n\t * @param tokenStream\n\t * @param text\n\t * @param maxNumFragments\n\t * @param mergeContiguousFragments\n\t * @throws IOException\n\t */\n\tpublic final TextFragment[] getBestTextFragments(\n\t\tTokenStream tokenStream,\t\n\t\tString text,\n\t\tboolean mergeContiguousFragments,\n\t\tint maxNumFragments)\n\t\tthrows IOException\n\t{\n\t\tArrayList docFrags = new ArrayList();\n\t\tStringBuffer newText=new StringBuffer();\n\n\t\tTextFragment currentFrag =\tnew TextFragment(newText,newText.length(), docFrags.size());\n\t\tfragmentScorer.startFragment(currentFrag);\n\t\tdocFrags.add(currentFrag);\n\t\n\t\tFragmentQueue fragQueue = new FragmentQueue(maxNumFragments);\n\n\t\ttry\n\t\t{\n\t\t\torg.apache.lucene.analysis.Token token;\n\t\t\tString tokenText;\n\t\t\tint startOffset;\n\t\t\tint endOffset;\n\t\t\tint lastEndOffset = 0;\n\t\t\ttextFragmenter.start(text);\n\t\t\n\t\t\tTokenGroup tokenGroup=new TokenGroup();\n\n\t\t\twhile ((token = tokenStream.next()) != null)\n\t\t\t{\n\t\t\t\tif((tokenGroup.numTokens>0)&&(tokenGroup.isDistinct(token)))\n\t\t\t\t{\n\t\t\t\t\t//the current token is distinct from previous tokens - \n\t\t\t\t\t// markup the cached token group info\n\t\t\t\t\tstartOffset = tokenGroup.startOffset;\n\t\t\t\t\tendOffset = tokenGroup.endOffset;\t\t\n\t\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\t\tnewText.append(markedUpText);\n\t\t\t\t\tlastEndOffset=endOffset;\n\t\t\t\t\ttokenGroup.clear();\n\n\t\t\t\t\t//check if current token marks the start of a new fragment\t\t\t\t\t\t\n\t\t\t\t\tif(textFragmenter.isNewFragment(token))\n\t\t\t\t\t{\n\t\t\t\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\t\t\t\t\t\t//record stats for a new fragment\n\t\t\t\t\t\tcurrentFrag.textEndPos = newText.length();\n\t\t\t\t\t\tcurrentFrag =new TextFragment(newText, newText.length(), docFrags.size());\n\t\t\t\t\t\tfragmentScorer.startFragment(currentFrag);\n\t\t\t\t\t\tdocFrags.add(currentFrag);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t\t\t\n\t\t\t\ttokenGroup.addToken(token,fragmentScorer.getTokenScore(token));\n\t\t\t\t\n\t\t\t\tif(lastEndOffset>maxDocBytesToAnalyze)\n\t\t\t\t{\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\t\n\t\t\tif(tokenGroup.numTokens>0)\n\t\t\t{\n\t\t\t\t//flush the accumulated text (same code as in above loop)\n\t\t\t\tstartOffset = tokenGroup.startOffset;\n\t\t\t\tendOffset = tokenGroup.endOffset;\t\t\n\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\tnewText.append(markedUpText);\n\t\t\t\tlastEndOffset=endOffset;\t\t\t\t\t\t\n\t\t\t}\n\n\t\t\t// append text after end of last token\n//\t\t\tif (lastEndOffset < text.length())\n//\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset)));\n\n\t\t\tcurrentFrag.textEndPos = newText.length();\n\n\t\t\t//sort the most relevant sections of the text\n\t\t\tfor (Iterator i = docFrags.iterator(); i.hasNext();)\n\t\t\t{\n\t\t\t\tcurrentFrag = (TextFragment) i.next();\n\n\t\t\t\t//If you are running with a version of Lucene before 11th Sept 03\n\t\t\t\t// you do not have PriorityQueue.insert() - so uncomment the code below\t\t\t\t\t\n\t\t\t\t/*\n\t\t\t\t\t\t\t\t\tif (currentFrag.getScore() >= minScore)\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tfragQueue.put(currentFrag);\n\t\t\t\t\t\t\t\t\t\tif (fragQueue.size() > maxNumFragments)\n\t\t\t\t\t\t\t\t\t\t{ // if hit queue overfull\n\t\t\t\t\t\t\t\t\t\t\tfragQueue.pop(); // remove lowest in hit queue\n\t\t\t\t\t\t\t\t\t\t\tminScore = ((TextFragment) fragQueue.top()).getScore(); // reset minScore\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t*/\n\t\t\t\t//The above code caused a problem as a result of Christoph Goller's 11th Sept 03\n\t\t\t\t//fix to PriorityQueue. The correct method to use here is the new \"insert\" method\n\t\t\t\t// USE ABOVE CODE IF THIS DOES NOT COMPILE!\n\t\t\t\tfragQueue.insert(currentFrag);\n\t\t\t}\n\n\t\t\t//return the most relevant fragments\n\t\t\tTextFragment frag[] = new TextFragment[fragQueue.size()];\n\t\t\tfor (int i = frag.length - 1; i >= 0; i--)\n\t\t\t{\n\t\t\t\tfrag[i] = (TextFragment) fragQueue.pop();\n\t\t\t}\n\t\t\t\n\t\t\t//merge any contiguous fragments to improve readability\n\t\t\tif(mergeContiguousFragments)\n\t\t\t{\n\t\t\t\tmergeContiguousFragments(frag);\n\t\t\t\tArrayList fragTexts = new ArrayList();\n\t\t\t\tfor (int i = 0; i < frag.length; i++)\n\t\t\t\t{\n\t\t\t\t\tif ((frag[i] != null) && (frag[i].getScore() > 0))\n\t\t\t\t\t{\n\t\t\t\t\t\tfragTexts.add(frag[i]);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfrag= (TextFragment[]) fragTexts.toArray(new TextFragment[0]);\t\t\t\t\n\t\t\t}\n\t\t\t\n\t\t\treturn frag;\n\n\t\t}\n\t\tfinally\n\t\t{\n\t\t\tif (tokenStream != null)\n\t\t\t{\n\t\t\t\ttry\n\t\t\t\t{\n\t\t\t\t\ttokenStream.close();\n\t\t\t\t}\n\t\t\t\tcatch (Exception e)\n\t\t\t\t{\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n","sourceOld":"\t/**\n\t * Low level api to get the most relevant (formatted) sections of the document.\n\t * This method has been made public to allow visibility of score information held in TextFragment objects.\n\t * Thanks to Jason Calabrese for help in redefining the interface.  \n\t * @param tokenStream\n\t * @param text\n\t * @param maxNumFragments\n\t * @param mergeContiguousFragments\n\t * @throws IOException\n\t */\n\tpublic final TextFragment[] getBestTextFragments(\n\t\tTokenStream tokenStream,\t\n\t\tString text,\n\t\tboolean mergeContiguousFragments,\n\t\tint maxNumFragments)\n\t\tthrows IOException\n\t{\n\t\tArrayList docFrags = new ArrayList();\n\t\tStringBuffer newText=new StringBuffer();\n\n\t\tTextFragment currentFrag =\tnew TextFragment(newText,newText.length(), docFrags.size());\n\t\tfragmentScorer.startFragment(currentFrag);\n\t\tdocFrags.add(currentFrag);\n\t\n\t\tFragmentQueue fragQueue = new FragmentQueue(maxNumFragments);\n\n\t\ttry\n\t\t{\n\t\t\torg.apache.lucene.analysis.Token token;\n\t\t\tString tokenText;\n\t\t\tint startOffset;\n\t\t\tint endOffset;\n\t\t\tint lastEndOffset = 0;\n\t\t\ttextFragmenter.start(text);\n\t\t\n\t\t\tTokenGroup tokenGroup=new TokenGroup();\n\n\t\t\twhile ((token = tokenStream.next()) != null)\n\t\t\t{\n\t\t\t\tif((tokenGroup.numTokens>0)&&(tokenGroup.isDistinct(token)))\n\t\t\t\t{\n\t\t\t\t\t//the current token is distinct from previous tokens - \n\t\t\t\t\t// markup the cached token group info\n\t\t\t\t\tstartOffset = tokenGroup.startOffset;\n\t\t\t\t\tendOffset = tokenGroup.endOffset;\t\t\n\t\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\t\tnewText.append(markedUpText);\n\t\t\t\t\tlastEndOffset=endOffset;\n\t\t\t\t\ttokenGroup.clear();\n\n\t\t\t\t\t//check if current token marks the start of a new fragment\t\t\t\t\t\t\n\t\t\t\t\tif(textFragmenter.isNewFragment(token))\n\t\t\t\t\t{\n\t\t\t\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\t\t\t\t\t\t//record stats for a new fragment\n\t\t\t\t\t\tcurrentFrag.textEndPos = newText.length();\n\t\t\t\t\t\tcurrentFrag =new TextFragment(newText, newText.length(), docFrags.size());\n\t\t\t\t\t\tfragmentScorer.startFragment(currentFrag);\n\t\t\t\t\t\tdocFrags.add(currentFrag);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t\t\t\n\t\t\t\ttokenGroup.addToken(token,fragmentScorer.getTokenScore(token));\n\t\t\t\t\n\t\t\t\tif(lastEndOffset>maxDocBytesToAnalyze)\n\t\t\t\t{\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\t\n\t\t\tif(tokenGroup.numTokens>0)\n\t\t\t{\n\t\t\t\t//flush the accumulated text (same code as in above loop)\n\t\t\t\tstartOffset = tokenGroup.startOffset;\n\t\t\t\tendOffset = tokenGroup.endOffset;\t\t\n\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\tnewText.append(markedUpText);\n\t\t\t\tlastEndOffset=endOffset;\t\t\t\t\t\t\n\t\t\t}\n\n\t\t\t// append text after end of last token\n\t\t\tif (lastEndOffset < text.length())\n\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset)));\n\n\t\t\tcurrentFrag.textEndPos = newText.length();\n\n\t\t\t//sort the most relevant sections of the text\n\t\t\tfor (Iterator i = docFrags.iterator(); i.hasNext();)\n\t\t\t{\n\t\t\t\tcurrentFrag = (TextFragment) i.next();\n\n\t\t\t\t//If you are running with a version of Lucene before 11th Sept 03\n\t\t\t\t// you do not have PriorityQueue.insert() - so uncomment the code below\t\t\t\t\t\n\t\t\t\t/*\n\t\t\t\t\t\t\t\t\tif (currentFrag.getScore() >= minScore)\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tfragQueue.put(currentFrag);\n\t\t\t\t\t\t\t\t\t\tif (fragQueue.size() > maxNumFragments)\n\t\t\t\t\t\t\t\t\t\t{ // if hit queue overfull\n\t\t\t\t\t\t\t\t\t\t\tfragQueue.pop(); // remove lowest in hit queue\n\t\t\t\t\t\t\t\t\t\t\tminScore = ((TextFragment) fragQueue.top()).getScore(); // reset minScore\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t*/\n\t\t\t\t//The above code caused a problem as a result of Christoph Goller's 11th Sept 03\n\t\t\t\t//fix to PriorityQueue. The correct method to use here is the new \"insert\" method\n\t\t\t\t// USE ABOVE CODE IF THIS DOES NOT COMPILE!\n\t\t\t\tfragQueue.insert(currentFrag);\n\t\t\t}\n\n\t\t\t//return the most relevant fragments\n\t\t\tTextFragment frag[] = new TextFragment[fragQueue.size()];\n\t\t\tfor (int i = frag.length - 1; i >= 0; i--)\n\t\t\t{\n\t\t\t\tfrag[i] = (TextFragment) fragQueue.pop();\n\t\t\t}\n\t\t\t\n\t\t\t//merge any contiguous fragments to improve readability\n\t\t\tif(mergeContiguousFragments)\n\t\t\t{\n\t\t\t\tmergeContiguousFragments(frag);\n\t\t\t\tArrayList fragTexts = new ArrayList();\n\t\t\t\tfor (int i = 0; i < frag.length; i++)\n\t\t\t\t{\n\t\t\t\t\tif ((frag[i] != null) && (frag[i].getScore() > 0))\n\t\t\t\t\t{\n\t\t\t\t\t\tfragTexts.add(frag[i]);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfrag= (TextFragment[]) fragTexts.toArray(new TextFragment[0]);\t\t\t\t\n\t\t\t}\n\t\t\t\n\t\t\treturn frag;\n\n\t\t}\n\t\tfinally\n\t\t{\n\t\t\tif (tokenStream != null)\n\t\t\t{\n\t\t\t\ttry\n\t\t\t\t{\n\t\t\t\t\ttokenStream.close();\n\t\t\t\t}\n\t\t\t\tcatch (Exception e)\n\t\t\t\t{\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n","bugFix":null,"bugIntro":["9532290bd66e70c1787e80aae9fb0427ce080194"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f504fc2bf24530fd47d0ccafcf776c8c0b9e4c7f","date":1153001991,"type":3,"author":"Mark Harwood","isMerge":false,"pathNew":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter#getBestTextFragments(TokenStream,String,boolean,int).mjava","pathOld":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter#getBestTextFragments(TokenStream,String,boolean,int).mjava","sourceNew":"\t/**\n\t * Low level api to get the most relevant (formatted) sections of the document.\n\t * This method has been made public to allow visibility of score information held in TextFragment objects.\n\t * Thanks to Jason Calabrese for help in redefining the interface.\n\t * @param tokenStream\n\t * @param text\n\t * @param maxNumFragments\n\t * @param mergeContiguousFragments\n\t * @throws IOException\n\t */\n\tpublic final TextFragment[] getBestTextFragments(\n\t\tTokenStream tokenStream,\n\t\tString text,\n\t\tboolean mergeContiguousFragments,\n\t\tint maxNumFragments)\n\t\tthrows IOException\n\t{\n\t\tArrayList docFrags = new ArrayList();\n\t\tStringBuffer newText=new StringBuffer();\n\n\t\tTextFragment currentFrag =\tnew TextFragment(newText,newText.length(), docFrags.size());\n\t\tfragmentScorer.startFragment(currentFrag);\n\t\tdocFrags.add(currentFrag);\n\n\t\tFragmentQueue fragQueue = new FragmentQueue(maxNumFragments);\n\n\t\ttry\n\t\t{\n\t\t\torg.apache.lucene.analysis.Token token;\n\t\t\tString tokenText;\n\t\t\tint startOffset;\n\t\t\tint endOffset;\n\t\t\tint lastEndOffset = 0;\n\t\t\ttextFragmenter.start(text);\n\n\t\t\tTokenGroup tokenGroup=new TokenGroup();\n\n\t\t\twhile ((token = tokenStream.next()) != null)\n\t\t\t{\n\t\t\t\tif((tokenGroup.numTokens>0)&&(tokenGroup.isDistinct(token)))\n\t\t\t\t{\n\t\t\t\t\t//the current token is distinct from previous tokens -\n\t\t\t\t\t// markup the cached token group info\n\t\t\t\t\tstartOffset = tokenGroup.matchStartOffset;\n\t\t\t\t\tendOffset = tokenGroup.matchEndOffset;\n\t\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\t\tnewText.append(markedUpText);\n\t\t\t\t\tlastEndOffset=Math.max(endOffset, lastEndOffset);\n\t\t\t\t\ttokenGroup.clear();\n\n\t\t\t\t\t//check if current token marks the start of a new fragment\n\t\t\t\t\tif(textFragmenter.isNewFragment(token))\n\t\t\t\t\t{\n\t\t\t\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\t\t\t\t\t\t//record stats for a new fragment\n\t\t\t\t\t\tcurrentFrag.textEndPos = newText.length();\n\t\t\t\t\t\tcurrentFrag =new TextFragment(newText, newText.length(), docFrags.size());\n\t\t\t\t\t\tfragmentScorer.startFragment(currentFrag);\n\t\t\t\t\t\tdocFrags.add(currentFrag);\n\t\t\t\t\t}\n\t\t\t\t}\n\n        tokenGroup.addToken(token,fragmentScorer.getTokenScore(token));\n\n\t\t\t\tif(lastEndOffset>maxDocBytesToAnalyze)\n\t\t\t\t{\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\n\t\t\tif(tokenGroup.numTokens>0)\n\t\t\t{\n\t\t\t\t//flush the accumulated text (same code as in above loop)\n\t\t\t\tstartOffset = tokenGroup.matchStartOffset;\n\t\t\t\tendOffset = tokenGroup.matchEndOffset;\n\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\tnewText.append(markedUpText);\n\t\t\t\tlastEndOffset=Math.max(lastEndOffset,endOffset);\n\t\t\t}\n\n\t\t\t// append text after end of last token\n//\t\t\tif (lastEndOffset < text.length())\n//\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset)));\n\n\t\t\tcurrentFrag.textEndPos = newText.length();\n\n\t\t\t//sort the most relevant sections of the text\n\t\t\tfor (Iterator i = docFrags.iterator(); i.hasNext();)\n\t\t\t{\n\t\t\t\tcurrentFrag = (TextFragment) i.next();\n\n\t\t\t\t//If you are running with a version of Lucene before 11th Sept 03\n\t\t\t\t// you do not have PriorityQueue.insert() - so uncomment the code below\n\t\t\t\t/*\n\t\t\t\t\t\t\t\t\tif (currentFrag.getScore() >= minScore)\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tfragQueue.put(currentFrag);\n\t\t\t\t\t\t\t\t\t\tif (fragQueue.size() > maxNumFragments)\n\t\t\t\t\t\t\t\t\t\t{ // if hit queue overfull\n\t\t\t\t\t\t\t\t\t\t\tfragQueue.pop(); // remove lowest in hit queue\n\t\t\t\t\t\t\t\t\t\t\tminScore = ((TextFragment) fragQueue.top()).getScore(); // reset minScore\n\t\t\t\t\t\t\t\t\t\t}\n\n\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t*/\n\t\t\t\t//The above code caused a problem as a result of Christoph Goller's 11th Sept 03\n\t\t\t\t//fix to PriorityQueue. The correct method to use here is the new \"insert\" method\n\t\t\t\t// USE ABOVE CODE IF THIS DOES NOT COMPILE!\n\t\t\t\tfragQueue.insert(currentFrag);\n\t\t\t}\n\n\t\t\t//return the most relevant fragments\n\t\t\tTextFragment frag[] = new TextFragment[fragQueue.size()];\n\t\t\tfor (int i = frag.length - 1; i >= 0; i--)\n\t\t\t{\n\t\t\t\tfrag[i] = (TextFragment) fragQueue.pop();\n\t\t\t}\n\n\t\t\t//merge any contiguous fragments to improve readability\n\t\t\tif(mergeContiguousFragments)\n\t\t\t{\n\t\t\t\tmergeContiguousFragments(frag);\n\t\t\t\tArrayList fragTexts = new ArrayList();\n\t\t\t\tfor (int i = 0; i < frag.length; i++)\n\t\t\t\t{\n\t\t\t\t\tif ((frag[i] != null) && (frag[i].getScore() > 0))\n\t\t\t\t\t{\n\t\t\t\t\t\tfragTexts.add(frag[i]);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfrag= (TextFragment[]) fragTexts.toArray(new TextFragment[0]);\n\t\t\t}\n\n\t\t\treturn frag;\n\n\t\t}\n\t\tfinally\n\t\t{\n\t\t\tif (tokenStream != null)\n\t\t\t{\n\t\t\t\ttry\n\t\t\t\t{\n\t\t\t\t\ttokenStream.close();\n\t\t\t\t}\n\t\t\t\tcatch (Exception e)\n\t\t\t\t{\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n","sourceOld":"\t/**\n\t * Low level api to get the most relevant (formatted) sections of the document.\n\t * This method has been made public to allow visibility of score information held in TextFragment objects.\n\t * Thanks to Jason Calabrese for help in redefining the interface.  \n\t * @param tokenStream\n\t * @param text\n\t * @param maxNumFragments\n\t * @param mergeContiguousFragments\n\t * @throws IOException\n\t */\n\tpublic final TextFragment[] getBestTextFragments(\n\t\tTokenStream tokenStream,\t\n\t\tString text,\n\t\tboolean mergeContiguousFragments,\n\t\tint maxNumFragments)\n\t\tthrows IOException\n\t{\n\t\tArrayList docFrags = new ArrayList();\n\t\tStringBuffer newText=new StringBuffer();\n\n\t\tTextFragment currentFrag =\tnew TextFragment(newText,newText.length(), docFrags.size());\n\t\tfragmentScorer.startFragment(currentFrag);\n\t\tdocFrags.add(currentFrag);\n\t\n\t\tFragmentQueue fragQueue = new FragmentQueue(maxNumFragments);\n\n\t\ttry\n\t\t{\n\t\t\torg.apache.lucene.analysis.Token token;\n\t\t\tString tokenText;\n\t\t\tint startOffset;\n\t\t\tint endOffset;\n\t\t\tint lastEndOffset = 0;\n\t\t\ttextFragmenter.start(text);\n\t\t\n\t\t\tTokenGroup tokenGroup=new TokenGroup();\n\n\t\t\twhile ((token = tokenStream.next()) != null)\n\t\t\t{\n\t\t\t\tif((tokenGroup.numTokens>0)&&(tokenGroup.isDistinct(token)))\n\t\t\t\t{\n\t\t\t\t\t//the current token is distinct from previous tokens - \n\t\t\t\t\t// markup the cached token group info\n\t\t\t\t\tstartOffset = tokenGroup.startOffset;\n\t\t\t\t\tendOffset = tokenGroup.endOffset;\t\t\n\t\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\t\tnewText.append(markedUpText);\n\t\t\t\t\tlastEndOffset=endOffset;\n\t\t\t\t\ttokenGroup.clear();\n\n\t\t\t\t\t//check if current token marks the start of a new fragment\t\t\t\t\t\t\n\t\t\t\t\tif(textFragmenter.isNewFragment(token))\n\t\t\t\t\t{\n\t\t\t\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\t\t\t\t\t\t//record stats for a new fragment\n\t\t\t\t\t\tcurrentFrag.textEndPos = newText.length();\n\t\t\t\t\t\tcurrentFrag =new TextFragment(newText, newText.length(), docFrags.size());\n\t\t\t\t\t\tfragmentScorer.startFragment(currentFrag);\n\t\t\t\t\t\tdocFrags.add(currentFrag);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t\t\t\n\t\t\t\ttokenGroup.addToken(token,fragmentScorer.getTokenScore(token));\n\t\t\t\t\n\t\t\t\tif(lastEndOffset>maxDocBytesToAnalyze)\n\t\t\t\t{\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\t\n\t\t\tif(tokenGroup.numTokens>0)\n\t\t\t{\n\t\t\t\t//flush the accumulated text (same code as in above loop)\n\t\t\t\tstartOffset = tokenGroup.startOffset;\n\t\t\t\tendOffset = tokenGroup.endOffset;\t\t\n\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\tnewText.append(markedUpText);\n\t\t\t\tlastEndOffset=endOffset;\t\t\t\t\t\t\n\t\t\t}\n\n\t\t\t// append text after end of last token\n//\t\t\tif (lastEndOffset < text.length())\n//\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset)));\n\n\t\t\tcurrentFrag.textEndPos = newText.length();\n\n\t\t\t//sort the most relevant sections of the text\n\t\t\tfor (Iterator i = docFrags.iterator(); i.hasNext();)\n\t\t\t{\n\t\t\t\tcurrentFrag = (TextFragment) i.next();\n\n\t\t\t\t//If you are running with a version of Lucene before 11th Sept 03\n\t\t\t\t// you do not have PriorityQueue.insert() - so uncomment the code below\t\t\t\t\t\n\t\t\t\t/*\n\t\t\t\t\t\t\t\t\tif (currentFrag.getScore() >= minScore)\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tfragQueue.put(currentFrag);\n\t\t\t\t\t\t\t\t\t\tif (fragQueue.size() > maxNumFragments)\n\t\t\t\t\t\t\t\t\t\t{ // if hit queue overfull\n\t\t\t\t\t\t\t\t\t\t\tfragQueue.pop(); // remove lowest in hit queue\n\t\t\t\t\t\t\t\t\t\t\tminScore = ((TextFragment) fragQueue.top()).getScore(); // reset minScore\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t*/\n\t\t\t\t//The above code caused a problem as a result of Christoph Goller's 11th Sept 03\n\t\t\t\t//fix to PriorityQueue. The correct method to use here is the new \"insert\" method\n\t\t\t\t// USE ABOVE CODE IF THIS DOES NOT COMPILE!\n\t\t\t\tfragQueue.insert(currentFrag);\n\t\t\t}\n\n\t\t\t//return the most relevant fragments\n\t\t\tTextFragment frag[] = new TextFragment[fragQueue.size()];\n\t\t\tfor (int i = frag.length - 1; i >= 0; i--)\n\t\t\t{\n\t\t\t\tfrag[i] = (TextFragment) fragQueue.pop();\n\t\t\t}\n\t\t\t\n\t\t\t//merge any contiguous fragments to improve readability\n\t\t\tif(mergeContiguousFragments)\n\t\t\t{\n\t\t\t\tmergeContiguousFragments(frag);\n\t\t\t\tArrayList fragTexts = new ArrayList();\n\t\t\t\tfor (int i = 0; i < frag.length; i++)\n\t\t\t\t{\n\t\t\t\t\tif ((frag[i] != null) && (frag[i].getScore() > 0))\n\t\t\t\t\t{\n\t\t\t\t\t\tfragTexts.add(frag[i]);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfrag= (TextFragment[]) fragTexts.toArray(new TextFragment[0]);\t\t\t\t\n\t\t\t}\n\t\t\t\n\t\t\treturn frag;\n\n\t\t}\n\t\tfinally\n\t\t{\n\t\t\tif (tokenStream != null)\n\t\t\t{\n\t\t\t\ttry\n\t\t\t\t{\n\t\t\t\t\ttokenStream.close();\n\t\t\t\t}\n\t\t\t\tcatch (Exception e)\n\t\t\t\t{\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n","bugFix":null,"bugIntro":["9532290bd66e70c1787e80aae9fb0427ce080194"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9532290bd66e70c1787e80aae9fb0427ce080194","date":1155764538,"type":3,"author":"Mark Harwood","isMerge":false,"pathNew":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter#getBestTextFragments(TokenStream,String,boolean,int).mjava","pathOld":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter#getBestTextFragments(TokenStream,String,boolean,int).mjava","sourceNew":"\t/**\n\t * Low level api to get the most relevant (formatted) sections of the document.\n\t * This method has been made public to allow visibility of score information held in TextFragment objects.\n\t * Thanks to Jason Calabrese for help in redefining the interface.\n\t * @param tokenStream\n\t * @param text\n\t * @param maxNumFragments\n\t * @param mergeContiguousFragments\n\t * @throws IOException\n\t */\n\tpublic final TextFragment[] getBestTextFragments(\n\t\tTokenStream tokenStream,\n\t\tString text,\n\t\tboolean mergeContiguousFragments,\n\t\tint maxNumFragments)\n\t\tthrows IOException\n\t{\n\t\tArrayList docFrags = new ArrayList();\n\t\tStringBuffer newText=new StringBuffer();\n\n\t\tTextFragment currentFrag =\tnew TextFragment(newText,newText.length(), docFrags.size());\n\t\tfragmentScorer.startFragment(currentFrag);\n\t\tdocFrags.add(currentFrag);\n\n\t\tFragmentQueue fragQueue = new FragmentQueue(maxNumFragments);\n\n\t\ttry\n\t\t{\n\t\t\torg.apache.lucene.analysis.Token token;\n\t\t\tString tokenText;\n\t\t\tint startOffset;\n\t\t\tint endOffset;\n\t\t\tint lastEndOffset = 0;\n\t\t\ttextFragmenter.start(text);\n\n\t\t\tTokenGroup tokenGroup=new TokenGroup();\n\t\t\ttoken = tokenStream.next();\n\t\t\twhile ((token!= null)&&(token.startOffset()<maxDocBytesToAnalyze))\n\t\t\t{\n\t\t\t\tif((tokenGroup.numTokens>0)&&(tokenGroup.isDistinct(token)))\n\t\t\t\t{\n\t\t\t\t\t//the current token is distinct from previous tokens -\n\t\t\t\t\t// markup the cached token group info\n\t\t\t\t\tstartOffset = tokenGroup.matchStartOffset;\n\t\t\t\t\tendOffset = tokenGroup.matchEndOffset;\n\t\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\t\tnewText.append(markedUpText);\n\t\t\t\t\tlastEndOffset=Math.max(endOffset, lastEndOffset);\n\t\t\t\t\ttokenGroup.clear();\n\n\t\t\t\t\t//check if current token marks the start of a new fragment\n\t\t\t\t\tif(textFragmenter.isNewFragment(token))\n\t\t\t\t\t{\n\t\t\t\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\t\t\t\t\t\t//record stats for a new fragment\n\t\t\t\t\t\tcurrentFrag.textEndPos = newText.length();\n\t\t\t\t\t\tcurrentFrag =new TextFragment(newText, newText.length(), docFrags.size());\n\t\t\t\t\t\tfragmentScorer.startFragment(currentFrag);\n\t\t\t\t\t\tdocFrags.add(currentFrag);\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\ttokenGroup.addToken(token,fragmentScorer.getTokenScore(token));\n\n//\t\t\t\tif(lastEndOffset>maxDocBytesToAnalyze)\n//\t\t\t\t{\n//\t\t\t\t\tbreak;\n//\t\t\t\t}\n\t\t\t\ttoken = tokenStream.next();\n\t\t\t}\n\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\n\t\t\tif(tokenGroup.numTokens>0)\n\t\t\t{\n\t\t\t\t//flush the accumulated text (same code as in above loop)\n\t\t\t\tstartOffset = tokenGroup.matchStartOffset;\n\t\t\t\tendOffset = tokenGroup.matchEndOffset;\n\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\tnewText.append(markedUpText);\n\t\t\t\tlastEndOffset=Math.max(lastEndOffset,endOffset);\n\t\t\t}\n\n\t\t\t//Test what remains of the original text beyond the point where we stopped analyzing \n\t\t\tif (\n//\t\t\t\t\tif there is text beyond the last token considered..\n\t\t\t\t\t(lastEndOffset < text.length()) \n\t\t\t\t\t&&\n//\t\t\t\t\tand that text is not too large...\n\t\t\t\t\t(text.length()<maxDocBytesToAnalyze)\n\t\t\t\t)\t\t\t\t\n\t\t\t{\n\t\t\t\t//append it to the last fragment\n\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset)));\n\t\t\t}\n\n\t\t\tcurrentFrag.textEndPos = newText.length();\n\n\t\t\t//sort the most relevant sections of the text\n\t\t\tfor (Iterator i = docFrags.iterator(); i.hasNext();)\n\t\t\t{\n\t\t\t\tcurrentFrag = (TextFragment) i.next();\n\n\t\t\t\t//If you are running with a version of Lucene before 11th Sept 03\n\t\t\t\t// you do not have PriorityQueue.insert() - so uncomment the code below\n\t\t\t\t/*\n\t\t\t\t\t\t\t\t\tif (currentFrag.getScore() >= minScore)\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tfragQueue.put(currentFrag);\n\t\t\t\t\t\t\t\t\t\tif (fragQueue.size() > maxNumFragments)\n\t\t\t\t\t\t\t\t\t\t{ // if hit queue overfull\n\t\t\t\t\t\t\t\t\t\t\tfragQueue.pop(); // remove lowest in hit queue\n\t\t\t\t\t\t\t\t\t\t\tminScore = ((TextFragment) fragQueue.top()).getScore(); // reset minScore\n\t\t\t\t\t\t\t\t\t\t}\n\n\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t*/\n\t\t\t\t//The above code caused a problem as a result of Christoph Goller's 11th Sept 03\n\t\t\t\t//fix to PriorityQueue. The correct method to use here is the new \"insert\" method\n\t\t\t\t// USE ABOVE CODE IF THIS DOES NOT COMPILE!\n\t\t\t\tfragQueue.insert(currentFrag);\n\t\t\t}\n\n\t\t\t//return the most relevant fragments\n\t\t\tTextFragment frag[] = new TextFragment[fragQueue.size()];\n\t\t\tfor (int i = frag.length - 1; i >= 0; i--)\n\t\t\t{\n\t\t\t\tfrag[i] = (TextFragment) fragQueue.pop();\n\t\t\t}\n\n\t\t\t//merge any contiguous fragments to improve readability\n\t\t\tif(mergeContiguousFragments)\n\t\t\t{\n\t\t\t\tmergeContiguousFragments(frag);\n\t\t\t\tArrayList fragTexts = new ArrayList();\n\t\t\t\tfor (int i = 0; i < frag.length; i++)\n\t\t\t\t{\n\t\t\t\t\tif ((frag[i] != null) && (frag[i].getScore() > 0))\n\t\t\t\t\t{\n\t\t\t\t\t\tfragTexts.add(frag[i]);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfrag= (TextFragment[]) fragTexts.toArray(new TextFragment[0]);\n\t\t\t}\n\n\t\t\treturn frag;\n\n\t\t}\n\t\tfinally\n\t\t{\n\t\t\tif (tokenStream != null)\n\t\t\t{\n\t\t\t\ttry\n\t\t\t\t{\n\t\t\t\t\ttokenStream.close();\n\t\t\t\t}\n\t\t\t\tcatch (Exception e)\n\t\t\t\t{\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n","sourceOld":"\t/**\n\t * Low level api to get the most relevant (formatted) sections of the document.\n\t * This method has been made public to allow visibility of score information held in TextFragment objects.\n\t * Thanks to Jason Calabrese for help in redefining the interface.\n\t * @param tokenStream\n\t * @param text\n\t * @param maxNumFragments\n\t * @param mergeContiguousFragments\n\t * @throws IOException\n\t */\n\tpublic final TextFragment[] getBestTextFragments(\n\t\tTokenStream tokenStream,\n\t\tString text,\n\t\tboolean mergeContiguousFragments,\n\t\tint maxNumFragments)\n\t\tthrows IOException\n\t{\n\t\tArrayList docFrags = new ArrayList();\n\t\tStringBuffer newText=new StringBuffer();\n\n\t\tTextFragment currentFrag =\tnew TextFragment(newText,newText.length(), docFrags.size());\n\t\tfragmentScorer.startFragment(currentFrag);\n\t\tdocFrags.add(currentFrag);\n\n\t\tFragmentQueue fragQueue = new FragmentQueue(maxNumFragments);\n\n\t\ttry\n\t\t{\n\t\t\torg.apache.lucene.analysis.Token token;\n\t\t\tString tokenText;\n\t\t\tint startOffset;\n\t\t\tint endOffset;\n\t\t\tint lastEndOffset = 0;\n\t\t\ttextFragmenter.start(text);\n\n\t\t\tTokenGroup tokenGroup=new TokenGroup();\n\n\t\t\twhile ((token = tokenStream.next()) != null)\n\t\t\t{\n\t\t\t\tif((tokenGroup.numTokens>0)&&(tokenGroup.isDistinct(token)))\n\t\t\t\t{\n\t\t\t\t\t//the current token is distinct from previous tokens -\n\t\t\t\t\t// markup the cached token group info\n\t\t\t\t\tstartOffset = tokenGroup.matchStartOffset;\n\t\t\t\t\tendOffset = tokenGroup.matchEndOffset;\n\t\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\t\tnewText.append(markedUpText);\n\t\t\t\t\tlastEndOffset=Math.max(endOffset, lastEndOffset);\n\t\t\t\t\ttokenGroup.clear();\n\n\t\t\t\t\t//check if current token marks the start of a new fragment\n\t\t\t\t\tif(textFragmenter.isNewFragment(token))\n\t\t\t\t\t{\n\t\t\t\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\t\t\t\t\t\t//record stats for a new fragment\n\t\t\t\t\t\tcurrentFrag.textEndPos = newText.length();\n\t\t\t\t\t\tcurrentFrag =new TextFragment(newText, newText.length(), docFrags.size());\n\t\t\t\t\t\tfragmentScorer.startFragment(currentFrag);\n\t\t\t\t\t\tdocFrags.add(currentFrag);\n\t\t\t\t\t}\n\t\t\t\t}\n\n        tokenGroup.addToken(token,fragmentScorer.getTokenScore(token));\n\n\t\t\t\tif(lastEndOffset>maxDocBytesToAnalyze)\n\t\t\t\t{\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\n\t\t\tif(tokenGroup.numTokens>0)\n\t\t\t{\n\t\t\t\t//flush the accumulated text (same code as in above loop)\n\t\t\t\tstartOffset = tokenGroup.matchStartOffset;\n\t\t\t\tendOffset = tokenGroup.matchEndOffset;\n\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\tnewText.append(markedUpText);\n\t\t\t\tlastEndOffset=Math.max(lastEndOffset,endOffset);\n\t\t\t}\n\n\t\t\t// append text after end of last token\n//\t\t\tif (lastEndOffset < text.length())\n//\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset)));\n\n\t\t\tcurrentFrag.textEndPos = newText.length();\n\n\t\t\t//sort the most relevant sections of the text\n\t\t\tfor (Iterator i = docFrags.iterator(); i.hasNext();)\n\t\t\t{\n\t\t\t\tcurrentFrag = (TextFragment) i.next();\n\n\t\t\t\t//If you are running with a version of Lucene before 11th Sept 03\n\t\t\t\t// you do not have PriorityQueue.insert() - so uncomment the code below\n\t\t\t\t/*\n\t\t\t\t\t\t\t\t\tif (currentFrag.getScore() >= minScore)\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tfragQueue.put(currentFrag);\n\t\t\t\t\t\t\t\t\t\tif (fragQueue.size() > maxNumFragments)\n\t\t\t\t\t\t\t\t\t\t{ // if hit queue overfull\n\t\t\t\t\t\t\t\t\t\t\tfragQueue.pop(); // remove lowest in hit queue\n\t\t\t\t\t\t\t\t\t\t\tminScore = ((TextFragment) fragQueue.top()).getScore(); // reset minScore\n\t\t\t\t\t\t\t\t\t\t}\n\n\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t*/\n\t\t\t\t//The above code caused a problem as a result of Christoph Goller's 11th Sept 03\n\t\t\t\t//fix to PriorityQueue. The correct method to use here is the new \"insert\" method\n\t\t\t\t// USE ABOVE CODE IF THIS DOES NOT COMPILE!\n\t\t\t\tfragQueue.insert(currentFrag);\n\t\t\t}\n\n\t\t\t//return the most relevant fragments\n\t\t\tTextFragment frag[] = new TextFragment[fragQueue.size()];\n\t\t\tfor (int i = frag.length - 1; i >= 0; i--)\n\t\t\t{\n\t\t\t\tfrag[i] = (TextFragment) fragQueue.pop();\n\t\t\t}\n\n\t\t\t//merge any contiguous fragments to improve readability\n\t\t\tif(mergeContiguousFragments)\n\t\t\t{\n\t\t\t\tmergeContiguousFragments(frag);\n\t\t\t\tArrayList fragTexts = new ArrayList();\n\t\t\t\tfor (int i = 0; i < frag.length; i++)\n\t\t\t\t{\n\t\t\t\t\tif ((frag[i] != null) && (frag[i].getScore() > 0))\n\t\t\t\t\t{\n\t\t\t\t\t\tfragTexts.add(frag[i]);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfrag= (TextFragment[]) fragTexts.toArray(new TextFragment[0]);\n\t\t\t}\n\n\t\t\treturn frag;\n\n\t\t}\n\t\tfinally\n\t\t{\n\t\t\tif (tokenStream != null)\n\t\t\t{\n\t\t\t\ttry\n\t\t\t\t{\n\t\t\t\t\ttokenStream.close();\n\t\t\t\t}\n\t\t\t\tcatch (Exception e)\n\t\t\t\t{\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n","bugFix":["f504fc2bf24530fd47d0ccafcf776c8c0b9e4c7f","db2e1c87dfa9ca908febe5b39f6dd3dee2fbe9e2","923b43f6b9130def5724aebbdf0672c17a2d4fd9"],"bugIntro":["a710e1326e4ffd9966ad8e37ba4e5f720778c5d9"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a710e1326e4ffd9966ad8e37ba4e5f720778c5d9","date":1201613713,"type":3,"author":"Grant Ingersoll","isMerge":false,"pathNew":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter#getBestTextFragments(TokenStream,String,boolean,int).mjava","pathOld":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter#getBestTextFragments(TokenStream,String,boolean,int).mjava","sourceNew":"\t/**\n\t * Low level api to get the most relevant (formatted) sections of the document.\n\t * This method has been made public to allow visibility of score information held in TextFragment objects.\n\t * Thanks to Jason Calabrese for help in redefining the interface.\n\t * @param tokenStream\n\t * @param text\n\t * @param maxNumFragments\n\t * @param mergeContiguousFragments\n\t * @throws IOException\n\t */\n\tpublic final TextFragment[] getBestTextFragments(\n\t\tTokenStream tokenStream,\n\t\tString text,\n\t\tboolean mergeContiguousFragments,\n\t\tint maxNumFragments)\n\t\tthrows IOException\n\t{\n\t\tArrayList docFrags = new ArrayList();\n\t\tStringBuffer newText=new StringBuffer();\n\n\t\tTextFragment currentFrag =\tnew TextFragment(newText,newText.length(), docFrags.size());\n\t\tfragmentScorer.startFragment(currentFrag);\n\t\tdocFrags.add(currentFrag);\n\n\t\tFragmentQueue fragQueue = new FragmentQueue(maxNumFragments);\n\n\t\ttry\n\t\t{\n\t\t\torg.apache.lucene.analysis.Token token;\n\t\t\tString tokenText;\n\t\t\tint startOffset;\n\t\t\tint endOffset;\n\t\t\tint lastEndOffset = 0;\n\t\t\ttextFragmenter.start(text);\n\n\t\t\tTokenGroup tokenGroup=new TokenGroup();\n\t\t\ttoken = tokenStream.next();\n\t\t\twhile ((token!= null)&&(token.startOffset()< maxDocCharsToAnalyze))\n\t\t\t{\n\t\t\t\tif((tokenGroup.numTokens>0)&&(tokenGroup.isDistinct(token)))\n\t\t\t\t{\n\t\t\t\t\t//the current token is distinct from previous tokens -\n\t\t\t\t\t// markup the cached token group info\n\t\t\t\t\tstartOffset = tokenGroup.matchStartOffset;\n\t\t\t\t\tendOffset = tokenGroup.matchEndOffset;\n\t\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\t\tnewText.append(markedUpText);\n\t\t\t\t\tlastEndOffset=Math.max(endOffset, lastEndOffset);\n\t\t\t\t\ttokenGroup.clear();\n\n\t\t\t\t\t//check if current token marks the start of a new fragment\n\t\t\t\t\tif(textFragmenter.isNewFragment(token))\n\t\t\t\t\t{\n\t\t\t\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\t\t\t\t\t\t//record stats for a new fragment\n\t\t\t\t\t\tcurrentFrag.textEndPos = newText.length();\n\t\t\t\t\t\tcurrentFrag =new TextFragment(newText, newText.length(), docFrags.size());\n\t\t\t\t\t\tfragmentScorer.startFragment(currentFrag);\n\t\t\t\t\t\tdocFrags.add(currentFrag);\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\ttokenGroup.addToken(token,fragmentScorer.getTokenScore(token));\n\n//\t\t\t\tif(lastEndOffset>maxDocBytesToAnalyze)\n//\t\t\t\t{\n//\t\t\t\t\tbreak;\n//\t\t\t\t}\n\t\t\t\ttoken = tokenStream.next();\n\t\t\t}\n\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\n\t\t\tif(tokenGroup.numTokens>0)\n\t\t\t{\n\t\t\t\t//flush the accumulated text (same code as in above loop)\n\t\t\t\tstartOffset = tokenGroup.matchStartOffset;\n\t\t\t\tendOffset = tokenGroup.matchEndOffset;\n\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\tnewText.append(markedUpText);\n\t\t\t\tlastEndOffset=Math.max(lastEndOffset,endOffset);\n\t\t\t}\n\n\t\t\t//Test what remains of the original text beyond the point where we stopped analyzing \n\t\t\tif (\n//\t\t\t\t\tif there is text beyond the last token considered..\n\t\t\t\t\t(lastEndOffset < text.length()) \n\t\t\t\t\t&&\n//\t\t\t\t\tand that text is not too large...\n\t\t\t\t\t(text.length()< maxDocCharsToAnalyze)\n\t\t\t\t)\t\t\t\t\n\t\t\t{\n\t\t\t\t//append it to the last fragment\n\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset)));\n\t\t\t}\n\n\t\t\tcurrentFrag.textEndPos = newText.length();\n\n\t\t\t//sort the most relevant sections of the text\n\t\t\tfor (Iterator i = docFrags.iterator(); i.hasNext();)\n\t\t\t{\n\t\t\t\tcurrentFrag = (TextFragment) i.next();\n\n\t\t\t\t//If you are running with a version of Lucene before 11th Sept 03\n\t\t\t\t// you do not have PriorityQueue.insert() - so uncomment the code below\n\t\t\t\t/*\n\t\t\t\t\t\t\t\t\tif (currentFrag.getScore() >= minScore)\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tfragQueue.put(currentFrag);\n\t\t\t\t\t\t\t\t\t\tif (fragQueue.size() > maxNumFragments)\n\t\t\t\t\t\t\t\t\t\t{ // if hit queue overfull\n\t\t\t\t\t\t\t\t\t\t\tfragQueue.pop(); // remove lowest in hit queue\n\t\t\t\t\t\t\t\t\t\t\tminScore = ((TextFragment) fragQueue.top()).getScore(); // reset minScore\n\t\t\t\t\t\t\t\t\t\t}\n\n\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t*/\n\t\t\t\t//The above code caused a problem as a result of Christoph Goller's 11th Sept 03\n\t\t\t\t//fix to PriorityQueue. The correct method to use here is the new \"insert\" method\n\t\t\t\t// USE ABOVE CODE IF THIS DOES NOT COMPILE!\n\t\t\t\tfragQueue.insert(currentFrag);\n\t\t\t}\n\n\t\t\t//return the most relevant fragments\n\t\t\tTextFragment frag[] = new TextFragment[fragQueue.size()];\n\t\t\tfor (int i = frag.length - 1; i >= 0; i--)\n\t\t\t{\n\t\t\t\tfrag[i] = (TextFragment) fragQueue.pop();\n\t\t\t}\n\n\t\t\t//merge any contiguous fragments to improve readability\n\t\t\tif(mergeContiguousFragments)\n\t\t\t{\n\t\t\t\tmergeContiguousFragments(frag);\n\t\t\t\tArrayList fragTexts = new ArrayList();\n\t\t\t\tfor (int i = 0; i < frag.length; i++)\n\t\t\t\t{\n\t\t\t\t\tif ((frag[i] != null) && (frag[i].getScore() > 0))\n\t\t\t\t\t{\n\t\t\t\t\t\tfragTexts.add(frag[i]);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfrag= (TextFragment[]) fragTexts.toArray(new TextFragment[0]);\n\t\t\t}\n\n\t\t\treturn frag;\n\n\t\t}\n\t\tfinally\n\t\t{\n\t\t\tif (tokenStream != null)\n\t\t\t{\n\t\t\t\ttry\n\t\t\t\t{\n\t\t\t\t\ttokenStream.close();\n\t\t\t\t}\n\t\t\t\tcatch (Exception e)\n\t\t\t\t{\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n","sourceOld":"\t/**\n\t * Low level api to get the most relevant (formatted) sections of the document.\n\t * This method has been made public to allow visibility of score information held in TextFragment objects.\n\t * Thanks to Jason Calabrese for help in redefining the interface.\n\t * @param tokenStream\n\t * @param text\n\t * @param maxNumFragments\n\t * @param mergeContiguousFragments\n\t * @throws IOException\n\t */\n\tpublic final TextFragment[] getBestTextFragments(\n\t\tTokenStream tokenStream,\n\t\tString text,\n\t\tboolean mergeContiguousFragments,\n\t\tint maxNumFragments)\n\t\tthrows IOException\n\t{\n\t\tArrayList docFrags = new ArrayList();\n\t\tStringBuffer newText=new StringBuffer();\n\n\t\tTextFragment currentFrag =\tnew TextFragment(newText,newText.length(), docFrags.size());\n\t\tfragmentScorer.startFragment(currentFrag);\n\t\tdocFrags.add(currentFrag);\n\n\t\tFragmentQueue fragQueue = new FragmentQueue(maxNumFragments);\n\n\t\ttry\n\t\t{\n\t\t\torg.apache.lucene.analysis.Token token;\n\t\t\tString tokenText;\n\t\t\tint startOffset;\n\t\t\tint endOffset;\n\t\t\tint lastEndOffset = 0;\n\t\t\ttextFragmenter.start(text);\n\n\t\t\tTokenGroup tokenGroup=new TokenGroup();\n\t\t\ttoken = tokenStream.next();\n\t\t\twhile ((token!= null)&&(token.startOffset()<maxDocBytesToAnalyze))\n\t\t\t{\n\t\t\t\tif((tokenGroup.numTokens>0)&&(tokenGroup.isDistinct(token)))\n\t\t\t\t{\n\t\t\t\t\t//the current token is distinct from previous tokens -\n\t\t\t\t\t// markup the cached token group info\n\t\t\t\t\tstartOffset = tokenGroup.matchStartOffset;\n\t\t\t\t\tendOffset = tokenGroup.matchEndOffset;\n\t\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\t\tnewText.append(markedUpText);\n\t\t\t\t\tlastEndOffset=Math.max(endOffset, lastEndOffset);\n\t\t\t\t\ttokenGroup.clear();\n\n\t\t\t\t\t//check if current token marks the start of a new fragment\n\t\t\t\t\tif(textFragmenter.isNewFragment(token))\n\t\t\t\t\t{\n\t\t\t\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\t\t\t\t\t\t//record stats for a new fragment\n\t\t\t\t\t\tcurrentFrag.textEndPos = newText.length();\n\t\t\t\t\t\tcurrentFrag =new TextFragment(newText, newText.length(), docFrags.size());\n\t\t\t\t\t\tfragmentScorer.startFragment(currentFrag);\n\t\t\t\t\t\tdocFrags.add(currentFrag);\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\ttokenGroup.addToken(token,fragmentScorer.getTokenScore(token));\n\n//\t\t\t\tif(lastEndOffset>maxDocBytesToAnalyze)\n//\t\t\t\t{\n//\t\t\t\t\tbreak;\n//\t\t\t\t}\n\t\t\t\ttoken = tokenStream.next();\n\t\t\t}\n\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\n\t\t\tif(tokenGroup.numTokens>0)\n\t\t\t{\n\t\t\t\t//flush the accumulated text (same code as in above loop)\n\t\t\t\tstartOffset = tokenGroup.matchStartOffset;\n\t\t\t\tendOffset = tokenGroup.matchEndOffset;\n\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\tnewText.append(markedUpText);\n\t\t\t\tlastEndOffset=Math.max(lastEndOffset,endOffset);\n\t\t\t}\n\n\t\t\t//Test what remains of the original text beyond the point where we stopped analyzing \n\t\t\tif (\n//\t\t\t\t\tif there is text beyond the last token considered..\n\t\t\t\t\t(lastEndOffset < text.length()) \n\t\t\t\t\t&&\n//\t\t\t\t\tand that text is not too large...\n\t\t\t\t\t(text.length()<maxDocBytesToAnalyze)\n\t\t\t\t)\t\t\t\t\n\t\t\t{\n\t\t\t\t//append it to the last fragment\n\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset)));\n\t\t\t}\n\n\t\t\tcurrentFrag.textEndPos = newText.length();\n\n\t\t\t//sort the most relevant sections of the text\n\t\t\tfor (Iterator i = docFrags.iterator(); i.hasNext();)\n\t\t\t{\n\t\t\t\tcurrentFrag = (TextFragment) i.next();\n\n\t\t\t\t//If you are running with a version of Lucene before 11th Sept 03\n\t\t\t\t// you do not have PriorityQueue.insert() - so uncomment the code below\n\t\t\t\t/*\n\t\t\t\t\t\t\t\t\tif (currentFrag.getScore() >= minScore)\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tfragQueue.put(currentFrag);\n\t\t\t\t\t\t\t\t\t\tif (fragQueue.size() > maxNumFragments)\n\t\t\t\t\t\t\t\t\t\t{ // if hit queue overfull\n\t\t\t\t\t\t\t\t\t\t\tfragQueue.pop(); // remove lowest in hit queue\n\t\t\t\t\t\t\t\t\t\t\tminScore = ((TextFragment) fragQueue.top()).getScore(); // reset minScore\n\t\t\t\t\t\t\t\t\t\t}\n\n\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t*/\n\t\t\t\t//The above code caused a problem as a result of Christoph Goller's 11th Sept 03\n\t\t\t\t//fix to PriorityQueue. The correct method to use here is the new \"insert\" method\n\t\t\t\t// USE ABOVE CODE IF THIS DOES NOT COMPILE!\n\t\t\t\tfragQueue.insert(currentFrag);\n\t\t\t}\n\n\t\t\t//return the most relevant fragments\n\t\t\tTextFragment frag[] = new TextFragment[fragQueue.size()];\n\t\t\tfor (int i = frag.length - 1; i >= 0; i--)\n\t\t\t{\n\t\t\t\tfrag[i] = (TextFragment) fragQueue.pop();\n\t\t\t}\n\n\t\t\t//merge any contiguous fragments to improve readability\n\t\t\tif(mergeContiguousFragments)\n\t\t\t{\n\t\t\t\tmergeContiguousFragments(frag);\n\t\t\t\tArrayList fragTexts = new ArrayList();\n\t\t\t\tfor (int i = 0; i < frag.length; i++)\n\t\t\t\t{\n\t\t\t\t\tif ((frag[i] != null) && (frag[i].getScore() > 0))\n\t\t\t\t\t{\n\t\t\t\t\t\tfragTexts.add(frag[i]);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfrag= (TextFragment[]) fragTexts.toArray(new TextFragment[0]);\n\t\t\t}\n\n\t\t\treturn frag;\n\n\t\t}\n\t\tfinally\n\t\t{\n\t\t\tif (tokenStream != null)\n\t\t\t{\n\t\t\t\ttry\n\t\t\t\t{\n\t\t\t\t\ttokenStream.close();\n\t\t\t\t}\n\t\t\t\tcatch (Exception e)\n\t\t\t\t{\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n","bugFix":["9532290bd66e70c1787e80aae9fb0427ce080194"],"bugIntro":["af56a7fe9b0a12db7411a3f2ac1ad227cd35b246"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"af56a7fe9b0a12db7411a3f2ac1ad227cd35b246","date":1214948673,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter#getBestTextFragments(TokenStream,String,boolean,int).mjava","pathOld":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter#getBestTextFragments(TokenStream,String,boolean,int).mjava","sourceNew":"\t/**\n\t * Low level api to get the most relevant (formatted) sections of the document.\n\t * This method has been made public to allow visibility of score information held in TextFragment objects.\n\t * Thanks to Jason Calabrese for help in redefining the interface.\n\t * @param tokenStream\n\t * @param text\n\t * @param maxNumFragments\n\t * @param mergeContiguousFragments\n\t * @throws IOException\n\t */\n\tpublic final TextFragment[] getBestTextFragments(\n\t\tTokenStream tokenStream,\n\t\tString text,\n\t\tboolean mergeContiguousFragments,\n\t\tint maxNumFragments)\n\t\tthrows IOException\n\t{\n\t\tArrayList docFrags = new ArrayList();\n\t\tStringBuffer newText=new StringBuffer();\n\n\t\tTextFragment currentFrag =\tnew TextFragment(newText,newText.length(), docFrags.size());\n\t\tfragmentScorer.startFragment(currentFrag);\n\t\tdocFrags.add(currentFrag);\n\n\t\tFragmentQueue fragQueue = new FragmentQueue(maxNumFragments);\n\n\t\ttry\n\t\t{\n\t\t\torg.apache.lucene.analysis.Token token;\n\t\t\tString tokenText;\n\t\t\tint startOffset;\n\t\t\tint endOffset;\n\t\t\tint lastEndOffset = 0;\n\t\t\ttextFragmenter.start(text);\n\n\t\t\tTokenGroup tokenGroup=new TokenGroup();\n\t\t\ttoken = tokenStream.next();\n\t\t\twhile ((token!= null)&&(token.startOffset()< maxDocCharsToAnalyze))\n\t\t\t{\n\t\t\t\tif((tokenGroup.numTokens>0)&&(tokenGroup.isDistinct(token)))\n\t\t\t\t{\n\t\t\t\t\t//the current token is distinct from previous tokens -\n\t\t\t\t\t// markup the cached token group info\n\t\t\t\t\tstartOffset = tokenGroup.matchStartOffset;\n\t\t\t\t\tendOffset = tokenGroup.matchEndOffset;\n\t\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\t\tnewText.append(markedUpText);\n\t\t\t\t\tlastEndOffset=Math.max(endOffset, lastEndOffset);\n\t\t\t\t\ttokenGroup.clear();\n\n\t\t\t\t\t//check if current token marks the start of a new fragment\n\t\t\t\t\tif(textFragmenter.isNewFragment(token))\n\t\t\t\t\t{\n\t\t\t\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\t\t\t\t\t\t//record stats for a new fragment\n\t\t\t\t\t\tcurrentFrag.textEndPos = newText.length();\n\t\t\t\t\t\tcurrentFrag =new TextFragment(newText, newText.length(), docFrags.size());\n\t\t\t\t\t\tfragmentScorer.startFragment(currentFrag);\n\t\t\t\t\t\tdocFrags.add(currentFrag);\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\ttokenGroup.addToken(token,fragmentScorer.getTokenScore(token));\n\n//\t\t\t\tif(lastEndOffset>maxDocBytesToAnalyze)\n//\t\t\t\t{\n//\t\t\t\t\tbreak;\n//\t\t\t\t}\n\t\t\t\ttoken = tokenStream.next();\n\t\t\t}\n\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\n\t\t\tif(tokenGroup.numTokens>0)\n\t\t\t{\n\t\t\t\t//flush the accumulated text (same code as in above loop)\n\t\t\t\tstartOffset = tokenGroup.matchStartOffset;\n\t\t\t\tendOffset = tokenGroup.matchEndOffset;\n\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\tnewText.append(markedUpText);\n\t\t\t\tlastEndOffset=Math.max(lastEndOffset,endOffset);\n\t\t\t}\n\n\t\t\t//Test what remains of the original text beyond the point where we stopped analyzing \n\t\t\tif (\n//\t\t\t\t\tif there is text beyond the last token considered..\n\t\t\t\t\t(lastEndOffset < text.length()) \n\t\t\t\t\t&&\n//\t\t\t\t\tand that text is not too large...\n\t\t\t\t\t(text.length()<= maxDocCharsToAnalyze)\n\t\t\t\t)\t\t\t\t\n\t\t\t{\n\t\t\t\t//append it to the last fragment\n\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset)));\n\t\t\t}\n\n\t\t\tcurrentFrag.textEndPos = newText.length();\n\n\t\t\t//sort the most relevant sections of the text\n\t\t\tfor (Iterator i = docFrags.iterator(); i.hasNext();)\n\t\t\t{\n\t\t\t\tcurrentFrag = (TextFragment) i.next();\n\n\t\t\t\t//If you are running with a version of Lucene before 11th Sept 03\n\t\t\t\t// you do not have PriorityQueue.insert() - so uncomment the code below\n\t\t\t\t/*\n\t\t\t\t\t\t\t\t\tif (currentFrag.getScore() >= minScore)\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tfragQueue.put(currentFrag);\n\t\t\t\t\t\t\t\t\t\tif (fragQueue.size() > maxNumFragments)\n\t\t\t\t\t\t\t\t\t\t{ // if hit queue overfull\n\t\t\t\t\t\t\t\t\t\t\tfragQueue.pop(); // remove lowest in hit queue\n\t\t\t\t\t\t\t\t\t\t\tminScore = ((TextFragment) fragQueue.top()).getScore(); // reset minScore\n\t\t\t\t\t\t\t\t\t\t}\n\n\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t*/\n\t\t\t\t//The above code caused a problem as a result of Christoph Goller's 11th Sept 03\n\t\t\t\t//fix to PriorityQueue. The correct method to use here is the new \"insert\" method\n\t\t\t\t// USE ABOVE CODE IF THIS DOES NOT COMPILE!\n\t\t\t\tfragQueue.insert(currentFrag);\n\t\t\t}\n\n\t\t\t//return the most relevant fragments\n\t\t\tTextFragment frag[] = new TextFragment[fragQueue.size()];\n\t\t\tfor (int i = frag.length - 1; i >= 0; i--)\n\t\t\t{\n\t\t\t\tfrag[i] = (TextFragment) fragQueue.pop();\n\t\t\t}\n\n\t\t\t//merge any contiguous fragments to improve readability\n\t\t\tif(mergeContiguousFragments)\n\t\t\t{\n\t\t\t\tmergeContiguousFragments(frag);\n\t\t\t\tArrayList fragTexts = new ArrayList();\n\t\t\t\tfor (int i = 0; i < frag.length; i++)\n\t\t\t\t{\n\t\t\t\t\tif ((frag[i] != null) && (frag[i].getScore() > 0))\n\t\t\t\t\t{\n\t\t\t\t\t\tfragTexts.add(frag[i]);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfrag= (TextFragment[]) fragTexts.toArray(new TextFragment[0]);\n\t\t\t}\n\n\t\t\treturn frag;\n\n\t\t}\n\t\tfinally\n\t\t{\n\t\t\tif (tokenStream != null)\n\t\t\t{\n\t\t\t\ttry\n\t\t\t\t{\n\t\t\t\t\ttokenStream.close();\n\t\t\t\t}\n\t\t\t\tcatch (Exception e)\n\t\t\t\t{\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n","sourceOld":"\t/**\n\t * Low level api to get the most relevant (formatted) sections of the document.\n\t * This method has been made public to allow visibility of score information held in TextFragment objects.\n\t * Thanks to Jason Calabrese for help in redefining the interface.\n\t * @param tokenStream\n\t * @param text\n\t * @param maxNumFragments\n\t * @param mergeContiguousFragments\n\t * @throws IOException\n\t */\n\tpublic final TextFragment[] getBestTextFragments(\n\t\tTokenStream tokenStream,\n\t\tString text,\n\t\tboolean mergeContiguousFragments,\n\t\tint maxNumFragments)\n\t\tthrows IOException\n\t{\n\t\tArrayList docFrags = new ArrayList();\n\t\tStringBuffer newText=new StringBuffer();\n\n\t\tTextFragment currentFrag =\tnew TextFragment(newText,newText.length(), docFrags.size());\n\t\tfragmentScorer.startFragment(currentFrag);\n\t\tdocFrags.add(currentFrag);\n\n\t\tFragmentQueue fragQueue = new FragmentQueue(maxNumFragments);\n\n\t\ttry\n\t\t{\n\t\t\torg.apache.lucene.analysis.Token token;\n\t\t\tString tokenText;\n\t\t\tint startOffset;\n\t\t\tint endOffset;\n\t\t\tint lastEndOffset = 0;\n\t\t\ttextFragmenter.start(text);\n\n\t\t\tTokenGroup tokenGroup=new TokenGroup();\n\t\t\ttoken = tokenStream.next();\n\t\t\twhile ((token!= null)&&(token.startOffset()< maxDocCharsToAnalyze))\n\t\t\t{\n\t\t\t\tif((tokenGroup.numTokens>0)&&(tokenGroup.isDistinct(token)))\n\t\t\t\t{\n\t\t\t\t\t//the current token is distinct from previous tokens -\n\t\t\t\t\t// markup the cached token group info\n\t\t\t\t\tstartOffset = tokenGroup.matchStartOffset;\n\t\t\t\t\tendOffset = tokenGroup.matchEndOffset;\n\t\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\t\tnewText.append(markedUpText);\n\t\t\t\t\tlastEndOffset=Math.max(endOffset, lastEndOffset);\n\t\t\t\t\ttokenGroup.clear();\n\n\t\t\t\t\t//check if current token marks the start of a new fragment\n\t\t\t\t\tif(textFragmenter.isNewFragment(token))\n\t\t\t\t\t{\n\t\t\t\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\t\t\t\t\t\t//record stats for a new fragment\n\t\t\t\t\t\tcurrentFrag.textEndPos = newText.length();\n\t\t\t\t\t\tcurrentFrag =new TextFragment(newText, newText.length(), docFrags.size());\n\t\t\t\t\t\tfragmentScorer.startFragment(currentFrag);\n\t\t\t\t\t\tdocFrags.add(currentFrag);\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\ttokenGroup.addToken(token,fragmentScorer.getTokenScore(token));\n\n//\t\t\t\tif(lastEndOffset>maxDocBytesToAnalyze)\n//\t\t\t\t{\n//\t\t\t\t\tbreak;\n//\t\t\t\t}\n\t\t\t\ttoken = tokenStream.next();\n\t\t\t}\n\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\n\t\t\tif(tokenGroup.numTokens>0)\n\t\t\t{\n\t\t\t\t//flush the accumulated text (same code as in above loop)\n\t\t\t\tstartOffset = tokenGroup.matchStartOffset;\n\t\t\t\tendOffset = tokenGroup.matchEndOffset;\n\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\tnewText.append(markedUpText);\n\t\t\t\tlastEndOffset=Math.max(lastEndOffset,endOffset);\n\t\t\t}\n\n\t\t\t//Test what remains of the original text beyond the point where we stopped analyzing \n\t\t\tif (\n//\t\t\t\t\tif there is text beyond the last token considered..\n\t\t\t\t\t(lastEndOffset < text.length()) \n\t\t\t\t\t&&\n//\t\t\t\t\tand that text is not too large...\n\t\t\t\t\t(text.length()< maxDocCharsToAnalyze)\n\t\t\t\t)\t\t\t\t\n\t\t\t{\n\t\t\t\t//append it to the last fragment\n\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset)));\n\t\t\t}\n\n\t\t\tcurrentFrag.textEndPos = newText.length();\n\n\t\t\t//sort the most relevant sections of the text\n\t\t\tfor (Iterator i = docFrags.iterator(); i.hasNext();)\n\t\t\t{\n\t\t\t\tcurrentFrag = (TextFragment) i.next();\n\n\t\t\t\t//If you are running with a version of Lucene before 11th Sept 03\n\t\t\t\t// you do not have PriorityQueue.insert() - so uncomment the code below\n\t\t\t\t/*\n\t\t\t\t\t\t\t\t\tif (currentFrag.getScore() >= minScore)\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tfragQueue.put(currentFrag);\n\t\t\t\t\t\t\t\t\t\tif (fragQueue.size() > maxNumFragments)\n\t\t\t\t\t\t\t\t\t\t{ // if hit queue overfull\n\t\t\t\t\t\t\t\t\t\t\tfragQueue.pop(); // remove lowest in hit queue\n\t\t\t\t\t\t\t\t\t\t\tminScore = ((TextFragment) fragQueue.top()).getScore(); // reset minScore\n\t\t\t\t\t\t\t\t\t\t}\n\n\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t*/\n\t\t\t\t//The above code caused a problem as a result of Christoph Goller's 11th Sept 03\n\t\t\t\t//fix to PriorityQueue. The correct method to use here is the new \"insert\" method\n\t\t\t\t// USE ABOVE CODE IF THIS DOES NOT COMPILE!\n\t\t\t\tfragQueue.insert(currentFrag);\n\t\t\t}\n\n\t\t\t//return the most relevant fragments\n\t\t\tTextFragment frag[] = new TextFragment[fragQueue.size()];\n\t\t\tfor (int i = frag.length - 1; i >= 0; i--)\n\t\t\t{\n\t\t\t\tfrag[i] = (TextFragment) fragQueue.pop();\n\t\t\t}\n\n\t\t\t//merge any contiguous fragments to improve readability\n\t\t\tif(mergeContiguousFragments)\n\t\t\t{\n\t\t\t\tmergeContiguousFragments(frag);\n\t\t\t\tArrayList fragTexts = new ArrayList();\n\t\t\t\tfor (int i = 0; i < frag.length; i++)\n\t\t\t\t{\n\t\t\t\t\tif ((frag[i] != null) && (frag[i].getScore() > 0))\n\t\t\t\t\t{\n\t\t\t\t\t\tfragTexts.add(frag[i]);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfrag= (TextFragment[]) fragTexts.toArray(new TextFragment[0]);\n\t\t\t}\n\n\t\t\treturn frag;\n\n\t\t}\n\t\tfinally\n\t\t{\n\t\t\tif (tokenStream != null)\n\t\t\t{\n\t\t\t\ttry\n\t\t\t\t{\n\t\t\t\t\ttokenStream.close();\n\t\t\t\t}\n\t\t\t\tcatch (Exception e)\n\t\t\t\t{\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n","bugFix":["a710e1326e4ffd9966ad8e37ba4e5f720778c5d9"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7e2cb543b41c145f33390f460ee743d6693c9c6c","date":1219243087,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter#getBestTextFragments(TokenStream,String,boolean,int).mjava","pathOld":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter#getBestTextFragments(TokenStream,String,boolean,int).mjava","sourceNew":"\t/**\n\t * Low level api to get the most relevant (formatted) sections of the document.\n\t * This method has been made public to allow visibility of score information held in TextFragment objects.\n\t * Thanks to Jason Calabrese for help in redefining the interface.\n\t * @param tokenStream\n\t * @param text\n\t * @param maxNumFragments\n\t * @param mergeContiguousFragments\n\t * @throws IOException\n\t */\n\tpublic final TextFragment[] getBestTextFragments(\n\t\tTokenStream tokenStream,\n\t\tString text,\n\t\tboolean mergeContiguousFragments,\n\t\tint maxNumFragments)\n\t\tthrows IOException\n\t{\n\t\tArrayList docFrags = new ArrayList();\n\t\tStringBuffer newText=new StringBuffer();\n\n\t\tTextFragment currentFrag =\tnew TextFragment(newText,newText.length(), docFrags.size());\n\t\tfragmentScorer.startFragment(currentFrag);\n\t\tdocFrags.add(currentFrag);\n\n\t\tFragmentQueue fragQueue = new FragmentQueue(maxNumFragments);\n\n\t\ttry\n\t\t{\n                  final Token reusableToken = new Token();\n\t\t\tString tokenText;\n\t\t\tint startOffset;\n\t\t\tint endOffset;\n\t\t\tint lastEndOffset = 0;\n\t\t\ttextFragmenter.start(text);\n\n\t\t\tTokenGroup tokenGroup=new TokenGroup();\n\t\t\t\n\t\t\tfor (Token nextToken = tokenStream.next(reusableToken);\n\t\t\t     (nextToken!= null)&&(nextToken.startOffset()< maxDocCharsToAnalyze);\n\t\t\t     nextToken = tokenStream.next(reusableToken))\n\t\t\t{\n\t\t\t\tif((tokenGroup.numTokens>0)&&(tokenGroup.isDistinct(nextToken)))\n\t\t\t\t{\n\t\t\t\t\t//the current token is distinct from previous tokens -\n\t\t\t\t\t// markup the cached token group info\n\t\t\t\t\tstartOffset = tokenGroup.matchStartOffset;\n\t\t\t\t\tendOffset = tokenGroup.matchEndOffset;\n\t\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\t\tnewText.append(markedUpText);\n\t\t\t\t\tlastEndOffset=Math.max(endOffset, lastEndOffset);\n\t\t\t\t\ttokenGroup.clear();\n\n\t\t\t\t\t//check if current token marks the start of a new fragment\n\t\t\t\t\tif(textFragmenter.isNewFragment(nextToken))\n\t\t\t\t\t{\n\t\t\t\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\t\t\t\t\t\t//record stats for a new fragment\n\t\t\t\t\t\tcurrentFrag.textEndPos = newText.length();\n\t\t\t\t\t\tcurrentFrag =new TextFragment(newText, newText.length(), docFrags.size());\n\t\t\t\t\t\tfragmentScorer.startFragment(currentFrag);\n\t\t\t\t\t\tdocFrags.add(currentFrag);\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\ttokenGroup.addToken(nextToken,fragmentScorer.getTokenScore(nextToken));\n\n//\t\t\t\tif(lastEndOffset>maxDocBytesToAnalyze)\n//\t\t\t\t{\n//\t\t\t\t\tbreak;\n//\t\t\t\t}\n\t\t\t}\n\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\n\t\t\tif(tokenGroup.numTokens>0)\n\t\t\t{\n\t\t\t\t//flush the accumulated text (same code as in above loop)\n\t\t\t\tstartOffset = tokenGroup.matchStartOffset;\n\t\t\t\tendOffset = tokenGroup.matchEndOffset;\n\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\tnewText.append(markedUpText);\n\t\t\t\tlastEndOffset=Math.max(lastEndOffset,endOffset);\n\t\t\t}\n\n\t\t\t//Test what remains of the original text beyond the point where we stopped analyzing \n\t\t\tif (\n//\t\t\t\t\tif there is text beyond the last token considered..\n\t\t\t\t\t(lastEndOffset < text.length()) \n\t\t\t\t\t&&\n//\t\t\t\t\tand that text is not too large...\n\t\t\t\t\t(text.length()<= maxDocCharsToAnalyze)\n\t\t\t\t)\t\t\t\t\n\t\t\t{\n\t\t\t\t//append it to the last fragment\n\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset)));\n\t\t\t}\n\n\t\t\tcurrentFrag.textEndPos = newText.length();\n\n\t\t\t//sort the most relevant sections of the text\n\t\t\tfor (Iterator i = docFrags.iterator(); i.hasNext();)\n\t\t\t{\n\t\t\t\tcurrentFrag = (TextFragment) i.next();\n\n\t\t\t\t//If you are running with a version of Lucene before 11th Sept 03\n\t\t\t\t// you do not have PriorityQueue.insert() - so uncomment the code below\n\t\t\t\t/*\n\t\t\t\t\t\t\t\t\tif (currentFrag.getScore() >= minScore)\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tfragQueue.put(currentFrag);\n\t\t\t\t\t\t\t\t\t\tif (fragQueue.size() > maxNumFragments)\n\t\t\t\t\t\t\t\t\t\t{ // if hit queue overfull\n\t\t\t\t\t\t\t\t\t\t\tfragQueue.pop(); // remove lowest in hit queue\n\t\t\t\t\t\t\t\t\t\t\tminScore = ((TextFragment) fragQueue.top()).getScore(); // reset minScore\n\t\t\t\t\t\t\t\t\t\t}\n\n\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t*/\n\t\t\t\t//The above code caused a problem as a result of Christoph Goller's 11th Sept 03\n\t\t\t\t//fix to PriorityQueue. The correct method to use here is the new \"insert\" method\n\t\t\t\t// USE ABOVE CODE IF THIS DOES NOT COMPILE!\n\t\t\t\tfragQueue.insert(currentFrag);\n\t\t\t}\n\n\t\t\t//return the most relevant fragments\n\t\t\tTextFragment frag[] = new TextFragment[fragQueue.size()];\n\t\t\tfor (int i = frag.length - 1; i >= 0; i--)\n\t\t\t{\n\t\t\t\tfrag[i] = (TextFragment) fragQueue.pop();\n\t\t\t}\n\n\t\t\t//merge any contiguous fragments to improve readability\n\t\t\tif(mergeContiguousFragments)\n\t\t\t{\n\t\t\t\tmergeContiguousFragments(frag);\n\t\t\t\tArrayList fragTexts = new ArrayList();\n\t\t\t\tfor (int i = 0; i < frag.length; i++)\n\t\t\t\t{\n\t\t\t\t\tif ((frag[i] != null) && (frag[i].getScore() > 0))\n\t\t\t\t\t{\n\t\t\t\t\t\tfragTexts.add(frag[i]);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfrag= (TextFragment[]) fragTexts.toArray(new TextFragment[0]);\n\t\t\t}\n\n\t\t\treturn frag;\n\n\t\t}\n\t\tfinally\n\t\t{\n\t\t\tif (tokenStream != null)\n\t\t\t{\n\t\t\t\ttry\n\t\t\t\t{\n\t\t\t\t\ttokenStream.close();\n\t\t\t\t}\n\t\t\t\tcatch (Exception e)\n\t\t\t\t{\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n","sourceOld":"\t/**\n\t * Low level api to get the most relevant (formatted) sections of the document.\n\t * This method has been made public to allow visibility of score information held in TextFragment objects.\n\t * Thanks to Jason Calabrese for help in redefining the interface.\n\t * @param tokenStream\n\t * @param text\n\t * @param maxNumFragments\n\t * @param mergeContiguousFragments\n\t * @throws IOException\n\t */\n\tpublic final TextFragment[] getBestTextFragments(\n\t\tTokenStream tokenStream,\n\t\tString text,\n\t\tboolean mergeContiguousFragments,\n\t\tint maxNumFragments)\n\t\tthrows IOException\n\t{\n\t\tArrayList docFrags = new ArrayList();\n\t\tStringBuffer newText=new StringBuffer();\n\n\t\tTextFragment currentFrag =\tnew TextFragment(newText,newText.length(), docFrags.size());\n\t\tfragmentScorer.startFragment(currentFrag);\n\t\tdocFrags.add(currentFrag);\n\n\t\tFragmentQueue fragQueue = new FragmentQueue(maxNumFragments);\n\n\t\ttry\n\t\t{\n\t\t\torg.apache.lucene.analysis.Token token;\n\t\t\tString tokenText;\n\t\t\tint startOffset;\n\t\t\tint endOffset;\n\t\t\tint lastEndOffset = 0;\n\t\t\ttextFragmenter.start(text);\n\n\t\t\tTokenGroup tokenGroup=new TokenGroup();\n\t\t\ttoken = tokenStream.next();\n\t\t\twhile ((token!= null)&&(token.startOffset()< maxDocCharsToAnalyze))\n\t\t\t{\n\t\t\t\tif((tokenGroup.numTokens>0)&&(tokenGroup.isDistinct(token)))\n\t\t\t\t{\n\t\t\t\t\t//the current token is distinct from previous tokens -\n\t\t\t\t\t// markup the cached token group info\n\t\t\t\t\tstartOffset = tokenGroup.matchStartOffset;\n\t\t\t\t\tendOffset = tokenGroup.matchEndOffset;\n\t\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\t\tnewText.append(markedUpText);\n\t\t\t\t\tlastEndOffset=Math.max(endOffset, lastEndOffset);\n\t\t\t\t\ttokenGroup.clear();\n\n\t\t\t\t\t//check if current token marks the start of a new fragment\n\t\t\t\t\tif(textFragmenter.isNewFragment(token))\n\t\t\t\t\t{\n\t\t\t\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\t\t\t\t\t\t//record stats for a new fragment\n\t\t\t\t\t\tcurrentFrag.textEndPos = newText.length();\n\t\t\t\t\t\tcurrentFrag =new TextFragment(newText, newText.length(), docFrags.size());\n\t\t\t\t\t\tfragmentScorer.startFragment(currentFrag);\n\t\t\t\t\t\tdocFrags.add(currentFrag);\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\ttokenGroup.addToken(token,fragmentScorer.getTokenScore(token));\n\n//\t\t\t\tif(lastEndOffset>maxDocBytesToAnalyze)\n//\t\t\t\t{\n//\t\t\t\t\tbreak;\n//\t\t\t\t}\n\t\t\t\ttoken = tokenStream.next();\n\t\t\t}\n\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\n\t\t\tif(tokenGroup.numTokens>0)\n\t\t\t{\n\t\t\t\t//flush the accumulated text (same code as in above loop)\n\t\t\t\tstartOffset = tokenGroup.matchStartOffset;\n\t\t\t\tendOffset = tokenGroup.matchEndOffset;\n\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\tnewText.append(markedUpText);\n\t\t\t\tlastEndOffset=Math.max(lastEndOffset,endOffset);\n\t\t\t}\n\n\t\t\t//Test what remains of the original text beyond the point where we stopped analyzing \n\t\t\tif (\n//\t\t\t\t\tif there is text beyond the last token considered..\n\t\t\t\t\t(lastEndOffset < text.length()) \n\t\t\t\t\t&&\n//\t\t\t\t\tand that text is not too large...\n\t\t\t\t\t(text.length()<= maxDocCharsToAnalyze)\n\t\t\t\t)\t\t\t\t\n\t\t\t{\n\t\t\t\t//append it to the last fragment\n\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset)));\n\t\t\t}\n\n\t\t\tcurrentFrag.textEndPos = newText.length();\n\n\t\t\t//sort the most relevant sections of the text\n\t\t\tfor (Iterator i = docFrags.iterator(); i.hasNext();)\n\t\t\t{\n\t\t\t\tcurrentFrag = (TextFragment) i.next();\n\n\t\t\t\t//If you are running with a version of Lucene before 11th Sept 03\n\t\t\t\t// you do not have PriorityQueue.insert() - so uncomment the code below\n\t\t\t\t/*\n\t\t\t\t\t\t\t\t\tif (currentFrag.getScore() >= minScore)\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tfragQueue.put(currentFrag);\n\t\t\t\t\t\t\t\t\t\tif (fragQueue.size() > maxNumFragments)\n\t\t\t\t\t\t\t\t\t\t{ // if hit queue overfull\n\t\t\t\t\t\t\t\t\t\t\tfragQueue.pop(); // remove lowest in hit queue\n\t\t\t\t\t\t\t\t\t\t\tminScore = ((TextFragment) fragQueue.top()).getScore(); // reset minScore\n\t\t\t\t\t\t\t\t\t\t}\n\n\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t*/\n\t\t\t\t//The above code caused a problem as a result of Christoph Goller's 11th Sept 03\n\t\t\t\t//fix to PriorityQueue. The correct method to use here is the new \"insert\" method\n\t\t\t\t// USE ABOVE CODE IF THIS DOES NOT COMPILE!\n\t\t\t\tfragQueue.insert(currentFrag);\n\t\t\t}\n\n\t\t\t//return the most relevant fragments\n\t\t\tTextFragment frag[] = new TextFragment[fragQueue.size()];\n\t\t\tfor (int i = frag.length - 1; i >= 0; i--)\n\t\t\t{\n\t\t\t\tfrag[i] = (TextFragment) fragQueue.pop();\n\t\t\t}\n\n\t\t\t//merge any contiguous fragments to improve readability\n\t\t\tif(mergeContiguousFragments)\n\t\t\t{\n\t\t\t\tmergeContiguousFragments(frag);\n\t\t\t\tArrayList fragTexts = new ArrayList();\n\t\t\t\tfor (int i = 0; i < frag.length; i++)\n\t\t\t\t{\n\t\t\t\t\tif ((frag[i] != null) && (frag[i].getScore() > 0))\n\t\t\t\t\t{\n\t\t\t\t\t\tfragTexts.add(frag[i]);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfrag= (TextFragment[]) fragTexts.toArray(new TextFragment[0]);\n\t\t\t}\n\n\t\t\treturn frag;\n\n\t\t}\n\t\tfinally\n\t\t{\n\t\t\tif (tokenStream != null)\n\t\t\t{\n\t\t\t\ttry\n\t\t\t\t{\n\t\t\t\t\ttokenStream.close();\n\t\t\t\t}\n\t\t\t\tcatch (Exception e)\n\t\t\t\t{\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bf4dbfaec317df80ca6f412ce1b94b337b581e17","date":1238022314,"type":3,"author":"Mark Harwood","isMerge":false,"pathNew":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter#getBestTextFragments(TokenStream,String,boolean,int).mjava","pathOld":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter#getBestTextFragments(TokenStream,String,boolean,int).mjava","sourceNew":"\t/**\n\t * Low level api to get the most relevant (formatted) sections of the document.\n\t * This method has been made public to allow visibility of score information held in TextFragment objects.\n\t * Thanks to Jason Calabrese for help in redefining the interface.\n\t * @param tokenStream\n\t * @param text\n\t * @param maxNumFragments\n\t * @param mergeContiguousFragments\n\t * @throws IOException\n\t * @throws InvalidTokenOffsetsException thrown if any token's endOffset exceeds the provided text's length\n\t */\n\tpublic final TextFragment[] getBestTextFragments(\n\t\tTokenStream tokenStream,\n\t\tString text,\n\t\tboolean mergeContiguousFragments,\n\t\tint maxNumFragments)\n\t\tthrows IOException, InvalidTokenOffsetsException\n\t{\n\t\tArrayList docFrags = new ArrayList();\n\t\tStringBuffer newText=new StringBuffer();\n\n\t\tTextFragment currentFrag =\tnew TextFragment(newText,newText.length(), docFrags.size());\n\t\tfragmentScorer.startFragment(currentFrag);\n\t\tdocFrags.add(currentFrag);\n\n\t\tFragmentQueue fragQueue = new FragmentQueue(maxNumFragments);\n\n\t\ttry\n\t\t{\n                  final Token reusableToken = new Token();\n\t\t\tString tokenText;\n\t\t\tint startOffset;\n\t\t\tint endOffset;\n\t\t\tint lastEndOffset = 0;\n\t\t\ttextFragmenter.start(text);\n\n\t\t\tTokenGroup tokenGroup=new TokenGroup();\n\t\t\t\n\t\t\tfor (Token nextToken = tokenStream.next(reusableToken);\n\t\t\t     (nextToken!= null)&&(nextToken.startOffset()< maxDocCharsToAnalyze);\n\t\t\t     nextToken = tokenStream.next(reusableToken))\n\t\t\t{\n\t\t\t\tif(\t(nextToken.endOffset()>text.length())\n\t\t\t\t\t||\n\t\t\t\t\t(nextToken.startOffset()>text.length())\n\t\t\t\t\t)\t\t\t\t\t\t\n\t\t\t\t{\n\t\t\t\t\tthrow new InvalidTokenOffsetsException(\"Token \"+nextToken.toString()\n\t\t\t\t\t\t\t+\" exceeds length of provided text sized \"+text.length());\n\t\t\t\t}\n\t\t\t\tif((tokenGroup.numTokens>0)&&(tokenGroup.isDistinct(nextToken)))\n\t\t\t\t{\n\t\t\t\t\t//the current token is distinct from previous tokens -\n\t\t\t\t\t// markup the cached token group info\n\t\t\t\t\tstartOffset = tokenGroup.matchStartOffset;\n\t\t\t\t\tendOffset = tokenGroup.matchEndOffset;\n\t\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\t\tnewText.append(markedUpText);\n\t\t\t\t\tlastEndOffset=Math.max(endOffset, lastEndOffset);\n\t\t\t\t\ttokenGroup.clear();\n\n\t\t\t\t\t//check if current token marks the start of a new fragment\n\t\t\t\t\tif(textFragmenter.isNewFragment(nextToken))\n\t\t\t\t\t{\n\t\t\t\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\t\t\t\t\t\t//record stats for a new fragment\n\t\t\t\t\t\tcurrentFrag.textEndPos = newText.length();\n\t\t\t\t\t\tcurrentFrag =new TextFragment(newText, newText.length(), docFrags.size());\n\t\t\t\t\t\tfragmentScorer.startFragment(currentFrag);\n\t\t\t\t\t\tdocFrags.add(currentFrag);\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\ttokenGroup.addToken(nextToken,fragmentScorer.getTokenScore(nextToken));\n\n//\t\t\t\tif(lastEndOffset>maxDocBytesToAnalyze)\n//\t\t\t\t{\n//\t\t\t\t\tbreak;\n//\t\t\t\t}\n\t\t\t}\n\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\n\t\t\tif(tokenGroup.numTokens>0)\n\t\t\t{\n\t\t\t\t//flush the accumulated text (same code as in above loop)\n\t\t\t\tstartOffset = tokenGroup.matchStartOffset;\n\t\t\t\tendOffset = tokenGroup.matchEndOffset;\n\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\tnewText.append(markedUpText);\n\t\t\t\tlastEndOffset=Math.max(lastEndOffset,endOffset);\n\t\t\t}\n\n\t\t\t//Test what remains of the original text beyond the point where we stopped analyzing \n\t\t\tif (\n//\t\t\t\t\tif there is text beyond the last token considered..\n\t\t\t\t\t(lastEndOffset < text.length()) \n\t\t\t\t\t&&\n//\t\t\t\t\tand that text is not too large...\n\t\t\t\t\t(text.length()<= maxDocCharsToAnalyze)\n\t\t\t\t)\t\t\t\t\n\t\t\t{\n\t\t\t\t//append it to the last fragment\n\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset)));\n\t\t\t}\n\n\t\t\tcurrentFrag.textEndPos = newText.length();\n\n\t\t\t//sort the most relevant sections of the text\n\t\t\tfor (Iterator i = docFrags.iterator(); i.hasNext();)\n\t\t\t{\n\t\t\t\tcurrentFrag = (TextFragment) i.next();\n\n\t\t\t\t//If you are running with a version of Lucene before 11th Sept 03\n\t\t\t\t// you do not have PriorityQueue.insert() - so uncomment the code below\n\t\t\t\t/*\n\t\t\t\t\t\t\t\t\tif (currentFrag.getScore() >= minScore)\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tfragQueue.put(currentFrag);\n\t\t\t\t\t\t\t\t\t\tif (fragQueue.size() > maxNumFragments)\n\t\t\t\t\t\t\t\t\t\t{ // if hit queue overfull\n\t\t\t\t\t\t\t\t\t\t\tfragQueue.pop(); // remove lowest in hit queue\n\t\t\t\t\t\t\t\t\t\t\tminScore = ((TextFragment) fragQueue.top()).getScore(); // reset minScore\n\t\t\t\t\t\t\t\t\t\t}\n\n\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t*/\n\t\t\t\t//The above code caused a problem as a result of Christoph Goller's 11th Sept 03\n\t\t\t\t//fix to PriorityQueue. The correct method to use here is the new \"insert\" method\n\t\t\t\t// USE ABOVE CODE IF THIS DOES NOT COMPILE!\n\t\t\t\tfragQueue.insert(currentFrag);\n\t\t\t}\n\n\t\t\t//return the most relevant fragments\n\t\t\tTextFragment frag[] = new TextFragment[fragQueue.size()];\n\t\t\tfor (int i = frag.length - 1; i >= 0; i--)\n\t\t\t{\n\t\t\t\tfrag[i] = (TextFragment) fragQueue.pop();\n\t\t\t}\n\n\t\t\t//merge any contiguous fragments to improve readability\n\t\t\tif(mergeContiguousFragments)\n\t\t\t{\n\t\t\t\tmergeContiguousFragments(frag);\n\t\t\t\tArrayList fragTexts = new ArrayList();\n\t\t\t\tfor (int i = 0; i < frag.length; i++)\n\t\t\t\t{\n\t\t\t\t\tif ((frag[i] != null) && (frag[i].getScore() > 0))\n\t\t\t\t\t{\n\t\t\t\t\t\tfragTexts.add(frag[i]);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfrag= (TextFragment[]) fragTexts.toArray(new TextFragment[0]);\n\t\t\t}\n\n\t\t\treturn frag;\n\n\t\t}\n\t\tfinally\n\t\t{\n\t\t\tif (tokenStream != null)\n\t\t\t{\n\t\t\t\ttry\n\t\t\t\t{\n\t\t\t\t\ttokenStream.close();\n\t\t\t\t}\n\t\t\t\tcatch (Exception e)\n\t\t\t\t{\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n","sourceOld":"\t/**\n\t * Low level api to get the most relevant (formatted) sections of the document.\n\t * This method has been made public to allow visibility of score information held in TextFragment objects.\n\t * Thanks to Jason Calabrese for help in redefining the interface.\n\t * @param tokenStream\n\t * @param text\n\t * @param maxNumFragments\n\t * @param mergeContiguousFragments\n\t * @throws IOException\n\t */\n\tpublic final TextFragment[] getBestTextFragments(\n\t\tTokenStream tokenStream,\n\t\tString text,\n\t\tboolean mergeContiguousFragments,\n\t\tint maxNumFragments)\n\t\tthrows IOException\n\t{\n\t\tArrayList docFrags = new ArrayList();\n\t\tStringBuffer newText=new StringBuffer();\n\n\t\tTextFragment currentFrag =\tnew TextFragment(newText,newText.length(), docFrags.size());\n\t\tfragmentScorer.startFragment(currentFrag);\n\t\tdocFrags.add(currentFrag);\n\n\t\tFragmentQueue fragQueue = new FragmentQueue(maxNumFragments);\n\n\t\ttry\n\t\t{\n                  final Token reusableToken = new Token();\n\t\t\tString tokenText;\n\t\t\tint startOffset;\n\t\t\tint endOffset;\n\t\t\tint lastEndOffset = 0;\n\t\t\ttextFragmenter.start(text);\n\n\t\t\tTokenGroup tokenGroup=new TokenGroup();\n\t\t\t\n\t\t\tfor (Token nextToken = tokenStream.next(reusableToken);\n\t\t\t     (nextToken!= null)&&(nextToken.startOffset()< maxDocCharsToAnalyze);\n\t\t\t     nextToken = tokenStream.next(reusableToken))\n\t\t\t{\n\t\t\t\tif((tokenGroup.numTokens>0)&&(tokenGroup.isDistinct(nextToken)))\n\t\t\t\t{\n\t\t\t\t\t//the current token is distinct from previous tokens -\n\t\t\t\t\t// markup the cached token group info\n\t\t\t\t\tstartOffset = tokenGroup.matchStartOffset;\n\t\t\t\t\tendOffset = tokenGroup.matchEndOffset;\n\t\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\t\tnewText.append(markedUpText);\n\t\t\t\t\tlastEndOffset=Math.max(endOffset, lastEndOffset);\n\t\t\t\t\ttokenGroup.clear();\n\n\t\t\t\t\t//check if current token marks the start of a new fragment\n\t\t\t\t\tif(textFragmenter.isNewFragment(nextToken))\n\t\t\t\t\t{\n\t\t\t\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\t\t\t\t\t\t//record stats for a new fragment\n\t\t\t\t\t\tcurrentFrag.textEndPos = newText.length();\n\t\t\t\t\t\tcurrentFrag =new TextFragment(newText, newText.length(), docFrags.size());\n\t\t\t\t\t\tfragmentScorer.startFragment(currentFrag);\n\t\t\t\t\t\tdocFrags.add(currentFrag);\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\ttokenGroup.addToken(nextToken,fragmentScorer.getTokenScore(nextToken));\n\n//\t\t\t\tif(lastEndOffset>maxDocBytesToAnalyze)\n//\t\t\t\t{\n//\t\t\t\t\tbreak;\n//\t\t\t\t}\n\t\t\t}\n\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\n\t\t\tif(tokenGroup.numTokens>0)\n\t\t\t{\n\t\t\t\t//flush the accumulated text (same code as in above loop)\n\t\t\t\tstartOffset = tokenGroup.matchStartOffset;\n\t\t\t\tendOffset = tokenGroup.matchEndOffset;\n\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\tnewText.append(markedUpText);\n\t\t\t\tlastEndOffset=Math.max(lastEndOffset,endOffset);\n\t\t\t}\n\n\t\t\t//Test what remains of the original text beyond the point where we stopped analyzing \n\t\t\tif (\n//\t\t\t\t\tif there is text beyond the last token considered..\n\t\t\t\t\t(lastEndOffset < text.length()) \n\t\t\t\t\t&&\n//\t\t\t\t\tand that text is not too large...\n\t\t\t\t\t(text.length()<= maxDocCharsToAnalyze)\n\t\t\t\t)\t\t\t\t\n\t\t\t{\n\t\t\t\t//append it to the last fragment\n\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset)));\n\t\t\t}\n\n\t\t\tcurrentFrag.textEndPos = newText.length();\n\n\t\t\t//sort the most relevant sections of the text\n\t\t\tfor (Iterator i = docFrags.iterator(); i.hasNext();)\n\t\t\t{\n\t\t\t\tcurrentFrag = (TextFragment) i.next();\n\n\t\t\t\t//If you are running with a version of Lucene before 11th Sept 03\n\t\t\t\t// you do not have PriorityQueue.insert() - so uncomment the code below\n\t\t\t\t/*\n\t\t\t\t\t\t\t\t\tif (currentFrag.getScore() >= minScore)\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tfragQueue.put(currentFrag);\n\t\t\t\t\t\t\t\t\t\tif (fragQueue.size() > maxNumFragments)\n\t\t\t\t\t\t\t\t\t\t{ // if hit queue overfull\n\t\t\t\t\t\t\t\t\t\t\tfragQueue.pop(); // remove lowest in hit queue\n\t\t\t\t\t\t\t\t\t\t\tminScore = ((TextFragment) fragQueue.top()).getScore(); // reset minScore\n\t\t\t\t\t\t\t\t\t\t}\n\n\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t*/\n\t\t\t\t//The above code caused a problem as a result of Christoph Goller's 11th Sept 03\n\t\t\t\t//fix to PriorityQueue. The correct method to use here is the new \"insert\" method\n\t\t\t\t// USE ABOVE CODE IF THIS DOES NOT COMPILE!\n\t\t\t\tfragQueue.insert(currentFrag);\n\t\t\t}\n\n\t\t\t//return the most relevant fragments\n\t\t\tTextFragment frag[] = new TextFragment[fragQueue.size()];\n\t\t\tfor (int i = frag.length - 1; i >= 0; i--)\n\t\t\t{\n\t\t\t\tfrag[i] = (TextFragment) fragQueue.pop();\n\t\t\t}\n\n\t\t\t//merge any contiguous fragments to improve readability\n\t\t\tif(mergeContiguousFragments)\n\t\t\t{\n\t\t\t\tmergeContiguousFragments(frag);\n\t\t\t\tArrayList fragTexts = new ArrayList();\n\t\t\t\tfor (int i = 0; i < frag.length; i++)\n\t\t\t\t{\n\t\t\t\t\tif ((frag[i] != null) && (frag[i].getScore() > 0))\n\t\t\t\t\t{\n\t\t\t\t\t\tfragTexts.add(frag[i]);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfrag= (TextFragment[]) fragTexts.toArray(new TextFragment[0]);\n\t\t\t}\n\n\t\t\treturn frag;\n\n\t\t}\n\t\tfinally\n\t\t{\n\t\t\tif (tokenStream != null)\n\t\t\t{\n\t\t\t\ttry\n\t\t\t\t{\n\t\t\t\t\ttokenStream.close();\n\t\t\t\t}\n\t\t\t\tcatch (Exception e)\n\t\t\t\t{\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b4471b2ef75c0e11869f60b23cabe292b895c3ee","date":1248991247,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter#getBestTextFragments(TokenStream,String,boolean,int).mjava","pathOld":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter#getBestTextFragments(TokenStream,String,boolean,int).mjava","sourceNew":"\t/**\n\t * Low level api to get the most relevant (formatted) sections of the document.\n\t * This method has been made public to allow visibility of score information held in TextFragment objects.\n\t * Thanks to Jason Calabrese for help in redefining the interface.\n\t * @param tokenStream\n\t * @param text\n\t * @param maxNumFragments\n\t * @param mergeContiguousFragments\n\t * @throws IOException\n\t * @throws InvalidTokenOffsetsException thrown if any token's endOffset exceeds the provided text's length\n\t */\n\tpublic final TextFragment[] getBestTextFragments(\n\t\tTokenStream tokenStream,\n\t\tString text,\n\t\tboolean mergeContiguousFragments,\n\t\tint maxNumFragments)\n\t\tthrows IOException, InvalidTokenOffsetsException\n\t{\n\t\tArrayList docFrags = new ArrayList();\n\t\tStringBuffer newText=new StringBuffer();\n\t\t\n\t    TermAttribute termAtt = (TermAttribute) tokenStream.addAttribute(TermAttribute.class);\n\t    OffsetAttribute offsetAtt = (OffsetAttribute) tokenStream.addAttribute(OffsetAttribute.class);\n\t    tokenStream.addAttribute(PositionIncrementAttribute.class);\n\t    tokenStream.reset();\n\t    \n\t\tTextFragment currentFrag =\tnew TextFragment(newText,newText.length(), docFrags.size());\n\t\tfragmentScorer.init(tokenStream);\n\t\tfragmentScorer.startFragment(currentFrag);\n\t\tdocFrags.add(currentFrag);\n\n\t\tFragmentQueue fragQueue = new FragmentQueue(maxNumFragments);\n\n\t\ttry\n\t\t{\n\n\t\t\tString tokenText;\n\t\t\tint startOffset;\n\t\t\tint endOffset;\n\t\t\tint lastEndOffset = 0;\n\t\t\ttextFragmenter.start(text, tokenStream);\n\n\t\t\tTokenGroup tokenGroup=new TokenGroup(tokenStream);\n\n\t\t\tfor (boolean next = tokenStream.incrementToken(); next && (offsetAtt.startOffset()< maxDocCharsToAnalyze);\n\t\t\t      next = tokenStream.incrementToken())\n\t\t\t{\n\t\t\t\tif(\t(offsetAtt.endOffset()>text.length())\n\t\t\t\t\t||\n\t\t\t\t\t(offsetAtt.startOffset()>text.length())\n\t\t\t\t\t)\t\t\t\t\t\t\n\t\t\t\t{\n\t\t\t\t\tthrow new InvalidTokenOffsetsException(\"Token \"+ termAtt.term()\n\t\t\t\t\t\t\t+\" exceeds length of provided text sized \"+text.length());\n\t\t\t\t}\n\t\t\t\tif((tokenGroup.numTokens>0)&&(tokenGroup.isDistinct()))\n\t\t\t\t{\n\t\t\t\t\t//the current token is distinct from previous tokens -\n\t\t\t\t\t// markup the cached token group info\n\t\t\t\t\tstartOffset = tokenGroup.matchStartOffset;\n\t\t\t\t\tendOffset = tokenGroup.matchEndOffset;\n\t\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\t\tnewText.append(markedUpText);\n\t\t\t\t\tlastEndOffset=Math.max(endOffset, lastEndOffset);\n\t\t\t\t\ttokenGroup.clear();\n\n\t\t\t\t\t//check if current token marks the start of a new fragment\n\t\t\t\t\tif(textFragmenter.isNewFragment())\n\t\t\t\t\t{\n\t\t\t\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\t\t\t\t\t\t//record stats for a new fragment\n\t\t\t\t\t\tcurrentFrag.textEndPos = newText.length();\n\t\t\t\t\t\tcurrentFrag =new TextFragment(newText, newText.length(), docFrags.size());\n\t\t\t\t\t\tfragmentScorer.startFragment(currentFrag);\n\t\t\t\t\t\tdocFrags.add(currentFrag);\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\ttokenGroup.addToken(fragmentScorer.getTokenScore());\n\n//\t\t\t\tif(lastEndOffset>maxDocBytesToAnalyze)\n//\t\t\t\t{\n//\t\t\t\t\tbreak;\n//\t\t\t\t}\n\t\t\t}\n\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\n\t\t\tif(tokenGroup.numTokens>0)\n\t\t\t{\n\t\t\t\t//flush the accumulated text (same code as in above loop)\n\t\t\t\tstartOffset = tokenGroup.matchStartOffset;\n\t\t\t\tendOffset = tokenGroup.matchEndOffset;\n\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\tnewText.append(markedUpText);\n\t\t\t\tlastEndOffset=Math.max(lastEndOffset,endOffset);\n\t\t\t}\n\n\t\t\t//Test what remains of the original text beyond the point where we stopped analyzing \n\t\t\tif (\n//\t\t\t\t\tif there is text beyond the last token considered..\n\t\t\t\t\t(lastEndOffset < text.length()) \n\t\t\t\t\t&&\n//\t\t\t\t\tand that text is not too large...\n\t\t\t\t\t(text.length()<= maxDocCharsToAnalyze)\n\t\t\t\t)\t\t\t\t\n\t\t\t{\n\t\t\t\t//append it to the last fragment\n\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset)));\n\t\t\t}\n\n\t\t\tcurrentFrag.textEndPos = newText.length();\n\n\t\t\t//sort the most relevant sections of the text\n\t\t\tfor (Iterator i = docFrags.iterator(); i.hasNext();)\n\t\t\t{\n\t\t\t\tcurrentFrag = (TextFragment) i.next();\n\n\t\t\t\t//If you are running with a version of Lucene before 11th Sept 03\n\t\t\t\t// you do not have PriorityQueue.insert() - so uncomment the code below\n\t\t\t\t/*\n\t\t\t\t\t\t\t\t\tif (currentFrag.getScore() >= minScore)\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tfragQueue.put(currentFrag);\n\t\t\t\t\t\t\t\t\t\tif (fragQueue.size() > maxNumFragments)\n\t\t\t\t\t\t\t\t\t\t{ // if hit queue overfull\n\t\t\t\t\t\t\t\t\t\t\tfragQueue.pop(); // remove lowest in hit queue\n\t\t\t\t\t\t\t\t\t\t\tminScore = ((TextFragment) fragQueue.top()).getScore(); // reset minScore\n\t\t\t\t\t\t\t\t\t\t}\n\n\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t*/\n\t\t\t\t//The above code caused a problem as a result of Christoph Goller's 11th Sept 03\n\t\t\t\t//fix to PriorityQueue. The correct method to use here is the new \"insert\" method\n\t\t\t\t// USE ABOVE CODE IF THIS DOES NOT COMPILE!\n\t\t\t\tfragQueue.insertWithOverflow(currentFrag);\n\t\t\t}\n\n\t\t\t//return the most relevant fragments\n\t\t\tTextFragment frag[] = new TextFragment[fragQueue.size()];\n\t\t\tfor (int i = frag.length - 1; i >= 0; i--)\n\t\t\t{\n\t\t\t\tfrag[i] = (TextFragment) fragQueue.pop();\n\t\t\t}\n\n\t\t\t//merge any contiguous fragments to improve readability\n\t\t\tif(mergeContiguousFragments)\n\t\t\t{\n\t\t\t\tmergeContiguousFragments(frag);\n\t\t\t\tArrayList fragTexts = new ArrayList();\n\t\t\t\tfor (int i = 0; i < frag.length; i++)\n\t\t\t\t{\n\t\t\t\t\tif ((frag[i] != null) && (frag[i].getScore() > 0))\n\t\t\t\t\t{\n\t\t\t\t\t\tfragTexts.add(frag[i]);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfrag= (TextFragment[]) fragTexts.toArray(new TextFragment[0]);\n\t\t\t}\n\n\t\t\treturn frag;\n\n\t\t}\n\t\tfinally\n\t\t{\n\t\t\tif (tokenStream != null)\n\t\t\t{\n\t\t\t\ttry\n\t\t\t\t{\n\t\t\t\t\ttokenStream.close();\n\t\t\t\t}\n\t\t\t\tcatch (Exception e)\n\t\t\t\t{\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n","sourceOld":"\t/**\n\t * Low level api to get the most relevant (formatted) sections of the document.\n\t * This method has been made public to allow visibility of score information held in TextFragment objects.\n\t * Thanks to Jason Calabrese for help in redefining the interface.\n\t * @param tokenStream\n\t * @param text\n\t * @param maxNumFragments\n\t * @param mergeContiguousFragments\n\t * @throws IOException\n\t * @throws InvalidTokenOffsetsException thrown if any token's endOffset exceeds the provided text's length\n\t */\n\tpublic final TextFragment[] getBestTextFragments(\n\t\tTokenStream tokenStream,\n\t\tString text,\n\t\tboolean mergeContiguousFragments,\n\t\tint maxNumFragments)\n\t\tthrows IOException, InvalidTokenOffsetsException\n\t{\n\t\tArrayList docFrags = new ArrayList();\n\t\tStringBuffer newText=new StringBuffer();\n\n\t\tTextFragment currentFrag =\tnew TextFragment(newText,newText.length(), docFrags.size());\n\t\tfragmentScorer.startFragment(currentFrag);\n\t\tdocFrags.add(currentFrag);\n\n\t\tFragmentQueue fragQueue = new FragmentQueue(maxNumFragments);\n\n\t\ttry\n\t\t{\n                  final Token reusableToken = new Token();\n\t\t\tString tokenText;\n\t\t\tint startOffset;\n\t\t\tint endOffset;\n\t\t\tint lastEndOffset = 0;\n\t\t\ttextFragmenter.start(text);\n\n\t\t\tTokenGroup tokenGroup=new TokenGroup();\n\t\t\t\n\t\t\tfor (Token nextToken = tokenStream.next(reusableToken);\n\t\t\t     (nextToken!= null)&&(nextToken.startOffset()< maxDocCharsToAnalyze);\n\t\t\t     nextToken = tokenStream.next(reusableToken))\n\t\t\t{\n\t\t\t\tif(\t(nextToken.endOffset()>text.length())\n\t\t\t\t\t||\n\t\t\t\t\t(nextToken.startOffset()>text.length())\n\t\t\t\t\t)\t\t\t\t\t\t\n\t\t\t\t{\n\t\t\t\t\tthrow new InvalidTokenOffsetsException(\"Token \"+nextToken.toString()\n\t\t\t\t\t\t\t+\" exceeds length of provided text sized \"+text.length());\n\t\t\t\t}\n\t\t\t\tif((tokenGroup.numTokens>0)&&(tokenGroup.isDistinct(nextToken)))\n\t\t\t\t{\n\t\t\t\t\t//the current token is distinct from previous tokens -\n\t\t\t\t\t// markup the cached token group info\n\t\t\t\t\tstartOffset = tokenGroup.matchStartOffset;\n\t\t\t\t\tendOffset = tokenGroup.matchEndOffset;\n\t\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\t\tnewText.append(markedUpText);\n\t\t\t\t\tlastEndOffset=Math.max(endOffset, lastEndOffset);\n\t\t\t\t\ttokenGroup.clear();\n\n\t\t\t\t\t//check if current token marks the start of a new fragment\n\t\t\t\t\tif(textFragmenter.isNewFragment(nextToken))\n\t\t\t\t\t{\n\t\t\t\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\t\t\t\t\t\t//record stats for a new fragment\n\t\t\t\t\t\tcurrentFrag.textEndPos = newText.length();\n\t\t\t\t\t\tcurrentFrag =new TextFragment(newText, newText.length(), docFrags.size());\n\t\t\t\t\t\tfragmentScorer.startFragment(currentFrag);\n\t\t\t\t\t\tdocFrags.add(currentFrag);\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\ttokenGroup.addToken(nextToken,fragmentScorer.getTokenScore(nextToken));\n\n//\t\t\t\tif(lastEndOffset>maxDocBytesToAnalyze)\n//\t\t\t\t{\n//\t\t\t\t\tbreak;\n//\t\t\t\t}\n\t\t\t}\n\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\n\t\t\tif(tokenGroup.numTokens>0)\n\t\t\t{\n\t\t\t\t//flush the accumulated text (same code as in above loop)\n\t\t\t\tstartOffset = tokenGroup.matchStartOffset;\n\t\t\t\tendOffset = tokenGroup.matchEndOffset;\n\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\tnewText.append(markedUpText);\n\t\t\t\tlastEndOffset=Math.max(lastEndOffset,endOffset);\n\t\t\t}\n\n\t\t\t//Test what remains of the original text beyond the point where we stopped analyzing \n\t\t\tif (\n//\t\t\t\t\tif there is text beyond the last token considered..\n\t\t\t\t\t(lastEndOffset < text.length()) \n\t\t\t\t\t&&\n//\t\t\t\t\tand that text is not too large...\n\t\t\t\t\t(text.length()<= maxDocCharsToAnalyze)\n\t\t\t\t)\t\t\t\t\n\t\t\t{\n\t\t\t\t//append it to the last fragment\n\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset)));\n\t\t\t}\n\n\t\t\tcurrentFrag.textEndPos = newText.length();\n\n\t\t\t//sort the most relevant sections of the text\n\t\t\tfor (Iterator i = docFrags.iterator(); i.hasNext();)\n\t\t\t{\n\t\t\t\tcurrentFrag = (TextFragment) i.next();\n\n\t\t\t\t//If you are running with a version of Lucene before 11th Sept 03\n\t\t\t\t// you do not have PriorityQueue.insert() - so uncomment the code below\n\t\t\t\t/*\n\t\t\t\t\t\t\t\t\tif (currentFrag.getScore() >= minScore)\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tfragQueue.put(currentFrag);\n\t\t\t\t\t\t\t\t\t\tif (fragQueue.size() > maxNumFragments)\n\t\t\t\t\t\t\t\t\t\t{ // if hit queue overfull\n\t\t\t\t\t\t\t\t\t\t\tfragQueue.pop(); // remove lowest in hit queue\n\t\t\t\t\t\t\t\t\t\t\tminScore = ((TextFragment) fragQueue.top()).getScore(); // reset minScore\n\t\t\t\t\t\t\t\t\t\t}\n\n\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t*/\n\t\t\t\t//The above code caused a problem as a result of Christoph Goller's 11th Sept 03\n\t\t\t\t//fix to PriorityQueue. The correct method to use here is the new \"insert\" method\n\t\t\t\t// USE ABOVE CODE IF THIS DOES NOT COMPILE!\n\t\t\t\tfragQueue.insert(currentFrag);\n\t\t\t}\n\n\t\t\t//return the most relevant fragments\n\t\t\tTextFragment frag[] = new TextFragment[fragQueue.size()];\n\t\t\tfor (int i = frag.length - 1; i >= 0; i--)\n\t\t\t{\n\t\t\t\tfrag[i] = (TextFragment) fragQueue.pop();\n\t\t\t}\n\n\t\t\t//merge any contiguous fragments to improve readability\n\t\t\tif(mergeContiguousFragments)\n\t\t\t{\n\t\t\t\tmergeContiguousFragments(frag);\n\t\t\t\tArrayList fragTexts = new ArrayList();\n\t\t\t\tfor (int i = 0; i < frag.length; i++)\n\t\t\t\t{\n\t\t\t\t\tif ((frag[i] != null) && (frag[i].getScore() > 0))\n\t\t\t\t\t{\n\t\t\t\t\t\tfragTexts.add(frag[i]);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfrag= (TextFragment[]) fragTexts.toArray(new TextFragment[0]);\n\t\t\t}\n\n\t\t\treturn frag;\n\n\t\t}\n\t\tfinally\n\t\t{\n\t\t\tif (tokenStream != null)\n\t\t\t{\n\t\t\t\ttry\n\t\t\t\t{\n\t\t\t\t\ttokenStream.close();\n\t\t\t\t}\n\t\t\t\tcatch (Exception e)\n\t\t\t\t{\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"943c3f9cf96b8df37f4273d66a66182e2a669467","date":1249394171,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter#getBestTextFragments(TokenStream,String,boolean,int).mjava","pathOld":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter#getBestTextFragments(TokenStream,String,boolean,int).mjava","sourceNew":"\t/**\n\t * Low level api to get the most relevant (formatted) sections of the document.\n\t * This method has been made public to allow visibility of score information held in TextFragment objects.\n\t * Thanks to Jason Calabrese for help in redefining the interface.\n\t * @param tokenStream\n\t * @param text\n\t * @param maxNumFragments\n\t * @param mergeContiguousFragments\n\t * @throws IOException\n\t * @throws InvalidTokenOffsetsException thrown if any token's endOffset exceeds the provided text's length\n\t */\n\tpublic final TextFragment[] getBestTextFragments(\n\t\tTokenStream tokenStream,\n\t\tString text,\n\t\tboolean mergeContiguousFragments,\n\t\tint maxNumFragments)\n\t\tthrows IOException, InvalidTokenOffsetsException\n\t{\n\t\tArrayList docFrags = new ArrayList();\n\t\tStringBuffer newText=new StringBuffer();\n\t\t\n\t    TermAttribute termAtt = (TermAttribute) tokenStream.addAttribute(TermAttribute.class);\n\t    OffsetAttribute offsetAtt = (OffsetAttribute) tokenStream.addAttribute(OffsetAttribute.class);\n\t    tokenStream.addAttribute(PositionIncrementAttribute.class);\n\t    tokenStream.reset();\n\t    \n\t\tTextFragment currentFrag =\tnew TextFragment(newText,newText.length(), docFrags.size());\n\t\tTokenStream newStream = fragmentScorer.init(tokenStream);\n\t\tif(newStream != null) {\n\t\t  tokenStream = newStream;\n\t\t}\n\t\tfragmentScorer.startFragment(currentFrag);\n\t\tdocFrags.add(currentFrag);\n\n\t\tFragmentQueue fragQueue = new FragmentQueue(maxNumFragments);\n\n\t\ttry\n\t\t{\n\n\t\t\tString tokenText;\n\t\t\tint startOffset;\n\t\t\tint endOffset;\n\t\t\tint lastEndOffset = 0;\n\t\t\ttextFragmenter.start(text, tokenStream);\n\n\t\t\tTokenGroup tokenGroup=new TokenGroup(tokenStream);\n\n\t\t\tfor (boolean next = tokenStream.incrementToken(); next && (offsetAtt.startOffset()< maxDocCharsToAnalyze);\n\t\t\t      next = tokenStream.incrementToken())\n\t\t\t{\n\t\t\t\tif(\t(offsetAtt.endOffset()>text.length())\n\t\t\t\t\t||\n\t\t\t\t\t(offsetAtt.startOffset()>text.length())\n\t\t\t\t\t)\t\t\t\t\t\t\n\t\t\t\t{\n\t\t\t\t\tthrow new InvalidTokenOffsetsException(\"Token \"+ termAtt.term()\n\t\t\t\t\t\t\t+\" exceeds length of provided text sized \"+text.length());\n\t\t\t\t}\n\t\t\t\tif((tokenGroup.numTokens>0)&&(tokenGroup.isDistinct()))\n\t\t\t\t{\n\t\t\t\t\t//the current token is distinct from previous tokens -\n\t\t\t\t\t// markup the cached token group info\n\t\t\t\t\tstartOffset = tokenGroup.matchStartOffset;\n\t\t\t\t\tendOffset = tokenGroup.matchEndOffset;\n\t\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\t\tnewText.append(markedUpText);\n\t\t\t\t\tlastEndOffset=Math.max(endOffset, lastEndOffset);\n\t\t\t\t\ttokenGroup.clear();\n\n\t\t\t\t\t//check if current token marks the start of a new fragment\n\t\t\t\t\tif(textFragmenter.isNewFragment())\n\t\t\t\t\t{\n\t\t\t\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\t\t\t\t\t\t//record stats for a new fragment\n\t\t\t\t\t\tcurrentFrag.textEndPos = newText.length();\n\t\t\t\t\t\tcurrentFrag =new TextFragment(newText, newText.length(), docFrags.size());\n\t\t\t\t\t\tfragmentScorer.startFragment(currentFrag);\n\t\t\t\t\t\tdocFrags.add(currentFrag);\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\ttokenGroup.addToken(fragmentScorer.getTokenScore());\n\n//\t\t\t\tif(lastEndOffset>maxDocBytesToAnalyze)\n//\t\t\t\t{\n//\t\t\t\t\tbreak;\n//\t\t\t\t}\n\t\t\t}\n\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\n\t\t\tif(tokenGroup.numTokens>0)\n\t\t\t{\n\t\t\t\t//flush the accumulated text (same code as in above loop)\n\t\t\t\tstartOffset = tokenGroup.matchStartOffset;\n\t\t\t\tendOffset = tokenGroup.matchEndOffset;\n\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\tnewText.append(markedUpText);\n\t\t\t\tlastEndOffset=Math.max(lastEndOffset,endOffset);\n\t\t\t}\n\n\t\t\t//Test what remains of the original text beyond the point where we stopped analyzing \n\t\t\tif (\n//\t\t\t\t\tif there is text beyond the last token considered..\n\t\t\t\t\t(lastEndOffset < text.length()) \n\t\t\t\t\t&&\n//\t\t\t\t\tand that text is not too large...\n\t\t\t\t\t(text.length()<= maxDocCharsToAnalyze)\n\t\t\t\t)\t\t\t\t\n\t\t\t{\n\t\t\t\t//append it to the last fragment\n\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset)));\n\t\t\t}\n\n\t\t\tcurrentFrag.textEndPos = newText.length();\n\n\t\t\t//sort the most relevant sections of the text\n\t\t\tfor (Iterator i = docFrags.iterator(); i.hasNext();)\n\t\t\t{\n\t\t\t\tcurrentFrag = (TextFragment) i.next();\n\n\t\t\t\t//If you are running with a version of Lucene before 11th Sept 03\n\t\t\t\t// you do not have PriorityQueue.insert() - so uncomment the code below\n\t\t\t\t/*\n\t\t\t\t\t\t\t\t\tif (currentFrag.getScore() >= minScore)\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tfragQueue.put(currentFrag);\n\t\t\t\t\t\t\t\t\t\tif (fragQueue.size() > maxNumFragments)\n\t\t\t\t\t\t\t\t\t\t{ // if hit queue overfull\n\t\t\t\t\t\t\t\t\t\t\tfragQueue.pop(); // remove lowest in hit queue\n\t\t\t\t\t\t\t\t\t\t\tminScore = ((TextFragment) fragQueue.top()).getScore(); // reset minScore\n\t\t\t\t\t\t\t\t\t\t}\n\n\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t*/\n\t\t\t\t//The above code caused a problem as a result of Christoph Goller's 11th Sept 03\n\t\t\t\t//fix to PriorityQueue. The correct method to use here is the new \"insert\" method\n\t\t\t\t// USE ABOVE CODE IF THIS DOES NOT COMPILE!\n\t\t\t\tfragQueue.insertWithOverflow(currentFrag);\n\t\t\t}\n\n\t\t\t//return the most relevant fragments\n\t\t\tTextFragment frag[] = new TextFragment[fragQueue.size()];\n\t\t\tfor (int i = frag.length - 1; i >= 0; i--)\n\t\t\t{\n\t\t\t\tfrag[i] = (TextFragment) fragQueue.pop();\n\t\t\t}\n\n\t\t\t//merge any contiguous fragments to improve readability\n\t\t\tif(mergeContiguousFragments)\n\t\t\t{\n\t\t\t\tmergeContiguousFragments(frag);\n\t\t\t\tArrayList fragTexts = new ArrayList();\n\t\t\t\tfor (int i = 0; i < frag.length; i++)\n\t\t\t\t{\n\t\t\t\t\tif ((frag[i] != null) && (frag[i].getScore() > 0))\n\t\t\t\t\t{\n\t\t\t\t\t\tfragTexts.add(frag[i]);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfrag= (TextFragment[]) fragTexts.toArray(new TextFragment[0]);\n\t\t\t}\n\n\t\t\treturn frag;\n\n\t\t}\n\t\tfinally\n\t\t{\n\t\t\tif (tokenStream != null)\n\t\t\t{\n\t\t\t\ttry\n\t\t\t\t{\n\t\t\t\t\ttokenStream.close();\n\t\t\t\t}\n\t\t\t\tcatch (Exception e)\n\t\t\t\t{\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n","sourceOld":"\t/**\n\t * Low level api to get the most relevant (formatted) sections of the document.\n\t * This method has been made public to allow visibility of score information held in TextFragment objects.\n\t * Thanks to Jason Calabrese for help in redefining the interface.\n\t * @param tokenStream\n\t * @param text\n\t * @param maxNumFragments\n\t * @param mergeContiguousFragments\n\t * @throws IOException\n\t * @throws InvalidTokenOffsetsException thrown if any token's endOffset exceeds the provided text's length\n\t */\n\tpublic final TextFragment[] getBestTextFragments(\n\t\tTokenStream tokenStream,\n\t\tString text,\n\t\tboolean mergeContiguousFragments,\n\t\tint maxNumFragments)\n\t\tthrows IOException, InvalidTokenOffsetsException\n\t{\n\t\tArrayList docFrags = new ArrayList();\n\t\tStringBuffer newText=new StringBuffer();\n\t\t\n\t    TermAttribute termAtt = (TermAttribute) tokenStream.addAttribute(TermAttribute.class);\n\t    OffsetAttribute offsetAtt = (OffsetAttribute) tokenStream.addAttribute(OffsetAttribute.class);\n\t    tokenStream.addAttribute(PositionIncrementAttribute.class);\n\t    tokenStream.reset();\n\t    \n\t\tTextFragment currentFrag =\tnew TextFragment(newText,newText.length(), docFrags.size());\n\t\tfragmentScorer.init(tokenStream);\n\t\tfragmentScorer.startFragment(currentFrag);\n\t\tdocFrags.add(currentFrag);\n\n\t\tFragmentQueue fragQueue = new FragmentQueue(maxNumFragments);\n\n\t\ttry\n\t\t{\n\n\t\t\tString tokenText;\n\t\t\tint startOffset;\n\t\t\tint endOffset;\n\t\t\tint lastEndOffset = 0;\n\t\t\ttextFragmenter.start(text, tokenStream);\n\n\t\t\tTokenGroup tokenGroup=new TokenGroup(tokenStream);\n\n\t\t\tfor (boolean next = tokenStream.incrementToken(); next && (offsetAtt.startOffset()< maxDocCharsToAnalyze);\n\t\t\t      next = tokenStream.incrementToken())\n\t\t\t{\n\t\t\t\tif(\t(offsetAtt.endOffset()>text.length())\n\t\t\t\t\t||\n\t\t\t\t\t(offsetAtt.startOffset()>text.length())\n\t\t\t\t\t)\t\t\t\t\t\t\n\t\t\t\t{\n\t\t\t\t\tthrow new InvalidTokenOffsetsException(\"Token \"+ termAtt.term()\n\t\t\t\t\t\t\t+\" exceeds length of provided text sized \"+text.length());\n\t\t\t\t}\n\t\t\t\tif((tokenGroup.numTokens>0)&&(tokenGroup.isDistinct()))\n\t\t\t\t{\n\t\t\t\t\t//the current token is distinct from previous tokens -\n\t\t\t\t\t// markup the cached token group info\n\t\t\t\t\tstartOffset = tokenGroup.matchStartOffset;\n\t\t\t\t\tendOffset = tokenGroup.matchEndOffset;\n\t\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\t\tnewText.append(markedUpText);\n\t\t\t\t\tlastEndOffset=Math.max(endOffset, lastEndOffset);\n\t\t\t\t\ttokenGroup.clear();\n\n\t\t\t\t\t//check if current token marks the start of a new fragment\n\t\t\t\t\tif(textFragmenter.isNewFragment())\n\t\t\t\t\t{\n\t\t\t\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\t\t\t\t\t\t//record stats for a new fragment\n\t\t\t\t\t\tcurrentFrag.textEndPos = newText.length();\n\t\t\t\t\t\tcurrentFrag =new TextFragment(newText, newText.length(), docFrags.size());\n\t\t\t\t\t\tfragmentScorer.startFragment(currentFrag);\n\t\t\t\t\t\tdocFrags.add(currentFrag);\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\ttokenGroup.addToken(fragmentScorer.getTokenScore());\n\n//\t\t\t\tif(lastEndOffset>maxDocBytesToAnalyze)\n//\t\t\t\t{\n//\t\t\t\t\tbreak;\n//\t\t\t\t}\n\t\t\t}\n\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\n\t\t\tif(tokenGroup.numTokens>0)\n\t\t\t{\n\t\t\t\t//flush the accumulated text (same code as in above loop)\n\t\t\t\tstartOffset = tokenGroup.matchStartOffset;\n\t\t\t\tendOffset = tokenGroup.matchEndOffset;\n\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\tnewText.append(markedUpText);\n\t\t\t\tlastEndOffset=Math.max(lastEndOffset,endOffset);\n\t\t\t}\n\n\t\t\t//Test what remains of the original text beyond the point where we stopped analyzing \n\t\t\tif (\n//\t\t\t\t\tif there is text beyond the last token considered..\n\t\t\t\t\t(lastEndOffset < text.length()) \n\t\t\t\t\t&&\n//\t\t\t\t\tand that text is not too large...\n\t\t\t\t\t(text.length()<= maxDocCharsToAnalyze)\n\t\t\t\t)\t\t\t\t\n\t\t\t{\n\t\t\t\t//append it to the last fragment\n\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset)));\n\t\t\t}\n\n\t\t\tcurrentFrag.textEndPos = newText.length();\n\n\t\t\t//sort the most relevant sections of the text\n\t\t\tfor (Iterator i = docFrags.iterator(); i.hasNext();)\n\t\t\t{\n\t\t\t\tcurrentFrag = (TextFragment) i.next();\n\n\t\t\t\t//If you are running with a version of Lucene before 11th Sept 03\n\t\t\t\t// you do not have PriorityQueue.insert() - so uncomment the code below\n\t\t\t\t/*\n\t\t\t\t\t\t\t\t\tif (currentFrag.getScore() >= minScore)\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tfragQueue.put(currentFrag);\n\t\t\t\t\t\t\t\t\t\tif (fragQueue.size() > maxNumFragments)\n\t\t\t\t\t\t\t\t\t\t{ // if hit queue overfull\n\t\t\t\t\t\t\t\t\t\t\tfragQueue.pop(); // remove lowest in hit queue\n\t\t\t\t\t\t\t\t\t\t\tminScore = ((TextFragment) fragQueue.top()).getScore(); // reset minScore\n\t\t\t\t\t\t\t\t\t\t}\n\n\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t*/\n\t\t\t\t//The above code caused a problem as a result of Christoph Goller's 11th Sept 03\n\t\t\t\t//fix to PriorityQueue. The correct method to use here is the new \"insert\" method\n\t\t\t\t// USE ABOVE CODE IF THIS DOES NOT COMPILE!\n\t\t\t\tfragQueue.insertWithOverflow(currentFrag);\n\t\t\t}\n\n\t\t\t//return the most relevant fragments\n\t\t\tTextFragment frag[] = new TextFragment[fragQueue.size()];\n\t\t\tfor (int i = frag.length - 1; i >= 0; i--)\n\t\t\t{\n\t\t\t\tfrag[i] = (TextFragment) fragQueue.pop();\n\t\t\t}\n\n\t\t\t//merge any contiguous fragments to improve readability\n\t\t\tif(mergeContiguousFragments)\n\t\t\t{\n\t\t\t\tmergeContiguousFragments(frag);\n\t\t\t\tArrayList fragTexts = new ArrayList();\n\t\t\t\tfor (int i = 0; i < frag.length; i++)\n\t\t\t\t{\n\t\t\t\t\tif ((frag[i] != null) && (frag[i].getScore() > 0))\n\t\t\t\t\t{\n\t\t\t\t\t\tfragTexts.add(frag[i]);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfrag= (TextFragment[]) fragTexts.toArray(new TextFragment[0]);\n\t\t\t}\n\n\t\t\treturn frag;\n\n\t\t}\n\t\tfinally\n\t\t{\n\t\t\tif (tokenStream != null)\n\t\t\t{\n\t\t\t\ttry\n\t\t\t\t{\n\t\t\t\t\ttokenStream.close();\n\t\t\t\t}\n\t\t\t\tcatch (Exception e)\n\t\t\t\t{\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8d78f014fded44fbde905f4f84cdc21907b371e8","date":1254383623,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter#getBestTextFragments(TokenStream,String,boolean,int).mjava","pathOld":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter#getBestTextFragments(TokenStream,String,boolean,int).mjava","sourceNew":"\t/**\n\t * Low level api to get the most relevant (formatted) sections of the document.\n\t * This method has been made public to allow visibility of score information held in TextFragment objects.\n\t * Thanks to Jason Calabrese for help in redefining the interface.\n\t * @param tokenStream\n\t * @param text\n\t * @param maxNumFragments\n\t * @param mergeContiguousFragments\n\t * @throws IOException\n\t * @throws InvalidTokenOffsetsException thrown if any token's endOffset exceeds the provided text's length\n\t */\n\tpublic final TextFragment[] getBestTextFragments(\n\t\tTokenStream tokenStream,\n\t\tString text,\n\t\tboolean mergeContiguousFragments,\n\t\tint maxNumFragments)\n\t\tthrows IOException, InvalidTokenOffsetsException\n\t{\n\t\tArrayList docFrags = new ArrayList();\n\t\tStringBuffer newText=new StringBuffer();\n\t\t\n\t    TermAttribute termAtt = tokenStream.addAttribute(TermAttribute.class);\n\t    OffsetAttribute offsetAtt = tokenStream.addAttribute(OffsetAttribute.class);\n\t    tokenStream.addAttribute(PositionIncrementAttribute.class);\n\t    tokenStream.reset();\n\t    \n\t\tTextFragment currentFrag =\tnew TextFragment(newText,newText.length(), docFrags.size());\n\t\tTokenStream newStream = fragmentScorer.init(tokenStream);\n\t\tif(newStream != null) {\n\t\t  tokenStream = newStream;\n\t\t}\n\t\tfragmentScorer.startFragment(currentFrag);\n\t\tdocFrags.add(currentFrag);\n\n\t\tFragmentQueue fragQueue = new FragmentQueue(maxNumFragments);\n\n\t\ttry\n\t\t{\n\n\t\t\tString tokenText;\n\t\t\tint startOffset;\n\t\t\tint endOffset;\n\t\t\tint lastEndOffset = 0;\n\t\t\ttextFragmenter.start(text, tokenStream);\n\n\t\t\tTokenGroup tokenGroup=new TokenGroup(tokenStream);\n\n\t\t\tfor (boolean next = tokenStream.incrementToken(); next && (offsetAtt.startOffset()< maxDocCharsToAnalyze);\n\t\t\t      next = tokenStream.incrementToken())\n\t\t\t{\n\t\t\t\tif(\t(offsetAtt.endOffset()>text.length())\n\t\t\t\t\t||\n\t\t\t\t\t(offsetAtt.startOffset()>text.length())\n\t\t\t\t\t)\t\t\t\t\t\t\n\t\t\t\t{\n\t\t\t\t\tthrow new InvalidTokenOffsetsException(\"Token \"+ termAtt.term()\n\t\t\t\t\t\t\t+\" exceeds length of provided text sized \"+text.length());\n\t\t\t\t}\n\t\t\t\tif((tokenGroup.numTokens>0)&&(tokenGroup.isDistinct()))\n\t\t\t\t{\n\t\t\t\t\t//the current token is distinct from previous tokens -\n\t\t\t\t\t// markup the cached token group info\n\t\t\t\t\tstartOffset = tokenGroup.matchStartOffset;\n\t\t\t\t\tendOffset = tokenGroup.matchEndOffset;\n\t\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\t\tnewText.append(markedUpText);\n\t\t\t\t\tlastEndOffset=Math.max(endOffset, lastEndOffset);\n\t\t\t\t\ttokenGroup.clear();\n\n\t\t\t\t\t//check if current token marks the start of a new fragment\n\t\t\t\t\tif(textFragmenter.isNewFragment())\n\t\t\t\t\t{\n\t\t\t\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\t\t\t\t\t\t//record stats for a new fragment\n\t\t\t\t\t\tcurrentFrag.textEndPos = newText.length();\n\t\t\t\t\t\tcurrentFrag =new TextFragment(newText, newText.length(), docFrags.size());\n\t\t\t\t\t\tfragmentScorer.startFragment(currentFrag);\n\t\t\t\t\t\tdocFrags.add(currentFrag);\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\ttokenGroup.addToken(fragmentScorer.getTokenScore());\n\n//\t\t\t\tif(lastEndOffset>maxDocBytesToAnalyze)\n//\t\t\t\t{\n//\t\t\t\t\tbreak;\n//\t\t\t\t}\n\t\t\t}\n\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\n\t\t\tif(tokenGroup.numTokens>0)\n\t\t\t{\n\t\t\t\t//flush the accumulated text (same code as in above loop)\n\t\t\t\tstartOffset = tokenGroup.matchStartOffset;\n\t\t\t\tendOffset = tokenGroup.matchEndOffset;\n\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\tnewText.append(markedUpText);\n\t\t\t\tlastEndOffset=Math.max(lastEndOffset,endOffset);\n\t\t\t}\n\n\t\t\t//Test what remains of the original text beyond the point where we stopped analyzing \n\t\t\tif (\n//\t\t\t\t\tif there is text beyond the last token considered..\n\t\t\t\t\t(lastEndOffset < text.length()) \n\t\t\t\t\t&&\n//\t\t\t\t\tand that text is not too large...\n\t\t\t\t\t(text.length()<= maxDocCharsToAnalyze)\n\t\t\t\t)\t\t\t\t\n\t\t\t{\n\t\t\t\t//append it to the last fragment\n\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset)));\n\t\t\t}\n\n\t\t\tcurrentFrag.textEndPos = newText.length();\n\n\t\t\t//sort the most relevant sections of the text\n\t\t\tfor (Iterator i = docFrags.iterator(); i.hasNext();)\n\t\t\t{\n\t\t\t\tcurrentFrag = (TextFragment) i.next();\n\n\t\t\t\t//If you are running with a version of Lucene before 11th Sept 03\n\t\t\t\t// you do not have PriorityQueue.insert() - so uncomment the code below\n\t\t\t\t/*\n\t\t\t\t\t\t\t\t\tif (currentFrag.getScore() >= minScore)\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tfragQueue.put(currentFrag);\n\t\t\t\t\t\t\t\t\t\tif (fragQueue.size() > maxNumFragments)\n\t\t\t\t\t\t\t\t\t\t{ // if hit queue overfull\n\t\t\t\t\t\t\t\t\t\t\tfragQueue.pop(); // remove lowest in hit queue\n\t\t\t\t\t\t\t\t\t\t\tminScore = ((TextFragment) fragQueue.top()).getScore(); // reset minScore\n\t\t\t\t\t\t\t\t\t\t}\n\n\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t*/\n\t\t\t\t//The above code caused a problem as a result of Christoph Goller's 11th Sept 03\n\t\t\t\t//fix to PriorityQueue. The correct method to use here is the new \"insert\" method\n\t\t\t\t// USE ABOVE CODE IF THIS DOES NOT COMPILE!\n\t\t\t\tfragQueue.insertWithOverflow(currentFrag);\n\t\t\t}\n\n\t\t\t//return the most relevant fragments\n\t\t\tTextFragment frag[] = new TextFragment[fragQueue.size()];\n\t\t\tfor (int i = frag.length - 1; i >= 0; i--)\n\t\t\t{\n\t\t\t\tfrag[i] = (TextFragment) fragQueue.pop();\n\t\t\t}\n\n\t\t\t//merge any contiguous fragments to improve readability\n\t\t\tif(mergeContiguousFragments)\n\t\t\t{\n\t\t\t\tmergeContiguousFragments(frag);\n\t\t\t\tArrayList fragTexts = new ArrayList();\n\t\t\t\tfor (int i = 0; i < frag.length; i++)\n\t\t\t\t{\n\t\t\t\t\tif ((frag[i] != null) && (frag[i].getScore() > 0))\n\t\t\t\t\t{\n\t\t\t\t\t\tfragTexts.add(frag[i]);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfrag= (TextFragment[]) fragTexts.toArray(new TextFragment[0]);\n\t\t\t}\n\n\t\t\treturn frag;\n\n\t\t}\n\t\tfinally\n\t\t{\n\t\t\tif (tokenStream != null)\n\t\t\t{\n\t\t\t\ttry\n\t\t\t\t{\n\t\t\t\t\ttokenStream.close();\n\t\t\t\t}\n\t\t\t\tcatch (Exception e)\n\t\t\t\t{\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n","sourceOld":"\t/**\n\t * Low level api to get the most relevant (formatted) sections of the document.\n\t * This method has been made public to allow visibility of score information held in TextFragment objects.\n\t * Thanks to Jason Calabrese for help in redefining the interface.\n\t * @param tokenStream\n\t * @param text\n\t * @param maxNumFragments\n\t * @param mergeContiguousFragments\n\t * @throws IOException\n\t * @throws InvalidTokenOffsetsException thrown if any token's endOffset exceeds the provided text's length\n\t */\n\tpublic final TextFragment[] getBestTextFragments(\n\t\tTokenStream tokenStream,\n\t\tString text,\n\t\tboolean mergeContiguousFragments,\n\t\tint maxNumFragments)\n\t\tthrows IOException, InvalidTokenOffsetsException\n\t{\n\t\tArrayList docFrags = new ArrayList();\n\t\tStringBuffer newText=new StringBuffer();\n\t\t\n\t    TermAttribute termAtt = (TermAttribute) tokenStream.addAttribute(TermAttribute.class);\n\t    OffsetAttribute offsetAtt = (OffsetAttribute) tokenStream.addAttribute(OffsetAttribute.class);\n\t    tokenStream.addAttribute(PositionIncrementAttribute.class);\n\t    tokenStream.reset();\n\t    \n\t\tTextFragment currentFrag =\tnew TextFragment(newText,newText.length(), docFrags.size());\n\t\tTokenStream newStream = fragmentScorer.init(tokenStream);\n\t\tif(newStream != null) {\n\t\t  tokenStream = newStream;\n\t\t}\n\t\tfragmentScorer.startFragment(currentFrag);\n\t\tdocFrags.add(currentFrag);\n\n\t\tFragmentQueue fragQueue = new FragmentQueue(maxNumFragments);\n\n\t\ttry\n\t\t{\n\n\t\t\tString tokenText;\n\t\t\tint startOffset;\n\t\t\tint endOffset;\n\t\t\tint lastEndOffset = 0;\n\t\t\ttextFragmenter.start(text, tokenStream);\n\n\t\t\tTokenGroup tokenGroup=new TokenGroup(tokenStream);\n\n\t\t\tfor (boolean next = tokenStream.incrementToken(); next && (offsetAtt.startOffset()< maxDocCharsToAnalyze);\n\t\t\t      next = tokenStream.incrementToken())\n\t\t\t{\n\t\t\t\tif(\t(offsetAtt.endOffset()>text.length())\n\t\t\t\t\t||\n\t\t\t\t\t(offsetAtt.startOffset()>text.length())\n\t\t\t\t\t)\t\t\t\t\t\t\n\t\t\t\t{\n\t\t\t\t\tthrow new InvalidTokenOffsetsException(\"Token \"+ termAtt.term()\n\t\t\t\t\t\t\t+\" exceeds length of provided text sized \"+text.length());\n\t\t\t\t}\n\t\t\t\tif((tokenGroup.numTokens>0)&&(tokenGroup.isDistinct()))\n\t\t\t\t{\n\t\t\t\t\t//the current token is distinct from previous tokens -\n\t\t\t\t\t// markup the cached token group info\n\t\t\t\t\tstartOffset = tokenGroup.matchStartOffset;\n\t\t\t\t\tendOffset = tokenGroup.matchEndOffset;\n\t\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\t\tnewText.append(markedUpText);\n\t\t\t\t\tlastEndOffset=Math.max(endOffset, lastEndOffset);\n\t\t\t\t\ttokenGroup.clear();\n\n\t\t\t\t\t//check if current token marks the start of a new fragment\n\t\t\t\t\tif(textFragmenter.isNewFragment())\n\t\t\t\t\t{\n\t\t\t\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\t\t\t\t\t\t//record stats for a new fragment\n\t\t\t\t\t\tcurrentFrag.textEndPos = newText.length();\n\t\t\t\t\t\tcurrentFrag =new TextFragment(newText, newText.length(), docFrags.size());\n\t\t\t\t\t\tfragmentScorer.startFragment(currentFrag);\n\t\t\t\t\t\tdocFrags.add(currentFrag);\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\ttokenGroup.addToken(fragmentScorer.getTokenScore());\n\n//\t\t\t\tif(lastEndOffset>maxDocBytesToAnalyze)\n//\t\t\t\t{\n//\t\t\t\t\tbreak;\n//\t\t\t\t}\n\t\t\t}\n\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\n\t\t\tif(tokenGroup.numTokens>0)\n\t\t\t{\n\t\t\t\t//flush the accumulated text (same code as in above loop)\n\t\t\t\tstartOffset = tokenGroup.matchStartOffset;\n\t\t\t\tendOffset = tokenGroup.matchEndOffset;\n\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\tnewText.append(markedUpText);\n\t\t\t\tlastEndOffset=Math.max(lastEndOffset,endOffset);\n\t\t\t}\n\n\t\t\t//Test what remains of the original text beyond the point where we stopped analyzing \n\t\t\tif (\n//\t\t\t\t\tif there is text beyond the last token considered..\n\t\t\t\t\t(lastEndOffset < text.length()) \n\t\t\t\t\t&&\n//\t\t\t\t\tand that text is not too large...\n\t\t\t\t\t(text.length()<= maxDocCharsToAnalyze)\n\t\t\t\t)\t\t\t\t\n\t\t\t{\n\t\t\t\t//append it to the last fragment\n\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset)));\n\t\t\t}\n\n\t\t\tcurrentFrag.textEndPos = newText.length();\n\n\t\t\t//sort the most relevant sections of the text\n\t\t\tfor (Iterator i = docFrags.iterator(); i.hasNext();)\n\t\t\t{\n\t\t\t\tcurrentFrag = (TextFragment) i.next();\n\n\t\t\t\t//If you are running with a version of Lucene before 11th Sept 03\n\t\t\t\t// you do not have PriorityQueue.insert() - so uncomment the code below\n\t\t\t\t/*\n\t\t\t\t\t\t\t\t\tif (currentFrag.getScore() >= minScore)\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tfragQueue.put(currentFrag);\n\t\t\t\t\t\t\t\t\t\tif (fragQueue.size() > maxNumFragments)\n\t\t\t\t\t\t\t\t\t\t{ // if hit queue overfull\n\t\t\t\t\t\t\t\t\t\t\tfragQueue.pop(); // remove lowest in hit queue\n\t\t\t\t\t\t\t\t\t\t\tminScore = ((TextFragment) fragQueue.top()).getScore(); // reset minScore\n\t\t\t\t\t\t\t\t\t\t}\n\n\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t*/\n\t\t\t\t//The above code caused a problem as a result of Christoph Goller's 11th Sept 03\n\t\t\t\t//fix to PriorityQueue. The correct method to use here is the new \"insert\" method\n\t\t\t\t// USE ABOVE CODE IF THIS DOES NOT COMPILE!\n\t\t\t\tfragQueue.insertWithOverflow(currentFrag);\n\t\t\t}\n\n\t\t\t//return the most relevant fragments\n\t\t\tTextFragment frag[] = new TextFragment[fragQueue.size()];\n\t\t\tfor (int i = frag.length - 1; i >= 0; i--)\n\t\t\t{\n\t\t\t\tfrag[i] = (TextFragment) fragQueue.pop();\n\t\t\t}\n\n\t\t\t//merge any contiguous fragments to improve readability\n\t\t\tif(mergeContiguousFragments)\n\t\t\t{\n\t\t\t\tmergeContiguousFragments(frag);\n\t\t\t\tArrayList fragTexts = new ArrayList();\n\t\t\t\tfor (int i = 0; i < frag.length; i++)\n\t\t\t\t{\n\t\t\t\t\tif ((frag[i] != null) && (frag[i].getScore() > 0))\n\t\t\t\t\t{\n\t\t\t\t\t\tfragTexts.add(frag[i]);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfrag= (TextFragment[]) fragTexts.toArray(new TextFragment[0]);\n\t\t\t}\n\n\t\t\treturn frag;\n\n\t\t}\n\t\tfinally\n\t\t{\n\t\t\tif (tokenStream != null)\n\t\t\t{\n\t\t\t\ttry\n\t\t\t\t{\n\t\t\t\t\ttokenStream.close();\n\t\t\t\t}\n\t\t\t\tcatch (Exception e)\n\t\t\t\t{\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4625cb7ffd7c9caaf2d62b206ba9a382d68da82c","date":1254521470,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter#getBestTextFragments(TokenStream,String,boolean,int).mjava","pathOld":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter#getBestTextFragments(TokenStream,String,boolean,int).mjava","sourceNew":"\t/**\n\t * Low level api to get the most relevant (formatted) sections of the document.\n\t * This method has been made public to allow visibility of score information held in TextFragment objects.\n\t * Thanks to Jason Calabrese for help in redefining the interface.\n\t * @param tokenStream\n\t * @param text\n\t * @param maxNumFragments\n\t * @param mergeContiguousFragments\n\t * @throws IOException\n\t * @throws InvalidTokenOffsetsException thrown if any token's endOffset exceeds the provided text's length\n\t */\n\tpublic final TextFragment[] getBestTextFragments(\n\t\tTokenStream tokenStream,\n\t\tString text,\n\t\tboolean mergeContiguousFragments,\n\t\tint maxNumFragments)\n\t\tthrows IOException, InvalidTokenOffsetsException\n\t{\n\t\tArrayList docFrags = new ArrayList();\n\t\tStringBuilder newText=new StringBuilder();\n\t\t\n\t    TermAttribute termAtt = tokenStream.addAttribute(TermAttribute.class);\n\t    OffsetAttribute offsetAtt = tokenStream.addAttribute(OffsetAttribute.class);\n\t    tokenStream.addAttribute(PositionIncrementAttribute.class);\n\t    tokenStream.reset();\n\t    \n\t\tTextFragment currentFrag =\tnew TextFragment(newText,newText.length(), docFrags.size());\n\t\tTokenStream newStream = fragmentScorer.init(tokenStream);\n\t\tif(newStream != null) {\n\t\t  tokenStream = newStream;\n\t\t}\n\t\tfragmentScorer.startFragment(currentFrag);\n\t\tdocFrags.add(currentFrag);\n\n\t\tFragmentQueue fragQueue = new FragmentQueue(maxNumFragments);\n\n\t\ttry\n\t\t{\n\n\t\t\tString tokenText;\n\t\t\tint startOffset;\n\t\t\tint endOffset;\n\t\t\tint lastEndOffset = 0;\n\t\t\ttextFragmenter.start(text, tokenStream);\n\n\t\t\tTokenGroup tokenGroup=new TokenGroup(tokenStream);\n\n\t\t\tfor (boolean next = tokenStream.incrementToken(); next && (offsetAtt.startOffset()< maxDocCharsToAnalyze);\n\t\t\t      next = tokenStream.incrementToken())\n\t\t\t{\n\t\t\t\tif(\t(offsetAtt.endOffset()>text.length())\n\t\t\t\t\t||\n\t\t\t\t\t(offsetAtt.startOffset()>text.length())\n\t\t\t\t\t)\t\t\t\t\t\t\n\t\t\t\t{\n\t\t\t\t\tthrow new InvalidTokenOffsetsException(\"Token \"+ termAtt.term()\n\t\t\t\t\t\t\t+\" exceeds length of provided text sized \"+text.length());\n\t\t\t\t}\n\t\t\t\tif((tokenGroup.numTokens>0)&&(tokenGroup.isDistinct()))\n\t\t\t\t{\n\t\t\t\t\t//the current token is distinct from previous tokens -\n\t\t\t\t\t// markup the cached token group info\n\t\t\t\t\tstartOffset = tokenGroup.matchStartOffset;\n\t\t\t\t\tendOffset = tokenGroup.matchEndOffset;\n\t\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\t\tnewText.append(markedUpText);\n\t\t\t\t\tlastEndOffset=Math.max(endOffset, lastEndOffset);\n\t\t\t\t\ttokenGroup.clear();\n\n\t\t\t\t\t//check if current token marks the start of a new fragment\n\t\t\t\t\tif(textFragmenter.isNewFragment())\n\t\t\t\t\t{\n\t\t\t\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\t\t\t\t\t\t//record stats for a new fragment\n\t\t\t\t\t\tcurrentFrag.textEndPos = newText.length();\n\t\t\t\t\t\tcurrentFrag =new TextFragment(newText, newText.length(), docFrags.size());\n\t\t\t\t\t\tfragmentScorer.startFragment(currentFrag);\n\t\t\t\t\t\tdocFrags.add(currentFrag);\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\ttokenGroup.addToken(fragmentScorer.getTokenScore());\n\n//\t\t\t\tif(lastEndOffset>maxDocBytesToAnalyze)\n//\t\t\t\t{\n//\t\t\t\t\tbreak;\n//\t\t\t\t}\n\t\t\t}\n\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\n\t\t\tif(tokenGroup.numTokens>0)\n\t\t\t{\n\t\t\t\t//flush the accumulated text (same code as in above loop)\n\t\t\t\tstartOffset = tokenGroup.matchStartOffset;\n\t\t\t\tendOffset = tokenGroup.matchEndOffset;\n\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\tnewText.append(markedUpText);\n\t\t\t\tlastEndOffset=Math.max(lastEndOffset,endOffset);\n\t\t\t}\n\n\t\t\t//Test what remains of the original text beyond the point where we stopped analyzing \n\t\t\tif (\n//\t\t\t\t\tif there is text beyond the last token considered..\n\t\t\t\t\t(lastEndOffset < text.length()) \n\t\t\t\t\t&&\n//\t\t\t\t\tand that text is not too large...\n\t\t\t\t\t(text.length()<= maxDocCharsToAnalyze)\n\t\t\t\t)\t\t\t\t\n\t\t\t{\n\t\t\t\t//append it to the last fragment\n\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset)));\n\t\t\t}\n\n\t\t\tcurrentFrag.textEndPos = newText.length();\n\n\t\t\t//sort the most relevant sections of the text\n\t\t\tfor (Iterator i = docFrags.iterator(); i.hasNext();)\n\t\t\t{\n\t\t\t\tcurrentFrag = (TextFragment) i.next();\n\n\t\t\t\t//If you are running with a version of Lucene before 11th Sept 03\n\t\t\t\t// you do not have PriorityQueue.insert() - so uncomment the code below\n\t\t\t\t/*\n\t\t\t\t\t\t\t\t\tif (currentFrag.getScore() >= minScore)\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tfragQueue.put(currentFrag);\n\t\t\t\t\t\t\t\t\t\tif (fragQueue.size() > maxNumFragments)\n\t\t\t\t\t\t\t\t\t\t{ // if hit queue overfull\n\t\t\t\t\t\t\t\t\t\t\tfragQueue.pop(); // remove lowest in hit queue\n\t\t\t\t\t\t\t\t\t\t\tminScore = ((TextFragment) fragQueue.top()).getScore(); // reset minScore\n\t\t\t\t\t\t\t\t\t\t}\n\n\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t*/\n\t\t\t\t//The above code caused a problem as a result of Christoph Goller's 11th Sept 03\n\t\t\t\t//fix to PriorityQueue. The correct method to use here is the new \"insert\" method\n\t\t\t\t// USE ABOVE CODE IF THIS DOES NOT COMPILE!\n\t\t\t\tfragQueue.insertWithOverflow(currentFrag);\n\t\t\t}\n\n\t\t\t//return the most relevant fragments\n\t\t\tTextFragment frag[] = new TextFragment[fragQueue.size()];\n\t\t\tfor (int i = frag.length - 1; i >= 0; i--)\n\t\t\t{\n\t\t\t\tfrag[i] = (TextFragment) fragQueue.pop();\n\t\t\t}\n\n\t\t\t//merge any contiguous fragments to improve readability\n\t\t\tif(mergeContiguousFragments)\n\t\t\t{\n\t\t\t\tmergeContiguousFragments(frag);\n\t\t\t\tArrayList fragTexts = new ArrayList();\n\t\t\t\tfor (int i = 0; i < frag.length; i++)\n\t\t\t\t{\n\t\t\t\t\tif ((frag[i] != null) && (frag[i].getScore() > 0))\n\t\t\t\t\t{\n\t\t\t\t\t\tfragTexts.add(frag[i]);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfrag= (TextFragment[]) fragTexts.toArray(new TextFragment[0]);\n\t\t\t}\n\n\t\t\treturn frag;\n\n\t\t}\n\t\tfinally\n\t\t{\n\t\t\tif (tokenStream != null)\n\t\t\t{\n\t\t\t\ttry\n\t\t\t\t{\n\t\t\t\t\ttokenStream.close();\n\t\t\t\t}\n\t\t\t\tcatch (Exception e)\n\t\t\t\t{\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n","sourceOld":"\t/**\n\t * Low level api to get the most relevant (formatted) sections of the document.\n\t * This method has been made public to allow visibility of score information held in TextFragment objects.\n\t * Thanks to Jason Calabrese for help in redefining the interface.\n\t * @param tokenStream\n\t * @param text\n\t * @param maxNumFragments\n\t * @param mergeContiguousFragments\n\t * @throws IOException\n\t * @throws InvalidTokenOffsetsException thrown if any token's endOffset exceeds the provided text's length\n\t */\n\tpublic final TextFragment[] getBestTextFragments(\n\t\tTokenStream tokenStream,\n\t\tString text,\n\t\tboolean mergeContiguousFragments,\n\t\tint maxNumFragments)\n\t\tthrows IOException, InvalidTokenOffsetsException\n\t{\n\t\tArrayList docFrags = new ArrayList();\n\t\tStringBuffer newText=new StringBuffer();\n\t\t\n\t    TermAttribute termAtt = tokenStream.addAttribute(TermAttribute.class);\n\t    OffsetAttribute offsetAtt = tokenStream.addAttribute(OffsetAttribute.class);\n\t    tokenStream.addAttribute(PositionIncrementAttribute.class);\n\t    tokenStream.reset();\n\t    \n\t\tTextFragment currentFrag =\tnew TextFragment(newText,newText.length(), docFrags.size());\n\t\tTokenStream newStream = fragmentScorer.init(tokenStream);\n\t\tif(newStream != null) {\n\t\t  tokenStream = newStream;\n\t\t}\n\t\tfragmentScorer.startFragment(currentFrag);\n\t\tdocFrags.add(currentFrag);\n\n\t\tFragmentQueue fragQueue = new FragmentQueue(maxNumFragments);\n\n\t\ttry\n\t\t{\n\n\t\t\tString tokenText;\n\t\t\tint startOffset;\n\t\t\tint endOffset;\n\t\t\tint lastEndOffset = 0;\n\t\t\ttextFragmenter.start(text, tokenStream);\n\n\t\t\tTokenGroup tokenGroup=new TokenGroup(tokenStream);\n\n\t\t\tfor (boolean next = tokenStream.incrementToken(); next && (offsetAtt.startOffset()< maxDocCharsToAnalyze);\n\t\t\t      next = tokenStream.incrementToken())\n\t\t\t{\n\t\t\t\tif(\t(offsetAtt.endOffset()>text.length())\n\t\t\t\t\t||\n\t\t\t\t\t(offsetAtt.startOffset()>text.length())\n\t\t\t\t\t)\t\t\t\t\t\t\n\t\t\t\t{\n\t\t\t\t\tthrow new InvalidTokenOffsetsException(\"Token \"+ termAtt.term()\n\t\t\t\t\t\t\t+\" exceeds length of provided text sized \"+text.length());\n\t\t\t\t}\n\t\t\t\tif((tokenGroup.numTokens>0)&&(tokenGroup.isDistinct()))\n\t\t\t\t{\n\t\t\t\t\t//the current token is distinct from previous tokens -\n\t\t\t\t\t// markup the cached token group info\n\t\t\t\t\tstartOffset = tokenGroup.matchStartOffset;\n\t\t\t\t\tendOffset = tokenGroup.matchEndOffset;\n\t\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\t\tnewText.append(markedUpText);\n\t\t\t\t\tlastEndOffset=Math.max(endOffset, lastEndOffset);\n\t\t\t\t\ttokenGroup.clear();\n\n\t\t\t\t\t//check if current token marks the start of a new fragment\n\t\t\t\t\tif(textFragmenter.isNewFragment())\n\t\t\t\t\t{\n\t\t\t\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\t\t\t\t\t\t//record stats for a new fragment\n\t\t\t\t\t\tcurrentFrag.textEndPos = newText.length();\n\t\t\t\t\t\tcurrentFrag =new TextFragment(newText, newText.length(), docFrags.size());\n\t\t\t\t\t\tfragmentScorer.startFragment(currentFrag);\n\t\t\t\t\t\tdocFrags.add(currentFrag);\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\ttokenGroup.addToken(fragmentScorer.getTokenScore());\n\n//\t\t\t\tif(lastEndOffset>maxDocBytesToAnalyze)\n//\t\t\t\t{\n//\t\t\t\t\tbreak;\n//\t\t\t\t}\n\t\t\t}\n\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\n\t\t\tif(tokenGroup.numTokens>0)\n\t\t\t{\n\t\t\t\t//flush the accumulated text (same code as in above loop)\n\t\t\t\tstartOffset = tokenGroup.matchStartOffset;\n\t\t\t\tendOffset = tokenGroup.matchEndOffset;\n\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\tnewText.append(markedUpText);\n\t\t\t\tlastEndOffset=Math.max(lastEndOffset,endOffset);\n\t\t\t}\n\n\t\t\t//Test what remains of the original text beyond the point where we stopped analyzing \n\t\t\tif (\n//\t\t\t\t\tif there is text beyond the last token considered..\n\t\t\t\t\t(lastEndOffset < text.length()) \n\t\t\t\t\t&&\n//\t\t\t\t\tand that text is not too large...\n\t\t\t\t\t(text.length()<= maxDocCharsToAnalyze)\n\t\t\t\t)\t\t\t\t\n\t\t\t{\n\t\t\t\t//append it to the last fragment\n\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset)));\n\t\t\t}\n\n\t\t\tcurrentFrag.textEndPos = newText.length();\n\n\t\t\t//sort the most relevant sections of the text\n\t\t\tfor (Iterator i = docFrags.iterator(); i.hasNext();)\n\t\t\t{\n\t\t\t\tcurrentFrag = (TextFragment) i.next();\n\n\t\t\t\t//If you are running with a version of Lucene before 11th Sept 03\n\t\t\t\t// you do not have PriorityQueue.insert() - so uncomment the code below\n\t\t\t\t/*\n\t\t\t\t\t\t\t\t\tif (currentFrag.getScore() >= minScore)\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tfragQueue.put(currentFrag);\n\t\t\t\t\t\t\t\t\t\tif (fragQueue.size() > maxNumFragments)\n\t\t\t\t\t\t\t\t\t\t{ // if hit queue overfull\n\t\t\t\t\t\t\t\t\t\t\tfragQueue.pop(); // remove lowest in hit queue\n\t\t\t\t\t\t\t\t\t\t\tminScore = ((TextFragment) fragQueue.top()).getScore(); // reset minScore\n\t\t\t\t\t\t\t\t\t\t}\n\n\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t*/\n\t\t\t\t//The above code caused a problem as a result of Christoph Goller's 11th Sept 03\n\t\t\t\t//fix to PriorityQueue. The correct method to use here is the new \"insert\" method\n\t\t\t\t// USE ABOVE CODE IF THIS DOES NOT COMPILE!\n\t\t\t\tfragQueue.insertWithOverflow(currentFrag);\n\t\t\t}\n\n\t\t\t//return the most relevant fragments\n\t\t\tTextFragment frag[] = new TextFragment[fragQueue.size()];\n\t\t\tfor (int i = frag.length - 1; i >= 0; i--)\n\t\t\t{\n\t\t\t\tfrag[i] = (TextFragment) fragQueue.pop();\n\t\t\t}\n\n\t\t\t//merge any contiguous fragments to improve readability\n\t\t\tif(mergeContiguousFragments)\n\t\t\t{\n\t\t\t\tmergeContiguousFragments(frag);\n\t\t\t\tArrayList fragTexts = new ArrayList();\n\t\t\t\tfor (int i = 0; i < frag.length; i++)\n\t\t\t\t{\n\t\t\t\t\tif ((frag[i] != null) && (frag[i].getScore() > 0))\n\t\t\t\t\t{\n\t\t\t\t\t\tfragTexts.add(frag[i]);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfrag= (TextFragment[]) fragTexts.toArray(new TextFragment[0]);\n\t\t\t}\n\n\t\t\treturn frag;\n\n\t\t}\n\t\tfinally\n\t\t{\n\t\t\tif (tokenStream != null)\n\t\t\t{\n\t\t\t\ttry\n\t\t\t\t{\n\t\t\t\t\ttokenStream.close();\n\t\t\t\t}\n\t\t\t\tcatch (Exception e)\n\t\t\t\t{\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ffdf794cee8d43eb612df752c592cef2dc3e75ae","date":1256465578,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter#getBestTextFragments(TokenStream,String,boolean,int).mjava","pathOld":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter#getBestTextFragments(TokenStream,String,boolean,int).mjava","sourceNew":"\t/**\n\t * Low level api to get the most relevant (formatted) sections of the document.\n\t * This method has been made public to allow visibility of score information held in TextFragment objects.\n\t * Thanks to Jason Calabrese for help in redefining the interface.\n\t * @param tokenStream\n\t * @param text\n\t * @param maxNumFragments\n\t * @param mergeContiguousFragments\n\t * @throws IOException\n\t * @throws InvalidTokenOffsetsException thrown if any token's endOffset exceeds the provided text's length\n\t */\n\tpublic final TextFragment[] getBestTextFragments(\n\t\tTokenStream tokenStream,\n\t\tString text,\n\t\tboolean mergeContiguousFragments,\n\t\tint maxNumFragments)\n\t\tthrows IOException, InvalidTokenOffsetsException\n\t{\n\t\tArrayList<TextFragment> docFrags = new ArrayList<TextFragment>();\n\t\tStringBuilder newText=new StringBuilder();\n\t\t\n\t    TermAttribute termAtt = tokenStream.addAttribute(TermAttribute.class);\n\t    OffsetAttribute offsetAtt = tokenStream.addAttribute(OffsetAttribute.class);\n\t    tokenStream.addAttribute(PositionIncrementAttribute.class);\n\t    tokenStream.reset();\n\t    \n\t\tTextFragment currentFrag =\tnew TextFragment(newText,newText.length(), docFrags.size());\n\t\tTokenStream newStream = fragmentScorer.init(tokenStream);\n\t\tif(newStream != null) {\n\t\t  tokenStream = newStream;\n\t\t}\n\t\tfragmentScorer.startFragment(currentFrag);\n\t\tdocFrags.add(currentFrag);\n\n\t\tFragmentQueue fragQueue = new FragmentQueue(maxNumFragments);\n\n\t\ttry\n\t\t{\n\n\t\t\tString tokenText;\n\t\t\tint startOffset;\n\t\t\tint endOffset;\n\t\t\tint lastEndOffset = 0;\n\t\t\ttextFragmenter.start(text, tokenStream);\n\n\t\t\tTokenGroup tokenGroup=new TokenGroup(tokenStream);\n\n\t\t\tfor (boolean next = tokenStream.incrementToken(); next && (offsetAtt.startOffset()< maxDocCharsToAnalyze);\n\t\t\t      next = tokenStream.incrementToken())\n\t\t\t{\n\t\t\t\tif(\t(offsetAtt.endOffset()>text.length())\n\t\t\t\t\t||\n\t\t\t\t\t(offsetAtt.startOffset()>text.length())\n\t\t\t\t\t)\t\t\t\t\t\t\n\t\t\t\t{\n\t\t\t\t\tthrow new InvalidTokenOffsetsException(\"Token \"+ termAtt.term()\n\t\t\t\t\t\t\t+\" exceeds length of provided text sized \"+text.length());\n\t\t\t\t}\n\t\t\t\tif((tokenGroup.numTokens>0)&&(tokenGroup.isDistinct()))\n\t\t\t\t{\n\t\t\t\t\t//the current token is distinct from previous tokens -\n\t\t\t\t\t// markup the cached token group info\n\t\t\t\t\tstartOffset = tokenGroup.matchStartOffset;\n\t\t\t\t\tendOffset = tokenGroup.matchEndOffset;\n\t\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\t\tnewText.append(markedUpText);\n\t\t\t\t\tlastEndOffset=Math.max(endOffset, lastEndOffset);\n\t\t\t\t\ttokenGroup.clear();\n\n\t\t\t\t\t//check if current token marks the start of a new fragment\n\t\t\t\t\tif(textFragmenter.isNewFragment())\n\t\t\t\t\t{\n\t\t\t\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\t\t\t\t\t\t//record stats for a new fragment\n\t\t\t\t\t\tcurrentFrag.textEndPos = newText.length();\n\t\t\t\t\t\tcurrentFrag =new TextFragment(newText, newText.length(), docFrags.size());\n\t\t\t\t\t\tfragmentScorer.startFragment(currentFrag);\n\t\t\t\t\t\tdocFrags.add(currentFrag);\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\ttokenGroup.addToken(fragmentScorer.getTokenScore());\n\n//\t\t\t\tif(lastEndOffset>maxDocBytesToAnalyze)\n//\t\t\t\t{\n//\t\t\t\t\tbreak;\n//\t\t\t\t}\n\t\t\t}\n\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\n\t\t\tif(tokenGroup.numTokens>0)\n\t\t\t{\n\t\t\t\t//flush the accumulated text (same code as in above loop)\n\t\t\t\tstartOffset = tokenGroup.matchStartOffset;\n\t\t\t\tendOffset = tokenGroup.matchEndOffset;\n\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\tnewText.append(markedUpText);\n\t\t\t\tlastEndOffset=Math.max(lastEndOffset,endOffset);\n\t\t\t}\n\n\t\t\t//Test what remains of the original text beyond the point where we stopped analyzing \n\t\t\tif (\n//\t\t\t\t\tif there is text beyond the last token considered..\n\t\t\t\t\t(lastEndOffset < text.length()) \n\t\t\t\t\t&&\n//\t\t\t\t\tand that text is not too large...\n\t\t\t\t\t(text.length()<= maxDocCharsToAnalyze)\n\t\t\t\t)\t\t\t\t\n\t\t\t{\n\t\t\t\t//append it to the last fragment\n\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset)));\n\t\t\t}\n\n\t\t\tcurrentFrag.textEndPos = newText.length();\n\n\t\t\t//sort the most relevant sections of the text\n\t\t\tfor (Iterator<TextFragment> i = docFrags.iterator(); i.hasNext();)\n\t\t\t{\n\t\t\t\tcurrentFrag = i.next();\n\n\t\t\t\t//If you are running with a version of Lucene before 11th Sept 03\n\t\t\t\t// you do not have PriorityQueue.insert() - so uncomment the code below\n\t\t\t\t/*\n\t\t\t\t\t\t\t\t\tif (currentFrag.getScore() >= minScore)\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tfragQueue.put(currentFrag);\n\t\t\t\t\t\t\t\t\t\tif (fragQueue.size() > maxNumFragments)\n\t\t\t\t\t\t\t\t\t\t{ // if hit queue overfull\n\t\t\t\t\t\t\t\t\t\t\tfragQueue.pop(); // remove lowest in hit queue\n\t\t\t\t\t\t\t\t\t\t\tminScore = ((TextFragment) fragQueue.top()).getScore(); // reset minScore\n\t\t\t\t\t\t\t\t\t\t}\n\n\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t*/\n\t\t\t\t//The above code caused a problem as a result of Christoph Goller's 11th Sept 03\n\t\t\t\t//fix to PriorityQueue. The correct method to use here is the new \"insert\" method\n\t\t\t\t// USE ABOVE CODE IF THIS DOES NOT COMPILE!\n\t\t\t\tfragQueue.insertWithOverflow(currentFrag);\n\t\t\t}\n\n\t\t\t//return the most relevant fragments\n\t\t\tTextFragment frag[] = new TextFragment[fragQueue.size()];\n\t\t\tfor (int i = frag.length - 1; i >= 0; i--)\n\t\t\t{\n\t\t\t\tfrag[i] = fragQueue.pop();\n\t\t\t}\n\n\t\t\t//merge any contiguous fragments to improve readability\n\t\t\tif(mergeContiguousFragments)\n\t\t\t{\n\t\t\t\tmergeContiguousFragments(frag);\n\t\t\t\tArrayList<TextFragment> fragTexts = new ArrayList<TextFragment>();\n\t\t\t\tfor (int i = 0; i < frag.length; i++)\n\t\t\t\t{\n\t\t\t\t\tif ((frag[i] != null) && (frag[i].getScore() > 0))\n\t\t\t\t\t{\n\t\t\t\t\t\tfragTexts.add(frag[i]);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfrag= fragTexts.toArray(new TextFragment[0]);\n\t\t\t}\n\n\t\t\treturn frag;\n\n\t\t}\n\t\tfinally\n\t\t{\n\t\t\tif (tokenStream != null)\n\t\t\t{\n\t\t\t\ttry\n\t\t\t\t{\n\t\t\t\t\ttokenStream.close();\n\t\t\t\t}\n\t\t\t\tcatch (Exception e)\n\t\t\t\t{\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n","sourceOld":"\t/**\n\t * Low level api to get the most relevant (formatted) sections of the document.\n\t * This method has been made public to allow visibility of score information held in TextFragment objects.\n\t * Thanks to Jason Calabrese for help in redefining the interface.\n\t * @param tokenStream\n\t * @param text\n\t * @param maxNumFragments\n\t * @param mergeContiguousFragments\n\t * @throws IOException\n\t * @throws InvalidTokenOffsetsException thrown if any token's endOffset exceeds the provided text's length\n\t */\n\tpublic final TextFragment[] getBestTextFragments(\n\t\tTokenStream tokenStream,\n\t\tString text,\n\t\tboolean mergeContiguousFragments,\n\t\tint maxNumFragments)\n\t\tthrows IOException, InvalidTokenOffsetsException\n\t{\n\t\tArrayList docFrags = new ArrayList();\n\t\tStringBuilder newText=new StringBuilder();\n\t\t\n\t    TermAttribute termAtt = tokenStream.addAttribute(TermAttribute.class);\n\t    OffsetAttribute offsetAtt = tokenStream.addAttribute(OffsetAttribute.class);\n\t    tokenStream.addAttribute(PositionIncrementAttribute.class);\n\t    tokenStream.reset();\n\t    \n\t\tTextFragment currentFrag =\tnew TextFragment(newText,newText.length(), docFrags.size());\n\t\tTokenStream newStream = fragmentScorer.init(tokenStream);\n\t\tif(newStream != null) {\n\t\t  tokenStream = newStream;\n\t\t}\n\t\tfragmentScorer.startFragment(currentFrag);\n\t\tdocFrags.add(currentFrag);\n\n\t\tFragmentQueue fragQueue = new FragmentQueue(maxNumFragments);\n\n\t\ttry\n\t\t{\n\n\t\t\tString tokenText;\n\t\t\tint startOffset;\n\t\t\tint endOffset;\n\t\t\tint lastEndOffset = 0;\n\t\t\ttextFragmenter.start(text, tokenStream);\n\n\t\t\tTokenGroup tokenGroup=new TokenGroup(tokenStream);\n\n\t\t\tfor (boolean next = tokenStream.incrementToken(); next && (offsetAtt.startOffset()< maxDocCharsToAnalyze);\n\t\t\t      next = tokenStream.incrementToken())\n\t\t\t{\n\t\t\t\tif(\t(offsetAtt.endOffset()>text.length())\n\t\t\t\t\t||\n\t\t\t\t\t(offsetAtt.startOffset()>text.length())\n\t\t\t\t\t)\t\t\t\t\t\t\n\t\t\t\t{\n\t\t\t\t\tthrow new InvalidTokenOffsetsException(\"Token \"+ termAtt.term()\n\t\t\t\t\t\t\t+\" exceeds length of provided text sized \"+text.length());\n\t\t\t\t}\n\t\t\t\tif((tokenGroup.numTokens>0)&&(tokenGroup.isDistinct()))\n\t\t\t\t{\n\t\t\t\t\t//the current token is distinct from previous tokens -\n\t\t\t\t\t// markup the cached token group info\n\t\t\t\t\tstartOffset = tokenGroup.matchStartOffset;\n\t\t\t\t\tendOffset = tokenGroup.matchEndOffset;\n\t\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\t\tnewText.append(markedUpText);\n\t\t\t\t\tlastEndOffset=Math.max(endOffset, lastEndOffset);\n\t\t\t\t\ttokenGroup.clear();\n\n\t\t\t\t\t//check if current token marks the start of a new fragment\n\t\t\t\t\tif(textFragmenter.isNewFragment())\n\t\t\t\t\t{\n\t\t\t\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\t\t\t\t\t\t//record stats for a new fragment\n\t\t\t\t\t\tcurrentFrag.textEndPos = newText.length();\n\t\t\t\t\t\tcurrentFrag =new TextFragment(newText, newText.length(), docFrags.size());\n\t\t\t\t\t\tfragmentScorer.startFragment(currentFrag);\n\t\t\t\t\t\tdocFrags.add(currentFrag);\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\ttokenGroup.addToken(fragmentScorer.getTokenScore());\n\n//\t\t\t\tif(lastEndOffset>maxDocBytesToAnalyze)\n//\t\t\t\t{\n//\t\t\t\t\tbreak;\n//\t\t\t\t}\n\t\t\t}\n\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\n\t\t\tif(tokenGroup.numTokens>0)\n\t\t\t{\n\t\t\t\t//flush the accumulated text (same code as in above loop)\n\t\t\t\tstartOffset = tokenGroup.matchStartOffset;\n\t\t\t\tendOffset = tokenGroup.matchEndOffset;\n\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\tnewText.append(markedUpText);\n\t\t\t\tlastEndOffset=Math.max(lastEndOffset,endOffset);\n\t\t\t}\n\n\t\t\t//Test what remains of the original text beyond the point where we stopped analyzing \n\t\t\tif (\n//\t\t\t\t\tif there is text beyond the last token considered..\n\t\t\t\t\t(lastEndOffset < text.length()) \n\t\t\t\t\t&&\n//\t\t\t\t\tand that text is not too large...\n\t\t\t\t\t(text.length()<= maxDocCharsToAnalyze)\n\t\t\t\t)\t\t\t\t\n\t\t\t{\n\t\t\t\t//append it to the last fragment\n\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset)));\n\t\t\t}\n\n\t\t\tcurrentFrag.textEndPos = newText.length();\n\n\t\t\t//sort the most relevant sections of the text\n\t\t\tfor (Iterator i = docFrags.iterator(); i.hasNext();)\n\t\t\t{\n\t\t\t\tcurrentFrag = (TextFragment) i.next();\n\n\t\t\t\t//If you are running with a version of Lucene before 11th Sept 03\n\t\t\t\t// you do not have PriorityQueue.insert() - so uncomment the code below\n\t\t\t\t/*\n\t\t\t\t\t\t\t\t\tif (currentFrag.getScore() >= minScore)\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tfragQueue.put(currentFrag);\n\t\t\t\t\t\t\t\t\t\tif (fragQueue.size() > maxNumFragments)\n\t\t\t\t\t\t\t\t\t\t{ // if hit queue overfull\n\t\t\t\t\t\t\t\t\t\t\tfragQueue.pop(); // remove lowest in hit queue\n\t\t\t\t\t\t\t\t\t\t\tminScore = ((TextFragment) fragQueue.top()).getScore(); // reset minScore\n\t\t\t\t\t\t\t\t\t\t}\n\n\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t*/\n\t\t\t\t//The above code caused a problem as a result of Christoph Goller's 11th Sept 03\n\t\t\t\t//fix to PriorityQueue. The correct method to use here is the new \"insert\" method\n\t\t\t\t// USE ABOVE CODE IF THIS DOES NOT COMPILE!\n\t\t\t\tfragQueue.insertWithOverflow(currentFrag);\n\t\t\t}\n\n\t\t\t//return the most relevant fragments\n\t\t\tTextFragment frag[] = new TextFragment[fragQueue.size()];\n\t\t\tfor (int i = frag.length - 1; i >= 0; i--)\n\t\t\t{\n\t\t\t\tfrag[i] = (TextFragment) fragQueue.pop();\n\t\t\t}\n\n\t\t\t//merge any contiguous fragments to improve readability\n\t\t\tif(mergeContiguousFragments)\n\t\t\t{\n\t\t\t\tmergeContiguousFragments(frag);\n\t\t\t\tArrayList fragTexts = new ArrayList();\n\t\t\t\tfor (int i = 0; i < frag.length; i++)\n\t\t\t\t{\n\t\t\t\t\tif ((frag[i] != null) && (frag[i].getScore() > 0))\n\t\t\t\t\t{\n\t\t\t\t\t\tfragTexts.add(frag[i]);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfrag= (TextFragment[]) fragTexts.toArray(new TextFragment[0]);\n\t\t\t}\n\n\t\t\treturn frag;\n\n\t\t}\n\t\tfinally\n\t\t{\n\t\t\tif (tokenStream != null)\n\t\t\t{\n\t\t\t\ttry\n\t\t\t\t{\n\t\t\t\t\ttokenStream.close();\n\t\t\t\t}\n\t\t\t\tcatch (Exception e)\n\t\t\t\t{\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter#getBestTextFragments(TokenStream,String,boolean,int).mjava","pathOld":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter#getBestTextFragments(TokenStream,String,boolean,int).mjava","sourceNew":"\t/**\n\t * Low level api to get the most relevant (formatted) sections of the document.\n\t * This method has been made public to allow visibility of score information held in TextFragment objects.\n\t * Thanks to Jason Calabrese for help in redefining the interface.\n\t * @param tokenStream\n\t * @param text\n\t * @param maxNumFragments\n\t * @param mergeContiguousFragments\n\t * @throws IOException\n\t * @throws InvalidTokenOffsetsException thrown if any token's endOffset exceeds the provided text's length\n\t */\n\tpublic final TextFragment[] getBestTextFragments(\n\t\tTokenStream tokenStream,\n\t\tString text,\n\t\tboolean mergeContiguousFragments,\n\t\tint maxNumFragments)\n\t\tthrows IOException, InvalidTokenOffsetsException\n\t{\n\t\tArrayList<TextFragment> docFrags = new ArrayList<TextFragment>();\n\t\tStringBuilder newText=new StringBuilder();\n\t\t\n\t    TermAttribute termAtt = tokenStream.addAttribute(TermAttribute.class);\n\t    OffsetAttribute offsetAtt = tokenStream.addAttribute(OffsetAttribute.class);\n\t    tokenStream.addAttribute(PositionIncrementAttribute.class);\n\t    tokenStream.reset();\n\t    \n\t\tTextFragment currentFrag =\tnew TextFragment(newText,newText.length(), docFrags.size());\n\t\tTokenStream newStream = fragmentScorer.init(tokenStream);\n\t\tif(newStream != null) {\n\t\t  tokenStream = newStream;\n\t\t}\n\t\tfragmentScorer.startFragment(currentFrag);\n\t\tdocFrags.add(currentFrag);\n\n\t\tFragmentQueue fragQueue = new FragmentQueue(maxNumFragments);\n\n\t\ttry\n\t\t{\n\n\t\t\tString tokenText;\n\t\t\tint startOffset;\n\t\t\tint endOffset;\n\t\t\tint lastEndOffset = 0;\n\t\t\ttextFragmenter.start(text, tokenStream);\n\n\t\t\tTokenGroup tokenGroup=new TokenGroup(tokenStream);\n\n\t\t\tfor (boolean next = tokenStream.incrementToken(); next && (offsetAtt.startOffset()< maxDocCharsToAnalyze);\n\t\t\t      next = tokenStream.incrementToken())\n\t\t\t{\n\t\t\t\tif(\t(offsetAtt.endOffset()>text.length())\n\t\t\t\t\t||\n\t\t\t\t\t(offsetAtt.startOffset()>text.length())\n\t\t\t\t\t)\t\t\t\t\t\t\n\t\t\t\t{\n\t\t\t\t\tthrow new InvalidTokenOffsetsException(\"Token \"+ termAtt.term()\n\t\t\t\t\t\t\t+\" exceeds length of provided text sized \"+text.length());\n\t\t\t\t}\n\t\t\t\tif((tokenGroup.numTokens>0)&&(tokenGroup.isDistinct()))\n\t\t\t\t{\n\t\t\t\t\t//the current token is distinct from previous tokens -\n\t\t\t\t\t// markup the cached token group info\n\t\t\t\t\tstartOffset = tokenGroup.matchStartOffset;\n\t\t\t\t\tendOffset = tokenGroup.matchEndOffset;\n\t\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\t\tnewText.append(markedUpText);\n\t\t\t\t\tlastEndOffset=Math.max(endOffset, lastEndOffset);\n\t\t\t\t\ttokenGroup.clear();\n\n\t\t\t\t\t//check if current token marks the start of a new fragment\n\t\t\t\t\tif(textFragmenter.isNewFragment())\n\t\t\t\t\t{\n\t\t\t\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\t\t\t\t\t\t//record stats for a new fragment\n\t\t\t\t\t\tcurrentFrag.textEndPos = newText.length();\n\t\t\t\t\t\tcurrentFrag =new TextFragment(newText, newText.length(), docFrags.size());\n\t\t\t\t\t\tfragmentScorer.startFragment(currentFrag);\n\t\t\t\t\t\tdocFrags.add(currentFrag);\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\ttokenGroup.addToken(fragmentScorer.getTokenScore());\n\n//\t\t\t\tif(lastEndOffset>maxDocBytesToAnalyze)\n//\t\t\t\t{\n//\t\t\t\t\tbreak;\n//\t\t\t\t}\n\t\t\t}\n\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\n\t\t\tif(tokenGroup.numTokens>0)\n\t\t\t{\n\t\t\t\t//flush the accumulated text (same code as in above loop)\n\t\t\t\tstartOffset = tokenGroup.matchStartOffset;\n\t\t\t\tendOffset = tokenGroup.matchEndOffset;\n\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\tnewText.append(markedUpText);\n\t\t\t\tlastEndOffset=Math.max(lastEndOffset,endOffset);\n\t\t\t}\n\n\t\t\t//Test what remains of the original text beyond the point where we stopped analyzing \n\t\t\tif (\n//\t\t\t\t\tif there is text beyond the last token considered..\n\t\t\t\t\t(lastEndOffset < text.length()) \n\t\t\t\t\t&&\n//\t\t\t\t\tand that text is not too large...\n\t\t\t\t\t(text.length()<= maxDocCharsToAnalyze)\n\t\t\t\t)\t\t\t\t\n\t\t\t{\n\t\t\t\t//append it to the last fragment\n\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset)));\n\t\t\t}\n\n\t\t\tcurrentFrag.textEndPos = newText.length();\n\n\t\t\t//sort the most relevant sections of the text\n\t\t\tfor (Iterator<TextFragment> i = docFrags.iterator(); i.hasNext();)\n\t\t\t{\n\t\t\t\tcurrentFrag = i.next();\n\n\t\t\t\t//If you are running with a version of Lucene before 11th Sept 03\n\t\t\t\t// you do not have PriorityQueue.insert() - so uncomment the code below\n\t\t\t\t/*\n\t\t\t\t\t\t\t\t\tif (currentFrag.getScore() >= minScore)\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tfragQueue.put(currentFrag);\n\t\t\t\t\t\t\t\t\t\tif (fragQueue.size() > maxNumFragments)\n\t\t\t\t\t\t\t\t\t\t{ // if hit queue overfull\n\t\t\t\t\t\t\t\t\t\t\tfragQueue.pop(); // remove lowest in hit queue\n\t\t\t\t\t\t\t\t\t\t\tminScore = ((TextFragment) fragQueue.top()).getScore(); // reset minScore\n\t\t\t\t\t\t\t\t\t\t}\n\n\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t*/\n\t\t\t\t//The above code caused a problem as a result of Christoph Goller's 11th Sept 03\n\t\t\t\t//fix to PriorityQueue. The correct method to use here is the new \"insert\" method\n\t\t\t\t// USE ABOVE CODE IF THIS DOES NOT COMPILE!\n\t\t\t\tfragQueue.insertWithOverflow(currentFrag);\n\t\t\t}\n\n\t\t\t//return the most relevant fragments\n\t\t\tTextFragment frag[] = new TextFragment[fragQueue.size()];\n\t\t\tfor (int i = frag.length - 1; i >= 0; i--)\n\t\t\t{\n\t\t\t\tfrag[i] = fragQueue.pop();\n\t\t\t}\n\n\t\t\t//merge any contiguous fragments to improve readability\n\t\t\tif(mergeContiguousFragments)\n\t\t\t{\n\t\t\t\tmergeContiguousFragments(frag);\n\t\t\t\tArrayList<TextFragment> fragTexts = new ArrayList<TextFragment>();\n\t\t\t\tfor (int i = 0; i < frag.length; i++)\n\t\t\t\t{\n\t\t\t\t\tif ((frag[i] != null) && (frag[i].getScore() > 0))\n\t\t\t\t\t{\n\t\t\t\t\t\tfragTexts.add(frag[i]);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfrag= fragTexts.toArray(new TextFragment[0]);\n\t\t\t}\n\n\t\t\treturn frag;\n\n\t\t}\n\t\tfinally\n\t\t{\n\t\t\tif (tokenStream != null)\n\t\t\t{\n\t\t\t\ttry\n\t\t\t\t{\n\t\t\t\t\ttokenStream.close();\n\t\t\t\t}\n\t\t\t\tcatch (Exception e)\n\t\t\t\t{\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n","sourceOld":"\t/**\n\t * Low level api to get the most relevant (formatted) sections of the document.\n\t * This method has been made public to allow visibility of score information held in TextFragment objects.\n\t * Thanks to Jason Calabrese for help in redefining the interface.\n\t * @param tokenStream\n\t * @param text\n\t * @param maxNumFragments\n\t * @param mergeContiguousFragments\n\t * @throws IOException\n\t * @throws InvalidTokenOffsetsException thrown if any token's endOffset exceeds the provided text's length\n\t */\n\tpublic final TextFragment[] getBestTextFragments(\n\t\tTokenStream tokenStream,\n\t\tString text,\n\t\tboolean mergeContiguousFragments,\n\t\tint maxNumFragments)\n\t\tthrows IOException, InvalidTokenOffsetsException\n\t{\n\t\tArrayList<TextFragment> docFrags = new ArrayList<TextFragment>();\n\t\tStringBuilder newText=new StringBuilder();\n\t\t\n\t    TermAttribute termAtt = tokenStream.addAttribute(TermAttribute.class);\n\t    OffsetAttribute offsetAtt = tokenStream.addAttribute(OffsetAttribute.class);\n\t    tokenStream.addAttribute(PositionIncrementAttribute.class);\n\t    tokenStream.reset();\n\t    \n\t\tTextFragment currentFrag =\tnew TextFragment(newText,newText.length(), docFrags.size());\n\t\tTokenStream newStream = fragmentScorer.init(tokenStream);\n\t\tif(newStream != null) {\n\t\t  tokenStream = newStream;\n\t\t}\n\t\tfragmentScorer.startFragment(currentFrag);\n\t\tdocFrags.add(currentFrag);\n\n\t\tFragmentQueue fragQueue = new FragmentQueue(maxNumFragments);\n\n\t\ttry\n\t\t{\n\n\t\t\tString tokenText;\n\t\t\tint startOffset;\n\t\t\tint endOffset;\n\t\t\tint lastEndOffset = 0;\n\t\t\ttextFragmenter.start(text, tokenStream);\n\n\t\t\tTokenGroup tokenGroup=new TokenGroup(tokenStream);\n\n\t\t\tfor (boolean next = tokenStream.incrementToken(); next && (offsetAtt.startOffset()< maxDocCharsToAnalyze);\n\t\t\t      next = tokenStream.incrementToken())\n\t\t\t{\n\t\t\t\tif(\t(offsetAtt.endOffset()>text.length())\n\t\t\t\t\t||\n\t\t\t\t\t(offsetAtt.startOffset()>text.length())\n\t\t\t\t\t)\t\t\t\t\t\t\n\t\t\t\t{\n\t\t\t\t\tthrow new InvalidTokenOffsetsException(\"Token \"+ termAtt.term()\n\t\t\t\t\t\t\t+\" exceeds length of provided text sized \"+text.length());\n\t\t\t\t}\n\t\t\t\tif((tokenGroup.numTokens>0)&&(tokenGroup.isDistinct()))\n\t\t\t\t{\n\t\t\t\t\t//the current token is distinct from previous tokens -\n\t\t\t\t\t// markup the cached token group info\n\t\t\t\t\tstartOffset = tokenGroup.matchStartOffset;\n\t\t\t\t\tendOffset = tokenGroup.matchEndOffset;\n\t\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\t\tnewText.append(markedUpText);\n\t\t\t\t\tlastEndOffset=Math.max(endOffset, lastEndOffset);\n\t\t\t\t\ttokenGroup.clear();\n\n\t\t\t\t\t//check if current token marks the start of a new fragment\n\t\t\t\t\tif(textFragmenter.isNewFragment())\n\t\t\t\t\t{\n\t\t\t\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\t\t\t\t\t\t//record stats for a new fragment\n\t\t\t\t\t\tcurrentFrag.textEndPos = newText.length();\n\t\t\t\t\t\tcurrentFrag =new TextFragment(newText, newText.length(), docFrags.size());\n\t\t\t\t\t\tfragmentScorer.startFragment(currentFrag);\n\t\t\t\t\t\tdocFrags.add(currentFrag);\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\ttokenGroup.addToken(fragmentScorer.getTokenScore());\n\n//\t\t\t\tif(lastEndOffset>maxDocBytesToAnalyze)\n//\t\t\t\t{\n//\t\t\t\t\tbreak;\n//\t\t\t\t}\n\t\t\t}\n\t\t\tcurrentFrag.setScore(fragmentScorer.getFragmentScore());\n\n\t\t\tif(tokenGroup.numTokens>0)\n\t\t\t{\n\t\t\t\t//flush the accumulated text (same code as in above loop)\n\t\t\t\tstartOffset = tokenGroup.matchStartOffset;\n\t\t\t\tendOffset = tokenGroup.matchEndOffset;\n\t\t\t\ttokenText = text.substring(startOffset, endOffset);\n\t\t\t\tString markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText), tokenGroup);\n\t\t\t\t//store any whitespace etc from between this and last group\n\t\t\t\tif (startOffset > lastEndOffset)\n\t\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset, startOffset)));\n\t\t\t\tnewText.append(markedUpText);\n\t\t\t\tlastEndOffset=Math.max(lastEndOffset,endOffset);\n\t\t\t}\n\n\t\t\t//Test what remains of the original text beyond the point where we stopped analyzing \n\t\t\tif (\n//\t\t\t\t\tif there is text beyond the last token considered..\n\t\t\t\t\t(lastEndOffset < text.length()) \n\t\t\t\t\t&&\n//\t\t\t\t\tand that text is not too large...\n\t\t\t\t\t(text.length()<= maxDocCharsToAnalyze)\n\t\t\t\t)\t\t\t\t\n\t\t\t{\n\t\t\t\t//append it to the last fragment\n\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset)));\n\t\t\t}\n\n\t\t\tcurrentFrag.textEndPos = newText.length();\n\n\t\t\t//sort the most relevant sections of the text\n\t\t\tfor (Iterator<TextFragment> i = docFrags.iterator(); i.hasNext();)\n\t\t\t{\n\t\t\t\tcurrentFrag = i.next();\n\n\t\t\t\t//If you are running with a version of Lucene before 11th Sept 03\n\t\t\t\t// you do not have PriorityQueue.insert() - so uncomment the code below\n\t\t\t\t/*\n\t\t\t\t\t\t\t\t\tif (currentFrag.getScore() >= minScore)\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tfragQueue.put(currentFrag);\n\t\t\t\t\t\t\t\t\t\tif (fragQueue.size() > maxNumFragments)\n\t\t\t\t\t\t\t\t\t\t{ // if hit queue overfull\n\t\t\t\t\t\t\t\t\t\t\tfragQueue.pop(); // remove lowest in hit queue\n\t\t\t\t\t\t\t\t\t\t\tminScore = ((TextFragment) fragQueue.top()).getScore(); // reset minScore\n\t\t\t\t\t\t\t\t\t\t}\n\n\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t*/\n\t\t\t\t//The above code caused a problem as a result of Christoph Goller's 11th Sept 03\n\t\t\t\t//fix to PriorityQueue. The correct method to use here is the new \"insert\" method\n\t\t\t\t// USE ABOVE CODE IF THIS DOES NOT COMPILE!\n\t\t\t\tfragQueue.insertWithOverflow(currentFrag);\n\t\t\t}\n\n\t\t\t//return the most relevant fragments\n\t\t\tTextFragment frag[] = new TextFragment[fragQueue.size()];\n\t\t\tfor (int i = frag.length - 1; i >= 0; i--)\n\t\t\t{\n\t\t\t\tfrag[i] = fragQueue.pop();\n\t\t\t}\n\n\t\t\t//merge any contiguous fragments to improve readability\n\t\t\tif(mergeContiguousFragments)\n\t\t\t{\n\t\t\t\tmergeContiguousFragments(frag);\n\t\t\t\tArrayList<TextFragment> fragTexts = new ArrayList<TextFragment>();\n\t\t\t\tfor (int i = 0; i < frag.length; i++)\n\t\t\t\t{\n\t\t\t\t\tif ((frag[i] != null) && (frag[i].getScore() > 0))\n\t\t\t\t\t{\n\t\t\t\t\t\tfragTexts.add(frag[i]);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfrag= fragTexts.toArray(new TextFragment[0]);\n\t\t\t}\n\n\t\t\treturn frag;\n\n\t\t}\n\t\tfinally\n\t\t{\n\t\t\tif (tokenStream != null)\n\t\t\t{\n\t\t\t\ttry\n\t\t\t\t{\n\t\t\t\t\ttokenStream.close();\n\t\t\t\t}\n\t\t\t\tcatch (Exception e)\n\t\t\t\t{\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"7e2cb543b41c145f33390f460ee743d6693c9c6c":["af56a7fe9b0a12db7411a3f2ac1ad227cd35b246"],"2fde44b2385ae1519002d7aa717f921b45b58276":["043c298cb215f13ba7b9b81d20760704e8f93d66"],"043c298cb215f13ba7b9b81d20760704e8f93d66":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"9532290bd66e70c1787e80aae9fb0427ce080194":["f504fc2bf24530fd47d0ccafcf776c8c0b9e4c7f"],"78c79c829112a79287f8b7389502c7083d99c51b":["e6ec63b41d741f5323f34c2820265518550b50dd"],"e6ec63b41d741f5323f34c2820265518550b50dd":["2fde44b2385ae1519002d7aa717f921b45b58276"],"943c3f9cf96b8df37f4273d66a66182e2a669467":["b4471b2ef75c0e11869f60b23cabe292b895c3ee"],"a710e1326e4ffd9966ad8e37ba4e5f720778c5d9":["9532290bd66e70c1787e80aae9fb0427ce080194"],"bf4dbfaec317df80ca6f412ce1b94b337b581e17":["7e2cb543b41c145f33390f460ee743d6693c9c6c"],"923b43f6b9130def5724aebbdf0672c17a2d4fd9":["78c79c829112a79287f8b7389502c7083d99c51b"],"ffdf794cee8d43eb612df752c592cef2dc3e75ae":["4625cb7ffd7c9caaf2d62b206ba9a382d68da82c"],"b4471b2ef75c0e11869f60b23cabe292b895c3ee":["bf4dbfaec317df80ca6f412ce1b94b337b581e17"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"af56a7fe9b0a12db7411a3f2ac1ad227cd35b246":["a710e1326e4ffd9966ad8e37ba4e5f720778c5d9"],"f504fc2bf24530fd47d0ccafcf776c8c0b9e4c7f":["923b43f6b9130def5724aebbdf0672c17a2d4fd9"],"8d78f014fded44fbde905f4f84cdc21907b371e8":["943c3f9cf96b8df37f4273d66a66182e2a669467"],"4625cb7ffd7c9caaf2d62b206ba9a382d68da82c":["8d78f014fded44fbde905f4f84cdc21907b371e8"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["ffdf794cee8d43eb612df752c592cef2dc3e75ae"]},"commit2Childs":{"7e2cb543b41c145f33390f460ee743d6693c9c6c":["bf4dbfaec317df80ca6f412ce1b94b337b581e17"],"2fde44b2385ae1519002d7aa717f921b45b58276":["e6ec63b41d741f5323f34c2820265518550b50dd"],"043c298cb215f13ba7b9b81d20760704e8f93d66":["2fde44b2385ae1519002d7aa717f921b45b58276"],"9532290bd66e70c1787e80aae9fb0427ce080194":["a710e1326e4ffd9966ad8e37ba4e5f720778c5d9"],"78c79c829112a79287f8b7389502c7083d99c51b":["923b43f6b9130def5724aebbdf0672c17a2d4fd9"],"e6ec63b41d741f5323f34c2820265518550b50dd":["78c79c829112a79287f8b7389502c7083d99c51b"],"943c3f9cf96b8df37f4273d66a66182e2a669467":["8d78f014fded44fbde905f4f84cdc21907b371e8"],"a710e1326e4ffd9966ad8e37ba4e5f720778c5d9":["af56a7fe9b0a12db7411a3f2ac1ad227cd35b246"],"bf4dbfaec317df80ca6f412ce1b94b337b581e17":["b4471b2ef75c0e11869f60b23cabe292b895c3ee"],"923b43f6b9130def5724aebbdf0672c17a2d4fd9":["f504fc2bf24530fd47d0ccafcf776c8c0b9e4c7f"],"ffdf794cee8d43eb612df752c592cef2dc3e75ae":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["043c298cb215f13ba7b9b81d20760704e8f93d66"],"b4471b2ef75c0e11869f60b23cabe292b895c3ee":["943c3f9cf96b8df37f4273d66a66182e2a669467"],"af56a7fe9b0a12db7411a3f2ac1ad227cd35b246":["7e2cb543b41c145f33390f460ee743d6693c9c6c"],"f504fc2bf24530fd47d0ccafcf776c8c0b9e4c7f":["9532290bd66e70c1787e80aae9fb0427ce080194"],"8d78f014fded44fbde905f4f84cdc21907b371e8":["4625cb7ffd7c9caaf2d62b206ba9a382d68da82c"],"4625cb7ffd7c9caaf2d62b206ba9a382d68da82c":["ffdf794cee8d43eb612df752c592cef2dc3e75ae"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}