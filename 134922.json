{"path":"contrib/misc/src/java/org/apache/lucene/index/TermVectorAccessor#build(IndexReader,String,TermVectorMapper,int).mjava","commits":[{"id":"48bedd31c61edafb8baaff4bcbcac19449fb7c3a","date":1251468037,"type":1,"author":"Mark Robert Miller","isMerge":false,"pathNew":"contrib/misc/src/java/org/apache/lucene/index/TermVectorAccessor#build(IndexReader,String,TermVectorMapper,int).mjava","pathOld":"contrib/miscellaneous/src/java/org/apache/lucene/index/TermVectorAccessor#build(IndexReader,String,TermVectorMapper,int).mjava","sourceNew":"  /**\n   * Populates the mapper with terms available for the given field in a document\n   * by resolving the inverted index.\n   *\n   * @param indexReader\n   * @param field interned field name\n   * @param mapper\n   * @param documentNumber\n   * @throws IOException\n   */\n  private void build(IndexReader indexReader, String field, TermVectorMapper mapper, int documentNumber) throws IOException {\n\n    if (tokens == null) {\n      tokens = new ArrayList/*<String>*/(500);\n      positions = new ArrayList/*<int[]>*/(500);\n      frequencies = new ArrayList/*<Integer>*/(500);\n    } else {\n      tokens.clear();\n      frequencies.clear();\n      positions.clear();\n    }\n\n    TermEnum termEnum = indexReader.terms();\n    if (termEnum.skipTo(new Term(field, \"\"))) {\n\n      while (termEnum.term().field() == field) {\n        TermPositions termPositions = indexReader.termPositions(termEnum.term());\n        if (termPositions.skipTo(documentNumber)) {\n\n          frequencies.add(new Integer(termPositions.freq()));\n          tokens.add(termEnum.term().text());\n\n\n          if (!mapper.isIgnoringPositions()) {\n            int[] positions = new int[termPositions.freq()];\n            for (int i = 0; i < positions.length; i++) {\n              positions[i] = termPositions.nextPosition();\n            }\n            this.positions.add(positions);\n          } else {\n            positions.add(null);\n          }\n        }\n        termPositions.close();\n        if (!termEnum.next()) {\n          break;\n        }\n      }\n\n      mapper.setDocumentNumber(documentNumber);\n      mapper.setExpectations(field, tokens.size(), false, !mapper.isIgnoringPositions());\n      for (int i = 0; i < tokens.size(); i++) {\n        mapper.map((String) tokens.get(i), ((Integer) frequencies.get(i)).intValue(), (TermVectorOffsetInfo[]) null, (int[]) positions.get(i));\n      }\n\n    }\n    termEnum.close();\n\n\n  }\n\n","sourceOld":"  /**\n   * Populates the mapper with terms available for the given field in a document\n   * by resolving the inverted index.\n   *\n   * @param indexReader\n   * @param field interned field name\n   * @param mapper\n   * @param documentNumber\n   * @throws IOException\n   */\n  private void build(IndexReader indexReader, String field, TermVectorMapper mapper, int documentNumber) throws IOException {\n\n    if (tokens == null) {\n      tokens = new ArrayList/*<String>*/(500);\n      positions = new ArrayList/*<int[]>*/(500);\n      frequencies = new ArrayList/*<Integer>*/(500);\n    } else {\n      tokens.clear();\n      frequencies.clear();\n      positions.clear();\n    }\n\n    TermEnum termEnum = indexReader.terms();\n    if (termEnum.skipTo(new Term(field, \"\"))) {\n\n      while (termEnum.term().field() == field) {\n        TermPositions termPositions = indexReader.termPositions(termEnum.term());\n        if (termPositions.skipTo(documentNumber)) {\n\n          frequencies.add(new Integer(termPositions.freq()));\n          tokens.add(termEnum.term().text());\n\n\n          if (!mapper.isIgnoringPositions()) {\n            int[] positions = new int[termPositions.freq()];\n            for (int i = 0; i < positions.length; i++) {\n              positions[i] = termPositions.nextPosition();\n            }\n            this.positions.add(positions);\n          } else {\n            positions.add(null);\n          }\n        }\n        termPositions.close();\n        if (!termEnum.next()) {\n          break;\n        }\n      }\n\n      mapper.setDocumentNumber(documentNumber);\n      mapper.setExpectations(field, tokens.size(), false, !mapper.isIgnoringPositions());\n      for (int i = 0; i < tokens.size(); i++) {\n        mapper.map((String) tokens.get(i), ((Integer) frequencies.get(i)).intValue(), (TermVectorOffsetInfo[]) null, (int[]) positions.get(i));\n      }\n\n    }\n    termEnum.close();\n\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6bcde5e3f23911110baa101ed062b544162825b5","date":1254521804,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/misc/src/java/org/apache/lucene/index/TermVectorAccessor#build(IndexReader,String,TermVectorMapper,int).mjava","pathOld":"contrib/misc/src/java/org/apache/lucene/index/TermVectorAccessor#build(IndexReader,String,TermVectorMapper,int).mjava","sourceNew":"  /**\n   * Populates the mapper with terms available for the given field in a document\n   * by resolving the inverted index.\n   *\n   * @param indexReader\n   * @param field interned field name\n   * @param mapper\n   * @param documentNumber\n   * @throws IOException\n   */\n  private void build(IndexReader indexReader, String field, TermVectorMapper mapper, int documentNumber) throws IOException {\n\n    if (tokens == null) {\n      tokens = new ArrayList/*<String>*/(500);\n      positions = new ArrayList/*<int[]>*/(500);\n      frequencies = new ArrayList/*<Integer>*/(500);\n    } else {\n      tokens.clear();\n      frequencies.clear();\n      positions.clear();\n    }\n\n    TermEnum termEnum = indexReader.terms();\n    if (termEnum.skipTo(new Term(field, \"\"))) {\n\n      while (termEnum.term().field() == field) {\n        TermPositions termPositions = indexReader.termPositions(termEnum.term());\n        if (termPositions.skipTo(documentNumber)) {\n\n          frequencies.add(Integer.valueOf(termPositions.freq()));\n          tokens.add(termEnum.term().text());\n\n\n          if (!mapper.isIgnoringPositions()) {\n            int[] positions = new int[termPositions.freq()];\n            for (int i = 0; i < positions.length; i++) {\n              positions[i] = termPositions.nextPosition();\n            }\n            this.positions.add(positions);\n          } else {\n            positions.add(null);\n          }\n        }\n        termPositions.close();\n        if (!termEnum.next()) {\n          break;\n        }\n      }\n\n      mapper.setDocumentNumber(documentNumber);\n      mapper.setExpectations(field, tokens.size(), false, !mapper.isIgnoringPositions());\n      for (int i = 0; i < tokens.size(); i++) {\n        mapper.map((String) tokens.get(i), ((Integer) frequencies.get(i)).intValue(), (TermVectorOffsetInfo[]) null, (int[]) positions.get(i));\n      }\n\n    }\n    termEnum.close();\n\n\n  }\n\n","sourceOld":"  /**\n   * Populates the mapper with terms available for the given field in a document\n   * by resolving the inverted index.\n   *\n   * @param indexReader\n   * @param field interned field name\n   * @param mapper\n   * @param documentNumber\n   * @throws IOException\n   */\n  private void build(IndexReader indexReader, String field, TermVectorMapper mapper, int documentNumber) throws IOException {\n\n    if (tokens == null) {\n      tokens = new ArrayList/*<String>*/(500);\n      positions = new ArrayList/*<int[]>*/(500);\n      frequencies = new ArrayList/*<Integer>*/(500);\n    } else {\n      tokens.clear();\n      frequencies.clear();\n      positions.clear();\n    }\n\n    TermEnum termEnum = indexReader.terms();\n    if (termEnum.skipTo(new Term(field, \"\"))) {\n\n      while (termEnum.term().field() == field) {\n        TermPositions termPositions = indexReader.termPositions(termEnum.term());\n        if (termPositions.skipTo(documentNumber)) {\n\n          frequencies.add(new Integer(termPositions.freq()));\n          tokens.add(termEnum.term().text());\n\n\n          if (!mapper.isIgnoringPositions()) {\n            int[] positions = new int[termPositions.freq()];\n            for (int i = 0; i < positions.length; i++) {\n              positions[i] = termPositions.nextPosition();\n            }\n            this.positions.add(positions);\n          } else {\n            positions.add(null);\n          }\n        }\n        termPositions.close();\n        if (!termEnum.next()) {\n          break;\n        }\n      }\n\n      mapper.setDocumentNumber(documentNumber);\n      mapper.setExpectations(field, tokens.size(), false, !mapper.isIgnoringPositions());\n      for (int i = 0; i < tokens.size(); i++) {\n        mapper.map((String) tokens.get(i), ((Integer) frequencies.get(i)).intValue(), (TermVectorOffsetInfo[]) null, (int[]) positions.get(i));\n      }\n\n    }\n    termEnum.close();\n\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"560b3a3bb8efcae105d6ae5fbee0f8b03c7decc7","date":1255555265,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"contrib/misc/src/java/org/apache/lucene/index/TermVectorAccessor#build(IndexReader,String,TermVectorMapper,int).mjava","pathOld":"contrib/misc/src/java/org/apache/lucene/index/TermVectorAccessor#build(IndexReader,String,TermVectorMapper,int).mjava","sourceNew":"  /**\n   * Populates the mapper with terms available for the given field in a document\n   * by resolving the inverted index.\n   *\n   * @param indexReader\n   * @param field interned field name\n   * @param mapper\n   * @param documentNumber\n   * @throws IOException\n   */\n  private void build(IndexReader indexReader, String field, TermVectorMapper mapper, int documentNumber) throws IOException {\n\n    if (tokens == null) {\n      tokens = new ArrayList/*<String>*/(500);\n      positions = new ArrayList/*<int[]>*/(500);\n      frequencies = new ArrayList/*<Integer>*/(500);\n    } else {\n      tokens.clear();\n      frequencies.clear();\n      positions.clear();\n    }\n\n    TermEnum termEnum = indexReader.terms(new Term(field, \"\"));\n    if (termEnum.term() != null) {\n      while (termEnum.term().field() == field) {\n        TermPositions termPositions = indexReader.termPositions(termEnum.term());\n        if (termPositions.skipTo(documentNumber)) {\n  \n          frequencies.add(Integer.valueOf(termPositions.freq()));\n          tokens.add(termEnum.term().text());\n  \n  \n          if (!mapper.isIgnoringPositions()) {\n            int[] positions = new int[termPositions.freq()];\n            for (int i = 0; i < positions.length; i++) {\n              positions[i] = termPositions.nextPosition();\n            }\n            this.positions.add(positions);\n          } else {\n            positions.add(null);\n          }\n        }\n        termPositions.close();\n        if (!termEnum.next()) {\n          break;\n        }\n      }\n      mapper.setDocumentNumber(documentNumber);\n      mapper.setExpectations(field, tokens.size(), false, !mapper.isIgnoringPositions());\n      for (int i = 0; i < tokens.size(); i++) {\n        mapper.map((String) tokens.get(i), ((Integer) frequencies.get(i)).intValue(), (TermVectorOffsetInfo[]) null, (int[]) positions.get(i));\n      }\n    }\n    termEnum.close();\n\n\n  }\n\n","sourceOld":"  /**\n   * Populates the mapper with terms available for the given field in a document\n   * by resolving the inverted index.\n   *\n   * @param indexReader\n   * @param field interned field name\n   * @param mapper\n   * @param documentNumber\n   * @throws IOException\n   */\n  private void build(IndexReader indexReader, String field, TermVectorMapper mapper, int documentNumber) throws IOException {\n\n    if (tokens == null) {\n      tokens = new ArrayList/*<String>*/(500);\n      positions = new ArrayList/*<int[]>*/(500);\n      frequencies = new ArrayList/*<Integer>*/(500);\n    } else {\n      tokens.clear();\n      frequencies.clear();\n      positions.clear();\n    }\n\n    TermEnum termEnum = indexReader.terms();\n    if (termEnum.skipTo(new Term(field, \"\"))) {\n\n      while (termEnum.term().field() == field) {\n        TermPositions termPositions = indexReader.termPositions(termEnum.term());\n        if (termPositions.skipTo(documentNumber)) {\n\n          frequencies.add(Integer.valueOf(termPositions.freq()));\n          tokens.add(termEnum.term().text());\n\n\n          if (!mapper.isIgnoringPositions()) {\n            int[] positions = new int[termPositions.freq()];\n            for (int i = 0; i < positions.length; i++) {\n              positions[i] = termPositions.nextPosition();\n            }\n            this.positions.add(positions);\n          } else {\n            positions.add(null);\n          }\n        }\n        termPositions.close();\n        if (!termEnum.next()) {\n          break;\n        }\n      }\n\n      mapper.setDocumentNumber(documentNumber);\n      mapper.setExpectations(field, tokens.size(), false, !mapper.isIgnoringPositions());\n      for (int i = 0; i < tokens.size(); i++) {\n        mapper.map((String) tokens.get(i), ((Integer) frequencies.get(i)).intValue(), (TermVectorOffsetInfo[]) null, (int[]) positions.get(i));\n      }\n\n    }\n    termEnum.close();\n\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f11899016a0460a7ea2e4b008d002e1e75c7d867","date":1256772085,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/misc/src/java/org/apache/lucene/index/TermVectorAccessor#build(IndexReader,String,TermVectorMapper,int).mjava","pathOld":"contrib/misc/src/java/org/apache/lucene/index/TermVectorAccessor#build(IndexReader,String,TermVectorMapper,int).mjava","sourceNew":"  /**\n   * Populates the mapper with terms available for the given field in a document\n   * by resolving the inverted index.\n   *\n   * @param indexReader\n   * @param field interned field name\n   * @param mapper\n   * @param documentNumber\n   * @throws IOException\n   */\n  private void build(IndexReader indexReader, String field, TermVectorMapper mapper, int documentNumber) throws IOException {\n\n    if (tokens == null) {\n      tokens = new ArrayList<String>(500);\n      positions = new ArrayList<int[]>(500);\n      frequencies = new ArrayList<Integer>(500);\n    } else {\n      tokens.clear();\n      frequencies.clear();\n      positions.clear();\n    }\n\n    TermEnum termEnum = indexReader.terms(new Term(field, \"\"));\n    if (termEnum.term() != null) {\n      while (termEnum.term().field() == field) {\n        TermPositions termPositions = indexReader.termPositions(termEnum.term());\n        if (termPositions.skipTo(documentNumber)) {\n  \n          frequencies.add(Integer.valueOf(termPositions.freq()));\n          tokens.add(termEnum.term().text());\n  \n  \n          if (!mapper.isIgnoringPositions()) {\n            int[] positions = new int[termPositions.freq()];\n            for (int i = 0; i < positions.length; i++) {\n              positions[i] = termPositions.nextPosition();\n            }\n            this.positions.add(positions);\n          } else {\n            positions.add(null);\n          }\n        }\n        termPositions.close();\n        if (!termEnum.next()) {\n          break;\n        }\n      }\n      mapper.setDocumentNumber(documentNumber);\n      mapper.setExpectations(field, tokens.size(), false, !mapper.isIgnoringPositions());\n      for (int i = 0; i < tokens.size(); i++) {\n        mapper.map(tokens.get(i), frequencies.get(i).intValue(), (TermVectorOffsetInfo[]) null, positions.get(i));\n      }\n    }\n    termEnum.close();\n\n\n  }\n\n","sourceOld":"  /**\n   * Populates the mapper with terms available for the given field in a document\n   * by resolving the inverted index.\n   *\n   * @param indexReader\n   * @param field interned field name\n   * @param mapper\n   * @param documentNumber\n   * @throws IOException\n   */\n  private void build(IndexReader indexReader, String field, TermVectorMapper mapper, int documentNumber) throws IOException {\n\n    if (tokens == null) {\n      tokens = new ArrayList/*<String>*/(500);\n      positions = new ArrayList/*<int[]>*/(500);\n      frequencies = new ArrayList/*<Integer>*/(500);\n    } else {\n      tokens.clear();\n      frequencies.clear();\n      positions.clear();\n    }\n\n    TermEnum termEnum = indexReader.terms(new Term(field, \"\"));\n    if (termEnum.term() != null) {\n      while (termEnum.term().field() == field) {\n        TermPositions termPositions = indexReader.termPositions(termEnum.term());\n        if (termPositions.skipTo(documentNumber)) {\n  \n          frequencies.add(Integer.valueOf(termPositions.freq()));\n          tokens.add(termEnum.term().text());\n  \n  \n          if (!mapper.isIgnoringPositions()) {\n            int[] positions = new int[termPositions.freq()];\n            for (int i = 0; i < positions.length; i++) {\n              positions[i] = termPositions.nextPosition();\n            }\n            this.positions.add(positions);\n          } else {\n            positions.add(null);\n          }\n        }\n        termPositions.close();\n        if (!termEnum.next()) {\n          break;\n        }\n      }\n      mapper.setDocumentNumber(documentNumber);\n      mapper.setExpectations(field, tokens.size(), false, !mapper.isIgnoringPositions());\n      for (int i = 0; i < tokens.size(); i++) {\n        mapper.map((String) tokens.get(i), ((Integer) frequencies.get(i)).intValue(), (TermVectorOffsetInfo[]) null, (int[]) positions.get(i));\n      }\n    }\n    termEnum.close();\n\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/index/TermVectorAccessor#build(IndexReader,String,TermVectorMapper,int).mjava","pathOld":"contrib/misc/src/java/org/apache/lucene/index/TermVectorAccessor#build(IndexReader,String,TermVectorMapper,int).mjava","sourceNew":"  /**\n   * Populates the mapper with terms available for the given field in a document\n   * by resolving the inverted index.\n   *\n   * @param indexReader\n   * @param field interned field name\n   * @param mapper\n   * @param documentNumber\n   * @throws IOException\n   */\n  private void build(IndexReader indexReader, String field, TermVectorMapper mapper, int documentNumber) throws IOException {\n\n    if (tokens == null) {\n      tokens = new ArrayList<String>(500);\n      positions = new ArrayList<int[]>(500);\n      frequencies = new ArrayList<Integer>(500);\n    } else {\n      tokens.clear();\n      frequencies.clear();\n      positions.clear();\n    }\n\n    TermEnum termEnum = indexReader.terms(new Term(field, \"\"));\n    if (termEnum.term() != null) {\n      while (termEnum.term().field() == field) {\n        TermPositions termPositions = indexReader.termPositions(termEnum.term());\n        if (termPositions.skipTo(documentNumber)) {\n  \n          frequencies.add(Integer.valueOf(termPositions.freq()));\n          tokens.add(termEnum.term().text());\n  \n  \n          if (!mapper.isIgnoringPositions()) {\n            int[] positions = new int[termPositions.freq()];\n            for (int i = 0; i < positions.length; i++) {\n              positions[i] = termPositions.nextPosition();\n            }\n            this.positions.add(positions);\n          } else {\n            positions.add(null);\n          }\n        }\n        termPositions.close();\n        if (!termEnum.next()) {\n          break;\n        }\n      }\n      mapper.setDocumentNumber(documentNumber);\n      mapper.setExpectations(field, tokens.size(), false, !mapper.isIgnoringPositions());\n      for (int i = 0; i < tokens.size(); i++) {\n        mapper.map(tokens.get(i), frequencies.get(i).intValue(), (TermVectorOffsetInfo[]) null, positions.get(i));\n      }\n    }\n    termEnum.close();\n\n\n  }\n\n","sourceOld":"  /**\n   * Populates the mapper with terms available for the given field in a document\n   * by resolving the inverted index.\n   *\n   * @param indexReader\n   * @param field interned field name\n   * @param mapper\n   * @param documentNumber\n   * @throws IOException\n   */\n  private void build(IndexReader indexReader, String field, TermVectorMapper mapper, int documentNumber) throws IOException {\n\n    if (tokens == null) {\n      tokens = new ArrayList<String>(500);\n      positions = new ArrayList<int[]>(500);\n      frequencies = new ArrayList<Integer>(500);\n    } else {\n      tokens.clear();\n      frequencies.clear();\n      positions.clear();\n    }\n\n    TermEnum termEnum = indexReader.terms(new Term(field, \"\"));\n    if (termEnum.term() != null) {\n      while (termEnum.term().field() == field) {\n        TermPositions termPositions = indexReader.termPositions(termEnum.term());\n        if (termPositions.skipTo(documentNumber)) {\n  \n          frequencies.add(Integer.valueOf(termPositions.freq()));\n          tokens.add(termEnum.term().text());\n  \n  \n          if (!mapper.isIgnoringPositions()) {\n            int[] positions = new int[termPositions.freq()];\n            for (int i = 0; i < positions.length; i++) {\n              positions[i] = termPositions.nextPosition();\n            }\n            this.positions.add(positions);\n          } else {\n            positions.add(null);\n          }\n        }\n        termPositions.close();\n        if (!termEnum.next()) {\n          break;\n        }\n      }\n      mapper.setDocumentNumber(documentNumber);\n      mapper.setExpectations(field, tokens.size(), false, !mapper.isIgnoringPositions());\n      for (int i = 0; i < tokens.size(); i++) {\n        mapper.map(tokens.get(i), frequencies.get(i).intValue(), (TermVectorOffsetInfo[]) null, positions.get(i));\n      }\n    }\n    termEnum.close();\n\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"6bcde5e3f23911110baa101ed062b544162825b5":["48bedd31c61edafb8baaff4bcbcac19449fb7c3a"],"48bedd31c61edafb8baaff4bcbcac19449fb7c3a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"560b3a3bb8efcae105d6ae5fbee0f8b03c7decc7":["6bcde5e3f23911110baa101ed062b544162825b5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["f11899016a0460a7ea2e4b008d002e1e75c7d867"],"f11899016a0460a7ea2e4b008d002e1e75c7d867":["560b3a3bb8efcae105d6ae5fbee0f8b03c7decc7"]},"commit2Childs":{"6bcde5e3f23911110baa101ed062b544162825b5":["560b3a3bb8efcae105d6ae5fbee0f8b03c7decc7"],"48bedd31c61edafb8baaff4bcbcac19449fb7c3a":["6bcde5e3f23911110baa101ed062b544162825b5"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["48bedd31c61edafb8baaff4bcbcac19449fb7c3a"],"560b3a3bb8efcae105d6ae5fbee0f8b03c7decc7":["f11899016a0460a7ea2e4b008d002e1e75c7d867"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"f11899016a0460a7ea2e4b008d002e1e75c7d867":["9454a6510e2db155fb01faa5c049b06ece95fab9"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}