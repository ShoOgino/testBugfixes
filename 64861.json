{"path":"solr/core/src/test/org/apache/solr/handler/tagger/Tagger2Test#testVeryLongWord().mjava","commits":[{"id":"e091f281a6e026f8bb17aaf194efd0bbd3a7f549","date":1528221895,"type":0,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/handler/tagger/Tagger2Test#testVeryLongWord().mjava","pathOld":"/dev/null","sourceNew":"  // As of Lucene/Solr 4.9, StandardTokenizer never does this anymore (reported to Lucene dev-list,\n  // Jan 26th 2015.  Honestly it's not particularly important to us but it renders this test\n  // pointless.\n  /** Orig issue https://github.com/OpenSextant/SolrTextTagger/issues/2  related: #13 */\n  @Test\n  @Ignore\n  public void testVeryLongWord() throws Exception {\n    String SANFRAN = \"San Francisco\";\n    buildNames(SANFRAN);\n\n    // exceeds default 255 max token length which means it in-effect becomes a stop-word\n    StringBuilder STOP = new StringBuilder(260);//>255\n    for (int i = 0; i < STOP.capacity(); i++) {\n      STOP.append((char) ('0' + (i % 10)));\n    }\n\n    String doc = \"San \" + STOP + \" Francisco\";\n    assertTags(doc);//no match due to default stop word handling\n    //and we find it when we ignore stop words\n    assertTags(reqDoc(doc, \"ignoreStopwords\", \"true\"), new TestTag(0, doc.length(), doc, lookupByName(SANFRAN)));\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f592209545c71895260367152601e9200399776d","date":1528238935,"type":0,"author":"Michael Braun","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/handler/tagger/Tagger2Test#testVeryLongWord().mjava","pathOld":"/dev/null","sourceNew":"  // As of Lucene/Solr 4.9, StandardTokenizer never does this anymore (reported to Lucene dev-list,\n  // Jan 26th 2015.  Honestly it's not particularly important to us but it renders this test\n  // pointless.\n  /** Orig issue https://github.com/OpenSextant/SolrTextTagger/issues/2  related: #13 */\n  @Test\n  @Ignore\n  public void testVeryLongWord() throws Exception {\n    String SANFRAN = \"San Francisco\";\n    buildNames(SANFRAN);\n\n    // exceeds default 255 max token length which means it in-effect becomes a stop-word\n    StringBuilder STOP = new StringBuilder(260);//>255\n    for (int i = 0; i < STOP.capacity(); i++) {\n      STOP.append((char) ('0' + (i % 10)));\n    }\n\n    String doc = \"San \" + STOP + \" Francisco\";\n    assertTags(doc);//no match due to default stop word handling\n    //and we find it when we ignore stop words\n    assertTags(reqDoc(doc, \"ignoreStopwords\", \"true\"), new TestTag(0, doc.length(), doc, lookupByName(SANFRAN)));\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b70042a8a492f7054d480ccdd2be9796510d4327","date":1528386658,"type":0,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/handler/tagger/Tagger2Test#testVeryLongWord().mjava","pathOld":"/dev/null","sourceNew":"  // As of Lucene/Solr 4.9, StandardTokenizer never does this anymore (reported to Lucene dev-list,\n  // Jan 26th 2015.  Honestly it's not particularly important to us but it renders this test\n  // pointless.\n  /** Orig issue https://github.com/OpenSextant/SolrTextTagger/issues/2  related: #13 */\n  @Test\n  @Ignore\n  public void testVeryLongWord() throws Exception {\n    String SANFRAN = \"San Francisco\";\n    buildNames(SANFRAN);\n\n    // exceeds default 255 max token length which means it in-effect becomes a stop-word\n    StringBuilder STOP = new StringBuilder(260);//>255\n    for (int i = 0; i < STOP.capacity(); i++) {\n      STOP.append((char) ('0' + (i % 10)));\n    }\n\n    String doc = \"San \" + STOP + \" Francisco\";\n    assertTags(doc);//no match due to default stop word handling\n    //and we find it when we ignore stop words\n    assertTags(reqDoc(doc, \"ignoreStopwords\", \"true\"), new TestTag(0, doc.length(), doc, lookupByName(SANFRAN)));\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b70042a8a492f7054d480ccdd2be9796510d4327":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","e091f281a6e026f8bb17aaf194efd0bbd3a7f549"],"f592209545c71895260367152601e9200399776d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","e091f281a6e026f8bb17aaf194efd0bbd3a7f549"],"e091f281a6e026f8bb17aaf194efd0bbd3a7f549":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["e091f281a6e026f8bb17aaf194efd0bbd3a7f549"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b70042a8a492f7054d480ccdd2be9796510d4327","f592209545c71895260367152601e9200399776d","e091f281a6e026f8bb17aaf194efd0bbd3a7f549"],"b70042a8a492f7054d480ccdd2be9796510d4327":[],"f592209545c71895260367152601e9200399776d":[],"e091f281a6e026f8bb17aaf194efd0bbd3a7f549":["b70042a8a492f7054d480ccdd2be9796510d4327","f592209545c71895260367152601e9200399776d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["b70042a8a492f7054d480ccdd2be9796510d4327","f592209545c71895260367152601e9200399776d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}