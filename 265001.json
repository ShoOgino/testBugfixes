{"path":"lucene/contrib/misc/src/test/org/apache/lucene/queryParser/complexPhrase/TestComplexPhraseQuery#checkMatches(String,String).mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/misc/src/test/org/apache/lucene/queryParser/complexPhrase/TestComplexPhraseQuery#checkMatches(String,String).mjava","pathOld":"contrib/misc/src/test/org/apache/lucene/queryParser/complexPhrase/TestComplexPhraseQuery#checkMatches(String,String).mjava","sourceNew":"  private void checkMatches(String qString, String expectedVals)\n      throws Exception {\n    QueryParser qp = new ComplexPhraseQueryParser(TEST_VERSION_CURRENT, defaultFieldName, analyzer);\n    qp.setFuzzyPrefixLength(1); // usually a good idea\n\n    Query q = qp.parse(qString);\n\n    HashSet<String> expecteds = new HashSet<String>();\n    String[] vals = expectedVals.split(\",\");\n    for (int i = 0; i < vals.length; i++) {\n      if (vals[i].length() > 0)\n        expecteds.add(vals[i]);\n    }\n\n    TopDocs td = searcher.search(q, 10);\n    ScoreDoc[] sd = td.scoreDocs;\n    for (int i = 0; i < sd.length; i++) {\n      Document doc = searcher.doc(sd[i].doc);\n      String id = doc.get(\"id\");\n      assertTrue(qString + \"matched doc#\" + id + \" not expected\", expecteds\n          .contains(id));\n      expecteds.remove(id);\n    }\n\n    assertEquals(qString + \" missing some matches \", 0, expecteds.size());\n\n  }\n\n","sourceOld":"  private void checkMatches(String qString, String expectedVals)\n      throws Exception {\n    QueryParser qp = new ComplexPhraseQueryParser(TEST_VERSION_CURRENT, defaultFieldName, analyzer);\n    qp.setFuzzyPrefixLength(1); // usually a good idea\n\n    Query q = qp.parse(qString);\n\n    HashSet<String> expecteds = new HashSet<String>();\n    String[] vals = expectedVals.split(\",\");\n    for (int i = 0; i < vals.length; i++) {\n      if (vals[i].length() > 0)\n        expecteds.add(vals[i]);\n    }\n\n    TopDocs td = searcher.search(q, 10);\n    ScoreDoc[] sd = td.scoreDocs;\n    for (int i = 0; i < sd.length; i++) {\n      Document doc = searcher.doc(sd[i].doc);\n      String id = doc.get(\"id\");\n      assertTrue(qString + \"matched doc#\" + id + \" not expected\", expecteds\n          .contains(id));\n      expecteds.remove(id);\n    }\n\n    assertEquals(qString + \" missing some matches \", 0, expecteds.size());\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"36f91bf9cfc9d0c3155edab43359e7670ea8a5af","date":1269580873,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/queryparser/src/test/org/apache/lucene/queryParser/complexPhrase/TestComplexPhraseQuery#checkMatches(String,String).mjava","pathOld":"lucene/contrib/misc/src/test/org/apache/lucene/queryParser/complexPhrase/TestComplexPhraseQuery#checkMatches(String,String).mjava","sourceNew":"  private void checkMatches(String qString, String expectedVals)\n      throws Exception {\n    QueryParser qp = new ComplexPhraseQueryParser(TEST_VERSION_CURRENT, defaultFieldName, analyzer);\n    qp.setFuzzyPrefixLength(1); // usually a good idea\n\n    Query q = qp.parse(qString);\n\n    HashSet<String> expecteds = new HashSet<String>();\n    String[] vals = expectedVals.split(\",\");\n    for (int i = 0; i < vals.length; i++) {\n      if (vals[i].length() > 0)\n        expecteds.add(vals[i]);\n    }\n\n    TopDocs td = searcher.search(q, 10);\n    ScoreDoc[] sd = td.scoreDocs;\n    for (int i = 0; i < sd.length; i++) {\n      Document doc = searcher.doc(sd[i].doc);\n      String id = doc.get(\"id\");\n      assertTrue(qString + \"matched doc#\" + id + \" not expected\", expecteds\n          .contains(id));\n      expecteds.remove(id);\n    }\n\n    assertEquals(qString + \" missing some matches \", 0, expecteds.size());\n\n  }\n\n","sourceOld":"  private void checkMatches(String qString, String expectedVals)\n      throws Exception {\n    QueryParser qp = new ComplexPhraseQueryParser(TEST_VERSION_CURRENT, defaultFieldName, analyzer);\n    qp.setFuzzyPrefixLength(1); // usually a good idea\n\n    Query q = qp.parse(qString);\n\n    HashSet<String> expecteds = new HashSet<String>();\n    String[] vals = expectedVals.split(\",\");\n    for (int i = 0; i < vals.length; i++) {\n      if (vals[i].length() > 0)\n        expecteds.add(vals[i]);\n    }\n\n    TopDocs td = searcher.search(q, 10);\n    ScoreDoc[] sd = td.scoreDocs;\n    for (int i = 0; i < sd.length; i++) {\n      Document doc = searcher.doc(sd[i].doc);\n      String id = doc.get(\"id\");\n      assertTrue(qString + \"matched doc#\" + id + \" not expected\", expecteds\n          .contains(id));\n      expecteds.remove(id);\n    }\n\n    assertEquals(qString + \" missing some matches \", 0, expecteds.size());\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"36f91bf9cfc9d0c3155edab43359e7670ea8a5af":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["36f91bf9cfc9d0c3155edab43359e7670ea8a5af"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"36f91bf9cfc9d0c3155edab43359e7670ea8a5af":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["36f91bf9cfc9d0c3155edab43359e7670ea8a5af"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}