{"path":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#SegmentReader(SegmentInfoPerCommit,SegmentReader,Bits,int).mjava","commits":[{"id":"e072d0b1fc19e0533d8ce432eed245196bca6fde","date":1379265112,"type":0,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#SegmentReader(SegmentInfoPerCommit,SegmentReader,Bits,int).mjava","pathOld":"/dev/null","sourceNew":"  /** Create new SegmentReader sharing core from a previous\n   *  SegmentReader and using the provided in-memory\n   *  liveDocs.  Used by IndexWriter to provide a new NRT\n   *  reader */\n  SegmentReader(SegmentInfoPerCommit si, SegmentReader sr, Bits liveDocs, int numDocs) throws IOException {\n    this.si = si;\n    this.liveDocs = liveDocs;\n    this.numDocs = numDocs;\n    this.core = sr.core;\n    core.incRef();\n    \n    // increment refCount of DocValuesProducers that are used by this reader\n    boolean success = false;\n    try {\n      if (core.fieldInfos.hasDocValues()) {\n        final Codec codec = si.info.getCodec();\n        final Directory dir = core.cfsReader != null ? core.cfsReader : si.info.dir;\n        \n        final DocValuesFormat dvFormat = codec.docValuesFormat();\n        final Map<Long,List<FieldInfo>> genInfos = getGenInfos(si);\n        \n        for (Entry<Long,List<FieldInfo>> e : genInfos.entrySet()) {\n          Long gen = e.getKey();\n          List<FieldInfo> infos = e.getValue();\n          RefCount<DocValuesProducer> dvp = genDVProducers.get(gen);\n          if (dvp == null) {\n            // check if this DVP gen is used by the given reader\n            dvp = sr.genDVProducers.get(gen);\n            if (dvp != null) {\n              // gen used by given reader, incRef its DVP\n              dvp.incRef();\n            } else {\n              // this gen is not used by given reader, initialize a new one\n              dvp = newDocValuesProducer(si, IOContext.READ, dir, dvFormat, gen, infos);\n            }\n            assert dvp != null;\n            genDVProducers.put(gen, dvp);\n          }\n          for (FieldInfo fi : infos) {\n            dvProducers.put(fi.name, dvp.get());\n          }\n        }\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        doClose();\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["f412711b73fe38b28bb793928ad02da8c829cff5"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"75e4e08ceec867127dcd9913a5ebbc46cf85a28d","date":1379651991,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#SegmentReader(SegmentInfoPerCommit,SegmentReader,Bits,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#SegmentReader(SegmentInfoPerCommit,SegmentReader,Bits,int).mjava","sourceNew":"  /** Create new SegmentReader sharing core from a previous\n   *  SegmentReader and using the provided in-memory\n   *  liveDocs.  Used by IndexWriter to provide a new NRT\n   *  reader */\n  SegmentReader(SegmentInfoPerCommit si, SegmentReader sr, Bits liveDocs, int numDocs) throws IOException {\n    this.si = si;\n    this.liveDocs = liveDocs;\n    this.numDocs = numDocs;\n    this.core = sr.core;\n    core.incRef();\n    \n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.init: sharing reader: \" + sr + \" for gens=\" + sr.genDVProducers.keySet());\n    \n    // increment refCount of DocValuesProducers that are used by this reader\n    boolean success = false;\n    try {\n      if (core.fieldInfos.hasDocValues()) {\n        final Codec codec = si.info.getCodec();\n        final Directory dir = core.cfsReader != null ? core.cfsReader : si.info.dir;\n        \n        final DocValuesFormat dvFormat = codec.docValuesFormat();\n        final Map<Long,List<FieldInfo>> genInfos = getGenInfos(si);\n        \n        for (Entry<Long,List<FieldInfo>> e : genInfos.entrySet()) {\n          Long gen = e.getKey();\n          List<FieldInfo> infos = e.getValue();\n          RefCount<DocValuesProducer> dvp = genDVProducers.get(gen);\n          if (dvp == null) {\n            // check if this DVP gen is used by the given reader\n            dvp = sr.genDVProducers.get(gen);\n            if (dvp != null) {\n              // gen used by given reader, incRef its DVP\n              dvp.incRef();\n//              System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.init: sharing DVP for gen=\" + gen + \" refCount=\" + dvp.getRefCount());\n            } else {\n              // this gen is not used by given reader, initialize a new one\n              dvp = newDocValuesProducer(si, IOContext.READ, dir, dvFormat, gen, infos);\n//              System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.init: new DVP for gen=\" + gen + \" refCount=\" + dvp.getRefCount());\n            }\n            assert dvp != null;\n            genDVProducers.put(gen, dvp);\n          }\n          for (FieldInfo fi : infos) {\n            dvProducers.put(fi.name, dvp.get());\n          }\n        }\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        doClose();\n      }\n    }\n  }\n\n","sourceOld":"  /** Create new SegmentReader sharing core from a previous\n   *  SegmentReader and using the provided in-memory\n   *  liveDocs.  Used by IndexWriter to provide a new NRT\n   *  reader */\n  SegmentReader(SegmentInfoPerCommit si, SegmentReader sr, Bits liveDocs, int numDocs) throws IOException {\n    this.si = si;\n    this.liveDocs = liveDocs;\n    this.numDocs = numDocs;\n    this.core = sr.core;\n    core.incRef();\n    \n    // increment refCount of DocValuesProducers that are used by this reader\n    boolean success = false;\n    try {\n      if (core.fieldInfos.hasDocValues()) {\n        final Codec codec = si.info.getCodec();\n        final Directory dir = core.cfsReader != null ? core.cfsReader : si.info.dir;\n        \n        final DocValuesFormat dvFormat = codec.docValuesFormat();\n        final Map<Long,List<FieldInfo>> genInfos = getGenInfos(si);\n        \n        for (Entry<Long,List<FieldInfo>> e : genInfos.entrySet()) {\n          Long gen = e.getKey();\n          List<FieldInfo> infos = e.getValue();\n          RefCount<DocValuesProducer> dvp = genDVProducers.get(gen);\n          if (dvp == null) {\n            // check if this DVP gen is used by the given reader\n            dvp = sr.genDVProducers.get(gen);\n            if (dvp != null) {\n              // gen used by given reader, incRef its DVP\n              dvp.incRef();\n            } else {\n              // this gen is not used by given reader, initialize a new one\n              dvp = newDocValuesProducer(si, IOContext.READ, dir, dvFormat, gen, infos);\n            }\n            assert dvp != null;\n            genDVProducers.put(gen, dvp);\n          }\n          for (FieldInfo fi : infos) {\n            dvProducers.put(fi.name, dvp.get());\n          }\n        }\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        doClose();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8435160e9702b19398118ddf76b61c846612b6a4","date":1380349140,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#SegmentReader(SegmentInfoPerCommit,SegmentReader,Bits,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#SegmentReader(SegmentInfoPerCommit,SegmentReader,Bits,int).mjava","sourceNew":"  /** Create new SegmentReader sharing core from a previous\n   *  SegmentReader and using the provided in-memory\n   *  liveDocs.  Used by IndexWriter to provide a new NRT\n   *  reader */\n  SegmentReader(SegmentInfoPerCommit si, SegmentReader sr, Bits liveDocs, int numDocs) throws IOException {\n    this.si = si;\n    this.liveDocs = liveDocs;\n    this.numDocs = numDocs;\n    this.core = sr.core;\n    core.incRef();\n    \n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.init: sharing reader: \" + sr + \" for gens=\" + sr.genDVProducers.keySet());\n    \n    // increment refCount of DocValuesProducers that are used by this reader\n    boolean success = false;\n    try {\n      final Codec codec = si.info.getCodec();\n      if (si.getFieldInfosGen() == -1) {\n        fieldInfos = sr.fieldInfos;\n      } else {\n        fieldInfos = readFieldInfos(si);\n      }\n      \n      if (fieldInfos.hasDocValues()) {\n        final Directory dir = core.cfsReader != null ? core.cfsReader : si.info.dir;\n        \n        final DocValuesFormat dvFormat = codec.docValuesFormat();\n        final Map<Long,List<FieldInfo>> genInfos = getGenInfos(si);\n        \n        for (Entry<Long,List<FieldInfo>> e : genInfos.entrySet()) {\n          Long gen = e.getKey();\n          List<FieldInfo> infos = e.getValue();\n          RefCount<DocValuesProducer> dvp = genDVProducers.get(gen);\n          if (dvp == null) {\n            // check if this DVP gen is used by the given reader\n            dvp = sr.genDVProducers.get(gen);\n            if (dvp != null) {\n              // gen used by given reader, incRef its DVP\n              dvp.incRef();\n//              System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.init: sharing DVP for gen=\" + gen + \" refCount=\" + dvp.getRefCount());\n            } else {\n              // this gen is not used by given reader, initialize a new one\n              dvp = newDocValuesProducer(si, IOContext.READ, dir, dvFormat, gen, infos);\n//              System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.init: new DVP for gen=\" + gen + \" refCount=\" + dvp.getRefCount());\n            }\n            assert dvp != null;\n            genDVProducers.put(gen, dvp);\n          }\n          for (FieldInfo fi : infos) {\n            dvProducers.put(fi.name, dvp.get());\n          }\n        }\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        doClose();\n      }\n    }\n  }\n\n","sourceOld":"  /** Create new SegmentReader sharing core from a previous\n   *  SegmentReader and using the provided in-memory\n   *  liveDocs.  Used by IndexWriter to provide a new NRT\n   *  reader */\n  SegmentReader(SegmentInfoPerCommit si, SegmentReader sr, Bits liveDocs, int numDocs) throws IOException {\n    this.si = si;\n    this.liveDocs = liveDocs;\n    this.numDocs = numDocs;\n    this.core = sr.core;\n    core.incRef();\n    \n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.init: sharing reader: \" + sr + \" for gens=\" + sr.genDVProducers.keySet());\n    \n    // increment refCount of DocValuesProducers that are used by this reader\n    boolean success = false;\n    try {\n      if (core.fieldInfos.hasDocValues()) {\n        final Codec codec = si.info.getCodec();\n        final Directory dir = core.cfsReader != null ? core.cfsReader : si.info.dir;\n        \n        final DocValuesFormat dvFormat = codec.docValuesFormat();\n        final Map<Long,List<FieldInfo>> genInfos = getGenInfos(si);\n        \n        for (Entry<Long,List<FieldInfo>> e : genInfos.entrySet()) {\n          Long gen = e.getKey();\n          List<FieldInfo> infos = e.getValue();\n          RefCount<DocValuesProducer> dvp = genDVProducers.get(gen);\n          if (dvp == null) {\n            // check if this DVP gen is used by the given reader\n            dvp = sr.genDVProducers.get(gen);\n            if (dvp != null) {\n              // gen used by given reader, incRef its DVP\n              dvp.incRef();\n//              System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.init: sharing DVP for gen=\" + gen + \" refCount=\" + dvp.getRefCount());\n            } else {\n              // this gen is not used by given reader, initialize a new one\n              dvp = newDocValuesProducer(si, IOContext.READ, dir, dvFormat, gen, infos);\n//              System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.init: new DVP for gen=\" + gen + \" refCount=\" + dvp.getRefCount());\n            }\n            assert dvp != null;\n            genDVProducers.put(gen, dvp);\n          }\n          for (FieldInfo fi : infos) {\n            dvProducers.put(fi.name, dvp.get());\n          }\n        }\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        doClose();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2f13fb377f9b5df46af44bf90a2e507a884f2c30","date":1380476222,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#SegmentReader(SegmentInfoPerCommit,SegmentReader,Bits,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#SegmentReader(SegmentInfoPerCommit,SegmentReader,Bits,int).mjava","sourceNew":"  /** Create new SegmentReader sharing core from a previous\n   *  SegmentReader and using the provided in-memory\n   *  liveDocs.  Used by IndexWriter to provide a new NRT\n   *  reader */\n  SegmentReader(SegmentInfoPerCommit si, SegmentReader sr, Bits liveDocs, int numDocs) throws IOException {\n    this.si = si;\n    this.liveDocs = liveDocs;\n    this.numDocs = numDocs;\n    this.core = sr.core;\n    core.incRef();\n    \n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.init: sharing reader: \" + sr + \" for gens=\" + sr.genDVProducers.keySet());\n    \n    // increment refCount of DocValuesProducers that are used by this reader\n    boolean success = false;\n    try {\n      final Codec codec = si.info.getCodec();\n      if (si.getFieldInfosGen() == -1) {\n        fieldInfos = sr.fieldInfos;\n      } else {\n        fieldInfos = readFieldInfos(si);\n      }\n      \n      if (fieldInfos.hasDocValues()) {\n        final Directory dir = core.cfsReader != null ? core.cfsReader : si.info.dir;\n        \n        final DocValuesFormat dvFormat = codec.docValuesFormat();\n        final Map<Long,List<FieldInfo>> genInfos = getGenInfos();\n        \n        for (Entry<Long,List<FieldInfo>> e : genInfos.entrySet()) {\n          Long gen = e.getKey();\n          List<FieldInfo> infos = e.getValue();\n          RefCount<DocValuesProducer> dvp = genDVProducers.get(gen);\n          if (dvp == null) {\n            // check if this DVP gen is used by the given reader\n            dvp = sr.genDVProducers.get(gen);\n            if (dvp != null) {\n              // gen used by given reader, incRef its DVP\n              dvp.incRef();\n//              System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.init: sharing DVP for gen=\" + gen + \" refCount=\" + dvp.getRefCount());\n            } else {\n              // this gen is not used by given reader, initialize a new one\n              dvp = newDocValuesProducer(si, IOContext.READ, dir, dvFormat, gen, infos);\n//              System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.init: new DVP for gen=\" + gen + \" refCount=\" + dvp.getRefCount());\n            }\n            assert dvp != null;\n            genDVProducers.put(gen, dvp);\n          }\n          for (FieldInfo fi : infos) {\n            dvProducers.put(fi.name, dvp.get());\n          }\n        }\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        doClose();\n      }\n    }\n  }\n\n","sourceOld":"  /** Create new SegmentReader sharing core from a previous\n   *  SegmentReader and using the provided in-memory\n   *  liveDocs.  Used by IndexWriter to provide a new NRT\n   *  reader */\n  SegmentReader(SegmentInfoPerCommit si, SegmentReader sr, Bits liveDocs, int numDocs) throws IOException {\n    this.si = si;\n    this.liveDocs = liveDocs;\n    this.numDocs = numDocs;\n    this.core = sr.core;\n    core.incRef();\n    \n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.init: sharing reader: \" + sr + \" for gens=\" + sr.genDVProducers.keySet());\n    \n    // increment refCount of DocValuesProducers that are used by this reader\n    boolean success = false;\n    try {\n      final Codec codec = si.info.getCodec();\n      if (si.getFieldInfosGen() == -1) {\n        fieldInfos = sr.fieldInfos;\n      } else {\n        fieldInfos = readFieldInfos(si);\n      }\n      \n      if (fieldInfos.hasDocValues()) {\n        final Directory dir = core.cfsReader != null ? core.cfsReader : si.info.dir;\n        \n        final DocValuesFormat dvFormat = codec.docValuesFormat();\n        final Map<Long,List<FieldInfo>> genInfos = getGenInfos(si);\n        \n        for (Entry<Long,List<FieldInfo>> e : genInfos.entrySet()) {\n          Long gen = e.getKey();\n          List<FieldInfo> infos = e.getValue();\n          RefCount<DocValuesProducer> dvp = genDVProducers.get(gen);\n          if (dvp == null) {\n            // check if this DVP gen is used by the given reader\n            dvp = sr.genDVProducers.get(gen);\n            if (dvp != null) {\n              // gen used by given reader, incRef its DVP\n              dvp.incRef();\n//              System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.init: sharing DVP for gen=\" + gen + \" refCount=\" + dvp.getRefCount());\n            } else {\n              // this gen is not used by given reader, initialize a new one\n              dvp = newDocValuesProducer(si, IOContext.READ, dir, dvFormat, gen, infos);\n//              System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.init: new DVP for gen=\" + gen + \" refCount=\" + dvp.getRefCount());\n            }\n            assert dvp != null;\n            genDVProducers.put(gen, dvp);\n          }\n          for (FieldInfo fi : infos) {\n            dvProducers.put(fi.name, dvp.get());\n          }\n        }\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        doClose();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ac14bdd59867c398bdb1a9cc50583bd3c93593e5","date":1382646404,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#SegmentReader(SegmentInfoPerCommit,SegmentReader,Bits,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#SegmentReader(SegmentInfoPerCommit,SegmentReader,Bits,int).mjava","sourceNew":"  /** Create new SegmentReader sharing core from a previous\n   *  SegmentReader and using the provided in-memory\n   *  liveDocs.  Used by IndexWriter to provide a new NRT\n   *  reader */\n  SegmentReader(SegmentInfoPerCommit si, SegmentReader sr, Bits liveDocs, int numDocs) throws IOException {\n    this.si = si;\n    this.liveDocs = liveDocs;\n    this.numDocs = numDocs;\n    this.core = sr.core;\n    core.incRef();\n    this.segDocValues = sr.segDocValues;\n    \n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.init: sharing reader: \" + sr + \" for gens=\" + sr.genDVProducers.keySet());\n    \n    // increment refCount of DocValuesProducers that are used by this reader\n    boolean success = false;\n    try {\n      final Codec codec = si.info.getCodec();\n      if (si.getFieldInfosGen() == -1) {\n        fieldInfos = sr.fieldInfos;\n      } else {\n        fieldInfos = readFieldInfos(si);\n      }\n      \n      if (fieldInfos.hasDocValues()) {\n        initDocValuesProducers(codec);\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        doClose();\n      }\n    }\n  }\n\n","sourceOld":"  /** Create new SegmentReader sharing core from a previous\n   *  SegmentReader and using the provided in-memory\n   *  liveDocs.  Used by IndexWriter to provide a new NRT\n   *  reader */\n  SegmentReader(SegmentInfoPerCommit si, SegmentReader sr, Bits liveDocs, int numDocs) throws IOException {\n    this.si = si;\n    this.liveDocs = liveDocs;\n    this.numDocs = numDocs;\n    this.core = sr.core;\n    core.incRef();\n    \n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.init: sharing reader: \" + sr + \" for gens=\" + sr.genDVProducers.keySet());\n    \n    // increment refCount of DocValuesProducers that are used by this reader\n    boolean success = false;\n    try {\n      final Codec codec = si.info.getCodec();\n      if (si.getFieldInfosGen() == -1) {\n        fieldInfos = sr.fieldInfos;\n      } else {\n        fieldInfos = readFieldInfos(si);\n      }\n      \n      if (fieldInfos.hasDocValues()) {\n        final Directory dir = core.cfsReader != null ? core.cfsReader : si.info.dir;\n        \n        final DocValuesFormat dvFormat = codec.docValuesFormat();\n        final Map<Long,List<FieldInfo>> genInfos = getGenInfos();\n        \n        for (Entry<Long,List<FieldInfo>> e : genInfos.entrySet()) {\n          Long gen = e.getKey();\n          List<FieldInfo> infos = e.getValue();\n          RefCount<DocValuesProducer> dvp = genDVProducers.get(gen);\n          if (dvp == null) {\n            // check if this DVP gen is used by the given reader\n            dvp = sr.genDVProducers.get(gen);\n            if (dvp != null) {\n              // gen used by given reader, incRef its DVP\n              dvp.incRef();\n//              System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.init: sharing DVP for gen=\" + gen + \" refCount=\" + dvp.getRefCount());\n            } else {\n              // this gen is not used by given reader, initialize a new one\n              dvp = newDocValuesProducer(si, IOContext.READ, dir, dvFormat, gen, infos);\n//              System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.init: new DVP for gen=\" + gen + \" refCount=\" + dvp.getRefCount());\n            }\n            assert dvp != null;\n            genDVProducers.put(gen, dvp);\n          }\n          for (FieldInfo fi : infos) {\n            dvProducers.put(fi.name, dvp.get());\n          }\n        }\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        doClose();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["f412711b73fe38b28bb793928ad02da8c829cff5"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0","date":1383367127,"type":5,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#SegmentReader(SegmentCommitInfo,SegmentReader,Bits,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#SegmentReader(SegmentInfoPerCommit,SegmentReader,Bits,int).mjava","sourceNew":"  /** Create new SegmentReader sharing core from a previous\n   *  SegmentReader and using the provided in-memory\n   *  liveDocs.  Used by IndexWriter to provide a new NRT\n   *  reader */\n  SegmentReader(SegmentCommitInfo si, SegmentReader sr, Bits liveDocs, int numDocs) throws IOException {\n    this.si = si;\n    this.liveDocs = liveDocs;\n    this.numDocs = numDocs;\n    this.core = sr.core;\n    core.incRef();\n    this.segDocValues = sr.segDocValues;\n    \n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.init: sharing reader: \" + sr + \" for gens=\" + sr.genDVProducers.keySet());\n    \n    // increment refCount of DocValuesProducers that are used by this reader\n    boolean success = false;\n    try {\n      final Codec codec = si.info.getCodec();\n      if (si.getFieldInfosGen() == -1) {\n        fieldInfos = sr.fieldInfos;\n      } else {\n        fieldInfos = readFieldInfos(si);\n      }\n      \n      if (fieldInfos.hasDocValues()) {\n        initDocValuesProducers(codec);\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        doClose();\n      }\n    }\n  }\n\n","sourceOld":"  /** Create new SegmentReader sharing core from a previous\n   *  SegmentReader and using the provided in-memory\n   *  liveDocs.  Used by IndexWriter to provide a new NRT\n   *  reader */\n  SegmentReader(SegmentInfoPerCommit si, SegmentReader sr, Bits liveDocs, int numDocs) throws IOException {\n    this.si = si;\n    this.liveDocs = liveDocs;\n    this.numDocs = numDocs;\n    this.core = sr.core;\n    core.incRef();\n    this.segDocValues = sr.segDocValues;\n    \n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.init: sharing reader: \" + sr + \" for gens=\" + sr.genDVProducers.keySet());\n    \n    // increment refCount of DocValuesProducers that are used by this reader\n    boolean success = false;\n    try {\n      final Codec codec = si.info.getCodec();\n      if (si.getFieldInfosGen() == -1) {\n        fieldInfos = sr.fieldInfos;\n      } else {\n        fieldInfos = readFieldInfos(si);\n      }\n      \n      if (fieldInfos.hasDocValues()) {\n        initDocValuesProducers(codec);\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        doClose();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"e072d0b1fc19e0533d8ce432eed245196bca6fde":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0":["ac14bdd59867c398bdb1a9cc50583bd3c93593e5"],"75e4e08ceec867127dcd9913a5ebbc46cf85a28d":["e072d0b1fc19e0533d8ce432eed245196bca6fde"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"8435160e9702b19398118ddf76b61c846612b6a4":["75e4e08ceec867127dcd9913a5ebbc46cf85a28d"],"2f13fb377f9b5df46af44bf90a2e507a884f2c30":["8435160e9702b19398118ddf76b61c846612b6a4"],"ac14bdd59867c398bdb1a9cc50583bd3c93593e5":["2f13fb377f9b5df46af44bf90a2e507a884f2c30"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0"]},"commit2Childs":{"e072d0b1fc19e0533d8ce432eed245196bca6fde":["75e4e08ceec867127dcd9913a5ebbc46cf85a28d"],"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"75e4e08ceec867127dcd9913a5ebbc46cf85a28d":["8435160e9702b19398118ddf76b61c846612b6a4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["e072d0b1fc19e0533d8ce432eed245196bca6fde"],"8435160e9702b19398118ddf76b61c846612b6a4":["2f13fb377f9b5df46af44bf90a2e507a884f2c30"],"2f13fb377f9b5df46af44bf90a2e507a884f2c30":["ac14bdd59867c398bdb1a9cc50583bd3c93593e5"],"ac14bdd59867c398bdb1a9cc50583bd3c93593e5":["73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}