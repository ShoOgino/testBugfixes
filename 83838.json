{"path":"lucene/sandbox/src/test/org/apache/lucene/search/TestTermAutomatonQuery#testRandom().mjava","commits":[{"id":"06a4493f0c732d2928d1a4f773f15d19434aa8ba","date":1405856163,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/sandbox/src/test/org/apache/lucene/search/TestTermAutomatonQuery#testRandom().mjava","pathOld":"/dev/null","sourceNew":"  public void testRandom() throws Exception {\n    int numDocs = atLeast(100);\n    Directory dir = newDirectory();\n\n    // Adds occassional random synonyms:\n    Analyzer analyzer = new Analyzer() {\n        @Override\n        public TokenStreamComponents createComponents(String fieldName) {\n          MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true, 100);\n          tokenizer.setEnableChecks(true);\n          TokenFilter filt = new MockTokenFilter(tokenizer, MockTokenFilter.EMPTY_STOPSET);\n          filt = new RandomSynonymFilter(filt);\n          return new TokenStreamComponents(tokenizer, filt);\n        }\n      };\n\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    for(int i=0;i<numDocs;i++) {\n      Document doc = new Document();\n      int numTokens = atLeast(10);\n\n      StringBuilder sb = new StringBuilder();\n      for(int j=0;j<numTokens;j++) {\n        sb.append(' ');\n        sb.append((char) (97 + random().nextInt(3)));\n      }\n      String contents = sb.toString();\n      doc.add(newTextField(\"field\", contents, Field.Store.NO));\n      doc.add(new StoredField(\"id\", \"\"+i));\n      if (VERBOSE) {\n        System.out.println(\"  doc \" + i + \" -> \" + contents);\n      }\n      w.addDocument(doc);\n    }\n\n    IndexReader r = w.getReader();\n    IndexSearcher s = newSearcher(r);\n\n    // Used to match ANY using MultiPhraseQuery:\n    Term[] allTerms = new Term[] {new Term(\"field\", \"a\"),\n                                  new Term(\"field\", \"b\"),\n                                  new Term(\"field\", \"c\")};\n    int numIters = atLeast(1000);\n    for(int iter=0;iter<numIters;iter++) {\n\n      // Build the (finite, no any transitions) TermAutomatonQuery and\n      // also the \"equivalent\" BooleanQuery and make sure they match the\n      // same docs:\n      BooleanQuery bq = new BooleanQuery();\n      int count = TestUtil.nextInt(random(), 1, 5);\n      Set<BytesRef> strings = new HashSet<>();\n      for(int i=0;i<count;i++) {\n        StringBuilder sb = new StringBuilder();\n        int numTokens = TestUtil.nextInt(random(), 1, 5);\n        for(int j=0;j<numTokens;j++) {\n          if (j > 0 && j < numTokens-1 && random().nextInt(5) == 3) {\n            sb.append('*');\n          } else {\n            sb.append((char) (97 + random().nextInt(3)));\n          }\n        }\n        String string = sb.toString();\n        MultiPhraseQuery mpq = new MultiPhraseQuery();\n        for(int j=0;j<string.length();j++) {\n          if (string.charAt(j) == '*') {\n            mpq.add(allTerms);\n          } else {\n            mpq.add(new Term(\"field\", \"\"+string.charAt(j)));\n          }\n        }\n        bq.add(mpq, BooleanClause.Occur.SHOULD);\n        strings.add(new BytesRef(string));\n      }\n\n      List<BytesRef> stringsList = new ArrayList<>(strings);\n      Collections.sort(stringsList);\n\n      Automaton a = Automata.makeStringUnion(stringsList);\n\n      // Translate automaton to query:\n    \n      TermAutomatonQuery q = new TermAutomatonQuery(\"field\");\n      int numStates = a.getNumStates();\n      for(int i=0;i<numStates;i++) {\n        q.createState();\n        q.setAccept(i, a.isAccept(i));\n      }\n\n      Transition t = new Transition();\n      for(int i=0;i<numStates;i++) {\n        int transCount = a.initTransition(i, t);\n        for(int j=0;j<transCount;j++) {\n          a.getNextTransition(t);\n          for(int label=t.min;label<=t.max;label++) {\n            if ((char) label == '*') {\n              q.addAnyTransition(t.source, t.dest);\n            } else {\n              q.addTransition(t.source, t.dest, \"\"+(char) label);\n            }\n          }\n        }\n      }\n      q.finish();\n\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n        for(BytesRef string : stringsList) {\n          System.out.println(\"  string: \" + string.utf8ToString());\n        }\n        System.out.println(q.toDot());\n      }\n      \n      Filter filter;\n      if (random().nextInt(5) == 1) {\n        filter = new RandomFilter(random().nextLong(), random().nextFloat());\n      } else {\n        filter = null;\n      }\n\n      TopDocs hits1 = s.search(q, filter, numDocs);\n      TopDocs hits2 = s.search(bq, filter, numDocs);\n      Set<String> hits1Docs = toDocIDs(s, hits1);\n      Set<String> hits2Docs = toDocIDs(s, hits2);\n\n      try {\n        assertEquals(hits2.totalHits, hits1.totalHits);\n        assertEquals(hits2Docs, hits1Docs);\n      } catch (AssertionError ae) {\n        System.out.println(\"FAILED:\");\n        for(String id : hits1Docs) {\n          if (hits2Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s matched but should not have\", id));\n          }\n        }\n        for(String id : hits2Docs) {\n          if (hits1Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s did not match but should have\", id));\n          }\n        }\n        throw ae;\n      }\n    }\n\n    w.close();\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/sandbox/src/test/org/apache/lucene/search/TestTermAutomatonQuery#testRandom().mjava","pathOld":"lucene/sandbox/src/test/org/apache/lucene/search/TestTermAutomatonQuery#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n    int numDocs = atLeast(100);\n    Directory dir = newDirectory();\n\n    // Adds occassional random synonyms:\n    Analyzer analyzer = new Analyzer() {\n        @Override\n        public TokenStreamComponents createComponents(String fieldName) {\n          MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true, 100);\n          tokenizer.setEnableChecks(true);\n          TokenFilter filt = new MockTokenFilter(tokenizer, MockTokenFilter.EMPTY_STOPSET);\n          filt = new RandomSynonymFilter(filt);\n          return new TokenStreamComponents(tokenizer, filt);\n        }\n      };\n\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    for(int i=0;i<numDocs;i++) {\n      Document doc = new Document();\n      int numTokens = atLeast(10);\n\n      StringBuilder sb = new StringBuilder();\n      for(int j=0;j<numTokens;j++) {\n        sb.append(' ');\n        sb.append((char) (97 + random().nextInt(3)));\n      }\n      String contents = sb.toString();\n      doc.add(newTextField(\"field\", contents, Field.Store.NO));\n      doc.add(new StoredField(\"id\", \"\"+i));\n      if (VERBOSE) {\n        System.out.println(\"  doc \" + i + \" -> \" + contents);\n      }\n      w.addDocument(doc);\n    }\n\n    IndexReader r = w.getReader();\n    IndexSearcher s = newSearcher(r);\n\n    // Used to match ANY using MultiPhraseQuery:\n    Term[] allTerms = new Term[] {new Term(\"field\", \"a\"),\n                                  new Term(\"field\", \"b\"),\n                                  new Term(\"field\", \"c\")};\n    int numIters = atLeast(1000);\n    for(int iter=0;iter<numIters;iter++) {\n\n      // Build the (finite, no any transitions) TermAutomatonQuery and\n      // also the \"equivalent\" BooleanQuery and make sure they match the\n      // same docs:\n      BooleanQuery bq = new BooleanQuery();\n      int count = TestUtil.nextInt(random(), 1, 5);\n      Set<BytesRef> strings = new HashSet<>();\n      for(int i=0;i<count;i++) {\n        StringBuilder sb = new StringBuilder();\n        int numTokens = TestUtil.nextInt(random(), 1, 5);\n        for(int j=0;j<numTokens;j++) {\n          if (j > 0 && j < numTokens-1 && random().nextInt(5) == 3) {\n            sb.append('*');\n          } else {\n            sb.append((char) (97 + random().nextInt(3)));\n          }\n        }\n        String string = sb.toString();\n        MultiPhraseQuery mpq = new MultiPhraseQuery();\n        for(int j=0;j<string.length();j++) {\n          if (string.charAt(j) == '*') {\n            mpq.add(allTerms);\n          } else {\n            mpq.add(new Term(\"field\", \"\"+string.charAt(j)));\n          }\n        }\n        bq.add(mpq, BooleanClause.Occur.SHOULD);\n        strings.add(new BytesRef(string));\n      }\n\n      List<BytesRef> stringsList = new ArrayList<>(strings);\n      Collections.sort(stringsList);\n\n      Automaton a = Automata.makeStringUnion(stringsList);\n\n      // Translate automaton to query:\n    \n      TermAutomatonQuery q = new TermAutomatonQuery(\"field\");\n      int numStates = a.getNumStates();\n      for(int i=0;i<numStates;i++) {\n        q.createState();\n        q.setAccept(i, a.isAccept(i));\n      }\n\n      Transition t = new Transition();\n      for(int i=0;i<numStates;i++) {\n        int transCount = a.initTransition(i, t);\n        for(int j=0;j<transCount;j++) {\n          a.getNextTransition(t);\n          for(int label=t.min;label<=t.max;label++) {\n            if ((char) label == '*') {\n              q.addAnyTransition(t.source, t.dest);\n            } else {\n              q.addTransition(t.source, t.dest, \"\"+(char) label);\n            }\n          }\n        }\n      }\n      q.finish();\n\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n        for(BytesRef string : stringsList) {\n          System.out.println(\"  string: \" + string.utf8ToString());\n        }\n        System.out.println(q.toDot());\n      }\n      \n      Filter filter;\n      if (random().nextInt(5) == 1) {\n        filter = new RandomFilter(random().nextLong(), random().nextFloat());\n      } else {\n        filter = null;\n      }\n\n      TopDocs hits1 = s.search(q, filter, numDocs);\n      TopDocs hits2 = s.search(bq, filter, numDocs);\n      Set<String> hits1Docs = toDocIDs(s, hits1);\n      Set<String> hits2Docs = toDocIDs(s, hits2);\n\n      try {\n        assertEquals(hits2.totalHits, hits1.totalHits);\n        assertEquals(hits2Docs, hits1Docs);\n      } catch (AssertionError ae) {\n        System.out.println(\"FAILED:\");\n        for(String id : hits1Docs) {\n          if (hits2Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s matched but should not have\", id));\n          }\n        }\n        for(String id : hits2Docs) {\n          if (hits1Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s did not match but should have\", id));\n          }\n        }\n        throw ae;\n      }\n    }\n\n    w.close();\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n    int numDocs = atLeast(100);\n    Directory dir = newDirectory();\n\n    // Adds occassional random synonyms:\n    Analyzer analyzer = new Analyzer() {\n        @Override\n        public TokenStreamComponents createComponents(String fieldName) {\n          MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true, 100);\n          tokenizer.setEnableChecks(true);\n          TokenFilter filt = new MockTokenFilter(tokenizer, MockTokenFilter.EMPTY_STOPSET);\n          filt = new RandomSynonymFilter(filt);\n          return new TokenStreamComponents(tokenizer, filt);\n        }\n      };\n\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    for(int i=0;i<numDocs;i++) {\n      Document doc = new Document();\n      int numTokens = atLeast(10);\n\n      StringBuilder sb = new StringBuilder();\n      for(int j=0;j<numTokens;j++) {\n        sb.append(' ');\n        sb.append((char) (97 + random().nextInt(3)));\n      }\n      String contents = sb.toString();\n      doc.add(newTextField(\"field\", contents, Field.Store.NO));\n      doc.add(new StoredField(\"id\", \"\"+i));\n      if (VERBOSE) {\n        System.out.println(\"  doc \" + i + \" -> \" + contents);\n      }\n      w.addDocument(doc);\n    }\n\n    IndexReader r = w.getReader();\n    IndexSearcher s = newSearcher(r);\n\n    // Used to match ANY using MultiPhraseQuery:\n    Term[] allTerms = new Term[] {new Term(\"field\", \"a\"),\n                                  new Term(\"field\", \"b\"),\n                                  new Term(\"field\", \"c\")};\n    int numIters = atLeast(1000);\n    for(int iter=0;iter<numIters;iter++) {\n\n      // Build the (finite, no any transitions) TermAutomatonQuery and\n      // also the \"equivalent\" BooleanQuery and make sure they match the\n      // same docs:\n      BooleanQuery bq = new BooleanQuery();\n      int count = TestUtil.nextInt(random(), 1, 5);\n      Set<BytesRef> strings = new HashSet<>();\n      for(int i=0;i<count;i++) {\n        StringBuilder sb = new StringBuilder();\n        int numTokens = TestUtil.nextInt(random(), 1, 5);\n        for(int j=0;j<numTokens;j++) {\n          if (j > 0 && j < numTokens-1 && random().nextInt(5) == 3) {\n            sb.append('*');\n          } else {\n            sb.append((char) (97 + random().nextInt(3)));\n          }\n        }\n        String string = sb.toString();\n        MultiPhraseQuery mpq = new MultiPhraseQuery();\n        for(int j=0;j<string.length();j++) {\n          if (string.charAt(j) == '*') {\n            mpq.add(allTerms);\n          } else {\n            mpq.add(new Term(\"field\", \"\"+string.charAt(j)));\n          }\n        }\n        bq.add(mpq, BooleanClause.Occur.SHOULD);\n        strings.add(new BytesRef(string));\n      }\n\n      List<BytesRef> stringsList = new ArrayList<>(strings);\n      Collections.sort(stringsList);\n\n      Automaton a = Automata.makeStringUnion(stringsList);\n\n      // Translate automaton to query:\n    \n      TermAutomatonQuery q = new TermAutomatonQuery(\"field\");\n      int numStates = a.getNumStates();\n      for(int i=0;i<numStates;i++) {\n        q.createState();\n        q.setAccept(i, a.isAccept(i));\n      }\n\n      Transition t = new Transition();\n      for(int i=0;i<numStates;i++) {\n        int transCount = a.initTransition(i, t);\n        for(int j=0;j<transCount;j++) {\n          a.getNextTransition(t);\n          for(int label=t.min;label<=t.max;label++) {\n            if ((char) label == '*') {\n              q.addAnyTransition(t.source, t.dest);\n            } else {\n              q.addTransition(t.source, t.dest, \"\"+(char) label);\n            }\n          }\n        }\n      }\n      q.finish();\n\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n        for(BytesRef string : stringsList) {\n          System.out.println(\"  string: \" + string.utf8ToString());\n        }\n        System.out.println(q.toDot());\n      }\n      \n      Filter filter;\n      if (random().nextInt(5) == 1) {\n        filter = new RandomFilter(random().nextLong(), random().nextFloat());\n      } else {\n        filter = null;\n      }\n\n      TopDocs hits1 = s.search(q, filter, numDocs);\n      TopDocs hits2 = s.search(bq, filter, numDocs);\n      Set<String> hits1Docs = toDocIDs(s, hits1);\n      Set<String> hits2Docs = toDocIDs(s, hits2);\n\n      try {\n        assertEquals(hits2.totalHits, hits1.totalHits);\n        assertEquals(hits2Docs, hits1Docs);\n      } catch (AssertionError ae) {\n        System.out.println(\"FAILED:\");\n        for(String id : hits1Docs) {\n          if (hits2Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s matched but should not have\", id));\n          }\n        }\n        for(String id : hits2Docs) {\n          if (hits1Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s did not match but should have\", id));\n          }\n        }\n        throw ae;\n      }\n    }\n\n    w.close();\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc","date":1424799790,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/sandbox/src/test/org/apache/lucene/search/TestTermAutomatonQuery#testRandom().mjava","pathOld":"lucene/sandbox/src/test/org/apache/lucene/search/TestTermAutomatonQuery#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n    int numDocs = atLeast(100);\n    Directory dir = newDirectory();\n\n    // Adds occassional random synonyms:\n    Analyzer analyzer = new Analyzer() {\n        @Override\n        public TokenStreamComponents createComponents(String fieldName) {\n          MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true, 100);\n          tokenizer.setEnableChecks(true);\n          TokenFilter filt = new MockTokenFilter(tokenizer, MockTokenFilter.EMPTY_STOPSET);\n          filt = new RandomSynonymFilter(filt);\n          return new TokenStreamComponents(tokenizer, filt);\n        }\n      };\n\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    for(int i=0;i<numDocs;i++) {\n      Document doc = new Document();\n      int numTokens = atLeast(10);\n\n      StringBuilder sb = new StringBuilder();\n      for(int j=0;j<numTokens;j++) {\n        sb.append(' ');\n        sb.append((char) (97 + random().nextInt(3)));\n      }\n      String contents = sb.toString();\n      doc.add(newTextField(\"field\", contents, Field.Store.NO));\n      doc.add(new StoredField(\"id\", \"\"+i));\n      if (VERBOSE) {\n        System.out.println(\"  doc \" + i + \" -> \" + contents);\n      }\n      w.addDocument(doc);\n    }\n\n    IndexReader r = w.getReader();\n    IndexSearcher s = newSearcher(r);\n\n    // Used to match ANY using MultiPhraseQuery:\n    Term[] allTerms = new Term[] {new Term(\"field\", \"a\"),\n                                  new Term(\"field\", \"b\"),\n                                  new Term(\"field\", \"c\")};\n    int numIters = atLeast(1000);\n    for(int iter=0;iter<numIters;iter++) {\n\n      // Build the (finite, no any transitions) TermAutomatonQuery and\n      // also the \"equivalent\" BooleanQuery and make sure they match the\n      // same docs:\n      BooleanQuery bq = new BooleanQuery();\n      int count = TestUtil.nextInt(random(), 1, 5);\n      Set<BytesRef> strings = new HashSet<>();\n      for(int i=0;i<count;i++) {\n        StringBuilder sb = new StringBuilder();\n        int numTokens = TestUtil.nextInt(random(), 1, 5);\n        for(int j=0;j<numTokens;j++) {\n          if (j > 0 && j < numTokens-1 && random().nextInt(5) == 3) {\n            sb.append('*');\n          } else {\n            sb.append((char) (97 + random().nextInt(3)));\n          }\n        }\n        String string = sb.toString();\n        MultiPhraseQuery mpq = new MultiPhraseQuery();\n        for(int j=0;j<string.length();j++) {\n          if (string.charAt(j) == '*') {\n            mpq.add(allTerms);\n          } else {\n            mpq.add(new Term(\"field\", \"\"+string.charAt(j)));\n          }\n        }\n        bq.add(mpq, BooleanClause.Occur.SHOULD);\n        strings.add(new BytesRef(string));\n      }\n\n      List<BytesRef> stringsList = new ArrayList<>(strings);\n      Collections.sort(stringsList);\n\n      Automaton a = Automata.makeStringUnion(stringsList);\n\n      // Translate automaton to query:\n    \n      TermAutomatonQuery q = new TermAutomatonQuery(\"field\");\n      int numStates = a.getNumStates();\n      for(int i=0;i<numStates;i++) {\n        q.createState();\n        q.setAccept(i, a.isAccept(i));\n      }\n\n      Transition t = new Transition();\n      for(int i=0;i<numStates;i++) {\n        int transCount = a.initTransition(i, t);\n        for(int j=0;j<transCount;j++) {\n          a.getNextTransition(t);\n          for(int label=t.min;label<=t.max;label++) {\n            if ((char) label == '*') {\n              q.addAnyTransition(t.source, t.dest);\n            } else {\n              q.addTransition(t.source, t.dest, \"\"+(char) label);\n            }\n          }\n        }\n      }\n      q.finish();\n\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n        for(BytesRef string : stringsList) {\n          System.out.println(\"  string: \" + string.utf8ToString());\n        }\n        System.out.println(q.toDot());\n      }\n      \n      Query q1 = q;\n      Query q2 = bq;\n      if (random().nextInt(5) == 1) {\n        RandomFilter filter = new RandomFilter(random().nextLong(), random().nextFloat());\n        q1 = new FilteredQuery(q1, filter);\n        q2 = new FilteredQuery(q2, filter);\n      }\n\n      TopDocs hits1 = s.search(q1, numDocs);\n      TopDocs hits2 = s.search(q2, numDocs);\n      Set<String> hits1Docs = toDocIDs(s, hits1);\n      Set<String> hits2Docs = toDocIDs(s, hits2);\n\n      try {\n        assertEquals(hits2.totalHits, hits1.totalHits);\n        assertEquals(hits2Docs, hits1Docs);\n      } catch (AssertionError ae) {\n        System.out.println(\"FAILED:\");\n        for(String id : hits1Docs) {\n          if (hits2Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s matched but should not have\", id));\n          }\n        }\n        for(String id : hits2Docs) {\n          if (hits1Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s did not match but should have\", id));\n          }\n        }\n        throw ae;\n      }\n    }\n\n    w.close();\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n    int numDocs = atLeast(100);\n    Directory dir = newDirectory();\n\n    // Adds occassional random synonyms:\n    Analyzer analyzer = new Analyzer() {\n        @Override\n        public TokenStreamComponents createComponents(String fieldName) {\n          MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true, 100);\n          tokenizer.setEnableChecks(true);\n          TokenFilter filt = new MockTokenFilter(tokenizer, MockTokenFilter.EMPTY_STOPSET);\n          filt = new RandomSynonymFilter(filt);\n          return new TokenStreamComponents(tokenizer, filt);\n        }\n      };\n\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    for(int i=0;i<numDocs;i++) {\n      Document doc = new Document();\n      int numTokens = atLeast(10);\n\n      StringBuilder sb = new StringBuilder();\n      for(int j=0;j<numTokens;j++) {\n        sb.append(' ');\n        sb.append((char) (97 + random().nextInt(3)));\n      }\n      String contents = sb.toString();\n      doc.add(newTextField(\"field\", contents, Field.Store.NO));\n      doc.add(new StoredField(\"id\", \"\"+i));\n      if (VERBOSE) {\n        System.out.println(\"  doc \" + i + \" -> \" + contents);\n      }\n      w.addDocument(doc);\n    }\n\n    IndexReader r = w.getReader();\n    IndexSearcher s = newSearcher(r);\n\n    // Used to match ANY using MultiPhraseQuery:\n    Term[] allTerms = new Term[] {new Term(\"field\", \"a\"),\n                                  new Term(\"field\", \"b\"),\n                                  new Term(\"field\", \"c\")};\n    int numIters = atLeast(1000);\n    for(int iter=0;iter<numIters;iter++) {\n\n      // Build the (finite, no any transitions) TermAutomatonQuery and\n      // also the \"equivalent\" BooleanQuery and make sure they match the\n      // same docs:\n      BooleanQuery bq = new BooleanQuery();\n      int count = TestUtil.nextInt(random(), 1, 5);\n      Set<BytesRef> strings = new HashSet<>();\n      for(int i=0;i<count;i++) {\n        StringBuilder sb = new StringBuilder();\n        int numTokens = TestUtil.nextInt(random(), 1, 5);\n        for(int j=0;j<numTokens;j++) {\n          if (j > 0 && j < numTokens-1 && random().nextInt(5) == 3) {\n            sb.append('*');\n          } else {\n            sb.append((char) (97 + random().nextInt(3)));\n          }\n        }\n        String string = sb.toString();\n        MultiPhraseQuery mpq = new MultiPhraseQuery();\n        for(int j=0;j<string.length();j++) {\n          if (string.charAt(j) == '*') {\n            mpq.add(allTerms);\n          } else {\n            mpq.add(new Term(\"field\", \"\"+string.charAt(j)));\n          }\n        }\n        bq.add(mpq, BooleanClause.Occur.SHOULD);\n        strings.add(new BytesRef(string));\n      }\n\n      List<BytesRef> stringsList = new ArrayList<>(strings);\n      Collections.sort(stringsList);\n\n      Automaton a = Automata.makeStringUnion(stringsList);\n\n      // Translate automaton to query:\n    \n      TermAutomatonQuery q = new TermAutomatonQuery(\"field\");\n      int numStates = a.getNumStates();\n      for(int i=0;i<numStates;i++) {\n        q.createState();\n        q.setAccept(i, a.isAccept(i));\n      }\n\n      Transition t = new Transition();\n      for(int i=0;i<numStates;i++) {\n        int transCount = a.initTransition(i, t);\n        for(int j=0;j<transCount;j++) {\n          a.getNextTransition(t);\n          for(int label=t.min;label<=t.max;label++) {\n            if ((char) label == '*') {\n              q.addAnyTransition(t.source, t.dest);\n            } else {\n              q.addTransition(t.source, t.dest, \"\"+(char) label);\n            }\n          }\n        }\n      }\n      q.finish();\n\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n        for(BytesRef string : stringsList) {\n          System.out.println(\"  string: \" + string.utf8ToString());\n        }\n        System.out.println(q.toDot());\n      }\n      \n      Filter filter;\n      if (random().nextInt(5) == 1) {\n        filter = new RandomFilter(random().nextLong(), random().nextFloat());\n      } else {\n        filter = null;\n      }\n\n      TopDocs hits1 = s.search(q, filter, numDocs);\n      TopDocs hits2 = s.search(bq, filter, numDocs);\n      Set<String> hits1Docs = toDocIDs(s, hits1);\n      Set<String> hits2Docs = toDocIDs(s, hits2);\n\n      try {\n        assertEquals(hits2.totalHits, hits1.totalHits);\n        assertEquals(hits2Docs, hits1Docs);\n      } catch (AssertionError ae) {\n        System.out.println(\"FAILED:\");\n        for(String id : hits1Docs) {\n          if (hits2Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s matched but should not have\", id));\n          }\n        }\n        for(String id : hits2Docs) {\n          if (hits1Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s did not match but should have\", id));\n          }\n        }\n        throw ae;\n      }\n    }\n\n    w.close();\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"50c99225e51de7d0aff8f06f1ab6a99d4bb0f2a4","date":1425256347,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/sandbox/src/test/org/apache/lucene/search/TestTermAutomatonQuery#testRandom().mjava","pathOld":"lucene/sandbox/src/test/org/apache/lucene/search/TestTermAutomatonQuery#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n    int numDocs = atLeast(100);\n    Directory dir = newDirectory();\n\n    // Adds occassional random synonyms:\n    Analyzer analyzer = new Analyzer() {\n        @Override\n        public TokenStreamComponents createComponents(String fieldName) {\n          MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true, 100);\n          tokenizer.setEnableChecks(true);\n          TokenFilter filt = new MockTokenFilter(tokenizer, MockTokenFilter.EMPTY_STOPSET);\n          filt = new RandomSynonymFilter(filt);\n          return new TokenStreamComponents(tokenizer, filt);\n        }\n      };\n\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    for(int i=0;i<numDocs;i++) {\n      Document doc = new Document();\n      int numTokens = atLeast(10);\n\n      StringBuilder sb = new StringBuilder();\n      for(int j=0;j<numTokens;j++) {\n        sb.append(' ');\n        sb.append((char) (97 + random().nextInt(3)));\n      }\n      String contents = sb.toString();\n      doc.add(newTextField(\"field\", contents, Field.Store.NO));\n      doc.add(new StoredField(\"id\", \"\"+i));\n      if (VERBOSE) {\n        System.out.println(\"  doc \" + i + \" -> \" + contents);\n      }\n      w.addDocument(doc);\n    }\n\n    IndexReader r = w.getReader();\n    IndexSearcher s = newSearcher(r);\n\n    // Used to match ANY using MultiPhraseQuery:\n    Term[] allTerms = new Term[] {new Term(\"field\", \"a\"),\n                                  new Term(\"field\", \"b\"),\n                                  new Term(\"field\", \"c\")};\n    int numIters = atLeast(1000);\n    for(int iter=0;iter<numIters;iter++) {\n\n      // Build the (finite, no any transitions) TermAutomatonQuery and\n      // also the \"equivalent\" BooleanQuery and make sure they match the\n      // same docs:\n      BooleanQuery bq = new BooleanQuery();\n      int count = TestUtil.nextInt(random(), 1, 5);\n      Set<BytesRef> strings = new HashSet<>();\n      for(int i=0;i<count;i++) {\n        StringBuilder sb = new StringBuilder();\n        int numTokens = TestUtil.nextInt(random(), 1, 5);\n        for(int j=0;j<numTokens;j++) {\n          if (j > 0 && j < numTokens-1 && random().nextInt(5) == 3) {\n            sb.append('*');\n          } else {\n            sb.append((char) (97 + random().nextInt(3)));\n          }\n        }\n        String string = sb.toString();\n        MultiPhraseQuery mpq = new MultiPhraseQuery();\n        for(int j=0;j<string.length();j++) {\n          if (string.charAt(j) == '*') {\n            mpq.add(allTerms);\n          } else {\n            mpq.add(new Term(\"field\", \"\"+string.charAt(j)));\n          }\n        }\n        bq.add(mpq, BooleanClause.Occur.SHOULD);\n        strings.add(new BytesRef(string));\n      }\n\n      List<BytesRef> stringsList = new ArrayList<>(strings);\n      Collections.sort(stringsList);\n\n      Automaton a = Automata.makeStringUnion(stringsList);\n\n      // Translate automaton to query:\n    \n      TermAutomatonQuery q = new TermAutomatonQuery(\"field\");\n      int numStates = a.getNumStates();\n      for(int i=0;i<numStates;i++) {\n        q.createState();\n        q.setAccept(i, a.isAccept(i));\n      }\n\n      Transition t = new Transition();\n      for(int i=0;i<numStates;i++) {\n        int transCount = a.initTransition(i, t);\n        for(int j=0;j<transCount;j++) {\n          a.getNextTransition(t);\n          for(int label=t.min;label<=t.max;label++) {\n            if ((char) label == '*') {\n              q.addAnyTransition(t.source, t.dest);\n            } else {\n              q.addTransition(t.source, t.dest, \"\"+(char) label);\n            }\n          }\n        }\n      }\n      q.finish();\n\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n        for(BytesRef string : stringsList) {\n          System.out.println(\"  string: \" + string.utf8ToString());\n        }\n        System.out.println(q.toDot());\n      }\n      \n      Query q1 = q;\n      Query q2 = bq;\n      if (random().nextInt(5) == 1) {\n        if (VERBOSE) {\n          System.out.println(\"  use random filter\");\n        }\n        RandomFilter filter = new RandomFilter(random().nextLong(), random().nextFloat());\n        q1 = new FilteredQuery(q1, filter);\n        q2 = new FilteredQuery(q2, filter);\n      }\n\n      TopDocs hits1 = s.search(q1, numDocs);\n      TopDocs hits2 = s.search(q2, numDocs);\n      Set<String> hits1Docs = toDocIDs(s, hits1);\n      Set<String> hits2Docs = toDocIDs(s, hits2);\n\n      try {\n        assertEquals(hits2.totalHits, hits1.totalHits);\n        assertEquals(hits2Docs, hits1Docs);\n      } catch (AssertionError ae) {\n        System.out.println(\"FAILED:\");\n        for(String id : hits1Docs) {\n          if (hits2Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s matched but should not have\", id));\n          }\n        }\n        for(String id : hits2Docs) {\n          if (hits1Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s did not match but should have\", id));\n          }\n        }\n        throw ae;\n      }\n    }\n\n    w.close();\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n    int numDocs = atLeast(100);\n    Directory dir = newDirectory();\n\n    // Adds occassional random synonyms:\n    Analyzer analyzer = new Analyzer() {\n        @Override\n        public TokenStreamComponents createComponents(String fieldName) {\n          MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true, 100);\n          tokenizer.setEnableChecks(true);\n          TokenFilter filt = new MockTokenFilter(tokenizer, MockTokenFilter.EMPTY_STOPSET);\n          filt = new RandomSynonymFilter(filt);\n          return new TokenStreamComponents(tokenizer, filt);\n        }\n      };\n\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    for(int i=0;i<numDocs;i++) {\n      Document doc = new Document();\n      int numTokens = atLeast(10);\n\n      StringBuilder sb = new StringBuilder();\n      for(int j=0;j<numTokens;j++) {\n        sb.append(' ');\n        sb.append((char) (97 + random().nextInt(3)));\n      }\n      String contents = sb.toString();\n      doc.add(newTextField(\"field\", contents, Field.Store.NO));\n      doc.add(new StoredField(\"id\", \"\"+i));\n      if (VERBOSE) {\n        System.out.println(\"  doc \" + i + \" -> \" + contents);\n      }\n      w.addDocument(doc);\n    }\n\n    IndexReader r = w.getReader();\n    IndexSearcher s = newSearcher(r);\n\n    // Used to match ANY using MultiPhraseQuery:\n    Term[] allTerms = new Term[] {new Term(\"field\", \"a\"),\n                                  new Term(\"field\", \"b\"),\n                                  new Term(\"field\", \"c\")};\n    int numIters = atLeast(1000);\n    for(int iter=0;iter<numIters;iter++) {\n\n      // Build the (finite, no any transitions) TermAutomatonQuery and\n      // also the \"equivalent\" BooleanQuery and make sure they match the\n      // same docs:\n      BooleanQuery bq = new BooleanQuery();\n      int count = TestUtil.nextInt(random(), 1, 5);\n      Set<BytesRef> strings = new HashSet<>();\n      for(int i=0;i<count;i++) {\n        StringBuilder sb = new StringBuilder();\n        int numTokens = TestUtil.nextInt(random(), 1, 5);\n        for(int j=0;j<numTokens;j++) {\n          if (j > 0 && j < numTokens-1 && random().nextInt(5) == 3) {\n            sb.append('*');\n          } else {\n            sb.append((char) (97 + random().nextInt(3)));\n          }\n        }\n        String string = sb.toString();\n        MultiPhraseQuery mpq = new MultiPhraseQuery();\n        for(int j=0;j<string.length();j++) {\n          if (string.charAt(j) == '*') {\n            mpq.add(allTerms);\n          } else {\n            mpq.add(new Term(\"field\", \"\"+string.charAt(j)));\n          }\n        }\n        bq.add(mpq, BooleanClause.Occur.SHOULD);\n        strings.add(new BytesRef(string));\n      }\n\n      List<BytesRef> stringsList = new ArrayList<>(strings);\n      Collections.sort(stringsList);\n\n      Automaton a = Automata.makeStringUnion(stringsList);\n\n      // Translate automaton to query:\n    \n      TermAutomatonQuery q = new TermAutomatonQuery(\"field\");\n      int numStates = a.getNumStates();\n      for(int i=0;i<numStates;i++) {\n        q.createState();\n        q.setAccept(i, a.isAccept(i));\n      }\n\n      Transition t = new Transition();\n      for(int i=0;i<numStates;i++) {\n        int transCount = a.initTransition(i, t);\n        for(int j=0;j<transCount;j++) {\n          a.getNextTransition(t);\n          for(int label=t.min;label<=t.max;label++) {\n            if ((char) label == '*') {\n              q.addAnyTransition(t.source, t.dest);\n            } else {\n              q.addTransition(t.source, t.dest, \"\"+(char) label);\n            }\n          }\n        }\n      }\n      q.finish();\n\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n        for(BytesRef string : stringsList) {\n          System.out.println(\"  string: \" + string.utf8ToString());\n        }\n        System.out.println(q.toDot());\n      }\n      \n      Query q1 = q;\n      Query q2 = bq;\n      if (random().nextInt(5) == 1) {\n        RandomFilter filter = new RandomFilter(random().nextLong(), random().nextFloat());\n        q1 = new FilteredQuery(q1, filter);\n        q2 = new FilteredQuery(q2, filter);\n      }\n\n      TopDocs hits1 = s.search(q1, numDocs);\n      TopDocs hits2 = s.search(q2, numDocs);\n      Set<String> hits1Docs = toDocIDs(s, hits1);\n      Set<String> hits2Docs = toDocIDs(s, hits2);\n\n      try {\n        assertEquals(hits2.totalHits, hits1.totalHits);\n        assertEquals(hits2Docs, hits1Docs);\n      } catch (AssertionError ae) {\n        System.out.println(\"FAILED:\");\n        for(String id : hits1Docs) {\n          if (hits2Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s matched but should not have\", id));\n          }\n        }\n        for(String id : hits2Docs) {\n          if (hits1Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s did not match but should have\", id));\n          }\n        }\n        throw ae;\n      }\n    }\n\n    w.close();\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"299a2348fa24151d150182211b6208a38e5e3450","date":1425304608,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/sandbox/src/test/org/apache/lucene/search/TestTermAutomatonQuery#testRandom().mjava","pathOld":"lucene/sandbox/src/test/org/apache/lucene/search/TestTermAutomatonQuery#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n    int numDocs = atLeast(100);\n    Directory dir = newDirectory();\n\n    // Adds occassional random synonyms:\n    Analyzer analyzer = new Analyzer() {\n        @Override\n        public TokenStreamComponents createComponents(String fieldName) {\n          MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true, 100);\n          tokenizer.setEnableChecks(true);\n          TokenFilter filt = new MockTokenFilter(tokenizer, MockTokenFilter.EMPTY_STOPSET);\n          filt = new RandomSynonymFilter(filt);\n          return new TokenStreamComponents(tokenizer, filt);\n        }\n      };\n\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    for(int i=0;i<numDocs;i++) {\n      Document doc = new Document();\n      int numTokens = atLeast(10);\n\n      StringBuilder sb = new StringBuilder();\n      for(int j=0;j<numTokens;j++) {\n        sb.append(' ');\n        sb.append((char) (97 + random().nextInt(3)));\n      }\n      String contents = sb.toString();\n      doc.add(newTextField(\"field\", contents, Field.Store.NO));\n      doc.add(new StoredField(\"id\", \"\"+i));\n      if (VERBOSE) {\n        System.out.println(\"  doc \" + i + \" -> \" + contents);\n      }\n      w.addDocument(doc);\n    }\n\n    IndexReader r = w.getReader();\n    IndexSearcher s = newSearcher(r);\n\n    // Used to match ANY using MultiPhraseQuery:\n    Term[] allTerms = new Term[] {new Term(\"field\", \"a\"),\n                                  new Term(\"field\", \"b\"),\n                                  new Term(\"field\", \"c\")};\n    int numIters = atLeast(1000);\n    for(int iter=0;iter<numIters;iter++) {\n\n      // Build the (finite, no any transitions) TermAutomatonQuery and\n      // also the \"equivalent\" BooleanQuery and make sure they match the\n      // same docs:\n      BooleanQuery bq = new BooleanQuery();\n      int count = TestUtil.nextInt(random(), 1, 5);\n      Set<BytesRef> strings = new HashSet<>();\n      for(int i=0;i<count;i++) {\n        StringBuilder sb = new StringBuilder();\n        int numTokens = TestUtil.nextInt(random(), 1, 5);\n        for(int j=0;j<numTokens;j++) {\n          if (j > 0 && j < numTokens-1 && random().nextInt(5) == 3) {\n            sb.append('*');\n          } else {\n            sb.append((char) (97 + random().nextInt(3)));\n          }\n        }\n        String string = sb.toString();\n        MultiPhraseQuery mpq = new MultiPhraseQuery();\n        for(int j=0;j<string.length();j++) {\n          if (string.charAt(j) == '*') {\n            mpq.add(allTerms);\n          } else {\n            mpq.add(new Term(\"field\", \"\"+string.charAt(j)));\n          }\n        }\n        bq.add(mpq, BooleanClause.Occur.SHOULD);\n        strings.add(new BytesRef(string));\n      }\n\n      List<BytesRef> stringsList = new ArrayList<>(strings);\n      Collections.sort(stringsList);\n\n      Automaton a = Automata.makeStringUnion(stringsList);\n\n      // Translate automaton to query:\n    \n      TermAutomatonQuery q = new TermAutomatonQuery(\"field\");\n      int numStates = a.getNumStates();\n      for(int i=0;i<numStates;i++) {\n        q.createState();\n        q.setAccept(i, a.isAccept(i));\n      }\n\n      Transition t = new Transition();\n      for(int i=0;i<numStates;i++) {\n        int transCount = a.initTransition(i, t);\n        for(int j=0;j<transCount;j++) {\n          a.getNextTransition(t);\n          for(int label=t.min;label<=t.max;label++) {\n            if ((char) label == '*') {\n              q.addAnyTransition(t.source, t.dest);\n            } else {\n              q.addTransition(t.source, t.dest, \"\"+(char) label);\n            }\n          }\n        }\n      }\n      q.finish();\n\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n        for(BytesRef string : stringsList) {\n          System.out.println(\"  string: \" + string.utf8ToString());\n        }\n        System.out.println(q.toDot());\n      }\n      \n      Query q1 = q;\n      Query q2 = bq;\n      if (random().nextInt(5) == 1) {\n        if (VERBOSE) {\n          System.out.println(\"  use random filter\");\n        }\n        RandomFilter filter = new RandomFilter(random().nextLong(), random().nextFloat());\n        q1 = new FilteredQuery(q1, filter);\n        q2 = new FilteredQuery(q2, filter);\n      }\n\n      TopDocs hits1 = s.search(q1, numDocs);\n      TopDocs hits2 = s.search(q2, numDocs);\n      Set<String> hits1Docs = toDocIDs(s, hits1);\n      Set<String> hits2Docs = toDocIDs(s, hits2);\n\n      try {\n        assertEquals(hits2.totalHits, hits1.totalHits);\n        assertEquals(hits2Docs, hits1Docs);\n      } catch (AssertionError ae) {\n        System.out.println(\"FAILED:\");\n        for(String id : hits1Docs) {\n          if (hits2Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s matched but should not have\", id));\n          }\n        }\n        for(String id : hits2Docs) {\n          if (hits1Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s did not match but should have\", id));\n          }\n        }\n        throw ae;\n      }\n    }\n\n    w.close();\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n    int numDocs = atLeast(100);\n    Directory dir = newDirectory();\n\n    // Adds occassional random synonyms:\n    Analyzer analyzer = new Analyzer() {\n        @Override\n        public TokenStreamComponents createComponents(String fieldName) {\n          MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true, 100);\n          tokenizer.setEnableChecks(true);\n          TokenFilter filt = new MockTokenFilter(tokenizer, MockTokenFilter.EMPTY_STOPSET);\n          filt = new RandomSynonymFilter(filt);\n          return new TokenStreamComponents(tokenizer, filt);\n        }\n      };\n\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    for(int i=0;i<numDocs;i++) {\n      Document doc = new Document();\n      int numTokens = atLeast(10);\n\n      StringBuilder sb = new StringBuilder();\n      for(int j=0;j<numTokens;j++) {\n        sb.append(' ');\n        sb.append((char) (97 + random().nextInt(3)));\n      }\n      String contents = sb.toString();\n      doc.add(newTextField(\"field\", contents, Field.Store.NO));\n      doc.add(new StoredField(\"id\", \"\"+i));\n      if (VERBOSE) {\n        System.out.println(\"  doc \" + i + \" -> \" + contents);\n      }\n      w.addDocument(doc);\n    }\n\n    IndexReader r = w.getReader();\n    IndexSearcher s = newSearcher(r);\n\n    // Used to match ANY using MultiPhraseQuery:\n    Term[] allTerms = new Term[] {new Term(\"field\", \"a\"),\n                                  new Term(\"field\", \"b\"),\n                                  new Term(\"field\", \"c\")};\n    int numIters = atLeast(1000);\n    for(int iter=0;iter<numIters;iter++) {\n\n      // Build the (finite, no any transitions) TermAutomatonQuery and\n      // also the \"equivalent\" BooleanQuery and make sure they match the\n      // same docs:\n      BooleanQuery bq = new BooleanQuery();\n      int count = TestUtil.nextInt(random(), 1, 5);\n      Set<BytesRef> strings = new HashSet<>();\n      for(int i=0;i<count;i++) {\n        StringBuilder sb = new StringBuilder();\n        int numTokens = TestUtil.nextInt(random(), 1, 5);\n        for(int j=0;j<numTokens;j++) {\n          if (j > 0 && j < numTokens-1 && random().nextInt(5) == 3) {\n            sb.append('*');\n          } else {\n            sb.append((char) (97 + random().nextInt(3)));\n          }\n        }\n        String string = sb.toString();\n        MultiPhraseQuery mpq = new MultiPhraseQuery();\n        for(int j=0;j<string.length();j++) {\n          if (string.charAt(j) == '*') {\n            mpq.add(allTerms);\n          } else {\n            mpq.add(new Term(\"field\", \"\"+string.charAt(j)));\n          }\n        }\n        bq.add(mpq, BooleanClause.Occur.SHOULD);\n        strings.add(new BytesRef(string));\n      }\n\n      List<BytesRef> stringsList = new ArrayList<>(strings);\n      Collections.sort(stringsList);\n\n      Automaton a = Automata.makeStringUnion(stringsList);\n\n      // Translate automaton to query:\n    \n      TermAutomatonQuery q = new TermAutomatonQuery(\"field\");\n      int numStates = a.getNumStates();\n      for(int i=0;i<numStates;i++) {\n        q.createState();\n        q.setAccept(i, a.isAccept(i));\n      }\n\n      Transition t = new Transition();\n      for(int i=0;i<numStates;i++) {\n        int transCount = a.initTransition(i, t);\n        for(int j=0;j<transCount;j++) {\n          a.getNextTransition(t);\n          for(int label=t.min;label<=t.max;label++) {\n            if ((char) label == '*') {\n              q.addAnyTransition(t.source, t.dest);\n            } else {\n              q.addTransition(t.source, t.dest, \"\"+(char) label);\n            }\n          }\n        }\n      }\n      q.finish();\n\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n        for(BytesRef string : stringsList) {\n          System.out.println(\"  string: \" + string.utf8ToString());\n        }\n        System.out.println(q.toDot());\n      }\n      \n      Query q1 = q;\n      Query q2 = bq;\n      if (random().nextInt(5) == 1) {\n        RandomFilter filter = new RandomFilter(random().nextLong(), random().nextFloat());\n        q1 = new FilteredQuery(q1, filter);\n        q2 = new FilteredQuery(q2, filter);\n      }\n\n      TopDocs hits1 = s.search(q1, numDocs);\n      TopDocs hits2 = s.search(q2, numDocs);\n      Set<String> hits1Docs = toDocIDs(s, hits1);\n      Set<String> hits2Docs = toDocIDs(s, hits2);\n\n      try {\n        assertEquals(hits2.totalHits, hits1.totalHits);\n        assertEquals(hits2Docs, hits1Docs);\n      } catch (AssertionError ae) {\n        System.out.println(\"FAILED:\");\n        for(String id : hits1Docs) {\n          if (hits2Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s matched but should not have\", id));\n          }\n        }\n        for(String id : hits2Docs) {\n          if (hits1Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s did not match but should have\", id));\n          }\n        }\n        throw ae;\n      }\n    }\n\n    w.close();\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a56958d7f71a28824f20031ffbb2e13502a0274e","date":1425573902,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/sandbox/src/test/org/apache/lucene/search/TestTermAutomatonQuery#testRandom().mjava","pathOld":"lucene/sandbox/src/test/org/apache/lucene/search/TestTermAutomatonQuery#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n    int numDocs = atLeast(100);\n    Directory dir = newDirectory();\n\n    // Adds occassional random synonyms:\n    Analyzer analyzer = new Analyzer() {\n        @Override\n        public TokenStreamComponents createComponents(String fieldName) {\n          MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true, 100);\n          tokenizer.setEnableChecks(true);\n          TokenFilter filt = new MockTokenFilter(tokenizer, MockTokenFilter.EMPTY_STOPSET);\n          filt = new RandomSynonymFilter(filt);\n          return new TokenStreamComponents(tokenizer, filt);\n        }\n      };\n\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    for(int i=0;i<numDocs;i++) {\n      Document doc = new Document();\n      int numTokens = atLeast(10);\n\n      StringBuilder sb = new StringBuilder();\n      for(int j=0;j<numTokens;j++) {\n        sb.append(' ');\n        sb.append((char) (97 + random().nextInt(3)));\n      }\n      String contents = sb.toString();\n      doc.add(newTextField(\"field\", contents, Field.Store.NO));\n      doc.add(new StoredField(\"id\", \"\"+i));\n      if (VERBOSE) {\n        System.out.println(\"  doc \" + i + \" -> \" + contents);\n      }\n      w.addDocument(doc);\n    }\n\n    IndexReader r = w.getReader();\n    IndexSearcher s = newSearcher(r);\n\n    // Used to match ANY using MultiPhraseQuery:\n    Term[] allTerms = new Term[] {new Term(\"field\", \"a\"),\n                                  new Term(\"field\", \"b\"),\n                                  new Term(\"field\", \"c\")};\n    int numIters = atLeast(1000);\n    for(int iter=0;iter<numIters;iter++) {\n\n      // Build the (finite, no any transitions) TermAutomatonQuery and\n      // also the \"equivalent\" BooleanQuery and make sure they match the\n      // same docs:\n      BooleanQuery bq = new BooleanQuery();\n      int count = TestUtil.nextInt(random(), 1, 5);\n      Set<BytesRef> strings = new HashSet<>();\n      for(int i=0;i<count;i++) {\n        StringBuilder sb = new StringBuilder();\n        int numTokens = TestUtil.nextInt(random(), 1, 5);\n        for(int j=0;j<numTokens;j++) {\n          if (j > 0 && j < numTokens-1 && random().nextInt(5) == 3) {\n            sb.append('*');\n          } else {\n            sb.append((char) (97 + random().nextInt(3)));\n          }\n        }\n        String string = sb.toString();\n        MultiPhraseQuery mpq = new MultiPhraseQuery();\n        for(int j=0;j<string.length();j++) {\n          if (string.charAt(j) == '*') {\n            mpq.add(allTerms);\n          } else {\n            mpq.add(new Term(\"field\", \"\"+string.charAt(j)));\n          }\n        }\n        bq.add(mpq, BooleanClause.Occur.SHOULD);\n        strings.add(new BytesRef(string));\n      }\n\n      List<BytesRef> stringsList = new ArrayList<>(strings);\n      Collections.sort(stringsList);\n\n      Automaton a = Automata.makeStringUnion(stringsList);\n\n      // Translate automaton to query:\n    \n      TermAutomatonQuery q = new TermAutomatonQuery(\"field\");\n      int numStates = a.getNumStates();\n      for(int i=0;i<numStates;i++) {\n        q.createState();\n        q.setAccept(i, a.isAccept(i));\n      }\n\n      Transition t = new Transition();\n      for(int i=0;i<numStates;i++) {\n        int transCount = a.initTransition(i, t);\n        for(int j=0;j<transCount;j++) {\n          a.getNextTransition(t);\n          for(int label=t.min;label<=t.max;label++) {\n            if ((char) label == '*') {\n              q.addAnyTransition(t.source, t.dest);\n            } else {\n              q.addTransition(t.source, t.dest, \"\"+(char) label);\n            }\n          }\n        }\n      }\n      q.finish();\n\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n        for(BytesRef string : stringsList) {\n          System.out.println(\"  string: \" + string.utf8ToString());\n        }\n        System.out.println(q.toDot());\n      }\n      \n      Query q1 = q;\n      Query q2 = bq;\n      if (random().nextInt(5) == 1) {\n        if (VERBOSE) {\n          System.out.println(\"  use random filter\");\n        }\n        RandomFilter filter = new RandomFilter(random().nextLong(), random().nextFloat());\n        q1 = new FilteredQuery(q1, filter);\n        q2 = new FilteredQuery(q2, filter);\n      }\n\n      TopDocs hits1 = s.search(q1, numDocs);\n      TopDocs hits2 = s.search(q2, numDocs);\n      Set<String> hits1Docs = toDocIDs(s, hits1);\n      Set<String> hits2Docs = toDocIDs(s, hits2);\n\n      try {\n        assertEquals(hits2.totalHits, hits1.totalHits);\n        assertEquals(hits2Docs, hits1Docs);\n      } catch (AssertionError ae) {\n        System.out.println(\"FAILED:\");\n        for(String id : hits1Docs) {\n          if (hits2Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s matched but should not have\", id));\n          }\n        }\n        for(String id : hits2Docs) {\n          if (hits1Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s did not match but should have\", id));\n          }\n        }\n        throw ae;\n      }\n    }\n\n    IOUtils.close(w, r, dir, analyzer);\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n    int numDocs = atLeast(100);\n    Directory dir = newDirectory();\n\n    // Adds occassional random synonyms:\n    Analyzer analyzer = new Analyzer() {\n        @Override\n        public TokenStreamComponents createComponents(String fieldName) {\n          MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true, 100);\n          tokenizer.setEnableChecks(true);\n          TokenFilter filt = new MockTokenFilter(tokenizer, MockTokenFilter.EMPTY_STOPSET);\n          filt = new RandomSynonymFilter(filt);\n          return new TokenStreamComponents(tokenizer, filt);\n        }\n      };\n\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    for(int i=0;i<numDocs;i++) {\n      Document doc = new Document();\n      int numTokens = atLeast(10);\n\n      StringBuilder sb = new StringBuilder();\n      for(int j=0;j<numTokens;j++) {\n        sb.append(' ');\n        sb.append((char) (97 + random().nextInt(3)));\n      }\n      String contents = sb.toString();\n      doc.add(newTextField(\"field\", contents, Field.Store.NO));\n      doc.add(new StoredField(\"id\", \"\"+i));\n      if (VERBOSE) {\n        System.out.println(\"  doc \" + i + \" -> \" + contents);\n      }\n      w.addDocument(doc);\n    }\n\n    IndexReader r = w.getReader();\n    IndexSearcher s = newSearcher(r);\n\n    // Used to match ANY using MultiPhraseQuery:\n    Term[] allTerms = new Term[] {new Term(\"field\", \"a\"),\n                                  new Term(\"field\", \"b\"),\n                                  new Term(\"field\", \"c\")};\n    int numIters = atLeast(1000);\n    for(int iter=0;iter<numIters;iter++) {\n\n      // Build the (finite, no any transitions) TermAutomatonQuery and\n      // also the \"equivalent\" BooleanQuery and make sure they match the\n      // same docs:\n      BooleanQuery bq = new BooleanQuery();\n      int count = TestUtil.nextInt(random(), 1, 5);\n      Set<BytesRef> strings = new HashSet<>();\n      for(int i=0;i<count;i++) {\n        StringBuilder sb = new StringBuilder();\n        int numTokens = TestUtil.nextInt(random(), 1, 5);\n        for(int j=0;j<numTokens;j++) {\n          if (j > 0 && j < numTokens-1 && random().nextInt(5) == 3) {\n            sb.append('*');\n          } else {\n            sb.append((char) (97 + random().nextInt(3)));\n          }\n        }\n        String string = sb.toString();\n        MultiPhraseQuery mpq = new MultiPhraseQuery();\n        for(int j=0;j<string.length();j++) {\n          if (string.charAt(j) == '*') {\n            mpq.add(allTerms);\n          } else {\n            mpq.add(new Term(\"field\", \"\"+string.charAt(j)));\n          }\n        }\n        bq.add(mpq, BooleanClause.Occur.SHOULD);\n        strings.add(new BytesRef(string));\n      }\n\n      List<BytesRef> stringsList = new ArrayList<>(strings);\n      Collections.sort(stringsList);\n\n      Automaton a = Automata.makeStringUnion(stringsList);\n\n      // Translate automaton to query:\n    \n      TermAutomatonQuery q = new TermAutomatonQuery(\"field\");\n      int numStates = a.getNumStates();\n      for(int i=0;i<numStates;i++) {\n        q.createState();\n        q.setAccept(i, a.isAccept(i));\n      }\n\n      Transition t = new Transition();\n      for(int i=0;i<numStates;i++) {\n        int transCount = a.initTransition(i, t);\n        for(int j=0;j<transCount;j++) {\n          a.getNextTransition(t);\n          for(int label=t.min;label<=t.max;label++) {\n            if ((char) label == '*') {\n              q.addAnyTransition(t.source, t.dest);\n            } else {\n              q.addTransition(t.source, t.dest, \"\"+(char) label);\n            }\n          }\n        }\n      }\n      q.finish();\n\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n        for(BytesRef string : stringsList) {\n          System.out.println(\"  string: \" + string.utf8ToString());\n        }\n        System.out.println(q.toDot());\n      }\n      \n      Query q1 = q;\n      Query q2 = bq;\n      if (random().nextInt(5) == 1) {\n        if (VERBOSE) {\n          System.out.println(\"  use random filter\");\n        }\n        RandomFilter filter = new RandomFilter(random().nextLong(), random().nextFloat());\n        q1 = new FilteredQuery(q1, filter);\n        q2 = new FilteredQuery(q2, filter);\n      }\n\n      TopDocs hits1 = s.search(q1, numDocs);\n      TopDocs hits2 = s.search(q2, numDocs);\n      Set<String> hits1Docs = toDocIDs(s, hits1);\n      Set<String> hits2Docs = toDocIDs(s, hits2);\n\n      try {\n        assertEquals(hits2.totalHits, hits1.totalHits);\n        assertEquals(hits2Docs, hits1Docs);\n      } catch (AssertionError ae) {\n        System.out.println(\"FAILED:\");\n        for(String id : hits1Docs) {\n          if (hits2Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s matched but should not have\", id));\n          }\n        }\n        for(String id : hits2Docs) {\n          if (hits1Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s did not match but should have\", id));\n          }\n        }\n        throw ae;\n      }\n    }\n\n    w.close();\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":3,"author":"Ryan Ernst","isMerge":true,"pathNew":"lucene/sandbox/src/test/org/apache/lucene/search/TestTermAutomatonQuery#testRandom().mjava","pathOld":"lucene/sandbox/src/test/org/apache/lucene/search/TestTermAutomatonQuery#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n    int numDocs = atLeast(100);\n    Directory dir = newDirectory();\n\n    // Adds occassional random synonyms:\n    Analyzer analyzer = new Analyzer() {\n        @Override\n        public TokenStreamComponents createComponents(String fieldName) {\n          MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true, 100);\n          tokenizer.setEnableChecks(true);\n          TokenFilter filt = new MockTokenFilter(tokenizer, MockTokenFilter.EMPTY_STOPSET);\n          filt = new RandomSynonymFilter(filt);\n          return new TokenStreamComponents(tokenizer, filt);\n        }\n      };\n\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    for(int i=0;i<numDocs;i++) {\n      Document doc = new Document();\n      int numTokens = atLeast(10);\n\n      StringBuilder sb = new StringBuilder();\n      for(int j=0;j<numTokens;j++) {\n        sb.append(' ');\n        sb.append((char) (97 + random().nextInt(3)));\n      }\n      String contents = sb.toString();\n      doc.add(newTextField(\"field\", contents, Field.Store.NO));\n      doc.add(new StoredField(\"id\", \"\"+i));\n      if (VERBOSE) {\n        System.out.println(\"  doc \" + i + \" -> \" + contents);\n      }\n      w.addDocument(doc);\n    }\n\n    IndexReader r = w.getReader();\n    IndexSearcher s = newSearcher(r);\n\n    // Used to match ANY using MultiPhraseQuery:\n    Term[] allTerms = new Term[] {new Term(\"field\", \"a\"),\n                                  new Term(\"field\", \"b\"),\n                                  new Term(\"field\", \"c\")};\n    int numIters = atLeast(1000);\n    for(int iter=0;iter<numIters;iter++) {\n\n      // Build the (finite, no any transitions) TermAutomatonQuery and\n      // also the \"equivalent\" BooleanQuery and make sure they match the\n      // same docs:\n      BooleanQuery bq = new BooleanQuery();\n      int count = TestUtil.nextInt(random(), 1, 5);\n      Set<BytesRef> strings = new HashSet<>();\n      for(int i=0;i<count;i++) {\n        StringBuilder sb = new StringBuilder();\n        int numTokens = TestUtil.nextInt(random(), 1, 5);\n        for(int j=0;j<numTokens;j++) {\n          if (j > 0 && j < numTokens-1 && random().nextInt(5) == 3) {\n            sb.append('*');\n          } else {\n            sb.append((char) (97 + random().nextInt(3)));\n          }\n        }\n        String string = sb.toString();\n        MultiPhraseQuery mpq = new MultiPhraseQuery();\n        for(int j=0;j<string.length();j++) {\n          if (string.charAt(j) == '*') {\n            mpq.add(allTerms);\n          } else {\n            mpq.add(new Term(\"field\", \"\"+string.charAt(j)));\n          }\n        }\n        bq.add(mpq, BooleanClause.Occur.SHOULD);\n        strings.add(new BytesRef(string));\n      }\n\n      List<BytesRef> stringsList = new ArrayList<>(strings);\n      Collections.sort(stringsList);\n\n      Automaton a = Automata.makeStringUnion(stringsList);\n\n      // Translate automaton to query:\n    \n      TermAutomatonQuery q = new TermAutomatonQuery(\"field\");\n      int numStates = a.getNumStates();\n      for(int i=0;i<numStates;i++) {\n        q.createState();\n        q.setAccept(i, a.isAccept(i));\n      }\n\n      Transition t = new Transition();\n      for(int i=0;i<numStates;i++) {\n        int transCount = a.initTransition(i, t);\n        for(int j=0;j<transCount;j++) {\n          a.getNextTransition(t);\n          for(int label=t.min;label<=t.max;label++) {\n            if ((char) label == '*') {\n              q.addAnyTransition(t.source, t.dest);\n            } else {\n              q.addTransition(t.source, t.dest, \"\"+(char) label);\n            }\n          }\n        }\n      }\n      q.finish();\n\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n        for(BytesRef string : stringsList) {\n          System.out.println(\"  string: \" + string.utf8ToString());\n        }\n        System.out.println(q.toDot());\n      }\n      \n      Query q1 = q;\n      Query q2 = bq;\n      if (random().nextInt(5) == 1) {\n        if (VERBOSE) {\n          System.out.println(\"  use random filter\");\n        }\n        RandomFilter filter = new RandomFilter(random().nextLong(), random().nextFloat());\n        q1 = new FilteredQuery(q1, filter);\n        q2 = new FilteredQuery(q2, filter);\n      }\n\n      TopDocs hits1 = s.search(q1, numDocs);\n      TopDocs hits2 = s.search(q2, numDocs);\n      Set<String> hits1Docs = toDocIDs(s, hits1);\n      Set<String> hits2Docs = toDocIDs(s, hits2);\n\n      try {\n        assertEquals(hits2.totalHits, hits1.totalHits);\n        assertEquals(hits2Docs, hits1Docs);\n      } catch (AssertionError ae) {\n        System.out.println(\"FAILED:\");\n        for(String id : hits1Docs) {\n          if (hits2Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s matched but should not have\", id));\n          }\n        }\n        for(String id : hits2Docs) {\n          if (hits1Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s did not match but should have\", id));\n          }\n        }\n        throw ae;\n      }\n    }\n\n    IOUtils.close(w, r, dir, analyzer);\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n    int numDocs = atLeast(100);\n    Directory dir = newDirectory();\n\n    // Adds occassional random synonyms:\n    Analyzer analyzer = new Analyzer() {\n        @Override\n        public TokenStreamComponents createComponents(String fieldName) {\n          MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true, 100);\n          tokenizer.setEnableChecks(true);\n          TokenFilter filt = new MockTokenFilter(tokenizer, MockTokenFilter.EMPTY_STOPSET);\n          filt = new RandomSynonymFilter(filt);\n          return new TokenStreamComponents(tokenizer, filt);\n        }\n      };\n\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    for(int i=0;i<numDocs;i++) {\n      Document doc = new Document();\n      int numTokens = atLeast(10);\n\n      StringBuilder sb = new StringBuilder();\n      for(int j=0;j<numTokens;j++) {\n        sb.append(' ');\n        sb.append((char) (97 + random().nextInt(3)));\n      }\n      String contents = sb.toString();\n      doc.add(newTextField(\"field\", contents, Field.Store.NO));\n      doc.add(new StoredField(\"id\", \"\"+i));\n      if (VERBOSE) {\n        System.out.println(\"  doc \" + i + \" -> \" + contents);\n      }\n      w.addDocument(doc);\n    }\n\n    IndexReader r = w.getReader();\n    IndexSearcher s = newSearcher(r);\n\n    // Used to match ANY using MultiPhraseQuery:\n    Term[] allTerms = new Term[] {new Term(\"field\", \"a\"),\n                                  new Term(\"field\", \"b\"),\n                                  new Term(\"field\", \"c\")};\n    int numIters = atLeast(1000);\n    for(int iter=0;iter<numIters;iter++) {\n\n      // Build the (finite, no any transitions) TermAutomatonQuery and\n      // also the \"equivalent\" BooleanQuery and make sure they match the\n      // same docs:\n      BooleanQuery bq = new BooleanQuery();\n      int count = TestUtil.nextInt(random(), 1, 5);\n      Set<BytesRef> strings = new HashSet<>();\n      for(int i=0;i<count;i++) {\n        StringBuilder sb = new StringBuilder();\n        int numTokens = TestUtil.nextInt(random(), 1, 5);\n        for(int j=0;j<numTokens;j++) {\n          if (j > 0 && j < numTokens-1 && random().nextInt(5) == 3) {\n            sb.append('*');\n          } else {\n            sb.append((char) (97 + random().nextInt(3)));\n          }\n        }\n        String string = sb.toString();\n        MultiPhraseQuery mpq = new MultiPhraseQuery();\n        for(int j=0;j<string.length();j++) {\n          if (string.charAt(j) == '*') {\n            mpq.add(allTerms);\n          } else {\n            mpq.add(new Term(\"field\", \"\"+string.charAt(j)));\n          }\n        }\n        bq.add(mpq, BooleanClause.Occur.SHOULD);\n        strings.add(new BytesRef(string));\n      }\n\n      List<BytesRef> stringsList = new ArrayList<>(strings);\n      Collections.sort(stringsList);\n\n      Automaton a = Automata.makeStringUnion(stringsList);\n\n      // Translate automaton to query:\n    \n      TermAutomatonQuery q = new TermAutomatonQuery(\"field\");\n      int numStates = a.getNumStates();\n      for(int i=0;i<numStates;i++) {\n        q.createState();\n        q.setAccept(i, a.isAccept(i));\n      }\n\n      Transition t = new Transition();\n      for(int i=0;i<numStates;i++) {\n        int transCount = a.initTransition(i, t);\n        for(int j=0;j<transCount;j++) {\n          a.getNextTransition(t);\n          for(int label=t.min;label<=t.max;label++) {\n            if ((char) label == '*') {\n              q.addAnyTransition(t.source, t.dest);\n            } else {\n              q.addTransition(t.source, t.dest, \"\"+(char) label);\n            }\n          }\n        }\n      }\n      q.finish();\n\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n        for(BytesRef string : stringsList) {\n          System.out.println(\"  string: \" + string.utf8ToString());\n        }\n        System.out.println(q.toDot());\n      }\n      \n      Query q1 = q;\n      Query q2 = bq;\n      if (random().nextInt(5) == 1) {\n        RandomFilter filter = new RandomFilter(random().nextLong(), random().nextFloat());\n        q1 = new FilteredQuery(q1, filter);\n        q2 = new FilteredQuery(q2, filter);\n      }\n\n      TopDocs hits1 = s.search(q1, numDocs);\n      TopDocs hits2 = s.search(q2, numDocs);\n      Set<String> hits1Docs = toDocIDs(s, hits1);\n      Set<String> hits2Docs = toDocIDs(s, hits2);\n\n      try {\n        assertEquals(hits2.totalHits, hits1.totalHits);\n        assertEquals(hits2Docs, hits1Docs);\n      } catch (AssertionError ae) {\n        System.out.println(\"FAILED:\");\n        for(String id : hits1Docs) {\n          if (hits2Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s matched but should not have\", id));\n          }\n        }\n        for(String id : hits2Docs) {\n          if (hits1Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s did not match but should have\", id));\n          }\n        }\n        throw ae;\n      }\n    }\n\n    w.close();\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3f68d01cf19df971dcdcb05e30247f4ad7ec9747","date":1434611645,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/sandbox/src/test/org/apache/lucene/search/TestTermAutomatonQuery#testRandom().mjava","pathOld":"lucene/sandbox/src/test/org/apache/lucene/search/TestTermAutomatonQuery#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n    int numDocs = atLeast(100);\n    Directory dir = newDirectory();\n\n    // Adds occassional random synonyms:\n    Analyzer analyzer = new Analyzer() {\n        @Override\n        public TokenStreamComponents createComponents(String fieldName) {\n          MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true, 100);\n          tokenizer.setEnableChecks(true);\n          TokenFilter filt = new MockTokenFilter(tokenizer, MockTokenFilter.EMPTY_STOPSET);\n          filt = new RandomSynonymFilter(filt);\n          return new TokenStreamComponents(tokenizer, filt);\n        }\n      };\n\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    for(int i=0;i<numDocs;i++) {\n      Document doc = new Document();\n      int numTokens = atLeast(10);\n\n      StringBuilder sb = new StringBuilder();\n      for(int j=0;j<numTokens;j++) {\n        sb.append(' ');\n        sb.append((char) (97 + random().nextInt(3)));\n      }\n      String contents = sb.toString();\n      doc.add(newTextField(\"field\", contents, Field.Store.NO));\n      doc.add(new StoredField(\"id\", \"\"+i));\n      if (VERBOSE) {\n        System.out.println(\"  doc \" + i + \" -> \" + contents);\n      }\n      w.addDocument(doc);\n    }\n\n    IndexReader r = w.getReader();\n    IndexSearcher s = newSearcher(r);\n\n    // Used to match ANY using MultiPhraseQuery:\n    Term[] allTerms = new Term[] {new Term(\"field\", \"a\"),\n                                  new Term(\"field\", \"b\"),\n                                  new Term(\"field\", \"c\")};\n    int numIters = atLeast(1000);\n    for(int iter=0;iter<numIters;iter++) {\n\n      // Build the (finite, no any transitions) TermAutomatonQuery and\n      // also the \"equivalent\" BooleanQuery and make sure they match the\n      // same docs:\n      BooleanQuery.Builder bq = new BooleanQuery.Builder();\n      int count = TestUtil.nextInt(random(), 1, 5);\n      Set<BytesRef> strings = new HashSet<>();\n      for(int i=0;i<count;i++) {\n        StringBuilder sb = new StringBuilder();\n        int numTokens = TestUtil.nextInt(random(), 1, 5);\n        for(int j=0;j<numTokens;j++) {\n          if (j > 0 && j < numTokens-1 && random().nextInt(5) == 3) {\n            sb.append('*');\n          } else {\n            sb.append((char) (97 + random().nextInt(3)));\n          }\n        }\n        String string = sb.toString();\n        MultiPhraseQuery mpq = new MultiPhraseQuery();\n        for(int j=0;j<string.length();j++) {\n          if (string.charAt(j) == '*') {\n            mpq.add(allTerms);\n          } else {\n            mpq.add(new Term(\"field\", \"\"+string.charAt(j)));\n          }\n        }\n        bq.add(mpq, BooleanClause.Occur.SHOULD);\n        strings.add(new BytesRef(string));\n      }\n\n      List<BytesRef> stringsList = new ArrayList<>(strings);\n      Collections.sort(stringsList);\n\n      Automaton a = Automata.makeStringUnion(stringsList);\n\n      // Translate automaton to query:\n    \n      TermAutomatonQuery q = new TermAutomatonQuery(\"field\");\n      int numStates = a.getNumStates();\n      for(int i=0;i<numStates;i++) {\n        q.createState();\n        q.setAccept(i, a.isAccept(i));\n      }\n\n      Transition t = new Transition();\n      for(int i=0;i<numStates;i++) {\n        int transCount = a.initTransition(i, t);\n        for(int j=0;j<transCount;j++) {\n          a.getNextTransition(t);\n          for(int label=t.min;label<=t.max;label++) {\n            if ((char) label == '*') {\n              q.addAnyTransition(t.source, t.dest);\n            } else {\n              q.addTransition(t.source, t.dest, \"\"+(char) label);\n            }\n          }\n        }\n      }\n      q.finish();\n\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n        for(BytesRef string : stringsList) {\n          System.out.println(\"  string: \" + string.utf8ToString());\n        }\n        System.out.println(q.toDot());\n      }\n      \n      Query q1 = q;\n      Query q2 = bq.build();\n      if (random().nextInt(5) == 1) {\n        if (VERBOSE) {\n          System.out.println(\"  use random filter\");\n        }\n        RandomFilter filter = new RandomFilter(random().nextLong(), random().nextFloat());\n        q1 = new FilteredQuery(q1, filter);\n        q2 = new FilteredQuery(q2, filter);\n      }\n\n      TopDocs hits1 = s.search(q1, numDocs);\n      TopDocs hits2 = s.search(q2, numDocs);\n      Set<String> hits1Docs = toDocIDs(s, hits1);\n      Set<String> hits2Docs = toDocIDs(s, hits2);\n\n      try {\n        assertEquals(hits2.totalHits, hits1.totalHits);\n        assertEquals(hits2Docs, hits1Docs);\n      } catch (AssertionError ae) {\n        System.out.println(\"FAILED:\");\n        for(String id : hits1Docs) {\n          if (hits2Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s matched but should not have\", id));\n          }\n        }\n        for(String id : hits2Docs) {\n          if (hits1Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s did not match but should have\", id));\n          }\n        }\n        throw ae;\n      }\n    }\n\n    IOUtils.close(w, r, dir, analyzer);\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n    int numDocs = atLeast(100);\n    Directory dir = newDirectory();\n\n    // Adds occassional random synonyms:\n    Analyzer analyzer = new Analyzer() {\n        @Override\n        public TokenStreamComponents createComponents(String fieldName) {\n          MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true, 100);\n          tokenizer.setEnableChecks(true);\n          TokenFilter filt = new MockTokenFilter(tokenizer, MockTokenFilter.EMPTY_STOPSET);\n          filt = new RandomSynonymFilter(filt);\n          return new TokenStreamComponents(tokenizer, filt);\n        }\n      };\n\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    for(int i=0;i<numDocs;i++) {\n      Document doc = new Document();\n      int numTokens = atLeast(10);\n\n      StringBuilder sb = new StringBuilder();\n      for(int j=0;j<numTokens;j++) {\n        sb.append(' ');\n        sb.append((char) (97 + random().nextInt(3)));\n      }\n      String contents = sb.toString();\n      doc.add(newTextField(\"field\", contents, Field.Store.NO));\n      doc.add(new StoredField(\"id\", \"\"+i));\n      if (VERBOSE) {\n        System.out.println(\"  doc \" + i + \" -> \" + contents);\n      }\n      w.addDocument(doc);\n    }\n\n    IndexReader r = w.getReader();\n    IndexSearcher s = newSearcher(r);\n\n    // Used to match ANY using MultiPhraseQuery:\n    Term[] allTerms = new Term[] {new Term(\"field\", \"a\"),\n                                  new Term(\"field\", \"b\"),\n                                  new Term(\"field\", \"c\")};\n    int numIters = atLeast(1000);\n    for(int iter=0;iter<numIters;iter++) {\n\n      // Build the (finite, no any transitions) TermAutomatonQuery and\n      // also the \"equivalent\" BooleanQuery and make sure they match the\n      // same docs:\n      BooleanQuery bq = new BooleanQuery();\n      int count = TestUtil.nextInt(random(), 1, 5);\n      Set<BytesRef> strings = new HashSet<>();\n      for(int i=0;i<count;i++) {\n        StringBuilder sb = new StringBuilder();\n        int numTokens = TestUtil.nextInt(random(), 1, 5);\n        for(int j=0;j<numTokens;j++) {\n          if (j > 0 && j < numTokens-1 && random().nextInt(5) == 3) {\n            sb.append('*');\n          } else {\n            sb.append((char) (97 + random().nextInt(3)));\n          }\n        }\n        String string = sb.toString();\n        MultiPhraseQuery mpq = new MultiPhraseQuery();\n        for(int j=0;j<string.length();j++) {\n          if (string.charAt(j) == '*') {\n            mpq.add(allTerms);\n          } else {\n            mpq.add(new Term(\"field\", \"\"+string.charAt(j)));\n          }\n        }\n        bq.add(mpq, BooleanClause.Occur.SHOULD);\n        strings.add(new BytesRef(string));\n      }\n\n      List<BytesRef> stringsList = new ArrayList<>(strings);\n      Collections.sort(stringsList);\n\n      Automaton a = Automata.makeStringUnion(stringsList);\n\n      // Translate automaton to query:\n    \n      TermAutomatonQuery q = new TermAutomatonQuery(\"field\");\n      int numStates = a.getNumStates();\n      for(int i=0;i<numStates;i++) {\n        q.createState();\n        q.setAccept(i, a.isAccept(i));\n      }\n\n      Transition t = new Transition();\n      for(int i=0;i<numStates;i++) {\n        int transCount = a.initTransition(i, t);\n        for(int j=0;j<transCount;j++) {\n          a.getNextTransition(t);\n          for(int label=t.min;label<=t.max;label++) {\n            if ((char) label == '*') {\n              q.addAnyTransition(t.source, t.dest);\n            } else {\n              q.addTransition(t.source, t.dest, \"\"+(char) label);\n            }\n          }\n        }\n      }\n      q.finish();\n\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n        for(BytesRef string : stringsList) {\n          System.out.println(\"  string: \" + string.utf8ToString());\n        }\n        System.out.println(q.toDot());\n      }\n      \n      Query q1 = q;\n      Query q2 = bq;\n      if (random().nextInt(5) == 1) {\n        if (VERBOSE) {\n          System.out.println(\"  use random filter\");\n        }\n        RandomFilter filter = new RandomFilter(random().nextLong(), random().nextFloat());\n        q1 = new FilteredQuery(q1, filter);\n        q2 = new FilteredQuery(q2, filter);\n      }\n\n      TopDocs hits1 = s.search(q1, numDocs);\n      TopDocs hits2 = s.search(q2, numDocs);\n      Set<String> hits1Docs = toDocIDs(s, hits1);\n      Set<String> hits2Docs = toDocIDs(s, hits2);\n\n      try {\n        assertEquals(hits2.totalHits, hits1.totalHits);\n        assertEquals(hits2Docs, hits1Docs);\n      } catch (AssertionError ae) {\n        System.out.println(\"FAILED:\");\n        for(String id : hits1Docs) {\n          if (hits2Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s matched but should not have\", id));\n          }\n        }\n        for(String id : hits2Docs) {\n          if (hits1Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s did not match but should have\", id));\n          }\n        }\n        throw ae;\n      }\n    }\n\n    IOUtils.close(w, r, dir, analyzer);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1db68e96dd908fcd79ef809095822736aa601d08","date":1434630596,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/sandbox/src/test/org/apache/lucene/search/TestTermAutomatonQuery#testRandom().mjava","pathOld":"lucene/sandbox/src/test/org/apache/lucene/search/TestTermAutomatonQuery#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n    int numDocs = atLeast(100);\n    Directory dir = newDirectory();\n\n    // Adds occassional random synonyms:\n    Analyzer analyzer = new Analyzer() {\n        @Override\n        public TokenStreamComponents createComponents(String fieldName) {\n          MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true, 100);\n          tokenizer.setEnableChecks(true);\n          TokenFilter filt = new MockTokenFilter(tokenizer, MockTokenFilter.EMPTY_STOPSET);\n          filt = new RandomSynonymFilter(filt);\n          return new TokenStreamComponents(tokenizer, filt);\n        }\n      };\n\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    for(int i=0;i<numDocs;i++) {\n      Document doc = new Document();\n      int numTokens = atLeast(10);\n\n      StringBuilder sb = new StringBuilder();\n      for(int j=0;j<numTokens;j++) {\n        sb.append(' ');\n        sb.append((char) (97 + random().nextInt(3)));\n      }\n      String contents = sb.toString();\n      doc.add(newTextField(\"field\", contents, Field.Store.NO));\n      doc.add(new StoredField(\"id\", \"\"+i));\n      if (VERBOSE) {\n        System.out.println(\"  doc \" + i + \" -> \" + contents);\n      }\n      w.addDocument(doc);\n    }\n\n    IndexReader r = w.getReader();\n    IndexSearcher s = newSearcher(r);\n\n    // Used to match ANY using MultiPhraseQuery:\n    Term[] allTerms = new Term[] {new Term(\"field\", \"a\"),\n                                  new Term(\"field\", \"b\"),\n                                  new Term(\"field\", \"c\")};\n    int numIters = atLeast(1000);\n    for(int iter=0;iter<numIters;iter++) {\n\n      // Build the (finite, no any transitions) TermAutomatonQuery and\n      // also the \"equivalent\" BooleanQuery and make sure they match the\n      // same docs:\n      BooleanQuery.Builder bq = new BooleanQuery.Builder();\n      int count = TestUtil.nextInt(random(), 1, 5);\n      Set<BytesRef> strings = new HashSet<>();\n      for(int i=0;i<count;i++) {\n        StringBuilder sb = new StringBuilder();\n        int numTokens = TestUtil.nextInt(random(), 1, 5);\n        for(int j=0;j<numTokens;j++) {\n          if (j > 0 && j < numTokens-1 && random().nextInt(5) == 3) {\n            sb.append('*');\n          } else {\n            sb.append((char) (97 + random().nextInt(3)));\n          }\n        }\n        String string = sb.toString();\n        MultiPhraseQuery mpq = new MultiPhraseQuery();\n        for(int j=0;j<string.length();j++) {\n          if (string.charAt(j) == '*') {\n            mpq.add(allTerms);\n          } else {\n            mpq.add(new Term(\"field\", \"\"+string.charAt(j)));\n          }\n        }\n        bq.add(mpq, BooleanClause.Occur.SHOULD);\n        strings.add(new BytesRef(string));\n      }\n\n      List<BytesRef> stringsList = new ArrayList<>(strings);\n      Collections.sort(stringsList);\n\n      Automaton a = Automata.makeStringUnion(stringsList);\n\n      // Translate automaton to query:\n    \n      TermAutomatonQuery q = new TermAutomatonQuery(\"field\");\n      int numStates = a.getNumStates();\n      for(int i=0;i<numStates;i++) {\n        q.createState();\n        q.setAccept(i, a.isAccept(i));\n      }\n\n      Transition t = new Transition();\n      for(int i=0;i<numStates;i++) {\n        int transCount = a.initTransition(i, t);\n        for(int j=0;j<transCount;j++) {\n          a.getNextTransition(t);\n          for(int label=t.min;label<=t.max;label++) {\n            if ((char) label == '*') {\n              q.addAnyTransition(t.source, t.dest);\n            } else {\n              q.addTransition(t.source, t.dest, \"\"+(char) label);\n            }\n          }\n        }\n      }\n      q.finish();\n\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n        for(BytesRef string : stringsList) {\n          System.out.println(\"  string: \" + string.utf8ToString());\n        }\n        System.out.println(q.toDot());\n      }\n      \n      Query q1 = q;\n      Query q2 = bq.build();\n      if (random().nextInt(5) == 1) {\n        if (VERBOSE) {\n          System.out.println(\"  use random filter\");\n        }\n        RandomFilter filter = new RandomFilter(random().nextLong(), random().nextFloat());\n        q1 = new BooleanQuery.Builder()\n            .add(q1, Occur.MUST)\n            .add(filter, Occur.FILTER)\n            .build();\n        q2 = new BooleanQuery.Builder()\n            .add(q2, Occur.MUST)\n            .add(filter, Occur.FILTER)\n            .build();\n      }\n\n      TopDocs hits1 = s.search(q1, numDocs);\n      TopDocs hits2 = s.search(q2, numDocs);\n      Set<String> hits1Docs = toDocIDs(s, hits1);\n      Set<String> hits2Docs = toDocIDs(s, hits2);\n\n      try {\n        assertEquals(hits2.totalHits, hits1.totalHits);\n        assertEquals(hits2Docs, hits1Docs);\n      } catch (AssertionError ae) {\n        System.out.println(\"FAILED:\");\n        for(String id : hits1Docs) {\n          if (hits2Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s matched but should not have\", id));\n          }\n        }\n        for(String id : hits2Docs) {\n          if (hits1Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s did not match but should have\", id));\n          }\n        }\n        throw ae;\n      }\n    }\n\n    IOUtils.close(w, r, dir, analyzer);\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n    int numDocs = atLeast(100);\n    Directory dir = newDirectory();\n\n    // Adds occassional random synonyms:\n    Analyzer analyzer = new Analyzer() {\n        @Override\n        public TokenStreamComponents createComponents(String fieldName) {\n          MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true, 100);\n          tokenizer.setEnableChecks(true);\n          TokenFilter filt = new MockTokenFilter(tokenizer, MockTokenFilter.EMPTY_STOPSET);\n          filt = new RandomSynonymFilter(filt);\n          return new TokenStreamComponents(tokenizer, filt);\n        }\n      };\n\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    for(int i=0;i<numDocs;i++) {\n      Document doc = new Document();\n      int numTokens = atLeast(10);\n\n      StringBuilder sb = new StringBuilder();\n      for(int j=0;j<numTokens;j++) {\n        sb.append(' ');\n        sb.append((char) (97 + random().nextInt(3)));\n      }\n      String contents = sb.toString();\n      doc.add(newTextField(\"field\", contents, Field.Store.NO));\n      doc.add(new StoredField(\"id\", \"\"+i));\n      if (VERBOSE) {\n        System.out.println(\"  doc \" + i + \" -> \" + contents);\n      }\n      w.addDocument(doc);\n    }\n\n    IndexReader r = w.getReader();\n    IndexSearcher s = newSearcher(r);\n\n    // Used to match ANY using MultiPhraseQuery:\n    Term[] allTerms = new Term[] {new Term(\"field\", \"a\"),\n                                  new Term(\"field\", \"b\"),\n                                  new Term(\"field\", \"c\")};\n    int numIters = atLeast(1000);\n    for(int iter=0;iter<numIters;iter++) {\n\n      // Build the (finite, no any transitions) TermAutomatonQuery and\n      // also the \"equivalent\" BooleanQuery and make sure they match the\n      // same docs:\n      BooleanQuery.Builder bq = new BooleanQuery.Builder();\n      int count = TestUtil.nextInt(random(), 1, 5);\n      Set<BytesRef> strings = new HashSet<>();\n      for(int i=0;i<count;i++) {\n        StringBuilder sb = new StringBuilder();\n        int numTokens = TestUtil.nextInt(random(), 1, 5);\n        for(int j=0;j<numTokens;j++) {\n          if (j > 0 && j < numTokens-1 && random().nextInt(5) == 3) {\n            sb.append('*');\n          } else {\n            sb.append((char) (97 + random().nextInt(3)));\n          }\n        }\n        String string = sb.toString();\n        MultiPhraseQuery mpq = new MultiPhraseQuery();\n        for(int j=0;j<string.length();j++) {\n          if (string.charAt(j) == '*') {\n            mpq.add(allTerms);\n          } else {\n            mpq.add(new Term(\"field\", \"\"+string.charAt(j)));\n          }\n        }\n        bq.add(mpq, BooleanClause.Occur.SHOULD);\n        strings.add(new BytesRef(string));\n      }\n\n      List<BytesRef> stringsList = new ArrayList<>(strings);\n      Collections.sort(stringsList);\n\n      Automaton a = Automata.makeStringUnion(stringsList);\n\n      // Translate automaton to query:\n    \n      TermAutomatonQuery q = new TermAutomatonQuery(\"field\");\n      int numStates = a.getNumStates();\n      for(int i=0;i<numStates;i++) {\n        q.createState();\n        q.setAccept(i, a.isAccept(i));\n      }\n\n      Transition t = new Transition();\n      for(int i=0;i<numStates;i++) {\n        int transCount = a.initTransition(i, t);\n        for(int j=0;j<transCount;j++) {\n          a.getNextTransition(t);\n          for(int label=t.min;label<=t.max;label++) {\n            if ((char) label == '*') {\n              q.addAnyTransition(t.source, t.dest);\n            } else {\n              q.addTransition(t.source, t.dest, \"\"+(char) label);\n            }\n          }\n        }\n      }\n      q.finish();\n\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n        for(BytesRef string : stringsList) {\n          System.out.println(\"  string: \" + string.utf8ToString());\n        }\n        System.out.println(q.toDot());\n      }\n      \n      Query q1 = q;\n      Query q2 = bq.build();\n      if (random().nextInt(5) == 1) {\n        if (VERBOSE) {\n          System.out.println(\"  use random filter\");\n        }\n        RandomFilter filter = new RandomFilter(random().nextLong(), random().nextFloat());\n        q1 = new FilteredQuery(q1, filter);\n        q2 = new FilteredQuery(q2, filter);\n      }\n\n      TopDocs hits1 = s.search(q1, numDocs);\n      TopDocs hits2 = s.search(q2, numDocs);\n      Set<String> hits1Docs = toDocIDs(s, hits1);\n      Set<String> hits2Docs = toDocIDs(s, hits2);\n\n      try {\n        assertEquals(hits2.totalHits, hits1.totalHits);\n        assertEquals(hits2Docs, hits1Docs);\n      } catch (AssertionError ae) {\n        System.out.println(\"FAILED:\");\n        for(String id : hits1Docs) {\n          if (hits2Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s matched but should not have\", id));\n          }\n        }\n        for(String id : hits2Docs) {\n          if (hits1Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s did not match but should have\", id));\n          }\n        }\n        throw ae;\n      }\n    }\n\n    IOUtils.close(w, r, dir, analyzer);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d52e48927ca4ef3655a261f2230b968b6fdf3608","date":1444652107,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/sandbox/src/test/org/apache/lucene/search/TestTermAutomatonQuery#testRandom().mjava","pathOld":"lucene/sandbox/src/test/org/apache/lucene/search/TestTermAutomatonQuery#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n    int numDocs = atLeast(100);\n    Directory dir = newDirectory();\n\n    // Adds occassional random synonyms:\n    Analyzer analyzer = new Analyzer() {\n        @Override\n        public TokenStreamComponents createComponents(String fieldName) {\n          MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true, 100);\n          tokenizer.setEnableChecks(true);\n          TokenFilter filt = new MockTokenFilter(tokenizer, MockTokenFilter.EMPTY_STOPSET);\n          filt = new RandomSynonymFilter(filt);\n          return new TokenStreamComponents(tokenizer, filt);\n        }\n      };\n\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    for(int i=0;i<numDocs;i++) {\n      Document doc = new Document();\n      int numTokens = atLeast(10);\n\n      StringBuilder sb = new StringBuilder();\n      for(int j=0;j<numTokens;j++) {\n        sb.append(' ');\n        sb.append((char) (97 + random().nextInt(3)));\n      }\n      String contents = sb.toString();\n      doc.add(newTextField(\"field\", contents, Field.Store.NO));\n      doc.add(new StoredField(\"id\", \"\"+i));\n      if (VERBOSE) {\n        System.out.println(\"  doc \" + i + \" -> \" + contents);\n      }\n      w.addDocument(doc);\n    }\n\n    IndexReader r = w.getReader();\n    IndexSearcher s = newSearcher(r);\n\n    // Used to match ANY using MultiPhraseQuery:\n    Term[] allTerms = new Term[] {new Term(\"field\", \"a\"),\n                                  new Term(\"field\", \"b\"),\n                                  new Term(\"field\", \"c\")};\n    int numIters = atLeast(1000);\n    for(int iter=0;iter<numIters;iter++) {\n\n      // Build the (finite, no any transitions) TermAutomatonQuery and\n      // also the \"equivalent\" BooleanQuery and make sure they match the\n      // same docs:\n      BooleanQuery.Builder bq = new BooleanQuery.Builder();\n      int count = TestUtil.nextInt(random(), 1, 5);\n      Set<BytesRef> strings = new HashSet<>();\n      for(int i=0;i<count;i++) {\n        StringBuilder sb = new StringBuilder();\n        int numTokens = TestUtil.nextInt(random(), 1, 5);\n        for(int j=0;j<numTokens;j++) {\n          if (j > 0 && j < numTokens-1 && random().nextInt(5) == 3) {\n            sb.append('*');\n          } else {\n            sb.append((char) (97 + random().nextInt(3)));\n          }\n        }\n        String string = sb.toString();\n        MultiPhraseQuery mpq = new MultiPhraseQuery();\n        for(int j=0;j<string.length();j++) {\n          if (string.charAt(j) == '*') {\n            mpq.add(allTerms);\n          } else {\n            mpq.add(new Term(\"field\", \"\"+string.charAt(j)));\n          }\n        }\n        bq.add(mpq, BooleanClause.Occur.SHOULD);\n        strings.add(new BytesRef(string));\n      }\n\n      List<BytesRef> stringsList = new ArrayList<>(strings);\n      Collections.sort(stringsList);\n\n      Automaton a = Automata.makeStringUnion(stringsList);\n\n      // Translate automaton to query:\n    \n      TermAutomatonQuery q = new TermAutomatonQuery(\"field\");\n      int numStates = a.getNumStates();\n      for(int i=0;i<numStates;i++) {\n        q.createState();\n        q.setAccept(i, a.isAccept(i));\n      }\n\n      Transition t = new Transition();\n      for(int i=0;i<numStates;i++) {\n        int transCount = a.initTransition(i, t);\n        for(int j=0;j<transCount;j++) {\n          a.getNextTransition(t);\n          for(int label=t.min;label<=t.max;label++) {\n            if ((char) label == '*') {\n              q.addAnyTransition(t.source, t.dest);\n            } else {\n              q.addTransition(t.source, t.dest, \"\"+(char) label);\n            }\n          }\n        }\n      }\n      q.finish();\n\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n        for(BytesRef string : stringsList) {\n          System.out.println(\"  string: \" + string.utf8ToString());\n        }\n        System.out.println(q.toDot());\n      }\n      \n      Query q1 = q;\n      Query q2 = bq.build();\n      if (random().nextInt(5) == 1) {\n        if (VERBOSE) {\n          System.out.println(\"  use random filter\");\n        }\n        RandomQuery filter = new RandomQuery(random().nextLong(), random().nextFloat());\n        q1 = new BooleanQuery.Builder()\n            .add(q1, Occur.MUST)\n            .add(filter, Occur.FILTER)\n            .build();\n        q2 = new BooleanQuery.Builder()\n            .add(q2, Occur.MUST)\n            .add(filter, Occur.FILTER)\n            .build();\n      }\n\n      TopDocs hits1 = s.search(q1, numDocs);\n      TopDocs hits2 = s.search(q2, numDocs);\n      Set<String> hits1Docs = toDocIDs(s, hits1);\n      Set<String> hits2Docs = toDocIDs(s, hits2);\n\n      try {\n        assertEquals(hits2.totalHits, hits1.totalHits);\n        assertEquals(hits2Docs, hits1Docs);\n      } catch (AssertionError ae) {\n        System.out.println(\"FAILED:\");\n        for(String id : hits1Docs) {\n          if (hits2Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s matched but should not have\", id));\n          }\n        }\n        for(String id : hits2Docs) {\n          if (hits1Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s did not match but should have\", id));\n          }\n        }\n        throw ae;\n      }\n    }\n\n    IOUtils.close(w, r, dir, analyzer);\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n    int numDocs = atLeast(100);\n    Directory dir = newDirectory();\n\n    // Adds occassional random synonyms:\n    Analyzer analyzer = new Analyzer() {\n        @Override\n        public TokenStreamComponents createComponents(String fieldName) {\n          MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true, 100);\n          tokenizer.setEnableChecks(true);\n          TokenFilter filt = new MockTokenFilter(tokenizer, MockTokenFilter.EMPTY_STOPSET);\n          filt = new RandomSynonymFilter(filt);\n          return new TokenStreamComponents(tokenizer, filt);\n        }\n      };\n\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    for(int i=0;i<numDocs;i++) {\n      Document doc = new Document();\n      int numTokens = atLeast(10);\n\n      StringBuilder sb = new StringBuilder();\n      for(int j=0;j<numTokens;j++) {\n        sb.append(' ');\n        sb.append((char) (97 + random().nextInt(3)));\n      }\n      String contents = sb.toString();\n      doc.add(newTextField(\"field\", contents, Field.Store.NO));\n      doc.add(new StoredField(\"id\", \"\"+i));\n      if (VERBOSE) {\n        System.out.println(\"  doc \" + i + \" -> \" + contents);\n      }\n      w.addDocument(doc);\n    }\n\n    IndexReader r = w.getReader();\n    IndexSearcher s = newSearcher(r);\n\n    // Used to match ANY using MultiPhraseQuery:\n    Term[] allTerms = new Term[] {new Term(\"field\", \"a\"),\n                                  new Term(\"field\", \"b\"),\n                                  new Term(\"field\", \"c\")};\n    int numIters = atLeast(1000);\n    for(int iter=0;iter<numIters;iter++) {\n\n      // Build the (finite, no any transitions) TermAutomatonQuery and\n      // also the \"equivalent\" BooleanQuery and make sure they match the\n      // same docs:\n      BooleanQuery.Builder bq = new BooleanQuery.Builder();\n      int count = TestUtil.nextInt(random(), 1, 5);\n      Set<BytesRef> strings = new HashSet<>();\n      for(int i=0;i<count;i++) {\n        StringBuilder sb = new StringBuilder();\n        int numTokens = TestUtil.nextInt(random(), 1, 5);\n        for(int j=0;j<numTokens;j++) {\n          if (j > 0 && j < numTokens-1 && random().nextInt(5) == 3) {\n            sb.append('*');\n          } else {\n            sb.append((char) (97 + random().nextInt(3)));\n          }\n        }\n        String string = sb.toString();\n        MultiPhraseQuery mpq = new MultiPhraseQuery();\n        for(int j=0;j<string.length();j++) {\n          if (string.charAt(j) == '*') {\n            mpq.add(allTerms);\n          } else {\n            mpq.add(new Term(\"field\", \"\"+string.charAt(j)));\n          }\n        }\n        bq.add(mpq, BooleanClause.Occur.SHOULD);\n        strings.add(new BytesRef(string));\n      }\n\n      List<BytesRef> stringsList = new ArrayList<>(strings);\n      Collections.sort(stringsList);\n\n      Automaton a = Automata.makeStringUnion(stringsList);\n\n      // Translate automaton to query:\n    \n      TermAutomatonQuery q = new TermAutomatonQuery(\"field\");\n      int numStates = a.getNumStates();\n      for(int i=0;i<numStates;i++) {\n        q.createState();\n        q.setAccept(i, a.isAccept(i));\n      }\n\n      Transition t = new Transition();\n      for(int i=0;i<numStates;i++) {\n        int transCount = a.initTransition(i, t);\n        for(int j=0;j<transCount;j++) {\n          a.getNextTransition(t);\n          for(int label=t.min;label<=t.max;label++) {\n            if ((char) label == '*') {\n              q.addAnyTransition(t.source, t.dest);\n            } else {\n              q.addTransition(t.source, t.dest, \"\"+(char) label);\n            }\n          }\n        }\n      }\n      q.finish();\n\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n        for(BytesRef string : stringsList) {\n          System.out.println(\"  string: \" + string.utf8ToString());\n        }\n        System.out.println(q.toDot());\n      }\n      \n      Query q1 = q;\n      Query q2 = bq.build();\n      if (random().nextInt(5) == 1) {\n        if (VERBOSE) {\n          System.out.println(\"  use random filter\");\n        }\n        RandomFilter filter = new RandomFilter(random().nextLong(), random().nextFloat());\n        q1 = new BooleanQuery.Builder()\n            .add(q1, Occur.MUST)\n            .add(filter, Occur.FILTER)\n            .build();\n        q2 = new BooleanQuery.Builder()\n            .add(q2, Occur.MUST)\n            .add(filter, Occur.FILTER)\n            .build();\n      }\n\n      TopDocs hits1 = s.search(q1, numDocs);\n      TopDocs hits2 = s.search(q2, numDocs);\n      Set<String> hits1Docs = toDocIDs(s, hits1);\n      Set<String> hits2Docs = toDocIDs(s, hits2);\n\n      try {\n        assertEquals(hits2.totalHits, hits1.totalHits);\n        assertEquals(hits2Docs, hits1Docs);\n      } catch (AssertionError ae) {\n        System.out.println(\"FAILED:\");\n        for(String id : hits1Docs) {\n          if (hits2Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s matched but should not have\", id));\n          }\n        }\n        for(String id : hits2Docs) {\n          if (hits1Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s did not match but should have\", id));\n          }\n        }\n        throw ae;\n      }\n    }\n\n    IOUtils.close(w, r, dir, analyzer);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"92b4a131f1796dd57cc6698aae3d589d32a29deb","date":1457087316,"type":3,"author":"Luc Vanlerberghe","isMerge":false,"pathNew":"lucene/sandbox/src/test/org/apache/lucene/search/TestTermAutomatonQuery#testRandom().mjava","pathOld":"lucene/sandbox/src/test/org/apache/lucene/search/TestTermAutomatonQuery#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n    int numDocs = atLeast(100);\n    Directory dir = newDirectory();\n\n    // Adds occassional random synonyms:\n    Analyzer analyzer = new Analyzer() {\n        @Override\n        public TokenStreamComponents createComponents(String fieldName) {\n          MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true, 100);\n          tokenizer.setEnableChecks(true);\n          TokenFilter filt = new MockTokenFilter(tokenizer, MockTokenFilter.EMPTY_STOPSET);\n          filt = new RandomSynonymFilter(filt);\n          return new TokenStreamComponents(tokenizer, filt);\n        }\n      };\n\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    for(int i=0;i<numDocs;i++) {\n      Document doc = new Document();\n      int numTokens = atLeast(10);\n\n      StringBuilder sb = new StringBuilder();\n      for(int j=0;j<numTokens;j++) {\n        sb.append(' ');\n        sb.append((char) (97 + random().nextInt(3)));\n      }\n      String contents = sb.toString();\n      doc.add(newTextField(\"field\", contents, Field.Store.NO));\n      doc.add(new StoredField(\"id\", \"\"+i));\n      if (VERBOSE) {\n        System.out.println(\"  doc \" + i + \" -> \" + contents);\n      }\n      w.addDocument(doc);\n    }\n\n    IndexReader r = w.getReader();\n    IndexSearcher s = newSearcher(r);\n\n    // Used to match ANY using MultiPhraseQuery:\n    Term[] allTerms = new Term[] {new Term(\"field\", \"a\"),\n                                  new Term(\"field\", \"b\"),\n                                  new Term(\"field\", \"c\")};\n    int numIters = atLeast(1000);\n    for(int iter=0;iter<numIters;iter++) {\n\n      // Build the (finite, no any transitions) TermAutomatonQuery and\n      // also the \"equivalent\" BooleanQuery and make sure they match the\n      // same docs:\n      BooleanQuery.Builder bq = new BooleanQuery.Builder();\n      int count = TestUtil.nextInt(random(), 1, 5);\n      Set<BytesRef> strings = new HashSet<>();\n      for(int i=0;i<count;i++) {\n        StringBuilder sb = new StringBuilder();\n        int numTokens = TestUtil.nextInt(random(), 1, 5);\n        for(int j=0;j<numTokens;j++) {\n          if (j > 0 && j < numTokens-1 && random().nextInt(5) == 3) {\n            sb.append('*');\n          } else {\n            sb.append((char) (97 + random().nextInt(3)));\n          }\n        }\n        String string = sb.toString();\n        MultiPhraseQuery.Builder mpqb = new MultiPhraseQuery.Builder();\n        for(int j=0;j<string.length();j++) {\n          if (string.charAt(j) == '*') {\n            mpqb.add(allTerms);\n          } else {\n            mpqb.add(new Term(\"field\", \"\"+string.charAt(j)));\n          }\n        }\n        bq.add(mpqb.build(), BooleanClause.Occur.SHOULD);\n        strings.add(new BytesRef(string));\n      }\n\n      List<BytesRef> stringsList = new ArrayList<>(strings);\n      Collections.sort(stringsList);\n\n      Automaton a = Automata.makeStringUnion(stringsList);\n\n      // Translate automaton to query:\n    \n      TermAutomatonQuery q = new TermAutomatonQuery(\"field\");\n      int numStates = a.getNumStates();\n      for(int i=0;i<numStates;i++) {\n        q.createState();\n        q.setAccept(i, a.isAccept(i));\n      }\n\n      Transition t = new Transition();\n      for(int i=0;i<numStates;i++) {\n        int transCount = a.initTransition(i, t);\n        for(int j=0;j<transCount;j++) {\n          a.getNextTransition(t);\n          for(int label=t.min;label<=t.max;label++) {\n            if ((char) label == '*') {\n              q.addAnyTransition(t.source, t.dest);\n            } else {\n              q.addTransition(t.source, t.dest, \"\"+(char) label);\n            }\n          }\n        }\n      }\n      q.finish();\n\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n        for(BytesRef string : stringsList) {\n          System.out.println(\"  string: \" + string.utf8ToString());\n        }\n        System.out.println(q.toDot());\n      }\n      \n      Query q1 = q;\n      Query q2 = bq.build();\n      if (random().nextInt(5) == 1) {\n        if (VERBOSE) {\n          System.out.println(\"  use random filter\");\n        }\n        RandomQuery filter = new RandomQuery(random().nextLong(), random().nextFloat());\n        q1 = new BooleanQuery.Builder()\n            .add(q1, Occur.MUST)\n            .add(filter, Occur.FILTER)\n            .build();\n        q2 = new BooleanQuery.Builder()\n            .add(q2, Occur.MUST)\n            .add(filter, Occur.FILTER)\n            .build();\n      }\n\n      TopDocs hits1 = s.search(q1, numDocs);\n      TopDocs hits2 = s.search(q2, numDocs);\n      Set<String> hits1Docs = toDocIDs(s, hits1);\n      Set<String> hits2Docs = toDocIDs(s, hits2);\n\n      try {\n        assertEquals(hits2.totalHits, hits1.totalHits);\n        assertEquals(hits2Docs, hits1Docs);\n      } catch (AssertionError ae) {\n        System.out.println(\"FAILED:\");\n        for(String id : hits1Docs) {\n          if (hits2Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s matched but should not have\", id));\n          }\n        }\n        for(String id : hits2Docs) {\n          if (hits1Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s did not match but should have\", id));\n          }\n        }\n        throw ae;\n      }\n    }\n\n    IOUtils.close(w, r, dir, analyzer);\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n    int numDocs = atLeast(100);\n    Directory dir = newDirectory();\n\n    // Adds occassional random synonyms:\n    Analyzer analyzer = new Analyzer() {\n        @Override\n        public TokenStreamComponents createComponents(String fieldName) {\n          MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true, 100);\n          tokenizer.setEnableChecks(true);\n          TokenFilter filt = new MockTokenFilter(tokenizer, MockTokenFilter.EMPTY_STOPSET);\n          filt = new RandomSynonymFilter(filt);\n          return new TokenStreamComponents(tokenizer, filt);\n        }\n      };\n\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    for(int i=0;i<numDocs;i++) {\n      Document doc = new Document();\n      int numTokens = atLeast(10);\n\n      StringBuilder sb = new StringBuilder();\n      for(int j=0;j<numTokens;j++) {\n        sb.append(' ');\n        sb.append((char) (97 + random().nextInt(3)));\n      }\n      String contents = sb.toString();\n      doc.add(newTextField(\"field\", contents, Field.Store.NO));\n      doc.add(new StoredField(\"id\", \"\"+i));\n      if (VERBOSE) {\n        System.out.println(\"  doc \" + i + \" -> \" + contents);\n      }\n      w.addDocument(doc);\n    }\n\n    IndexReader r = w.getReader();\n    IndexSearcher s = newSearcher(r);\n\n    // Used to match ANY using MultiPhraseQuery:\n    Term[] allTerms = new Term[] {new Term(\"field\", \"a\"),\n                                  new Term(\"field\", \"b\"),\n                                  new Term(\"field\", \"c\")};\n    int numIters = atLeast(1000);\n    for(int iter=0;iter<numIters;iter++) {\n\n      // Build the (finite, no any transitions) TermAutomatonQuery and\n      // also the \"equivalent\" BooleanQuery and make sure they match the\n      // same docs:\n      BooleanQuery.Builder bq = new BooleanQuery.Builder();\n      int count = TestUtil.nextInt(random(), 1, 5);\n      Set<BytesRef> strings = new HashSet<>();\n      for(int i=0;i<count;i++) {\n        StringBuilder sb = new StringBuilder();\n        int numTokens = TestUtil.nextInt(random(), 1, 5);\n        for(int j=0;j<numTokens;j++) {\n          if (j > 0 && j < numTokens-1 && random().nextInt(5) == 3) {\n            sb.append('*');\n          } else {\n            sb.append((char) (97 + random().nextInt(3)));\n          }\n        }\n        String string = sb.toString();\n        MultiPhraseQuery mpq = new MultiPhraseQuery();\n        for(int j=0;j<string.length();j++) {\n          if (string.charAt(j) == '*') {\n            mpq.add(allTerms);\n          } else {\n            mpq.add(new Term(\"field\", \"\"+string.charAt(j)));\n          }\n        }\n        bq.add(mpq, BooleanClause.Occur.SHOULD);\n        strings.add(new BytesRef(string));\n      }\n\n      List<BytesRef> stringsList = new ArrayList<>(strings);\n      Collections.sort(stringsList);\n\n      Automaton a = Automata.makeStringUnion(stringsList);\n\n      // Translate automaton to query:\n    \n      TermAutomatonQuery q = new TermAutomatonQuery(\"field\");\n      int numStates = a.getNumStates();\n      for(int i=0;i<numStates;i++) {\n        q.createState();\n        q.setAccept(i, a.isAccept(i));\n      }\n\n      Transition t = new Transition();\n      for(int i=0;i<numStates;i++) {\n        int transCount = a.initTransition(i, t);\n        for(int j=0;j<transCount;j++) {\n          a.getNextTransition(t);\n          for(int label=t.min;label<=t.max;label++) {\n            if ((char) label == '*') {\n              q.addAnyTransition(t.source, t.dest);\n            } else {\n              q.addTransition(t.source, t.dest, \"\"+(char) label);\n            }\n          }\n        }\n      }\n      q.finish();\n\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n        for(BytesRef string : stringsList) {\n          System.out.println(\"  string: \" + string.utf8ToString());\n        }\n        System.out.println(q.toDot());\n      }\n      \n      Query q1 = q;\n      Query q2 = bq.build();\n      if (random().nextInt(5) == 1) {\n        if (VERBOSE) {\n          System.out.println(\"  use random filter\");\n        }\n        RandomQuery filter = new RandomQuery(random().nextLong(), random().nextFloat());\n        q1 = new BooleanQuery.Builder()\n            .add(q1, Occur.MUST)\n            .add(filter, Occur.FILTER)\n            .build();\n        q2 = new BooleanQuery.Builder()\n            .add(q2, Occur.MUST)\n            .add(filter, Occur.FILTER)\n            .build();\n      }\n\n      TopDocs hits1 = s.search(q1, numDocs);\n      TopDocs hits2 = s.search(q2, numDocs);\n      Set<String> hits1Docs = toDocIDs(s, hits1);\n      Set<String> hits2Docs = toDocIDs(s, hits2);\n\n      try {\n        assertEquals(hits2.totalHits, hits1.totalHits);\n        assertEquals(hits2Docs, hits1Docs);\n      } catch (AssertionError ae) {\n        System.out.println(\"FAILED:\");\n        for(String id : hits1Docs) {\n          if (hits2Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s matched but should not have\", id));\n          }\n        }\n        for(String id : hits2Docs) {\n          if (hits1Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s did not match but should have\", id));\n          }\n        }\n        throw ae;\n      }\n    }\n\n    IOUtils.close(w, r, dir, analyzer);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cf1a614098b46c9c22afebd7b898ae4d1d2fc273","date":1457088850,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"lucene/sandbox/src/test/org/apache/lucene/search/TestTermAutomatonQuery#testRandom().mjava","pathOld":"lucene/sandbox/src/test/org/apache/lucene/search/TestTermAutomatonQuery#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n    int numDocs = atLeast(100);\n    Directory dir = newDirectory();\n\n    // Adds occassional random synonyms:\n    Analyzer analyzer = new Analyzer() {\n        @Override\n        public TokenStreamComponents createComponents(String fieldName) {\n          MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true, 100);\n          tokenizer.setEnableChecks(true);\n          TokenFilter filt = new MockTokenFilter(tokenizer, MockTokenFilter.EMPTY_STOPSET);\n          filt = new RandomSynonymFilter(filt);\n          return new TokenStreamComponents(tokenizer, filt);\n        }\n      };\n\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    for(int i=0;i<numDocs;i++) {\n      Document doc = new Document();\n      int numTokens = atLeast(10);\n\n      StringBuilder sb = new StringBuilder();\n      for(int j=0;j<numTokens;j++) {\n        sb.append(' ');\n        sb.append((char) (97 + random().nextInt(3)));\n      }\n      String contents = sb.toString();\n      doc.add(newTextField(\"field\", contents, Field.Store.NO));\n      doc.add(new StoredField(\"id\", \"\"+i));\n      if (VERBOSE) {\n        System.out.println(\"  doc \" + i + \" -> \" + contents);\n      }\n      w.addDocument(doc);\n    }\n\n    IndexReader r = w.getReader();\n    IndexSearcher s = newSearcher(r);\n\n    // Used to match ANY using MultiPhraseQuery:\n    Term[] allTerms = new Term[] {new Term(\"field\", \"a\"),\n                                  new Term(\"field\", \"b\"),\n                                  new Term(\"field\", \"c\")};\n    int numIters = atLeast(1000);\n    for(int iter=0;iter<numIters;iter++) {\n\n      // Build the (finite, no any transitions) TermAutomatonQuery and\n      // also the \"equivalent\" BooleanQuery and make sure they match the\n      // same docs:\n      BooleanQuery.Builder bq = new BooleanQuery.Builder();\n      int count = TestUtil.nextInt(random(), 1, 5);\n      Set<BytesRef> strings = new HashSet<>();\n      for(int i=0;i<count;i++) {\n        StringBuilder sb = new StringBuilder();\n        int numTokens = TestUtil.nextInt(random(), 1, 5);\n        for(int j=0;j<numTokens;j++) {\n          if (j > 0 && j < numTokens-1 && random().nextInt(5) == 3) {\n            sb.append('*');\n          } else {\n            sb.append((char) (97 + random().nextInt(3)));\n          }\n        }\n        String string = sb.toString();\n        MultiPhraseQuery.Builder mpqb = new MultiPhraseQuery.Builder();\n        for(int j=0;j<string.length();j++) {\n          if (string.charAt(j) == '*') {\n            mpqb.add(allTerms);\n          } else {\n            mpqb.add(new Term(\"field\", \"\"+string.charAt(j)));\n          }\n        }\n        bq.add(mpqb.build(), BooleanClause.Occur.SHOULD);\n        strings.add(new BytesRef(string));\n      }\n\n      List<BytesRef> stringsList = new ArrayList<>(strings);\n      Collections.sort(stringsList);\n\n      Automaton a = Automata.makeStringUnion(stringsList);\n\n      // Translate automaton to query:\n    \n      TermAutomatonQuery q = new TermAutomatonQuery(\"field\");\n      int numStates = a.getNumStates();\n      for(int i=0;i<numStates;i++) {\n        q.createState();\n        q.setAccept(i, a.isAccept(i));\n      }\n\n      Transition t = new Transition();\n      for(int i=0;i<numStates;i++) {\n        int transCount = a.initTransition(i, t);\n        for(int j=0;j<transCount;j++) {\n          a.getNextTransition(t);\n          for(int label=t.min;label<=t.max;label++) {\n            if ((char) label == '*') {\n              q.addAnyTransition(t.source, t.dest);\n            } else {\n              q.addTransition(t.source, t.dest, \"\"+(char) label);\n            }\n          }\n        }\n      }\n      q.finish();\n\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n        for(BytesRef string : stringsList) {\n          System.out.println(\"  string: \" + string.utf8ToString());\n        }\n        System.out.println(q.toDot());\n      }\n      \n      Query q1 = q;\n      Query q2 = bq.build();\n      if (random().nextInt(5) == 1) {\n        if (VERBOSE) {\n          System.out.println(\"  use random filter\");\n        }\n        RandomQuery filter = new RandomQuery(random().nextLong(), random().nextFloat());\n        q1 = new BooleanQuery.Builder()\n            .add(q1, Occur.MUST)\n            .add(filter, Occur.FILTER)\n            .build();\n        q2 = new BooleanQuery.Builder()\n            .add(q2, Occur.MUST)\n            .add(filter, Occur.FILTER)\n            .build();\n      }\n\n      TopDocs hits1 = s.search(q1, numDocs);\n      TopDocs hits2 = s.search(q2, numDocs);\n      Set<String> hits1Docs = toDocIDs(s, hits1);\n      Set<String> hits2Docs = toDocIDs(s, hits2);\n\n      try {\n        assertEquals(hits2.totalHits, hits1.totalHits);\n        assertEquals(hits2Docs, hits1Docs);\n      } catch (AssertionError ae) {\n        System.out.println(\"FAILED:\");\n        for(String id : hits1Docs) {\n          if (hits2Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s matched but should not have\", id));\n          }\n        }\n        for(String id : hits2Docs) {\n          if (hits1Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s did not match but should have\", id));\n          }\n        }\n        throw ae;\n      }\n    }\n\n    IOUtils.close(w, r, dir, analyzer);\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n    int numDocs = atLeast(100);\n    Directory dir = newDirectory();\n\n    // Adds occassional random synonyms:\n    Analyzer analyzer = new Analyzer() {\n        @Override\n        public TokenStreamComponents createComponents(String fieldName) {\n          MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true, 100);\n          tokenizer.setEnableChecks(true);\n          TokenFilter filt = new MockTokenFilter(tokenizer, MockTokenFilter.EMPTY_STOPSET);\n          filt = new RandomSynonymFilter(filt);\n          return new TokenStreamComponents(tokenizer, filt);\n        }\n      };\n\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    for(int i=0;i<numDocs;i++) {\n      Document doc = new Document();\n      int numTokens = atLeast(10);\n\n      StringBuilder sb = new StringBuilder();\n      for(int j=0;j<numTokens;j++) {\n        sb.append(' ');\n        sb.append((char) (97 + random().nextInt(3)));\n      }\n      String contents = sb.toString();\n      doc.add(newTextField(\"field\", contents, Field.Store.NO));\n      doc.add(new StoredField(\"id\", \"\"+i));\n      if (VERBOSE) {\n        System.out.println(\"  doc \" + i + \" -> \" + contents);\n      }\n      w.addDocument(doc);\n    }\n\n    IndexReader r = w.getReader();\n    IndexSearcher s = newSearcher(r);\n\n    // Used to match ANY using MultiPhraseQuery:\n    Term[] allTerms = new Term[] {new Term(\"field\", \"a\"),\n                                  new Term(\"field\", \"b\"),\n                                  new Term(\"field\", \"c\")};\n    int numIters = atLeast(1000);\n    for(int iter=0;iter<numIters;iter++) {\n\n      // Build the (finite, no any transitions) TermAutomatonQuery and\n      // also the \"equivalent\" BooleanQuery and make sure they match the\n      // same docs:\n      BooleanQuery.Builder bq = new BooleanQuery.Builder();\n      int count = TestUtil.nextInt(random(), 1, 5);\n      Set<BytesRef> strings = new HashSet<>();\n      for(int i=0;i<count;i++) {\n        StringBuilder sb = new StringBuilder();\n        int numTokens = TestUtil.nextInt(random(), 1, 5);\n        for(int j=0;j<numTokens;j++) {\n          if (j > 0 && j < numTokens-1 && random().nextInt(5) == 3) {\n            sb.append('*');\n          } else {\n            sb.append((char) (97 + random().nextInt(3)));\n          }\n        }\n        String string = sb.toString();\n        MultiPhraseQuery mpq = new MultiPhraseQuery();\n        for(int j=0;j<string.length();j++) {\n          if (string.charAt(j) == '*') {\n            mpq.add(allTerms);\n          } else {\n            mpq.add(new Term(\"field\", \"\"+string.charAt(j)));\n          }\n        }\n        bq.add(mpq, BooleanClause.Occur.SHOULD);\n        strings.add(new BytesRef(string));\n      }\n\n      List<BytesRef> stringsList = new ArrayList<>(strings);\n      Collections.sort(stringsList);\n\n      Automaton a = Automata.makeStringUnion(stringsList);\n\n      // Translate automaton to query:\n    \n      TermAutomatonQuery q = new TermAutomatonQuery(\"field\");\n      int numStates = a.getNumStates();\n      for(int i=0;i<numStates;i++) {\n        q.createState();\n        q.setAccept(i, a.isAccept(i));\n      }\n\n      Transition t = new Transition();\n      for(int i=0;i<numStates;i++) {\n        int transCount = a.initTransition(i, t);\n        for(int j=0;j<transCount;j++) {\n          a.getNextTransition(t);\n          for(int label=t.min;label<=t.max;label++) {\n            if ((char) label == '*') {\n              q.addAnyTransition(t.source, t.dest);\n            } else {\n              q.addTransition(t.source, t.dest, \"\"+(char) label);\n            }\n          }\n        }\n      }\n      q.finish();\n\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n        for(BytesRef string : stringsList) {\n          System.out.println(\"  string: \" + string.utf8ToString());\n        }\n        System.out.println(q.toDot());\n      }\n      \n      Query q1 = q;\n      Query q2 = bq.build();\n      if (random().nextInt(5) == 1) {\n        if (VERBOSE) {\n          System.out.println(\"  use random filter\");\n        }\n        RandomQuery filter = new RandomQuery(random().nextLong(), random().nextFloat());\n        q1 = new BooleanQuery.Builder()\n            .add(q1, Occur.MUST)\n            .add(filter, Occur.FILTER)\n            .build();\n        q2 = new BooleanQuery.Builder()\n            .add(q2, Occur.MUST)\n            .add(filter, Occur.FILTER)\n            .build();\n      }\n\n      TopDocs hits1 = s.search(q1, numDocs);\n      TopDocs hits2 = s.search(q2, numDocs);\n      Set<String> hits1Docs = toDocIDs(s, hits1);\n      Set<String> hits2Docs = toDocIDs(s, hits2);\n\n      try {\n        assertEquals(hits2.totalHits, hits1.totalHits);\n        assertEquals(hits2Docs, hits1Docs);\n      } catch (AssertionError ae) {\n        System.out.println(\"FAILED:\");\n        for(String id : hits1Docs) {\n          if (hits2Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s matched but should not have\", id));\n          }\n        }\n        for(String id : hits2Docs) {\n          if (hits1Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s did not match but should have\", id));\n          }\n        }\n        throw ae;\n      }\n    }\n\n    IOUtils.close(w, r, dir, analyzer);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"83788ad129a5154d5c6562c4e8ce3db48793aada","date":1532961485,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/sandbox/src/test/org/apache/lucene/search/TestTermAutomatonQuery#testRandom().mjava","pathOld":"lucene/sandbox/src/test/org/apache/lucene/search/TestTermAutomatonQuery#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n    int numDocs = atLeast(100);\n    Directory dir = newDirectory();\n\n    // Adds occassional random synonyms:\n    Analyzer analyzer = new Analyzer() {\n        @Override\n        public TokenStreamComponents createComponents(String fieldName) {\n          MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true, 100);\n          tokenizer.setEnableChecks(true);\n          TokenFilter filt = new MockTokenFilter(tokenizer, MockTokenFilter.EMPTY_STOPSET);\n          filt = new RandomSynonymFilter(filt);\n          return new TokenStreamComponents(tokenizer, filt);\n        }\n      };\n\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    for(int i=0;i<numDocs;i++) {\n      Document doc = new Document();\n      int numTokens = atLeast(10);\n\n      StringBuilder sb = new StringBuilder();\n      for(int j=0;j<numTokens;j++) {\n        sb.append(' ');\n        sb.append((char) (97 + random().nextInt(3)));\n      }\n      String contents = sb.toString();\n      doc.add(newTextField(\"field\", contents, Field.Store.NO));\n      doc.add(new StoredField(\"id\", \"\"+i));\n      if (VERBOSE) {\n        System.out.println(\"  doc \" + i + \" -> \" + contents);\n      }\n      w.addDocument(doc);\n    }\n\n    IndexReader r = w.getReader();\n    IndexSearcher s = newSearcher(r);\n\n    // Used to match ANY using MultiPhraseQuery:\n    Term[] allTerms = new Term[] {new Term(\"field\", \"a\"),\n                                  new Term(\"field\", \"b\"),\n                                  new Term(\"field\", \"c\")};\n    int numIters = atLeast(1000);\n    for(int iter=0;iter<numIters;iter++) {\n\n      // Build the (finite, no any transitions) TermAutomatonQuery and\n      // also the \"equivalent\" BooleanQuery and make sure they match the\n      // same docs:\n      BooleanQuery.Builder bq = new BooleanQuery.Builder();\n      int count = TestUtil.nextInt(random(), 1, 5);\n      Set<BytesRef> strings = new HashSet<>();\n      for(int i=0;i<count;i++) {\n        StringBuilder sb = new StringBuilder();\n        int numTokens = TestUtil.nextInt(random(), 1, 5);\n        for(int j=0;j<numTokens;j++) {\n          if (j > 0 && j < numTokens-1 && random().nextInt(5) == 3) {\n            sb.append('*');\n          } else {\n            sb.append((char) (97 + random().nextInt(3)));\n          }\n        }\n        String string = sb.toString();\n        MultiPhraseQuery.Builder mpqb = new MultiPhraseQuery.Builder();\n        for(int j=0;j<string.length();j++) {\n          if (string.charAt(j) == '*') {\n            mpqb.add(allTerms);\n          } else {\n            mpqb.add(new Term(\"field\", \"\"+string.charAt(j)));\n          }\n        }\n        bq.add(mpqb.build(), BooleanClause.Occur.SHOULD);\n        strings.add(new BytesRef(string));\n      }\n\n      List<BytesRef> stringsList = new ArrayList<>(strings);\n      Collections.sort(stringsList);\n\n      Automaton a = Automata.makeStringUnion(stringsList);\n\n      // Translate automaton to query:\n    \n      TermAutomatonQuery q = new TermAutomatonQuery(\"field\");\n      int numStates = a.getNumStates();\n      for(int i=0;i<numStates;i++) {\n        q.createState();\n        q.setAccept(i, a.isAccept(i));\n      }\n\n      Transition t = new Transition();\n      for(int i=0;i<numStates;i++) {\n        int transCount = a.initTransition(i, t);\n        for(int j=0;j<transCount;j++) {\n          a.getNextTransition(t);\n          for(int label=t.min;label<=t.max;label++) {\n            if ((char) label == '*') {\n              q.addAnyTransition(t.source, t.dest);\n            } else {\n              q.addTransition(t.source, t.dest, \"\"+(char) label);\n            }\n          }\n        }\n      }\n      q.finish();\n\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n        for(BytesRef string : stringsList) {\n          System.out.println(\"  string: \" + string.utf8ToString());\n        }\n        System.out.println(q.toDot());\n      }\n      \n      Query q1 = q;\n      Query q2 = bq.build();\n      if (random().nextInt(5) == 1) {\n        if (VERBOSE) {\n          System.out.println(\"  use random filter\");\n        }\n        RandomQuery filter = new RandomQuery(random().nextLong(), random().nextFloat());\n        q1 = new BooleanQuery.Builder()\n            .add(q1, Occur.MUST)\n            .add(filter, Occur.FILTER)\n            .build();\n        q2 = new BooleanQuery.Builder()\n            .add(q2, Occur.MUST)\n            .add(filter, Occur.FILTER)\n            .build();\n      }\n\n      TopDocs hits1 = s.search(q1, numDocs);\n      TopDocs hits2 = s.search(q2, numDocs);\n      Set<String> hits1Docs = toDocIDs(s, hits1);\n      Set<String> hits2Docs = toDocIDs(s, hits2);\n\n      try {\n        assertEquals(hits2.totalHits.value, hits1.totalHits.value);\n        assertEquals(hits2Docs, hits1Docs);\n      } catch (AssertionError ae) {\n        System.out.println(\"FAILED:\");\n        for(String id : hits1Docs) {\n          if (hits2Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s matched but should not have\", id));\n          }\n        }\n        for(String id : hits2Docs) {\n          if (hits1Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s did not match but should have\", id));\n          }\n        }\n        throw ae;\n      }\n    }\n\n    IOUtils.close(w, r, dir, analyzer);\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n    int numDocs = atLeast(100);\n    Directory dir = newDirectory();\n\n    // Adds occassional random synonyms:\n    Analyzer analyzer = new Analyzer() {\n        @Override\n        public TokenStreamComponents createComponents(String fieldName) {\n          MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true, 100);\n          tokenizer.setEnableChecks(true);\n          TokenFilter filt = new MockTokenFilter(tokenizer, MockTokenFilter.EMPTY_STOPSET);\n          filt = new RandomSynonymFilter(filt);\n          return new TokenStreamComponents(tokenizer, filt);\n        }\n      };\n\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    for(int i=0;i<numDocs;i++) {\n      Document doc = new Document();\n      int numTokens = atLeast(10);\n\n      StringBuilder sb = new StringBuilder();\n      for(int j=0;j<numTokens;j++) {\n        sb.append(' ');\n        sb.append((char) (97 + random().nextInt(3)));\n      }\n      String contents = sb.toString();\n      doc.add(newTextField(\"field\", contents, Field.Store.NO));\n      doc.add(new StoredField(\"id\", \"\"+i));\n      if (VERBOSE) {\n        System.out.println(\"  doc \" + i + \" -> \" + contents);\n      }\n      w.addDocument(doc);\n    }\n\n    IndexReader r = w.getReader();\n    IndexSearcher s = newSearcher(r);\n\n    // Used to match ANY using MultiPhraseQuery:\n    Term[] allTerms = new Term[] {new Term(\"field\", \"a\"),\n                                  new Term(\"field\", \"b\"),\n                                  new Term(\"field\", \"c\")};\n    int numIters = atLeast(1000);\n    for(int iter=0;iter<numIters;iter++) {\n\n      // Build the (finite, no any transitions) TermAutomatonQuery and\n      // also the \"equivalent\" BooleanQuery and make sure they match the\n      // same docs:\n      BooleanQuery.Builder bq = new BooleanQuery.Builder();\n      int count = TestUtil.nextInt(random(), 1, 5);\n      Set<BytesRef> strings = new HashSet<>();\n      for(int i=0;i<count;i++) {\n        StringBuilder sb = new StringBuilder();\n        int numTokens = TestUtil.nextInt(random(), 1, 5);\n        for(int j=0;j<numTokens;j++) {\n          if (j > 0 && j < numTokens-1 && random().nextInt(5) == 3) {\n            sb.append('*');\n          } else {\n            sb.append((char) (97 + random().nextInt(3)));\n          }\n        }\n        String string = sb.toString();\n        MultiPhraseQuery.Builder mpqb = new MultiPhraseQuery.Builder();\n        for(int j=0;j<string.length();j++) {\n          if (string.charAt(j) == '*') {\n            mpqb.add(allTerms);\n          } else {\n            mpqb.add(new Term(\"field\", \"\"+string.charAt(j)));\n          }\n        }\n        bq.add(mpqb.build(), BooleanClause.Occur.SHOULD);\n        strings.add(new BytesRef(string));\n      }\n\n      List<BytesRef> stringsList = new ArrayList<>(strings);\n      Collections.sort(stringsList);\n\n      Automaton a = Automata.makeStringUnion(stringsList);\n\n      // Translate automaton to query:\n    \n      TermAutomatonQuery q = new TermAutomatonQuery(\"field\");\n      int numStates = a.getNumStates();\n      for(int i=0;i<numStates;i++) {\n        q.createState();\n        q.setAccept(i, a.isAccept(i));\n      }\n\n      Transition t = new Transition();\n      for(int i=0;i<numStates;i++) {\n        int transCount = a.initTransition(i, t);\n        for(int j=0;j<transCount;j++) {\n          a.getNextTransition(t);\n          for(int label=t.min;label<=t.max;label++) {\n            if ((char) label == '*') {\n              q.addAnyTransition(t.source, t.dest);\n            } else {\n              q.addTransition(t.source, t.dest, \"\"+(char) label);\n            }\n          }\n        }\n      }\n      q.finish();\n\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n        for(BytesRef string : stringsList) {\n          System.out.println(\"  string: \" + string.utf8ToString());\n        }\n        System.out.println(q.toDot());\n      }\n      \n      Query q1 = q;\n      Query q2 = bq.build();\n      if (random().nextInt(5) == 1) {\n        if (VERBOSE) {\n          System.out.println(\"  use random filter\");\n        }\n        RandomQuery filter = new RandomQuery(random().nextLong(), random().nextFloat());\n        q1 = new BooleanQuery.Builder()\n            .add(q1, Occur.MUST)\n            .add(filter, Occur.FILTER)\n            .build();\n        q2 = new BooleanQuery.Builder()\n            .add(q2, Occur.MUST)\n            .add(filter, Occur.FILTER)\n            .build();\n      }\n\n      TopDocs hits1 = s.search(q1, numDocs);\n      TopDocs hits2 = s.search(q2, numDocs);\n      Set<String> hits1Docs = toDocIDs(s, hits1);\n      Set<String> hits2Docs = toDocIDs(s, hits2);\n\n      try {\n        assertEquals(hits2.totalHits, hits1.totalHits);\n        assertEquals(hits2Docs, hits1Docs);\n      } catch (AssertionError ae) {\n        System.out.println(\"FAILED:\");\n        for(String id : hits1Docs) {\n          if (hits2Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s matched but should not have\", id));\n          }\n        }\n        for(String id : hits2Docs) {\n          if (hits1Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s did not match but should have\", id));\n          }\n        }\n        throw ae;\n      }\n    }\n\n    IOUtils.close(w, r, dir, analyzer);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f","date":1579652839,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/sandbox/src/test/org/apache/lucene/search/TestTermAutomatonQuery#testRandom().mjava","pathOld":"lucene/sandbox/src/test/org/apache/lucene/search/TestTermAutomatonQuery#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n    int numDocs = atLeast(50);\n    Directory dir = newDirectory();\n\n    // Adds occasional random synonyms:\n    Analyzer analyzer = new Analyzer() {\n        @Override\n        public TokenStreamComponents createComponents(String fieldName) {\n          MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true, 100);\n          tokenizer.setEnableChecks(true);\n          TokenFilter filt = new MockTokenFilter(tokenizer, MockTokenFilter.EMPTY_STOPSET);\n          filt = new RandomSynonymFilter(filt);\n          return new TokenStreamComponents(tokenizer, filt);\n        }\n      };\n\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    for(int i=0;i<numDocs;i++) {\n      Document doc = new Document();\n      int numTokens = atLeast(10);\n\n      StringBuilder sb = new StringBuilder();\n      for(int j=0;j<numTokens;j++) {\n        sb.append(' ');\n        sb.append((char) (97 + random().nextInt(3)));\n      }\n      String contents = sb.toString();\n      doc.add(newTextField(\"field\", contents, Field.Store.NO));\n      doc.add(new StoredField(\"id\", \"\"+i));\n      if (VERBOSE) {\n        System.out.println(\"  doc \" + i + \" -> \" + contents);\n      }\n      w.addDocument(doc);\n    }\n\n    IndexReader r = w.getReader();\n    IndexSearcher s = newSearcher(r);\n\n    // Used to match ANY using MultiPhraseQuery:\n    Term[] allTerms = new Term[] {new Term(\"field\", \"a\"),\n                                  new Term(\"field\", \"b\"),\n                                  new Term(\"field\", \"c\")};\n    int numIters = atLeast(1000);\n    for(int iter=0;iter<numIters;iter++) {\n\n      // Build the (finite, no any transitions) TermAutomatonQuery and\n      // also the \"equivalent\" BooleanQuery and make sure they match the\n      // same docs:\n      BooleanQuery.Builder bq = new BooleanQuery.Builder();\n      int count = TestUtil.nextInt(random(), 1, 5);\n      Set<BytesRef> strings = new HashSet<>();\n      for(int i=0;i<count;i++) {\n        StringBuilder sb = new StringBuilder();\n        int numTokens = TestUtil.nextInt(random(), 1, 5);\n        for(int j=0;j<numTokens;j++) {\n          if (j > 0 && j < numTokens-1 && random().nextInt(5) == 3) {\n            sb.append('*');\n          } else {\n            sb.append((char) (97 + random().nextInt(3)));\n          }\n        }\n        String string = sb.toString();\n        MultiPhraseQuery.Builder mpqb = new MultiPhraseQuery.Builder();\n        for(int j=0;j<string.length();j++) {\n          if (string.charAt(j) == '*') {\n            mpqb.add(allTerms);\n          } else {\n            mpqb.add(new Term(\"field\", \"\"+string.charAt(j)));\n          }\n        }\n        bq.add(mpqb.build(), BooleanClause.Occur.SHOULD);\n        strings.add(new BytesRef(string));\n      }\n\n      List<BytesRef> stringsList = new ArrayList<>(strings);\n      Collections.sort(stringsList);\n\n      Automaton a = Automata.makeStringUnion(stringsList);\n\n      // Translate automaton to query:\n    \n      TermAutomatonQuery q = new TermAutomatonQuery(\"field\");\n      int numStates = a.getNumStates();\n      for(int i=0;i<numStates;i++) {\n        q.createState();\n        q.setAccept(i, a.isAccept(i));\n      }\n\n      Transition t = new Transition();\n      for(int i=0;i<numStates;i++) {\n        int transCount = a.initTransition(i, t);\n        for(int j=0;j<transCount;j++) {\n          a.getNextTransition(t);\n          for(int label=t.min;label<=t.max;label++) {\n            if ((char) label == '*') {\n              q.addAnyTransition(t.source, t.dest);\n            } else {\n              q.addTransition(t.source, t.dest, \"\"+(char) label);\n            }\n          }\n        }\n      }\n      q.finish();\n\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n        for(BytesRef string : stringsList) {\n          System.out.println(\"  string: \" + string.utf8ToString());\n        }\n        System.out.println(q.toDot());\n      }\n      \n      Query q1 = q;\n      Query q2 = bq.build();\n      if (random().nextInt(5) == 1) {\n        if (VERBOSE) {\n          System.out.println(\"  use random filter\");\n        }\n        RandomQuery filter = new RandomQuery(random().nextLong(), random().nextFloat());\n        q1 = new BooleanQuery.Builder()\n            .add(q1, Occur.MUST)\n            .add(filter, Occur.FILTER)\n            .build();\n        q2 = new BooleanQuery.Builder()\n            .add(q2, Occur.MUST)\n            .add(filter, Occur.FILTER)\n            .build();\n      }\n\n      TopDocs hits1 = s.search(q1, numDocs);\n      TopDocs hits2 = s.search(q2, numDocs);\n      Set<String> hits1Docs = toDocIDs(s, hits1);\n      Set<String> hits2Docs = toDocIDs(s, hits2);\n\n      try {\n        assertEquals(hits2.totalHits.value, hits1.totalHits.value);\n        assertEquals(hits2Docs, hits1Docs);\n      } catch (AssertionError ae) {\n        System.out.println(\"FAILED:\");\n        for(String id : hits1Docs) {\n          if (hits2Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s matched but should not have\", id));\n          }\n        }\n        for(String id : hits2Docs) {\n          if (hits1Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s did not match but should have\", id));\n          }\n        }\n        throw ae;\n      }\n    }\n\n    IOUtils.close(w, r, dir, analyzer);\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n    int numDocs = atLeast(100);\n    Directory dir = newDirectory();\n\n    // Adds occassional random synonyms:\n    Analyzer analyzer = new Analyzer() {\n        @Override\n        public TokenStreamComponents createComponents(String fieldName) {\n          MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true, 100);\n          tokenizer.setEnableChecks(true);\n          TokenFilter filt = new MockTokenFilter(tokenizer, MockTokenFilter.EMPTY_STOPSET);\n          filt = new RandomSynonymFilter(filt);\n          return new TokenStreamComponents(tokenizer, filt);\n        }\n      };\n\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    for(int i=0;i<numDocs;i++) {\n      Document doc = new Document();\n      int numTokens = atLeast(10);\n\n      StringBuilder sb = new StringBuilder();\n      for(int j=0;j<numTokens;j++) {\n        sb.append(' ');\n        sb.append((char) (97 + random().nextInt(3)));\n      }\n      String contents = sb.toString();\n      doc.add(newTextField(\"field\", contents, Field.Store.NO));\n      doc.add(new StoredField(\"id\", \"\"+i));\n      if (VERBOSE) {\n        System.out.println(\"  doc \" + i + \" -> \" + contents);\n      }\n      w.addDocument(doc);\n    }\n\n    IndexReader r = w.getReader();\n    IndexSearcher s = newSearcher(r);\n\n    // Used to match ANY using MultiPhraseQuery:\n    Term[] allTerms = new Term[] {new Term(\"field\", \"a\"),\n                                  new Term(\"field\", \"b\"),\n                                  new Term(\"field\", \"c\")};\n    int numIters = atLeast(1000);\n    for(int iter=0;iter<numIters;iter++) {\n\n      // Build the (finite, no any transitions) TermAutomatonQuery and\n      // also the \"equivalent\" BooleanQuery and make sure they match the\n      // same docs:\n      BooleanQuery.Builder bq = new BooleanQuery.Builder();\n      int count = TestUtil.nextInt(random(), 1, 5);\n      Set<BytesRef> strings = new HashSet<>();\n      for(int i=0;i<count;i++) {\n        StringBuilder sb = new StringBuilder();\n        int numTokens = TestUtil.nextInt(random(), 1, 5);\n        for(int j=0;j<numTokens;j++) {\n          if (j > 0 && j < numTokens-1 && random().nextInt(5) == 3) {\n            sb.append('*');\n          } else {\n            sb.append((char) (97 + random().nextInt(3)));\n          }\n        }\n        String string = sb.toString();\n        MultiPhraseQuery.Builder mpqb = new MultiPhraseQuery.Builder();\n        for(int j=0;j<string.length();j++) {\n          if (string.charAt(j) == '*') {\n            mpqb.add(allTerms);\n          } else {\n            mpqb.add(new Term(\"field\", \"\"+string.charAt(j)));\n          }\n        }\n        bq.add(mpqb.build(), BooleanClause.Occur.SHOULD);\n        strings.add(new BytesRef(string));\n      }\n\n      List<BytesRef> stringsList = new ArrayList<>(strings);\n      Collections.sort(stringsList);\n\n      Automaton a = Automata.makeStringUnion(stringsList);\n\n      // Translate automaton to query:\n    \n      TermAutomatonQuery q = new TermAutomatonQuery(\"field\");\n      int numStates = a.getNumStates();\n      for(int i=0;i<numStates;i++) {\n        q.createState();\n        q.setAccept(i, a.isAccept(i));\n      }\n\n      Transition t = new Transition();\n      for(int i=0;i<numStates;i++) {\n        int transCount = a.initTransition(i, t);\n        for(int j=0;j<transCount;j++) {\n          a.getNextTransition(t);\n          for(int label=t.min;label<=t.max;label++) {\n            if ((char) label == '*') {\n              q.addAnyTransition(t.source, t.dest);\n            } else {\n              q.addTransition(t.source, t.dest, \"\"+(char) label);\n            }\n          }\n        }\n      }\n      q.finish();\n\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n        for(BytesRef string : stringsList) {\n          System.out.println(\"  string: \" + string.utf8ToString());\n        }\n        System.out.println(q.toDot());\n      }\n      \n      Query q1 = q;\n      Query q2 = bq.build();\n      if (random().nextInt(5) == 1) {\n        if (VERBOSE) {\n          System.out.println(\"  use random filter\");\n        }\n        RandomQuery filter = new RandomQuery(random().nextLong(), random().nextFloat());\n        q1 = new BooleanQuery.Builder()\n            .add(q1, Occur.MUST)\n            .add(filter, Occur.FILTER)\n            .build();\n        q2 = new BooleanQuery.Builder()\n            .add(q2, Occur.MUST)\n            .add(filter, Occur.FILTER)\n            .build();\n      }\n\n      TopDocs hits1 = s.search(q1, numDocs);\n      TopDocs hits2 = s.search(q2, numDocs);\n      Set<String> hits1Docs = toDocIDs(s, hits1);\n      Set<String> hits2Docs = toDocIDs(s, hits2);\n\n      try {\n        assertEquals(hits2.totalHits.value, hits1.totalHits.value);\n        assertEquals(hits2Docs, hits1Docs);\n      } catch (AssertionError ae) {\n        System.out.println(\"FAILED:\");\n        for(String id : hits1Docs) {\n          if (hits2Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s matched but should not have\", id));\n          }\n        }\n        for(String id : hits2Docs) {\n          if (hits1Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s did not match but should have\", id));\n          }\n        }\n        throw ae;\n      }\n    }\n\n    IOUtils.close(w, r, dir, analyzer);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c37ab80ad12b466f3dc92e4baa7b0cbf9aded429","date":1590107358,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"lucene/sandbox/src/test/org/apache/lucene/search/TestTermAutomatonQuery#testRandom().mjava","pathOld":"lucene/sandbox/src/test/org/apache/lucene/search/TestTermAutomatonQuery#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n    int numDocs = atLeast(50);\n    Directory dir = newDirectory();\n\n    // Adds occasional random synonyms:\n    Analyzer analyzer = new Analyzer() {\n        @Override\n        public TokenStreamComponents createComponents(String fieldName) {\n          MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true, 100);\n          tokenizer.setEnableChecks(true);\n          TokenFilter filt = new MockTokenFilter(tokenizer, MockTokenFilter.EMPTY_STOPSET);\n          filt = new RandomSynonymFilter(filt);\n          return new TokenStreamComponents(tokenizer, filt);\n        }\n      };\n\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    for(int i=0;i<numDocs;i++) {\n      Document doc = new Document();\n      int numTokens = atLeast(10);\n\n      StringBuilder sb = new StringBuilder();\n      for(int j=0;j<numTokens;j++) {\n        sb.append(' ');\n        sb.append((char) (97 + random().nextInt(3)));\n      }\n      String contents = sb.toString();\n      doc.add(newTextField(\"field\", contents, Field.Store.NO));\n      doc.add(new StoredField(\"id\", \"\"+i));\n      if (VERBOSE) {\n        System.out.println(\"  doc \" + i + \" -> \" + contents);\n      }\n      w.addDocument(doc);\n    }\n\n    IndexReader r = w.getReader();\n    w.close();\n    IndexSearcher s = newSearcher(r);\n\n    // Used to match ANY using MultiPhraseQuery:\n    Term[] allTerms = new Term[] {new Term(\"field\", \"a\"),\n                                  new Term(\"field\", \"b\"),\n                                  new Term(\"field\", \"c\")};\n    int numIters = atLeast(1000);\n    for(int iter=0;iter<numIters;iter++) {\n\n      // Build the (finite, no any transitions) TermAutomatonQuery and\n      // also the \"equivalent\" BooleanQuery and make sure they match the\n      // same docs:\n      BooleanQuery.Builder bq = new BooleanQuery.Builder();\n      int count = TestUtil.nextInt(random(), 1, 5);\n      Set<BytesRef> strings = new HashSet<>();\n      for(int i=0;i<count;i++) {\n        StringBuilder sb = new StringBuilder();\n        int numTokens = TestUtil.nextInt(random(), 1, 5);\n        for(int j=0;j<numTokens;j++) {\n          if (j > 0 && j < numTokens-1 && random().nextInt(5) == 3) {\n            sb.append('*');\n          } else {\n            sb.append((char) (97 + random().nextInt(3)));\n          }\n        }\n        String string = sb.toString();\n        MultiPhraseQuery.Builder mpqb = new MultiPhraseQuery.Builder();\n        for(int j=0;j<string.length();j++) {\n          if (string.charAt(j) == '*') {\n            mpqb.add(allTerms);\n          } else {\n            mpqb.add(new Term(\"field\", \"\"+string.charAt(j)));\n          }\n        }\n        bq.add(mpqb.build(), BooleanClause.Occur.SHOULD);\n        strings.add(new BytesRef(string));\n      }\n\n      List<BytesRef> stringsList = new ArrayList<>(strings);\n      Collections.sort(stringsList);\n\n      Automaton a = Automata.makeStringUnion(stringsList);\n\n      // Translate automaton to query:\n    \n      TermAutomatonQuery q = new TermAutomatonQuery(\"field\");\n      int numStates = a.getNumStates();\n      for(int i=0;i<numStates;i++) {\n        q.createState();\n        q.setAccept(i, a.isAccept(i));\n      }\n\n      Transition t = new Transition();\n      for(int i=0;i<numStates;i++) {\n        int transCount = a.initTransition(i, t);\n        for(int j=0;j<transCount;j++) {\n          a.getNextTransition(t);\n          for(int label=t.min;label<=t.max;label++) {\n            if ((char) label == '*') {\n              q.addAnyTransition(t.source, t.dest);\n            } else {\n              q.addTransition(t.source, t.dest, \"\"+(char) label);\n            }\n          }\n        }\n      }\n      q.finish();\n\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n        for(BytesRef string : stringsList) {\n          System.out.println(\"  string: \" + string.utf8ToString());\n        }\n        System.out.println(q.toDot());\n      }\n      \n      Query q1 = q;\n      Query q2 = bq.build();\n      if (random().nextInt(5) == 1) {\n        if (VERBOSE) {\n          System.out.println(\"  use random filter\");\n        }\n        RandomQuery filter = new RandomQuery(random().nextLong(), random().nextFloat());\n        q1 = new BooleanQuery.Builder()\n            .add(q1, Occur.MUST)\n            .add(filter, Occur.FILTER)\n            .build();\n        q2 = new BooleanQuery.Builder()\n            .add(q2, Occur.MUST)\n            .add(filter, Occur.FILTER)\n            .build();\n      }\n\n      TopDocs hits1 = s.search(q1, numDocs);\n      TopDocs hits2 = s.search(q2, numDocs);\n      Set<String> hits1Docs = toDocIDs(s, hits1);\n      Set<String> hits2Docs = toDocIDs(s, hits2);\n\n      try {\n        assertEquals(hits2.totalHits.value, hits1.totalHits.value);\n        assertEquals(hits2Docs, hits1Docs);\n      } catch (AssertionError ae) {\n        System.out.println(\"FAILED:\");\n        for(String id : hits1Docs) {\n          if (hits2Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s matched but should not have\", id));\n          }\n        }\n        for(String id : hits2Docs) {\n          if (hits1Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s did not match but should have\", id));\n          }\n        }\n        throw ae;\n      }\n    }\n\n    IOUtils.close(r, dir, analyzer);\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n    int numDocs = atLeast(50);\n    Directory dir = newDirectory();\n\n    // Adds occasional random synonyms:\n    Analyzer analyzer = new Analyzer() {\n        @Override\n        public TokenStreamComponents createComponents(String fieldName) {\n          MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true, 100);\n          tokenizer.setEnableChecks(true);\n          TokenFilter filt = new MockTokenFilter(tokenizer, MockTokenFilter.EMPTY_STOPSET);\n          filt = new RandomSynonymFilter(filt);\n          return new TokenStreamComponents(tokenizer, filt);\n        }\n      };\n\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    for(int i=0;i<numDocs;i++) {\n      Document doc = new Document();\n      int numTokens = atLeast(10);\n\n      StringBuilder sb = new StringBuilder();\n      for(int j=0;j<numTokens;j++) {\n        sb.append(' ');\n        sb.append((char) (97 + random().nextInt(3)));\n      }\n      String contents = sb.toString();\n      doc.add(newTextField(\"field\", contents, Field.Store.NO));\n      doc.add(new StoredField(\"id\", \"\"+i));\n      if (VERBOSE) {\n        System.out.println(\"  doc \" + i + \" -> \" + contents);\n      }\n      w.addDocument(doc);\n    }\n\n    IndexReader r = w.getReader();\n    IndexSearcher s = newSearcher(r);\n\n    // Used to match ANY using MultiPhraseQuery:\n    Term[] allTerms = new Term[] {new Term(\"field\", \"a\"),\n                                  new Term(\"field\", \"b\"),\n                                  new Term(\"field\", \"c\")};\n    int numIters = atLeast(1000);\n    for(int iter=0;iter<numIters;iter++) {\n\n      // Build the (finite, no any transitions) TermAutomatonQuery and\n      // also the \"equivalent\" BooleanQuery and make sure they match the\n      // same docs:\n      BooleanQuery.Builder bq = new BooleanQuery.Builder();\n      int count = TestUtil.nextInt(random(), 1, 5);\n      Set<BytesRef> strings = new HashSet<>();\n      for(int i=0;i<count;i++) {\n        StringBuilder sb = new StringBuilder();\n        int numTokens = TestUtil.nextInt(random(), 1, 5);\n        for(int j=0;j<numTokens;j++) {\n          if (j > 0 && j < numTokens-1 && random().nextInt(5) == 3) {\n            sb.append('*');\n          } else {\n            sb.append((char) (97 + random().nextInt(3)));\n          }\n        }\n        String string = sb.toString();\n        MultiPhraseQuery.Builder mpqb = new MultiPhraseQuery.Builder();\n        for(int j=0;j<string.length();j++) {\n          if (string.charAt(j) == '*') {\n            mpqb.add(allTerms);\n          } else {\n            mpqb.add(new Term(\"field\", \"\"+string.charAt(j)));\n          }\n        }\n        bq.add(mpqb.build(), BooleanClause.Occur.SHOULD);\n        strings.add(new BytesRef(string));\n      }\n\n      List<BytesRef> stringsList = new ArrayList<>(strings);\n      Collections.sort(stringsList);\n\n      Automaton a = Automata.makeStringUnion(stringsList);\n\n      // Translate automaton to query:\n    \n      TermAutomatonQuery q = new TermAutomatonQuery(\"field\");\n      int numStates = a.getNumStates();\n      for(int i=0;i<numStates;i++) {\n        q.createState();\n        q.setAccept(i, a.isAccept(i));\n      }\n\n      Transition t = new Transition();\n      for(int i=0;i<numStates;i++) {\n        int transCount = a.initTransition(i, t);\n        for(int j=0;j<transCount;j++) {\n          a.getNextTransition(t);\n          for(int label=t.min;label<=t.max;label++) {\n            if ((char) label == '*') {\n              q.addAnyTransition(t.source, t.dest);\n            } else {\n              q.addTransition(t.source, t.dest, \"\"+(char) label);\n            }\n          }\n        }\n      }\n      q.finish();\n\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n        for(BytesRef string : stringsList) {\n          System.out.println(\"  string: \" + string.utf8ToString());\n        }\n        System.out.println(q.toDot());\n      }\n      \n      Query q1 = q;\n      Query q2 = bq.build();\n      if (random().nextInt(5) == 1) {\n        if (VERBOSE) {\n          System.out.println(\"  use random filter\");\n        }\n        RandomQuery filter = new RandomQuery(random().nextLong(), random().nextFloat());\n        q1 = new BooleanQuery.Builder()\n            .add(q1, Occur.MUST)\n            .add(filter, Occur.FILTER)\n            .build();\n        q2 = new BooleanQuery.Builder()\n            .add(q2, Occur.MUST)\n            .add(filter, Occur.FILTER)\n            .build();\n      }\n\n      TopDocs hits1 = s.search(q1, numDocs);\n      TopDocs hits2 = s.search(q2, numDocs);\n      Set<String> hits1Docs = toDocIDs(s, hits1);\n      Set<String> hits2Docs = toDocIDs(s, hits2);\n\n      try {\n        assertEquals(hits2.totalHits.value, hits1.totalHits.value);\n        assertEquals(hits2Docs, hits1Docs);\n      } catch (AssertionError ae) {\n        System.out.println(\"FAILED:\");\n        for(String id : hits1Docs) {\n          if (hits2Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s matched but should not have\", id));\n          }\n        }\n        for(String id : hits2Docs) {\n          if (hits1Docs.contains(id) == false) {\n            System.out.println(String.format(Locale.ROOT, \"  id=%3s did not match but should have\", id));\n          }\n        }\n        throw ae;\n      }\n    }\n\n    IOUtils.close(w, r, dir, analyzer);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f":["83788ad129a5154d5c6562c4e8ce3db48793aada"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["06a4493f0c732d2928d1a4f773f15d19434aa8ba"],"06a4493f0c732d2928d1a4f773f15d19434aa8ba":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"c37ab80ad12b466f3dc92e4baa7b0cbf9aded429":["fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f"],"3f68d01cf19df971dcdcb05e30247f4ad7ec9747":["a56958d7f71a28824f20031ffbb2e13502a0274e"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc","a56958d7f71a28824f20031ffbb2e13502a0274e"],"1db68e96dd908fcd79ef809095822736aa601d08":["3f68d01cf19df971dcdcb05e30247f4ad7ec9747"],"92b4a131f1796dd57cc6698aae3d589d32a29deb":["d52e48927ca4ef3655a261f2230b968b6fdf3608"],"d52e48927ca4ef3655a261f2230b968b6fdf3608":["1db68e96dd908fcd79ef809095822736aa601d08"],"f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"83788ad129a5154d5c6562c4e8ce3db48793aada":["cf1a614098b46c9c22afebd7b898ae4d1d2fc273"],"cf1a614098b46c9c22afebd7b898ae4d1d2fc273":["d52e48927ca4ef3655a261f2230b968b6fdf3608","92b4a131f1796dd57cc6698aae3d589d32a29deb"],"a56958d7f71a28824f20031ffbb2e13502a0274e":["50c99225e51de7d0aff8f06f1ab6a99d4bb0f2a4"],"299a2348fa24151d150182211b6208a38e5e3450":["f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc","50c99225e51de7d0aff8f06f1ab6a99d4bb0f2a4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c37ab80ad12b466f3dc92e4baa7b0cbf9aded429"],"50c99225e51de7d0aff8f06f1ab6a99d4bb0f2a4":["f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc"]},"commit2Childs":{"fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f":["c37ab80ad12b466f3dc92e4baa7b0cbf9aded429"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc"],"06a4493f0c732d2928d1a4f773f15d19434aa8ba":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"c37ab80ad12b466f3dc92e4baa7b0cbf9aded429":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3f68d01cf19df971dcdcb05e30247f4ad7ec9747":["1db68e96dd908fcd79ef809095822736aa601d08"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"1db68e96dd908fcd79ef809095822736aa601d08":["d52e48927ca4ef3655a261f2230b968b6fdf3608"],"92b4a131f1796dd57cc6698aae3d589d32a29deb":["cf1a614098b46c9c22afebd7b898ae4d1d2fc273"],"d52e48927ca4ef3655a261f2230b968b6fdf3608":["92b4a131f1796dd57cc6698aae3d589d32a29deb","cf1a614098b46c9c22afebd7b898ae4d1d2fc273"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["06a4493f0c732d2928d1a4f773f15d19434aa8ba"],"f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","299a2348fa24151d150182211b6208a38e5e3450","50c99225e51de7d0aff8f06f1ab6a99d4bb0f2a4"],"83788ad129a5154d5c6562c4e8ce3db48793aada":["fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f"],"cf1a614098b46c9c22afebd7b898ae4d1d2fc273":["83788ad129a5154d5c6562c4e8ce3db48793aada"],"a56958d7f71a28824f20031ffbb2e13502a0274e":["3f68d01cf19df971dcdcb05e30247f4ad7ec9747","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae"],"299a2348fa24151d150182211b6208a38e5e3450":[],"50c99225e51de7d0aff8f06f1ab6a99d4bb0f2a4":["a56958d7f71a28824f20031ffbb2e13502a0274e","299a2348fa24151d150182211b6208a38e5e3450"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","299a2348fa24151d150182211b6208a38e5e3450","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}