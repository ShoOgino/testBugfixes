{"path":"src/test-deprecated/org/apache/lucene/search/TestTermVectors#testKnownSetOfDocuments().mjava","commits":[{"id":"5b5461affe637a07375542c763a4805300802be8","date":1102270918,"type":0,"author":"Bernhard Messer","isMerge":false,"pathNew":"src/test-deprecated/org/apache/lucene/search/TestTermVectors#testKnownSetOfDocuments().mjava","pathOld":"/dev/null","sourceNew":"  public void testKnownSetOfDocuments() {\n    String [] termArray = {\"eating\", \"chocolate\", \"in\", \"a\", \"computer\", \"lab\", \"grows\", \"old\", \"colored\",\n                      \"with\", \"an\"};\n    String test1 = \"eating chocolate in a computer lab\"; //6 terms\n    String test2 = \"computer in a computer lab\"; //5 terms\n    String test3 = \"a chocolate lab grows old\"; //5 terms\n    String test4 = \"eating chocolate with a chocolate lab in an old chocolate colored computer lab\"; //13 terms\n    Map test4Map = new HashMap();\n    test4Map.put(\"chocolate\", new Integer(3));\n    test4Map.put(\"lab\", new Integer(2));\n    test4Map.put(\"eating\", new Integer(1));\n    test4Map.put(\"computer\", new Integer(1));\n    test4Map.put(\"with\", new Integer(1));\n    test4Map.put(\"a\", new Integer(1));\n    test4Map.put(\"colored\", new Integer(1));\n    test4Map.put(\"in\", new Integer(1));\n    test4Map.put(\"an\", new Integer(1));\n    test4Map.put(\"computer\", new Integer(1));\n    test4Map.put(\"old\", new Integer(1));\n    \n    Document testDoc1 = new Document();\n    setupDoc(testDoc1, test1);\n    Document testDoc2 = new Document();\n    setupDoc(testDoc2, test2);\n    Document testDoc3 = new Document();\n    setupDoc(testDoc3, test3);\n    Document testDoc4 = new Document();\n    setupDoc(testDoc4, test4);\n        \n    Directory dir = new RAMDirectory();\n    \n    try {\n      IndexWriter writer = new IndexWriter(dir, new SimpleAnalyzer(), true);\n      assertTrue(writer != null);\n      writer.addDocument(testDoc1);\n      writer.addDocument(testDoc2);\n      writer.addDocument(testDoc3);\n      writer.addDocument(testDoc4);\n      writer.close();\n      IndexSearcher knownSearcher = new IndexSearcher(dir);\n      TermEnum termEnum = knownSearcher.reader.terms();\n      TermDocs termDocs = knownSearcher.reader.termDocs();\n      //System.out.println(\"Terms: \" + termEnum.size() + \" Orig Len: \" + termArray.length);\n      \n      Similarity sim = knownSearcher.getSimilarity();\n      while (termEnum.next() == true)\n      {\n        Term term = termEnum.term();\n        //System.out.println(\"Term: \" + term);\n        termDocs.seek(term);\n        while (termDocs.next())\n        {\n          int docId = termDocs.doc();\n          int freq = termDocs.freq();\n          //System.out.println(\"Doc Id: \" + docId + \" freq \" + freq);\n          TermFreqVector vector = knownSearcher.reader.getTermFreqVector(docId, \"field\");\n          float tf = sim.tf(freq);\n          float idf = sim.idf(term, knownSearcher);\n          //float qNorm = sim.queryNorm()\n          //This is fine since we don't have stop words\n          float lNorm = sim.lengthNorm(\"field\", vector.getTerms().length);\n          //float coord = sim.coord()\n          //System.out.println(\"TF: \" + tf + \" IDF: \" + idf + \" LenNorm: \" + lNorm);\n          assertTrue(vector != null);\n          String[] vTerms = vector.getTerms();\n          int [] freqs = vector.getTermFrequencies();\n          for (int i = 0; i < vTerms.length; i++)\n          {\n            if (term.text().equals(vTerms[i]) == true)\n            {\n              assertTrue(freqs[i] == freq);\n            }\n          }\n          \n        }\n        //System.out.println(\"--------\");\n      }\n      Query query = new TermQuery(new Term(\"field\", \"chocolate\"));\n      Hits hits = knownSearcher.search(query);\n      //doc 3 should be the first hit b/c it is the shortest match\n      assertTrue(hits.length() == 3);\n      float score = hits.score(0);\n      /*System.out.println(\"Hit 0: \" + hits.id(0) + \" Score: \" + hits.score(0) + \" String: \" + hits.doc(0).toString());\n      System.out.println(\"Explain: \" + knownSearcher.explain(query, hits.id(0)));\n      System.out.println(\"Hit 1: \" + hits.id(1) + \" Score: \" + hits.score(1) + \" String: \" + hits.doc(1).toString());\n      System.out.println(\"Explain: \" + knownSearcher.explain(query, hits.id(1)));\n      System.out.println(\"Hit 2: \" + hits.id(2) + \" Score: \" + hits.score(2) + \" String: \" +  hits.doc(2).toString());\n      System.out.println(\"Explain: \" + knownSearcher.explain(query, hits.id(2)));*/\n      assertTrue(testDoc3.toString().equals(hits.doc(0).toString()));\n      assertTrue(testDoc4.toString().equals(hits.doc(1).toString()));\n      assertTrue(testDoc1.toString().equals(hits.doc(2).toString()));\n      TermFreqVector vector = knownSearcher.reader.getTermFreqVector(hits.id(1), \"field\");\n      assertTrue(vector != null);\n      //System.out.println(\"Vector: \" + vector);\n      String[] terms = vector.getTerms();\n      int [] freqs = vector.getTermFrequencies();\n      assertTrue(terms != null && terms.length == 10);\n      for (int i = 0; i < terms.length; i++) {\n        String term = terms[i];\n        //System.out.println(\"Term: \" + term);\n        int freq = freqs[i];\n        assertTrue(test4.indexOf(term) != -1);\n        Integer freqInt = (Integer)test4Map.get(term);\n        assertTrue(freqInt != null);\n        assertTrue(freqInt.intValue() == freq);        \n      } \n      knownSearcher.close();\n    } catch (IOException e) {\n      e.printStackTrace();\n      assertTrue(false);\n    }\n\n\n  } \n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c69e98ffd83f56083b99e5443ca713cd5783a2ae","date":1142955392,"type":4,"author":"Yonik Seeley","isMerge":false,"pathNew":"/dev/null","pathOld":"src/test-deprecated/org/apache/lucene/search/TestTermVectors#testKnownSetOfDocuments().mjava","sourceNew":null,"sourceOld":"  public void testKnownSetOfDocuments() {\n    String [] termArray = {\"eating\", \"chocolate\", \"in\", \"a\", \"computer\", \"lab\", \"grows\", \"old\", \"colored\",\n                      \"with\", \"an\"};\n    String test1 = \"eating chocolate in a computer lab\"; //6 terms\n    String test2 = \"computer in a computer lab\"; //5 terms\n    String test3 = \"a chocolate lab grows old\"; //5 terms\n    String test4 = \"eating chocolate with a chocolate lab in an old chocolate colored computer lab\"; //13 terms\n    Map test4Map = new HashMap();\n    test4Map.put(\"chocolate\", new Integer(3));\n    test4Map.put(\"lab\", new Integer(2));\n    test4Map.put(\"eating\", new Integer(1));\n    test4Map.put(\"computer\", new Integer(1));\n    test4Map.put(\"with\", new Integer(1));\n    test4Map.put(\"a\", new Integer(1));\n    test4Map.put(\"colored\", new Integer(1));\n    test4Map.put(\"in\", new Integer(1));\n    test4Map.put(\"an\", new Integer(1));\n    test4Map.put(\"computer\", new Integer(1));\n    test4Map.put(\"old\", new Integer(1));\n    \n    Document testDoc1 = new Document();\n    setupDoc(testDoc1, test1);\n    Document testDoc2 = new Document();\n    setupDoc(testDoc2, test2);\n    Document testDoc3 = new Document();\n    setupDoc(testDoc3, test3);\n    Document testDoc4 = new Document();\n    setupDoc(testDoc4, test4);\n        \n    Directory dir = new RAMDirectory();\n    \n    try {\n      IndexWriter writer = new IndexWriter(dir, new SimpleAnalyzer(), true);\n      assertTrue(writer != null);\n      writer.addDocument(testDoc1);\n      writer.addDocument(testDoc2);\n      writer.addDocument(testDoc3);\n      writer.addDocument(testDoc4);\n      writer.close();\n      IndexSearcher knownSearcher = new IndexSearcher(dir);\n      TermEnum termEnum = knownSearcher.reader.terms();\n      TermDocs termDocs = knownSearcher.reader.termDocs();\n      //System.out.println(\"Terms: \" + termEnum.size() + \" Orig Len: \" + termArray.length);\n      \n      Similarity sim = knownSearcher.getSimilarity();\n      while (termEnum.next() == true)\n      {\n        Term term = termEnum.term();\n        //System.out.println(\"Term: \" + term);\n        termDocs.seek(term);\n        while (termDocs.next())\n        {\n          int docId = termDocs.doc();\n          int freq = termDocs.freq();\n          //System.out.println(\"Doc Id: \" + docId + \" freq \" + freq);\n          TermFreqVector vector = knownSearcher.reader.getTermFreqVector(docId, \"field\");\n          float tf = sim.tf(freq);\n          float idf = sim.idf(term, knownSearcher);\n          //float qNorm = sim.queryNorm()\n          //This is fine since we don't have stop words\n          float lNorm = sim.lengthNorm(\"field\", vector.getTerms().length);\n          //float coord = sim.coord()\n          //System.out.println(\"TF: \" + tf + \" IDF: \" + idf + \" LenNorm: \" + lNorm);\n          assertTrue(vector != null);\n          String[] vTerms = vector.getTerms();\n          int [] freqs = vector.getTermFrequencies();\n          for (int i = 0; i < vTerms.length; i++)\n          {\n            if (term.text().equals(vTerms[i]) == true)\n            {\n              assertTrue(freqs[i] == freq);\n            }\n          }\n          \n        }\n        //System.out.println(\"--------\");\n      }\n      Query query = new TermQuery(new Term(\"field\", \"chocolate\"));\n      Hits hits = knownSearcher.search(query);\n      //doc 3 should be the first hit b/c it is the shortest match\n      assertTrue(hits.length() == 3);\n      float score = hits.score(0);\n      /*System.out.println(\"Hit 0: \" + hits.id(0) + \" Score: \" + hits.score(0) + \" String: \" + hits.doc(0).toString());\n      System.out.println(\"Explain: \" + knownSearcher.explain(query, hits.id(0)));\n      System.out.println(\"Hit 1: \" + hits.id(1) + \" Score: \" + hits.score(1) + \" String: \" + hits.doc(1).toString());\n      System.out.println(\"Explain: \" + knownSearcher.explain(query, hits.id(1)));\n      System.out.println(\"Hit 2: \" + hits.id(2) + \" Score: \" + hits.score(2) + \" String: \" +  hits.doc(2).toString());\n      System.out.println(\"Explain: \" + knownSearcher.explain(query, hits.id(2)));*/\n      assertTrue(testDoc3.toString().equals(hits.doc(0).toString()));\n      assertTrue(testDoc4.toString().equals(hits.doc(1).toString()));\n      assertTrue(testDoc1.toString().equals(hits.doc(2).toString()));\n      TermFreqVector vector = knownSearcher.reader.getTermFreqVector(hits.id(1), \"field\");\n      assertTrue(vector != null);\n      //System.out.println(\"Vector: \" + vector);\n      String[] terms = vector.getTerms();\n      int [] freqs = vector.getTermFrequencies();\n      assertTrue(terms != null && terms.length == 10);\n      for (int i = 0; i < terms.length; i++) {\n        String term = terms[i];\n        //System.out.println(\"Term: \" + term);\n        int freq = freqs[i];\n        assertTrue(test4.indexOf(term) != -1);\n        Integer freqInt = (Integer)test4Map.get(term);\n        assertTrue(freqInt != null);\n        assertTrue(freqInt.intValue() == freq);        \n      } \n      knownSearcher.close();\n    } catch (IOException e) {\n      e.printStackTrace();\n      assertTrue(false);\n    }\n\n\n  } \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"5b5461affe637a07375542c763a4805300802be8":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"c69e98ffd83f56083b99e5443ca713cd5783a2ae":["5b5461affe637a07375542c763a4805300802be8"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c69e98ffd83f56083b99e5443ca713cd5783a2ae"]},"commit2Childs":{"5b5461affe637a07375542c763a4805300802be8":["c69e98ffd83f56083b99e5443ca713cd5783a2ae"],"c69e98ffd83f56083b99e5443ca713cd5783a2ae":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["5b5461affe637a07375542c763a4805300802be8"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}