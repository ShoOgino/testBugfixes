{"path":"modules/analysis/common/src/java/org/apache/lucene/analysis/cjk/CJKBigramFilter#refill().mjava","commits":[{"id":"680e7f726eaa1fd44ade8bc1f8a02f452ca7c4ee","date":1325135089,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"modules/analysis/common/src/java/org/apache/lucene/analysis/cjk/CJKBigramFilter#refill().mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * refills buffers with new data from the current token.\n   */\n  private void refill() throws IOException {\n    // compact buffers to keep them smallish if they become large\n    // just a safety check, but technically we only need the last codepoint\n    if (bufferLen > 64) {\n      int last = bufferLen - 1;\n      buffer[0] = buffer[last];\n      startOffset[0] = startOffset[last];\n      endOffset[0] = endOffset[last];\n      bufferLen = 1;\n      index -= last;\n    }\n\n    char termBuffer[] = termAtt.buffer();\n    int len = termAtt.length();\n    int start = offsetAtt.startOffset();\n    int end = offsetAtt.endOffset();\n    \n    int newSize = bufferLen + len;\n    buffer = ArrayUtil.grow(buffer, newSize);\n    startOffset = ArrayUtil.grow(startOffset, newSize);\n    endOffset = ArrayUtil.grow(endOffset, newSize);\n    lastEndOffset = end;\n\n    if (end - start != len) {\n      // crazy offsets (modified by synonym or charfilter): just preserve\n      for (int i = 0, cp = 0; i < len; i += Character.charCount(cp)) {\n        cp = buffer[bufferLen] = Character.codePointAt(termBuffer, i, len);\n        startOffset[bufferLen] = start;\n        endOffset[bufferLen] = end;\n        bufferLen++;\n      }\n    } else {\n      // normal offsets\n      for (int i = 0, cp = 0, cpLen = 0; i < len; i += cpLen) {\n        cp = buffer[bufferLen] = Character.codePointAt(termBuffer, i, len);\n        cpLen = Character.charCount(cp);\n        startOffset[bufferLen] = start;\n        start = endOffset[bufferLen] = start + cpLen;\n        bufferLen++;\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/cjk/CJKBigramFilter#refill().mjava","pathOld":"modules/analysis/common/src/java/org/apache/lucene/analysis/cjk/CJKBigramFilter#refill().mjava","sourceNew":"  /**\n   * refills buffers with new data from the current token.\n   */\n  private void refill() throws IOException {\n    // compact buffers to keep them smallish if they become large\n    // just a safety check, but technically we only need the last codepoint\n    if (bufferLen > 64) {\n      int last = bufferLen - 1;\n      buffer[0] = buffer[last];\n      startOffset[0] = startOffset[last];\n      endOffset[0] = endOffset[last];\n      bufferLen = 1;\n      index -= last;\n    }\n\n    char termBuffer[] = termAtt.buffer();\n    int len = termAtt.length();\n    int start = offsetAtt.startOffset();\n    int end = offsetAtt.endOffset();\n    \n    int newSize = bufferLen + len;\n    buffer = ArrayUtil.grow(buffer, newSize);\n    startOffset = ArrayUtil.grow(startOffset, newSize);\n    endOffset = ArrayUtil.grow(endOffset, newSize);\n    lastEndOffset = end;\n\n    if (end - start != len) {\n      // crazy offsets (modified by synonym or charfilter): just preserve\n      for (int i = 0, cp = 0; i < len; i += Character.charCount(cp)) {\n        cp = buffer[bufferLen] = Character.codePointAt(termBuffer, i, len);\n        startOffset[bufferLen] = start;\n        endOffset[bufferLen] = end;\n        bufferLen++;\n      }\n    } else {\n      // normal offsets\n      for (int i = 0, cp = 0, cpLen = 0; i < len; i += cpLen) {\n        cp = buffer[bufferLen] = Character.codePointAt(termBuffer, i, len);\n        cpLen = Character.charCount(cp);\n        startOffset[bufferLen] = start;\n        start = endOffset[bufferLen] = start + cpLen;\n        bufferLen++;\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * refills buffers with new data from the current token.\n   */\n  private void refill() throws IOException {\n    // compact buffers to keep them smallish if they become large\n    // just a safety check, but technically we only need the last codepoint\n    if (bufferLen > 64) {\n      int last = bufferLen - 1;\n      buffer[0] = buffer[last];\n      startOffset[0] = startOffset[last];\n      endOffset[0] = endOffset[last];\n      bufferLen = 1;\n      index -= last;\n    }\n\n    char termBuffer[] = termAtt.buffer();\n    int len = termAtt.length();\n    int start = offsetAtt.startOffset();\n    int end = offsetAtt.endOffset();\n    \n    int newSize = bufferLen + len;\n    buffer = ArrayUtil.grow(buffer, newSize);\n    startOffset = ArrayUtil.grow(startOffset, newSize);\n    endOffset = ArrayUtil.grow(endOffset, newSize);\n    lastEndOffset = end;\n\n    if (end - start != len) {\n      // crazy offsets (modified by synonym or charfilter): just preserve\n      for (int i = 0, cp = 0; i < len; i += Character.charCount(cp)) {\n        cp = buffer[bufferLen] = Character.codePointAt(termBuffer, i, len);\n        startOffset[bufferLen] = start;\n        endOffset[bufferLen] = end;\n        bufferLen++;\n      }\n    } else {\n      // normal offsets\n      for (int i = 0, cp = 0, cpLen = 0; i < len; i += cpLen) {\n        cp = buffer[bufferLen] = Character.codePointAt(termBuffer, i, len);\n        cpLen = Character.charCount(cp);\n        startOffset[bufferLen] = start;\n        start = endOffset[bufferLen] = start + cpLen;\n        bufferLen++;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["680e7f726eaa1fd44ade8bc1f8a02f452ca7c4ee"],"680e7f726eaa1fd44ade8bc1f8a02f452ca7c4ee":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b89678825b68eccaf09e6ab71675fc0b0af1e099"]},"commit2Childs":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"680e7f726eaa1fd44ade8bc1f8a02f452ca7c4ee":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["680e7f726eaa1fd44ade8bc1f8a02f452ca7c4ee"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}