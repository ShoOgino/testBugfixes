{"path":"solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestSortedMapBackedCache#testCacheReopensWithUpdate().mjava","commits":[{"id":"3337b86edd36607f0208321f1deee79c55e5fd21","date":1321266471,"type":0,"author":"Noble Paul","isMerge":false,"pathNew":"solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestSortedMapBackedCache#testCacheReopensWithUpdate().mjava","pathOld":"/dev/null","sourceNew":"\t@Test\n\tpublic void testCacheReopensWithUpdate() {\n\t\tDIHCache cache = null;\n\t\ttry {\t\t\t\n\t\t\tMap<String, String> cacheProps = new HashMap<String, String>();\n\t\t\tcacheProps.put(DIHCacheSupport.CACHE_PRIMARY_KEY, \"a_id\");\n\t\t\t\n\t\t\tcache = new SortedMapBackedCache();\n\t\t\tcache.open(getContext(cacheProps));\n\t\t\t// We can let the data hit the cache with the fields out of order because\n\t\t\t// we've identified the pk up-front.\n\t\t\tloadData(cache, data, fieldNames, false);\n\n\t\t\t// Close the cache.\n\t\t\tcache.close();\n\n\t\t\tList<ControlData> newControlData = new ArrayList<ControlData>();\n\t\t\tObject[] newIdEqualsThree = null;\n\t\t\tint j = 0;\n\t\t\tfor (int i = 0; i < data.size(); i++) {\n\t\t\t\t// We'll be deleting a_id=1 so remove it from the control data.\n\t\t\t\tif (data.get(i).data[0].equals(new Integer(1))) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n\t\t\t\t// We'll be changing \"Cookie\" to \"Carrot\" in a_id=3 so change it in the control data.\n\t\t\t\tif (data.get(i).data[0].equals(new Integer(3))) {\n\t\t\t\t\tnewIdEqualsThree = new Object[data.get(i).data.length];\n\t\t\t\t\tSystem.arraycopy(data.get(i).data, 0, newIdEqualsThree, 0, newIdEqualsThree.length);\n\t\t\t\t\tnewIdEqualsThree[3] = \"Carrot\";\n\t\t\t\t\tnewControlData.add(new ControlData(newIdEqualsThree));\n\t\t\t\t}\n\t\t\t\t// Everything else can just be copied over.\n\t\t\t\telse {\n\t\t\t\t\tnewControlData.add(data.get(i));\n\t\t\t\t}\n\n\t\t\t\tj++;\n\t\t\t}\n\n\t\t\t// These new rows of data will get added to the cache, so add them to the control data too.\n\t\t\tObject[] newDataRow1 = new Object[] { new Integer(99), new BigDecimal(Math.PI), \"Z\", \"Zebra\", new Float(99.99), Feb21_2011, null };\n\t\t\tObject[] newDataRow2 = new Object[] { new Integer(2), new BigDecimal(Math.PI), \"B\", \"Ballerina\", new Float(2.22), Feb21_2011, null };\n\n\t\t\tnewControlData.add(new ControlData(newDataRow1));\n\t\t\tnewControlData.add(new ControlData(newDataRow2));\n\n\t\t\t// Re-open the cache\n\t\t\tcache.open(getContext(new HashMap<String,String>()));\n\n\t\t\t// Delete a_id=1 from the cache.\n\t\t\tcache.delete(new Integer(1));\n\n\t\t\t// Because the cache allows duplicates, the only way to update is to\n\t\t\t// delete first then add.\n\t\t\tcache.delete(new Integer(3));\n\t\t\tcache.add(controlDataToMap(new ControlData(newIdEqualsThree), fieldNames, false));\n\n\t\t\t// Add this row with a new Primary key.\n\t\t\tcache.add(controlDataToMap(new ControlData(newDataRow1), fieldNames, false));\n\n\t\t\t// Add this row, creating two records in the cache with a_id=2.\n\t\t\tcache.add(controlDataToMap(new ControlData(newDataRow2), fieldNames, false));\n\n\t\t\t// Read the cache back and compare to the newControlData\n\t\t\tList<ControlData> testData = extractDataInKeyOrder(cache, fieldNames);\n\t\t\tcompareData(newControlData, testData);\n\n\t\t\t// Now try reading the cache read-only.\n\t\t\tcache.close();\n\t\t\tcache.open(getContext(new HashMap<String,String>()));\n\t\t\ttestData = extractDataInKeyOrder(cache, fieldNames);\n\t\t\tcompareData(newControlData, testData);\n\n\t\t} catch (Exception e) {\n\t\t\tlog.warn(\"Exception thrown: \" + e.toString());\n\t\t\tAssert.fail();\n\t\t} finally {\n\t\t\ttry {\n\t\t\t\tcache.destroy();\n\t\t\t} catch (Exception ex) {\n\t\t\t}\n\t\t}\n\t}\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4093b270ba337f9c25a4c0e6cb2ae2c07f697376","date":1347897716,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestSortedMapBackedCache#testCacheReopensWithUpdate().mjava","pathOld":"solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestSortedMapBackedCache#testCacheReopensWithUpdate().mjava","sourceNew":"  @Test\n  public void testCacheReopensWithUpdate() {\n    DIHCache cache = null;\n    try {      \n      Map<String, String> cacheProps = new HashMap<String, String>();\n      cacheProps.put(DIHCacheSupport.CACHE_PRIMARY_KEY, \"a_id\");\n      \n      cache = new SortedMapBackedCache();\n      cache.open(getContext(cacheProps));\n      // We can let the data hit the cache with the fields out of order because\n      // we've identified the pk up-front.\n      loadData(cache, data, fieldNames, false);\n\n      // Close the cache.\n      cache.close();\n\n      List<ControlData> newControlData = new ArrayList<ControlData>();\n      Object[] newIdEqualsThree = null;\n      int j = 0;\n      for (int i = 0; i < data.size(); i++) {\n        // We'll be deleting a_id=1 so remove it from the control data.\n        if (data.get(i).data[0].equals(new Integer(1))) {\n          continue;\n        }\n\n        // We'll be changing \"Cookie\" to \"Carrot\" in a_id=3 so change it in the control data.\n        if (data.get(i).data[0].equals(new Integer(3))) {\n          newIdEqualsThree = new Object[data.get(i).data.length];\n          System.arraycopy(data.get(i).data, 0, newIdEqualsThree, 0, newIdEqualsThree.length);\n          newIdEqualsThree[3] = \"Carrot\";\n          newControlData.add(new ControlData(newIdEqualsThree));\n        }\n        // Everything else can just be copied over.\n        else {\n          newControlData.add(data.get(i));\n        }\n\n        j++;\n      }\n\n      // These new rows of data will get added to the cache, so add them to the control data too.\n      Object[] newDataRow1 = new Object[] { new Integer(99), new BigDecimal(Math.PI), \"Z\", \"Zebra\", new Float(99.99), Feb21_2011, null };\n      Object[] newDataRow2 = new Object[] { new Integer(2), new BigDecimal(Math.PI), \"B\", \"Ballerina\", new Float(2.22), Feb21_2011, null };\n\n      newControlData.add(new ControlData(newDataRow1));\n      newControlData.add(new ControlData(newDataRow2));\n\n      // Re-open the cache\n      cache.open(getContext(new HashMap<String,String>()));\n\n      // Delete a_id=1 from the cache.\n      cache.delete(new Integer(1));\n\n      // Because the cache allows duplicates, the only way to update is to\n      // delete first then add.\n      cache.delete(new Integer(3));\n      cache.add(controlDataToMap(new ControlData(newIdEqualsThree), fieldNames, false));\n\n      // Add this row with a new Primary key.\n      cache.add(controlDataToMap(new ControlData(newDataRow1), fieldNames, false));\n\n      // Add this row, creating two records in the cache with a_id=2.\n      cache.add(controlDataToMap(new ControlData(newDataRow2), fieldNames, false));\n\n      // Read the cache back and compare to the newControlData\n      List<ControlData> testData = extractDataInKeyOrder(cache, fieldNames);\n      compareData(newControlData, testData);\n\n      // Now try reading the cache read-only.\n      cache.close();\n      cache.open(getContext(new HashMap<String,String>()));\n      testData = extractDataInKeyOrder(cache, fieldNames);\n      compareData(newControlData, testData);\n\n    } catch (Exception e) {\n      log.warn(\"Exception thrown: \" + e.toString());\n      Assert.fail();\n    } finally {\n      try {\n        cache.destroy();\n      } catch (Exception ex) {\n      }\n    }\n  }\n\n","sourceOld":"\t@Test\n\tpublic void testCacheReopensWithUpdate() {\n\t\tDIHCache cache = null;\n\t\ttry {\t\t\t\n\t\t\tMap<String, String> cacheProps = new HashMap<String, String>();\n\t\t\tcacheProps.put(DIHCacheSupport.CACHE_PRIMARY_KEY, \"a_id\");\n\t\t\t\n\t\t\tcache = new SortedMapBackedCache();\n\t\t\tcache.open(getContext(cacheProps));\n\t\t\t// We can let the data hit the cache with the fields out of order because\n\t\t\t// we've identified the pk up-front.\n\t\t\tloadData(cache, data, fieldNames, false);\n\n\t\t\t// Close the cache.\n\t\t\tcache.close();\n\n\t\t\tList<ControlData> newControlData = new ArrayList<ControlData>();\n\t\t\tObject[] newIdEqualsThree = null;\n\t\t\tint j = 0;\n\t\t\tfor (int i = 0; i < data.size(); i++) {\n\t\t\t\t// We'll be deleting a_id=1 so remove it from the control data.\n\t\t\t\tif (data.get(i).data[0].equals(new Integer(1))) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n\t\t\t\t// We'll be changing \"Cookie\" to \"Carrot\" in a_id=3 so change it in the control data.\n\t\t\t\tif (data.get(i).data[0].equals(new Integer(3))) {\n\t\t\t\t\tnewIdEqualsThree = new Object[data.get(i).data.length];\n\t\t\t\t\tSystem.arraycopy(data.get(i).data, 0, newIdEqualsThree, 0, newIdEqualsThree.length);\n\t\t\t\t\tnewIdEqualsThree[3] = \"Carrot\";\n\t\t\t\t\tnewControlData.add(new ControlData(newIdEqualsThree));\n\t\t\t\t}\n\t\t\t\t// Everything else can just be copied over.\n\t\t\t\telse {\n\t\t\t\t\tnewControlData.add(data.get(i));\n\t\t\t\t}\n\n\t\t\t\tj++;\n\t\t\t}\n\n\t\t\t// These new rows of data will get added to the cache, so add them to the control data too.\n\t\t\tObject[] newDataRow1 = new Object[] { new Integer(99), new BigDecimal(Math.PI), \"Z\", \"Zebra\", new Float(99.99), Feb21_2011, null };\n\t\t\tObject[] newDataRow2 = new Object[] { new Integer(2), new BigDecimal(Math.PI), \"B\", \"Ballerina\", new Float(2.22), Feb21_2011, null };\n\n\t\t\tnewControlData.add(new ControlData(newDataRow1));\n\t\t\tnewControlData.add(new ControlData(newDataRow2));\n\n\t\t\t// Re-open the cache\n\t\t\tcache.open(getContext(new HashMap<String,String>()));\n\n\t\t\t// Delete a_id=1 from the cache.\n\t\t\tcache.delete(new Integer(1));\n\n\t\t\t// Because the cache allows duplicates, the only way to update is to\n\t\t\t// delete first then add.\n\t\t\tcache.delete(new Integer(3));\n\t\t\tcache.add(controlDataToMap(new ControlData(newIdEqualsThree), fieldNames, false));\n\n\t\t\t// Add this row with a new Primary key.\n\t\t\tcache.add(controlDataToMap(new ControlData(newDataRow1), fieldNames, false));\n\n\t\t\t// Add this row, creating two records in the cache with a_id=2.\n\t\t\tcache.add(controlDataToMap(new ControlData(newDataRow2), fieldNames, false));\n\n\t\t\t// Read the cache back and compare to the newControlData\n\t\t\tList<ControlData> testData = extractDataInKeyOrder(cache, fieldNames);\n\t\t\tcompareData(newControlData, testData);\n\n\t\t\t// Now try reading the cache read-only.\n\t\t\tcache.close();\n\t\t\tcache.open(getContext(new HashMap<String,String>()));\n\t\t\ttestData = extractDataInKeyOrder(cache, fieldNames);\n\t\t\tcompareData(newControlData, testData);\n\n\t\t} catch (Exception e) {\n\t\t\tlog.warn(\"Exception thrown: \" + e.toString());\n\t\t\tAssert.fail();\n\t\t} finally {\n\t\t\ttry {\n\t\t\t\tcache.destroy();\n\t\t\t} catch (Exception ex) {\n\t\t\t}\n\t\t}\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestSortedMapBackedCache#testCacheReopensWithUpdate().mjava","pathOld":"solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestSortedMapBackedCache#testCacheReopensWithUpdate().mjava","sourceNew":"  @Test\n  public void testCacheReopensWithUpdate() {\n    DIHCache cache = null;\n    try {      \n      Map<String, String> cacheProps = new HashMap<>();\n      cacheProps.put(DIHCacheSupport.CACHE_PRIMARY_KEY, \"a_id\");\n      \n      cache = new SortedMapBackedCache();\n      cache.open(getContext(cacheProps));\n      // We can let the data hit the cache with the fields out of order because\n      // we've identified the pk up-front.\n      loadData(cache, data, fieldNames, false);\n\n      // Close the cache.\n      cache.close();\n\n      List<ControlData> newControlData = new ArrayList<>();\n      Object[] newIdEqualsThree = null;\n      int j = 0;\n      for (int i = 0; i < data.size(); i++) {\n        // We'll be deleting a_id=1 so remove it from the control data.\n        if (data.get(i).data[0].equals(new Integer(1))) {\n          continue;\n        }\n\n        // We'll be changing \"Cookie\" to \"Carrot\" in a_id=3 so change it in the control data.\n        if (data.get(i).data[0].equals(new Integer(3))) {\n          newIdEqualsThree = new Object[data.get(i).data.length];\n          System.arraycopy(data.get(i).data, 0, newIdEqualsThree, 0, newIdEqualsThree.length);\n          newIdEqualsThree[3] = \"Carrot\";\n          newControlData.add(new ControlData(newIdEqualsThree));\n        }\n        // Everything else can just be copied over.\n        else {\n          newControlData.add(data.get(i));\n        }\n\n        j++;\n      }\n\n      // These new rows of data will get added to the cache, so add them to the control data too.\n      Object[] newDataRow1 = new Object[] { new Integer(99), new BigDecimal(Math.PI), \"Z\", \"Zebra\", new Float(99.99), Feb21_2011, null };\n      Object[] newDataRow2 = new Object[] { new Integer(2), new BigDecimal(Math.PI), \"B\", \"Ballerina\", new Float(2.22), Feb21_2011, null };\n\n      newControlData.add(new ControlData(newDataRow1));\n      newControlData.add(new ControlData(newDataRow2));\n\n      // Re-open the cache\n      cache.open(getContext(new HashMap<String,String>()));\n\n      // Delete a_id=1 from the cache.\n      cache.delete(new Integer(1));\n\n      // Because the cache allows duplicates, the only way to update is to\n      // delete first then add.\n      cache.delete(new Integer(3));\n      cache.add(controlDataToMap(new ControlData(newIdEqualsThree), fieldNames, false));\n\n      // Add this row with a new Primary key.\n      cache.add(controlDataToMap(new ControlData(newDataRow1), fieldNames, false));\n\n      // Add this row, creating two records in the cache with a_id=2.\n      cache.add(controlDataToMap(new ControlData(newDataRow2), fieldNames, false));\n\n      // Read the cache back and compare to the newControlData\n      List<ControlData> testData = extractDataInKeyOrder(cache, fieldNames);\n      compareData(newControlData, testData);\n\n      // Now try reading the cache read-only.\n      cache.close();\n      cache.open(getContext(new HashMap<String,String>()));\n      testData = extractDataInKeyOrder(cache, fieldNames);\n      compareData(newControlData, testData);\n\n    } catch (Exception e) {\n      log.warn(\"Exception thrown: \" + e.toString());\n      Assert.fail();\n    } finally {\n      try {\n        cache.destroy();\n      } catch (Exception ex) {\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testCacheReopensWithUpdate() {\n    DIHCache cache = null;\n    try {      \n      Map<String, String> cacheProps = new HashMap<String, String>();\n      cacheProps.put(DIHCacheSupport.CACHE_PRIMARY_KEY, \"a_id\");\n      \n      cache = new SortedMapBackedCache();\n      cache.open(getContext(cacheProps));\n      // We can let the data hit the cache with the fields out of order because\n      // we've identified the pk up-front.\n      loadData(cache, data, fieldNames, false);\n\n      // Close the cache.\n      cache.close();\n\n      List<ControlData> newControlData = new ArrayList<ControlData>();\n      Object[] newIdEqualsThree = null;\n      int j = 0;\n      for (int i = 0; i < data.size(); i++) {\n        // We'll be deleting a_id=1 so remove it from the control data.\n        if (data.get(i).data[0].equals(new Integer(1))) {\n          continue;\n        }\n\n        // We'll be changing \"Cookie\" to \"Carrot\" in a_id=3 so change it in the control data.\n        if (data.get(i).data[0].equals(new Integer(3))) {\n          newIdEqualsThree = new Object[data.get(i).data.length];\n          System.arraycopy(data.get(i).data, 0, newIdEqualsThree, 0, newIdEqualsThree.length);\n          newIdEqualsThree[3] = \"Carrot\";\n          newControlData.add(new ControlData(newIdEqualsThree));\n        }\n        // Everything else can just be copied over.\n        else {\n          newControlData.add(data.get(i));\n        }\n\n        j++;\n      }\n\n      // These new rows of data will get added to the cache, so add them to the control data too.\n      Object[] newDataRow1 = new Object[] { new Integer(99), new BigDecimal(Math.PI), \"Z\", \"Zebra\", new Float(99.99), Feb21_2011, null };\n      Object[] newDataRow2 = new Object[] { new Integer(2), new BigDecimal(Math.PI), \"B\", \"Ballerina\", new Float(2.22), Feb21_2011, null };\n\n      newControlData.add(new ControlData(newDataRow1));\n      newControlData.add(new ControlData(newDataRow2));\n\n      // Re-open the cache\n      cache.open(getContext(new HashMap<String,String>()));\n\n      // Delete a_id=1 from the cache.\n      cache.delete(new Integer(1));\n\n      // Because the cache allows duplicates, the only way to update is to\n      // delete first then add.\n      cache.delete(new Integer(3));\n      cache.add(controlDataToMap(new ControlData(newIdEqualsThree), fieldNames, false));\n\n      // Add this row with a new Primary key.\n      cache.add(controlDataToMap(new ControlData(newDataRow1), fieldNames, false));\n\n      // Add this row, creating two records in the cache with a_id=2.\n      cache.add(controlDataToMap(new ControlData(newDataRow2), fieldNames, false));\n\n      // Read the cache back and compare to the newControlData\n      List<ControlData> testData = extractDataInKeyOrder(cache, fieldNames);\n      compareData(newControlData, testData);\n\n      // Now try reading the cache read-only.\n      cache.close();\n      cache.open(getContext(new HashMap<String,String>()));\n      testData = extractDataInKeyOrder(cache, fieldNames);\n      compareData(newControlData, testData);\n\n    } catch (Exception e) {\n      log.warn(\"Exception thrown: \" + e.toString());\n      Assert.fail();\n    } finally {\n      try {\n        cache.destroy();\n      } catch (Exception ex) {\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b6a269c1ddba3f8c9fa9a40572ecc538eddda41a","date":1528054850,"type":3,"author":"Michael Braun","isMerge":false,"pathNew":"solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestSortedMapBackedCache#testCacheReopensWithUpdate().mjava","pathOld":"solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestSortedMapBackedCache#testCacheReopensWithUpdate().mjava","sourceNew":"  @Test\n  public void testCacheReopensWithUpdate() {\n    DIHCache cache = null;\n    try {      \n      Map<String, String> cacheProps = new HashMap<>();\n      cacheProps.put(DIHCacheSupport.CACHE_PRIMARY_KEY, \"a_id\");\n      \n      cache = new SortedMapBackedCache();\n      cache.open(getContext(cacheProps));\n      // We can let the data hit the cache with the fields out of order because\n      // we've identified the pk up-front.\n      loadData(cache, data, fieldNames, false);\n\n      // Close the cache.\n      cache.close();\n\n      List<ControlData> newControlData = new ArrayList<>();\n      Object[] newIdEqualsThree = null;\n      int j = 0;\n      for (int i = 0; i < data.size(); i++) {\n        // We'll be deleting a_id=1 so remove it from the control data.\n        if (data.get(i).data[0].equals(1)) {\n          continue;\n        }\n\n        // We'll be changing \"Cookie\" to \"Carrot\" in a_id=3 so change it in the control data.\n        if (data.get(i).data[0].equals(3)) {\n          newIdEqualsThree = new Object[data.get(i).data.length];\n          System.arraycopy(data.get(i).data, 0, newIdEqualsThree, 0, newIdEqualsThree.length);\n          newIdEqualsThree[3] = \"Carrot\";\n          newControlData.add(new ControlData(newIdEqualsThree));\n        }\n        // Everything else can just be copied over.\n        else {\n          newControlData.add(data.get(i));\n        }\n\n        j++;\n      }\n\n      // These new rows of data will get added to the cache, so add them to the control data too.\n      Object[] newDataRow1 = new Object[] {99, new BigDecimal(Math.PI), \"Z\", \"Zebra\", 99.99f, Feb21_2011, null };\n      Object[] newDataRow2 = new Object[] {2, new BigDecimal(Math.PI), \"B\", \"Ballerina\", 2.22f, Feb21_2011, null };\n\n      newControlData.add(new ControlData(newDataRow1));\n      newControlData.add(new ControlData(newDataRow2));\n\n      // Re-open the cache\n      cache.open(getContext(new HashMap<String,String>()));\n\n      // Delete a_id=1 from the cache.\n      cache.delete(1);\n\n      // Because the cache allows duplicates, the only way to update is to\n      // delete first then add.\n      cache.delete(3);\n      cache.add(controlDataToMap(new ControlData(newIdEqualsThree), fieldNames, false));\n\n      // Add this row with a new Primary key.\n      cache.add(controlDataToMap(new ControlData(newDataRow1), fieldNames, false));\n\n      // Add this row, creating two records in the cache with a_id=2.\n      cache.add(controlDataToMap(new ControlData(newDataRow2), fieldNames, false));\n\n      // Read the cache back and compare to the newControlData\n      List<ControlData> testData = extractDataInKeyOrder(cache, fieldNames);\n      compareData(newControlData, testData);\n\n      // Now try reading the cache read-only.\n      cache.close();\n      cache.open(getContext(new HashMap<String,String>()));\n      testData = extractDataInKeyOrder(cache, fieldNames);\n      compareData(newControlData, testData);\n\n    } catch (Exception e) {\n      log.warn(\"Exception thrown: \" + e.toString());\n      Assert.fail();\n    } finally {\n      try {\n        cache.destroy();\n      } catch (Exception ex) {\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testCacheReopensWithUpdate() {\n    DIHCache cache = null;\n    try {      \n      Map<String, String> cacheProps = new HashMap<>();\n      cacheProps.put(DIHCacheSupport.CACHE_PRIMARY_KEY, \"a_id\");\n      \n      cache = new SortedMapBackedCache();\n      cache.open(getContext(cacheProps));\n      // We can let the data hit the cache with the fields out of order because\n      // we've identified the pk up-front.\n      loadData(cache, data, fieldNames, false);\n\n      // Close the cache.\n      cache.close();\n\n      List<ControlData> newControlData = new ArrayList<>();\n      Object[] newIdEqualsThree = null;\n      int j = 0;\n      for (int i = 0; i < data.size(); i++) {\n        // We'll be deleting a_id=1 so remove it from the control data.\n        if (data.get(i).data[0].equals(new Integer(1))) {\n          continue;\n        }\n\n        // We'll be changing \"Cookie\" to \"Carrot\" in a_id=3 so change it in the control data.\n        if (data.get(i).data[0].equals(new Integer(3))) {\n          newIdEqualsThree = new Object[data.get(i).data.length];\n          System.arraycopy(data.get(i).data, 0, newIdEqualsThree, 0, newIdEqualsThree.length);\n          newIdEqualsThree[3] = \"Carrot\";\n          newControlData.add(new ControlData(newIdEqualsThree));\n        }\n        // Everything else can just be copied over.\n        else {\n          newControlData.add(data.get(i));\n        }\n\n        j++;\n      }\n\n      // These new rows of data will get added to the cache, so add them to the control data too.\n      Object[] newDataRow1 = new Object[] { new Integer(99), new BigDecimal(Math.PI), \"Z\", \"Zebra\", new Float(99.99), Feb21_2011, null };\n      Object[] newDataRow2 = new Object[] { new Integer(2), new BigDecimal(Math.PI), \"B\", \"Ballerina\", new Float(2.22), Feb21_2011, null };\n\n      newControlData.add(new ControlData(newDataRow1));\n      newControlData.add(new ControlData(newDataRow2));\n\n      // Re-open the cache\n      cache.open(getContext(new HashMap<String,String>()));\n\n      // Delete a_id=1 from the cache.\n      cache.delete(new Integer(1));\n\n      // Because the cache allows duplicates, the only way to update is to\n      // delete first then add.\n      cache.delete(new Integer(3));\n      cache.add(controlDataToMap(new ControlData(newIdEqualsThree), fieldNames, false));\n\n      // Add this row with a new Primary key.\n      cache.add(controlDataToMap(new ControlData(newDataRow1), fieldNames, false));\n\n      // Add this row, creating two records in the cache with a_id=2.\n      cache.add(controlDataToMap(new ControlData(newDataRow2), fieldNames, false));\n\n      // Read the cache back and compare to the newControlData\n      List<ControlData> testData = extractDataInKeyOrder(cache, fieldNames);\n      compareData(newControlData, testData);\n\n      // Now try reading the cache read-only.\n      cache.close();\n      cache.open(getContext(new HashMap<String,String>()));\n      testData = extractDataInKeyOrder(cache, fieldNames);\n      compareData(newControlData, testData);\n\n    } catch (Exception e) {\n      log.warn(\"Exception thrown: \" + e.toString());\n      Assert.fail();\n    } finally {\n      try {\n        cache.destroy();\n      } catch (Exception ex) {\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"628903f37b6c442da0d390db1c6af9a0e74d41a7","date":1531736685,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestSortedMapBackedCache#testCacheReopensWithUpdate().mjava","pathOld":"solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestSortedMapBackedCache#testCacheReopensWithUpdate().mjava","sourceNew":"  @Test\n  public void testCacheReopensWithUpdate() {\n    DIHCache cache = null;\n    try {      \n      Map<String, String> cacheProps = new HashMap<>();\n      cacheProps.put(DIHCacheSupport.CACHE_PRIMARY_KEY, \"a_id\");\n      \n      cache = new SortedMapBackedCache();\n      cache.open(getContext(cacheProps));\n      // We can let the data hit the cache with the fields out of order because\n      // we've identified the pk up-front.\n      loadData(cache, data, fieldNames, false);\n\n      // Close the cache.\n      cache.close();\n\n      List<ControlData> newControlData = new ArrayList<>();\n      Object[] newIdEqualsThree = null;\n      int j = 0;\n      for (int i = 0; i < data.size(); i++) {\n        // We'll be deleting a_id=1 so remove it from the control data.\n        if (data.get(i).data[0].equals(1)) {\n          continue;\n        }\n\n        // We'll be changing \"Cookie\" to \"Carrot\" in a_id=3 so change it in the control data.\n        if (data.get(i).data[0].equals(3)) {\n          newIdEqualsThree = new Object[data.get(i).data.length];\n          System.arraycopy(data.get(i).data, 0, newIdEqualsThree, 0, newIdEqualsThree.length);\n          newIdEqualsThree[3] = \"Carrot\";\n          newControlData.add(new ControlData(newIdEqualsThree));\n        }\n        // Everything else can just be copied over.\n        else {\n          newControlData.add(data.get(i));\n        }\n\n        j++;\n      }\n\n      // These new rows of data will get added to the cache, so add them to the control data too.\n      Object[] newDataRow1 = new Object[] {99, new BigDecimal(Math.PI), \"Z\", \"Zebra\", 99.99f, Feb21_2011, null };\n      Object[] newDataRow2 = new Object[] {2, new BigDecimal(Math.PI), \"B\", \"Ballerina\", 2.22f, Feb21_2011, null };\n\n      newControlData.add(new ControlData(newDataRow1));\n      newControlData.add(new ControlData(newDataRow2));\n\n      // Re-open the cache\n      cache.open(getContext(new HashMap<String,String>()));\n\n      // Delete a_id=1 from the cache.\n      cache.delete(1);\n\n      // Because the cache allows duplicates, the only way to update is to\n      // delete first then add.\n      cache.delete(3);\n      cache.add(controlDataToMap(new ControlData(newIdEqualsThree), fieldNames, false));\n\n      // Add this row with a new Primary key.\n      cache.add(controlDataToMap(new ControlData(newDataRow1), fieldNames, false));\n\n      // Add this row, creating two records in the cache with a_id=2.\n      cache.add(controlDataToMap(new ControlData(newDataRow2), fieldNames, false));\n\n      // Read the cache back and compare to the newControlData\n      List<ControlData> testData = extractDataInKeyOrder(cache, fieldNames);\n      compareData(newControlData, testData);\n\n      // Now try reading the cache read-only.\n      cache.close();\n      cache.open(getContext(new HashMap<String,String>()));\n      testData = extractDataInKeyOrder(cache, fieldNames);\n      compareData(newControlData, testData);\n\n    } catch (Exception e) {\n      log.warn(\"Exception thrown: \" + e.toString());\n      Assert.fail();\n    } finally {\n      try {\n        cache.destroy();\n      } catch (Exception ex) {\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testCacheReopensWithUpdate() {\n    DIHCache cache = null;\n    try {      \n      Map<String, String> cacheProps = new HashMap<>();\n      cacheProps.put(DIHCacheSupport.CACHE_PRIMARY_KEY, \"a_id\");\n      \n      cache = new SortedMapBackedCache();\n      cache.open(getContext(cacheProps));\n      // We can let the data hit the cache with the fields out of order because\n      // we've identified the pk up-front.\n      loadData(cache, data, fieldNames, false);\n\n      // Close the cache.\n      cache.close();\n\n      List<ControlData> newControlData = new ArrayList<>();\n      Object[] newIdEqualsThree = null;\n      int j = 0;\n      for (int i = 0; i < data.size(); i++) {\n        // We'll be deleting a_id=1 so remove it from the control data.\n        if (data.get(i).data[0].equals(new Integer(1))) {\n          continue;\n        }\n\n        // We'll be changing \"Cookie\" to \"Carrot\" in a_id=3 so change it in the control data.\n        if (data.get(i).data[0].equals(new Integer(3))) {\n          newIdEqualsThree = new Object[data.get(i).data.length];\n          System.arraycopy(data.get(i).data, 0, newIdEqualsThree, 0, newIdEqualsThree.length);\n          newIdEqualsThree[3] = \"Carrot\";\n          newControlData.add(new ControlData(newIdEqualsThree));\n        }\n        // Everything else can just be copied over.\n        else {\n          newControlData.add(data.get(i));\n        }\n\n        j++;\n      }\n\n      // These new rows of data will get added to the cache, so add them to the control data too.\n      Object[] newDataRow1 = new Object[] { new Integer(99), new BigDecimal(Math.PI), \"Z\", \"Zebra\", new Float(99.99), Feb21_2011, null };\n      Object[] newDataRow2 = new Object[] { new Integer(2), new BigDecimal(Math.PI), \"B\", \"Ballerina\", new Float(2.22), Feb21_2011, null };\n\n      newControlData.add(new ControlData(newDataRow1));\n      newControlData.add(new ControlData(newDataRow2));\n\n      // Re-open the cache\n      cache.open(getContext(new HashMap<String,String>()));\n\n      // Delete a_id=1 from the cache.\n      cache.delete(new Integer(1));\n\n      // Because the cache allows duplicates, the only way to update is to\n      // delete first then add.\n      cache.delete(new Integer(3));\n      cache.add(controlDataToMap(new ControlData(newIdEqualsThree), fieldNames, false));\n\n      // Add this row with a new Primary key.\n      cache.add(controlDataToMap(new ControlData(newDataRow1), fieldNames, false));\n\n      // Add this row, creating two records in the cache with a_id=2.\n      cache.add(controlDataToMap(new ControlData(newDataRow2), fieldNames, false));\n\n      // Read the cache back and compare to the newControlData\n      List<ControlData> testData = extractDataInKeyOrder(cache, fieldNames);\n      compareData(newControlData, testData);\n\n      // Now try reading the cache read-only.\n      cache.close();\n      cache.open(getContext(new HashMap<String,String>()));\n      testData = extractDataInKeyOrder(cache, fieldNames);\n      compareData(newControlData, testData);\n\n    } catch (Exception e) {\n      log.warn(\"Exception thrown: \" + e.toString());\n      Assert.fail();\n    } finally {\n      try {\n        cache.destroy();\n      } catch (Exception ex) {\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","date":1531905561,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestSortedMapBackedCache#testCacheReopensWithUpdate().mjava","pathOld":"solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestSortedMapBackedCache#testCacheReopensWithUpdate().mjava","sourceNew":"  @Test\n  public void testCacheReopensWithUpdate() {\n    DIHCache cache = null;\n    try {      \n      Map<String, String> cacheProps = new HashMap<>();\n      cacheProps.put(DIHCacheSupport.CACHE_PRIMARY_KEY, \"a_id\");\n      \n      cache = new SortedMapBackedCache();\n      cache.open(getContext(cacheProps));\n      // We can let the data hit the cache with the fields out of order because\n      // we've identified the pk up-front.\n      loadData(cache, data, fieldNames, false);\n\n      // Close the cache.\n      cache.close();\n\n      List<ControlData> newControlData = new ArrayList<>();\n      Object[] newIdEqualsThree = null;\n      int j = 0;\n      for (int i = 0; i < data.size(); i++) {\n        // We'll be deleting a_id=1 so remove it from the control data.\n        if (data.get(i).data[0].equals(1)) {\n          continue;\n        }\n\n        // We'll be changing \"Cookie\" to \"Carrot\" in a_id=3 so change it in the control data.\n        if (data.get(i).data[0].equals(3)) {\n          newIdEqualsThree = new Object[data.get(i).data.length];\n          System.arraycopy(data.get(i).data, 0, newIdEqualsThree, 0, newIdEqualsThree.length);\n          newIdEqualsThree[3] = \"Carrot\";\n          newControlData.add(new ControlData(newIdEqualsThree));\n        }\n        // Everything else can just be copied over.\n        else {\n          newControlData.add(data.get(i));\n        }\n\n        j++;\n      }\n\n      // These new rows of data will get added to the cache, so add them to the control data too.\n      Object[] newDataRow1 = new Object[] {99, new BigDecimal(Math.PI), \"Z\", \"Zebra\", 99.99f, Feb21_2011, null };\n      Object[] newDataRow2 = new Object[] {2, new BigDecimal(Math.PI), \"B\", \"Ballerina\", 2.22f, Feb21_2011, null };\n\n      newControlData.add(new ControlData(newDataRow1));\n      newControlData.add(new ControlData(newDataRow2));\n\n      // Re-open the cache\n      cache.open(getContext(new HashMap<String,String>()));\n\n      // Delete a_id=1 from the cache.\n      cache.delete(1);\n\n      // Because the cache allows duplicates, the only way to update is to\n      // delete first then add.\n      cache.delete(3);\n      cache.add(controlDataToMap(new ControlData(newIdEqualsThree), fieldNames, false));\n\n      // Add this row with a new Primary key.\n      cache.add(controlDataToMap(new ControlData(newDataRow1), fieldNames, false));\n\n      // Add this row, creating two records in the cache with a_id=2.\n      cache.add(controlDataToMap(new ControlData(newDataRow2), fieldNames, false));\n\n      // Read the cache back and compare to the newControlData\n      List<ControlData> testData = extractDataInKeyOrder(cache, fieldNames);\n      compareData(newControlData, testData);\n\n      // Now try reading the cache read-only.\n      cache.close();\n      cache.open(getContext(new HashMap<String,String>()));\n      testData = extractDataInKeyOrder(cache, fieldNames);\n      compareData(newControlData, testData);\n\n    } catch (Exception e) {\n      log.warn(\"Exception thrown: \" + e.toString());\n      Assert.fail();\n    } finally {\n      try {\n        cache.destroy();\n      } catch (Exception ex) {\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testCacheReopensWithUpdate() {\n    DIHCache cache = null;\n    try {      \n      Map<String, String> cacheProps = new HashMap<>();\n      cacheProps.put(DIHCacheSupport.CACHE_PRIMARY_KEY, \"a_id\");\n      \n      cache = new SortedMapBackedCache();\n      cache.open(getContext(cacheProps));\n      // We can let the data hit the cache with the fields out of order because\n      // we've identified the pk up-front.\n      loadData(cache, data, fieldNames, false);\n\n      // Close the cache.\n      cache.close();\n\n      List<ControlData> newControlData = new ArrayList<>();\n      Object[] newIdEqualsThree = null;\n      int j = 0;\n      for (int i = 0; i < data.size(); i++) {\n        // We'll be deleting a_id=1 so remove it from the control data.\n        if (data.get(i).data[0].equals(new Integer(1))) {\n          continue;\n        }\n\n        // We'll be changing \"Cookie\" to \"Carrot\" in a_id=3 so change it in the control data.\n        if (data.get(i).data[0].equals(new Integer(3))) {\n          newIdEqualsThree = new Object[data.get(i).data.length];\n          System.arraycopy(data.get(i).data, 0, newIdEqualsThree, 0, newIdEqualsThree.length);\n          newIdEqualsThree[3] = \"Carrot\";\n          newControlData.add(new ControlData(newIdEqualsThree));\n        }\n        // Everything else can just be copied over.\n        else {\n          newControlData.add(data.get(i));\n        }\n\n        j++;\n      }\n\n      // These new rows of data will get added to the cache, so add them to the control data too.\n      Object[] newDataRow1 = new Object[] { new Integer(99), new BigDecimal(Math.PI), \"Z\", \"Zebra\", new Float(99.99), Feb21_2011, null };\n      Object[] newDataRow2 = new Object[] { new Integer(2), new BigDecimal(Math.PI), \"B\", \"Ballerina\", new Float(2.22), Feb21_2011, null };\n\n      newControlData.add(new ControlData(newDataRow1));\n      newControlData.add(new ControlData(newDataRow2));\n\n      // Re-open the cache\n      cache.open(getContext(new HashMap<String,String>()));\n\n      // Delete a_id=1 from the cache.\n      cache.delete(new Integer(1));\n\n      // Because the cache allows duplicates, the only way to update is to\n      // delete first then add.\n      cache.delete(new Integer(3));\n      cache.add(controlDataToMap(new ControlData(newIdEqualsThree), fieldNames, false));\n\n      // Add this row with a new Primary key.\n      cache.add(controlDataToMap(new ControlData(newDataRow1), fieldNames, false));\n\n      // Add this row, creating two records in the cache with a_id=2.\n      cache.add(controlDataToMap(new ControlData(newDataRow2), fieldNames, false));\n\n      // Read the cache back and compare to the newControlData\n      List<ControlData> testData = extractDataInKeyOrder(cache, fieldNames);\n      compareData(newControlData, testData);\n\n      // Now try reading the cache read-only.\n      cache.close();\n      cache.open(getContext(new HashMap<String,String>()));\n      testData = extractDataInKeyOrder(cache, fieldNames);\n      compareData(newControlData, testData);\n\n    } catch (Exception e) {\n      log.warn(\"Exception thrown: \" + e.toString());\n      Assert.fail();\n    } finally {\n      try {\n        cache.destroy();\n      } catch (Exception ex) {\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a5df378a6155dcc1f4d4ecdcbd8ea5bc058560e9","date":1574619880,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestSortedMapBackedCache#testCacheReopensWithUpdate().mjava","pathOld":"solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestSortedMapBackedCache#testCacheReopensWithUpdate().mjava","sourceNew":"  @SuppressWarnings(\"unused\")\n  @Test\n  public void testCacheReopensWithUpdate() {\n    DIHCache cache = null;\n    try {      \n      Map<String, String> cacheProps = new HashMap<>();\n      cacheProps.put(DIHCacheSupport.CACHE_PRIMARY_KEY, \"a_id\");\n      \n      cache = new SortedMapBackedCache();\n      cache.open(getContext(cacheProps));\n      // We can let the data hit the cache with the fields out of order because\n      // we've identified the pk up-front.\n      loadData(cache, data, fieldNames, false);\n\n      // Close the cache.\n      cache.close();\n\n      List<ControlData> newControlData = new ArrayList<>();\n      Object[] newIdEqualsThree = null;\n      int j = 0;\n      for (int i = 0; i < data.size(); i++) {\n        // We'll be deleting a_id=1 so remove it from the control data.\n        if (data.get(i).data[0].equals(1)) {\n          continue;\n        }\n\n        // We'll be changing \"Cookie\" to \"Carrot\" in a_id=3 so change it in the control data.\n        if (data.get(i).data[0].equals(3)) {\n          newIdEqualsThree = new Object[data.get(i).data.length];\n          System.arraycopy(data.get(i).data, 0, newIdEqualsThree, 0, newIdEqualsThree.length);\n          newIdEqualsThree[3] = \"Carrot\";\n          newControlData.add(new ControlData(newIdEqualsThree));\n        }\n        // Everything else can just be copied over.\n        else {\n          newControlData.add(data.get(i));\n        }\n\n        j++;\n      }\n\n      // These new rows of data will get added to the cache, so add them to the control data too.\n      Object[] newDataRow1 = new Object[] {99, new BigDecimal(Math.PI), \"Z\", \"Zebra\", 99.99f, Feb21_2011, null };\n      Object[] newDataRow2 = new Object[] {2, new BigDecimal(Math.PI), \"B\", \"Ballerina\", 2.22f, Feb21_2011, null };\n\n      newControlData.add(new ControlData(newDataRow1));\n      newControlData.add(new ControlData(newDataRow2));\n\n      // Re-open the cache\n      cache.open(getContext(new HashMap<String,String>()));\n\n      // Delete a_id=1 from the cache.\n      cache.delete(1);\n\n      // Because the cache allows duplicates, the only way to update is to\n      // delete first then add.\n      cache.delete(3);\n      cache.add(controlDataToMap(new ControlData(newIdEqualsThree), fieldNames, false));\n\n      // Add this row with a new Primary key.\n      cache.add(controlDataToMap(new ControlData(newDataRow1), fieldNames, false));\n\n      // Add this row, creating two records in the cache with a_id=2.\n      cache.add(controlDataToMap(new ControlData(newDataRow2), fieldNames, false));\n\n      // Read the cache back and compare to the newControlData\n      List<ControlData> testData = extractDataInKeyOrder(cache, fieldNames);\n      compareData(newControlData, testData);\n\n      // Now try reading the cache read-only.\n      cache.close();\n      cache.open(getContext(new HashMap<String,String>()));\n      testData = extractDataInKeyOrder(cache, fieldNames);\n      compareData(newControlData, testData);\n\n    } catch (Exception e) {\n      log.warn(\"Exception thrown: \" + e.toString());\n      Assert.fail();\n    } finally {\n      try {\n        cache.destroy();\n      } catch (Exception ex) {\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testCacheReopensWithUpdate() {\n    DIHCache cache = null;\n    try {      \n      Map<String, String> cacheProps = new HashMap<>();\n      cacheProps.put(DIHCacheSupport.CACHE_PRIMARY_KEY, \"a_id\");\n      \n      cache = new SortedMapBackedCache();\n      cache.open(getContext(cacheProps));\n      // We can let the data hit the cache with the fields out of order because\n      // we've identified the pk up-front.\n      loadData(cache, data, fieldNames, false);\n\n      // Close the cache.\n      cache.close();\n\n      List<ControlData> newControlData = new ArrayList<>();\n      Object[] newIdEqualsThree = null;\n      int j = 0;\n      for (int i = 0; i < data.size(); i++) {\n        // We'll be deleting a_id=1 so remove it from the control data.\n        if (data.get(i).data[0].equals(1)) {\n          continue;\n        }\n\n        // We'll be changing \"Cookie\" to \"Carrot\" in a_id=3 so change it in the control data.\n        if (data.get(i).data[0].equals(3)) {\n          newIdEqualsThree = new Object[data.get(i).data.length];\n          System.arraycopy(data.get(i).data, 0, newIdEqualsThree, 0, newIdEqualsThree.length);\n          newIdEqualsThree[3] = \"Carrot\";\n          newControlData.add(new ControlData(newIdEqualsThree));\n        }\n        // Everything else can just be copied over.\n        else {\n          newControlData.add(data.get(i));\n        }\n\n        j++;\n      }\n\n      // These new rows of data will get added to the cache, so add them to the control data too.\n      Object[] newDataRow1 = new Object[] {99, new BigDecimal(Math.PI), \"Z\", \"Zebra\", 99.99f, Feb21_2011, null };\n      Object[] newDataRow2 = new Object[] {2, new BigDecimal(Math.PI), \"B\", \"Ballerina\", 2.22f, Feb21_2011, null };\n\n      newControlData.add(new ControlData(newDataRow1));\n      newControlData.add(new ControlData(newDataRow2));\n\n      // Re-open the cache\n      cache.open(getContext(new HashMap<String,String>()));\n\n      // Delete a_id=1 from the cache.\n      cache.delete(1);\n\n      // Because the cache allows duplicates, the only way to update is to\n      // delete first then add.\n      cache.delete(3);\n      cache.add(controlDataToMap(new ControlData(newIdEqualsThree), fieldNames, false));\n\n      // Add this row with a new Primary key.\n      cache.add(controlDataToMap(new ControlData(newDataRow1), fieldNames, false));\n\n      // Add this row, creating two records in the cache with a_id=2.\n      cache.add(controlDataToMap(new ControlData(newDataRow2), fieldNames, false));\n\n      // Read the cache back and compare to the newControlData\n      List<ControlData> testData = extractDataInKeyOrder(cache, fieldNames);\n      compareData(newControlData, testData);\n\n      // Now try reading the cache read-only.\n      cache.close();\n      cache.open(getContext(new HashMap<String,String>()));\n      testData = extractDataInKeyOrder(cache, fieldNames);\n      compareData(newControlData, testData);\n\n    } catch (Exception e) {\n      log.warn(\"Exception thrown: \" + e.toString());\n      Assert.fail();\n    } finally {\n      try {\n        cache.destroy();\n      } catch (Exception ex) {\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bb9c3baacabd473e8ecd6c4948aabacead49b88e","date":1574700980,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestSortedMapBackedCache#testCacheReopensWithUpdate().mjava","pathOld":"solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestSortedMapBackedCache#testCacheReopensWithUpdate().mjava","sourceNew":"  @Test\n  public void testCacheReopensWithUpdate() {\n    DIHCache cache = null;\n    try {      \n      Map<String, String> cacheProps = new HashMap<>();\n      cacheProps.put(DIHCacheSupport.CACHE_PRIMARY_KEY, \"a_id\");\n      \n      cache = new SortedMapBackedCache();\n      cache.open(getContext(cacheProps));\n      // We can let the data hit the cache with the fields out of order because\n      // we've identified the pk up-front.\n      loadData(cache, data, fieldNames, false);\n\n      // Close the cache.\n      cache.close();\n\n      List<ControlData> newControlData = new ArrayList<>();\n      Object[] newIdEqualsThree = null;\n      int j = 0;\n      for (int i = 0; i < data.size(); i++) {\n        // We'll be deleting a_id=1 so remove it from the control data.\n        if (data.get(i).data[0].equals(1)) {\n          continue;\n        }\n\n        // We'll be changing \"Cookie\" to \"Carrot\" in a_id=3 so change it in the control data.\n        if (data.get(i).data[0].equals(3)) {\n          newIdEqualsThree = new Object[data.get(i).data.length];\n          System.arraycopy(data.get(i).data, 0, newIdEqualsThree, 0, newIdEqualsThree.length);\n          newIdEqualsThree[3] = \"Carrot\";\n          newControlData.add(new ControlData(newIdEqualsThree));\n        }\n        // Everything else can just be copied over.\n        else {\n          newControlData.add(data.get(i));\n        }\n\n        j++;\n      }\n\n      // These new rows of data will get added to the cache, so add them to the control data too.\n      Object[] newDataRow1 = new Object[] {99, new BigDecimal(Math.PI), \"Z\", \"Zebra\", 99.99f, Feb21_2011, null };\n      Object[] newDataRow2 = new Object[] {2, new BigDecimal(Math.PI), \"B\", \"Ballerina\", 2.22f, Feb21_2011, null };\n\n      newControlData.add(new ControlData(newDataRow1));\n      newControlData.add(new ControlData(newDataRow2));\n\n      // Re-open the cache\n      cache.open(getContext(new HashMap<String,String>()));\n\n      // Delete a_id=1 from the cache.\n      cache.delete(1);\n\n      // Because the cache allows duplicates, the only way to update is to\n      // delete first then add.\n      cache.delete(3);\n      cache.add(controlDataToMap(new ControlData(newIdEqualsThree), fieldNames, false));\n\n      // Add this row with a new Primary key.\n      cache.add(controlDataToMap(new ControlData(newDataRow1), fieldNames, false));\n\n      // Add this row, creating two records in the cache with a_id=2.\n      cache.add(controlDataToMap(new ControlData(newDataRow2), fieldNames, false));\n\n      // Read the cache back and compare to the newControlData\n      List<ControlData> testData = extractDataInKeyOrder(cache, fieldNames);\n      compareData(newControlData, testData);\n\n      // Now try reading the cache read-only.\n      cache.close();\n      cache.open(getContext(new HashMap<String,String>()));\n      testData = extractDataInKeyOrder(cache, fieldNames);\n      compareData(newControlData, testData);\n\n    } catch (Exception e) {\n      log.warn(\"Exception thrown: \" + e.toString());\n      Assert.fail();\n    } finally {\n      try {\n        cache.destroy();\n      } catch (Exception ex) {\n      }\n    }\n  }\n\n","sourceOld":"  @SuppressWarnings(\"unused\")\n  @Test\n  public void testCacheReopensWithUpdate() {\n    DIHCache cache = null;\n    try {      \n      Map<String, String> cacheProps = new HashMap<>();\n      cacheProps.put(DIHCacheSupport.CACHE_PRIMARY_KEY, \"a_id\");\n      \n      cache = new SortedMapBackedCache();\n      cache.open(getContext(cacheProps));\n      // We can let the data hit the cache with the fields out of order because\n      // we've identified the pk up-front.\n      loadData(cache, data, fieldNames, false);\n\n      // Close the cache.\n      cache.close();\n\n      List<ControlData> newControlData = new ArrayList<>();\n      Object[] newIdEqualsThree = null;\n      int j = 0;\n      for (int i = 0; i < data.size(); i++) {\n        // We'll be deleting a_id=1 so remove it from the control data.\n        if (data.get(i).data[0].equals(1)) {\n          continue;\n        }\n\n        // We'll be changing \"Cookie\" to \"Carrot\" in a_id=3 so change it in the control data.\n        if (data.get(i).data[0].equals(3)) {\n          newIdEqualsThree = new Object[data.get(i).data.length];\n          System.arraycopy(data.get(i).data, 0, newIdEqualsThree, 0, newIdEqualsThree.length);\n          newIdEqualsThree[3] = \"Carrot\";\n          newControlData.add(new ControlData(newIdEqualsThree));\n        }\n        // Everything else can just be copied over.\n        else {\n          newControlData.add(data.get(i));\n        }\n\n        j++;\n      }\n\n      // These new rows of data will get added to the cache, so add them to the control data too.\n      Object[] newDataRow1 = new Object[] {99, new BigDecimal(Math.PI), \"Z\", \"Zebra\", 99.99f, Feb21_2011, null };\n      Object[] newDataRow2 = new Object[] {2, new BigDecimal(Math.PI), \"B\", \"Ballerina\", 2.22f, Feb21_2011, null };\n\n      newControlData.add(new ControlData(newDataRow1));\n      newControlData.add(new ControlData(newDataRow2));\n\n      // Re-open the cache\n      cache.open(getContext(new HashMap<String,String>()));\n\n      // Delete a_id=1 from the cache.\n      cache.delete(1);\n\n      // Because the cache allows duplicates, the only way to update is to\n      // delete first then add.\n      cache.delete(3);\n      cache.add(controlDataToMap(new ControlData(newIdEqualsThree), fieldNames, false));\n\n      // Add this row with a new Primary key.\n      cache.add(controlDataToMap(new ControlData(newDataRow1), fieldNames, false));\n\n      // Add this row, creating two records in the cache with a_id=2.\n      cache.add(controlDataToMap(new ControlData(newDataRow2), fieldNames, false));\n\n      // Read the cache back and compare to the newControlData\n      List<ControlData> testData = extractDataInKeyOrder(cache, fieldNames);\n      compareData(newControlData, testData);\n\n      // Now try reading the cache read-only.\n      cache.close();\n      cache.open(getContext(new HashMap<String,String>()));\n      testData = extractDataInKeyOrder(cache, fieldNames);\n      compareData(newControlData, testData);\n\n    } catch (Exception e) {\n      log.warn(\"Exception thrown: \" + e.toString());\n      Assert.fail();\n    } finally {\n      try {\n        cache.destroy();\n      } catch (Exception ex) {\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a966532d92cf9ba2856f15a8140151bb6b518e4b","date":1588290631,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestSortedMapBackedCache#testCacheReopensWithUpdate().mjava","pathOld":"solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestSortedMapBackedCache#testCacheReopensWithUpdate().mjava","sourceNew":"  @Test\n  public void testCacheReopensWithUpdate() {\n    DIHCache cache = null;\n    try {      \n      Map<String, String> cacheProps = new HashMap<>();\n      cacheProps.put(DIHCacheSupport.CACHE_PRIMARY_KEY, \"a_id\");\n      \n      cache = new SortedMapBackedCache();\n      cache.open(getContext(cacheProps));\n      // We can let the data hit the cache with the fields out of order because\n      // we've identified the pk up-front.\n      loadData(cache, data, fieldNames, false);\n\n      // Close the cache.\n      cache.close();\n\n      List<ControlData> newControlData = new ArrayList<>();\n      Object[] newIdEqualsThree = null;\n      int j = 0;\n      for (int i = 0; i < data.size(); i++) {\n        // We'll be deleting a_id=1 so remove it from the control data.\n        if (data.get(i).data[0].equals(1)) {\n          continue;\n        }\n\n        // We'll be changing \"Cookie\" to \"Carrot\" in a_id=3 so change it in the control data.\n        if (data.get(i).data[0].equals(3)) {\n          newIdEqualsThree = new Object[data.get(i).data.length];\n          System.arraycopy(data.get(i).data, 0, newIdEqualsThree, 0, newIdEqualsThree.length);\n          newIdEqualsThree[3] = \"Carrot\";\n          newControlData.add(new ControlData(newIdEqualsThree));\n        }\n        // Everything else can just be copied over.\n        else {\n          newControlData.add(data.get(i));\n        }\n\n        j++;\n      }\n\n      // These new rows of data will get added to the cache, so add them to the control data too.\n      Object[] newDataRow1 = new Object[] {99, new BigDecimal(Math.PI), \"Z\", \"Zebra\", 99.99f, Feb21_2011, null };\n      Object[] newDataRow2 = new Object[] {2, new BigDecimal(Math.PI), \"B\", \"Ballerina\", 2.22f, Feb21_2011, null };\n\n      newControlData.add(new ControlData(newDataRow1));\n      newControlData.add(new ControlData(newDataRow2));\n\n      // Re-open the cache\n      cache.open(getContext(new HashMap<String,String>()));\n\n      // Delete a_id=1 from the cache.\n      cache.delete(1);\n\n      // Because the cache allows duplicates, the only way to update is to\n      // delete first then add.\n      cache.delete(3);\n      cache.add(controlDataToMap(new ControlData(newIdEqualsThree), fieldNames, false));\n\n      // Add this row with a new Primary key.\n      cache.add(controlDataToMap(new ControlData(newDataRow1), fieldNames, false));\n\n      // Add this row, creating two records in the cache with a_id=2.\n      cache.add(controlDataToMap(new ControlData(newDataRow2), fieldNames, false));\n\n      // Read the cache back and compare to the newControlData\n      List<ControlData> testData = extractDataInKeyOrder(cache, fieldNames);\n      compareData(newControlData, testData);\n\n      // Now try reading the cache read-only.\n      cache.close();\n      cache.open(getContext(new HashMap<String,String>()));\n      testData = extractDataInKeyOrder(cache, fieldNames);\n      compareData(newControlData, testData);\n\n    } catch (Exception e) {\n      log.warn(\"Exception thrown: {}\", e);\n      Assert.fail();\n    } finally {\n      try {\n        cache.destroy();\n      } catch (Exception ex) {\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testCacheReopensWithUpdate() {\n    DIHCache cache = null;\n    try {      \n      Map<String, String> cacheProps = new HashMap<>();\n      cacheProps.put(DIHCacheSupport.CACHE_PRIMARY_KEY, \"a_id\");\n      \n      cache = new SortedMapBackedCache();\n      cache.open(getContext(cacheProps));\n      // We can let the data hit the cache with the fields out of order because\n      // we've identified the pk up-front.\n      loadData(cache, data, fieldNames, false);\n\n      // Close the cache.\n      cache.close();\n\n      List<ControlData> newControlData = new ArrayList<>();\n      Object[] newIdEqualsThree = null;\n      int j = 0;\n      for (int i = 0; i < data.size(); i++) {\n        // We'll be deleting a_id=1 so remove it from the control data.\n        if (data.get(i).data[0].equals(1)) {\n          continue;\n        }\n\n        // We'll be changing \"Cookie\" to \"Carrot\" in a_id=3 so change it in the control data.\n        if (data.get(i).data[0].equals(3)) {\n          newIdEqualsThree = new Object[data.get(i).data.length];\n          System.arraycopy(data.get(i).data, 0, newIdEqualsThree, 0, newIdEqualsThree.length);\n          newIdEqualsThree[3] = \"Carrot\";\n          newControlData.add(new ControlData(newIdEqualsThree));\n        }\n        // Everything else can just be copied over.\n        else {\n          newControlData.add(data.get(i));\n        }\n\n        j++;\n      }\n\n      // These new rows of data will get added to the cache, so add them to the control data too.\n      Object[] newDataRow1 = new Object[] {99, new BigDecimal(Math.PI), \"Z\", \"Zebra\", 99.99f, Feb21_2011, null };\n      Object[] newDataRow2 = new Object[] {2, new BigDecimal(Math.PI), \"B\", \"Ballerina\", 2.22f, Feb21_2011, null };\n\n      newControlData.add(new ControlData(newDataRow1));\n      newControlData.add(new ControlData(newDataRow2));\n\n      // Re-open the cache\n      cache.open(getContext(new HashMap<String,String>()));\n\n      // Delete a_id=1 from the cache.\n      cache.delete(1);\n\n      // Because the cache allows duplicates, the only way to update is to\n      // delete first then add.\n      cache.delete(3);\n      cache.add(controlDataToMap(new ControlData(newIdEqualsThree), fieldNames, false));\n\n      // Add this row with a new Primary key.\n      cache.add(controlDataToMap(new ControlData(newDataRow1), fieldNames, false));\n\n      // Add this row, creating two records in the cache with a_id=2.\n      cache.add(controlDataToMap(new ControlData(newDataRow2), fieldNames, false));\n\n      // Read the cache back and compare to the newControlData\n      List<ControlData> testData = extractDataInKeyOrder(cache, fieldNames);\n      compareData(newControlData, testData);\n\n      // Now try reading the cache read-only.\n      cache.close();\n      cache.open(getContext(new HashMap<String,String>()));\n      testData = extractDataInKeyOrder(cache, fieldNames);\n      compareData(newControlData, testData);\n\n    } catch (Exception e) {\n      log.warn(\"Exception thrown: \" + e.toString());\n      Assert.fail();\n    } finally {\n      try {\n        cache.destroy();\n      } catch (Exception ex) {\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d2c8f5c46c2501b61e2f55eb7ee59e6c5372290b","date":1598712724,"type":4,"author":"Alexandre Rafalovitch","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestSortedMapBackedCache#testCacheReopensWithUpdate().mjava","sourceNew":null,"sourceOld":"  @Test\n  public void testCacheReopensWithUpdate() {\n    DIHCache cache = null;\n    try {      \n      Map<String, String> cacheProps = new HashMap<>();\n      cacheProps.put(DIHCacheSupport.CACHE_PRIMARY_KEY, \"a_id\");\n      \n      cache = new SortedMapBackedCache();\n      cache.open(getContext(cacheProps));\n      // We can let the data hit the cache with the fields out of order because\n      // we've identified the pk up-front.\n      loadData(cache, data, fieldNames, false);\n\n      // Close the cache.\n      cache.close();\n\n      List<ControlData> newControlData = new ArrayList<>();\n      Object[] newIdEqualsThree = null;\n      int j = 0;\n      for (int i = 0; i < data.size(); i++) {\n        // We'll be deleting a_id=1 so remove it from the control data.\n        if (data.get(i).data[0].equals(1)) {\n          continue;\n        }\n\n        // We'll be changing \"Cookie\" to \"Carrot\" in a_id=3 so change it in the control data.\n        if (data.get(i).data[0].equals(3)) {\n          newIdEqualsThree = new Object[data.get(i).data.length];\n          System.arraycopy(data.get(i).data, 0, newIdEqualsThree, 0, newIdEqualsThree.length);\n          newIdEqualsThree[3] = \"Carrot\";\n          newControlData.add(new ControlData(newIdEqualsThree));\n        }\n        // Everything else can just be copied over.\n        else {\n          newControlData.add(data.get(i));\n        }\n\n        j++;\n      }\n\n      // These new rows of data will get added to the cache, so add them to the control data too.\n      Object[] newDataRow1 = new Object[] {99, new BigDecimal(Math.PI), \"Z\", \"Zebra\", 99.99f, Feb21_2011, null };\n      Object[] newDataRow2 = new Object[] {2, new BigDecimal(Math.PI), \"B\", \"Ballerina\", 2.22f, Feb21_2011, null };\n\n      newControlData.add(new ControlData(newDataRow1));\n      newControlData.add(new ControlData(newDataRow2));\n\n      // Re-open the cache\n      cache.open(getContext(new HashMap<String,String>()));\n\n      // Delete a_id=1 from the cache.\n      cache.delete(1);\n\n      // Because the cache allows duplicates, the only way to update is to\n      // delete first then add.\n      cache.delete(3);\n      cache.add(controlDataToMap(new ControlData(newIdEqualsThree), fieldNames, false));\n\n      // Add this row with a new Primary key.\n      cache.add(controlDataToMap(new ControlData(newDataRow1), fieldNames, false));\n\n      // Add this row, creating two records in the cache with a_id=2.\n      cache.add(controlDataToMap(new ControlData(newDataRow2), fieldNames, false));\n\n      // Read the cache back and compare to the newControlData\n      List<ControlData> testData = extractDataInKeyOrder(cache, fieldNames);\n      compareData(newControlData, testData);\n\n      // Now try reading the cache read-only.\n      cache.close();\n      cache.open(getContext(new HashMap<String,String>()));\n      testData = extractDataInKeyOrder(cache, fieldNames);\n      compareData(newControlData, testData);\n\n    } catch (Exception e) {\n      log.warn(\"Exception thrown: {}\", e);\n      Assert.fail();\n    } finally {\n      try {\n        cache.destroy();\n      } catch (Exception ex) {\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["4093b270ba337f9c25a4c0e6cb2ae2c07f697376"],"d2c8f5c46c2501b61e2f55eb7ee59e6c5372290b":["a966532d92cf9ba2856f15a8140151bb6b518e4b"],"b6a269c1ddba3f8c9fa9a40572ecc538eddda41a":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":["634f330c54fd3f9f491d52036dc3f40b4f4d8934","628903f37b6c442da0d390db1c6af9a0e74d41a7"],"a5df378a6155dcc1f4d4ecdcbd8ea5bc058560e9":["628903f37b6c442da0d390db1c6af9a0e74d41a7"],"3337b86edd36607f0208321f1deee79c55e5fd21":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"bb9c3baacabd473e8ecd6c4948aabacead49b88e":["a5df378a6155dcc1f4d4ecdcbd8ea5bc058560e9"],"a966532d92cf9ba2856f15a8140151bb6b518e4b":["bb9c3baacabd473e8ecd6c4948aabacead49b88e"],"628903f37b6c442da0d390db1c6af9a0e74d41a7":["634f330c54fd3f9f491d52036dc3f40b4f4d8934","b6a269c1ddba3f8c9fa9a40572ecc538eddda41a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["d2c8f5c46c2501b61e2f55eb7ee59e6c5372290b"],"4093b270ba337f9c25a4c0e6cb2ae2c07f697376":["3337b86edd36607f0208321f1deee79c55e5fd21"]},"commit2Childs":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["b6a269c1ddba3f8c9fa9a40572ecc538eddda41a","0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","628903f37b6c442da0d390db1c6af9a0e74d41a7"],"d2c8f5c46c2501b61e2f55eb7ee59e6c5372290b":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"b6a269c1ddba3f8c9fa9a40572ecc538eddda41a":["628903f37b6c442da0d390db1c6af9a0e74d41a7"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":[],"a5df378a6155dcc1f4d4ecdcbd8ea5bc058560e9":["bb9c3baacabd473e8ecd6c4948aabacead49b88e"],"3337b86edd36607f0208321f1deee79c55e5fd21":["4093b270ba337f9c25a4c0e6cb2ae2c07f697376"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3337b86edd36607f0208321f1deee79c55e5fd21"],"bb9c3baacabd473e8ecd6c4948aabacead49b88e":["a966532d92cf9ba2856f15a8140151bb6b518e4b"],"a966532d92cf9ba2856f15a8140151bb6b518e4b":["d2c8f5c46c2501b61e2f55eb7ee59e6c5372290b"],"628903f37b6c442da0d390db1c6af9a0e74d41a7":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","a5df378a6155dcc1f4d4ecdcbd8ea5bc058560e9"],"4093b270ba337f9c25a4c0e6cb2ae2c07f697376":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}