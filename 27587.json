{"path":"lucene/suggest/src/test/org/apache/lucene/search/suggest/document/CompletionTokenStreamTest#testWithSynonym().mjava","commits":[{"id":"509ddf2b18aec24f54a1cbabf7d15ed537d61ff2","date":1446074047,"type":0,"author":"Areek Zillur","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/document/CompletionTokenStreamTest#testWithSynonym().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testWithSynonym() throws Exception {\n    SynonymMap.Builder builder = new SynonymMap.Builder(true);\n    builder.add(new CharsRef(\"mykeyword\"), new CharsRef(\"mysynonym\"), true);\n    Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true);\n    tokenizer.setReader(new StringReader(\"mykeyword\"));\n    SynonymFilter filter = new SynonymFilter(tokenizer, builder.build(), true);\n    CompletionTokenStream completionTokenStream = new CompletionTokenStream(filter);\n    BytesRef payload = new BytesRef(\"payload\");\n    completionTokenStream.setPayload(payload);\n    PayloadAttrToTypeAttrFilter stream = new PayloadAttrToTypeAttrFilter(completionTokenStream);\n    assertTokenStreamContents(stream, new String[] {\"mykeyword\", \"mysynonym\"}, null, null, new String[] {payload.utf8ToString(), payload.utf8ToString()}, new int[] { 1, 1 }, null, null);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9e45ad199e1b1a4bbc15c1c08dcd73dc08fa927a","date":1528168051,"type":5,"author":"David Smiley","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestConcatenateGraphFilter#testWithSynonym().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/document/CompletionTokenStreamTest#testWithSynonym().mjava","sourceNew":"  @Test\n  public void testWithSynonym() throws Exception {\n    SynonymMap.Builder builder = new SynonymMap.Builder(true);\n    builder.add(new CharsRef(\"mykeyword\"), new CharsRef(\"mysynonym\"), true);\n    Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true);\n    tokenizer.setReader(new StringReader(\"mykeyword\"));\n    SynonymFilter filter = new SynonymFilter(tokenizer, builder.build(), true);\n    ConcatenateGraphFilter stream = new ConcatenateGraphFilter(filter);\n    assertTokenStreamContents(stream, new String[] {\"mykeyword\", \"mysynonym\"}, null, null, new int[] { 1, 0 });\n  }\n\n","sourceOld":"  @Test\n  public void testWithSynonym() throws Exception {\n    SynonymMap.Builder builder = new SynonymMap.Builder(true);\n    builder.add(new CharsRef(\"mykeyword\"), new CharsRef(\"mysynonym\"), true);\n    Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true);\n    tokenizer.setReader(new StringReader(\"mykeyword\"));\n    SynonymFilter filter = new SynonymFilter(tokenizer, builder.build(), true);\n    CompletionTokenStream completionTokenStream = new CompletionTokenStream(filter);\n    BytesRef payload = new BytesRef(\"payload\");\n    completionTokenStream.setPayload(payload);\n    PayloadAttrToTypeAttrFilter stream = new PayloadAttrToTypeAttrFilter(completionTokenStream);\n    assertTokenStreamContents(stream, new String[] {\"mykeyword\", \"mysynonym\"}, null, null, new String[] {payload.utf8ToString(), payload.utf8ToString()}, new int[] { 1, 1 }, null, null);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f592209545c71895260367152601e9200399776d","date":1528238935,"type":5,"author":"Michael Braun","isMerge":true,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestConcatenateGraphFilter#testWithSynonym().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/document/CompletionTokenStreamTest#testWithSynonym().mjava","sourceNew":"  @Test\n  public void testWithSynonym() throws Exception {\n    SynonymMap.Builder builder = new SynonymMap.Builder(true);\n    builder.add(new CharsRef(\"mykeyword\"), new CharsRef(\"mysynonym\"), true);\n    Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true);\n    tokenizer.setReader(new StringReader(\"mykeyword\"));\n    SynonymFilter filter = new SynonymFilter(tokenizer, builder.build(), true);\n    ConcatenateGraphFilter stream = new ConcatenateGraphFilter(filter);\n    assertTokenStreamContents(stream, new String[] {\"mykeyword\", \"mysynonym\"}, null, null, new int[] { 1, 0 });\n  }\n\n","sourceOld":"  @Test\n  public void testWithSynonym() throws Exception {\n    SynonymMap.Builder builder = new SynonymMap.Builder(true);\n    builder.add(new CharsRef(\"mykeyword\"), new CharsRef(\"mysynonym\"), true);\n    Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true);\n    tokenizer.setReader(new StringReader(\"mykeyword\"));\n    SynonymFilter filter = new SynonymFilter(tokenizer, builder.build(), true);\n    CompletionTokenStream completionTokenStream = new CompletionTokenStream(filter);\n    BytesRef payload = new BytesRef(\"payload\");\n    completionTokenStream.setPayload(payload);\n    PayloadAttrToTypeAttrFilter stream = new PayloadAttrToTypeAttrFilter(completionTokenStream);\n    assertTokenStreamContents(stream, new String[] {\"mykeyword\", \"mysynonym\"}, null, null, new String[] {payload.utf8ToString(), payload.utf8ToString()}, new int[] { 1, 1 }, null, null);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b70042a8a492f7054d480ccdd2be9796510d4327","date":1528386658,"type":5,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestConcatenateGraphFilter#testWithSynonym().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/document/CompletionTokenStreamTest#testWithSynonym().mjava","sourceNew":"  @Test\n  public void testWithSynonym() throws Exception {\n    SynonymMap.Builder builder = new SynonymMap.Builder(true);\n    builder.add(new CharsRef(\"mykeyword\"), new CharsRef(\"mysynonym\"), true);\n    Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true);\n    tokenizer.setReader(new StringReader(\"mykeyword\"));\n    SynonymFilter filter = new SynonymFilter(tokenizer, builder.build(), true);\n    ConcatenateGraphFilter stream = new ConcatenateGraphFilter(filter);\n    assertTokenStreamContents(stream, new String[] {\"mykeyword\", \"mysynonym\"}, null, null, new int[] { 1, 0 });\n  }\n\n","sourceOld":"  @Test\n  public void testWithSynonym() throws Exception {\n    SynonymMap.Builder builder = new SynonymMap.Builder(true);\n    builder.add(new CharsRef(\"mykeyword\"), new CharsRef(\"mysynonym\"), true);\n    Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true);\n    tokenizer.setReader(new StringReader(\"mykeyword\"));\n    SynonymFilter filter = new SynonymFilter(tokenizer, builder.build(), true);\n    CompletionTokenStream completionTokenStream = new CompletionTokenStream(filter);\n    BytesRef payload = new BytesRef(\"payload\");\n    completionTokenStream.setPayload(payload);\n    PayloadAttrToTypeAttrFilter stream = new PayloadAttrToTypeAttrFilter(completionTokenStream);\n    assertTokenStreamContents(stream, new String[] {\"mykeyword\", \"mysynonym\"}, null, null, new String[] {payload.utf8ToString(), payload.utf8ToString()}, new int[] { 1, 1 }, null, null);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"509ddf2b18aec24f54a1cbabf7d15ed537d61ff2":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b70042a8a492f7054d480ccdd2be9796510d4327":["509ddf2b18aec24f54a1cbabf7d15ed537d61ff2","9e45ad199e1b1a4bbc15c1c08dcd73dc08fa927a"],"9e45ad199e1b1a4bbc15c1c08dcd73dc08fa927a":["509ddf2b18aec24f54a1cbabf7d15ed537d61ff2"],"f592209545c71895260367152601e9200399776d":["509ddf2b18aec24f54a1cbabf7d15ed537d61ff2","9e45ad199e1b1a4bbc15c1c08dcd73dc08fa927a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9e45ad199e1b1a4bbc15c1c08dcd73dc08fa927a"]},"commit2Childs":{"509ddf2b18aec24f54a1cbabf7d15ed537d61ff2":["b70042a8a492f7054d480ccdd2be9796510d4327","9e45ad199e1b1a4bbc15c1c08dcd73dc08fa927a","f592209545c71895260367152601e9200399776d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["509ddf2b18aec24f54a1cbabf7d15ed537d61ff2"],"b70042a8a492f7054d480ccdd2be9796510d4327":[],"9e45ad199e1b1a4bbc15c1c08dcd73dc08fa927a":["b70042a8a492f7054d480ccdd2be9796510d4327","f592209545c71895260367152601e9200399776d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"f592209545c71895260367152601e9200399776d":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["b70042a8a492f7054d480ccdd2be9796510d4327","f592209545c71895260367152601e9200399776d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}