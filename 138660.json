{"path":"lucene/core/src/test/org/apache/lucene/index/TestStressNRT#test().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestStressNRT#test().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestStressNRT#test().mjava","sourceNew":"  public void test() throws Exception {\n    // update variables\n    final int commitPercent = random.nextInt(20);\n    final int softCommitPercent = random.nextInt(100); // what percent of the commits are soft\n    final int deletePercent = random.nextInt(50);\n    final int deleteByQueryPercent = random.nextInt(25);\n    final int ndocs = atLeast(50);\n    final int nWriteThreads = _TestUtil.nextInt(random, 1, TEST_NIGHTLY ? 10 : 5);\n    final int maxConcurrentCommits = _TestUtil.nextInt(random, 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n    \n    final boolean tombstones = random.nextBoolean();\n\n    // query variables\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n\n    final int nReadThreads = _TestUtil.nextInt(random, 1, TEST_NIGHTLY ? 10 : 5);\n    initModel(ndocs);\n\n    final FieldType storedOnlyType = new FieldType();\n    storedOnlyType.setStored(true);\n\n    if (VERBOSE) {\n      System.out.println(\"\\n\");\n      System.out.println(\"TEST: commitPercent=\" + commitPercent);\n      System.out.println(\"TEST: softCommitPercent=\" + softCommitPercent);\n      System.out.println(\"TEST: deletePercent=\" + deletePercent);\n      System.out.println(\"TEST: deleteByQueryPercent=\" + deleteByQueryPercent);\n      System.out.println(\"TEST: ndocs=\" + ndocs);\n      System.out.println(\"TEST: nWriteThreads=\" + nWriteThreads);\n      System.out.println(\"TEST: nReadThreads=\" + nReadThreads);\n      System.out.println(\"TEST: maxConcurrentCommits=\" + maxConcurrentCommits);\n      System.out.println(\"TEST: tombstones=\" + tombstones);\n      System.out.println(\"TEST: operations=\" + operations);\n      System.out.println(\"\\n\");\n    }\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    Directory dir = newDirectory();\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random, dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.setDoRandomForceMergeAssert(false);\n    writer.commit();\n    reader = IndexReader.open(dir);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n                  DirectoryReader oldReader;\n\n                  synchronized(TestStressNRT.this) {\n                    newCommittedModel = new HashMap<Integer,Long>(model);  // take a snapshot\n                    version = snapshotCount++;\n                    oldReader = reader;\n                    oldReader.incRef();  // increment the reference since we will use this for reopening\n                  }\n\n                  DirectoryReader newReader;\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    // assertU(h.commit(\"softCommit\",\"true\"));\n                    if (random.nextBoolean()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": call writer.getReader\");\n                      }\n                      newReader = writer.getReader(true);\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": reopen reader=\" + oldReader + \" version=\" + version);\n                      }\n                      newReader = DirectoryReader.openIfChanged(oldReader, writer.w, true);\n                    }\n                  } else {\n                    // assertU(commit());\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": commit+reopen reader=\" + oldReader + \" version=\" + version);\n                    }\n                    writer.commit();\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": now reopen after commit\");\n                    }\n                    newReader = DirectoryReader.openIfChanged(oldReader);\n                  }\n\n                  // Code below assumes newReader comes w/\n                  // extra ref:\n                  if (newReader == null) {\n                    oldReader.incRef();\n                    newReader = oldReader;\n                  }\n\n                  oldReader.decRef();\n\n                  synchronized(TestStressNRT.this) {\n                    // install the new reader if it's newest (and check the current version since another reader may have already been installed)\n                    //System.out.println(Thread.currentThread().getName() + \": newVersion=\" + newReader.getVersion());\n                    assert newReader.getRefCount() > 0;\n                    assert reader.getRefCount() > 0;\n                    if (newReader.getVersion() > reader.getVersion()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new reader=\" + newReader);\n                      }\n                      reader.decRef();\n                      reader = newReader;\n\n                      // Silly: forces fieldInfos to be\n                      // loaded so we don't hit IOE on later\n                      // reader.toString\n                      newReader.toString();\n\n                      // install this snapshot only if it's newer than the current one\n                      if (version >= committedModelClock) {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new model version=\" + version);\n                        }\n                        committedModel = newCommittedModel;\n                        committedModelClock = version;\n                      } else {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new model version=\" + version);\n                        }\n                      }\n                    } else {\n                      // if the same reader, don't decRef.\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new reader=\" + newReader);\n                      }\n                      newReader.decRef();\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else {\n\n                int id = rand.nextInt(ndocs);\n                Object sync = syncArr[id];\n\n                // set the lastId before we actually change it sometimes to try and\n                // uncover more race conditions between writing and reading\n                boolean before = random.nextBoolean();\n                if (before) {\n                  lastId = id;\n                }\n\n                // We can't concurrently update the same document and retain our invariants of increasing values\n                // since we can't guarantee what order the updates will be executed.\n                synchronized (sync) {\n                  Long val = model.get(id);\n                  long nextVal = Math.abs(val)+1;\n\n                  if (oper < commitPercent + deletePercent) {\n                    // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newField(\"id\", \"-\"+Integer.toString(id), StringField.TYPE_STORED));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": term delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new Term(\"id\",Integer.toString(id)));\n                    model.put(id, -nextVal);\n                  } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                    //assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newField(\"id\", \"-\"+Integer.toString(id), StringField.TYPE_STORED));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": query delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new TermQuery(new Term(\"id\", Integer.toString(id))));\n                    model.put(id, -nextVal);\n                  } else {\n                    // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                    Document d = new Document();\n                    d.add(newField(\"id\", Integer.toString(id), StringField.TYPE_STORED));\n                    d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": u id:\" + id + \" val=\" + nextVal);\n                    }\n                    writer.updateDocument(new Term(\"id\", Integer.toString(id)), d);\n                    if (tombstones) {\n                      // remove tombstone after new addition (this should be optional?)\n                      writer.deleteDocuments(new Term(\"id\",\"-\"+Integer.toString(id)));\n                    }\n                    model.put(id, nextVal);\n                  }\n                }\n\n                if (!before) {\n                  lastId = id;\n                }\n              }\n            }\n          } catch (Throwable e) {\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              long val;\n              DirectoryReader r;\n              synchronized(TestStressNRT.this) {\n                val = committedModel.get(id);\n                r = reader;\n                r.incRef();\n              }\n\n              if (VERBOSE) {\n                System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": s id=\" + id + \" val=\" + val + \" r=\" + r.getVersion());\n              }\n\n              //  sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              IndexSearcher searcher = new IndexSearcher(r);\n              Query q = new TermQuery(new Term(\"id\",Integer.toString(id)));\n              TopDocs results = searcher.search(q, 10);\n\n              if (results.totalHits == 0 && tombstones) {\n                // if we couldn't find the doc, look for its tombstone\n                q = new TermQuery(new Term(\"id\",\"-\"+Integer.toString(id)));\n                results = searcher.search(q, 1);\n                if (results.totalHits == 0) {\n                  if (val == -1L) {\n                    // expected... no doc was added yet\n                    r.decRef();\n                    continue;\n                  }\n                  fail(\"No documents or tombstones found for id \" + id + \", expected at least \" + val + \" reader=\" + r);\n                }\n              }\n\n              if (results.totalHits == 0 && !tombstones) {\n                // nothing to do - we can't tell anything from a deleted doc without tombstones\n              } else {\n                // we should have found the document, or its tombstone\n                if (results.totalHits != 1) {\n                  System.out.println(\"FAIL: hits id:\" + id + \" val=\" + val);\n                  for(ScoreDoc sd : results.scoreDocs) {\n                    final Document doc = r.document(sd.doc);\n                    System.out.println(\"  docID=\" + sd.doc + \" id:\" + doc.get(\"id\") + \" foundVal=\" + doc.get(field));\n                  }\n                  fail(\"id=\" + id + \" reader=\" + r + \" totalHits=\" + results.totalHits);\n                }\n                Document doc = searcher.doc(results.scoreDocs[0].doc);\n                long foundVal = Long.parseLong(doc.get(field));\n                if (foundVal < Math.abs(val)) {\n                  fail(\"foundVal=\" + foundVal + \" val=\" + val + \" id=\" + id + \" reader=\" + r);\n                }\n              }\n\n              r.decRef();\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    writer.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: close reader=\" + reader);\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    // update variables\n    final int commitPercent = random.nextInt(20);\n    final int softCommitPercent = random.nextInt(100); // what percent of the commits are soft\n    final int deletePercent = random.nextInt(50);\n    final int deleteByQueryPercent = random.nextInt(25);\n    final int ndocs = atLeast(50);\n    final int nWriteThreads = _TestUtil.nextInt(random, 1, TEST_NIGHTLY ? 10 : 5);\n    final int maxConcurrentCommits = _TestUtil.nextInt(random, 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n    \n    final boolean tombstones = random.nextBoolean();\n\n    // query variables\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n\n    final int nReadThreads = _TestUtil.nextInt(random, 1, TEST_NIGHTLY ? 10 : 5);\n    initModel(ndocs);\n\n    final FieldType storedOnlyType = new FieldType();\n    storedOnlyType.setStored(true);\n\n    if (VERBOSE) {\n      System.out.println(\"\\n\");\n      System.out.println(\"TEST: commitPercent=\" + commitPercent);\n      System.out.println(\"TEST: softCommitPercent=\" + softCommitPercent);\n      System.out.println(\"TEST: deletePercent=\" + deletePercent);\n      System.out.println(\"TEST: deleteByQueryPercent=\" + deleteByQueryPercent);\n      System.out.println(\"TEST: ndocs=\" + ndocs);\n      System.out.println(\"TEST: nWriteThreads=\" + nWriteThreads);\n      System.out.println(\"TEST: nReadThreads=\" + nReadThreads);\n      System.out.println(\"TEST: maxConcurrentCommits=\" + maxConcurrentCommits);\n      System.out.println(\"TEST: tombstones=\" + tombstones);\n      System.out.println(\"TEST: operations=\" + operations);\n      System.out.println(\"\\n\");\n    }\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    Directory dir = newDirectory();\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random, dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.setDoRandomForceMergeAssert(false);\n    writer.commit();\n    reader = IndexReader.open(dir);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n                  DirectoryReader oldReader;\n\n                  synchronized(TestStressNRT.this) {\n                    newCommittedModel = new HashMap<Integer,Long>(model);  // take a snapshot\n                    version = snapshotCount++;\n                    oldReader = reader;\n                    oldReader.incRef();  // increment the reference since we will use this for reopening\n                  }\n\n                  DirectoryReader newReader;\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    // assertU(h.commit(\"softCommit\",\"true\"));\n                    if (random.nextBoolean()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": call writer.getReader\");\n                      }\n                      newReader = writer.getReader(true);\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": reopen reader=\" + oldReader + \" version=\" + version);\n                      }\n                      newReader = DirectoryReader.openIfChanged(oldReader, writer.w, true);\n                    }\n                  } else {\n                    // assertU(commit());\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": commit+reopen reader=\" + oldReader + \" version=\" + version);\n                    }\n                    writer.commit();\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": now reopen after commit\");\n                    }\n                    newReader = DirectoryReader.openIfChanged(oldReader);\n                  }\n\n                  // Code below assumes newReader comes w/\n                  // extra ref:\n                  if (newReader == null) {\n                    oldReader.incRef();\n                    newReader = oldReader;\n                  }\n\n                  oldReader.decRef();\n\n                  synchronized(TestStressNRT.this) {\n                    // install the new reader if it's newest (and check the current version since another reader may have already been installed)\n                    //System.out.println(Thread.currentThread().getName() + \": newVersion=\" + newReader.getVersion());\n                    assert newReader.getRefCount() > 0;\n                    assert reader.getRefCount() > 0;\n                    if (newReader.getVersion() > reader.getVersion()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new reader=\" + newReader);\n                      }\n                      reader.decRef();\n                      reader = newReader;\n\n                      // Silly: forces fieldInfos to be\n                      // loaded so we don't hit IOE on later\n                      // reader.toString\n                      newReader.toString();\n\n                      // install this snapshot only if it's newer than the current one\n                      if (version >= committedModelClock) {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new model version=\" + version);\n                        }\n                        committedModel = newCommittedModel;\n                        committedModelClock = version;\n                      } else {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new model version=\" + version);\n                        }\n                      }\n                    } else {\n                      // if the same reader, don't decRef.\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new reader=\" + newReader);\n                      }\n                      newReader.decRef();\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else {\n\n                int id = rand.nextInt(ndocs);\n                Object sync = syncArr[id];\n\n                // set the lastId before we actually change it sometimes to try and\n                // uncover more race conditions between writing and reading\n                boolean before = random.nextBoolean();\n                if (before) {\n                  lastId = id;\n                }\n\n                // We can't concurrently update the same document and retain our invariants of increasing values\n                // since we can't guarantee what order the updates will be executed.\n                synchronized (sync) {\n                  Long val = model.get(id);\n                  long nextVal = Math.abs(val)+1;\n\n                  if (oper < commitPercent + deletePercent) {\n                    // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newField(\"id\", \"-\"+Integer.toString(id), StringField.TYPE_STORED));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": term delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new Term(\"id\",Integer.toString(id)));\n                    model.put(id, -nextVal);\n                  } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                    //assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newField(\"id\", \"-\"+Integer.toString(id), StringField.TYPE_STORED));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": query delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new TermQuery(new Term(\"id\", Integer.toString(id))));\n                    model.put(id, -nextVal);\n                  } else {\n                    // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                    Document d = new Document();\n                    d.add(newField(\"id\", Integer.toString(id), StringField.TYPE_STORED));\n                    d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": u id:\" + id + \" val=\" + nextVal);\n                    }\n                    writer.updateDocument(new Term(\"id\", Integer.toString(id)), d);\n                    if (tombstones) {\n                      // remove tombstone after new addition (this should be optional?)\n                      writer.deleteDocuments(new Term(\"id\",\"-\"+Integer.toString(id)));\n                    }\n                    model.put(id, nextVal);\n                  }\n                }\n\n                if (!before) {\n                  lastId = id;\n                }\n              }\n            }\n          } catch (Throwable e) {\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              long val;\n              DirectoryReader r;\n              synchronized(TestStressNRT.this) {\n                val = committedModel.get(id);\n                r = reader;\n                r.incRef();\n              }\n\n              if (VERBOSE) {\n                System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": s id=\" + id + \" val=\" + val + \" r=\" + r.getVersion());\n              }\n\n              //  sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              IndexSearcher searcher = new IndexSearcher(r);\n              Query q = new TermQuery(new Term(\"id\",Integer.toString(id)));\n              TopDocs results = searcher.search(q, 10);\n\n              if (results.totalHits == 0 && tombstones) {\n                // if we couldn't find the doc, look for its tombstone\n                q = new TermQuery(new Term(\"id\",\"-\"+Integer.toString(id)));\n                results = searcher.search(q, 1);\n                if (results.totalHits == 0) {\n                  if (val == -1L) {\n                    // expected... no doc was added yet\n                    r.decRef();\n                    continue;\n                  }\n                  fail(\"No documents or tombstones found for id \" + id + \", expected at least \" + val + \" reader=\" + r);\n                }\n              }\n\n              if (results.totalHits == 0 && !tombstones) {\n                // nothing to do - we can't tell anything from a deleted doc without tombstones\n              } else {\n                // we should have found the document, or its tombstone\n                if (results.totalHits != 1) {\n                  System.out.println(\"FAIL: hits id:\" + id + \" val=\" + val);\n                  for(ScoreDoc sd : results.scoreDocs) {\n                    final Document doc = r.document(sd.doc);\n                    System.out.println(\"  docID=\" + sd.doc + \" id:\" + doc.get(\"id\") + \" foundVal=\" + doc.get(field));\n                  }\n                  fail(\"id=\" + id + \" reader=\" + r + \" totalHits=\" + results.totalHits);\n                }\n                Document doc = searcher.doc(results.scoreDocs[0].doc);\n                long foundVal = Long.parseLong(doc.get(field));\n                if (foundVal < Math.abs(val)) {\n                  fail(\"foundVal=\" + foundVal + \" val=\" + val + \" id=\" + id + \" reader=\" + r);\n                }\n              }\n\n              r.decRef();\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    writer.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: close reader=\" + reader);\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestStressNRT#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestStressNRT#test().mjava","sourceNew":"  public void test() throws Exception {\n    // update variables\n    final int commitPercent = random().nextInt(20);\n    final int softCommitPercent = random().nextInt(100); // what percent of the commits are soft\n    final int deletePercent = random().nextInt(50);\n    final int deleteByQueryPercent = random().nextInt(25);\n    final int ndocs = atLeast(50);\n    final int nWriteThreads = _TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    final int maxConcurrentCommits = _TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n    \n    final boolean tombstones = random().nextBoolean();\n\n    // query variables\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n\n    final int nReadThreads = _TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    initModel(ndocs);\n\n    final FieldType storedOnlyType = new FieldType();\n    storedOnlyType.setStored(true);\n\n    if (VERBOSE) {\n      System.out.println(\"\\n\");\n      System.out.println(\"TEST: commitPercent=\" + commitPercent);\n      System.out.println(\"TEST: softCommitPercent=\" + softCommitPercent);\n      System.out.println(\"TEST: deletePercent=\" + deletePercent);\n      System.out.println(\"TEST: deleteByQueryPercent=\" + deleteByQueryPercent);\n      System.out.println(\"TEST: ndocs=\" + ndocs);\n      System.out.println(\"TEST: nWriteThreads=\" + nWriteThreads);\n      System.out.println(\"TEST: nReadThreads=\" + nReadThreads);\n      System.out.println(\"TEST: maxConcurrentCommits=\" + maxConcurrentCommits);\n      System.out.println(\"TEST: tombstones=\" + tombstones);\n      System.out.println(\"TEST: operations=\" + operations);\n      System.out.println(\"\\n\");\n    }\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    Directory dir = newDirectory();\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    writer.setDoRandomForceMergeAssert(false);\n    writer.commit();\n    reader = IndexReader.open(dir);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n                  DirectoryReader oldReader;\n\n                  synchronized(TestStressNRT.this) {\n                    newCommittedModel = new HashMap<Integer,Long>(model);  // take a snapshot\n                    version = snapshotCount++;\n                    oldReader = reader;\n                    oldReader.incRef();  // increment the reference since we will use this for reopening\n                  }\n\n                  DirectoryReader newReader;\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    // assertU(h.commit(\"softCommit\",\"true\"));\n                    if (random().nextBoolean()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": call writer.getReader\");\n                      }\n                      newReader = writer.getReader(true);\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": reopen reader=\" + oldReader + \" version=\" + version);\n                      }\n                      newReader = DirectoryReader.openIfChanged(oldReader, writer.w, true);\n                    }\n                  } else {\n                    // assertU(commit());\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": commit+reopen reader=\" + oldReader + \" version=\" + version);\n                    }\n                    writer.commit();\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": now reopen after commit\");\n                    }\n                    newReader = DirectoryReader.openIfChanged(oldReader);\n                  }\n\n                  // Code below assumes newReader comes w/\n                  // extra ref:\n                  if (newReader == null) {\n                    oldReader.incRef();\n                    newReader = oldReader;\n                  }\n\n                  oldReader.decRef();\n\n                  synchronized(TestStressNRT.this) {\n                    // install the new reader if it's newest (and check the current version since another reader may have already been installed)\n                    //System.out.println(Thread.currentThread().getName() + \": newVersion=\" + newReader.getVersion());\n                    assert newReader.getRefCount() > 0;\n                    assert reader.getRefCount() > 0;\n                    if (newReader.getVersion() > reader.getVersion()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new reader=\" + newReader);\n                      }\n                      reader.decRef();\n                      reader = newReader;\n\n                      // Silly: forces fieldInfos to be\n                      // loaded so we don't hit IOE on later\n                      // reader.toString\n                      newReader.toString();\n\n                      // install this snapshot only if it's newer than the current one\n                      if (version >= committedModelClock) {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new model version=\" + version);\n                        }\n                        committedModel = newCommittedModel;\n                        committedModelClock = version;\n                      } else {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new model version=\" + version);\n                        }\n                      }\n                    } else {\n                      // if the same reader, don't decRef.\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new reader=\" + newReader);\n                      }\n                      newReader.decRef();\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else {\n\n                int id = rand.nextInt(ndocs);\n                Object sync = syncArr[id];\n\n                // set the lastId before we actually change it sometimes to try and\n                // uncover more race conditions between writing and reading\n                boolean before = random().nextBoolean();\n                if (before) {\n                  lastId = id;\n                }\n\n                // We can't concurrently update the same document and retain our invariants of increasing values\n                // since we can't guarantee what order the updates will be executed.\n                synchronized (sync) {\n                  Long val = model.get(id);\n                  long nextVal = Math.abs(val)+1;\n\n                  if (oper < commitPercent + deletePercent) {\n                    // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newField(\"id\", \"-\"+Integer.toString(id), StringField.TYPE_STORED));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": term delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new Term(\"id\",Integer.toString(id)));\n                    model.put(id, -nextVal);\n                  } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                    //assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newField(\"id\", \"-\"+Integer.toString(id), StringField.TYPE_STORED));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": query delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new TermQuery(new Term(\"id\", Integer.toString(id))));\n                    model.put(id, -nextVal);\n                  } else {\n                    // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                    Document d = new Document();\n                    d.add(newField(\"id\", Integer.toString(id), StringField.TYPE_STORED));\n                    d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": u id:\" + id + \" val=\" + nextVal);\n                    }\n                    writer.updateDocument(new Term(\"id\", Integer.toString(id)), d);\n                    if (tombstones) {\n                      // remove tombstone after new addition (this should be optional?)\n                      writer.deleteDocuments(new Term(\"id\",\"-\"+Integer.toString(id)));\n                    }\n                    model.put(id, nextVal);\n                  }\n                }\n\n                if (!before) {\n                  lastId = id;\n                }\n              }\n            }\n          } catch (Throwable e) {\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              long val;\n              DirectoryReader r;\n              synchronized(TestStressNRT.this) {\n                val = committedModel.get(id);\n                r = reader;\n                r.incRef();\n              }\n\n              if (VERBOSE) {\n                System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": s id=\" + id + \" val=\" + val + \" r=\" + r.getVersion());\n              }\n\n              //  sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              IndexSearcher searcher = new IndexSearcher(r);\n              Query q = new TermQuery(new Term(\"id\",Integer.toString(id)));\n              TopDocs results = searcher.search(q, 10);\n\n              if (results.totalHits == 0 && tombstones) {\n                // if we couldn't find the doc, look for its tombstone\n                q = new TermQuery(new Term(\"id\",\"-\"+Integer.toString(id)));\n                results = searcher.search(q, 1);\n                if (results.totalHits == 0) {\n                  if (val == -1L) {\n                    // expected... no doc was added yet\n                    r.decRef();\n                    continue;\n                  }\n                  fail(\"No documents or tombstones found for id \" + id + \", expected at least \" + val + \" reader=\" + r);\n                }\n              }\n\n              if (results.totalHits == 0 && !tombstones) {\n                // nothing to do - we can't tell anything from a deleted doc without tombstones\n              } else {\n                // we should have found the document, or its tombstone\n                if (results.totalHits != 1) {\n                  System.out.println(\"FAIL: hits id:\" + id + \" val=\" + val);\n                  for(ScoreDoc sd : results.scoreDocs) {\n                    final Document doc = r.document(sd.doc);\n                    System.out.println(\"  docID=\" + sd.doc + \" id:\" + doc.get(\"id\") + \" foundVal=\" + doc.get(field));\n                  }\n                  fail(\"id=\" + id + \" reader=\" + r + \" totalHits=\" + results.totalHits);\n                }\n                Document doc = searcher.doc(results.scoreDocs[0].doc);\n                long foundVal = Long.parseLong(doc.get(field));\n                if (foundVal < Math.abs(val)) {\n                  fail(\"foundVal=\" + foundVal + \" val=\" + val + \" id=\" + id + \" reader=\" + r);\n                }\n              }\n\n              r.decRef();\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    writer.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: close reader=\" + reader);\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    // update variables\n    final int commitPercent = random.nextInt(20);\n    final int softCommitPercent = random.nextInt(100); // what percent of the commits are soft\n    final int deletePercent = random.nextInt(50);\n    final int deleteByQueryPercent = random.nextInt(25);\n    final int ndocs = atLeast(50);\n    final int nWriteThreads = _TestUtil.nextInt(random, 1, TEST_NIGHTLY ? 10 : 5);\n    final int maxConcurrentCommits = _TestUtil.nextInt(random, 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n    \n    final boolean tombstones = random.nextBoolean();\n\n    // query variables\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n\n    final int nReadThreads = _TestUtil.nextInt(random, 1, TEST_NIGHTLY ? 10 : 5);\n    initModel(ndocs);\n\n    final FieldType storedOnlyType = new FieldType();\n    storedOnlyType.setStored(true);\n\n    if (VERBOSE) {\n      System.out.println(\"\\n\");\n      System.out.println(\"TEST: commitPercent=\" + commitPercent);\n      System.out.println(\"TEST: softCommitPercent=\" + softCommitPercent);\n      System.out.println(\"TEST: deletePercent=\" + deletePercent);\n      System.out.println(\"TEST: deleteByQueryPercent=\" + deleteByQueryPercent);\n      System.out.println(\"TEST: ndocs=\" + ndocs);\n      System.out.println(\"TEST: nWriteThreads=\" + nWriteThreads);\n      System.out.println(\"TEST: nReadThreads=\" + nReadThreads);\n      System.out.println(\"TEST: maxConcurrentCommits=\" + maxConcurrentCommits);\n      System.out.println(\"TEST: tombstones=\" + tombstones);\n      System.out.println(\"TEST: operations=\" + operations);\n      System.out.println(\"\\n\");\n    }\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    Directory dir = newDirectory();\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random, dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.setDoRandomForceMergeAssert(false);\n    writer.commit();\n    reader = IndexReader.open(dir);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n                  DirectoryReader oldReader;\n\n                  synchronized(TestStressNRT.this) {\n                    newCommittedModel = new HashMap<Integer,Long>(model);  // take a snapshot\n                    version = snapshotCount++;\n                    oldReader = reader;\n                    oldReader.incRef();  // increment the reference since we will use this for reopening\n                  }\n\n                  DirectoryReader newReader;\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    // assertU(h.commit(\"softCommit\",\"true\"));\n                    if (random.nextBoolean()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": call writer.getReader\");\n                      }\n                      newReader = writer.getReader(true);\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": reopen reader=\" + oldReader + \" version=\" + version);\n                      }\n                      newReader = DirectoryReader.openIfChanged(oldReader, writer.w, true);\n                    }\n                  } else {\n                    // assertU(commit());\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": commit+reopen reader=\" + oldReader + \" version=\" + version);\n                    }\n                    writer.commit();\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": now reopen after commit\");\n                    }\n                    newReader = DirectoryReader.openIfChanged(oldReader);\n                  }\n\n                  // Code below assumes newReader comes w/\n                  // extra ref:\n                  if (newReader == null) {\n                    oldReader.incRef();\n                    newReader = oldReader;\n                  }\n\n                  oldReader.decRef();\n\n                  synchronized(TestStressNRT.this) {\n                    // install the new reader if it's newest (and check the current version since another reader may have already been installed)\n                    //System.out.println(Thread.currentThread().getName() + \": newVersion=\" + newReader.getVersion());\n                    assert newReader.getRefCount() > 0;\n                    assert reader.getRefCount() > 0;\n                    if (newReader.getVersion() > reader.getVersion()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new reader=\" + newReader);\n                      }\n                      reader.decRef();\n                      reader = newReader;\n\n                      // Silly: forces fieldInfos to be\n                      // loaded so we don't hit IOE on later\n                      // reader.toString\n                      newReader.toString();\n\n                      // install this snapshot only if it's newer than the current one\n                      if (version >= committedModelClock) {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new model version=\" + version);\n                        }\n                        committedModel = newCommittedModel;\n                        committedModelClock = version;\n                      } else {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new model version=\" + version);\n                        }\n                      }\n                    } else {\n                      // if the same reader, don't decRef.\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new reader=\" + newReader);\n                      }\n                      newReader.decRef();\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else {\n\n                int id = rand.nextInt(ndocs);\n                Object sync = syncArr[id];\n\n                // set the lastId before we actually change it sometimes to try and\n                // uncover more race conditions between writing and reading\n                boolean before = random.nextBoolean();\n                if (before) {\n                  lastId = id;\n                }\n\n                // We can't concurrently update the same document and retain our invariants of increasing values\n                // since we can't guarantee what order the updates will be executed.\n                synchronized (sync) {\n                  Long val = model.get(id);\n                  long nextVal = Math.abs(val)+1;\n\n                  if (oper < commitPercent + deletePercent) {\n                    // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newField(\"id\", \"-\"+Integer.toString(id), StringField.TYPE_STORED));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": term delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new Term(\"id\",Integer.toString(id)));\n                    model.put(id, -nextVal);\n                  } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                    //assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newField(\"id\", \"-\"+Integer.toString(id), StringField.TYPE_STORED));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": query delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new TermQuery(new Term(\"id\", Integer.toString(id))));\n                    model.put(id, -nextVal);\n                  } else {\n                    // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                    Document d = new Document();\n                    d.add(newField(\"id\", Integer.toString(id), StringField.TYPE_STORED));\n                    d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": u id:\" + id + \" val=\" + nextVal);\n                    }\n                    writer.updateDocument(new Term(\"id\", Integer.toString(id)), d);\n                    if (tombstones) {\n                      // remove tombstone after new addition (this should be optional?)\n                      writer.deleteDocuments(new Term(\"id\",\"-\"+Integer.toString(id)));\n                    }\n                    model.put(id, nextVal);\n                  }\n                }\n\n                if (!before) {\n                  lastId = id;\n                }\n              }\n            }\n          } catch (Throwable e) {\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              long val;\n              DirectoryReader r;\n              synchronized(TestStressNRT.this) {\n                val = committedModel.get(id);\n                r = reader;\n                r.incRef();\n              }\n\n              if (VERBOSE) {\n                System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": s id=\" + id + \" val=\" + val + \" r=\" + r.getVersion());\n              }\n\n              //  sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              IndexSearcher searcher = new IndexSearcher(r);\n              Query q = new TermQuery(new Term(\"id\",Integer.toString(id)));\n              TopDocs results = searcher.search(q, 10);\n\n              if (results.totalHits == 0 && tombstones) {\n                // if we couldn't find the doc, look for its tombstone\n                q = new TermQuery(new Term(\"id\",\"-\"+Integer.toString(id)));\n                results = searcher.search(q, 1);\n                if (results.totalHits == 0) {\n                  if (val == -1L) {\n                    // expected... no doc was added yet\n                    r.decRef();\n                    continue;\n                  }\n                  fail(\"No documents or tombstones found for id \" + id + \", expected at least \" + val + \" reader=\" + r);\n                }\n              }\n\n              if (results.totalHits == 0 && !tombstones) {\n                // nothing to do - we can't tell anything from a deleted doc without tombstones\n              } else {\n                // we should have found the document, or its tombstone\n                if (results.totalHits != 1) {\n                  System.out.println(\"FAIL: hits id:\" + id + \" val=\" + val);\n                  for(ScoreDoc sd : results.scoreDocs) {\n                    final Document doc = r.document(sd.doc);\n                    System.out.println(\"  docID=\" + sd.doc + \" id:\" + doc.get(\"id\") + \" foundVal=\" + doc.get(field));\n                  }\n                  fail(\"id=\" + id + \" reader=\" + r + \" totalHits=\" + results.totalHits);\n                }\n                Document doc = searcher.doc(results.scoreDocs[0].doc);\n                long foundVal = Long.parseLong(doc.get(field));\n                if (foundVal < Math.abs(val)) {\n                  fail(\"foundVal=\" + foundVal + \" val=\" + val + \" id=\" + id + \" reader=\" + r);\n                }\n              }\n\n              r.decRef();\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    writer.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: close reader=\" + reader);\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f","date":1338430031,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestStressNRT#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestStressNRT#test().mjava","sourceNew":"  public void test() throws Exception {\n    // update variables\n    final int commitPercent = random().nextInt(20);\n    final int softCommitPercent = random().nextInt(100); // what percent of the commits are soft\n    final int deletePercent = random().nextInt(50);\n    final int deleteByQueryPercent = random().nextInt(25);\n    final int ndocs = atLeast(50);\n    final int nWriteThreads = _TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    final int maxConcurrentCommits = _TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n    \n    final boolean tombstones = random().nextBoolean();\n\n    // query variables\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n\n    final int nReadThreads = _TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    initModel(ndocs);\n\n    final FieldType storedOnlyType = new FieldType();\n    storedOnlyType.setStored(true);\n\n    if (VERBOSE) {\n      System.out.println(\"\\n\");\n      System.out.println(\"TEST: commitPercent=\" + commitPercent);\n      System.out.println(\"TEST: softCommitPercent=\" + softCommitPercent);\n      System.out.println(\"TEST: deletePercent=\" + deletePercent);\n      System.out.println(\"TEST: deleteByQueryPercent=\" + deleteByQueryPercent);\n      System.out.println(\"TEST: ndocs=\" + ndocs);\n      System.out.println(\"TEST: nWriteThreads=\" + nWriteThreads);\n      System.out.println(\"TEST: nReadThreads=\" + nReadThreads);\n      System.out.println(\"TEST: maxConcurrentCommits=\" + maxConcurrentCommits);\n      System.out.println(\"TEST: tombstones=\" + tombstones);\n      System.out.println(\"TEST: operations=\" + operations);\n      System.out.println(\"\\n\");\n    }\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    Directory dir = newDirectory();\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    writer.setDoRandomForceMergeAssert(false);\n    writer.commit();\n    reader = DirectoryReader.open(dir);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n                  DirectoryReader oldReader;\n\n                  synchronized(TestStressNRT.this) {\n                    newCommittedModel = new HashMap<Integer,Long>(model);  // take a snapshot\n                    version = snapshotCount++;\n                    oldReader = reader;\n                    oldReader.incRef();  // increment the reference since we will use this for reopening\n                  }\n\n                  DirectoryReader newReader;\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    // assertU(h.commit(\"softCommit\",\"true\"));\n                    if (random().nextBoolean()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": call writer.getReader\");\n                      }\n                      newReader = writer.getReader(true);\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": reopen reader=\" + oldReader + \" version=\" + version);\n                      }\n                      newReader = DirectoryReader.openIfChanged(oldReader, writer.w, true);\n                    }\n                  } else {\n                    // assertU(commit());\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": commit+reopen reader=\" + oldReader + \" version=\" + version);\n                    }\n                    writer.commit();\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": now reopen after commit\");\n                    }\n                    newReader = DirectoryReader.openIfChanged(oldReader);\n                  }\n\n                  // Code below assumes newReader comes w/\n                  // extra ref:\n                  if (newReader == null) {\n                    oldReader.incRef();\n                    newReader = oldReader;\n                  }\n\n                  oldReader.decRef();\n\n                  synchronized(TestStressNRT.this) {\n                    // install the new reader if it's newest (and check the current version since another reader may have already been installed)\n                    //System.out.println(Thread.currentThread().getName() + \": newVersion=\" + newReader.getVersion());\n                    assert newReader.getRefCount() > 0;\n                    assert reader.getRefCount() > 0;\n                    if (newReader.getVersion() > reader.getVersion()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new reader=\" + newReader);\n                      }\n                      reader.decRef();\n                      reader = newReader;\n\n                      // Silly: forces fieldInfos to be\n                      // loaded so we don't hit IOE on later\n                      // reader.toString\n                      newReader.toString();\n\n                      // install this snapshot only if it's newer than the current one\n                      if (version >= committedModelClock) {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new model version=\" + version);\n                        }\n                        committedModel = newCommittedModel;\n                        committedModelClock = version;\n                      } else {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new model version=\" + version);\n                        }\n                      }\n                    } else {\n                      // if the same reader, don't decRef.\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new reader=\" + newReader);\n                      }\n                      newReader.decRef();\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else {\n\n                int id = rand.nextInt(ndocs);\n                Object sync = syncArr[id];\n\n                // set the lastId before we actually change it sometimes to try and\n                // uncover more race conditions between writing and reading\n                boolean before = random().nextBoolean();\n                if (before) {\n                  lastId = id;\n                }\n\n                // We can't concurrently update the same document and retain our invariants of increasing values\n                // since we can't guarantee what order the updates will be executed.\n                synchronized (sync) {\n                  Long val = model.get(id);\n                  long nextVal = Math.abs(val)+1;\n\n                  if (oper < commitPercent + deletePercent) {\n                    // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newField(\"id\", \"-\"+Integer.toString(id), StringField.TYPE_STORED));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": term delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new Term(\"id\",Integer.toString(id)));\n                    model.put(id, -nextVal);\n                  } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                    //assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newField(\"id\", \"-\"+Integer.toString(id), StringField.TYPE_STORED));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": query delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new TermQuery(new Term(\"id\", Integer.toString(id))));\n                    model.put(id, -nextVal);\n                  } else {\n                    // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                    Document d = new Document();\n                    d.add(newField(\"id\", Integer.toString(id), StringField.TYPE_STORED));\n                    d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": u id:\" + id + \" val=\" + nextVal);\n                    }\n                    writer.updateDocument(new Term(\"id\", Integer.toString(id)), d);\n                    if (tombstones) {\n                      // remove tombstone after new addition (this should be optional?)\n                      writer.deleteDocuments(new Term(\"id\",\"-\"+Integer.toString(id)));\n                    }\n                    model.put(id, nextVal);\n                  }\n                }\n\n                if (!before) {\n                  lastId = id;\n                }\n              }\n            }\n          } catch (Throwable e) {\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              long val;\n              DirectoryReader r;\n              synchronized(TestStressNRT.this) {\n                val = committedModel.get(id);\n                r = reader;\n                r.incRef();\n              }\n\n              if (VERBOSE) {\n                System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": s id=\" + id + \" val=\" + val + \" r=\" + r.getVersion());\n              }\n\n              //  sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              IndexSearcher searcher = new IndexSearcher(r);\n              Query q = new TermQuery(new Term(\"id\",Integer.toString(id)));\n              TopDocs results = searcher.search(q, 10);\n\n              if (results.totalHits == 0 && tombstones) {\n                // if we couldn't find the doc, look for its tombstone\n                q = new TermQuery(new Term(\"id\",\"-\"+Integer.toString(id)));\n                results = searcher.search(q, 1);\n                if (results.totalHits == 0) {\n                  if (val == -1L) {\n                    // expected... no doc was added yet\n                    r.decRef();\n                    continue;\n                  }\n                  fail(\"No documents or tombstones found for id \" + id + \", expected at least \" + val + \" reader=\" + r);\n                }\n              }\n\n              if (results.totalHits == 0 && !tombstones) {\n                // nothing to do - we can't tell anything from a deleted doc without tombstones\n              } else {\n                // we should have found the document, or its tombstone\n                if (results.totalHits != 1) {\n                  System.out.println(\"FAIL: hits id:\" + id + \" val=\" + val);\n                  for(ScoreDoc sd : results.scoreDocs) {\n                    final Document doc = r.document(sd.doc);\n                    System.out.println(\"  docID=\" + sd.doc + \" id:\" + doc.get(\"id\") + \" foundVal=\" + doc.get(field));\n                  }\n                  fail(\"id=\" + id + \" reader=\" + r + \" totalHits=\" + results.totalHits);\n                }\n                Document doc = searcher.doc(results.scoreDocs[0].doc);\n                long foundVal = Long.parseLong(doc.get(field));\n                if (foundVal < Math.abs(val)) {\n                  fail(\"foundVal=\" + foundVal + \" val=\" + val + \" id=\" + id + \" reader=\" + r);\n                }\n              }\n\n              r.decRef();\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    writer.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: close reader=\" + reader);\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    // update variables\n    final int commitPercent = random().nextInt(20);\n    final int softCommitPercent = random().nextInt(100); // what percent of the commits are soft\n    final int deletePercent = random().nextInt(50);\n    final int deleteByQueryPercent = random().nextInt(25);\n    final int ndocs = atLeast(50);\n    final int nWriteThreads = _TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    final int maxConcurrentCommits = _TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n    \n    final boolean tombstones = random().nextBoolean();\n\n    // query variables\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n\n    final int nReadThreads = _TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    initModel(ndocs);\n\n    final FieldType storedOnlyType = new FieldType();\n    storedOnlyType.setStored(true);\n\n    if (VERBOSE) {\n      System.out.println(\"\\n\");\n      System.out.println(\"TEST: commitPercent=\" + commitPercent);\n      System.out.println(\"TEST: softCommitPercent=\" + softCommitPercent);\n      System.out.println(\"TEST: deletePercent=\" + deletePercent);\n      System.out.println(\"TEST: deleteByQueryPercent=\" + deleteByQueryPercent);\n      System.out.println(\"TEST: ndocs=\" + ndocs);\n      System.out.println(\"TEST: nWriteThreads=\" + nWriteThreads);\n      System.out.println(\"TEST: nReadThreads=\" + nReadThreads);\n      System.out.println(\"TEST: maxConcurrentCommits=\" + maxConcurrentCommits);\n      System.out.println(\"TEST: tombstones=\" + tombstones);\n      System.out.println(\"TEST: operations=\" + operations);\n      System.out.println(\"\\n\");\n    }\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    Directory dir = newDirectory();\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    writer.setDoRandomForceMergeAssert(false);\n    writer.commit();\n    reader = IndexReader.open(dir);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n                  DirectoryReader oldReader;\n\n                  synchronized(TestStressNRT.this) {\n                    newCommittedModel = new HashMap<Integer,Long>(model);  // take a snapshot\n                    version = snapshotCount++;\n                    oldReader = reader;\n                    oldReader.incRef();  // increment the reference since we will use this for reopening\n                  }\n\n                  DirectoryReader newReader;\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    // assertU(h.commit(\"softCommit\",\"true\"));\n                    if (random().nextBoolean()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": call writer.getReader\");\n                      }\n                      newReader = writer.getReader(true);\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": reopen reader=\" + oldReader + \" version=\" + version);\n                      }\n                      newReader = DirectoryReader.openIfChanged(oldReader, writer.w, true);\n                    }\n                  } else {\n                    // assertU(commit());\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": commit+reopen reader=\" + oldReader + \" version=\" + version);\n                    }\n                    writer.commit();\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": now reopen after commit\");\n                    }\n                    newReader = DirectoryReader.openIfChanged(oldReader);\n                  }\n\n                  // Code below assumes newReader comes w/\n                  // extra ref:\n                  if (newReader == null) {\n                    oldReader.incRef();\n                    newReader = oldReader;\n                  }\n\n                  oldReader.decRef();\n\n                  synchronized(TestStressNRT.this) {\n                    // install the new reader if it's newest (and check the current version since another reader may have already been installed)\n                    //System.out.println(Thread.currentThread().getName() + \": newVersion=\" + newReader.getVersion());\n                    assert newReader.getRefCount() > 0;\n                    assert reader.getRefCount() > 0;\n                    if (newReader.getVersion() > reader.getVersion()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new reader=\" + newReader);\n                      }\n                      reader.decRef();\n                      reader = newReader;\n\n                      // Silly: forces fieldInfos to be\n                      // loaded so we don't hit IOE on later\n                      // reader.toString\n                      newReader.toString();\n\n                      // install this snapshot only if it's newer than the current one\n                      if (version >= committedModelClock) {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new model version=\" + version);\n                        }\n                        committedModel = newCommittedModel;\n                        committedModelClock = version;\n                      } else {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new model version=\" + version);\n                        }\n                      }\n                    } else {\n                      // if the same reader, don't decRef.\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new reader=\" + newReader);\n                      }\n                      newReader.decRef();\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else {\n\n                int id = rand.nextInt(ndocs);\n                Object sync = syncArr[id];\n\n                // set the lastId before we actually change it sometimes to try and\n                // uncover more race conditions between writing and reading\n                boolean before = random().nextBoolean();\n                if (before) {\n                  lastId = id;\n                }\n\n                // We can't concurrently update the same document and retain our invariants of increasing values\n                // since we can't guarantee what order the updates will be executed.\n                synchronized (sync) {\n                  Long val = model.get(id);\n                  long nextVal = Math.abs(val)+1;\n\n                  if (oper < commitPercent + deletePercent) {\n                    // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newField(\"id\", \"-\"+Integer.toString(id), StringField.TYPE_STORED));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": term delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new Term(\"id\",Integer.toString(id)));\n                    model.put(id, -nextVal);\n                  } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                    //assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newField(\"id\", \"-\"+Integer.toString(id), StringField.TYPE_STORED));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": query delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new TermQuery(new Term(\"id\", Integer.toString(id))));\n                    model.put(id, -nextVal);\n                  } else {\n                    // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                    Document d = new Document();\n                    d.add(newField(\"id\", Integer.toString(id), StringField.TYPE_STORED));\n                    d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": u id:\" + id + \" val=\" + nextVal);\n                    }\n                    writer.updateDocument(new Term(\"id\", Integer.toString(id)), d);\n                    if (tombstones) {\n                      // remove tombstone after new addition (this should be optional?)\n                      writer.deleteDocuments(new Term(\"id\",\"-\"+Integer.toString(id)));\n                    }\n                    model.put(id, nextVal);\n                  }\n                }\n\n                if (!before) {\n                  lastId = id;\n                }\n              }\n            }\n          } catch (Throwable e) {\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              long val;\n              DirectoryReader r;\n              synchronized(TestStressNRT.this) {\n                val = committedModel.get(id);\n                r = reader;\n                r.incRef();\n              }\n\n              if (VERBOSE) {\n                System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": s id=\" + id + \" val=\" + val + \" r=\" + r.getVersion());\n              }\n\n              //  sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              IndexSearcher searcher = new IndexSearcher(r);\n              Query q = new TermQuery(new Term(\"id\",Integer.toString(id)));\n              TopDocs results = searcher.search(q, 10);\n\n              if (results.totalHits == 0 && tombstones) {\n                // if we couldn't find the doc, look for its tombstone\n                q = new TermQuery(new Term(\"id\",\"-\"+Integer.toString(id)));\n                results = searcher.search(q, 1);\n                if (results.totalHits == 0) {\n                  if (val == -1L) {\n                    // expected... no doc was added yet\n                    r.decRef();\n                    continue;\n                  }\n                  fail(\"No documents or tombstones found for id \" + id + \", expected at least \" + val + \" reader=\" + r);\n                }\n              }\n\n              if (results.totalHits == 0 && !tombstones) {\n                // nothing to do - we can't tell anything from a deleted doc without tombstones\n              } else {\n                // we should have found the document, or its tombstone\n                if (results.totalHits != 1) {\n                  System.out.println(\"FAIL: hits id:\" + id + \" val=\" + val);\n                  for(ScoreDoc sd : results.scoreDocs) {\n                    final Document doc = r.document(sd.doc);\n                    System.out.println(\"  docID=\" + sd.doc + \" id:\" + doc.get(\"id\") + \" foundVal=\" + doc.get(field));\n                  }\n                  fail(\"id=\" + id + \" reader=\" + r + \" totalHits=\" + results.totalHits);\n                }\n                Document doc = searcher.doc(results.scoreDocs[0].doc);\n                long foundVal = Long.parseLong(doc.get(field));\n                if (foundVal < Math.abs(val)) {\n                  fail(\"foundVal=\" + foundVal + \" val=\" + val + \" id=\" + id + \" reader=\" + r);\n                }\n              }\n\n              r.decRef();\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    writer.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: close reader=\" + reader);\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"04f07771a2a7dd3a395700665ed839c3dae2def2","date":1339350139,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestStressNRT#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestStressNRT#test().mjava","sourceNew":"  public void test() throws Exception {\n    // update variables\n    final int commitPercent = random().nextInt(20);\n    final int softCommitPercent = random().nextInt(100); // what percent of the commits are soft\n    final int deletePercent = random().nextInt(50);\n    final int deleteByQueryPercent = random().nextInt(25);\n    final int ndocs = atLeast(50);\n    final int nWriteThreads = _TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    final int maxConcurrentCommits = _TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n    \n    final boolean tombstones = random().nextBoolean();\n\n    // query variables\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n\n    final int nReadThreads = _TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    initModel(ndocs);\n\n    final FieldType storedOnlyType = new FieldType();\n    storedOnlyType.setStored(true);\n\n    if (VERBOSE) {\n      System.out.println(\"\\n\");\n      System.out.println(\"TEST: commitPercent=\" + commitPercent);\n      System.out.println(\"TEST: softCommitPercent=\" + softCommitPercent);\n      System.out.println(\"TEST: deletePercent=\" + deletePercent);\n      System.out.println(\"TEST: deleteByQueryPercent=\" + deleteByQueryPercent);\n      System.out.println(\"TEST: ndocs=\" + ndocs);\n      System.out.println(\"TEST: nWriteThreads=\" + nWriteThreads);\n      System.out.println(\"TEST: nReadThreads=\" + nReadThreads);\n      System.out.println(\"TEST: maxConcurrentCommits=\" + maxConcurrentCommits);\n      System.out.println(\"TEST: tombstones=\" + tombstones);\n      System.out.println(\"TEST: operations=\" + operations);\n      System.out.println(\"\\n\");\n    }\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    Directory dir = newDirectory();\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    writer.setDoRandomForceMergeAssert(false);\n    writer.commit();\n    reader = DirectoryReader.open(dir);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n                  DirectoryReader oldReader;\n\n                  synchronized(TestStressNRT.this) {\n                    newCommittedModel = new HashMap<Integer,Long>(model);  // take a snapshot\n                    version = snapshotCount++;\n                    oldReader = reader;\n                    oldReader.incRef();  // increment the reference since we will use this for reopening\n                  }\n\n                  DirectoryReader newReader;\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    // assertU(h.commit(\"softCommit\",\"true\"));\n                    if (random().nextBoolean()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": call writer.getReader\");\n                      }\n                      newReader = writer.getReader(true);\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": reopen reader=\" + oldReader + \" version=\" + version);\n                      }\n                      newReader = DirectoryReader.openIfChanged(oldReader, writer.w, true);\n                    }\n                  } else {\n                    // assertU(commit());\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": commit+reopen reader=\" + oldReader + \" version=\" + version);\n                    }\n                    writer.commit();\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": now reopen after commit\");\n                    }\n                    newReader = DirectoryReader.openIfChanged(oldReader);\n                  }\n\n                  // Code below assumes newReader comes w/\n                  // extra ref:\n                  if (newReader == null) {\n                    oldReader.incRef();\n                    newReader = oldReader;\n                  }\n\n                  oldReader.decRef();\n\n                  synchronized(TestStressNRT.this) {\n                    // install the new reader if it's newest (and check the current version since another reader may have already been installed)\n                    //System.out.println(Thread.currentThread().getName() + \": newVersion=\" + newReader.getVersion());\n                    assert newReader.getRefCount() > 0;\n                    assert reader.getRefCount() > 0;\n                    if (newReader.getVersion() > reader.getVersion()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new reader=\" + newReader);\n                      }\n                      reader.decRef();\n                      reader = newReader;\n\n                      // Silly: forces fieldInfos to be\n                      // loaded so we don't hit IOE on later\n                      // reader.toString\n                      newReader.toString();\n\n                      // install this snapshot only if it's newer than the current one\n                      if (version >= committedModelClock) {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new model version=\" + version);\n                        }\n                        committedModel = newCommittedModel;\n                        committedModelClock = version;\n                      } else {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new model version=\" + version);\n                        }\n                      }\n                    } else {\n                      // if the same reader, don't decRef.\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new reader=\" + newReader);\n                      }\n                      newReader.decRef();\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else {\n\n                int id = rand.nextInt(ndocs);\n                Object sync = syncArr[id];\n\n                // set the lastId before we actually change it sometimes to try and\n                // uncover more race conditions between writing and reading\n                boolean before = random().nextBoolean();\n                if (before) {\n                  lastId = id;\n                }\n\n                // We can't concurrently update the same document and retain our invariants of increasing values\n                // since we can't guarantee what order the updates will be executed.\n                synchronized (sync) {\n                  Long val = model.get(id);\n                  long nextVal = Math.abs(val)+1;\n\n                  if (oper < commitPercent + deletePercent) {\n                    // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": term delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new Term(\"id\",Integer.toString(id)));\n                    model.put(id, -nextVal);\n                  } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                    //assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": query delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new TermQuery(new Term(\"id\", Integer.toString(id))));\n                    model.put(id, -nextVal);\n                  } else {\n                    // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                    Document d = new Document();\n                    d.add(newStringField(\"id\", Integer.toString(id), Field.Store.YES));\n                    d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": u id:\" + id + \" val=\" + nextVal);\n                    }\n                    writer.updateDocument(new Term(\"id\", Integer.toString(id)), d);\n                    if (tombstones) {\n                      // remove tombstone after new addition (this should be optional?)\n                      writer.deleteDocuments(new Term(\"id\",\"-\"+Integer.toString(id)));\n                    }\n                    model.put(id, nextVal);\n                  }\n                }\n\n                if (!before) {\n                  lastId = id;\n                }\n              }\n            }\n          } catch (Throwable e) {\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              long val;\n              DirectoryReader r;\n              synchronized(TestStressNRT.this) {\n                val = committedModel.get(id);\n                r = reader;\n                r.incRef();\n              }\n\n              if (VERBOSE) {\n                System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": s id=\" + id + \" val=\" + val + \" r=\" + r.getVersion());\n              }\n\n              //  sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              IndexSearcher searcher = new IndexSearcher(r);\n              Query q = new TermQuery(new Term(\"id\",Integer.toString(id)));\n              TopDocs results = searcher.search(q, 10);\n\n              if (results.totalHits == 0 && tombstones) {\n                // if we couldn't find the doc, look for its tombstone\n                q = new TermQuery(new Term(\"id\",\"-\"+Integer.toString(id)));\n                results = searcher.search(q, 1);\n                if (results.totalHits == 0) {\n                  if (val == -1L) {\n                    // expected... no doc was added yet\n                    r.decRef();\n                    continue;\n                  }\n                  fail(\"No documents or tombstones found for id \" + id + \", expected at least \" + val + \" reader=\" + r);\n                }\n              }\n\n              if (results.totalHits == 0 && !tombstones) {\n                // nothing to do - we can't tell anything from a deleted doc without tombstones\n              } else {\n                // we should have found the document, or its tombstone\n                if (results.totalHits != 1) {\n                  System.out.println(\"FAIL: hits id:\" + id + \" val=\" + val);\n                  for(ScoreDoc sd : results.scoreDocs) {\n                    final Document doc = r.document(sd.doc);\n                    System.out.println(\"  docID=\" + sd.doc + \" id:\" + doc.get(\"id\") + \" foundVal=\" + doc.get(field));\n                  }\n                  fail(\"id=\" + id + \" reader=\" + r + \" totalHits=\" + results.totalHits);\n                }\n                Document doc = searcher.doc(results.scoreDocs[0].doc);\n                long foundVal = Long.parseLong(doc.get(field));\n                if (foundVal < Math.abs(val)) {\n                  fail(\"foundVal=\" + foundVal + \" val=\" + val + \" id=\" + id + \" reader=\" + r);\n                }\n              }\n\n              r.decRef();\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    writer.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: close reader=\" + reader);\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    // update variables\n    final int commitPercent = random().nextInt(20);\n    final int softCommitPercent = random().nextInt(100); // what percent of the commits are soft\n    final int deletePercent = random().nextInt(50);\n    final int deleteByQueryPercent = random().nextInt(25);\n    final int ndocs = atLeast(50);\n    final int nWriteThreads = _TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    final int maxConcurrentCommits = _TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n    \n    final boolean tombstones = random().nextBoolean();\n\n    // query variables\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n\n    final int nReadThreads = _TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    initModel(ndocs);\n\n    final FieldType storedOnlyType = new FieldType();\n    storedOnlyType.setStored(true);\n\n    if (VERBOSE) {\n      System.out.println(\"\\n\");\n      System.out.println(\"TEST: commitPercent=\" + commitPercent);\n      System.out.println(\"TEST: softCommitPercent=\" + softCommitPercent);\n      System.out.println(\"TEST: deletePercent=\" + deletePercent);\n      System.out.println(\"TEST: deleteByQueryPercent=\" + deleteByQueryPercent);\n      System.out.println(\"TEST: ndocs=\" + ndocs);\n      System.out.println(\"TEST: nWriteThreads=\" + nWriteThreads);\n      System.out.println(\"TEST: nReadThreads=\" + nReadThreads);\n      System.out.println(\"TEST: maxConcurrentCommits=\" + maxConcurrentCommits);\n      System.out.println(\"TEST: tombstones=\" + tombstones);\n      System.out.println(\"TEST: operations=\" + operations);\n      System.out.println(\"\\n\");\n    }\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    Directory dir = newDirectory();\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    writer.setDoRandomForceMergeAssert(false);\n    writer.commit();\n    reader = DirectoryReader.open(dir);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n                  DirectoryReader oldReader;\n\n                  synchronized(TestStressNRT.this) {\n                    newCommittedModel = new HashMap<Integer,Long>(model);  // take a snapshot\n                    version = snapshotCount++;\n                    oldReader = reader;\n                    oldReader.incRef();  // increment the reference since we will use this for reopening\n                  }\n\n                  DirectoryReader newReader;\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    // assertU(h.commit(\"softCommit\",\"true\"));\n                    if (random().nextBoolean()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": call writer.getReader\");\n                      }\n                      newReader = writer.getReader(true);\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": reopen reader=\" + oldReader + \" version=\" + version);\n                      }\n                      newReader = DirectoryReader.openIfChanged(oldReader, writer.w, true);\n                    }\n                  } else {\n                    // assertU(commit());\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": commit+reopen reader=\" + oldReader + \" version=\" + version);\n                    }\n                    writer.commit();\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": now reopen after commit\");\n                    }\n                    newReader = DirectoryReader.openIfChanged(oldReader);\n                  }\n\n                  // Code below assumes newReader comes w/\n                  // extra ref:\n                  if (newReader == null) {\n                    oldReader.incRef();\n                    newReader = oldReader;\n                  }\n\n                  oldReader.decRef();\n\n                  synchronized(TestStressNRT.this) {\n                    // install the new reader if it's newest (and check the current version since another reader may have already been installed)\n                    //System.out.println(Thread.currentThread().getName() + \": newVersion=\" + newReader.getVersion());\n                    assert newReader.getRefCount() > 0;\n                    assert reader.getRefCount() > 0;\n                    if (newReader.getVersion() > reader.getVersion()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new reader=\" + newReader);\n                      }\n                      reader.decRef();\n                      reader = newReader;\n\n                      // Silly: forces fieldInfos to be\n                      // loaded so we don't hit IOE on later\n                      // reader.toString\n                      newReader.toString();\n\n                      // install this snapshot only if it's newer than the current one\n                      if (version >= committedModelClock) {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new model version=\" + version);\n                        }\n                        committedModel = newCommittedModel;\n                        committedModelClock = version;\n                      } else {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new model version=\" + version);\n                        }\n                      }\n                    } else {\n                      // if the same reader, don't decRef.\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new reader=\" + newReader);\n                      }\n                      newReader.decRef();\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else {\n\n                int id = rand.nextInt(ndocs);\n                Object sync = syncArr[id];\n\n                // set the lastId before we actually change it sometimes to try and\n                // uncover more race conditions between writing and reading\n                boolean before = random().nextBoolean();\n                if (before) {\n                  lastId = id;\n                }\n\n                // We can't concurrently update the same document and retain our invariants of increasing values\n                // since we can't guarantee what order the updates will be executed.\n                synchronized (sync) {\n                  Long val = model.get(id);\n                  long nextVal = Math.abs(val)+1;\n\n                  if (oper < commitPercent + deletePercent) {\n                    // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newField(\"id\", \"-\"+Integer.toString(id), StringField.TYPE_STORED));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": term delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new Term(\"id\",Integer.toString(id)));\n                    model.put(id, -nextVal);\n                  } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                    //assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newField(\"id\", \"-\"+Integer.toString(id), StringField.TYPE_STORED));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": query delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new TermQuery(new Term(\"id\", Integer.toString(id))));\n                    model.put(id, -nextVal);\n                  } else {\n                    // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                    Document d = new Document();\n                    d.add(newField(\"id\", Integer.toString(id), StringField.TYPE_STORED));\n                    d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": u id:\" + id + \" val=\" + nextVal);\n                    }\n                    writer.updateDocument(new Term(\"id\", Integer.toString(id)), d);\n                    if (tombstones) {\n                      // remove tombstone after new addition (this should be optional?)\n                      writer.deleteDocuments(new Term(\"id\",\"-\"+Integer.toString(id)));\n                    }\n                    model.put(id, nextVal);\n                  }\n                }\n\n                if (!before) {\n                  lastId = id;\n                }\n              }\n            }\n          } catch (Throwable e) {\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              long val;\n              DirectoryReader r;\n              synchronized(TestStressNRT.this) {\n                val = committedModel.get(id);\n                r = reader;\n                r.incRef();\n              }\n\n              if (VERBOSE) {\n                System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": s id=\" + id + \" val=\" + val + \" r=\" + r.getVersion());\n              }\n\n              //  sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              IndexSearcher searcher = new IndexSearcher(r);\n              Query q = new TermQuery(new Term(\"id\",Integer.toString(id)));\n              TopDocs results = searcher.search(q, 10);\n\n              if (results.totalHits == 0 && tombstones) {\n                // if we couldn't find the doc, look for its tombstone\n                q = new TermQuery(new Term(\"id\",\"-\"+Integer.toString(id)));\n                results = searcher.search(q, 1);\n                if (results.totalHits == 0) {\n                  if (val == -1L) {\n                    // expected... no doc was added yet\n                    r.decRef();\n                    continue;\n                  }\n                  fail(\"No documents or tombstones found for id \" + id + \", expected at least \" + val + \" reader=\" + r);\n                }\n              }\n\n              if (results.totalHits == 0 && !tombstones) {\n                // nothing to do - we can't tell anything from a deleted doc without tombstones\n              } else {\n                // we should have found the document, or its tombstone\n                if (results.totalHits != 1) {\n                  System.out.println(\"FAIL: hits id:\" + id + \" val=\" + val);\n                  for(ScoreDoc sd : results.scoreDocs) {\n                    final Document doc = r.document(sd.doc);\n                    System.out.println(\"  docID=\" + sd.doc + \" id:\" + doc.get(\"id\") + \" foundVal=\" + doc.get(field));\n                  }\n                  fail(\"id=\" + id + \" reader=\" + r + \" totalHits=\" + results.totalHits);\n                }\n                Document doc = searcher.doc(results.scoreDocs[0].doc);\n                long foundVal = Long.parseLong(doc.get(field));\n                if (foundVal < Math.abs(val)) {\n                  fail(\"foundVal=\" + foundVal + \" val=\" + val + \" id=\" + id + \" reader=\" + r);\n                }\n              }\n\n              r.decRef();\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    writer.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: close reader=\" + reader);\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8f0e28f2a7f0f3f0fca1a2ffedaa10c7ac9536c4","date":1341839195,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestStressNRT#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestStressNRT#test().mjava","sourceNew":"  public void test() throws Exception {\n    // update variables\n    final int commitPercent = random().nextInt(20);\n    final int softCommitPercent = random().nextInt(100); // what percent of the commits are soft\n    final int deletePercent = random().nextInt(50);\n    final int deleteByQueryPercent = random().nextInt(25);\n    final int ndocs = atLeast(50);\n    final int nWriteThreads = _TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    final int maxConcurrentCommits = _TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n    \n    final boolean tombstones = random().nextBoolean();\n\n    // query variables\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n\n    final int nReadThreads = _TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    initModel(ndocs);\n\n    final FieldType storedOnlyType = new FieldType();\n    storedOnlyType.setStored(true);\n\n    if (VERBOSE) {\n      System.out.println(\"\\n\");\n      System.out.println(\"TEST: commitPercent=\" + commitPercent);\n      System.out.println(\"TEST: softCommitPercent=\" + softCommitPercent);\n      System.out.println(\"TEST: deletePercent=\" + deletePercent);\n      System.out.println(\"TEST: deleteByQueryPercent=\" + deleteByQueryPercent);\n      System.out.println(\"TEST: ndocs=\" + ndocs);\n      System.out.println(\"TEST: nWriteThreads=\" + nWriteThreads);\n      System.out.println(\"TEST: nReadThreads=\" + nReadThreads);\n      System.out.println(\"TEST: maxConcurrentCommits=\" + maxConcurrentCommits);\n      System.out.println(\"TEST: tombstones=\" + tombstones);\n      System.out.println(\"TEST: operations=\" + operations);\n      System.out.println(\"\\n\");\n    }\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    Directory dir = newDirectory();\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    writer.setDoRandomForceMergeAssert(false);\n    writer.commit();\n    reader = DirectoryReader.open(dir);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n                  DirectoryReader oldReader;\n\n                  synchronized(TestStressNRT.this) {\n                    newCommittedModel = new HashMap<Integer,Long>(model);  // take a snapshot\n                    version = snapshotCount++;\n                    oldReader = reader;\n                    oldReader.incRef();  // increment the reference since we will use this for reopening\n                  }\n\n                  DirectoryReader newReader;\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    // assertU(h.commit(\"softCommit\",\"true\"));\n                    if (random().nextBoolean()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": call writer.getReader\");\n                      }\n                      newReader = writer.getReader(true);\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": reopen reader=\" + oldReader + \" version=\" + version);\n                      }\n                      newReader = DirectoryReader.openIfChanged(oldReader, writer.w, true);\n                    }\n                  } else {\n                    // assertU(commit());\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": commit+reopen reader=\" + oldReader + \" version=\" + version);\n                    }\n                    writer.commit();\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": now reopen after commit\");\n                    }\n                    newReader = DirectoryReader.openIfChanged(oldReader);\n                  }\n\n                  // Code below assumes newReader comes w/\n                  // extra ref:\n                  if (newReader == null) {\n                    oldReader.incRef();\n                    newReader = oldReader;\n                  }\n\n                  oldReader.decRef();\n\n                  synchronized(TestStressNRT.this) {\n                    // install the new reader if it's newest (and check the current version since another reader may have already been installed)\n                    //System.out.println(Thread.currentThread().getName() + \": newVersion=\" + newReader.getVersion());\n                    assert newReader.getRefCount() > 0;\n                    assert reader.getRefCount() > 0;\n                    if (newReader.getVersion() > reader.getVersion()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new reader=\" + newReader);\n                      }\n                      reader.decRef();\n                      reader = newReader;\n\n                      // Silly: forces fieldInfos to be\n                      // loaded so we don't hit IOE on later\n                      // reader.toString\n                      newReader.toString();\n\n                      // install this snapshot only if it's newer than the current one\n                      if (version >= committedModelClock) {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new model version=\" + version);\n                        }\n                        committedModel = newCommittedModel;\n                        committedModelClock = version;\n                      } else {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new model version=\" + version);\n                        }\n                      }\n                    } else {\n                      // if the same reader, don't decRef.\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new reader=\" + newReader);\n                      }\n                      newReader.decRef();\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else {\n\n                int id = rand.nextInt(ndocs);\n                Object sync = syncArr[id];\n\n                // set the lastId before we actually change it sometimes to try and\n                // uncover more race conditions between writing and reading\n                boolean before = random().nextBoolean();\n                if (before) {\n                  lastId = id;\n                }\n\n                // We can't concurrently update the same document and retain our invariants of increasing values\n                // since we can't guarantee what order the updates will be executed.\n                synchronized (sync) {\n                  Long val = model.get(id);\n                  long nextVal = Math.abs(val)+1;\n\n                  if (oper < commitPercent + deletePercent) {\n                    // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": term delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new Term(\"id\",Integer.toString(id)));\n                    model.put(id, -nextVal);\n                  } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                    //assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": query delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new TermQuery(new Term(\"id\", Integer.toString(id))));\n                    model.put(id, -nextVal);\n                  } else {\n                    // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                    Document d = new Document();\n                    d.add(newStringField(\"id\", Integer.toString(id), Field.Store.YES));\n                    d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": u id:\" + id + \" val=\" + nextVal);\n                    }\n                    writer.updateDocument(new Term(\"id\", Integer.toString(id)), d);\n                    if (tombstones) {\n                      // remove tombstone after new addition (this should be optional?)\n                      writer.deleteDocuments(new Term(\"id\",\"-\"+Integer.toString(id)));\n                    }\n                    model.put(id, nextVal);\n                  }\n                }\n\n                if (!before) {\n                  lastId = id;\n                }\n              }\n            }\n          } catch (Throwable e) {\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              long val;\n              DirectoryReader r;\n              synchronized(TestStressNRT.this) {\n                val = committedModel.get(id);\n                r = reader;\n                r.incRef();\n              }\n\n              if (VERBOSE) {\n                System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": s id=\" + id + \" val=\" + val + \" r=\" + r.getVersion());\n              }\n\n              //  sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              IndexSearcher searcher = new IndexSearcher(r);\n              Query q = new TermQuery(new Term(\"id\",Integer.toString(id)));\n              TopDocs results = searcher.search(q, 10);\n\n              if (results.totalHits == 0 && tombstones) {\n                // if we couldn't find the doc, look for its tombstone\n                q = new TermQuery(new Term(\"id\",\"-\"+Integer.toString(id)));\n                results = searcher.search(q, 1);\n                if (results.totalHits == 0) {\n                  if (val == -1L) {\n                    // expected... no doc was added yet\n                    r.decRef();\n                    continue;\n                  }\n                  fail(\"No documents or tombstones found for id \" + id + \", expected at least \" + val + \" reader=\" + r);\n                }\n              }\n\n              if (results.totalHits == 0 && !tombstones) {\n                // nothing to do - we can't tell anything from a deleted doc without tombstones\n              } else {\n                // we should have found the document, or its tombstone\n                if (results.totalHits != 1) {\n                  System.out.println(\"FAIL: hits id:\" + id + \" val=\" + val);\n                  for(ScoreDoc sd : results.scoreDocs) {\n                    final StoredDocument doc = r.document(sd.doc);\n                    System.out.println(\"  docID=\" + sd.doc + \" id:\" + doc.get(\"id\") + \" foundVal=\" + doc.get(field));\n                  }\n                  fail(\"id=\" + id + \" reader=\" + r + \" totalHits=\" + results.totalHits);\n                }\n                StoredDocument doc = searcher.doc(results.scoreDocs[0].doc);\n                long foundVal = Long.parseLong(doc.get(field));\n                if (foundVal < Math.abs(val)) {\n                  fail(\"foundVal=\" + foundVal + \" val=\" + val + \" id=\" + id + \" reader=\" + r);\n                }\n              }\n\n              r.decRef();\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    writer.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: close reader=\" + reader);\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    // update variables\n    final int commitPercent = random().nextInt(20);\n    final int softCommitPercent = random().nextInt(100); // what percent of the commits are soft\n    final int deletePercent = random().nextInt(50);\n    final int deleteByQueryPercent = random().nextInt(25);\n    final int ndocs = atLeast(50);\n    final int nWriteThreads = _TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    final int maxConcurrentCommits = _TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n    \n    final boolean tombstones = random().nextBoolean();\n\n    // query variables\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n\n    final int nReadThreads = _TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    initModel(ndocs);\n\n    final FieldType storedOnlyType = new FieldType();\n    storedOnlyType.setStored(true);\n\n    if (VERBOSE) {\n      System.out.println(\"\\n\");\n      System.out.println(\"TEST: commitPercent=\" + commitPercent);\n      System.out.println(\"TEST: softCommitPercent=\" + softCommitPercent);\n      System.out.println(\"TEST: deletePercent=\" + deletePercent);\n      System.out.println(\"TEST: deleteByQueryPercent=\" + deleteByQueryPercent);\n      System.out.println(\"TEST: ndocs=\" + ndocs);\n      System.out.println(\"TEST: nWriteThreads=\" + nWriteThreads);\n      System.out.println(\"TEST: nReadThreads=\" + nReadThreads);\n      System.out.println(\"TEST: maxConcurrentCommits=\" + maxConcurrentCommits);\n      System.out.println(\"TEST: tombstones=\" + tombstones);\n      System.out.println(\"TEST: operations=\" + operations);\n      System.out.println(\"\\n\");\n    }\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    Directory dir = newDirectory();\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    writer.setDoRandomForceMergeAssert(false);\n    writer.commit();\n    reader = DirectoryReader.open(dir);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n                  DirectoryReader oldReader;\n\n                  synchronized(TestStressNRT.this) {\n                    newCommittedModel = new HashMap<Integer,Long>(model);  // take a snapshot\n                    version = snapshotCount++;\n                    oldReader = reader;\n                    oldReader.incRef();  // increment the reference since we will use this for reopening\n                  }\n\n                  DirectoryReader newReader;\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    // assertU(h.commit(\"softCommit\",\"true\"));\n                    if (random().nextBoolean()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": call writer.getReader\");\n                      }\n                      newReader = writer.getReader(true);\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": reopen reader=\" + oldReader + \" version=\" + version);\n                      }\n                      newReader = DirectoryReader.openIfChanged(oldReader, writer.w, true);\n                    }\n                  } else {\n                    // assertU(commit());\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": commit+reopen reader=\" + oldReader + \" version=\" + version);\n                    }\n                    writer.commit();\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": now reopen after commit\");\n                    }\n                    newReader = DirectoryReader.openIfChanged(oldReader);\n                  }\n\n                  // Code below assumes newReader comes w/\n                  // extra ref:\n                  if (newReader == null) {\n                    oldReader.incRef();\n                    newReader = oldReader;\n                  }\n\n                  oldReader.decRef();\n\n                  synchronized(TestStressNRT.this) {\n                    // install the new reader if it's newest (and check the current version since another reader may have already been installed)\n                    //System.out.println(Thread.currentThread().getName() + \": newVersion=\" + newReader.getVersion());\n                    assert newReader.getRefCount() > 0;\n                    assert reader.getRefCount() > 0;\n                    if (newReader.getVersion() > reader.getVersion()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new reader=\" + newReader);\n                      }\n                      reader.decRef();\n                      reader = newReader;\n\n                      // Silly: forces fieldInfos to be\n                      // loaded so we don't hit IOE on later\n                      // reader.toString\n                      newReader.toString();\n\n                      // install this snapshot only if it's newer than the current one\n                      if (version >= committedModelClock) {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new model version=\" + version);\n                        }\n                        committedModel = newCommittedModel;\n                        committedModelClock = version;\n                      } else {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new model version=\" + version);\n                        }\n                      }\n                    } else {\n                      // if the same reader, don't decRef.\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new reader=\" + newReader);\n                      }\n                      newReader.decRef();\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else {\n\n                int id = rand.nextInt(ndocs);\n                Object sync = syncArr[id];\n\n                // set the lastId before we actually change it sometimes to try and\n                // uncover more race conditions between writing and reading\n                boolean before = random().nextBoolean();\n                if (before) {\n                  lastId = id;\n                }\n\n                // We can't concurrently update the same document and retain our invariants of increasing values\n                // since we can't guarantee what order the updates will be executed.\n                synchronized (sync) {\n                  Long val = model.get(id);\n                  long nextVal = Math.abs(val)+1;\n\n                  if (oper < commitPercent + deletePercent) {\n                    // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": term delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new Term(\"id\",Integer.toString(id)));\n                    model.put(id, -nextVal);\n                  } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                    //assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": query delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new TermQuery(new Term(\"id\", Integer.toString(id))));\n                    model.put(id, -nextVal);\n                  } else {\n                    // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                    Document d = new Document();\n                    d.add(newStringField(\"id\", Integer.toString(id), Field.Store.YES));\n                    d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": u id:\" + id + \" val=\" + nextVal);\n                    }\n                    writer.updateDocument(new Term(\"id\", Integer.toString(id)), d);\n                    if (tombstones) {\n                      // remove tombstone after new addition (this should be optional?)\n                      writer.deleteDocuments(new Term(\"id\",\"-\"+Integer.toString(id)));\n                    }\n                    model.put(id, nextVal);\n                  }\n                }\n\n                if (!before) {\n                  lastId = id;\n                }\n              }\n            }\n          } catch (Throwable e) {\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              long val;\n              DirectoryReader r;\n              synchronized(TestStressNRT.this) {\n                val = committedModel.get(id);\n                r = reader;\n                r.incRef();\n              }\n\n              if (VERBOSE) {\n                System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": s id=\" + id + \" val=\" + val + \" r=\" + r.getVersion());\n              }\n\n              //  sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              IndexSearcher searcher = new IndexSearcher(r);\n              Query q = new TermQuery(new Term(\"id\",Integer.toString(id)));\n              TopDocs results = searcher.search(q, 10);\n\n              if (results.totalHits == 0 && tombstones) {\n                // if we couldn't find the doc, look for its tombstone\n                q = new TermQuery(new Term(\"id\",\"-\"+Integer.toString(id)));\n                results = searcher.search(q, 1);\n                if (results.totalHits == 0) {\n                  if (val == -1L) {\n                    // expected... no doc was added yet\n                    r.decRef();\n                    continue;\n                  }\n                  fail(\"No documents or tombstones found for id \" + id + \", expected at least \" + val + \" reader=\" + r);\n                }\n              }\n\n              if (results.totalHits == 0 && !tombstones) {\n                // nothing to do - we can't tell anything from a deleted doc without tombstones\n              } else {\n                // we should have found the document, or its tombstone\n                if (results.totalHits != 1) {\n                  System.out.println(\"FAIL: hits id:\" + id + \" val=\" + val);\n                  for(ScoreDoc sd : results.scoreDocs) {\n                    final Document doc = r.document(sd.doc);\n                    System.out.println(\"  docID=\" + sd.doc + \" id:\" + doc.get(\"id\") + \" foundVal=\" + doc.get(field));\n                  }\n                  fail(\"id=\" + id + \" reader=\" + r + \" totalHits=\" + results.totalHits);\n                }\n                Document doc = searcher.doc(results.scoreDocs[0].doc);\n                long foundVal = Long.parseLong(doc.get(field));\n                if (foundVal < Math.abs(val)) {\n                  fail(\"foundVal=\" + foundVal + \" val=\" + val + \" id=\" + id + \" reader=\" + r);\n                }\n              }\n\n              r.decRef();\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    writer.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: close reader=\" + reader);\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1d028314cced5858683a1bb4741423d0f934257b","date":1346596535,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestStressNRT#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestStressNRT#test().mjava","sourceNew":"  public void test() throws Exception {\n    // update variables\n    final int commitPercent = random().nextInt(20);\n    final int softCommitPercent = random().nextInt(100); // what percent of the commits are soft\n    final int deletePercent = random().nextInt(50);\n    final int deleteByQueryPercent = random().nextInt(25);\n    final int ndocs = atLeast(50);\n    final int nWriteThreads = _TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    final int maxConcurrentCommits = _TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n    \n    final boolean tombstones = random().nextBoolean();\n\n    // query variables\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n\n    final int nReadThreads = _TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    initModel(ndocs);\n\n    final FieldType storedOnlyType = new FieldType();\n    storedOnlyType.setStored(true);\n\n    if (VERBOSE) {\n      System.out.println(\"\\n\");\n      System.out.println(\"TEST: commitPercent=\" + commitPercent);\n      System.out.println(\"TEST: softCommitPercent=\" + softCommitPercent);\n      System.out.println(\"TEST: deletePercent=\" + deletePercent);\n      System.out.println(\"TEST: deleteByQueryPercent=\" + deleteByQueryPercent);\n      System.out.println(\"TEST: ndocs=\" + ndocs);\n      System.out.println(\"TEST: nWriteThreads=\" + nWriteThreads);\n      System.out.println(\"TEST: nReadThreads=\" + nReadThreads);\n      System.out.println(\"TEST: maxConcurrentCommits=\" + maxConcurrentCommits);\n      System.out.println(\"TEST: tombstones=\" + tombstones);\n      System.out.println(\"TEST: operations=\" + operations);\n      System.out.println(\"\\n\");\n    }\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    Directory dir = newDirectory();\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    writer.setDoRandomForceMergeAssert(false);\n    writer.commit();\n    reader = DirectoryReader.open(dir);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n                  DirectoryReader oldReader;\n\n                  synchronized(TestStressNRT.this) {\n                    newCommittedModel = new HashMap<Integer,Long>(model);  // take a snapshot\n                    version = snapshotCount++;\n                    oldReader = reader;\n                    oldReader.incRef();  // increment the reference since we will use this for reopening\n                  }\n\n                  DirectoryReader newReader;\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    // assertU(h.commit(\"softCommit\",\"true\"));\n                    if (random().nextBoolean()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": call writer.getReader\");\n                      }\n                      newReader = writer.getReader(true);\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": reopen reader=\" + oldReader + \" version=\" + version);\n                      }\n                      newReader = DirectoryReader.openIfChanged(oldReader, writer.w, true);\n                    }\n                  } else {\n                    // assertU(commit());\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": commit+reopen reader=\" + oldReader + \" version=\" + version);\n                    }\n                    writer.commit();\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": now reopen after commit\");\n                    }\n                    newReader = DirectoryReader.openIfChanged(oldReader);\n                  }\n\n                  // Code below assumes newReader comes w/\n                  // extra ref:\n                  if (newReader == null) {\n                    oldReader.incRef();\n                    newReader = oldReader;\n                  }\n\n                  oldReader.decRef();\n\n                  synchronized(TestStressNRT.this) {\n                    // install the new reader if it's newest (and check the current version since another reader may have already been installed)\n                    //System.out.println(Thread.currentThread().getName() + \": newVersion=\" + newReader.getVersion());\n                    assert newReader.getRefCount() > 0;\n                    assert reader.getRefCount() > 0;\n                    if (newReader.getVersion() > reader.getVersion()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new reader=\" + newReader);\n                      }\n                      reader.decRef();\n                      reader = newReader;\n\n                      // Silly: forces fieldInfos to be\n                      // loaded so we don't hit IOE on later\n                      // reader.toString\n                      newReader.toString();\n\n                      // install this snapshot only if it's newer than the current one\n                      if (version >= committedModelClock) {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new model version=\" + version);\n                        }\n                        committedModel = newCommittedModel;\n                        committedModelClock = version;\n                      } else {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new model version=\" + version);\n                        }\n                      }\n                    } else {\n                      // if the same reader, don't decRef.\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new reader=\" + newReader);\n                      }\n                      newReader.decRef();\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else {\n\n                int id = rand.nextInt(ndocs);\n                Object sync = syncArr[id];\n\n                // set the lastId before we actually change it sometimes to try and\n                // uncover more race conditions between writing and reading\n                boolean before = random().nextBoolean();\n                if (before) {\n                  lastId = id;\n                }\n\n                // We can't concurrently update the same document and retain our invariants of increasing values\n                // since we can't guarantee what order the updates will be executed.\n                synchronized (sync) {\n                  Long val = model.get(id);\n                  long nextVal = Math.abs(val)+1;\n\n                  if (oper < commitPercent + deletePercent) {\n                    // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": term delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new Term(\"id\",Integer.toString(id)));\n                    model.put(id, -nextVal);\n                  } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                    //assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": query delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new TermQuery(new Term(\"id\", Integer.toString(id))));\n                    model.put(id, -nextVal);\n                  } else {\n                    // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                    Document d = new Document();\n                    d.add(newStringField(\"id\", Integer.toString(id), Field.Store.YES));\n                    d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": u id:\" + id + \" val=\" + nextVal);\n                    }\n                    writer.updateDocument(new Term(\"id\", Integer.toString(id)), d);\n                    if (tombstones) {\n                      // remove tombstone after new addition (this should be optional?)\n                      writer.deleteDocuments(new Term(\"id\",\"-\"+Integer.toString(id)));\n                    }\n                    model.put(id, nextVal);\n                  }\n                }\n\n                if (!before) {\n                  lastId = id;\n                }\n              }\n            }\n          } catch (Throwable e) {\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              long val;\n              DirectoryReader r;\n              synchronized(TestStressNRT.this) {\n                val = committedModel.get(id);\n                r = reader;\n                r.incRef();\n              }\n\n              if (VERBOSE) {\n                System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": s id=\" + id + \" val=\" + val + \" r=\" + r.getVersion());\n              }\n\n              //  sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              IndexSearcher searcher = new IndexSearcher(r);\n              Query q = new TermQuery(new Term(\"id\",Integer.toString(id)));\n              TopDocs results = searcher.search(q, 10);\n\n              if (results.totalHits == 0 && tombstones) {\n                // if we couldn't find the doc, look for its tombstone\n                q = new TermQuery(new Term(\"id\",\"-\"+Integer.toString(id)));\n                results = searcher.search(q, 1);\n                if (results.totalHits == 0) {\n                  if (val == -1L) {\n                    // expected... no doc was added yet\n                    r.decRef();\n                    continue;\n                  }\n                  fail(\"No documents or tombstones found for id \" + id + \", expected at least \" + val + \" reader=\" + r);\n                }\n              }\n\n              if (results.totalHits == 0 && !tombstones) {\n                // nothing to do - we can't tell anything from a deleted doc without tombstones\n              } else {\n                // we should have found the document, or its tombstone\n                if (results.totalHits != 1) {\n                  System.out.println(\"FAIL: hits id:\" + id + \" val=\" + val);\n                  for(ScoreDoc sd : results.scoreDocs) {\n                    final StoredDocument doc = r.document(sd.doc);\n                    System.out.println(\"  docID=\" + sd.doc + \" id:\" + doc.get(\"id\") + \" foundVal=\" + doc.get(field));\n                  }\n                  fail(\"id=\" + id + \" reader=\" + r + \" totalHits=\" + results.totalHits);\n                }\n                StoredDocument doc = searcher.doc(results.scoreDocs[0].doc);\n                long foundVal = Long.parseLong(doc.get(field));\n                if (foundVal < Math.abs(val)) {\n                  fail(\"foundVal=\" + foundVal + \" val=\" + val + \" id=\" + id + \" reader=\" + r);\n                }\n              }\n\n              r.decRef();\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    writer.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: close reader=\" + reader);\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    // update variables\n    final int commitPercent = random().nextInt(20);\n    final int softCommitPercent = random().nextInt(100); // what percent of the commits are soft\n    final int deletePercent = random().nextInt(50);\n    final int deleteByQueryPercent = random().nextInt(25);\n    final int ndocs = atLeast(50);\n    final int nWriteThreads = _TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    final int maxConcurrentCommits = _TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n    \n    final boolean tombstones = random().nextBoolean();\n\n    // query variables\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n\n    final int nReadThreads = _TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    initModel(ndocs);\n\n    final FieldType storedOnlyType = new FieldType();\n    storedOnlyType.setStored(true);\n\n    if (VERBOSE) {\n      System.out.println(\"\\n\");\n      System.out.println(\"TEST: commitPercent=\" + commitPercent);\n      System.out.println(\"TEST: softCommitPercent=\" + softCommitPercent);\n      System.out.println(\"TEST: deletePercent=\" + deletePercent);\n      System.out.println(\"TEST: deleteByQueryPercent=\" + deleteByQueryPercent);\n      System.out.println(\"TEST: ndocs=\" + ndocs);\n      System.out.println(\"TEST: nWriteThreads=\" + nWriteThreads);\n      System.out.println(\"TEST: nReadThreads=\" + nReadThreads);\n      System.out.println(\"TEST: maxConcurrentCommits=\" + maxConcurrentCommits);\n      System.out.println(\"TEST: tombstones=\" + tombstones);\n      System.out.println(\"TEST: operations=\" + operations);\n      System.out.println(\"\\n\");\n    }\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    Directory dir = newDirectory();\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    writer.setDoRandomForceMergeAssert(false);\n    writer.commit();\n    reader = DirectoryReader.open(dir);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n                  DirectoryReader oldReader;\n\n                  synchronized(TestStressNRT.this) {\n                    newCommittedModel = new HashMap<Integer,Long>(model);  // take a snapshot\n                    version = snapshotCount++;\n                    oldReader = reader;\n                    oldReader.incRef();  // increment the reference since we will use this for reopening\n                  }\n\n                  DirectoryReader newReader;\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    // assertU(h.commit(\"softCommit\",\"true\"));\n                    if (random().nextBoolean()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": call writer.getReader\");\n                      }\n                      newReader = writer.getReader(true);\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": reopen reader=\" + oldReader + \" version=\" + version);\n                      }\n                      newReader = DirectoryReader.openIfChanged(oldReader, writer.w, true);\n                    }\n                  } else {\n                    // assertU(commit());\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": commit+reopen reader=\" + oldReader + \" version=\" + version);\n                    }\n                    writer.commit();\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": now reopen after commit\");\n                    }\n                    newReader = DirectoryReader.openIfChanged(oldReader);\n                  }\n\n                  // Code below assumes newReader comes w/\n                  // extra ref:\n                  if (newReader == null) {\n                    oldReader.incRef();\n                    newReader = oldReader;\n                  }\n\n                  oldReader.decRef();\n\n                  synchronized(TestStressNRT.this) {\n                    // install the new reader if it's newest (and check the current version since another reader may have already been installed)\n                    //System.out.println(Thread.currentThread().getName() + \": newVersion=\" + newReader.getVersion());\n                    assert newReader.getRefCount() > 0;\n                    assert reader.getRefCount() > 0;\n                    if (newReader.getVersion() > reader.getVersion()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new reader=\" + newReader);\n                      }\n                      reader.decRef();\n                      reader = newReader;\n\n                      // Silly: forces fieldInfos to be\n                      // loaded so we don't hit IOE on later\n                      // reader.toString\n                      newReader.toString();\n\n                      // install this snapshot only if it's newer than the current one\n                      if (version >= committedModelClock) {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new model version=\" + version);\n                        }\n                        committedModel = newCommittedModel;\n                        committedModelClock = version;\n                      } else {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new model version=\" + version);\n                        }\n                      }\n                    } else {\n                      // if the same reader, don't decRef.\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new reader=\" + newReader);\n                      }\n                      newReader.decRef();\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else {\n\n                int id = rand.nextInt(ndocs);\n                Object sync = syncArr[id];\n\n                // set the lastId before we actually change it sometimes to try and\n                // uncover more race conditions between writing and reading\n                boolean before = random().nextBoolean();\n                if (before) {\n                  lastId = id;\n                }\n\n                // We can't concurrently update the same document and retain our invariants of increasing values\n                // since we can't guarantee what order the updates will be executed.\n                synchronized (sync) {\n                  Long val = model.get(id);\n                  long nextVal = Math.abs(val)+1;\n\n                  if (oper < commitPercent + deletePercent) {\n                    // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": term delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new Term(\"id\",Integer.toString(id)));\n                    model.put(id, -nextVal);\n                  } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                    //assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": query delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new TermQuery(new Term(\"id\", Integer.toString(id))));\n                    model.put(id, -nextVal);\n                  } else {\n                    // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                    Document d = new Document();\n                    d.add(newStringField(\"id\", Integer.toString(id), Field.Store.YES));\n                    d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": u id:\" + id + \" val=\" + nextVal);\n                    }\n                    writer.updateDocument(new Term(\"id\", Integer.toString(id)), d);\n                    if (tombstones) {\n                      // remove tombstone after new addition (this should be optional?)\n                      writer.deleteDocuments(new Term(\"id\",\"-\"+Integer.toString(id)));\n                    }\n                    model.put(id, nextVal);\n                  }\n                }\n\n                if (!before) {\n                  lastId = id;\n                }\n              }\n            }\n          } catch (Throwable e) {\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              long val;\n              DirectoryReader r;\n              synchronized(TestStressNRT.this) {\n                val = committedModel.get(id);\n                r = reader;\n                r.incRef();\n              }\n\n              if (VERBOSE) {\n                System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": s id=\" + id + \" val=\" + val + \" r=\" + r.getVersion());\n              }\n\n              //  sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              IndexSearcher searcher = new IndexSearcher(r);\n              Query q = new TermQuery(new Term(\"id\",Integer.toString(id)));\n              TopDocs results = searcher.search(q, 10);\n\n              if (results.totalHits == 0 && tombstones) {\n                // if we couldn't find the doc, look for its tombstone\n                q = new TermQuery(new Term(\"id\",\"-\"+Integer.toString(id)));\n                results = searcher.search(q, 1);\n                if (results.totalHits == 0) {\n                  if (val == -1L) {\n                    // expected... no doc was added yet\n                    r.decRef();\n                    continue;\n                  }\n                  fail(\"No documents or tombstones found for id \" + id + \", expected at least \" + val + \" reader=\" + r);\n                }\n              }\n\n              if (results.totalHits == 0 && !tombstones) {\n                // nothing to do - we can't tell anything from a deleted doc without tombstones\n              } else {\n                // we should have found the document, or its tombstone\n                if (results.totalHits != 1) {\n                  System.out.println(\"FAIL: hits id:\" + id + \" val=\" + val);\n                  for(ScoreDoc sd : results.scoreDocs) {\n                    final Document doc = r.document(sd.doc);\n                    System.out.println(\"  docID=\" + sd.doc + \" id:\" + doc.get(\"id\") + \" foundVal=\" + doc.get(field));\n                  }\n                  fail(\"id=\" + id + \" reader=\" + r + \" totalHits=\" + results.totalHits);\n                }\n                Document doc = searcher.doc(results.scoreDocs[0].doc);\n                long foundVal = Long.parseLong(doc.get(field));\n                if (foundVal < Math.abs(val)) {\n                  fail(\"foundVal=\" + foundVal + \" val=\" + val + \" id=\" + id + \" reader=\" + r);\n                }\n              }\n\n              r.decRef();\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    writer.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: close reader=\" + reader);\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3b0e8c39ca08b5a02de6edcd33d6f3b90b865173","date":1365631993,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestStressNRT#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestStressNRT#test().mjava","sourceNew":"  public void test() throws Exception {\n    // update variables\n    final int commitPercent = random().nextInt(20);\n    final int softCommitPercent = random().nextInt(100); // what percent of the commits are soft\n    final int deletePercent = random().nextInt(50);\n    final int deleteByQueryPercent = random().nextInt(25);\n    final int ndocs = atLeast(50);\n    final int nWriteThreads = _TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    final int maxConcurrentCommits = _TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n    \n    final boolean tombstones = random().nextBoolean();\n\n    // query variables\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n\n    final int nReadThreads = _TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    initModel(ndocs);\n\n    final FieldType storedOnlyType = new FieldType();\n    storedOnlyType.setStored(true);\n\n    if (VERBOSE) {\n      System.out.println(\"\\n\");\n      System.out.println(\"TEST: commitPercent=\" + commitPercent);\n      System.out.println(\"TEST: softCommitPercent=\" + softCommitPercent);\n      System.out.println(\"TEST: deletePercent=\" + deletePercent);\n      System.out.println(\"TEST: deleteByQueryPercent=\" + deleteByQueryPercent);\n      System.out.println(\"TEST: ndocs=\" + ndocs);\n      System.out.println(\"TEST: nWriteThreads=\" + nWriteThreads);\n      System.out.println(\"TEST: nReadThreads=\" + nReadThreads);\n      System.out.println(\"TEST: maxConcurrentCommits=\" + maxConcurrentCommits);\n      System.out.println(\"TEST: tombstones=\" + tombstones);\n      System.out.println(\"TEST: operations=\" + operations);\n      System.out.println(\"\\n\");\n    }\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    Directory dir = newDirectory();\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    writer.setDoRandomForceMergeAssert(false);\n    writer.commit();\n    reader = DirectoryReader.open(dir);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n                  DirectoryReader oldReader;\n\n                  synchronized(TestStressNRT.this) {\n                    newCommittedModel = new HashMap<Integer,Long>(model);  // take a snapshot\n                    version = snapshotCount++;\n                    oldReader = reader;\n                    oldReader.incRef();  // increment the reference since we will use this for reopening\n                  }\n\n                  DirectoryReader newReader;\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    // assertU(h.commit(\"softCommit\",\"true\"));\n                    if (random().nextBoolean()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": call writer.getReader\");\n                      }\n                      newReader = writer.getReader(true);\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": reopen reader=\" + oldReader + \" version=\" + version);\n                      }\n                      newReader = DirectoryReader.openIfChanged(oldReader, writer.w, true);\n                    }\n                  } else {\n                    // assertU(commit());\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": commit+reopen reader=\" + oldReader + \" version=\" + version);\n                    }\n                    writer.commit();\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": now reopen after commit\");\n                    }\n                    newReader = DirectoryReader.openIfChanged(oldReader);\n                  }\n\n                  // Code below assumes newReader comes w/\n                  // extra ref:\n                  if (newReader == null) {\n                    oldReader.incRef();\n                    newReader = oldReader;\n                  }\n\n                  oldReader.decRef();\n\n                  synchronized(TestStressNRT.this) {\n                    // install the new reader if it's newest (and check the current version since another reader may have already been installed)\n                    //System.out.println(Thread.currentThread().getName() + \": newVersion=\" + newReader.getVersion());\n                    assert newReader.getRefCount() > 0;\n                    assert reader.getRefCount() > 0;\n                    if (newReader.getVersion() > reader.getVersion()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new reader=\" + newReader);\n                      }\n                      reader.decRef();\n                      reader = newReader;\n\n                      // Silly: forces fieldInfos to be\n                      // loaded so we don't hit IOE on later\n                      // reader.toString\n                      newReader.toString();\n\n                      // install this snapshot only if it's newer than the current one\n                      if (version >= committedModelClock) {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new model version=\" + version);\n                        }\n                        committedModel = newCommittedModel;\n                        committedModelClock = version;\n                      } else {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new model version=\" + version);\n                        }\n                      }\n                    } else {\n                      // if the same reader, don't decRef.\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new reader=\" + newReader);\n                      }\n                      newReader.decRef();\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else {\n\n                int id = rand.nextInt(ndocs);\n                Object sync = syncArr[id];\n\n                // set the lastId before we actually change it sometimes to try and\n                // uncover more race conditions between writing and reading\n                boolean before = random().nextBoolean();\n                if (before) {\n                  lastId = id;\n                }\n\n                // We can't concurrently update the same document and retain our invariants of increasing values\n                // since we can't guarantee what order the updates will be executed.\n                synchronized (sync) {\n                  Long val = model.get(id);\n                  long nextVal = Math.abs(val)+1;\n\n                  if (oper < commitPercent + deletePercent) {\n                    // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": term delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new Term(\"id\",Integer.toString(id)));\n                    model.put(id, -nextVal);\n                  } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                    //assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": query delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new TermQuery(new Term(\"id\", Integer.toString(id))));\n                    model.put(id, -nextVal);\n                  } else {\n                    // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                    Document d = new Document();\n                    d.add(newStringField(\"id\", Integer.toString(id), Field.Store.YES));\n                    d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": u id:\" + id + \" val=\" + nextVal);\n                    }\n                    writer.updateDocument(new Term(\"id\", Integer.toString(id)), d);\n                    if (tombstones) {\n                      // remove tombstone after new addition (this should be optional?)\n                      writer.deleteDocuments(new Term(\"id\",\"-\"+Integer.toString(id)));\n                    }\n                    model.put(id, nextVal);\n                  }\n                }\n\n                if (!before) {\n                  lastId = id;\n                }\n              }\n            }\n          } catch (Throwable e) {\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              long val;\n              DirectoryReader r;\n              synchronized(TestStressNRT.this) {\n                val = committedModel.get(id);\n                r = reader;\n                r.incRef();\n              }\n\n              if (VERBOSE) {\n                System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": s id=\" + id + \" val=\" + val + \" r=\" + r.getVersion());\n              }\n\n              //  sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              IndexSearcher searcher = newSearcher(r);\n              Query q = new TermQuery(new Term(\"id\",Integer.toString(id)));\n              TopDocs results = searcher.search(q, 10);\n\n              if (results.totalHits == 0 && tombstones) {\n                // if we couldn't find the doc, look for its tombstone\n                q = new TermQuery(new Term(\"id\",\"-\"+Integer.toString(id)));\n                results = searcher.search(q, 1);\n                if (results.totalHits == 0) {\n                  if (val == -1L) {\n                    // expected... no doc was added yet\n                    r.decRef();\n                    continue;\n                  }\n                  fail(\"No documents or tombstones found for id \" + id + \", expected at least \" + val + \" reader=\" + r);\n                }\n              }\n\n              if (results.totalHits == 0 && !tombstones) {\n                // nothing to do - we can't tell anything from a deleted doc without tombstones\n              } else {\n                // we should have found the document, or its tombstone\n                if (results.totalHits != 1) {\n                  System.out.println(\"FAIL: hits id:\" + id + \" val=\" + val);\n                  for(ScoreDoc sd : results.scoreDocs) {\n                    final StoredDocument doc = r.document(sd.doc);\n                    System.out.println(\"  docID=\" + sd.doc + \" id:\" + doc.get(\"id\") + \" foundVal=\" + doc.get(field));\n                  }\n                  fail(\"id=\" + id + \" reader=\" + r + \" totalHits=\" + results.totalHits);\n                }\n                StoredDocument doc = searcher.doc(results.scoreDocs[0].doc);\n                long foundVal = Long.parseLong(doc.get(field));\n                if (foundVal < Math.abs(val)) {\n                  fail(\"foundVal=\" + foundVal + \" val=\" + val + \" id=\" + id + \" reader=\" + r);\n                }\n              }\n\n              r.decRef();\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    writer.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: close reader=\" + reader);\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    // update variables\n    final int commitPercent = random().nextInt(20);\n    final int softCommitPercent = random().nextInt(100); // what percent of the commits are soft\n    final int deletePercent = random().nextInt(50);\n    final int deleteByQueryPercent = random().nextInt(25);\n    final int ndocs = atLeast(50);\n    final int nWriteThreads = _TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    final int maxConcurrentCommits = _TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n    \n    final boolean tombstones = random().nextBoolean();\n\n    // query variables\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n\n    final int nReadThreads = _TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    initModel(ndocs);\n\n    final FieldType storedOnlyType = new FieldType();\n    storedOnlyType.setStored(true);\n\n    if (VERBOSE) {\n      System.out.println(\"\\n\");\n      System.out.println(\"TEST: commitPercent=\" + commitPercent);\n      System.out.println(\"TEST: softCommitPercent=\" + softCommitPercent);\n      System.out.println(\"TEST: deletePercent=\" + deletePercent);\n      System.out.println(\"TEST: deleteByQueryPercent=\" + deleteByQueryPercent);\n      System.out.println(\"TEST: ndocs=\" + ndocs);\n      System.out.println(\"TEST: nWriteThreads=\" + nWriteThreads);\n      System.out.println(\"TEST: nReadThreads=\" + nReadThreads);\n      System.out.println(\"TEST: maxConcurrentCommits=\" + maxConcurrentCommits);\n      System.out.println(\"TEST: tombstones=\" + tombstones);\n      System.out.println(\"TEST: operations=\" + operations);\n      System.out.println(\"\\n\");\n    }\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    Directory dir = newDirectory();\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    writer.setDoRandomForceMergeAssert(false);\n    writer.commit();\n    reader = DirectoryReader.open(dir);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n                  DirectoryReader oldReader;\n\n                  synchronized(TestStressNRT.this) {\n                    newCommittedModel = new HashMap<Integer,Long>(model);  // take a snapshot\n                    version = snapshotCount++;\n                    oldReader = reader;\n                    oldReader.incRef();  // increment the reference since we will use this for reopening\n                  }\n\n                  DirectoryReader newReader;\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    // assertU(h.commit(\"softCommit\",\"true\"));\n                    if (random().nextBoolean()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": call writer.getReader\");\n                      }\n                      newReader = writer.getReader(true);\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": reopen reader=\" + oldReader + \" version=\" + version);\n                      }\n                      newReader = DirectoryReader.openIfChanged(oldReader, writer.w, true);\n                    }\n                  } else {\n                    // assertU(commit());\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": commit+reopen reader=\" + oldReader + \" version=\" + version);\n                    }\n                    writer.commit();\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": now reopen after commit\");\n                    }\n                    newReader = DirectoryReader.openIfChanged(oldReader);\n                  }\n\n                  // Code below assumes newReader comes w/\n                  // extra ref:\n                  if (newReader == null) {\n                    oldReader.incRef();\n                    newReader = oldReader;\n                  }\n\n                  oldReader.decRef();\n\n                  synchronized(TestStressNRT.this) {\n                    // install the new reader if it's newest (and check the current version since another reader may have already been installed)\n                    //System.out.println(Thread.currentThread().getName() + \": newVersion=\" + newReader.getVersion());\n                    assert newReader.getRefCount() > 0;\n                    assert reader.getRefCount() > 0;\n                    if (newReader.getVersion() > reader.getVersion()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new reader=\" + newReader);\n                      }\n                      reader.decRef();\n                      reader = newReader;\n\n                      // Silly: forces fieldInfos to be\n                      // loaded so we don't hit IOE on later\n                      // reader.toString\n                      newReader.toString();\n\n                      // install this snapshot only if it's newer than the current one\n                      if (version >= committedModelClock) {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new model version=\" + version);\n                        }\n                        committedModel = newCommittedModel;\n                        committedModelClock = version;\n                      } else {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new model version=\" + version);\n                        }\n                      }\n                    } else {\n                      // if the same reader, don't decRef.\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new reader=\" + newReader);\n                      }\n                      newReader.decRef();\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else {\n\n                int id = rand.nextInt(ndocs);\n                Object sync = syncArr[id];\n\n                // set the lastId before we actually change it sometimes to try and\n                // uncover more race conditions between writing and reading\n                boolean before = random().nextBoolean();\n                if (before) {\n                  lastId = id;\n                }\n\n                // We can't concurrently update the same document and retain our invariants of increasing values\n                // since we can't guarantee what order the updates will be executed.\n                synchronized (sync) {\n                  Long val = model.get(id);\n                  long nextVal = Math.abs(val)+1;\n\n                  if (oper < commitPercent + deletePercent) {\n                    // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": term delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new Term(\"id\",Integer.toString(id)));\n                    model.put(id, -nextVal);\n                  } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                    //assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": query delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new TermQuery(new Term(\"id\", Integer.toString(id))));\n                    model.put(id, -nextVal);\n                  } else {\n                    // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                    Document d = new Document();\n                    d.add(newStringField(\"id\", Integer.toString(id), Field.Store.YES));\n                    d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": u id:\" + id + \" val=\" + nextVal);\n                    }\n                    writer.updateDocument(new Term(\"id\", Integer.toString(id)), d);\n                    if (tombstones) {\n                      // remove tombstone after new addition (this should be optional?)\n                      writer.deleteDocuments(new Term(\"id\",\"-\"+Integer.toString(id)));\n                    }\n                    model.put(id, nextVal);\n                  }\n                }\n\n                if (!before) {\n                  lastId = id;\n                }\n              }\n            }\n          } catch (Throwable e) {\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              long val;\n              DirectoryReader r;\n              synchronized(TestStressNRT.this) {\n                val = committedModel.get(id);\n                r = reader;\n                r.incRef();\n              }\n\n              if (VERBOSE) {\n                System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": s id=\" + id + \" val=\" + val + \" r=\" + r.getVersion());\n              }\n\n              //  sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              IndexSearcher searcher = new IndexSearcher(r);\n              Query q = new TermQuery(new Term(\"id\",Integer.toString(id)));\n              TopDocs results = searcher.search(q, 10);\n\n              if (results.totalHits == 0 && tombstones) {\n                // if we couldn't find the doc, look for its tombstone\n                q = new TermQuery(new Term(\"id\",\"-\"+Integer.toString(id)));\n                results = searcher.search(q, 1);\n                if (results.totalHits == 0) {\n                  if (val == -1L) {\n                    // expected... no doc was added yet\n                    r.decRef();\n                    continue;\n                  }\n                  fail(\"No documents or tombstones found for id \" + id + \", expected at least \" + val + \" reader=\" + r);\n                }\n              }\n\n              if (results.totalHits == 0 && !tombstones) {\n                // nothing to do - we can't tell anything from a deleted doc without tombstones\n              } else {\n                // we should have found the document, or its tombstone\n                if (results.totalHits != 1) {\n                  System.out.println(\"FAIL: hits id:\" + id + \" val=\" + val);\n                  for(ScoreDoc sd : results.scoreDocs) {\n                    final StoredDocument doc = r.document(sd.doc);\n                    System.out.println(\"  docID=\" + sd.doc + \" id:\" + doc.get(\"id\") + \" foundVal=\" + doc.get(field));\n                  }\n                  fail(\"id=\" + id + \" reader=\" + r + \" totalHits=\" + results.totalHits);\n                }\n                StoredDocument doc = searcher.doc(results.scoreDocs[0].doc);\n                long foundVal = Long.parseLong(doc.get(field));\n                if (foundVal < Math.abs(val)) {\n                  fail(\"foundVal=\" + foundVal + \" val=\" + val + \" id=\" + id + \" reader=\" + r);\n                }\n              }\n\n              r.decRef();\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    writer.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: close reader=\" + reader);\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8381e40f04c08698784f68f818258dc998398888","date":1365687513,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestStressNRT#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestStressNRT#test().mjava","sourceNew":"  public void test() throws Exception {\n    // update variables\n    final int commitPercent = random().nextInt(20);\n    final int softCommitPercent = random().nextInt(100); // what percent of the commits are soft\n    final int deletePercent = random().nextInt(50);\n    final int deleteByQueryPercent = random().nextInt(25);\n    final int ndocs = atLeast(50);\n    final int nWriteThreads = _TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    final int maxConcurrentCommits = _TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n    \n    final boolean tombstones = random().nextBoolean();\n\n    // query variables\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n\n    final int nReadThreads = _TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    initModel(ndocs);\n\n    final FieldType storedOnlyType = new FieldType();\n    storedOnlyType.setStored(true);\n\n    if (VERBOSE) {\n      System.out.println(\"\\n\");\n      System.out.println(\"TEST: commitPercent=\" + commitPercent);\n      System.out.println(\"TEST: softCommitPercent=\" + softCommitPercent);\n      System.out.println(\"TEST: deletePercent=\" + deletePercent);\n      System.out.println(\"TEST: deleteByQueryPercent=\" + deleteByQueryPercent);\n      System.out.println(\"TEST: ndocs=\" + ndocs);\n      System.out.println(\"TEST: nWriteThreads=\" + nWriteThreads);\n      System.out.println(\"TEST: nReadThreads=\" + nReadThreads);\n      System.out.println(\"TEST: maxConcurrentCommits=\" + maxConcurrentCommits);\n      System.out.println(\"TEST: tombstones=\" + tombstones);\n      System.out.println(\"TEST: operations=\" + operations);\n      System.out.println(\"\\n\");\n    }\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    Directory dir = newDirectory();\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    writer.setDoRandomForceMergeAssert(false);\n    writer.commit();\n    reader = DirectoryReader.open(dir);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n                  DirectoryReader oldReader;\n\n                  synchronized(TestStressNRT.this) {\n                    newCommittedModel = new HashMap<Integer,Long>(model);  // take a snapshot\n                    version = snapshotCount++;\n                    oldReader = reader;\n                    oldReader.incRef();  // increment the reference since we will use this for reopening\n                  }\n\n                  DirectoryReader newReader;\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    // assertU(h.commit(\"softCommit\",\"true\"));\n                    if (random().nextBoolean()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": call writer.getReader\");\n                      }\n                      newReader = writer.getReader(true);\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": reopen reader=\" + oldReader + \" version=\" + version);\n                      }\n                      newReader = DirectoryReader.openIfChanged(oldReader, writer.w, true);\n                    }\n                  } else {\n                    // assertU(commit());\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": commit+reopen reader=\" + oldReader + \" version=\" + version);\n                    }\n                    writer.commit();\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": now reopen after commit\");\n                    }\n                    newReader = DirectoryReader.openIfChanged(oldReader);\n                  }\n\n                  // Code below assumes newReader comes w/\n                  // extra ref:\n                  if (newReader == null) {\n                    oldReader.incRef();\n                    newReader = oldReader;\n                  }\n\n                  oldReader.decRef();\n\n                  synchronized(TestStressNRT.this) {\n                    // install the new reader if it's newest (and check the current version since another reader may have already been installed)\n                    //System.out.println(Thread.currentThread().getName() + \": newVersion=\" + newReader.getVersion());\n                    assert newReader.getRefCount() > 0;\n                    assert reader.getRefCount() > 0;\n                    if (newReader.getVersion() > reader.getVersion()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new reader=\" + newReader);\n                      }\n                      reader.decRef();\n                      reader = newReader;\n\n                      // Silly: forces fieldInfos to be\n                      // loaded so we don't hit IOE on later\n                      // reader.toString\n                      newReader.toString();\n\n                      // install this snapshot only if it's newer than the current one\n                      if (version >= committedModelClock) {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new model version=\" + version);\n                        }\n                        committedModel = newCommittedModel;\n                        committedModelClock = version;\n                      } else {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new model version=\" + version);\n                        }\n                      }\n                    } else {\n                      // if the same reader, don't decRef.\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new reader=\" + newReader);\n                      }\n                      newReader.decRef();\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else {\n\n                int id = rand.nextInt(ndocs);\n                Object sync = syncArr[id];\n\n                // set the lastId before we actually change it sometimes to try and\n                // uncover more race conditions between writing and reading\n                boolean before = random().nextBoolean();\n                if (before) {\n                  lastId = id;\n                }\n\n                // We can't concurrently update the same document and retain our invariants of increasing values\n                // since we can't guarantee what order the updates will be executed.\n                synchronized (sync) {\n                  Long val = model.get(id);\n                  long nextVal = Math.abs(val)+1;\n\n                  if (oper < commitPercent + deletePercent) {\n                    // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": term delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new Term(\"id\",Integer.toString(id)));\n                    model.put(id, -nextVal);\n                  } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                    //assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": query delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new TermQuery(new Term(\"id\", Integer.toString(id))));\n                    model.put(id, -nextVal);\n                  } else {\n                    // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                    Document d = new Document();\n                    d.add(newStringField(\"id\", Integer.toString(id), Field.Store.YES));\n                    d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": u id:\" + id + \" val=\" + nextVal);\n                    }\n                    writer.updateDocument(new Term(\"id\", Integer.toString(id)), d);\n                    if (tombstones) {\n                      // remove tombstone after new addition (this should be optional?)\n                      writer.deleteDocuments(new Term(\"id\",\"-\"+Integer.toString(id)));\n                    }\n                    model.put(id, nextVal);\n                  }\n                }\n\n                if (!before) {\n                  lastId = id;\n                }\n              }\n            }\n          } catch (Throwable e) {\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            IndexReader lastReader = null;\n            IndexSearcher lastSearcher = null;\n\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              long val;\n              DirectoryReader r;\n              synchronized(TestStressNRT.this) {\n                val = committedModel.get(id);\n                r = reader;\n                r.incRef();\n              }\n\n              if (VERBOSE) {\n                System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": s id=\" + id + \" val=\" + val + \" r=\" + r.getVersion());\n              }\n\n              //  sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              IndexSearcher searcher;\n              if (r == lastReader) {\n                // Just re-use lastSearcher, else\n                // newSearcher may create too many thread\n                // pools (ExecutorService):\n                searcher = lastSearcher;\n              } else {\n                searcher = newSearcher(r);\n                lastReader = r;\n                lastSearcher = searcher;\n              }\n              Query q = new TermQuery(new Term(\"id\",Integer.toString(id)));\n              TopDocs results = searcher.search(q, 10);\n\n              if (results.totalHits == 0 && tombstones) {\n                // if we couldn't find the doc, look for its tombstone\n                q = new TermQuery(new Term(\"id\",\"-\"+Integer.toString(id)));\n                results = searcher.search(q, 1);\n                if (results.totalHits == 0) {\n                  if (val == -1L) {\n                    // expected... no doc was added yet\n                    r.decRef();\n                    continue;\n                  }\n                  fail(\"No documents or tombstones found for id \" + id + \", expected at least \" + val + \" reader=\" + r);\n                }\n              }\n\n              if (results.totalHits == 0 && !tombstones) {\n                // nothing to do - we can't tell anything from a deleted doc without tombstones\n              } else {\n                // we should have found the document, or its tombstone\n                if (results.totalHits != 1) {\n                  System.out.println(\"FAIL: hits id:\" + id + \" val=\" + val);\n                  for(ScoreDoc sd : results.scoreDocs) {\n                    final StoredDocument doc = r.document(sd.doc);\n                    System.out.println(\"  docID=\" + sd.doc + \" id:\" + doc.get(\"id\") + \" foundVal=\" + doc.get(field));\n                  }\n                  fail(\"id=\" + id + \" reader=\" + r + \" totalHits=\" + results.totalHits);\n                }\n                StoredDocument doc = searcher.doc(results.scoreDocs[0].doc);\n                long foundVal = Long.parseLong(doc.get(field));\n                if (foundVal < Math.abs(val)) {\n                  fail(\"foundVal=\" + foundVal + \" val=\" + val + \" id=\" + id + \" reader=\" + r);\n                }\n              }\n\n              r.decRef();\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    writer.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: close reader=\" + reader);\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    // update variables\n    final int commitPercent = random().nextInt(20);\n    final int softCommitPercent = random().nextInt(100); // what percent of the commits are soft\n    final int deletePercent = random().nextInt(50);\n    final int deleteByQueryPercent = random().nextInt(25);\n    final int ndocs = atLeast(50);\n    final int nWriteThreads = _TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    final int maxConcurrentCommits = _TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n    \n    final boolean tombstones = random().nextBoolean();\n\n    // query variables\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n\n    final int nReadThreads = _TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    initModel(ndocs);\n\n    final FieldType storedOnlyType = new FieldType();\n    storedOnlyType.setStored(true);\n\n    if (VERBOSE) {\n      System.out.println(\"\\n\");\n      System.out.println(\"TEST: commitPercent=\" + commitPercent);\n      System.out.println(\"TEST: softCommitPercent=\" + softCommitPercent);\n      System.out.println(\"TEST: deletePercent=\" + deletePercent);\n      System.out.println(\"TEST: deleteByQueryPercent=\" + deleteByQueryPercent);\n      System.out.println(\"TEST: ndocs=\" + ndocs);\n      System.out.println(\"TEST: nWriteThreads=\" + nWriteThreads);\n      System.out.println(\"TEST: nReadThreads=\" + nReadThreads);\n      System.out.println(\"TEST: maxConcurrentCommits=\" + maxConcurrentCommits);\n      System.out.println(\"TEST: tombstones=\" + tombstones);\n      System.out.println(\"TEST: operations=\" + operations);\n      System.out.println(\"\\n\");\n    }\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    Directory dir = newDirectory();\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    writer.setDoRandomForceMergeAssert(false);\n    writer.commit();\n    reader = DirectoryReader.open(dir);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n                  DirectoryReader oldReader;\n\n                  synchronized(TestStressNRT.this) {\n                    newCommittedModel = new HashMap<Integer,Long>(model);  // take a snapshot\n                    version = snapshotCount++;\n                    oldReader = reader;\n                    oldReader.incRef();  // increment the reference since we will use this for reopening\n                  }\n\n                  DirectoryReader newReader;\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    // assertU(h.commit(\"softCommit\",\"true\"));\n                    if (random().nextBoolean()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": call writer.getReader\");\n                      }\n                      newReader = writer.getReader(true);\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": reopen reader=\" + oldReader + \" version=\" + version);\n                      }\n                      newReader = DirectoryReader.openIfChanged(oldReader, writer.w, true);\n                    }\n                  } else {\n                    // assertU(commit());\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": commit+reopen reader=\" + oldReader + \" version=\" + version);\n                    }\n                    writer.commit();\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": now reopen after commit\");\n                    }\n                    newReader = DirectoryReader.openIfChanged(oldReader);\n                  }\n\n                  // Code below assumes newReader comes w/\n                  // extra ref:\n                  if (newReader == null) {\n                    oldReader.incRef();\n                    newReader = oldReader;\n                  }\n\n                  oldReader.decRef();\n\n                  synchronized(TestStressNRT.this) {\n                    // install the new reader if it's newest (and check the current version since another reader may have already been installed)\n                    //System.out.println(Thread.currentThread().getName() + \": newVersion=\" + newReader.getVersion());\n                    assert newReader.getRefCount() > 0;\n                    assert reader.getRefCount() > 0;\n                    if (newReader.getVersion() > reader.getVersion()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new reader=\" + newReader);\n                      }\n                      reader.decRef();\n                      reader = newReader;\n\n                      // Silly: forces fieldInfos to be\n                      // loaded so we don't hit IOE on later\n                      // reader.toString\n                      newReader.toString();\n\n                      // install this snapshot only if it's newer than the current one\n                      if (version >= committedModelClock) {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new model version=\" + version);\n                        }\n                        committedModel = newCommittedModel;\n                        committedModelClock = version;\n                      } else {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new model version=\" + version);\n                        }\n                      }\n                    } else {\n                      // if the same reader, don't decRef.\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new reader=\" + newReader);\n                      }\n                      newReader.decRef();\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else {\n\n                int id = rand.nextInt(ndocs);\n                Object sync = syncArr[id];\n\n                // set the lastId before we actually change it sometimes to try and\n                // uncover more race conditions between writing and reading\n                boolean before = random().nextBoolean();\n                if (before) {\n                  lastId = id;\n                }\n\n                // We can't concurrently update the same document and retain our invariants of increasing values\n                // since we can't guarantee what order the updates will be executed.\n                synchronized (sync) {\n                  Long val = model.get(id);\n                  long nextVal = Math.abs(val)+1;\n\n                  if (oper < commitPercent + deletePercent) {\n                    // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": term delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new Term(\"id\",Integer.toString(id)));\n                    model.put(id, -nextVal);\n                  } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                    //assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": query delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new TermQuery(new Term(\"id\", Integer.toString(id))));\n                    model.put(id, -nextVal);\n                  } else {\n                    // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                    Document d = new Document();\n                    d.add(newStringField(\"id\", Integer.toString(id), Field.Store.YES));\n                    d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": u id:\" + id + \" val=\" + nextVal);\n                    }\n                    writer.updateDocument(new Term(\"id\", Integer.toString(id)), d);\n                    if (tombstones) {\n                      // remove tombstone after new addition (this should be optional?)\n                      writer.deleteDocuments(new Term(\"id\",\"-\"+Integer.toString(id)));\n                    }\n                    model.put(id, nextVal);\n                  }\n                }\n\n                if (!before) {\n                  lastId = id;\n                }\n              }\n            }\n          } catch (Throwable e) {\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              long val;\n              DirectoryReader r;\n              synchronized(TestStressNRT.this) {\n                val = committedModel.get(id);\n                r = reader;\n                r.incRef();\n              }\n\n              if (VERBOSE) {\n                System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": s id=\" + id + \" val=\" + val + \" r=\" + r.getVersion());\n              }\n\n              //  sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              IndexSearcher searcher = newSearcher(r);\n              Query q = new TermQuery(new Term(\"id\",Integer.toString(id)));\n              TopDocs results = searcher.search(q, 10);\n\n              if (results.totalHits == 0 && tombstones) {\n                // if we couldn't find the doc, look for its tombstone\n                q = new TermQuery(new Term(\"id\",\"-\"+Integer.toString(id)));\n                results = searcher.search(q, 1);\n                if (results.totalHits == 0) {\n                  if (val == -1L) {\n                    // expected... no doc was added yet\n                    r.decRef();\n                    continue;\n                  }\n                  fail(\"No documents or tombstones found for id \" + id + \", expected at least \" + val + \" reader=\" + r);\n                }\n              }\n\n              if (results.totalHits == 0 && !tombstones) {\n                // nothing to do - we can't tell anything from a deleted doc without tombstones\n              } else {\n                // we should have found the document, or its tombstone\n                if (results.totalHits != 1) {\n                  System.out.println(\"FAIL: hits id:\" + id + \" val=\" + val);\n                  for(ScoreDoc sd : results.scoreDocs) {\n                    final StoredDocument doc = r.document(sd.doc);\n                    System.out.println(\"  docID=\" + sd.doc + \" id:\" + doc.get(\"id\") + \" foundVal=\" + doc.get(field));\n                  }\n                  fail(\"id=\" + id + \" reader=\" + r + \" totalHits=\" + results.totalHits);\n                }\n                StoredDocument doc = searcher.doc(results.scoreDocs[0].doc);\n                long foundVal = Long.parseLong(doc.get(field));\n                if (foundVal < Math.abs(val)) {\n                  fail(\"foundVal=\" + foundVal + \" val=\" + val + \" id=\" + id + \" reader=\" + r);\n                }\n              }\n\n              r.decRef();\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    writer.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: close reader=\" + reader);\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6613659748fe4411a7dcf85266e55db1f95f7315","date":1392773913,"type":3,"author":"Benson Margulies","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestStressNRT#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestStressNRT#test().mjava","sourceNew":"  public void test() throws Exception {\n    // update variables\n    final int commitPercent = random().nextInt(20);\n    final int softCommitPercent = random().nextInt(100); // what percent of the commits are soft\n    final int deletePercent = random().nextInt(50);\n    final int deleteByQueryPercent = random().nextInt(25);\n    final int ndocs = atLeast(50);\n    final int nWriteThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    final int maxConcurrentCommits = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n    \n    final boolean tombstones = random().nextBoolean();\n\n    // query variables\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n\n    final int nReadThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    initModel(ndocs);\n\n    final FieldType storedOnlyType = new FieldType();\n    storedOnlyType.setStored(true);\n\n    if (VERBOSE) {\n      System.out.println(\"\\n\");\n      System.out.println(\"TEST: commitPercent=\" + commitPercent);\n      System.out.println(\"TEST: softCommitPercent=\" + softCommitPercent);\n      System.out.println(\"TEST: deletePercent=\" + deletePercent);\n      System.out.println(\"TEST: deleteByQueryPercent=\" + deleteByQueryPercent);\n      System.out.println(\"TEST: ndocs=\" + ndocs);\n      System.out.println(\"TEST: nWriteThreads=\" + nWriteThreads);\n      System.out.println(\"TEST: nReadThreads=\" + nReadThreads);\n      System.out.println(\"TEST: maxConcurrentCommits=\" + maxConcurrentCommits);\n      System.out.println(\"TEST: tombstones=\" + tombstones);\n      System.out.println(\"TEST: operations=\" + operations);\n      System.out.println(\"\\n\");\n    }\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    Directory dir = newDirectory();\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    writer.setDoRandomForceMergeAssert(false);\n    writer.commit();\n    reader = DirectoryReader.open(dir);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n                  DirectoryReader oldReader;\n\n                  synchronized(TestStressNRT.this) {\n                    newCommittedModel = new HashMap<Integer,Long>(model);  // take a snapshot\n                    version = snapshotCount++;\n                    oldReader = reader;\n                    oldReader.incRef();  // increment the reference since we will use this for reopening\n                  }\n\n                  DirectoryReader newReader;\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    // assertU(h.commit(\"softCommit\",\"true\"));\n                    if (random().nextBoolean()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": call writer.getReader\");\n                      }\n                      newReader = writer.getReader(true);\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": reopen reader=\" + oldReader + \" version=\" + version);\n                      }\n                      newReader = DirectoryReader.openIfChanged(oldReader, writer.w, true);\n                    }\n                  } else {\n                    // assertU(commit());\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": commit+reopen reader=\" + oldReader + \" version=\" + version);\n                    }\n                    writer.commit();\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": now reopen after commit\");\n                    }\n                    newReader = DirectoryReader.openIfChanged(oldReader);\n                  }\n\n                  // Code below assumes newReader comes w/\n                  // extra ref:\n                  if (newReader == null) {\n                    oldReader.incRef();\n                    newReader = oldReader;\n                  }\n\n                  oldReader.decRef();\n\n                  synchronized(TestStressNRT.this) {\n                    // install the new reader if it's newest (and check the current version since another reader may have already been installed)\n                    //System.out.println(Thread.currentThread().getName() + \": newVersion=\" + newReader.getVersion());\n                    assert newReader.getRefCount() > 0;\n                    assert reader.getRefCount() > 0;\n                    if (newReader.getVersion() > reader.getVersion()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new reader=\" + newReader);\n                      }\n                      reader.decRef();\n                      reader = newReader;\n\n                      // Silly: forces fieldInfos to be\n                      // loaded so we don't hit IOE on later\n                      // reader.toString\n                      newReader.toString();\n\n                      // install this snapshot only if it's newer than the current one\n                      if (version >= committedModelClock) {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new model version=\" + version);\n                        }\n                        committedModel = newCommittedModel;\n                        committedModelClock = version;\n                      } else {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new model version=\" + version);\n                        }\n                      }\n                    } else {\n                      // if the same reader, don't decRef.\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new reader=\" + newReader);\n                      }\n                      newReader.decRef();\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else {\n\n                int id = rand.nextInt(ndocs);\n                Object sync = syncArr[id];\n\n                // set the lastId before we actually change it sometimes to try and\n                // uncover more race conditions between writing and reading\n                boolean before = random().nextBoolean();\n                if (before) {\n                  lastId = id;\n                }\n\n                // We can't concurrently update the same document and retain our invariants of increasing values\n                // since we can't guarantee what order the updates will be executed.\n                synchronized (sync) {\n                  Long val = model.get(id);\n                  long nextVal = Math.abs(val)+1;\n\n                  if (oper < commitPercent + deletePercent) {\n                    // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": term delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new Term(\"id\",Integer.toString(id)));\n                    model.put(id, -nextVal);\n                  } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                    //assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": query delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new TermQuery(new Term(\"id\", Integer.toString(id))));\n                    model.put(id, -nextVal);\n                  } else {\n                    // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                    Document d = new Document();\n                    d.add(newStringField(\"id\", Integer.toString(id), Field.Store.YES));\n                    d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": u id:\" + id + \" val=\" + nextVal);\n                    }\n                    writer.updateDocument(new Term(\"id\", Integer.toString(id)), d);\n                    if (tombstones) {\n                      // remove tombstone after new addition (this should be optional?)\n                      writer.deleteDocuments(new Term(\"id\",\"-\"+Integer.toString(id)));\n                    }\n                    model.put(id, nextVal);\n                  }\n                }\n\n                if (!before) {\n                  lastId = id;\n                }\n              }\n            }\n          } catch (Throwable e) {\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            IndexReader lastReader = null;\n            IndexSearcher lastSearcher = null;\n\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              long val;\n              DirectoryReader r;\n              synchronized(TestStressNRT.this) {\n                val = committedModel.get(id);\n                r = reader;\n                r.incRef();\n              }\n\n              if (VERBOSE) {\n                System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": s id=\" + id + \" val=\" + val + \" r=\" + r.getVersion());\n              }\n\n              //  sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              IndexSearcher searcher;\n              if (r == lastReader) {\n                // Just re-use lastSearcher, else\n                // newSearcher may create too many thread\n                // pools (ExecutorService):\n                searcher = lastSearcher;\n              } else {\n                searcher = newSearcher(r);\n                lastReader = r;\n                lastSearcher = searcher;\n              }\n              Query q = new TermQuery(new Term(\"id\",Integer.toString(id)));\n              TopDocs results = searcher.search(q, 10);\n\n              if (results.totalHits == 0 && tombstones) {\n                // if we couldn't find the doc, look for its tombstone\n                q = new TermQuery(new Term(\"id\",\"-\"+Integer.toString(id)));\n                results = searcher.search(q, 1);\n                if (results.totalHits == 0) {\n                  if (val == -1L) {\n                    // expected... no doc was added yet\n                    r.decRef();\n                    continue;\n                  }\n                  fail(\"No documents or tombstones found for id \" + id + \", expected at least \" + val + \" reader=\" + r);\n                }\n              }\n\n              if (results.totalHits == 0 && !tombstones) {\n                // nothing to do - we can't tell anything from a deleted doc without tombstones\n              } else {\n                // we should have found the document, or its tombstone\n                if (results.totalHits != 1) {\n                  System.out.println(\"FAIL: hits id:\" + id + \" val=\" + val);\n                  for(ScoreDoc sd : results.scoreDocs) {\n                    final StoredDocument doc = r.document(sd.doc);\n                    System.out.println(\"  docID=\" + sd.doc + \" id:\" + doc.get(\"id\") + \" foundVal=\" + doc.get(field));\n                  }\n                  fail(\"id=\" + id + \" reader=\" + r + \" totalHits=\" + results.totalHits);\n                }\n                StoredDocument doc = searcher.doc(results.scoreDocs[0].doc);\n                long foundVal = Long.parseLong(doc.get(field));\n                if (foundVal < Math.abs(val)) {\n                  fail(\"foundVal=\" + foundVal + \" val=\" + val + \" id=\" + id + \" reader=\" + r);\n                }\n              }\n\n              r.decRef();\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    writer.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: close reader=\" + reader);\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    // update variables\n    final int commitPercent = random().nextInt(20);\n    final int softCommitPercent = random().nextInt(100); // what percent of the commits are soft\n    final int deletePercent = random().nextInt(50);\n    final int deleteByQueryPercent = random().nextInt(25);\n    final int ndocs = atLeast(50);\n    final int nWriteThreads = _TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    final int maxConcurrentCommits = _TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n    \n    final boolean tombstones = random().nextBoolean();\n\n    // query variables\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n\n    final int nReadThreads = _TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    initModel(ndocs);\n\n    final FieldType storedOnlyType = new FieldType();\n    storedOnlyType.setStored(true);\n\n    if (VERBOSE) {\n      System.out.println(\"\\n\");\n      System.out.println(\"TEST: commitPercent=\" + commitPercent);\n      System.out.println(\"TEST: softCommitPercent=\" + softCommitPercent);\n      System.out.println(\"TEST: deletePercent=\" + deletePercent);\n      System.out.println(\"TEST: deleteByQueryPercent=\" + deleteByQueryPercent);\n      System.out.println(\"TEST: ndocs=\" + ndocs);\n      System.out.println(\"TEST: nWriteThreads=\" + nWriteThreads);\n      System.out.println(\"TEST: nReadThreads=\" + nReadThreads);\n      System.out.println(\"TEST: maxConcurrentCommits=\" + maxConcurrentCommits);\n      System.out.println(\"TEST: tombstones=\" + tombstones);\n      System.out.println(\"TEST: operations=\" + operations);\n      System.out.println(\"\\n\");\n    }\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    Directory dir = newDirectory();\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    writer.setDoRandomForceMergeAssert(false);\n    writer.commit();\n    reader = DirectoryReader.open(dir);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n                  DirectoryReader oldReader;\n\n                  synchronized(TestStressNRT.this) {\n                    newCommittedModel = new HashMap<Integer,Long>(model);  // take a snapshot\n                    version = snapshotCount++;\n                    oldReader = reader;\n                    oldReader.incRef();  // increment the reference since we will use this for reopening\n                  }\n\n                  DirectoryReader newReader;\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    // assertU(h.commit(\"softCommit\",\"true\"));\n                    if (random().nextBoolean()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": call writer.getReader\");\n                      }\n                      newReader = writer.getReader(true);\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": reopen reader=\" + oldReader + \" version=\" + version);\n                      }\n                      newReader = DirectoryReader.openIfChanged(oldReader, writer.w, true);\n                    }\n                  } else {\n                    // assertU(commit());\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": commit+reopen reader=\" + oldReader + \" version=\" + version);\n                    }\n                    writer.commit();\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": now reopen after commit\");\n                    }\n                    newReader = DirectoryReader.openIfChanged(oldReader);\n                  }\n\n                  // Code below assumes newReader comes w/\n                  // extra ref:\n                  if (newReader == null) {\n                    oldReader.incRef();\n                    newReader = oldReader;\n                  }\n\n                  oldReader.decRef();\n\n                  synchronized(TestStressNRT.this) {\n                    // install the new reader if it's newest (and check the current version since another reader may have already been installed)\n                    //System.out.println(Thread.currentThread().getName() + \": newVersion=\" + newReader.getVersion());\n                    assert newReader.getRefCount() > 0;\n                    assert reader.getRefCount() > 0;\n                    if (newReader.getVersion() > reader.getVersion()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new reader=\" + newReader);\n                      }\n                      reader.decRef();\n                      reader = newReader;\n\n                      // Silly: forces fieldInfos to be\n                      // loaded so we don't hit IOE on later\n                      // reader.toString\n                      newReader.toString();\n\n                      // install this snapshot only if it's newer than the current one\n                      if (version >= committedModelClock) {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new model version=\" + version);\n                        }\n                        committedModel = newCommittedModel;\n                        committedModelClock = version;\n                      } else {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new model version=\" + version);\n                        }\n                      }\n                    } else {\n                      // if the same reader, don't decRef.\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new reader=\" + newReader);\n                      }\n                      newReader.decRef();\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else {\n\n                int id = rand.nextInt(ndocs);\n                Object sync = syncArr[id];\n\n                // set the lastId before we actually change it sometimes to try and\n                // uncover more race conditions between writing and reading\n                boolean before = random().nextBoolean();\n                if (before) {\n                  lastId = id;\n                }\n\n                // We can't concurrently update the same document and retain our invariants of increasing values\n                // since we can't guarantee what order the updates will be executed.\n                synchronized (sync) {\n                  Long val = model.get(id);\n                  long nextVal = Math.abs(val)+1;\n\n                  if (oper < commitPercent + deletePercent) {\n                    // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": term delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new Term(\"id\",Integer.toString(id)));\n                    model.put(id, -nextVal);\n                  } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                    //assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": query delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new TermQuery(new Term(\"id\", Integer.toString(id))));\n                    model.put(id, -nextVal);\n                  } else {\n                    // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                    Document d = new Document();\n                    d.add(newStringField(\"id\", Integer.toString(id), Field.Store.YES));\n                    d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": u id:\" + id + \" val=\" + nextVal);\n                    }\n                    writer.updateDocument(new Term(\"id\", Integer.toString(id)), d);\n                    if (tombstones) {\n                      // remove tombstone after new addition (this should be optional?)\n                      writer.deleteDocuments(new Term(\"id\",\"-\"+Integer.toString(id)));\n                    }\n                    model.put(id, nextVal);\n                  }\n                }\n\n                if (!before) {\n                  lastId = id;\n                }\n              }\n            }\n          } catch (Throwable e) {\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            IndexReader lastReader = null;\n            IndexSearcher lastSearcher = null;\n\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              long val;\n              DirectoryReader r;\n              synchronized(TestStressNRT.this) {\n                val = committedModel.get(id);\n                r = reader;\n                r.incRef();\n              }\n\n              if (VERBOSE) {\n                System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": s id=\" + id + \" val=\" + val + \" r=\" + r.getVersion());\n              }\n\n              //  sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              IndexSearcher searcher;\n              if (r == lastReader) {\n                // Just re-use lastSearcher, else\n                // newSearcher may create too many thread\n                // pools (ExecutorService):\n                searcher = lastSearcher;\n              } else {\n                searcher = newSearcher(r);\n                lastReader = r;\n                lastSearcher = searcher;\n              }\n              Query q = new TermQuery(new Term(\"id\",Integer.toString(id)));\n              TopDocs results = searcher.search(q, 10);\n\n              if (results.totalHits == 0 && tombstones) {\n                // if we couldn't find the doc, look for its tombstone\n                q = new TermQuery(new Term(\"id\",\"-\"+Integer.toString(id)));\n                results = searcher.search(q, 1);\n                if (results.totalHits == 0) {\n                  if (val == -1L) {\n                    // expected... no doc was added yet\n                    r.decRef();\n                    continue;\n                  }\n                  fail(\"No documents or tombstones found for id \" + id + \", expected at least \" + val + \" reader=\" + r);\n                }\n              }\n\n              if (results.totalHits == 0 && !tombstones) {\n                // nothing to do - we can't tell anything from a deleted doc without tombstones\n              } else {\n                // we should have found the document, or its tombstone\n                if (results.totalHits != 1) {\n                  System.out.println(\"FAIL: hits id:\" + id + \" val=\" + val);\n                  for(ScoreDoc sd : results.scoreDocs) {\n                    final StoredDocument doc = r.document(sd.doc);\n                    System.out.println(\"  docID=\" + sd.doc + \" id:\" + doc.get(\"id\") + \" foundVal=\" + doc.get(field));\n                  }\n                  fail(\"id=\" + id + \" reader=\" + r + \" totalHits=\" + results.totalHits);\n                }\n                StoredDocument doc = searcher.doc(results.scoreDocs[0].doc);\n                long foundVal = Long.parseLong(doc.get(field));\n                if (foundVal < Math.abs(val)) {\n                  fail(\"foundVal=\" + foundVal + \" val=\" + val + \" id=\" + id + \" reader=\" + r);\n                }\n              }\n\n              r.decRef();\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    writer.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: close reader=\" + reader);\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestStressNRT#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestStressNRT#test().mjava","sourceNew":"  public void test() throws Exception {\n    // update variables\n    final int commitPercent = random().nextInt(20);\n    final int softCommitPercent = random().nextInt(100); // what percent of the commits are soft\n    final int deletePercent = random().nextInt(50);\n    final int deleteByQueryPercent = random().nextInt(25);\n    final int ndocs = atLeast(50);\n    final int nWriteThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    final int maxConcurrentCommits = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n    \n    final boolean tombstones = random().nextBoolean();\n\n    // query variables\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n\n    final int nReadThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    initModel(ndocs);\n\n    final FieldType storedOnlyType = new FieldType();\n    storedOnlyType.setStored(true);\n\n    if (VERBOSE) {\n      System.out.println(\"\\n\");\n      System.out.println(\"TEST: commitPercent=\" + commitPercent);\n      System.out.println(\"TEST: softCommitPercent=\" + softCommitPercent);\n      System.out.println(\"TEST: deletePercent=\" + deletePercent);\n      System.out.println(\"TEST: deleteByQueryPercent=\" + deleteByQueryPercent);\n      System.out.println(\"TEST: ndocs=\" + ndocs);\n      System.out.println(\"TEST: nWriteThreads=\" + nWriteThreads);\n      System.out.println(\"TEST: nReadThreads=\" + nReadThreads);\n      System.out.println(\"TEST: maxConcurrentCommits=\" + maxConcurrentCommits);\n      System.out.println(\"TEST: tombstones=\" + tombstones);\n      System.out.println(\"TEST: operations=\" + operations);\n      System.out.println(\"\\n\");\n    }\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<>();\n\n    Directory dir = newDirectory();\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    writer.setDoRandomForceMergeAssert(false);\n    writer.commit();\n    reader = DirectoryReader.open(dir);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n                  DirectoryReader oldReader;\n\n                  synchronized(TestStressNRT.this) {\n                    newCommittedModel = new HashMap<>(model);  // take a snapshot\n                    version = snapshotCount++;\n                    oldReader = reader;\n                    oldReader.incRef();  // increment the reference since we will use this for reopening\n                  }\n\n                  DirectoryReader newReader;\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    // assertU(h.commit(\"softCommit\",\"true\"));\n                    if (random().nextBoolean()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": call writer.getReader\");\n                      }\n                      newReader = writer.getReader(true);\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": reopen reader=\" + oldReader + \" version=\" + version);\n                      }\n                      newReader = DirectoryReader.openIfChanged(oldReader, writer.w, true);\n                    }\n                  } else {\n                    // assertU(commit());\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": commit+reopen reader=\" + oldReader + \" version=\" + version);\n                    }\n                    writer.commit();\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": now reopen after commit\");\n                    }\n                    newReader = DirectoryReader.openIfChanged(oldReader);\n                  }\n\n                  // Code below assumes newReader comes w/\n                  // extra ref:\n                  if (newReader == null) {\n                    oldReader.incRef();\n                    newReader = oldReader;\n                  }\n\n                  oldReader.decRef();\n\n                  synchronized(TestStressNRT.this) {\n                    // install the new reader if it's newest (and check the current version since another reader may have already been installed)\n                    //System.out.println(Thread.currentThread().getName() + \": newVersion=\" + newReader.getVersion());\n                    assert newReader.getRefCount() > 0;\n                    assert reader.getRefCount() > 0;\n                    if (newReader.getVersion() > reader.getVersion()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new reader=\" + newReader);\n                      }\n                      reader.decRef();\n                      reader = newReader;\n\n                      // Silly: forces fieldInfos to be\n                      // loaded so we don't hit IOE on later\n                      // reader.toString\n                      newReader.toString();\n\n                      // install this snapshot only if it's newer than the current one\n                      if (version >= committedModelClock) {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new model version=\" + version);\n                        }\n                        committedModel = newCommittedModel;\n                        committedModelClock = version;\n                      } else {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new model version=\" + version);\n                        }\n                      }\n                    } else {\n                      // if the same reader, don't decRef.\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new reader=\" + newReader);\n                      }\n                      newReader.decRef();\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else {\n\n                int id = rand.nextInt(ndocs);\n                Object sync = syncArr[id];\n\n                // set the lastId before we actually change it sometimes to try and\n                // uncover more race conditions between writing and reading\n                boolean before = random().nextBoolean();\n                if (before) {\n                  lastId = id;\n                }\n\n                // We can't concurrently update the same document and retain our invariants of increasing values\n                // since we can't guarantee what order the updates will be executed.\n                synchronized (sync) {\n                  Long val = model.get(id);\n                  long nextVal = Math.abs(val)+1;\n\n                  if (oper < commitPercent + deletePercent) {\n                    // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": term delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new Term(\"id\",Integer.toString(id)));\n                    model.put(id, -nextVal);\n                  } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                    //assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": query delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new TermQuery(new Term(\"id\", Integer.toString(id))));\n                    model.put(id, -nextVal);\n                  } else {\n                    // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                    Document d = new Document();\n                    d.add(newStringField(\"id\", Integer.toString(id), Field.Store.YES));\n                    d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": u id:\" + id + \" val=\" + nextVal);\n                    }\n                    writer.updateDocument(new Term(\"id\", Integer.toString(id)), d);\n                    if (tombstones) {\n                      // remove tombstone after new addition (this should be optional?)\n                      writer.deleteDocuments(new Term(\"id\",\"-\"+Integer.toString(id)));\n                    }\n                    model.put(id, nextVal);\n                  }\n                }\n\n                if (!before) {\n                  lastId = id;\n                }\n              }\n            }\n          } catch (Throwable e) {\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            IndexReader lastReader = null;\n            IndexSearcher lastSearcher = null;\n\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              long val;\n              DirectoryReader r;\n              synchronized(TestStressNRT.this) {\n                val = committedModel.get(id);\n                r = reader;\n                r.incRef();\n              }\n\n              if (VERBOSE) {\n                System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": s id=\" + id + \" val=\" + val + \" r=\" + r.getVersion());\n              }\n\n              //  sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              IndexSearcher searcher;\n              if (r == lastReader) {\n                // Just re-use lastSearcher, else\n                // newSearcher may create too many thread\n                // pools (ExecutorService):\n                searcher = lastSearcher;\n              } else {\n                searcher = newSearcher(r);\n                lastReader = r;\n                lastSearcher = searcher;\n              }\n              Query q = new TermQuery(new Term(\"id\",Integer.toString(id)));\n              TopDocs results = searcher.search(q, 10);\n\n              if (results.totalHits == 0 && tombstones) {\n                // if we couldn't find the doc, look for its tombstone\n                q = new TermQuery(new Term(\"id\",\"-\"+Integer.toString(id)));\n                results = searcher.search(q, 1);\n                if (results.totalHits == 0) {\n                  if (val == -1L) {\n                    // expected... no doc was added yet\n                    r.decRef();\n                    continue;\n                  }\n                  fail(\"No documents or tombstones found for id \" + id + \", expected at least \" + val + \" reader=\" + r);\n                }\n              }\n\n              if (results.totalHits == 0 && !tombstones) {\n                // nothing to do - we can't tell anything from a deleted doc without tombstones\n              } else {\n                // we should have found the document, or its tombstone\n                if (results.totalHits != 1) {\n                  System.out.println(\"FAIL: hits id:\" + id + \" val=\" + val);\n                  for(ScoreDoc sd : results.scoreDocs) {\n                    final StoredDocument doc = r.document(sd.doc);\n                    System.out.println(\"  docID=\" + sd.doc + \" id:\" + doc.get(\"id\") + \" foundVal=\" + doc.get(field));\n                  }\n                  fail(\"id=\" + id + \" reader=\" + r + \" totalHits=\" + results.totalHits);\n                }\n                StoredDocument doc = searcher.doc(results.scoreDocs[0].doc);\n                long foundVal = Long.parseLong(doc.get(field));\n                if (foundVal < Math.abs(val)) {\n                  fail(\"foundVal=\" + foundVal + \" val=\" + val + \" id=\" + id + \" reader=\" + r);\n                }\n              }\n\n              r.decRef();\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    writer.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: close reader=\" + reader);\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    // update variables\n    final int commitPercent = random().nextInt(20);\n    final int softCommitPercent = random().nextInt(100); // what percent of the commits are soft\n    final int deletePercent = random().nextInt(50);\n    final int deleteByQueryPercent = random().nextInt(25);\n    final int ndocs = atLeast(50);\n    final int nWriteThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    final int maxConcurrentCommits = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n    \n    final boolean tombstones = random().nextBoolean();\n\n    // query variables\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n\n    final int nReadThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    initModel(ndocs);\n\n    final FieldType storedOnlyType = new FieldType();\n    storedOnlyType.setStored(true);\n\n    if (VERBOSE) {\n      System.out.println(\"\\n\");\n      System.out.println(\"TEST: commitPercent=\" + commitPercent);\n      System.out.println(\"TEST: softCommitPercent=\" + softCommitPercent);\n      System.out.println(\"TEST: deletePercent=\" + deletePercent);\n      System.out.println(\"TEST: deleteByQueryPercent=\" + deleteByQueryPercent);\n      System.out.println(\"TEST: ndocs=\" + ndocs);\n      System.out.println(\"TEST: nWriteThreads=\" + nWriteThreads);\n      System.out.println(\"TEST: nReadThreads=\" + nReadThreads);\n      System.out.println(\"TEST: maxConcurrentCommits=\" + maxConcurrentCommits);\n      System.out.println(\"TEST: tombstones=\" + tombstones);\n      System.out.println(\"TEST: operations=\" + operations);\n      System.out.println(\"\\n\");\n    }\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    Directory dir = newDirectory();\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    writer.setDoRandomForceMergeAssert(false);\n    writer.commit();\n    reader = DirectoryReader.open(dir);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n                  DirectoryReader oldReader;\n\n                  synchronized(TestStressNRT.this) {\n                    newCommittedModel = new HashMap<Integer,Long>(model);  // take a snapshot\n                    version = snapshotCount++;\n                    oldReader = reader;\n                    oldReader.incRef();  // increment the reference since we will use this for reopening\n                  }\n\n                  DirectoryReader newReader;\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    // assertU(h.commit(\"softCommit\",\"true\"));\n                    if (random().nextBoolean()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": call writer.getReader\");\n                      }\n                      newReader = writer.getReader(true);\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": reopen reader=\" + oldReader + \" version=\" + version);\n                      }\n                      newReader = DirectoryReader.openIfChanged(oldReader, writer.w, true);\n                    }\n                  } else {\n                    // assertU(commit());\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": commit+reopen reader=\" + oldReader + \" version=\" + version);\n                    }\n                    writer.commit();\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": now reopen after commit\");\n                    }\n                    newReader = DirectoryReader.openIfChanged(oldReader);\n                  }\n\n                  // Code below assumes newReader comes w/\n                  // extra ref:\n                  if (newReader == null) {\n                    oldReader.incRef();\n                    newReader = oldReader;\n                  }\n\n                  oldReader.decRef();\n\n                  synchronized(TestStressNRT.this) {\n                    // install the new reader if it's newest (and check the current version since another reader may have already been installed)\n                    //System.out.println(Thread.currentThread().getName() + \": newVersion=\" + newReader.getVersion());\n                    assert newReader.getRefCount() > 0;\n                    assert reader.getRefCount() > 0;\n                    if (newReader.getVersion() > reader.getVersion()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new reader=\" + newReader);\n                      }\n                      reader.decRef();\n                      reader = newReader;\n\n                      // Silly: forces fieldInfos to be\n                      // loaded so we don't hit IOE on later\n                      // reader.toString\n                      newReader.toString();\n\n                      // install this snapshot only if it's newer than the current one\n                      if (version >= committedModelClock) {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new model version=\" + version);\n                        }\n                        committedModel = newCommittedModel;\n                        committedModelClock = version;\n                      } else {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new model version=\" + version);\n                        }\n                      }\n                    } else {\n                      // if the same reader, don't decRef.\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new reader=\" + newReader);\n                      }\n                      newReader.decRef();\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else {\n\n                int id = rand.nextInt(ndocs);\n                Object sync = syncArr[id];\n\n                // set the lastId before we actually change it sometimes to try and\n                // uncover more race conditions between writing and reading\n                boolean before = random().nextBoolean();\n                if (before) {\n                  lastId = id;\n                }\n\n                // We can't concurrently update the same document and retain our invariants of increasing values\n                // since we can't guarantee what order the updates will be executed.\n                synchronized (sync) {\n                  Long val = model.get(id);\n                  long nextVal = Math.abs(val)+1;\n\n                  if (oper < commitPercent + deletePercent) {\n                    // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": term delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new Term(\"id\",Integer.toString(id)));\n                    model.put(id, -nextVal);\n                  } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                    //assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": query delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new TermQuery(new Term(\"id\", Integer.toString(id))));\n                    model.put(id, -nextVal);\n                  } else {\n                    // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                    Document d = new Document();\n                    d.add(newStringField(\"id\", Integer.toString(id), Field.Store.YES));\n                    d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": u id:\" + id + \" val=\" + nextVal);\n                    }\n                    writer.updateDocument(new Term(\"id\", Integer.toString(id)), d);\n                    if (tombstones) {\n                      // remove tombstone after new addition (this should be optional?)\n                      writer.deleteDocuments(new Term(\"id\",\"-\"+Integer.toString(id)));\n                    }\n                    model.put(id, nextVal);\n                  }\n                }\n\n                if (!before) {\n                  lastId = id;\n                }\n              }\n            }\n          } catch (Throwable e) {\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            IndexReader lastReader = null;\n            IndexSearcher lastSearcher = null;\n\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              long val;\n              DirectoryReader r;\n              synchronized(TestStressNRT.this) {\n                val = committedModel.get(id);\n                r = reader;\n                r.incRef();\n              }\n\n              if (VERBOSE) {\n                System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": s id=\" + id + \" val=\" + val + \" r=\" + r.getVersion());\n              }\n\n              //  sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              IndexSearcher searcher;\n              if (r == lastReader) {\n                // Just re-use lastSearcher, else\n                // newSearcher may create too many thread\n                // pools (ExecutorService):\n                searcher = lastSearcher;\n              } else {\n                searcher = newSearcher(r);\n                lastReader = r;\n                lastSearcher = searcher;\n              }\n              Query q = new TermQuery(new Term(\"id\",Integer.toString(id)));\n              TopDocs results = searcher.search(q, 10);\n\n              if (results.totalHits == 0 && tombstones) {\n                // if we couldn't find the doc, look for its tombstone\n                q = new TermQuery(new Term(\"id\",\"-\"+Integer.toString(id)));\n                results = searcher.search(q, 1);\n                if (results.totalHits == 0) {\n                  if (val == -1L) {\n                    // expected... no doc was added yet\n                    r.decRef();\n                    continue;\n                  }\n                  fail(\"No documents or tombstones found for id \" + id + \", expected at least \" + val + \" reader=\" + r);\n                }\n              }\n\n              if (results.totalHits == 0 && !tombstones) {\n                // nothing to do - we can't tell anything from a deleted doc without tombstones\n              } else {\n                // we should have found the document, or its tombstone\n                if (results.totalHits != 1) {\n                  System.out.println(\"FAIL: hits id:\" + id + \" val=\" + val);\n                  for(ScoreDoc sd : results.scoreDocs) {\n                    final StoredDocument doc = r.document(sd.doc);\n                    System.out.println(\"  docID=\" + sd.doc + \" id:\" + doc.get(\"id\") + \" foundVal=\" + doc.get(field));\n                  }\n                  fail(\"id=\" + id + \" reader=\" + r + \" totalHits=\" + results.totalHits);\n                }\n                StoredDocument doc = searcher.doc(results.scoreDocs[0].doc);\n                long foundVal = Long.parseLong(doc.get(field));\n                if (foundVal < Math.abs(val)) {\n                  fail(\"foundVal=\" + foundVal + \" val=\" + val + \" id=\" + id + \" reader=\" + r);\n                }\n              }\n\n              r.decRef();\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    writer.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: close reader=\" + reader);\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestStressNRT#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestStressNRT#test().mjava","sourceNew":"  public void test() throws Exception {\n    // update variables\n    final int commitPercent = random().nextInt(20);\n    final int softCommitPercent = random().nextInt(100); // what percent of the commits are soft\n    final int deletePercent = random().nextInt(50);\n    final int deleteByQueryPercent = random().nextInt(25);\n    final int ndocs = atLeast(50);\n    final int nWriteThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    final int maxConcurrentCommits = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n    \n    final boolean tombstones = random().nextBoolean();\n\n    // query variables\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n\n    final int nReadThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    initModel(ndocs);\n\n    final FieldType storedOnlyType = new FieldType();\n    storedOnlyType.setStored(true);\n\n    if (VERBOSE) {\n      System.out.println(\"\\n\");\n      System.out.println(\"TEST: commitPercent=\" + commitPercent);\n      System.out.println(\"TEST: softCommitPercent=\" + softCommitPercent);\n      System.out.println(\"TEST: deletePercent=\" + deletePercent);\n      System.out.println(\"TEST: deleteByQueryPercent=\" + deleteByQueryPercent);\n      System.out.println(\"TEST: ndocs=\" + ndocs);\n      System.out.println(\"TEST: nWriteThreads=\" + nWriteThreads);\n      System.out.println(\"TEST: nReadThreads=\" + nReadThreads);\n      System.out.println(\"TEST: maxConcurrentCommits=\" + maxConcurrentCommits);\n      System.out.println(\"TEST: tombstones=\" + tombstones);\n      System.out.println(\"TEST: operations=\" + operations);\n      System.out.println(\"\\n\");\n    }\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<>();\n\n    Directory dir = newDirectory();\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    writer.setDoRandomForceMergeAssert(false);\n    writer.commit();\n    reader = DirectoryReader.open(dir);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n                  DirectoryReader oldReader;\n\n                  synchronized(TestStressNRT.this) {\n                    newCommittedModel = new HashMap<>(model);  // take a snapshot\n                    version = snapshotCount++;\n                    oldReader = reader;\n                    oldReader.incRef();  // increment the reference since we will use this for reopening\n                  }\n\n                  DirectoryReader newReader;\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    // assertU(h.commit(\"softCommit\",\"true\"));\n                    if (random().nextBoolean()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": call writer.getReader\");\n                      }\n                      newReader = writer.getReader(true);\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": reopen reader=\" + oldReader + \" version=\" + version);\n                      }\n                      newReader = DirectoryReader.openIfChanged(oldReader, writer.w, true);\n                    }\n                  } else {\n                    // assertU(commit());\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": commit+reopen reader=\" + oldReader + \" version=\" + version);\n                    }\n                    writer.commit();\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": now reopen after commit\");\n                    }\n                    newReader = DirectoryReader.openIfChanged(oldReader);\n                  }\n\n                  // Code below assumes newReader comes w/\n                  // extra ref:\n                  if (newReader == null) {\n                    oldReader.incRef();\n                    newReader = oldReader;\n                  }\n\n                  oldReader.decRef();\n\n                  synchronized(TestStressNRT.this) {\n                    // install the new reader if it's newest (and check the current version since another reader may have already been installed)\n                    //System.out.println(Thread.currentThread().getName() + \": newVersion=\" + newReader.getVersion());\n                    assert newReader.getRefCount() > 0;\n                    assert reader.getRefCount() > 0;\n                    if (newReader.getVersion() > reader.getVersion()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new reader=\" + newReader);\n                      }\n                      reader.decRef();\n                      reader = newReader;\n\n                      // Silly: forces fieldInfos to be\n                      // loaded so we don't hit IOE on later\n                      // reader.toString\n                      newReader.toString();\n\n                      // install this snapshot only if it's newer than the current one\n                      if (version >= committedModelClock) {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new model version=\" + version);\n                        }\n                        committedModel = newCommittedModel;\n                        committedModelClock = version;\n                      } else {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new model version=\" + version);\n                        }\n                      }\n                    } else {\n                      // if the same reader, don't decRef.\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new reader=\" + newReader);\n                      }\n                      newReader.decRef();\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else {\n\n                int id = rand.nextInt(ndocs);\n                Object sync = syncArr[id];\n\n                // set the lastId before we actually change it sometimes to try and\n                // uncover more race conditions between writing and reading\n                boolean before = random().nextBoolean();\n                if (before) {\n                  lastId = id;\n                }\n\n                // We can't concurrently update the same document and retain our invariants of increasing values\n                // since we can't guarantee what order the updates will be executed.\n                synchronized (sync) {\n                  Long val = model.get(id);\n                  long nextVal = Math.abs(val)+1;\n\n                  if (oper < commitPercent + deletePercent) {\n                    // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": term delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new Term(\"id\",Integer.toString(id)));\n                    model.put(id, -nextVal);\n                  } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                    //assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": query delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new TermQuery(new Term(\"id\", Integer.toString(id))));\n                    model.put(id, -nextVal);\n                  } else {\n                    // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                    Document d = new Document();\n                    d.add(newStringField(\"id\", Integer.toString(id), Field.Store.YES));\n                    d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": u id:\" + id + \" val=\" + nextVal);\n                    }\n                    writer.updateDocument(new Term(\"id\", Integer.toString(id)), d);\n                    if (tombstones) {\n                      // remove tombstone after new addition (this should be optional?)\n                      writer.deleteDocuments(new Term(\"id\",\"-\"+Integer.toString(id)));\n                    }\n                    model.put(id, nextVal);\n                  }\n                }\n\n                if (!before) {\n                  lastId = id;\n                }\n              }\n            }\n          } catch (Throwable e) {\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            IndexReader lastReader = null;\n            IndexSearcher lastSearcher = null;\n\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              long val;\n              DirectoryReader r;\n              synchronized(TestStressNRT.this) {\n                val = committedModel.get(id);\n                r = reader;\n                r.incRef();\n              }\n\n              if (VERBOSE) {\n                System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": s id=\" + id + \" val=\" + val + \" r=\" + r.getVersion());\n              }\n\n              //  sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              IndexSearcher searcher;\n              if (r == lastReader) {\n                // Just re-use lastSearcher, else\n                // newSearcher may create too many thread\n                // pools (ExecutorService):\n                searcher = lastSearcher;\n              } else {\n                searcher = newSearcher(r);\n                lastReader = r;\n                lastSearcher = searcher;\n              }\n              Query q = new TermQuery(new Term(\"id\",Integer.toString(id)));\n              TopDocs results = searcher.search(q, 10);\n\n              if (results.totalHits == 0 && tombstones) {\n                // if we couldn't find the doc, look for its tombstone\n                q = new TermQuery(new Term(\"id\",\"-\"+Integer.toString(id)));\n                results = searcher.search(q, 1);\n                if (results.totalHits == 0) {\n                  if (val == -1L) {\n                    // expected... no doc was added yet\n                    r.decRef();\n                    continue;\n                  }\n                  fail(\"No documents or tombstones found for id \" + id + \", expected at least \" + val + \" reader=\" + r);\n                }\n              }\n\n              if (results.totalHits == 0 && !tombstones) {\n                // nothing to do - we can't tell anything from a deleted doc without tombstones\n              } else {\n                // we should have found the document, or its tombstone\n                if (results.totalHits != 1) {\n                  System.out.println(\"FAIL: hits id:\" + id + \" val=\" + val);\n                  for(ScoreDoc sd : results.scoreDocs) {\n                    final StoredDocument doc = r.document(sd.doc);\n                    System.out.println(\"  docID=\" + sd.doc + \" id:\" + doc.get(\"id\") + \" foundVal=\" + doc.get(field));\n                  }\n                  fail(\"id=\" + id + \" reader=\" + r + \" totalHits=\" + results.totalHits);\n                }\n                StoredDocument doc = searcher.doc(results.scoreDocs[0].doc);\n                long foundVal = Long.parseLong(doc.get(field));\n                if (foundVal < Math.abs(val)) {\n                  fail(\"foundVal=\" + foundVal + \" val=\" + val + \" id=\" + id + \" reader=\" + r);\n                }\n              }\n\n              r.decRef();\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    writer.shutdown();\n    if (VERBOSE) {\n      System.out.println(\"TEST: close reader=\" + reader);\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    // update variables\n    final int commitPercent = random().nextInt(20);\n    final int softCommitPercent = random().nextInt(100); // what percent of the commits are soft\n    final int deletePercent = random().nextInt(50);\n    final int deleteByQueryPercent = random().nextInt(25);\n    final int ndocs = atLeast(50);\n    final int nWriteThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    final int maxConcurrentCommits = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n    \n    final boolean tombstones = random().nextBoolean();\n\n    // query variables\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n\n    final int nReadThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    initModel(ndocs);\n\n    final FieldType storedOnlyType = new FieldType();\n    storedOnlyType.setStored(true);\n\n    if (VERBOSE) {\n      System.out.println(\"\\n\");\n      System.out.println(\"TEST: commitPercent=\" + commitPercent);\n      System.out.println(\"TEST: softCommitPercent=\" + softCommitPercent);\n      System.out.println(\"TEST: deletePercent=\" + deletePercent);\n      System.out.println(\"TEST: deleteByQueryPercent=\" + deleteByQueryPercent);\n      System.out.println(\"TEST: ndocs=\" + ndocs);\n      System.out.println(\"TEST: nWriteThreads=\" + nWriteThreads);\n      System.out.println(\"TEST: nReadThreads=\" + nReadThreads);\n      System.out.println(\"TEST: maxConcurrentCommits=\" + maxConcurrentCommits);\n      System.out.println(\"TEST: tombstones=\" + tombstones);\n      System.out.println(\"TEST: operations=\" + operations);\n      System.out.println(\"\\n\");\n    }\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<>();\n\n    Directory dir = newDirectory();\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    writer.setDoRandomForceMergeAssert(false);\n    writer.commit();\n    reader = DirectoryReader.open(dir);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n                  DirectoryReader oldReader;\n\n                  synchronized(TestStressNRT.this) {\n                    newCommittedModel = new HashMap<>(model);  // take a snapshot\n                    version = snapshotCount++;\n                    oldReader = reader;\n                    oldReader.incRef();  // increment the reference since we will use this for reopening\n                  }\n\n                  DirectoryReader newReader;\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    // assertU(h.commit(\"softCommit\",\"true\"));\n                    if (random().nextBoolean()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": call writer.getReader\");\n                      }\n                      newReader = writer.getReader(true);\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": reopen reader=\" + oldReader + \" version=\" + version);\n                      }\n                      newReader = DirectoryReader.openIfChanged(oldReader, writer.w, true);\n                    }\n                  } else {\n                    // assertU(commit());\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": commit+reopen reader=\" + oldReader + \" version=\" + version);\n                    }\n                    writer.commit();\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": now reopen after commit\");\n                    }\n                    newReader = DirectoryReader.openIfChanged(oldReader);\n                  }\n\n                  // Code below assumes newReader comes w/\n                  // extra ref:\n                  if (newReader == null) {\n                    oldReader.incRef();\n                    newReader = oldReader;\n                  }\n\n                  oldReader.decRef();\n\n                  synchronized(TestStressNRT.this) {\n                    // install the new reader if it's newest (and check the current version since another reader may have already been installed)\n                    //System.out.println(Thread.currentThread().getName() + \": newVersion=\" + newReader.getVersion());\n                    assert newReader.getRefCount() > 0;\n                    assert reader.getRefCount() > 0;\n                    if (newReader.getVersion() > reader.getVersion()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new reader=\" + newReader);\n                      }\n                      reader.decRef();\n                      reader = newReader;\n\n                      // Silly: forces fieldInfos to be\n                      // loaded so we don't hit IOE on later\n                      // reader.toString\n                      newReader.toString();\n\n                      // install this snapshot only if it's newer than the current one\n                      if (version >= committedModelClock) {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new model version=\" + version);\n                        }\n                        committedModel = newCommittedModel;\n                        committedModelClock = version;\n                      } else {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new model version=\" + version);\n                        }\n                      }\n                    } else {\n                      // if the same reader, don't decRef.\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new reader=\" + newReader);\n                      }\n                      newReader.decRef();\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else {\n\n                int id = rand.nextInt(ndocs);\n                Object sync = syncArr[id];\n\n                // set the lastId before we actually change it sometimes to try and\n                // uncover more race conditions between writing and reading\n                boolean before = random().nextBoolean();\n                if (before) {\n                  lastId = id;\n                }\n\n                // We can't concurrently update the same document and retain our invariants of increasing values\n                // since we can't guarantee what order the updates will be executed.\n                synchronized (sync) {\n                  Long val = model.get(id);\n                  long nextVal = Math.abs(val)+1;\n\n                  if (oper < commitPercent + deletePercent) {\n                    // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": term delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new Term(\"id\",Integer.toString(id)));\n                    model.put(id, -nextVal);\n                  } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                    //assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": query delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new TermQuery(new Term(\"id\", Integer.toString(id))));\n                    model.put(id, -nextVal);\n                  } else {\n                    // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                    Document d = new Document();\n                    d.add(newStringField(\"id\", Integer.toString(id), Field.Store.YES));\n                    d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": u id:\" + id + \" val=\" + nextVal);\n                    }\n                    writer.updateDocument(new Term(\"id\", Integer.toString(id)), d);\n                    if (tombstones) {\n                      // remove tombstone after new addition (this should be optional?)\n                      writer.deleteDocuments(new Term(\"id\",\"-\"+Integer.toString(id)));\n                    }\n                    model.put(id, nextVal);\n                  }\n                }\n\n                if (!before) {\n                  lastId = id;\n                }\n              }\n            }\n          } catch (Throwable e) {\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            IndexReader lastReader = null;\n            IndexSearcher lastSearcher = null;\n\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              long val;\n              DirectoryReader r;\n              synchronized(TestStressNRT.this) {\n                val = committedModel.get(id);\n                r = reader;\n                r.incRef();\n              }\n\n              if (VERBOSE) {\n                System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": s id=\" + id + \" val=\" + val + \" r=\" + r.getVersion());\n              }\n\n              //  sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              IndexSearcher searcher;\n              if (r == lastReader) {\n                // Just re-use lastSearcher, else\n                // newSearcher may create too many thread\n                // pools (ExecutorService):\n                searcher = lastSearcher;\n              } else {\n                searcher = newSearcher(r);\n                lastReader = r;\n                lastSearcher = searcher;\n              }\n              Query q = new TermQuery(new Term(\"id\",Integer.toString(id)));\n              TopDocs results = searcher.search(q, 10);\n\n              if (results.totalHits == 0 && tombstones) {\n                // if we couldn't find the doc, look for its tombstone\n                q = new TermQuery(new Term(\"id\",\"-\"+Integer.toString(id)));\n                results = searcher.search(q, 1);\n                if (results.totalHits == 0) {\n                  if (val == -1L) {\n                    // expected... no doc was added yet\n                    r.decRef();\n                    continue;\n                  }\n                  fail(\"No documents or tombstones found for id \" + id + \", expected at least \" + val + \" reader=\" + r);\n                }\n              }\n\n              if (results.totalHits == 0 && !tombstones) {\n                // nothing to do - we can't tell anything from a deleted doc without tombstones\n              } else {\n                // we should have found the document, or its tombstone\n                if (results.totalHits != 1) {\n                  System.out.println(\"FAIL: hits id:\" + id + \" val=\" + val);\n                  for(ScoreDoc sd : results.scoreDocs) {\n                    final StoredDocument doc = r.document(sd.doc);\n                    System.out.println(\"  docID=\" + sd.doc + \" id:\" + doc.get(\"id\") + \" foundVal=\" + doc.get(field));\n                  }\n                  fail(\"id=\" + id + \" reader=\" + r + \" totalHits=\" + results.totalHits);\n                }\n                StoredDocument doc = searcher.doc(results.scoreDocs[0].doc);\n                long foundVal = Long.parseLong(doc.get(field));\n                if (foundVal < Math.abs(val)) {\n                  fail(\"foundVal=\" + foundVal + \" val=\" + val + \" id=\" + id + \" reader=\" + r);\n                }\n              }\n\n              r.decRef();\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    writer.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: close reader=\" + reader);\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestStressNRT#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestStressNRT#test().mjava","sourceNew":"  public void test() throws Exception {\n    // update variables\n    final int commitPercent = random().nextInt(20);\n    final int softCommitPercent = random().nextInt(100); // what percent of the commits are soft\n    final int deletePercent = random().nextInt(50);\n    final int deleteByQueryPercent = random().nextInt(25);\n    final int ndocs = atLeast(50);\n    final int nWriteThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    final int maxConcurrentCommits = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n    \n    final boolean tombstones = random().nextBoolean();\n\n    // query variables\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n\n    final int nReadThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    initModel(ndocs);\n\n    final FieldType storedOnlyType = new FieldType();\n    storedOnlyType.setStored(true);\n\n    if (VERBOSE) {\n      System.out.println(\"\\n\");\n      System.out.println(\"TEST: commitPercent=\" + commitPercent);\n      System.out.println(\"TEST: softCommitPercent=\" + softCommitPercent);\n      System.out.println(\"TEST: deletePercent=\" + deletePercent);\n      System.out.println(\"TEST: deleteByQueryPercent=\" + deleteByQueryPercent);\n      System.out.println(\"TEST: ndocs=\" + ndocs);\n      System.out.println(\"TEST: nWriteThreads=\" + nWriteThreads);\n      System.out.println(\"TEST: nReadThreads=\" + nReadThreads);\n      System.out.println(\"TEST: maxConcurrentCommits=\" + maxConcurrentCommits);\n      System.out.println(\"TEST: tombstones=\" + tombstones);\n      System.out.println(\"TEST: operations=\" + operations);\n      System.out.println(\"\\n\");\n    }\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<>();\n\n    Directory dir = newDirectory();\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    writer.setDoRandomForceMergeAssert(false);\n    writer.commit();\n    reader = DirectoryReader.open(dir);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n                  DirectoryReader oldReader;\n\n                  synchronized(TestStressNRT.this) {\n                    newCommittedModel = new HashMap<>(model);  // take a snapshot\n                    version = snapshotCount++;\n                    oldReader = reader;\n                    oldReader.incRef();  // increment the reference since we will use this for reopening\n                  }\n\n                  DirectoryReader newReader;\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    // assertU(h.commit(\"softCommit\",\"true\"));\n                    if (random().nextBoolean()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": call writer.getReader\");\n                      }\n                      newReader = writer.getReader(true);\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": reopen reader=\" + oldReader + \" version=\" + version);\n                      }\n                      newReader = DirectoryReader.openIfChanged(oldReader, writer.w, true);\n                    }\n                  } else {\n                    // assertU(commit());\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": commit+reopen reader=\" + oldReader + \" version=\" + version);\n                    }\n                    writer.commit();\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": now reopen after commit\");\n                    }\n                    newReader = DirectoryReader.openIfChanged(oldReader);\n                  }\n\n                  // Code below assumes newReader comes w/\n                  // extra ref:\n                  if (newReader == null) {\n                    oldReader.incRef();\n                    newReader = oldReader;\n                  }\n\n                  oldReader.decRef();\n\n                  synchronized(TestStressNRT.this) {\n                    // install the new reader if it's newest (and check the current version since another reader may have already been installed)\n                    //System.out.println(Thread.currentThread().getName() + \": newVersion=\" + newReader.getVersion());\n                    assert newReader.getRefCount() > 0;\n                    assert reader.getRefCount() > 0;\n                    if (newReader.getVersion() > reader.getVersion()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new reader=\" + newReader);\n                      }\n                      reader.decRef();\n                      reader = newReader;\n\n                      // Silly: forces fieldInfos to be\n                      // loaded so we don't hit IOE on later\n                      // reader.toString\n                      newReader.toString();\n\n                      // install this snapshot only if it's newer than the current one\n                      if (version >= committedModelClock) {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new model version=\" + version);\n                        }\n                        committedModel = newCommittedModel;\n                        committedModelClock = version;\n                      } else {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new model version=\" + version);\n                        }\n                      }\n                    } else {\n                      // if the same reader, don't decRef.\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new reader=\" + newReader);\n                      }\n                      newReader.decRef();\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else {\n\n                int id = rand.nextInt(ndocs);\n                Object sync = syncArr[id];\n\n                // set the lastId before we actually change it sometimes to try and\n                // uncover more race conditions between writing and reading\n                boolean before = random().nextBoolean();\n                if (before) {\n                  lastId = id;\n                }\n\n                // We can't concurrently update the same document and retain our invariants of increasing values\n                // since we can't guarantee what order the updates will be executed.\n                synchronized (sync) {\n                  Long val = model.get(id);\n                  long nextVal = Math.abs(val)+1;\n\n                  if (oper < commitPercent + deletePercent) {\n                    // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": term delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new Term(\"id\",Integer.toString(id)));\n                    model.put(id, -nextVal);\n                  } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                    //assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": query delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new TermQuery(new Term(\"id\", Integer.toString(id))));\n                    model.put(id, -nextVal);\n                  } else {\n                    // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                    Document d = new Document();\n                    d.add(newStringField(\"id\", Integer.toString(id), Field.Store.YES));\n                    d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": u id:\" + id + \" val=\" + nextVal);\n                    }\n                    writer.updateDocument(new Term(\"id\", Integer.toString(id)), d);\n                    if (tombstones) {\n                      // remove tombstone after new addition (this should be optional?)\n                      writer.deleteDocuments(new Term(\"id\",\"-\"+Integer.toString(id)));\n                    }\n                    model.put(id, nextVal);\n                  }\n                }\n\n                if (!before) {\n                  lastId = id;\n                }\n              }\n            }\n          } catch (Throwable e) {\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            IndexReader lastReader = null;\n            IndexSearcher lastSearcher = null;\n\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              long val;\n              DirectoryReader r;\n              synchronized(TestStressNRT.this) {\n                val = committedModel.get(id);\n                r = reader;\n                r.incRef();\n              }\n\n              if (VERBOSE) {\n                System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": s id=\" + id + \" val=\" + val + \" r=\" + r.getVersion());\n              }\n\n              //  sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              IndexSearcher searcher;\n              if (r == lastReader) {\n                // Just re-use lastSearcher, else\n                // newSearcher may create too many thread\n                // pools (ExecutorService):\n                searcher = lastSearcher;\n              } else {\n                searcher = newSearcher(r);\n                lastReader = r;\n                lastSearcher = searcher;\n              }\n              Query q = new TermQuery(new Term(\"id\",Integer.toString(id)));\n              TopDocs results = searcher.search(q, 10);\n\n              if (results.totalHits == 0 && tombstones) {\n                // if we couldn't find the doc, look for its tombstone\n                q = new TermQuery(new Term(\"id\",\"-\"+Integer.toString(id)));\n                results = searcher.search(q, 1);\n                if (results.totalHits == 0) {\n                  if (val == -1L) {\n                    // expected... no doc was added yet\n                    r.decRef();\n                    continue;\n                  }\n                  fail(\"No documents or tombstones found for id \" + id + \", expected at least \" + val + \" reader=\" + r);\n                }\n              }\n\n              if (results.totalHits == 0 && !tombstones) {\n                // nothing to do - we can't tell anything from a deleted doc without tombstones\n              } else {\n                // we should have found the document, or its tombstone\n                if (results.totalHits != 1) {\n                  System.out.println(\"FAIL: hits id:\" + id + \" val=\" + val);\n                  for(ScoreDoc sd : results.scoreDocs) {\n                    final StoredDocument doc = r.document(sd.doc);\n                    System.out.println(\"  docID=\" + sd.doc + \" id:\" + doc.get(\"id\") + \" foundVal=\" + doc.get(field));\n                  }\n                  fail(\"id=\" + id + \" reader=\" + r + \" totalHits=\" + results.totalHits);\n                }\n                StoredDocument doc = searcher.doc(results.scoreDocs[0].doc);\n                long foundVal = Long.parseLong(doc.get(field));\n                if (foundVal < Math.abs(val)) {\n                  fail(\"foundVal=\" + foundVal + \" val=\" + val + \" id=\" + id + \" reader=\" + r);\n                }\n              }\n\n              r.decRef();\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    writer.shutdown();\n    if (VERBOSE) {\n      System.out.println(\"TEST: close reader=\" + reader);\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    // update variables\n    final int commitPercent = random().nextInt(20);\n    final int softCommitPercent = random().nextInt(100); // what percent of the commits are soft\n    final int deletePercent = random().nextInt(50);\n    final int deleteByQueryPercent = random().nextInt(25);\n    final int ndocs = atLeast(50);\n    final int nWriteThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    final int maxConcurrentCommits = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n    \n    final boolean tombstones = random().nextBoolean();\n\n    // query variables\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n\n    final int nReadThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    initModel(ndocs);\n\n    final FieldType storedOnlyType = new FieldType();\n    storedOnlyType.setStored(true);\n\n    if (VERBOSE) {\n      System.out.println(\"\\n\");\n      System.out.println(\"TEST: commitPercent=\" + commitPercent);\n      System.out.println(\"TEST: softCommitPercent=\" + softCommitPercent);\n      System.out.println(\"TEST: deletePercent=\" + deletePercent);\n      System.out.println(\"TEST: deleteByQueryPercent=\" + deleteByQueryPercent);\n      System.out.println(\"TEST: ndocs=\" + ndocs);\n      System.out.println(\"TEST: nWriteThreads=\" + nWriteThreads);\n      System.out.println(\"TEST: nReadThreads=\" + nReadThreads);\n      System.out.println(\"TEST: maxConcurrentCommits=\" + maxConcurrentCommits);\n      System.out.println(\"TEST: tombstones=\" + tombstones);\n      System.out.println(\"TEST: operations=\" + operations);\n      System.out.println(\"\\n\");\n    }\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<>();\n\n    Directory dir = newDirectory();\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    writer.setDoRandomForceMergeAssert(false);\n    writer.commit();\n    reader = DirectoryReader.open(dir);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n                  DirectoryReader oldReader;\n\n                  synchronized(TestStressNRT.this) {\n                    newCommittedModel = new HashMap<>(model);  // take a snapshot\n                    version = snapshotCount++;\n                    oldReader = reader;\n                    oldReader.incRef();  // increment the reference since we will use this for reopening\n                  }\n\n                  DirectoryReader newReader;\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    // assertU(h.commit(\"softCommit\",\"true\"));\n                    if (random().nextBoolean()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": call writer.getReader\");\n                      }\n                      newReader = writer.getReader(true);\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": reopen reader=\" + oldReader + \" version=\" + version);\n                      }\n                      newReader = DirectoryReader.openIfChanged(oldReader, writer.w, true);\n                    }\n                  } else {\n                    // assertU(commit());\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": commit+reopen reader=\" + oldReader + \" version=\" + version);\n                    }\n                    writer.commit();\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": now reopen after commit\");\n                    }\n                    newReader = DirectoryReader.openIfChanged(oldReader);\n                  }\n\n                  // Code below assumes newReader comes w/\n                  // extra ref:\n                  if (newReader == null) {\n                    oldReader.incRef();\n                    newReader = oldReader;\n                  }\n\n                  oldReader.decRef();\n\n                  synchronized(TestStressNRT.this) {\n                    // install the new reader if it's newest (and check the current version since another reader may have already been installed)\n                    //System.out.println(Thread.currentThread().getName() + \": newVersion=\" + newReader.getVersion());\n                    assert newReader.getRefCount() > 0;\n                    assert reader.getRefCount() > 0;\n                    if (newReader.getVersion() > reader.getVersion()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new reader=\" + newReader);\n                      }\n                      reader.decRef();\n                      reader = newReader;\n\n                      // Silly: forces fieldInfos to be\n                      // loaded so we don't hit IOE on later\n                      // reader.toString\n                      newReader.toString();\n\n                      // install this snapshot only if it's newer than the current one\n                      if (version >= committedModelClock) {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new model version=\" + version);\n                        }\n                        committedModel = newCommittedModel;\n                        committedModelClock = version;\n                      } else {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new model version=\" + version);\n                        }\n                      }\n                    } else {\n                      // if the same reader, don't decRef.\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new reader=\" + newReader);\n                      }\n                      newReader.decRef();\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else {\n\n                int id = rand.nextInt(ndocs);\n                Object sync = syncArr[id];\n\n                // set the lastId before we actually change it sometimes to try and\n                // uncover more race conditions between writing and reading\n                boolean before = random().nextBoolean();\n                if (before) {\n                  lastId = id;\n                }\n\n                // We can't concurrently update the same document and retain our invariants of increasing values\n                // since we can't guarantee what order the updates will be executed.\n                synchronized (sync) {\n                  Long val = model.get(id);\n                  long nextVal = Math.abs(val)+1;\n\n                  if (oper < commitPercent + deletePercent) {\n                    // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": term delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new Term(\"id\",Integer.toString(id)));\n                    model.put(id, -nextVal);\n                  } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                    //assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": query delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new TermQuery(new Term(\"id\", Integer.toString(id))));\n                    model.put(id, -nextVal);\n                  } else {\n                    // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                    Document d = new Document();\n                    d.add(newStringField(\"id\", Integer.toString(id), Field.Store.YES));\n                    d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": u id:\" + id + \" val=\" + nextVal);\n                    }\n                    writer.updateDocument(new Term(\"id\", Integer.toString(id)), d);\n                    if (tombstones) {\n                      // remove tombstone after new addition (this should be optional?)\n                      writer.deleteDocuments(new Term(\"id\",\"-\"+Integer.toString(id)));\n                    }\n                    model.put(id, nextVal);\n                  }\n                }\n\n                if (!before) {\n                  lastId = id;\n                }\n              }\n            }\n          } catch (Throwable e) {\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            IndexReader lastReader = null;\n            IndexSearcher lastSearcher = null;\n\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              long val;\n              DirectoryReader r;\n              synchronized(TestStressNRT.this) {\n                val = committedModel.get(id);\n                r = reader;\n                r.incRef();\n              }\n\n              if (VERBOSE) {\n                System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": s id=\" + id + \" val=\" + val + \" r=\" + r.getVersion());\n              }\n\n              //  sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              IndexSearcher searcher;\n              if (r == lastReader) {\n                // Just re-use lastSearcher, else\n                // newSearcher may create too many thread\n                // pools (ExecutorService):\n                searcher = lastSearcher;\n              } else {\n                searcher = newSearcher(r);\n                lastReader = r;\n                lastSearcher = searcher;\n              }\n              Query q = new TermQuery(new Term(\"id\",Integer.toString(id)));\n              TopDocs results = searcher.search(q, 10);\n\n              if (results.totalHits == 0 && tombstones) {\n                // if we couldn't find the doc, look for its tombstone\n                q = new TermQuery(new Term(\"id\",\"-\"+Integer.toString(id)));\n                results = searcher.search(q, 1);\n                if (results.totalHits == 0) {\n                  if (val == -1L) {\n                    // expected... no doc was added yet\n                    r.decRef();\n                    continue;\n                  }\n                  fail(\"No documents or tombstones found for id \" + id + \", expected at least \" + val + \" reader=\" + r);\n                }\n              }\n\n              if (results.totalHits == 0 && !tombstones) {\n                // nothing to do - we can't tell anything from a deleted doc without tombstones\n              } else {\n                // we should have found the document, or its tombstone\n                if (results.totalHits != 1) {\n                  System.out.println(\"FAIL: hits id:\" + id + \" val=\" + val);\n                  for(ScoreDoc sd : results.scoreDocs) {\n                    final StoredDocument doc = r.document(sd.doc);\n                    System.out.println(\"  docID=\" + sd.doc + \" id:\" + doc.get(\"id\") + \" foundVal=\" + doc.get(field));\n                  }\n                  fail(\"id=\" + id + \" reader=\" + r + \" totalHits=\" + results.totalHits);\n                }\n                StoredDocument doc = searcher.doc(results.scoreDocs[0].doc);\n                long foundVal = Long.parseLong(doc.get(field));\n                if (foundVal < Math.abs(val)) {\n                  fail(\"foundVal=\" + foundVal + \" val=\" + val + \" id=\" + id + \" reader=\" + r);\n                }\n              }\n\n              r.decRef();\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    writer.shutdown();\n    if (VERBOSE) {\n      System.out.println(\"TEST: close reader=\" + reader);\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestStressNRT#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestStressNRT#test().mjava","sourceNew":"  public void test() throws Exception {\n    // update variables\n    final int commitPercent = random().nextInt(20);\n    final int softCommitPercent = random().nextInt(100); // what percent of the commits are soft\n    final int deletePercent = random().nextInt(50);\n    final int deleteByQueryPercent = random().nextInt(25);\n    final int ndocs = atLeast(50);\n    final int nWriteThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    final int maxConcurrentCommits = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n    \n    final boolean tombstones = random().nextBoolean();\n\n    // query variables\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n\n    final int nReadThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    initModel(ndocs);\n\n    final FieldType storedOnlyType = new FieldType();\n    storedOnlyType.setStored(true);\n\n    if (VERBOSE) {\n      System.out.println(\"\\n\");\n      System.out.println(\"TEST: commitPercent=\" + commitPercent);\n      System.out.println(\"TEST: softCommitPercent=\" + softCommitPercent);\n      System.out.println(\"TEST: deletePercent=\" + deletePercent);\n      System.out.println(\"TEST: deleteByQueryPercent=\" + deleteByQueryPercent);\n      System.out.println(\"TEST: ndocs=\" + ndocs);\n      System.out.println(\"TEST: nWriteThreads=\" + nWriteThreads);\n      System.out.println(\"TEST: nReadThreads=\" + nReadThreads);\n      System.out.println(\"TEST: maxConcurrentCommits=\" + maxConcurrentCommits);\n      System.out.println(\"TEST: tombstones=\" + tombstones);\n      System.out.println(\"TEST: operations=\" + operations);\n      System.out.println(\"\\n\");\n    }\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<>();\n\n    Directory dir = newDirectory();\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    writer.setDoRandomForceMergeAssert(false);\n    writer.commit();\n    reader = DirectoryReader.open(dir);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n                  DirectoryReader oldReader;\n\n                  synchronized(TestStressNRT.this) {\n                    newCommittedModel = new HashMap<>(model);  // take a snapshot\n                    version = snapshotCount++;\n                    oldReader = reader;\n                    oldReader.incRef();  // increment the reference since we will use this for reopening\n                  }\n\n                  DirectoryReader newReader;\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    // assertU(h.commit(\"softCommit\",\"true\"));\n                    if (random().nextBoolean()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": call writer.getReader\");\n                      }\n                      newReader = writer.getReader(true);\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": reopen reader=\" + oldReader + \" version=\" + version);\n                      }\n                      newReader = DirectoryReader.openIfChanged(oldReader, writer.w, true);\n                    }\n                  } else {\n                    // assertU(commit());\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": commit+reopen reader=\" + oldReader + \" version=\" + version);\n                    }\n                    writer.commit();\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": now reopen after commit\");\n                    }\n                    newReader = DirectoryReader.openIfChanged(oldReader);\n                  }\n\n                  // Code below assumes newReader comes w/\n                  // extra ref:\n                  if (newReader == null) {\n                    oldReader.incRef();\n                    newReader = oldReader;\n                  }\n\n                  oldReader.decRef();\n\n                  synchronized(TestStressNRT.this) {\n                    // install the new reader if it's newest (and check the current version since another reader may have already been installed)\n                    //System.out.println(Thread.currentThread().getName() + \": newVersion=\" + newReader.getVersion());\n                    assert newReader.getRefCount() > 0;\n                    assert reader.getRefCount() > 0;\n                    if (newReader.getVersion() > reader.getVersion()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new reader=\" + newReader);\n                      }\n                      reader.decRef();\n                      reader = newReader;\n\n                      // Silly: forces fieldInfos to be\n                      // loaded so we don't hit IOE on later\n                      // reader.toString\n                      newReader.toString();\n\n                      // install this snapshot only if it's newer than the current one\n                      if (version >= committedModelClock) {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new model version=\" + version);\n                        }\n                        committedModel = newCommittedModel;\n                        committedModelClock = version;\n                      } else {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new model version=\" + version);\n                        }\n                      }\n                    } else {\n                      // if the same reader, don't decRef.\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new reader=\" + newReader);\n                      }\n                      newReader.decRef();\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else {\n\n                int id = rand.nextInt(ndocs);\n                Object sync = syncArr[id];\n\n                // set the lastId before we actually change it sometimes to try and\n                // uncover more race conditions between writing and reading\n                boolean before = random().nextBoolean();\n                if (before) {\n                  lastId = id;\n                }\n\n                // We can't concurrently update the same document and retain our invariants of increasing values\n                // since we can't guarantee what order the updates will be executed.\n                synchronized (sync) {\n                  Long val = model.get(id);\n                  long nextVal = Math.abs(val)+1;\n\n                  if (oper < commitPercent + deletePercent) {\n                    // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": term delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new Term(\"id\",Integer.toString(id)));\n                    model.put(id, -nextVal);\n                  } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                    //assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": query delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new TermQuery(new Term(\"id\", Integer.toString(id))));\n                    model.put(id, -nextVal);\n                  } else {\n                    // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                    Document d = new Document();\n                    d.add(newStringField(\"id\", Integer.toString(id), Field.Store.YES));\n                    d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": u id:\" + id + \" val=\" + nextVal);\n                    }\n                    writer.updateDocument(new Term(\"id\", Integer.toString(id)), d);\n                    if (tombstones) {\n                      // remove tombstone after new addition (this should be optional?)\n                      writer.deleteDocuments(new Term(\"id\",\"-\"+Integer.toString(id)));\n                    }\n                    model.put(id, nextVal);\n                  }\n                }\n\n                if (!before) {\n                  lastId = id;\n                }\n              }\n            }\n          } catch (Throwable e) {\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            IndexReader lastReader = null;\n            IndexSearcher lastSearcher = null;\n\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              long val;\n              DirectoryReader r;\n              synchronized(TestStressNRT.this) {\n                val = committedModel.get(id);\n                r = reader;\n                r.incRef();\n              }\n\n              if (VERBOSE) {\n                System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": s id=\" + id + \" val=\" + val + \" r=\" + r.getVersion());\n              }\n\n              //  sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              IndexSearcher searcher;\n              if (r == lastReader) {\n                // Just re-use lastSearcher, else\n                // newSearcher may create too many thread\n                // pools (ExecutorService):\n                searcher = lastSearcher;\n              } else {\n                searcher = newSearcher(r);\n                lastReader = r;\n                lastSearcher = searcher;\n              }\n              Query q = new TermQuery(new Term(\"id\",Integer.toString(id)));\n              TopDocs results = searcher.search(q, 10);\n\n              if (results.totalHits == 0 && tombstones) {\n                // if we couldn't find the doc, look for its tombstone\n                q = new TermQuery(new Term(\"id\",\"-\"+Integer.toString(id)));\n                results = searcher.search(q, 1);\n                if (results.totalHits == 0) {\n                  if (val == -1L) {\n                    // expected... no doc was added yet\n                    r.decRef();\n                    continue;\n                  }\n                  fail(\"No documents or tombstones found for id \" + id + \", expected at least \" + val + \" reader=\" + r);\n                }\n              }\n\n              if (results.totalHits == 0 && !tombstones) {\n                // nothing to do - we can't tell anything from a deleted doc without tombstones\n              } else {\n                // we should have found the document, or its tombstone\n                if (results.totalHits != 1) {\n                  System.out.println(\"FAIL: hits id:\" + id + \" val=\" + val);\n                  for(ScoreDoc sd : results.scoreDocs) {\n                    final StoredDocument doc = r.document(sd.doc);\n                    System.out.println(\"  docID=\" + sd.doc + \" id:\" + doc.get(\"id\") + \" foundVal=\" + doc.get(field));\n                  }\n                  fail(\"id=\" + id + \" reader=\" + r + \" totalHits=\" + results.totalHits);\n                }\n                StoredDocument doc = searcher.doc(results.scoreDocs[0].doc);\n                long foundVal = Long.parseLong(doc.get(field));\n                if (foundVal < Math.abs(val)) {\n                  fail(\"foundVal=\" + foundVal + \" val=\" + val + \" id=\" + id + \" reader=\" + r);\n                }\n              }\n\n              r.decRef();\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    writer.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: close reader=\" + reader);\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    // update variables\n    final int commitPercent = random().nextInt(20);\n    final int softCommitPercent = random().nextInt(100); // what percent of the commits are soft\n    final int deletePercent = random().nextInt(50);\n    final int deleteByQueryPercent = random().nextInt(25);\n    final int ndocs = atLeast(50);\n    final int nWriteThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    final int maxConcurrentCommits = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n    \n    final boolean tombstones = random().nextBoolean();\n\n    // query variables\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n\n    final int nReadThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    initModel(ndocs);\n\n    final FieldType storedOnlyType = new FieldType();\n    storedOnlyType.setStored(true);\n\n    if (VERBOSE) {\n      System.out.println(\"\\n\");\n      System.out.println(\"TEST: commitPercent=\" + commitPercent);\n      System.out.println(\"TEST: softCommitPercent=\" + softCommitPercent);\n      System.out.println(\"TEST: deletePercent=\" + deletePercent);\n      System.out.println(\"TEST: deleteByQueryPercent=\" + deleteByQueryPercent);\n      System.out.println(\"TEST: ndocs=\" + ndocs);\n      System.out.println(\"TEST: nWriteThreads=\" + nWriteThreads);\n      System.out.println(\"TEST: nReadThreads=\" + nReadThreads);\n      System.out.println(\"TEST: maxConcurrentCommits=\" + maxConcurrentCommits);\n      System.out.println(\"TEST: tombstones=\" + tombstones);\n      System.out.println(\"TEST: operations=\" + operations);\n      System.out.println(\"\\n\");\n    }\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<>();\n\n    Directory dir = newDirectory();\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    writer.setDoRandomForceMergeAssert(false);\n    writer.commit();\n    reader = DirectoryReader.open(dir);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n                  DirectoryReader oldReader;\n\n                  synchronized(TestStressNRT.this) {\n                    newCommittedModel = new HashMap<>(model);  // take a snapshot\n                    version = snapshotCount++;\n                    oldReader = reader;\n                    oldReader.incRef();  // increment the reference since we will use this for reopening\n                  }\n\n                  DirectoryReader newReader;\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    // assertU(h.commit(\"softCommit\",\"true\"));\n                    if (random().nextBoolean()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": call writer.getReader\");\n                      }\n                      newReader = writer.getReader(true);\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": reopen reader=\" + oldReader + \" version=\" + version);\n                      }\n                      newReader = DirectoryReader.openIfChanged(oldReader, writer.w, true);\n                    }\n                  } else {\n                    // assertU(commit());\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": commit+reopen reader=\" + oldReader + \" version=\" + version);\n                    }\n                    writer.commit();\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": now reopen after commit\");\n                    }\n                    newReader = DirectoryReader.openIfChanged(oldReader);\n                  }\n\n                  // Code below assumes newReader comes w/\n                  // extra ref:\n                  if (newReader == null) {\n                    oldReader.incRef();\n                    newReader = oldReader;\n                  }\n\n                  oldReader.decRef();\n\n                  synchronized(TestStressNRT.this) {\n                    // install the new reader if it's newest (and check the current version since another reader may have already been installed)\n                    //System.out.println(Thread.currentThread().getName() + \": newVersion=\" + newReader.getVersion());\n                    assert newReader.getRefCount() > 0;\n                    assert reader.getRefCount() > 0;\n                    if (newReader.getVersion() > reader.getVersion()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new reader=\" + newReader);\n                      }\n                      reader.decRef();\n                      reader = newReader;\n\n                      // Silly: forces fieldInfos to be\n                      // loaded so we don't hit IOE on later\n                      // reader.toString\n                      newReader.toString();\n\n                      // install this snapshot only if it's newer than the current one\n                      if (version >= committedModelClock) {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new model version=\" + version);\n                        }\n                        committedModel = newCommittedModel;\n                        committedModelClock = version;\n                      } else {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new model version=\" + version);\n                        }\n                      }\n                    } else {\n                      // if the same reader, don't decRef.\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new reader=\" + newReader);\n                      }\n                      newReader.decRef();\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else {\n\n                int id = rand.nextInt(ndocs);\n                Object sync = syncArr[id];\n\n                // set the lastId before we actually change it sometimes to try and\n                // uncover more race conditions between writing and reading\n                boolean before = random().nextBoolean();\n                if (before) {\n                  lastId = id;\n                }\n\n                // We can't concurrently update the same document and retain our invariants of increasing values\n                // since we can't guarantee what order the updates will be executed.\n                synchronized (sync) {\n                  Long val = model.get(id);\n                  long nextVal = Math.abs(val)+1;\n\n                  if (oper < commitPercent + deletePercent) {\n                    // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": term delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new Term(\"id\",Integer.toString(id)));\n                    model.put(id, -nextVal);\n                  } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                    //assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": query delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new TermQuery(new Term(\"id\", Integer.toString(id))));\n                    model.put(id, -nextVal);\n                  } else {\n                    // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                    Document d = new Document();\n                    d.add(newStringField(\"id\", Integer.toString(id), Field.Store.YES));\n                    d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": u id:\" + id + \" val=\" + nextVal);\n                    }\n                    writer.updateDocument(new Term(\"id\", Integer.toString(id)), d);\n                    if (tombstones) {\n                      // remove tombstone after new addition (this should be optional?)\n                      writer.deleteDocuments(new Term(\"id\",\"-\"+Integer.toString(id)));\n                    }\n                    model.put(id, nextVal);\n                  }\n                }\n\n                if (!before) {\n                  lastId = id;\n                }\n              }\n            }\n          } catch (Throwable e) {\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            IndexReader lastReader = null;\n            IndexSearcher lastSearcher = null;\n\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              long val;\n              DirectoryReader r;\n              synchronized(TestStressNRT.this) {\n                val = committedModel.get(id);\n                r = reader;\n                r.incRef();\n              }\n\n              if (VERBOSE) {\n                System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": s id=\" + id + \" val=\" + val + \" r=\" + r.getVersion());\n              }\n\n              //  sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              IndexSearcher searcher;\n              if (r == lastReader) {\n                // Just re-use lastSearcher, else\n                // newSearcher may create too many thread\n                // pools (ExecutorService):\n                searcher = lastSearcher;\n              } else {\n                searcher = newSearcher(r);\n                lastReader = r;\n                lastSearcher = searcher;\n              }\n              Query q = new TermQuery(new Term(\"id\",Integer.toString(id)));\n              TopDocs results = searcher.search(q, 10);\n\n              if (results.totalHits == 0 && tombstones) {\n                // if we couldn't find the doc, look for its tombstone\n                q = new TermQuery(new Term(\"id\",\"-\"+Integer.toString(id)));\n                results = searcher.search(q, 1);\n                if (results.totalHits == 0) {\n                  if (val == -1L) {\n                    // expected... no doc was added yet\n                    r.decRef();\n                    continue;\n                  }\n                  fail(\"No documents or tombstones found for id \" + id + \", expected at least \" + val + \" reader=\" + r);\n                }\n              }\n\n              if (results.totalHits == 0 && !tombstones) {\n                // nothing to do - we can't tell anything from a deleted doc without tombstones\n              } else {\n                // we should have found the document, or its tombstone\n                if (results.totalHits != 1) {\n                  System.out.println(\"FAIL: hits id:\" + id + \" val=\" + val);\n                  for(ScoreDoc sd : results.scoreDocs) {\n                    final StoredDocument doc = r.document(sd.doc);\n                    System.out.println(\"  docID=\" + sd.doc + \" id:\" + doc.get(\"id\") + \" foundVal=\" + doc.get(field));\n                  }\n                  fail(\"id=\" + id + \" reader=\" + r + \" totalHits=\" + results.totalHits);\n                }\n                StoredDocument doc = searcher.doc(results.scoreDocs[0].doc);\n                long foundVal = Long.parseLong(doc.get(field));\n                if (foundVal < Math.abs(val)) {\n                  fail(\"foundVal=\" + foundVal + \" val=\" + val + \" id=\" + id + \" reader=\" + r);\n                }\n              }\n\n              r.decRef();\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    writer.shutdown();\n    if (VERBOSE) {\n      System.out.println(\"TEST: close reader=\" + reader);\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c","date":1453060490,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestStressNRT#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestStressNRT#test().mjava","sourceNew":"  public void test() throws Exception {\n    // update variables\n    final int commitPercent = random().nextInt(20);\n    final int softCommitPercent = random().nextInt(100); // what percent of the commits are soft\n    final int deletePercent = random().nextInt(50);\n    final int deleteByQueryPercent = random().nextInt(25);\n    final int ndocs = atLeast(50);\n    final int nWriteThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    final int maxConcurrentCommits = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n    \n    final boolean tombstones = random().nextBoolean();\n\n    // query variables\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n\n    final int nReadThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    initModel(ndocs);\n\n    final FieldType storedOnlyType = new FieldType();\n    storedOnlyType.setStored(true);\n\n    if (VERBOSE) {\n      System.out.println(\"\\n\");\n      System.out.println(\"TEST: commitPercent=\" + commitPercent);\n      System.out.println(\"TEST: softCommitPercent=\" + softCommitPercent);\n      System.out.println(\"TEST: deletePercent=\" + deletePercent);\n      System.out.println(\"TEST: deleteByQueryPercent=\" + deleteByQueryPercent);\n      System.out.println(\"TEST: ndocs=\" + ndocs);\n      System.out.println(\"TEST: nWriteThreads=\" + nWriteThreads);\n      System.out.println(\"TEST: nReadThreads=\" + nReadThreads);\n      System.out.println(\"TEST: maxConcurrentCommits=\" + maxConcurrentCommits);\n      System.out.println(\"TEST: tombstones=\" + tombstones);\n      System.out.println(\"TEST: operations=\" + operations);\n      System.out.println(\"\\n\");\n    }\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<>();\n\n    Directory dir = newDirectory();\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    writer.setDoRandomForceMergeAssert(false);\n    writer.commit();\n    reader = DirectoryReader.open(dir);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n                  DirectoryReader oldReader;\n\n                  synchronized(TestStressNRT.this) {\n                    newCommittedModel = new HashMap<>(model);  // take a snapshot\n                    version = snapshotCount++;\n                    oldReader = reader;\n                    oldReader.incRef();  // increment the reference since we will use this for reopening\n                  }\n\n                  DirectoryReader newReader;\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    // assertU(h.commit(\"softCommit\",\"true\"));\n                    if (random().nextBoolean()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": call writer.getReader\");\n                      }\n                      newReader = writer.getReader(true);\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": reopen reader=\" + oldReader + \" version=\" + version);\n                      }\n                      newReader = DirectoryReader.openIfChanged(oldReader, writer.w, true);\n                    }\n                  } else {\n                    // assertU(commit());\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": commit+reopen reader=\" + oldReader + \" version=\" + version);\n                    }\n                    writer.commit();\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": now reopen after commit\");\n                    }\n                    newReader = DirectoryReader.openIfChanged(oldReader);\n                  }\n\n                  // Code below assumes newReader comes w/\n                  // extra ref:\n                  if (newReader == null) {\n                    oldReader.incRef();\n                    newReader = oldReader;\n                  }\n\n                  oldReader.decRef();\n\n                  synchronized(TestStressNRT.this) {\n                    // install the new reader if it's newest (and check the current version since another reader may have already been installed)\n                    //System.out.println(Thread.currentThread().getName() + \": newVersion=\" + newReader.getVersion());\n                    assert newReader.getRefCount() > 0;\n                    assert reader.getRefCount() > 0;\n                    if (newReader.getVersion() > reader.getVersion()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new reader=\" + newReader);\n                      }\n                      reader.decRef();\n                      reader = newReader;\n\n                      // Silly: forces fieldInfos to be\n                      // loaded so we don't hit IOE on later\n                      // reader.toString\n                      newReader.toString();\n\n                      // install this snapshot only if it's newer than the current one\n                      if (version >= committedModelClock) {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new model version=\" + version);\n                        }\n                        committedModel = newCommittedModel;\n                        committedModelClock = version;\n                      } else {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new model version=\" + version);\n                        }\n                      }\n                    } else {\n                      // if the same reader, don't decRef.\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new reader=\" + newReader);\n                      }\n                      newReader.decRef();\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else {\n\n                int id = rand.nextInt(ndocs);\n                Object sync = syncArr[id];\n\n                // set the lastId before we actually change it sometimes to try and\n                // uncover more race conditions between writing and reading\n                boolean before = random().nextBoolean();\n                if (before) {\n                  lastId = id;\n                }\n\n                // We can't concurrently update the same document and retain our invariants of increasing values\n                // since we can't guarantee what order the updates will be executed.\n                synchronized (sync) {\n                  Long val = model.get(id);\n                  long nextVal = Math.abs(val)+1;\n\n                  if (oper < commitPercent + deletePercent) {\n                    // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": term delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new Term(\"id\",Integer.toString(id)));\n                    model.put(id, -nextVal);\n                  } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                    //assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": query delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new TermQuery(new Term(\"id\", Integer.toString(id))));\n                    model.put(id, -nextVal);\n                  } else {\n                    // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                    Document d = new Document();\n                    d.add(newStringField(\"id\", Integer.toString(id), Field.Store.YES));\n                    d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": u id:\" + id + \" val=\" + nextVal);\n                    }\n                    writer.updateDocument(new Term(\"id\", Integer.toString(id)), d);\n                    if (tombstones) {\n                      // remove tombstone after new addition (this should be optional?)\n                      writer.deleteDocuments(new Term(\"id\",\"-\"+Integer.toString(id)));\n                    }\n                    model.put(id, nextVal);\n                  }\n                }\n\n                if (!before) {\n                  lastId = id;\n                }\n              }\n            }\n          } catch (Throwable e) {\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            IndexReader lastReader = null;\n            IndexSearcher lastSearcher = null;\n\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              long val;\n              DirectoryReader r;\n              synchronized(TestStressNRT.this) {\n                val = committedModel.get(id);\n                r = reader;\n                r.incRef();\n              }\n\n              if (VERBOSE) {\n                System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": s id=\" + id + \" val=\" + val + \" r=\" + r.getVersion());\n              }\n\n              //  sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              IndexSearcher searcher;\n              if (r == lastReader) {\n                // Just re-use lastSearcher, else\n                // newSearcher may create too many thread\n                // pools (ExecutorService):\n                searcher = lastSearcher;\n              } else {\n                searcher = newSearcher(r);\n                lastReader = r;\n                lastSearcher = searcher;\n              }\n              Query q = new TermQuery(new Term(\"id\",Integer.toString(id)));\n              TopDocs results = searcher.search(q, 10);\n\n              if (results.totalHits == 0 && tombstones) {\n                // if we couldn't find the doc, look for its tombstone\n                q = new TermQuery(new Term(\"id\",\"-\"+Integer.toString(id)));\n                results = searcher.search(q, 1);\n                if (results.totalHits == 0) {\n                  if (val == -1L) {\n                    // expected... no doc was added yet\n                    r.decRef();\n                    continue;\n                  }\n                  fail(\"No documents or tombstones found for id \" + id + \", expected at least \" + val + \" reader=\" + r);\n                }\n              }\n\n              if (results.totalHits == 0 && !tombstones) {\n                // nothing to do - we can't tell anything from a deleted doc without tombstones\n              } else {\n                // we should have found the document, or its tombstone\n                if (results.totalHits != 1) {\n                  System.out.println(\"FAIL: hits id:\" + id + \" val=\" + val);\n                  for(ScoreDoc sd : results.scoreDocs) {\n                    final Document doc = r.document(sd.doc);\n                    System.out.println(\"  docID=\" + sd.doc + \" id:\" + doc.get(\"id\") + \" foundVal=\" + doc.get(field));\n                  }\n                  fail(\"id=\" + id + \" reader=\" + r + \" totalHits=\" + results.totalHits);\n                }\n                Document doc = searcher.doc(results.scoreDocs[0].doc);\n                long foundVal = Long.parseLong(doc.get(field));\n                if (foundVal < Math.abs(val)) {\n                  fail(\"foundVal=\" + foundVal + \" val=\" + val + \" id=\" + id + \" reader=\" + r);\n                }\n              }\n\n              r.decRef();\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    writer.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: close reader=\" + reader);\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    // update variables\n    final int commitPercent = random().nextInt(20);\n    final int softCommitPercent = random().nextInt(100); // what percent of the commits are soft\n    final int deletePercent = random().nextInt(50);\n    final int deleteByQueryPercent = random().nextInt(25);\n    final int ndocs = atLeast(50);\n    final int nWriteThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    final int maxConcurrentCommits = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n    \n    final boolean tombstones = random().nextBoolean();\n\n    // query variables\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n\n    final int nReadThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    initModel(ndocs);\n\n    final FieldType storedOnlyType = new FieldType();\n    storedOnlyType.setStored(true);\n\n    if (VERBOSE) {\n      System.out.println(\"\\n\");\n      System.out.println(\"TEST: commitPercent=\" + commitPercent);\n      System.out.println(\"TEST: softCommitPercent=\" + softCommitPercent);\n      System.out.println(\"TEST: deletePercent=\" + deletePercent);\n      System.out.println(\"TEST: deleteByQueryPercent=\" + deleteByQueryPercent);\n      System.out.println(\"TEST: ndocs=\" + ndocs);\n      System.out.println(\"TEST: nWriteThreads=\" + nWriteThreads);\n      System.out.println(\"TEST: nReadThreads=\" + nReadThreads);\n      System.out.println(\"TEST: maxConcurrentCommits=\" + maxConcurrentCommits);\n      System.out.println(\"TEST: tombstones=\" + tombstones);\n      System.out.println(\"TEST: operations=\" + operations);\n      System.out.println(\"\\n\");\n    }\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<>();\n\n    Directory dir = newDirectory();\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    writer.setDoRandomForceMergeAssert(false);\n    writer.commit();\n    reader = DirectoryReader.open(dir);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n                  DirectoryReader oldReader;\n\n                  synchronized(TestStressNRT.this) {\n                    newCommittedModel = new HashMap<>(model);  // take a snapshot\n                    version = snapshotCount++;\n                    oldReader = reader;\n                    oldReader.incRef();  // increment the reference since we will use this for reopening\n                  }\n\n                  DirectoryReader newReader;\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    // assertU(h.commit(\"softCommit\",\"true\"));\n                    if (random().nextBoolean()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": call writer.getReader\");\n                      }\n                      newReader = writer.getReader(true);\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": reopen reader=\" + oldReader + \" version=\" + version);\n                      }\n                      newReader = DirectoryReader.openIfChanged(oldReader, writer.w, true);\n                    }\n                  } else {\n                    // assertU(commit());\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": commit+reopen reader=\" + oldReader + \" version=\" + version);\n                    }\n                    writer.commit();\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": now reopen after commit\");\n                    }\n                    newReader = DirectoryReader.openIfChanged(oldReader);\n                  }\n\n                  // Code below assumes newReader comes w/\n                  // extra ref:\n                  if (newReader == null) {\n                    oldReader.incRef();\n                    newReader = oldReader;\n                  }\n\n                  oldReader.decRef();\n\n                  synchronized(TestStressNRT.this) {\n                    // install the new reader if it's newest (and check the current version since another reader may have already been installed)\n                    //System.out.println(Thread.currentThread().getName() + \": newVersion=\" + newReader.getVersion());\n                    assert newReader.getRefCount() > 0;\n                    assert reader.getRefCount() > 0;\n                    if (newReader.getVersion() > reader.getVersion()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new reader=\" + newReader);\n                      }\n                      reader.decRef();\n                      reader = newReader;\n\n                      // Silly: forces fieldInfos to be\n                      // loaded so we don't hit IOE on later\n                      // reader.toString\n                      newReader.toString();\n\n                      // install this snapshot only if it's newer than the current one\n                      if (version >= committedModelClock) {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new model version=\" + version);\n                        }\n                        committedModel = newCommittedModel;\n                        committedModelClock = version;\n                      } else {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new model version=\" + version);\n                        }\n                      }\n                    } else {\n                      // if the same reader, don't decRef.\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new reader=\" + newReader);\n                      }\n                      newReader.decRef();\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else {\n\n                int id = rand.nextInt(ndocs);\n                Object sync = syncArr[id];\n\n                // set the lastId before we actually change it sometimes to try and\n                // uncover more race conditions between writing and reading\n                boolean before = random().nextBoolean();\n                if (before) {\n                  lastId = id;\n                }\n\n                // We can't concurrently update the same document and retain our invariants of increasing values\n                // since we can't guarantee what order the updates will be executed.\n                synchronized (sync) {\n                  Long val = model.get(id);\n                  long nextVal = Math.abs(val)+1;\n\n                  if (oper < commitPercent + deletePercent) {\n                    // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": term delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new Term(\"id\",Integer.toString(id)));\n                    model.put(id, -nextVal);\n                  } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                    //assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": query delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new TermQuery(new Term(\"id\", Integer.toString(id))));\n                    model.put(id, -nextVal);\n                  } else {\n                    // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                    Document d = new Document();\n                    d.add(newStringField(\"id\", Integer.toString(id), Field.Store.YES));\n                    d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": u id:\" + id + \" val=\" + nextVal);\n                    }\n                    writer.updateDocument(new Term(\"id\", Integer.toString(id)), d);\n                    if (tombstones) {\n                      // remove tombstone after new addition (this should be optional?)\n                      writer.deleteDocuments(new Term(\"id\",\"-\"+Integer.toString(id)));\n                    }\n                    model.put(id, nextVal);\n                  }\n                }\n\n                if (!before) {\n                  lastId = id;\n                }\n              }\n            }\n          } catch (Throwable e) {\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            IndexReader lastReader = null;\n            IndexSearcher lastSearcher = null;\n\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              long val;\n              DirectoryReader r;\n              synchronized(TestStressNRT.this) {\n                val = committedModel.get(id);\n                r = reader;\n                r.incRef();\n              }\n\n              if (VERBOSE) {\n                System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": s id=\" + id + \" val=\" + val + \" r=\" + r.getVersion());\n              }\n\n              //  sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              IndexSearcher searcher;\n              if (r == lastReader) {\n                // Just re-use lastSearcher, else\n                // newSearcher may create too many thread\n                // pools (ExecutorService):\n                searcher = lastSearcher;\n              } else {\n                searcher = newSearcher(r);\n                lastReader = r;\n                lastSearcher = searcher;\n              }\n              Query q = new TermQuery(new Term(\"id\",Integer.toString(id)));\n              TopDocs results = searcher.search(q, 10);\n\n              if (results.totalHits == 0 && tombstones) {\n                // if we couldn't find the doc, look for its tombstone\n                q = new TermQuery(new Term(\"id\",\"-\"+Integer.toString(id)));\n                results = searcher.search(q, 1);\n                if (results.totalHits == 0) {\n                  if (val == -1L) {\n                    // expected... no doc was added yet\n                    r.decRef();\n                    continue;\n                  }\n                  fail(\"No documents or tombstones found for id \" + id + \", expected at least \" + val + \" reader=\" + r);\n                }\n              }\n\n              if (results.totalHits == 0 && !tombstones) {\n                // nothing to do - we can't tell anything from a deleted doc without tombstones\n              } else {\n                // we should have found the document, or its tombstone\n                if (results.totalHits != 1) {\n                  System.out.println(\"FAIL: hits id:\" + id + \" val=\" + val);\n                  for(ScoreDoc sd : results.scoreDocs) {\n                    final StoredDocument doc = r.document(sd.doc);\n                    System.out.println(\"  docID=\" + sd.doc + \" id:\" + doc.get(\"id\") + \" foundVal=\" + doc.get(field));\n                  }\n                  fail(\"id=\" + id + \" reader=\" + r + \" totalHits=\" + results.totalHits);\n                }\n                StoredDocument doc = searcher.doc(results.scoreDocs[0].doc);\n                long foundVal = Long.parseLong(doc.get(field));\n                if (foundVal < Math.abs(val)) {\n                  fail(\"foundVal=\" + foundVal + \" val=\" + val + \" id=\" + id + \" reader=\" + r);\n                }\n              }\n\n              r.decRef();\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    writer.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: close reader=\" + reader);\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7b516a692d03225c8f0e81a13ceed2dc32bb457d","date":1453411951,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestStressNRT#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestStressNRT#test().mjava","sourceNew":"  public void test() throws Exception {\n    // update variables\n    final int commitPercent = random().nextInt(20);\n    final int softCommitPercent = random().nextInt(100); // what percent of the commits are soft\n    final int deletePercent = random().nextInt(50);\n    final int deleteByQueryPercent = random().nextInt(25);\n    final int ndocs = atLeast(50);\n    final int nWriteThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    final int maxConcurrentCommits = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n    \n    final boolean tombstones = random().nextBoolean();\n\n    // query variables\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n\n    final int nReadThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    initModel(ndocs);\n\n    final FieldType storedOnlyType = new FieldType();\n    storedOnlyType.setStored(true);\n\n    if (VERBOSE) {\n      System.out.println(\"\\n\");\n      System.out.println(\"TEST: commitPercent=\" + commitPercent);\n      System.out.println(\"TEST: softCommitPercent=\" + softCommitPercent);\n      System.out.println(\"TEST: deletePercent=\" + deletePercent);\n      System.out.println(\"TEST: deleteByQueryPercent=\" + deleteByQueryPercent);\n      System.out.println(\"TEST: ndocs=\" + ndocs);\n      System.out.println(\"TEST: nWriteThreads=\" + nWriteThreads);\n      System.out.println(\"TEST: nReadThreads=\" + nReadThreads);\n      System.out.println(\"TEST: maxConcurrentCommits=\" + maxConcurrentCommits);\n      System.out.println(\"TEST: tombstones=\" + tombstones);\n      System.out.println(\"TEST: operations=\" + operations);\n      System.out.println(\"\\n\");\n    }\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<>();\n\n    Directory dir = newDirectory();\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    writer.setDoRandomForceMergeAssert(false);\n    writer.commit();\n    reader = DirectoryReader.open(dir);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n                  DirectoryReader oldReader;\n\n                  synchronized(TestStressNRT.this) {\n                    newCommittedModel = new HashMap<>(model);  // take a snapshot\n                    version = snapshotCount++;\n                    oldReader = reader;\n                    oldReader.incRef();  // increment the reference since we will use this for reopening\n                  }\n\n                  DirectoryReader newReader;\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    // assertU(h.commit(\"softCommit\",\"true\"));\n                    if (random().nextBoolean()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": call writer.getReader\");\n                      }\n                      newReader = writer.getReader();\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": reopen reader=\" + oldReader + \" version=\" + version);\n                      }\n                      newReader = DirectoryReader.openIfChanged(oldReader, writer.w);\n                    }\n                  } else {\n                    // assertU(commit());\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": commit+reopen reader=\" + oldReader + \" version=\" + version);\n                    }\n                    writer.commit();\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": now reopen after commit\");\n                    }\n                    newReader = DirectoryReader.openIfChanged(oldReader);\n                  }\n\n                  // Code below assumes newReader comes w/\n                  // extra ref:\n                  if (newReader == null) {\n                    oldReader.incRef();\n                    newReader = oldReader;\n                  }\n\n                  oldReader.decRef();\n\n                  synchronized(TestStressNRT.this) {\n                    // install the new reader if it's newest (and check the current version since another reader may have already been installed)\n                    //System.out.println(Thread.currentThread().getName() + \": newVersion=\" + newReader.getVersion());\n                    assert newReader.getRefCount() > 0;\n                    assert reader.getRefCount() > 0;\n                    if (newReader.getVersion() > reader.getVersion()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new reader=\" + newReader);\n                      }\n                      reader.decRef();\n                      reader = newReader;\n\n                      // Silly: forces fieldInfos to be\n                      // loaded so we don't hit IOE on later\n                      // reader.toString\n                      newReader.toString();\n\n                      // install this snapshot only if it's newer than the current one\n                      if (version >= committedModelClock) {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new model version=\" + version);\n                        }\n                        committedModel = newCommittedModel;\n                        committedModelClock = version;\n                      } else {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new model version=\" + version);\n                        }\n                      }\n                    } else {\n                      // if the same reader, don't decRef.\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new reader=\" + newReader);\n                      }\n                      newReader.decRef();\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else {\n\n                int id = rand.nextInt(ndocs);\n                Object sync = syncArr[id];\n\n                // set the lastId before we actually change it sometimes to try and\n                // uncover more race conditions between writing and reading\n                boolean before = random().nextBoolean();\n                if (before) {\n                  lastId = id;\n                }\n\n                // We can't concurrently update the same document and retain our invariants of increasing values\n                // since we can't guarantee what order the updates will be executed.\n                synchronized (sync) {\n                  Long val = model.get(id);\n                  long nextVal = Math.abs(val)+1;\n\n                  if (oper < commitPercent + deletePercent) {\n                    // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": term delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new Term(\"id\",Integer.toString(id)));\n                    model.put(id, -nextVal);\n                  } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                    //assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": query delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new TermQuery(new Term(\"id\", Integer.toString(id))));\n                    model.put(id, -nextVal);\n                  } else {\n                    // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                    Document d = new Document();\n                    d.add(newStringField(\"id\", Integer.toString(id), Field.Store.YES));\n                    d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": u id:\" + id + \" val=\" + nextVal);\n                    }\n                    writer.updateDocument(new Term(\"id\", Integer.toString(id)), d);\n                    if (tombstones) {\n                      // remove tombstone after new addition (this should be optional?)\n                      writer.deleteDocuments(new Term(\"id\",\"-\"+Integer.toString(id)));\n                    }\n                    model.put(id, nextVal);\n                  }\n                }\n\n                if (!before) {\n                  lastId = id;\n                }\n              }\n            }\n          } catch (Throwable e) {\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            IndexReader lastReader = null;\n            IndexSearcher lastSearcher = null;\n\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              long val;\n              DirectoryReader r;\n              synchronized(TestStressNRT.this) {\n                val = committedModel.get(id);\n                r = reader;\n                r.incRef();\n              }\n\n              if (VERBOSE) {\n                System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": s id=\" + id + \" val=\" + val + \" r=\" + r.getVersion());\n              }\n\n              //  sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              IndexSearcher searcher;\n              if (r == lastReader) {\n                // Just re-use lastSearcher, else\n                // newSearcher may create too many thread\n                // pools (ExecutorService):\n                searcher = lastSearcher;\n              } else {\n                searcher = newSearcher(r);\n                lastReader = r;\n                lastSearcher = searcher;\n              }\n              Query q = new TermQuery(new Term(\"id\",Integer.toString(id)));\n              TopDocs results = searcher.search(q, 10);\n\n              if (results.totalHits == 0 && tombstones) {\n                // if we couldn't find the doc, look for its tombstone\n                q = new TermQuery(new Term(\"id\",\"-\"+Integer.toString(id)));\n                results = searcher.search(q, 1);\n                if (results.totalHits == 0) {\n                  if (val == -1L) {\n                    // expected... no doc was added yet\n                    r.decRef();\n                    continue;\n                  }\n                  fail(\"No documents or tombstones found for id \" + id + \", expected at least \" + val + \" reader=\" + r);\n                }\n              }\n\n              if (results.totalHits == 0 && !tombstones) {\n                // nothing to do - we can't tell anything from a deleted doc without tombstones\n              } else {\n                // we should have found the document, or its tombstone\n                if (results.totalHits != 1) {\n                  System.out.println(\"FAIL: hits id:\" + id + \" val=\" + val);\n                  for(ScoreDoc sd : results.scoreDocs) {\n                    final Document doc = r.document(sd.doc);\n                    System.out.println(\"  docID=\" + sd.doc + \" id:\" + doc.get(\"id\") + \" foundVal=\" + doc.get(field));\n                  }\n                  fail(\"id=\" + id + \" reader=\" + r + \" totalHits=\" + results.totalHits);\n                }\n                Document doc = searcher.doc(results.scoreDocs[0].doc);\n                long foundVal = Long.parseLong(doc.get(field));\n                if (foundVal < Math.abs(val)) {\n                  fail(\"foundVal=\" + foundVal + \" val=\" + val + \" id=\" + id + \" reader=\" + r);\n                }\n              }\n\n              r.decRef();\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    writer.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: close reader=\" + reader);\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    // update variables\n    final int commitPercent = random().nextInt(20);\n    final int softCommitPercent = random().nextInt(100); // what percent of the commits are soft\n    final int deletePercent = random().nextInt(50);\n    final int deleteByQueryPercent = random().nextInt(25);\n    final int ndocs = atLeast(50);\n    final int nWriteThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    final int maxConcurrentCommits = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n    \n    final boolean tombstones = random().nextBoolean();\n\n    // query variables\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n\n    final int nReadThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    initModel(ndocs);\n\n    final FieldType storedOnlyType = new FieldType();\n    storedOnlyType.setStored(true);\n\n    if (VERBOSE) {\n      System.out.println(\"\\n\");\n      System.out.println(\"TEST: commitPercent=\" + commitPercent);\n      System.out.println(\"TEST: softCommitPercent=\" + softCommitPercent);\n      System.out.println(\"TEST: deletePercent=\" + deletePercent);\n      System.out.println(\"TEST: deleteByQueryPercent=\" + deleteByQueryPercent);\n      System.out.println(\"TEST: ndocs=\" + ndocs);\n      System.out.println(\"TEST: nWriteThreads=\" + nWriteThreads);\n      System.out.println(\"TEST: nReadThreads=\" + nReadThreads);\n      System.out.println(\"TEST: maxConcurrentCommits=\" + maxConcurrentCommits);\n      System.out.println(\"TEST: tombstones=\" + tombstones);\n      System.out.println(\"TEST: operations=\" + operations);\n      System.out.println(\"\\n\");\n    }\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<>();\n\n    Directory dir = newDirectory();\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    writer.setDoRandomForceMergeAssert(false);\n    writer.commit();\n    reader = DirectoryReader.open(dir);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n                  DirectoryReader oldReader;\n\n                  synchronized(TestStressNRT.this) {\n                    newCommittedModel = new HashMap<>(model);  // take a snapshot\n                    version = snapshotCount++;\n                    oldReader = reader;\n                    oldReader.incRef();  // increment the reference since we will use this for reopening\n                  }\n\n                  DirectoryReader newReader;\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    // assertU(h.commit(\"softCommit\",\"true\"));\n                    if (random().nextBoolean()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": call writer.getReader\");\n                      }\n                      newReader = writer.getReader(true);\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": reopen reader=\" + oldReader + \" version=\" + version);\n                      }\n                      newReader = DirectoryReader.openIfChanged(oldReader, writer.w, true);\n                    }\n                  } else {\n                    // assertU(commit());\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": commit+reopen reader=\" + oldReader + \" version=\" + version);\n                    }\n                    writer.commit();\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": now reopen after commit\");\n                    }\n                    newReader = DirectoryReader.openIfChanged(oldReader);\n                  }\n\n                  // Code below assumes newReader comes w/\n                  // extra ref:\n                  if (newReader == null) {\n                    oldReader.incRef();\n                    newReader = oldReader;\n                  }\n\n                  oldReader.decRef();\n\n                  synchronized(TestStressNRT.this) {\n                    // install the new reader if it's newest (and check the current version since another reader may have already been installed)\n                    //System.out.println(Thread.currentThread().getName() + \": newVersion=\" + newReader.getVersion());\n                    assert newReader.getRefCount() > 0;\n                    assert reader.getRefCount() > 0;\n                    if (newReader.getVersion() > reader.getVersion()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new reader=\" + newReader);\n                      }\n                      reader.decRef();\n                      reader = newReader;\n\n                      // Silly: forces fieldInfos to be\n                      // loaded so we don't hit IOE on later\n                      // reader.toString\n                      newReader.toString();\n\n                      // install this snapshot only if it's newer than the current one\n                      if (version >= committedModelClock) {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new model version=\" + version);\n                        }\n                        committedModel = newCommittedModel;\n                        committedModelClock = version;\n                      } else {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new model version=\" + version);\n                        }\n                      }\n                    } else {\n                      // if the same reader, don't decRef.\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new reader=\" + newReader);\n                      }\n                      newReader.decRef();\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else {\n\n                int id = rand.nextInt(ndocs);\n                Object sync = syncArr[id];\n\n                // set the lastId before we actually change it sometimes to try and\n                // uncover more race conditions between writing and reading\n                boolean before = random().nextBoolean();\n                if (before) {\n                  lastId = id;\n                }\n\n                // We can't concurrently update the same document and retain our invariants of increasing values\n                // since we can't guarantee what order the updates will be executed.\n                synchronized (sync) {\n                  Long val = model.get(id);\n                  long nextVal = Math.abs(val)+1;\n\n                  if (oper < commitPercent + deletePercent) {\n                    // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": term delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new Term(\"id\",Integer.toString(id)));\n                    model.put(id, -nextVal);\n                  } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                    //assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": query delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new TermQuery(new Term(\"id\", Integer.toString(id))));\n                    model.put(id, -nextVal);\n                  } else {\n                    // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                    Document d = new Document();\n                    d.add(newStringField(\"id\", Integer.toString(id), Field.Store.YES));\n                    d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": u id:\" + id + \" val=\" + nextVal);\n                    }\n                    writer.updateDocument(new Term(\"id\", Integer.toString(id)), d);\n                    if (tombstones) {\n                      // remove tombstone after new addition (this should be optional?)\n                      writer.deleteDocuments(new Term(\"id\",\"-\"+Integer.toString(id)));\n                    }\n                    model.put(id, nextVal);\n                  }\n                }\n\n                if (!before) {\n                  lastId = id;\n                }\n              }\n            }\n          } catch (Throwable e) {\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            IndexReader lastReader = null;\n            IndexSearcher lastSearcher = null;\n\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              long val;\n              DirectoryReader r;\n              synchronized(TestStressNRT.this) {\n                val = committedModel.get(id);\n                r = reader;\n                r.incRef();\n              }\n\n              if (VERBOSE) {\n                System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": s id=\" + id + \" val=\" + val + \" r=\" + r.getVersion());\n              }\n\n              //  sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              IndexSearcher searcher;\n              if (r == lastReader) {\n                // Just re-use lastSearcher, else\n                // newSearcher may create too many thread\n                // pools (ExecutorService):\n                searcher = lastSearcher;\n              } else {\n                searcher = newSearcher(r);\n                lastReader = r;\n                lastSearcher = searcher;\n              }\n              Query q = new TermQuery(new Term(\"id\",Integer.toString(id)));\n              TopDocs results = searcher.search(q, 10);\n\n              if (results.totalHits == 0 && tombstones) {\n                // if we couldn't find the doc, look for its tombstone\n                q = new TermQuery(new Term(\"id\",\"-\"+Integer.toString(id)));\n                results = searcher.search(q, 1);\n                if (results.totalHits == 0) {\n                  if (val == -1L) {\n                    // expected... no doc was added yet\n                    r.decRef();\n                    continue;\n                  }\n                  fail(\"No documents or tombstones found for id \" + id + \", expected at least \" + val + \" reader=\" + r);\n                }\n              }\n\n              if (results.totalHits == 0 && !tombstones) {\n                // nothing to do - we can't tell anything from a deleted doc without tombstones\n              } else {\n                // we should have found the document, or its tombstone\n                if (results.totalHits != 1) {\n                  System.out.println(\"FAIL: hits id:\" + id + \" val=\" + val);\n                  for(ScoreDoc sd : results.scoreDocs) {\n                    final Document doc = r.document(sd.doc);\n                    System.out.println(\"  docID=\" + sd.doc + \" id:\" + doc.get(\"id\") + \" foundVal=\" + doc.get(field));\n                  }\n                  fail(\"id=\" + id + \" reader=\" + r + \" totalHits=\" + results.totalHits);\n                }\n                Document doc = searcher.doc(results.scoreDocs[0].doc);\n                long foundVal = Long.parseLong(doc.get(field));\n                if (foundVal < Math.abs(val)) {\n                  fail(\"foundVal=\" + foundVal + \" val=\" + val + \" id=\" + id + \" reader=\" + r);\n                }\n              }\n\n              r.decRef();\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    writer.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: close reader=\" + reader);\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1e6105d385afcbf42689e171e9bcea48d0c9ff6c","date":1454692764,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestStressNRT#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestStressNRT#test().mjava","sourceNew":"  public void test() throws Exception {\n    // update variables\n    final int commitPercent = random().nextInt(20);\n    final int softCommitPercent = random().nextInt(100); // what percent of the commits are soft\n    final int deletePercent = random().nextInt(50);\n    final int deleteByQueryPercent = random().nextInt(25);\n    final int ndocs = atLeast(50);\n    final int nWriteThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    final int maxConcurrentCommits = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n    \n    final boolean tombstones = random().nextBoolean();\n\n    // query variables\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n\n    final int nReadThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    initModel(ndocs);\n\n    final FieldType storedOnlyType = new FieldType();\n    storedOnlyType.setStored(true);\n\n    if (VERBOSE) {\n      System.out.println(\"\\n\");\n      System.out.println(\"TEST: commitPercent=\" + commitPercent);\n      System.out.println(\"TEST: softCommitPercent=\" + softCommitPercent);\n      System.out.println(\"TEST: deletePercent=\" + deletePercent);\n      System.out.println(\"TEST: deleteByQueryPercent=\" + deleteByQueryPercent);\n      System.out.println(\"TEST: ndocs=\" + ndocs);\n      System.out.println(\"TEST: nWriteThreads=\" + nWriteThreads);\n      System.out.println(\"TEST: nReadThreads=\" + nReadThreads);\n      System.out.println(\"TEST: maxConcurrentCommits=\" + maxConcurrentCommits);\n      System.out.println(\"TEST: tombstones=\" + tombstones);\n      System.out.println(\"TEST: operations=\" + operations);\n      System.out.println(\"\\n\");\n    }\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<>();\n\n    Directory dir = newMaybeVirusCheckingDirectory();\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    writer.setDoRandomForceMergeAssert(false);\n    writer.commit();\n    reader = DirectoryReader.open(dir);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n                  DirectoryReader oldReader;\n\n                  synchronized(TestStressNRT.this) {\n                    newCommittedModel = new HashMap<>(model);  // take a snapshot\n                    version = snapshotCount++;\n                    oldReader = reader;\n                    oldReader.incRef();  // increment the reference since we will use this for reopening\n                  }\n\n                  DirectoryReader newReader;\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    // assertU(h.commit(\"softCommit\",\"true\"));\n                    if (random().nextBoolean()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": call writer.getReader\");\n                      }\n                      newReader = writer.getReader();\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": reopen reader=\" + oldReader + \" version=\" + version);\n                      }\n                      newReader = DirectoryReader.openIfChanged(oldReader, writer.w);\n                    }\n                  } else {\n                    // assertU(commit());\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": commit+reopen reader=\" + oldReader + \" version=\" + version);\n                    }\n                    writer.commit();\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": now reopen after commit\");\n                    }\n                    newReader = DirectoryReader.openIfChanged(oldReader);\n                  }\n\n                  // Code below assumes newReader comes w/\n                  // extra ref:\n                  if (newReader == null) {\n                    oldReader.incRef();\n                    newReader = oldReader;\n                  }\n\n                  oldReader.decRef();\n\n                  synchronized(TestStressNRT.this) {\n                    // install the new reader if it's newest (and check the current version since another reader may have already been installed)\n                    //System.out.println(Thread.currentThread().getName() + \": newVersion=\" + newReader.getVersion());\n                    assert newReader.getRefCount() > 0;\n                    assert reader.getRefCount() > 0;\n                    if (newReader.getVersion() > reader.getVersion()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new reader=\" + newReader);\n                      }\n                      reader.decRef();\n                      reader = newReader;\n\n                      // Silly: forces fieldInfos to be\n                      // loaded so we don't hit IOE on later\n                      // reader.toString\n                      newReader.toString();\n\n                      // install this snapshot only if it's newer than the current one\n                      if (version >= committedModelClock) {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new model version=\" + version);\n                        }\n                        committedModel = newCommittedModel;\n                        committedModelClock = version;\n                      } else {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new model version=\" + version);\n                        }\n                      }\n                    } else {\n                      // if the same reader, don't decRef.\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new reader=\" + newReader);\n                      }\n                      newReader.decRef();\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else {\n\n                int id = rand.nextInt(ndocs);\n                Object sync = syncArr[id];\n\n                // set the lastId before we actually change it sometimes to try and\n                // uncover more race conditions between writing and reading\n                boolean before = random().nextBoolean();\n                if (before) {\n                  lastId = id;\n                }\n\n                // We can't concurrently update the same document and retain our invariants of increasing values\n                // since we can't guarantee what order the updates will be executed.\n                synchronized (sync) {\n                  Long val = model.get(id);\n                  long nextVal = Math.abs(val)+1;\n\n                  if (oper < commitPercent + deletePercent) {\n                    // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": term delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new Term(\"id\",Integer.toString(id)));\n                    model.put(id, -nextVal);\n                  } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                    //assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": query delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new TermQuery(new Term(\"id\", Integer.toString(id))));\n                    model.put(id, -nextVal);\n                  } else {\n                    // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                    Document d = new Document();\n                    d.add(newStringField(\"id\", Integer.toString(id), Field.Store.YES));\n                    d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": u id:\" + id + \" val=\" + nextVal);\n                    }\n                    writer.updateDocument(new Term(\"id\", Integer.toString(id)), d);\n                    if (tombstones) {\n                      // remove tombstone after new addition (this should be optional?)\n                      writer.deleteDocuments(new Term(\"id\",\"-\"+Integer.toString(id)));\n                    }\n                    model.put(id, nextVal);\n                  }\n                }\n\n                if (!before) {\n                  lastId = id;\n                }\n              }\n            }\n          } catch (Throwable e) {\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            IndexReader lastReader = null;\n            IndexSearcher lastSearcher = null;\n\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              long val;\n              DirectoryReader r;\n              synchronized(TestStressNRT.this) {\n                val = committedModel.get(id);\n                r = reader;\n                r.incRef();\n              }\n\n              if (VERBOSE) {\n                System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": s id=\" + id + \" val=\" + val + \" r=\" + r.getVersion());\n              }\n\n              //  sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              IndexSearcher searcher;\n              if (r == lastReader) {\n                // Just re-use lastSearcher, else\n                // newSearcher may create too many thread\n                // pools (ExecutorService):\n                searcher = lastSearcher;\n              } else {\n                searcher = newSearcher(r);\n                lastReader = r;\n                lastSearcher = searcher;\n              }\n              Query q = new TermQuery(new Term(\"id\",Integer.toString(id)));\n              TopDocs results = searcher.search(q, 10);\n\n              if (results.totalHits == 0 && tombstones) {\n                // if we couldn't find the doc, look for its tombstone\n                q = new TermQuery(new Term(\"id\",\"-\"+Integer.toString(id)));\n                results = searcher.search(q, 1);\n                if (results.totalHits == 0) {\n                  if (val == -1L) {\n                    // expected... no doc was added yet\n                    r.decRef();\n                    continue;\n                  }\n                  fail(\"No documents or tombstones found for id \" + id + \", expected at least \" + val + \" reader=\" + r);\n                }\n              }\n\n              if (results.totalHits == 0 && !tombstones) {\n                // nothing to do - we can't tell anything from a deleted doc without tombstones\n              } else {\n                // we should have found the document, or its tombstone\n                if (results.totalHits != 1) {\n                  System.out.println(\"FAIL: hits id:\" + id + \" val=\" + val);\n                  for(ScoreDoc sd : results.scoreDocs) {\n                    final Document doc = r.document(sd.doc);\n                    System.out.println(\"  docID=\" + sd.doc + \" id:\" + doc.get(\"id\") + \" foundVal=\" + doc.get(field));\n                  }\n                  fail(\"id=\" + id + \" reader=\" + r + \" totalHits=\" + results.totalHits);\n                }\n                Document doc = searcher.doc(results.scoreDocs[0].doc);\n                long foundVal = Long.parseLong(doc.get(field));\n                if (foundVal < Math.abs(val)) {\n                  fail(\"foundVal=\" + foundVal + \" val=\" + val + \" id=\" + id + \" reader=\" + r);\n                }\n              }\n\n              r.decRef();\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    writer.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: close reader=\" + reader);\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    // update variables\n    final int commitPercent = random().nextInt(20);\n    final int softCommitPercent = random().nextInt(100); // what percent of the commits are soft\n    final int deletePercent = random().nextInt(50);\n    final int deleteByQueryPercent = random().nextInt(25);\n    final int ndocs = atLeast(50);\n    final int nWriteThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    final int maxConcurrentCommits = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n    \n    final boolean tombstones = random().nextBoolean();\n\n    // query variables\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n\n    final int nReadThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    initModel(ndocs);\n\n    final FieldType storedOnlyType = new FieldType();\n    storedOnlyType.setStored(true);\n\n    if (VERBOSE) {\n      System.out.println(\"\\n\");\n      System.out.println(\"TEST: commitPercent=\" + commitPercent);\n      System.out.println(\"TEST: softCommitPercent=\" + softCommitPercent);\n      System.out.println(\"TEST: deletePercent=\" + deletePercent);\n      System.out.println(\"TEST: deleteByQueryPercent=\" + deleteByQueryPercent);\n      System.out.println(\"TEST: ndocs=\" + ndocs);\n      System.out.println(\"TEST: nWriteThreads=\" + nWriteThreads);\n      System.out.println(\"TEST: nReadThreads=\" + nReadThreads);\n      System.out.println(\"TEST: maxConcurrentCommits=\" + maxConcurrentCommits);\n      System.out.println(\"TEST: tombstones=\" + tombstones);\n      System.out.println(\"TEST: operations=\" + operations);\n      System.out.println(\"\\n\");\n    }\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<>();\n\n    Directory dir = newDirectory();\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    writer.setDoRandomForceMergeAssert(false);\n    writer.commit();\n    reader = DirectoryReader.open(dir);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n                  DirectoryReader oldReader;\n\n                  synchronized(TestStressNRT.this) {\n                    newCommittedModel = new HashMap<>(model);  // take a snapshot\n                    version = snapshotCount++;\n                    oldReader = reader;\n                    oldReader.incRef();  // increment the reference since we will use this for reopening\n                  }\n\n                  DirectoryReader newReader;\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    // assertU(h.commit(\"softCommit\",\"true\"));\n                    if (random().nextBoolean()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": call writer.getReader\");\n                      }\n                      newReader = writer.getReader();\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": reopen reader=\" + oldReader + \" version=\" + version);\n                      }\n                      newReader = DirectoryReader.openIfChanged(oldReader, writer.w);\n                    }\n                  } else {\n                    // assertU(commit());\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": commit+reopen reader=\" + oldReader + \" version=\" + version);\n                    }\n                    writer.commit();\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": now reopen after commit\");\n                    }\n                    newReader = DirectoryReader.openIfChanged(oldReader);\n                  }\n\n                  // Code below assumes newReader comes w/\n                  // extra ref:\n                  if (newReader == null) {\n                    oldReader.incRef();\n                    newReader = oldReader;\n                  }\n\n                  oldReader.decRef();\n\n                  synchronized(TestStressNRT.this) {\n                    // install the new reader if it's newest (and check the current version since another reader may have already been installed)\n                    //System.out.println(Thread.currentThread().getName() + \": newVersion=\" + newReader.getVersion());\n                    assert newReader.getRefCount() > 0;\n                    assert reader.getRefCount() > 0;\n                    if (newReader.getVersion() > reader.getVersion()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new reader=\" + newReader);\n                      }\n                      reader.decRef();\n                      reader = newReader;\n\n                      // Silly: forces fieldInfos to be\n                      // loaded so we don't hit IOE on later\n                      // reader.toString\n                      newReader.toString();\n\n                      // install this snapshot only if it's newer than the current one\n                      if (version >= committedModelClock) {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new model version=\" + version);\n                        }\n                        committedModel = newCommittedModel;\n                        committedModelClock = version;\n                      } else {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new model version=\" + version);\n                        }\n                      }\n                    } else {\n                      // if the same reader, don't decRef.\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new reader=\" + newReader);\n                      }\n                      newReader.decRef();\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else {\n\n                int id = rand.nextInt(ndocs);\n                Object sync = syncArr[id];\n\n                // set the lastId before we actually change it sometimes to try and\n                // uncover more race conditions between writing and reading\n                boolean before = random().nextBoolean();\n                if (before) {\n                  lastId = id;\n                }\n\n                // We can't concurrently update the same document and retain our invariants of increasing values\n                // since we can't guarantee what order the updates will be executed.\n                synchronized (sync) {\n                  Long val = model.get(id);\n                  long nextVal = Math.abs(val)+1;\n\n                  if (oper < commitPercent + deletePercent) {\n                    // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": term delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new Term(\"id\",Integer.toString(id)));\n                    model.put(id, -nextVal);\n                  } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                    //assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": query delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new TermQuery(new Term(\"id\", Integer.toString(id))));\n                    model.put(id, -nextVal);\n                  } else {\n                    // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                    Document d = new Document();\n                    d.add(newStringField(\"id\", Integer.toString(id), Field.Store.YES));\n                    d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": u id:\" + id + \" val=\" + nextVal);\n                    }\n                    writer.updateDocument(new Term(\"id\", Integer.toString(id)), d);\n                    if (tombstones) {\n                      // remove tombstone after new addition (this should be optional?)\n                      writer.deleteDocuments(new Term(\"id\",\"-\"+Integer.toString(id)));\n                    }\n                    model.put(id, nextVal);\n                  }\n                }\n\n                if (!before) {\n                  lastId = id;\n                }\n              }\n            }\n          } catch (Throwable e) {\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            IndexReader lastReader = null;\n            IndexSearcher lastSearcher = null;\n\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              long val;\n              DirectoryReader r;\n              synchronized(TestStressNRT.this) {\n                val = committedModel.get(id);\n                r = reader;\n                r.incRef();\n              }\n\n              if (VERBOSE) {\n                System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": s id=\" + id + \" val=\" + val + \" r=\" + r.getVersion());\n              }\n\n              //  sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              IndexSearcher searcher;\n              if (r == lastReader) {\n                // Just re-use lastSearcher, else\n                // newSearcher may create too many thread\n                // pools (ExecutorService):\n                searcher = lastSearcher;\n              } else {\n                searcher = newSearcher(r);\n                lastReader = r;\n                lastSearcher = searcher;\n              }\n              Query q = new TermQuery(new Term(\"id\",Integer.toString(id)));\n              TopDocs results = searcher.search(q, 10);\n\n              if (results.totalHits == 0 && tombstones) {\n                // if we couldn't find the doc, look for its tombstone\n                q = new TermQuery(new Term(\"id\",\"-\"+Integer.toString(id)));\n                results = searcher.search(q, 1);\n                if (results.totalHits == 0) {\n                  if (val == -1L) {\n                    // expected... no doc was added yet\n                    r.decRef();\n                    continue;\n                  }\n                  fail(\"No documents or tombstones found for id \" + id + \", expected at least \" + val + \" reader=\" + r);\n                }\n              }\n\n              if (results.totalHits == 0 && !tombstones) {\n                // nothing to do - we can't tell anything from a deleted doc without tombstones\n              } else {\n                // we should have found the document, or its tombstone\n                if (results.totalHits != 1) {\n                  System.out.println(\"FAIL: hits id:\" + id + \" val=\" + val);\n                  for(ScoreDoc sd : results.scoreDocs) {\n                    final Document doc = r.document(sd.doc);\n                    System.out.println(\"  docID=\" + sd.doc + \" id:\" + doc.get(\"id\") + \" foundVal=\" + doc.get(field));\n                  }\n                  fail(\"id=\" + id + \" reader=\" + r + \" totalHits=\" + results.totalHits);\n                }\n                Document doc = searcher.doc(results.scoreDocs[0].doc);\n                long foundVal = Long.parseLong(doc.get(field));\n                if (foundVal < Math.abs(val)) {\n                  fail(\"foundVal=\" + foundVal + \" val=\" + val + \" id=\" + id + \" reader=\" + r);\n                }\n              }\n\n              r.decRef();\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    writer.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: close reader=\" + reader);\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b470f36a9372c97283360b1304eacbde22df6c0d","date":1454765175,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestStressNRT#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestStressNRT#test().mjava","sourceNew":"  public void test() throws Exception {\n    // update variables\n    final int commitPercent = random().nextInt(20);\n    final int softCommitPercent = random().nextInt(100); // what percent of the commits are soft\n    final int deletePercent = random().nextInt(50);\n    final int deleteByQueryPercent = random().nextInt(25);\n    final int ndocs = atLeast(50);\n    final int nWriteThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    final int maxConcurrentCommits = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n    \n    final boolean tombstones = random().nextBoolean();\n\n    // query variables\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n\n    final int nReadThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    initModel(ndocs);\n\n    final FieldType storedOnlyType = new FieldType();\n    storedOnlyType.setStored(true);\n\n    if (VERBOSE) {\n      System.out.println(\"\\n\");\n      System.out.println(\"TEST: commitPercent=\" + commitPercent);\n      System.out.println(\"TEST: softCommitPercent=\" + softCommitPercent);\n      System.out.println(\"TEST: deletePercent=\" + deletePercent);\n      System.out.println(\"TEST: deleteByQueryPercent=\" + deleteByQueryPercent);\n      System.out.println(\"TEST: ndocs=\" + ndocs);\n      System.out.println(\"TEST: nWriteThreads=\" + nWriteThreads);\n      System.out.println(\"TEST: nReadThreads=\" + nReadThreads);\n      System.out.println(\"TEST: maxConcurrentCommits=\" + maxConcurrentCommits);\n      System.out.println(\"TEST: tombstones=\" + tombstones);\n      System.out.println(\"TEST: operations=\" + operations);\n      System.out.println(\"\\n\");\n    }\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<>();\n\n    Directory dir = newMaybeVirusCheckingDirectory();\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    writer.setDoRandomForceMergeAssert(false);\n    writer.commit();\n    reader = DirectoryReader.open(dir);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n                  DirectoryReader oldReader;\n\n                  synchronized(TestStressNRT.this) {\n                    newCommittedModel = new HashMap<>(model);  // take a snapshot\n                    version = snapshotCount++;\n                    oldReader = reader;\n                    oldReader.incRef();  // increment the reference since we will use this for reopening\n                  }\n\n                  DirectoryReader newReader;\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    // assertU(h.commit(\"softCommit\",\"true\"));\n                    if (random().nextBoolean()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": call writer.getReader\");\n                      }\n                      newReader = writer.getReader();\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": reopen reader=\" + oldReader + \" version=\" + version);\n                      }\n                      newReader = DirectoryReader.openIfChanged(oldReader, writer.w);\n                    }\n                  } else {\n                    // assertU(commit());\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": commit+reopen reader=\" + oldReader + \" version=\" + version);\n                    }\n                    writer.commit();\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": now reopen after commit\");\n                    }\n                    newReader = DirectoryReader.openIfChanged(oldReader);\n                  }\n\n                  // Code below assumes newReader comes w/\n                  // extra ref:\n                  if (newReader == null) {\n                    oldReader.incRef();\n                    newReader = oldReader;\n                  }\n\n                  oldReader.decRef();\n\n                  synchronized(TestStressNRT.this) {\n                    // install the new reader if it's newest (and check the current version since another reader may have already been installed)\n                    //System.out.println(Thread.currentThread().getName() + \": newVersion=\" + newReader.getVersion());\n                    assert newReader.getRefCount() > 0;\n                    assert reader.getRefCount() > 0;\n                    if (newReader.getVersion() > reader.getVersion()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new reader=\" + newReader);\n                      }\n                      reader.decRef();\n                      reader = newReader;\n\n                      // Silly: forces fieldInfos to be\n                      // loaded so we don't hit IOE on later\n                      // reader.toString\n                      newReader.toString();\n\n                      // install this snapshot only if it's newer than the current one\n                      if (version >= committedModelClock) {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new model version=\" + version);\n                        }\n                        committedModel = newCommittedModel;\n                        committedModelClock = version;\n                      } else {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new model version=\" + version);\n                        }\n                      }\n                    } else {\n                      // if the same reader, don't decRef.\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new reader=\" + newReader);\n                      }\n                      newReader.decRef();\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else {\n\n                int id = rand.nextInt(ndocs);\n                Object sync = syncArr[id];\n\n                // set the lastId before we actually change it sometimes to try and\n                // uncover more race conditions between writing and reading\n                boolean before = random().nextBoolean();\n                if (before) {\n                  lastId = id;\n                }\n\n                // We can't concurrently update the same document and retain our invariants of increasing values\n                // since we can't guarantee what order the updates will be executed.\n                synchronized (sync) {\n                  Long val = model.get(id);\n                  long nextVal = Math.abs(val)+1;\n\n                  if (oper < commitPercent + deletePercent) {\n                    // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": term delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new Term(\"id\",Integer.toString(id)));\n                    model.put(id, -nextVal);\n                  } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                    //assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": query delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new TermQuery(new Term(\"id\", Integer.toString(id))));\n                    model.put(id, -nextVal);\n                  } else {\n                    // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                    Document d = new Document();\n                    d.add(newStringField(\"id\", Integer.toString(id), Field.Store.YES));\n                    d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": u id:\" + id + \" val=\" + nextVal);\n                    }\n                    writer.updateDocument(new Term(\"id\", Integer.toString(id)), d);\n                    if (tombstones) {\n                      // remove tombstone after new addition (this should be optional?)\n                      writer.deleteDocuments(new Term(\"id\",\"-\"+Integer.toString(id)));\n                    }\n                    model.put(id, nextVal);\n                  }\n                }\n\n                if (!before) {\n                  lastId = id;\n                }\n              }\n            }\n          } catch (Throwable e) {\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            IndexReader lastReader = null;\n            IndexSearcher lastSearcher = null;\n\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              long val;\n              DirectoryReader r;\n              synchronized(TestStressNRT.this) {\n                val = committedModel.get(id);\n                r = reader;\n                r.incRef();\n              }\n\n              if (VERBOSE) {\n                System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": s id=\" + id + \" val=\" + val + \" r=\" + r.getVersion());\n              }\n\n              //  sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              IndexSearcher searcher;\n              if (r == lastReader) {\n                // Just re-use lastSearcher, else\n                // newSearcher may create too many thread\n                // pools (ExecutorService):\n                searcher = lastSearcher;\n              } else {\n                searcher = newSearcher(r);\n                lastReader = r;\n                lastSearcher = searcher;\n              }\n              Query q = new TermQuery(new Term(\"id\",Integer.toString(id)));\n              TopDocs results = searcher.search(q, 10);\n\n              if (results.totalHits == 0 && tombstones) {\n                // if we couldn't find the doc, look for its tombstone\n                q = new TermQuery(new Term(\"id\",\"-\"+Integer.toString(id)));\n                results = searcher.search(q, 1);\n                if (results.totalHits == 0) {\n                  if (val == -1L) {\n                    // expected... no doc was added yet\n                    r.decRef();\n                    continue;\n                  }\n                  fail(\"No documents or tombstones found for id \" + id + \", expected at least \" + val + \" reader=\" + r);\n                }\n              }\n\n              if (results.totalHits == 0 && !tombstones) {\n                // nothing to do - we can't tell anything from a deleted doc without tombstones\n              } else {\n                // we should have found the document, or its tombstone\n                if (results.totalHits != 1) {\n                  System.out.println(\"FAIL: hits id:\" + id + \" val=\" + val);\n                  for(ScoreDoc sd : results.scoreDocs) {\n                    final Document doc = r.document(sd.doc);\n                    System.out.println(\"  docID=\" + sd.doc + \" id:\" + doc.get(\"id\") + \" foundVal=\" + doc.get(field));\n                  }\n                  fail(\"id=\" + id + \" reader=\" + r + \" totalHits=\" + results.totalHits);\n                }\n                Document doc = searcher.doc(results.scoreDocs[0].doc);\n                long foundVal = Long.parseLong(doc.get(field));\n                if (foundVal < Math.abs(val)) {\n                  fail(\"foundVal=\" + foundVal + \" val=\" + val + \" id=\" + id + \" reader=\" + r);\n                }\n              }\n\n              r.decRef();\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    writer.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: close reader=\" + reader);\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    // update variables\n    final int commitPercent = random().nextInt(20);\n    final int softCommitPercent = random().nextInt(100); // what percent of the commits are soft\n    final int deletePercent = random().nextInt(50);\n    final int deleteByQueryPercent = random().nextInt(25);\n    final int ndocs = atLeast(50);\n    final int nWriteThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    final int maxConcurrentCommits = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n    \n    final boolean tombstones = random().nextBoolean();\n\n    // query variables\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n\n    final int nReadThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    initModel(ndocs);\n\n    final FieldType storedOnlyType = new FieldType();\n    storedOnlyType.setStored(true);\n\n    if (VERBOSE) {\n      System.out.println(\"\\n\");\n      System.out.println(\"TEST: commitPercent=\" + commitPercent);\n      System.out.println(\"TEST: softCommitPercent=\" + softCommitPercent);\n      System.out.println(\"TEST: deletePercent=\" + deletePercent);\n      System.out.println(\"TEST: deleteByQueryPercent=\" + deleteByQueryPercent);\n      System.out.println(\"TEST: ndocs=\" + ndocs);\n      System.out.println(\"TEST: nWriteThreads=\" + nWriteThreads);\n      System.out.println(\"TEST: nReadThreads=\" + nReadThreads);\n      System.out.println(\"TEST: maxConcurrentCommits=\" + maxConcurrentCommits);\n      System.out.println(\"TEST: tombstones=\" + tombstones);\n      System.out.println(\"TEST: operations=\" + operations);\n      System.out.println(\"\\n\");\n    }\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<>();\n\n    Directory dir = newDirectory();\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    writer.setDoRandomForceMergeAssert(false);\n    writer.commit();\n    reader = DirectoryReader.open(dir);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n                  DirectoryReader oldReader;\n\n                  synchronized(TestStressNRT.this) {\n                    newCommittedModel = new HashMap<>(model);  // take a snapshot\n                    version = snapshotCount++;\n                    oldReader = reader;\n                    oldReader.incRef();  // increment the reference since we will use this for reopening\n                  }\n\n                  DirectoryReader newReader;\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    // assertU(h.commit(\"softCommit\",\"true\"));\n                    if (random().nextBoolean()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": call writer.getReader\");\n                      }\n                      newReader = writer.getReader();\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": reopen reader=\" + oldReader + \" version=\" + version);\n                      }\n                      newReader = DirectoryReader.openIfChanged(oldReader, writer.w);\n                    }\n                  } else {\n                    // assertU(commit());\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": commit+reopen reader=\" + oldReader + \" version=\" + version);\n                    }\n                    writer.commit();\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": now reopen after commit\");\n                    }\n                    newReader = DirectoryReader.openIfChanged(oldReader);\n                  }\n\n                  // Code below assumes newReader comes w/\n                  // extra ref:\n                  if (newReader == null) {\n                    oldReader.incRef();\n                    newReader = oldReader;\n                  }\n\n                  oldReader.decRef();\n\n                  synchronized(TestStressNRT.this) {\n                    // install the new reader if it's newest (and check the current version since another reader may have already been installed)\n                    //System.out.println(Thread.currentThread().getName() + \": newVersion=\" + newReader.getVersion());\n                    assert newReader.getRefCount() > 0;\n                    assert reader.getRefCount() > 0;\n                    if (newReader.getVersion() > reader.getVersion()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new reader=\" + newReader);\n                      }\n                      reader.decRef();\n                      reader = newReader;\n\n                      // Silly: forces fieldInfos to be\n                      // loaded so we don't hit IOE on later\n                      // reader.toString\n                      newReader.toString();\n\n                      // install this snapshot only if it's newer than the current one\n                      if (version >= committedModelClock) {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new model version=\" + version);\n                        }\n                        committedModel = newCommittedModel;\n                        committedModelClock = version;\n                      } else {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new model version=\" + version);\n                        }\n                      }\n                    } else {\n                      // if the same reader, don't decRef.\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new reader=\" + newReader);\n                      }\n                      newReader.decRef();\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else {\n\n                int id = rand.nextInt(ndocs);\n                Object sync = syncArr[id];\n\n                // set the lastId before we actually change it sometimes to try and\n                // uncover more race conditions between writing and reading\n                boolean before = random().nextBoolean();\n                if (before) {\n                  lastId = id;\n                }\n\n                // We can't concurrently update the same document and retain our invariants of increasing values\n                // since we can't guarantee what order the updates will be executed.\n                synchronized (sync) {\n                  Long val = model.get(id);\n                  long nextVal = Math.abs(val)+1;\n\n                  if (oper < commitPercent + deletePercent) {\n                    // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": term delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new Term(\"id\",Integer.toString(id)));\n                    model.put(id, -nextVal);\n                  } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                    //assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": query delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new TermQuery(new Term(\"id\", Integer.toString(id))));\n                    model.put(id, -nextVal);\n                  } else {\n                    // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                    Document d = new Document();\n                    d.add(newStringField(\"id\", Integer.toString(id), Field.Store.YES));\n                    d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": u id:\" + id + \" val=\" + nextVal);\n                    }\n                    writer.updateDocument(new Term(\"id\", Integer.toString(id)), d);\n                    if (tombstones) {\n                      // remove tombstone after new addition (this should be optional?)\n                      writer.deleteDocuments(new Term(\"id\",\"-\"+Integer.toString(id)));\n                    }\n                    model.put(id, nextVal);\n                  }\n                }\n\n                if (!before) {\n                  lastId = id;\n                }\n              }\n            }\n          } catch (Throwable e) {\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            IndexReader lastReader = null;\n            IndexSearcher lastSearcher = null;\n\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              long val;\n              DirectoryReader r;\n              synchronized(TestStressNRT.this) {\n                val = committedModel.get(id);\n                r = reader;\n                r.incRef();\n              }\n\n              if (VERBOSE) {\n                System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": s id=\" + id + \" val=\" + val + \" r=\" + r.getVersion());\n              }\n\n              //  sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              IndexSearcher searcher;\n              if (r == lastReader) {\n                // Just re-use lastSearcher, else\n                // newSearcher may create too many thread\n                // pools (ExecutorService):\n                searcher = lastSearcher;\n              } else {\n                searcher = newSearcher(r);\n                lastReader = r;\n                lastSearcher = searcher;\n              }\n              Query q = new TermQuery(new Term(\"id\",Integer.toString(id)));\n              TopDocs results = searcher.search(q, 10);\n\n              if (results.totalHits == 0 && tombstones) {\n                // if we couldn't find the doc, look for its tombstone\n                q = new TermQuery(new Term(\"id\",\"-\"+Integer.toString(id)));\n                results = searcher.search(q, 1);\n                if (results.totalHits == 0) {\n                  if (val == -1L) {\n                    // expected... no doc was added yet\n                    r.decRef();\n                    continue;\n                  }\n                  fail(\"No documents or tombstones found for id \" + id + \", expected at least \" + val + \" reader=\" + r);\n                }\n              }\n\n              if (results.totalHits == 0 && !tombstones) {\n                // nothing to do - we can't tell anything from a deleted doc without tombstones\n              } else {\n                // we should have found the document, or its tombstone\n                if (results.totalHits != 1) {\n                  System.out.println(\"FAIL: hits id:\" + id + \" val=\" + val);\n                  for(ScoreDoc sd : results.scoreDocs) {\n                    final Document doc = r.document(sd.doc);\n                    System.out.println(\"  docID=\" + sd.doc + \" id:\" + doc.get(\"id\") + \" foundVal=\" + doc.get(field));\n                  }\n                  fail(\"id=\" + id + \" reader=\" + r + \" totalHits=\" + results.totalHits);\n                }\n                Document doc = searcher.doc(results.scoreDocs[0].doc);\n                long foundVal = Long.parseLong(doc.get(field));\n                if (foundVal < Math.abs(val)) {\n                  fail(\"foundVal=\" + foundVal + \" val=\" + val + \" id=\" + id + \" reader=\" + r);\n                }\n              }\n\n              r.decRef();\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    writer.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: close reader=\" + reader);\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1e6acbaae7af722f17204ceccf0f7db5753eccf3","date":1454775255,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestStressNRT#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestStressNRT#test().mjava","sourceNew":"  public void test() throws Exception {\n    // update variables\n    final int commitPercent = random().nextInt(20);\n    final int softCommitPercent = random().nextInt(100); // what percent of the commits are soft\n    final int deletePercent = random().nextInt(50);\n    final int deleteByQueryPercent = random().nextInt(25);\n    final int ndocs = atLeast(50);\n    final int nWriteThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    final int maxConcurrentCommits = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n    \n    final boolean tombstones = random().nextBoolean();\n\n    // query variables\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n\n    final int nReadThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    initModel(ndocs);\n\n    final FieldType storedOnlyType = new FieldType();\n    storedOnlyType.setStored(true);\n\n    if (VERBOSE) {\n      System.out.println(\"\\n\");\n      System.out.println(\"TEST: commitPercent=\" + commitPercent);\n      System.out.println(\"TEST: softCommitPercent=\" + softCommitPercent);\n      System.out.println(\"TEST: deletePercent=\" + deletePercent);\n      System.out.println(\"TEST: deleteByQueryPercent=\" + deleteByQueryPercent);\n      System.out.println(\"TEST: ndocs=\" + ndocs);\n      System.out.println(\"TEST: nWriteThreads=\" + nWriteThreads);\n      System.out.println(\"TEST: nReadThreads=\" + nReadThreads);\n      System.out.println(\"TEST: maxConcurrentCommits=\" + maxConcurrentCommits);\n      System.out.println(\"TEST: tombstones=\" + tombstones);\n      System.out.println(\"TEST: operations=\" + operations);\n      System.out.println(\"\\n\");\n    }\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<>();\n\n    Directory dir = newMaybeVirusCheckingDirectory();\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    writer.setDoRandomForceMergeAssert(false);\n    writer.commit();\n    reader = DirectoryReader.open(dir);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n                  DirectoryReader oldReader;\n\n                  synchronized(TestStressNRT.this) {\n                    newCommittedModel = new HashMap<>(model);  // take a snapshot\n                    version = snapshotCount++;\n                    oldReader = reader;\n                    oldReader.incRef();  // increment the reference since we will use this for reopening\n                  }\n\n                  DirectoryReader newReader;\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    // assertU(h.commit(\"softCommit\",\"true\"));\n                    if (random().nextBoolean()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": call writer.getReader\");\n                      }\n                      newReader = writer.getReader();\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": reopen reader=\" + oldReader + \" version=\" + version);\n                      }\n                      newReader = DirectoryReader.openIfChanged(oldReader, writer.w);\n                    }\n                  } else {\n                    // assertU(commit());\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": commit+reopen reader=\" + oldReader + \" version=\" + version);\n                    }\n                    writer.commit();\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": now reopen after commit\");\n                    }\n                    newReader = DirectoryReader.openIfChanged(oldReader);\n                  }\n\n                  // Code below assumes newReader comes w/\n                  // extra ref:\n                  if (newReader == null) {\n                    oldReader.incRef();\n                    newReader = oldReader;\n                  }\n\n                  oldReader.decRef();\n\n                  synchronized(TestStressNRT.this) {\n                    // install the new reader if it's newest (and check the current version since another reader may have already been installed)\n                    //System.out.println(Thread.currentThread().getName() + \": newVersion=\" + newReader.getVersion());\n                    assert newReader.getRefCount() > 0;\n                    assert reader.getRefCount() > 0;\n                    if (newReader.getVersion() > reader.getVersion()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new reader=\" + newReader);\n                      }\n                      reader.decRef();\n                      reader = newReader;\n\n                      // Silly: forces fieldInfos to be\n                      // loaded so we don't hit IOE on later\n                      // reader.toString\n                      newReader.toString();\n\n                      // install this snapshot only if it's newer than the current one\n                      if (version >= committedModelClock) {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new model version=\" + version);\n                        }\n                        committedModel = newCommittedModel;\n                        committedModelClock = version;\n                      } else {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new model version=\" + version);\n                        }\n                      }\n                    } else {\n                      // if the same reader, don't decRef.\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new reader=\" + newReader);\n                      }\n                      newReader.decRef();\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else {\n\n                int id = rand.nextInt(ndocs);\n                Object sync = syncArr[id];\n\n                // set the lastId before we actually change it sometimes to try and\n                // uncover more race conditions between writing and reading\n                boolean before = random().nextBoolean();\n                if (before) {\n                  lastId = id;\n                }\n\n                // We can't concurrently update the same document and retain our invariants of increasing values\n                // since we can't guarantee what order the updates will be executed.\n                synchronized (sync) {\n                  Long val = model.get(id);\n                  long nextVal = Math.abs(val)+1;\n\n                  if (oper < commitPercent + deletePercent) {\n                    // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": term delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new Term(\"id\",Integer.toString(id)));\n                    model.put(id, -nextVal);\n                  } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                    //assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": query delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new TermQuery(new Term(\"id\", Integer.toString(id))));\n                    model.put(id, -nextVal);\n                  } else {\n                    // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                    Document d = new Document();\n                    d.add(newStringField(\"id\", Integer.toString(id), Field.Store.YES));\n                    d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": u id:\" + id + \" val=\" + nextVal);\n                    }\n                    writer.updateDocument(new Term(\"id\", Integer.toString(id)), d);\n                    if (tombstones) {\n                      // remove tombstone after new addition (this should be optional?)\n                      writer.deleteDocuments(new Term(\"id\",\"-\"+Integer.toString(id)));\n                    }\n                    model.put(id, nextVal);\n                  }\n                }\n\n                if (!before) {\n                  lastId = id;\n                }\n              }\n            }\n          } catch (Throwable e) {\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            IndexReader lastReader = null;\n            IndexSearcher lastSearcher = null;\n\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              long val;\n              DirectoryReader r;\n              synchronized(TestStressNRT.this) {\n                val = committedModel.get(id);\n                r = reader;\n                r.incRef();\n              }\n\n              if (VERBOSE) {\n                System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": s id=\" + id + \" val=\" + val + \" r=\" + r.getVersion());\n              }\n\n              //  sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              IndexSearcher searcher;\n              if (r == lastReader) {\n                // Just re-use lastSearcher, else\n                // newSearcher may create too many thread\n                // pools (ExecutorService):\n                searcher = lastSearcher;\n              } else {\n                searcher = newSearcher(r);\n                lastReader = r;\n                lastSearcher = searcher;\n              }\n              Query q = new TermQuery(new Term(\"id\",Integer.toString(id)));\n              TopDocs results = searcher.search(q, 10);\n\n              if (results.totalHits == 0 && tombstones) {\n                // if we couldn't find the doc, look for its tombstone\n                q = new TermQuery(new Term(\"id\",\"-\"+Integer.toString(id)));\n                results = searcher.search(q, 1);\n                if (results.totalHits == 0) {\n                  if (val == -1L) {\n                    // expected... no doc was added yet\n                    r.decRef();\n                    continue;\n                  }\n                  fail(\"No documents or tombstones found for id \" + id + \", expected at least \" + val + \" reader=\" + r);\n                }\n              }\n\n              if (results.totalHits == 0 && !tombstones) {\n                // nothing to do - we can't tell anything from a deleted doc without tombstones\n              } else {\n                // we should have found the document, or its tombstone\n                if (results.totalHits != 1) {\n                  System.out.println(\"FAIL: hits id:\" + id + \" val=\" + val);\n                  for(ScoreDoc sd : results.scoreDocs) {\n                    final Document doc = r.document(sd.doc);\n                    System.out.println(\"  docID=\" + sd.doc + \" id:\" + doc.get(\"id\") + \" foundVal=\" + doc.get(field));\n                  }\n                  fail(\"id=\" + id + \" reader=\" + r + \" totalHits=\" + results.totalHits);\n                }\n                Document doc = searcher.doc(results.scoreDocs[0].doc);\n                long foundVal = Long.parseLong(doc.get(field));\n                if (foundVal < Math.abs(val)) {\n                  fail(\"foundVal=\" + foundVal + \" val=\" + val + \" id=\" + id + \" reader=\" + r);\n                }\n              }\n\n              r.decRef();\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    writer.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: close reader=\" + reader);\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    // update variables\n    final int commitPercent = random().nextInt(20);\n    final int softCommitPercent = random().nextInt(100); // what percent of the commits are soft\n    final int deletePercent = random().nextInt(50);\n    final int deleteByQueryPercent = random().nextInt(25);\n    final int ndocs = atLeast(50);\n    final int nWriteThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    final int maxConcurrentCommits = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n    \n    final boolean tombstones = random().nextBoolean();\n\n    // query variables\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n\n    final int nReadThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    initModel(ndocs);\n\n    final FieldType storedOnlyType = new FieldType();\n    storedOnlyType.setStored(true);\n\n    if (VERBOSE) {\n      System.out.println(\"\\n\");\n      System.out.println(\"TEST: commitPercent=\" + commitPercent);\n      System.out.println(\"TEST: softCommitPercent=\" + softCommitPercent);\n      System.out.println(\"TEST: deletePercent=\" + deletePercent);\n      System.out.println(\"TEST: deleteByQueryPercent=\" + deleteByQueryPercent);\n      System.out.println(\"TEST: ndocs=\" + ndocs);\n      System.out.println(\"TEST: nWriteThreads=\" + nWriteThreads);\n      System.out.println(\"TEST: nReadThreads=\" + nReadThreads);\n      System.out.println(\"TEST: maxConcurrentCommits=\" + maxConcurrentCommits);\n      System.out.println(\"TEST: tombstones=\" + tombstones);\n      System.out.println(\"TEST: operations=\" + operations);\n      System.out.println(\"\\n\");\n    }\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<>();\n\n    Directory dir = newDirectory();\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    writer.setDoRandomForceMergeAssert(false);\n    writer.commit();\n    reader = DirectoryReader.open(dir);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n                  DirectoryReader oldReader;\n\n                  synchronized(TestStressNRT.this) {\n                    newCommittedModel = new HashMap<>(model);  // take a snapshot\n                    version = snapshotCount++;\n                    oldReader = reader;\n                    oldReader.incRef();  // increment the reference since we will use this for reopening\n                  }\n\n                  DirectoryReader newReader;\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    // assertU(h.commit(\"softCommit\",\"true\"));\n                    if (random().nextBoolean()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": call writer.getReader\");\n                      }\n                      newReader = writer.getReader();\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": reopen reader=\" + oldReader + \" version=\" + version);\n                      }\n                      newReader = DirectoryReader.openIfChanged(oldReader, writer.w);\n                    }\n                  } else {\n                    // assertU(commit());\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": commit+reopen reader=\" + oldReader + \" version=\" + version);\n                    }\n                    writer.commit();\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": now reopen after commit\");\n                    }\n                    newReader = DirectoryReader.openIfChanged(oldReader);\n                  }\n\n                  // Code below assumes newReader comes w/\n                  // extra ref:\n                  if (newReader == null) {\n                    oldReader.incRef();\n                    newReader = oldReader;\n                  }\n\n                  oldReader.decRef();\n\n                  synchronized(TestStressNRT.this) {\n                    // install the new reader if it's newest (and check the current version since another reader may have already been installed)\n                    //System.out.println(Thread.currentThread().getName() + \": newVersion=\" + newReader.getVersion());\n                    assert newReader.getRefCount() > 0;\n                    assert reader.getRefCount() > 0;\n                    if (newReader.getVersion() > reader.getVersion()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new reader=\" + newReader);\n                      }\n                      reader.decRef();\n                      reader = newReader;\n\n                      // Silly: forces fieldInfos to be\n                      // loaded so we don't hit IOE on later\n                      // reader.toString\n                      newReader.toString();\n\n                      // install this snapshot only if it's newer than the current one\n                      if (version >= committedModelClock) {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new model version=\" + version);\n                        }\n                        committedModel = newCommittedModel;\n                        committedModelClock = version;\n                      } else {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new model version=\" + version);\n                        }\n                      }\n                    } else {\n                      // if the same reader, don't decRef.\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new reader=\" + newReader);\n                      }\n                      newReader.decRef();\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else {\n\n                int id = rand.nextInt(ndocs);\n                Object sync = syncArr[id];\n\n                // set the lastId before we actually change it sometimes to try and\n                // uncover more race conditions between writing and reading\n                boolean before = random().nextBoolean();\n                if (before) {\n                  lastId = id;\n                }\n\n                // We can't concurrently update the same document and retain our invariants of increasing values\n                // since we can't guarantee what order the updates will be executed.\n                synchronized (sync) {\n                  Long val = model.get(id);\n                  long nextVal = Math.abs(val)+1;\n\n                  if (oper < commitPercent + deletePercent) {\n                    // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": term delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new Term(\"id\",Integer.toString(id)));\n                    model.put(id, -nextVal);\n                  } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                    //assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": query delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new TermQuery(new Term(\"id\", Integer.toString(id))));\n                    model.put(id, -nextVal);\n                  } else {\n                    // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                    Document d = new Document();\n                    d.add(newStringField(\"id\", Integer.toString(id), Field.Store.YES));\n                    d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": u id:\" + id + \" val=\" + nextVal);\n                    }\n                    writer.updateDocument(new Term(\"id\", Integer.toString(id)), d);\n                    if (tombstones) {\n                      // remove tombstone after new addition (this should be optional?)\n                      writer.deleteDocuments(new Term(\"id\",\"-\"+Integer.toString(id)));\n                    }\n                    model.put(id, nextVal);\n                  }\n                }\n\n                if (!before) {\n                  lastId = id;\n                }\n              }\n            }\n          } catch (Throwable e) {\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            IndexReader lastReader = null;\n            IndexSearcher lastSearcher = null;\n\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              long val;\n              DirectoryReader r;\n              synchronized(TestStressNRT.this) {\n                val = committedModel.get(id);\n                r = reader;\n                r.incRef();\n              }\n\n              if (VERBOSE) {\n                System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": s id=\" + id + \" val=\" + val + \" r=\" + r.getVersion());\n              }\n\n              //  sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              IndexSearcher searcher;\n              if (r == lastReader) {\n                // Just re-use lastSearcher, else\n                // newSearcher may create too many thread\n                // pools (ExecutorService):\n                searcher = lastSearcher;\n              } else {\n                searcher = newSearcher(r);\n                lastReader = r;\n                lastSearcher = searcher;\n              }\n              Query q = new TermQuery(new Term(\"id\",Integer.toString(id)));\n              TopDocs results = searcher.search(q, 10);\n\n              if (results.totalHits == 0 && tombstones) {\n                // if we couldn't find the doc, look for its tombstone\n                q = new TermQuery(new Term(\"id\",\"-\"+Integer.toString(id)));\n                results = searcher.search(q, 1);\n                if (results.totalHits == 0) {\n                  if (val == -1L) {\n                    // expected... no doc was added yet\n                    r.decRef();\n                    continue;\n                  }\n                  fail(\"No documents or tombstones found for id \" + id + \", expected at least \" + val + \" reader=\" + r);\n                }\n              }\n\n              if (results.totalHits == 0 && !tombstones) {\n                // nothing to do - we can't tell anything from a deleted doc without tombstones\n              } else {\n                // we should have found the document, or its tombstone\n                if (results.totalHits != 1) {\n                  System.out.println(\"FAIL: hits id:\" + id + \" val=\" + val);\n                  for(ScoreDoc sd : results.scoreDocs) {\n                    final Document doc = r.document(sd.doc);\n                    System.out.println(\"  docID=\" + sd.doc + \" id:\" + doc.get(\"id\") + \" foundVal=\" + doc.get(field));\n                  }\n                  fail(\"id=\" + id + \" reader=\" + r + \" totalHits=\" + results.totalHits);\n                }\n                Document doc = searcher.doc(results.scoreDocs[0].doc);\n                long foundVal = Long.parseLong(doc.get(field));\n                if (foundVal < Math.abs(val)) {\n                  fail(\"foundVal=\" + foundVal + \" val=\" + val + \" id=\" + id + \" reader=\" + r);\n                }\n              }\n\n              r.decRef();\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    writer.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: close reader=\" + reader);\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5a207d19eac354d649c3f0e2cce070017c78125e","date":1454776470,"type":3,"author":"Erick Erickson","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestStressNRT#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestStressNRT#test().mjava","sourceNew":"  public void test() throws Exception {\n    // update variables\n    final int commitPercent = random().nextInt(20);\n    final int softCommitPercent = random().nextInt(100); // what percent of the commits are soft\n    final int deletePercent = random().nextInt(50);\n    final int deleteByQueryPercent = random().nextInt(25);\n    final int ndocs = atLeast(50);\n    final int nWriteThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    final int maxConcurrentCommits = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n    \n    final boolean tombstones = random().nextBoolean();\n\n    // query variables\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n\n    final int nReadThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    initModel(ndocs);\n\n    final FieldType storedOnlyType = new FieldType();\n    storedOnlyType.setStored(true);\n\n    if (VERBOSE) {\n      System.out.println(\"\\n\");\n      System.out.println(\"TEST: commitPercent=\" + commitPercent);\n      System.out.println(\"TEST: softCommitPercent=\" + softCommitPercent);\n      System.out.println(\"TEST: deletePercent=\" + deletePercent);\n      System.out.println(\"TEST: deleteByQueryPercent=\" + deleteByQueryPercent);\n      System.out.println(\"TEST: ndocs=\" + ndocs);\n      System.out.println(\"TEST: nWriteThreads=\" + nWriteThreads);\n      System.out.println(\"TEST: nReadThreads=\" + nReadThreads);\n      System.out.println(\"TEST: maxConcurrentCommits=\" + maxConcurrentCommits);\n      System.out.println(\"TEST: tombstones=\" + tombstones);\n      System.out.println(\"TEST: operations=\" + operations);\n      System.out.println(\"\\n\");\n    }\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<>();\n\n    Directory dir = newMaybeVirusCheckingDirectory();\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    writer.setDoRandomForceMergeAssert(false);\n    writer.commit();\n    reader = DirectoryReader.open(dir);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n                  DirectoryReader oldReader;\n\n                  synchronized(TestStressNRT.this) {\n                    newCommittedModel = new HashMap<>(model);  // take a snapshot\n                    version = snapshotCount++;\n                    oldReader = reader;\n                    oldReader.incRef();  // increment the reference since we will use this for reopening\n                  }\n\n                  DirectoryReader newReader;\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    // assertU(h.commit(\"softCommit\",\"true\"));\n                    if (random().nextBoolean()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": call writer.getReader\");\n                      }\n                      newReader = writer.getReader();\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": reopen reader=\" + oldReader + \" version=\" + version);\n                      }\n                      newReader = DirectoryReader.openIfChanged(oldReader, writer.w);\n                    }\n                  } else {\n                    // assertU(commit());\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": commit+reopen reader=\" + oldReader + \" version=\" + version);\n                    }\n                    writer.commit();\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": now reopen after commit\");\n                    }\n                    newReader = DirectoryReader.openIfChanged(oldReader);\n                  }\n\n                  // Code below assumes newReader comes w/\n                  // extra ref:\n                  if (newReader == null) {\n                    oldReader.incRef();\n                    newReader = oldReader;\n                  }\n\n                  oldReader.decRef();\n\n                  synchronized(TestStressNRT.this) {\n                    // install the new reader if it's newest (and check the current version since another reader may have already been installed)\n                    //System.out.println(Thread.currentThread().getName() + \": newVersion=\" + newReader.getVersion());\n                    assert newReader.getRefCount() > 0;\n                    assert reader.getRefCount() > 0;\n                    if (newReader.getVersion() > reader.getVersion()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new reader=\" + newReader);\n                      }\n                      reader.decRef();\n                      reader = newReader;\n\n                      // Silly: forces fieldInfos to be\n                      // loaded so we don't hit IOE on later\n                      // reader.toString\n                      newReader.toString();\n\n                      // install this snapshot only if it's newer than the current one\n                      if (version >= committedModelClock) {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new model version=\" + version);\n                        }\n                        committedModel = newCommittedModel;\n                        committedModelClock = version;\n                      } else {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new model version=\" + version);\n                        }\n                      }\n                    } else {\n                      // if the same reader, don't decRef.\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new reader=\" + newReader);\n                      }\n                      newReader.decRef();\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else {\n\n                int id = rand.nextInt(ndocs);\n                Object sync = syncArr[id];\n\n                // set the lastId before we actually change it sometimes to try and\n                // uncover more race conditions between writing and reading\n                boolean before = random().nextBoolean();\n                if (before) {\n                  lastId = id;\n                }\n\n                // We can't concurrently update the same document and retain our invariants of increasing values\n                // since we can't guarantee what order the updates will be executed.\n                synchronized (sync) {\n                  Long val = model.get(id);\n                  long nextVal = Math.abs(val)+1;\n\n                  if (oper < commitPercent + deletePercent) {\n                    // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": term delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new Term(\"id\",Integer.toString(id)));\n                    model.put(id, -nextVal);\n                  } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                    //assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": query delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new TermQuery(new Term(\"id\", Integer.toString(id))));\n                    model.put(id, -nextVal);\n                  } else {\n                    // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                    Document d = new Document();\n                    d.add(newStringField(\"id\", Integer.toString(id), Field.Store.YES));\n                    d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": u id:\" + id + \" val=\" + nextVal);\n                    }\n                    writer.updateDocument(new Term(\"id\", Integer.toString(id)), d);\n                    if (tombstones) {\n                      // remove tombstone after new addition (this should be optional?)\n                      writer.deleteDocuments(new Term(\"id\",\"-\"+Integer.toString(id)));\n                    }\n                    model.put(id, nextVal);\n                  }\n                }\n\n                if (!before) {\n                  lastId = id;\n                }\n              }\n            }\n          } catch (Throwable e) {\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            IndexReader lastReader = null;\n            IndexSearcher lastSearcher = null;\n\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              long val;\n              DirectoryReader r;\n              synchronized(TestStressNRT.this) {\n                val = committedModel.get(id);\n                r = reader;\n                r.incRef();\n              }\n\n              if (VERBOSE) {\n                System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": s id=\" + id + \" val=\" + val + \" r=\" + r.getVersion());\n              }\n\n              //  sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              IndexSearcher searcher;\n              if (r == lastReader) {\n                // Just re-use lastSearcher, else\n                // newSearcher may create too many thread\n                // pools (ExecutorService):\n                searcher = lastSearcher;\n              } else {\n                searcher = newSearcher(r);\n                lastReader = r;\n                lastSearcher = searcher;\n              }\n              Query q = new TermQuery(new Term(\"id\",Integer.toString(id)));\n              TopDocs results = searcher.search(q, 10);\n\n              if (results.totalHits == 0 && tombstones) {\n                // if we couldn't find the doc, look for its tombstone\n                q = new TermQuery(new Term(\"id\",\"-\"+Integer.toString(id)));\n                results = searcher.search(q, 1);\n                if (results.totalHits == 0) {\n                  if (val == -1L) {\n                    // expected... no doc was added yet\n                    r.decRef();\n                    continue;\n                  }\n                  fail(\"No documents or tombstones found for id \" + id + \", expected at least \" + val + \" reader=\" + r);\n                }\n              }\n\n              if (results.totalHits == 0 && !tombstones) {\n                // nothing to do - we can't tell anything from a deleted doc without tombstones\n              } else {\n                // we should have found the document, or its tombstone\n                if (results.totalHits != 1) {\n                  System.out.println(\"FAIL: hits id:\" + id + \" val=\" + val);\n                  for(ScoreDoc sd : results.scoreDocs) {\n                    final Document doc = r.document(sd.doc);\n                    System.out.println(\"  docID=\" + sd.doc + \" id:\" + doc.get(\"id\") + \" foundVal=\" + doc.get(field));\n                  }\n                  fail(\"id=\" + id + \" reader=\" + r + \" totalHits=\" + results.totalHits);\n                }\n                Document doc = searcher.doc(results.scoreDocs[0].doc);\n                long foundVal = Long.parseLong(doc.get(field));\n                if (foundVal < Math.abs(val)) {\n                  fail(\"foundVal=\" + foundVal + \" val=\" + val + \" id=\" + id + \" reader=\" + r);\n                }\n              }\n\n              r.decRef();\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    writer.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: close reader=\" + reader);\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    // update variables\n    final int commitPercent = random().nextInt(20);\n    final int softCommitPercent = random().nextInt(100); // what percent of the commits are soft\n    final int deletePercent = random().nextInt(50);\n    final int deleteByQueryPercent = random().nextInt(25);\n    final int ndocs = atLeast(50);\n    final int nWriteThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    final int maxConcurrentCommits = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n    \n    final boolean tombstones = random().nextBoolean();\n\n    // query variables\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n\n    final int nReadThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    initModel(ndocs);\n\n    final FieldType storedOnlyType = new FieldType();\n    storedOnlyType.setStored(true);\n\n    if (VERBOSE) {\n      System.out.println(\"\\n\");\n      System.out.println(\"TEST: commitPercent=\" + commitPercent);\n      System.out.println(\"TEST: softCommitPercent=\" + softCommitPercent);\n      System.out.println(\"TEST: deletePercent=\" + deletePercent);\n      System.out.println(\"TEST: deleteByQueryPercent=\" + deleteByQueryPercent);\n      System.out.println(\"TEST: ndocs=\" + ndocs);\n      System.out.println(\"TEST: nWriteThreads=\" + nWriteThreads);\n      System.out.println(\"TEST: nReadThreads=\" + nReadThreads);\n      System.out.println(\"TEST: maxConcurrentCommits=\" + maxConcurrentCommits);\n      System.out.println(\"TEST: tombstones=\" + tombstones);\n      System.out.println(\"TEST: operations=\" + operations);\n      System.out.println(\"\\n\");\n    }\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<>();\n\n    Directory dir = newDirectory();\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    writer.setDoRandomForceMergeAssert(false);\n    writer.commit();\n    reader = DirectoryReader.open(dir);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n                  DirectoryReader oldReader;\n\n                  synchronized(TestStressNRT.this) {\n                    newCommittedModel = new HashMap<>(model);  // take a snapshot\n                    version = snapshotCount++;\n                    oldReader = reader;\n                    oldReader.incRef();  // increment the reference since we will use this for reopening\n                  }\n\n                  DirectoryReader newReader;\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    // assertU(h.commit(\"softCommit\",\"true\"));\n                    if (random().nextBoolean()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": call writer.getReader\");\n                      }\n                      newReader = writer.getReader();\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": reopen reader=\" + oldReader + \" version=\" + version);\n                      }\n                      newReader = DirectoryReader.openIfChanged(oldReader, writer.w);\n                    }\n                  } else {\n                    // assertU(commit());\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": commit+reopen reader=\" + oldReader + \" version=\" + version);\n                    }\n                    writer.commit();\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": now reopen after commit\");\n                    }\n                    newReader = DirectoryReader.openIfChanged(oldReader);\n                  }\n\n                  // Code below assumes newReader comes w/\n                  // extra ref:\n                  if (newReader == null) {\n                    oldReader.incRef();\n                    newReader = oldReader;\n                  }\n\n                  oldReader.decRef();\n\n                  synchronized(TestStressNRT.this) {\n                    // install the new reader if it's newest (and check the current version since another reader may have already been installed)\n                    //System.out.println(Thread.currentThread().getName() + \": newVersion=\" + newReader.getVersion());\n                    assert newReader.getRefCount() > 0;\n                    assert reader.getRefCount() > 0;\n                    if (newReader.getVersion() > reader.getVersion()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new reader=\" + newReader);\n                      }\n                      reader.decRef();\n                      reader = newReader;\n\n                      // Silly: forces fieldInfos to be\n                      // loaded so we don't hit IOE on later\n                      // reader.toString\n                      newReader.toString();\n\n                      // install this snapshot only if it's newer than the current one\n                      if (version >= committedModelClock) {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new model version=\" + version);\n                        }\n                        committedModel = newCommittedModel;\n                        committedModelClock = version;\n                      } else {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new model version=\" + version);\n                        }\n                      }\n                    } else {\n                      // if the same reader, don't decRef.\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new reader=\" + newReader);\n                      }\n                      newReader.decRef();\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else {\n\n                int id = rand.nextInt(ndocs);\n                Object sync = syncArr[id];\n\n                // set the lastId before we actually change it sometimes to try and\n                // uncover more race conditions between writing and reading\n                boolean before = random().nextBoolean();\n                if (before) {\n                  lastId = id;\n                }\n\n                // We can't concurrently update the same document and retain our invariants of increasing values\n                // since we can't guarantee what order the updates will be executed.\n                synchronized (sync) {\n                  Long val = model.get(id);\n                  long nextVal = Math.abs(val)+1;\n\n                  if (oper < commitPercent + deletePercent) {\n                    // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": term delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new Term(\"id\",Integer.toString(id)));\n                    model.put(id, -nextVal);\n                  } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                    //assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": query delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new TermQuery(new Term(\"id\", Integer.toString(id))));\n                    model.put(id, -nextVal);\n                  } else {\n                    // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                    Document d = new Document();\n                    d.add(newStringField(\"id\", Integer.toString(id), Field.Store.YES));\n                    d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": u id:\" + id + \" val=\" + nextVal);\n                    }\n                    writer.updateDocument(new Term(\"id\", Integer.toString(id)), d);\n                    if (tombstones) {\n                      // remove tombstone after new addition (this should be optional?)\n                      writer.deleteDocuments(new Term(\"id\",\"-\"+Integer.toString(id)));\n                    }\n                    model.put(id, nextVal);\n                  }\n                }\n\n                if (!before) {\n                  lastId = id;\n                }\n              }\n            }\n          } catch (Throwable e) {\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            IndexReader lastReader = null;\n            IndexSearcher lastSearcher = null;\n\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              long val;\n              DirectoryReader r;\n              synchronized(TestStressNRT.this) {\n                val = committedModel.get(id);\n                r = reader;\n                r.incRef();\n              }\n\n              if (VERBOSE) {\n                System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": s id=\" + id + \" val=\" + val + \" r=\" + r.getVersion());\n              }\n\n              //  sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              IndexSearcher searcher;\n              if (r == lastReader) {\n                // Just re-use lastSearcher, else\n                // newSearcher may create too many thread\n                // pools (ExecutorService):\n                searcher = lastSearcher;\n              } else {\n                searcher = newSearcher(r);\n                lastReader = r;\n                lastSearcher = searcher;\n              }\n              Query q = new TermQuery(new Term(\"id\",Integer.toString(id)));\n              TopDocs results = searcher.search(q, 10);\n\n              if (results.totalHits == 0 && tombstones) {\n                // if we couldn't find the doc, look for its tombstone\n                q = new TermQuery(new Term(\"id\",\"-\"+Integer.toString(id)));\n                results = searcher.search(q, 1);\n                if (results.totalHits == 0) {\n                  if (val == -1L) {\n                    // expected... no doc was added yet\n                    r.decRef();\n                    continue;\n                  }\n                  fail(\"No documents or tombstones found for id \" + id + \", expected at least \" + val + \" reader=\" + r);\n                }\n              }\n\n              if (results.totalHits == 0 && !tombstones) {\n                // nothing to do - we can't tell anything from a deleted doc without tombstones\n              } else {\n                // we should have found the document, or its tombstone\n                if (results.totalHits != 1) {\n                  System.out.println(\"FAIL: hits id:\" + id + \" val=\" + val);\n                  for(ScoreDoc sd : results.scoreDocs) {\n                    final Document doc = r.document(sd.doc);\n                    System.out.println(\"  docID=\" + sd.doc + \" id:\" + doc.get(\"id\") + \" foundVal=\" + doc.get(field));\n                  }\n                  fail(\"id=\" + id + \" reader=\" + r + \" totalHits=\" + results.totalHits);\n                }\n                Document doc = searcher.doc(results.scoreDocs[0].doc);\n                long foundVal = Long.parseLong(doc.get(field));\n                if (foundVal < Math.abs(val)) {\n                  fail(\"foundVal=\" + foundVal + \" val=\" + val + \" id=\" + id + \" reader=\" + r);\n                }\n              }\n\n              r.decRef();\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    writer.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: close reader=\" + reader);\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5ee0394b8176abd7c90a4be8c05465be1879db79","date":1522842314,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestStressNRT#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestStressNRT#test().mjava","sourceNew":"  public void test() throws Exception {\n    // update variables\n    final int commitPercent = random().nextInt(20);\n    final int softCommitPercent = random().nextInt(100); // what percent of the commits are soft\n    final int deletePercent = random().nextInt(50);\n    final int deleteByQueryPercent = random().nextInt(25);\n    final int ndocs = atLeast(50);\n    final int nWriteThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    final int maxConcurrentCommits = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n    final boolean useSoftDeletes = random().nextInt(10) < 3;\n    \n    final boolean tombstones = random().nextBoolean();\n\n    // query variables\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n\n    final int nReadThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    initModel(ndocs);\n\n    final FieldType storedOnlyType = new FieldType();\n    storedOnlyType.setStored(true);\n\n    if (VERBOSE) {\n      System.out.println(\"\\n\");\n      System.out.println(\"TEST: commitPercent=\" + commitPercent);\n      System.out.println(\"TEST: softCommitPercent=\" + softCommitPercent);\n      System.out.println(\"TEST: deletePercent=\" + deletePercent);\n      System.out.println(\"TEST: deleteByQueryPercent=\" + deleteByQueryPercent);\n      System.out.println(\"TEST: ndocs=\" + ndocs);\n      System.out.println(\"TEST: nWriteThreads=\" + nWriteThreads);\n      System.out.println(\"TEST: nReadThreads=\" + nReadThreads);\n      System.out.println(\"TEST: maxConcurrentCommits=\" + maxConcurrentCommits);\n      System.out.println(\"TEST: tombstones=\" + tombstones);\n      System.out.println(\"TEST: operations=\" + operations);\n      System.out.println(\"\\n\");\n    }\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<>();\n\n    Directory dir = newMaybeVirusCheckingDirectory();\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), dir, newIndexWriterConfig(new MockAnalyzer(random())), useSoftDeletes);\n    writer.setDoRandomForceMergeAssert(false);\n    writer.commit();\n    reader = useSoftDeletes ? writer.getReader() : DirectoryReader.open(dir);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n                  DirectoryReader oldReader;\n\n                  synchronized(TestStressNRT.this) {\n                    newCommittedModel = new HashMap<>(model);  // take a snapshot\n                    version = snapshotCount++;\n                    oldReader = reader;\n                    oldReader.incRef();  // increment the reference since we will use this for reopening\n                  }\n\n                  DirectoryReader newReader;\n                  if (rand.nextInt(100) < softCommitPercent || useSoftDeletes) {\n                    // assertU(h.commit(\"softCommit\",\"true\"));\n                    if (random().nextBoolean()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": call writer.getReader\");\n                      }\n                      newReader = writer.getReader();\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": reopen reader=\" + oldReader + \" version=\" + version);\n                      }\n                      newReader = DirectoryReader.openIfChanged(oldReader, writer.w);\n                    }\n                  } else {\n                    // assertU(commit());\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": commit+reopen reader=\" + oldReader + \" version=\" + version);\n                    }\n                    writer.commit();\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": now reopen after commit\");\n                    }\n                    newReader = DirectoryReader.openIfChanged(oldReader);\n                  }\n\n                  // Code below assumes newReader comes w/\n                  // extra ref:\n                  if (newReader == null) {\n                    oldReader.incRef();\n                    newReader = oldReader;\n                  }\n\n                  oldReader.decRef();\n\n                  synchronized(TestStressNRT.this) {\n                    // install the new reader if it's newest (and check the current version since another reader may have already been installed)\n                    //System.out.println(Thread.currentThread().getName() + \": newVersion=\" + newReader.getVersion());\n                    assert newReader.getRefCount() > 0;\n                    assert reader.getRefCount() > 0;\n                    if (newReader.getVersion() > reader.getVersion()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new reader=\" + newReader);\n                      }\n                      reader.decRef();\n                      reader = newReader;\n\n                      // Silly: forces fieldInfos to be\n                      // loaded so we don't hit IOE on later\n                      // reader.toString\n                      newReader.toString();\n\n                      // install this snapshot only if it's newer than the current one\n                      if (version >= committedModelClock) {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new model version=\" + version);\n                        }\n                        committedModel = newCommittedModel;\n                        committedModelClock = version;\n                      } else {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new model version=\" + version);\n                        }\n                      }\n                    } else {\n                      // if the same reader, don't decRef.\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new reader=\" + newReader);\n                      }\n                      newReader.decRef();\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else {\n\n                int id = rand.nextInt(ndocs);\n                Object sync = syncArr[id];\n\n                // set the lastId before we actually change it sometimes to try and\n                // uncover more race conditions between writing and reading\n                boolean before = random().nextBoolean();\n                if (before) {\n                  lastId = id;\n                }\n\n                // We can't concurrently update the same document and retain our invariants of increasing values\n                // since we can't guarantee what order the updates will be executed.\n                synchronized (sync) {\n                  Long val = model.get(id);\n                  long nextVal = Math.abs(val)+1;\n\n                  if (oper < commitPercent + deletePercent) {\n                    // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": term delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new Term(\"id\",Integer.toString(id)));\n                    model.put(id, -nextVal);\n                  } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                    //assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": query delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new TermQuery(new Term(\"id\", Integer.toString(id))));\n                    model.put(id, -nextVal);\n                  } else {\n                    // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                    Document d = new Document();\n                    d.add(newStringField(\"id\", Integer.toString(id), Field.Store.YES));\n                    d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": u id:\" + id + \" val=\" + nextVal);\n                    }\n                    writer.updateDocument(new Term(\"id\", Integer.toString(id)), d);\n                    if (tombstones) {\n                      // remove tombstone after new addition (this should be optional?)\n                      writer.deleteDocuments(new Term(\"id\",\"-\"+Integer.toString(id)));\n                    }\n                    model.put(id, nextVal);\n                  }\n                }\n\n                if (!before) {\n                  lastId = id;\n                }\n              }\n            }\n          } catch (Throwable e) {\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            IndexReader lastReader = null;\n            IndexSearcher lastSearcher = null;\n\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              long val;\n              DirectoryReader r;\n              synchronized(TestStressNRT.this) {\n                val = committedModel.get(id);\n                r = reader;\n                r.incRef();\n              }\n\n              if (VERBOSE) {\n                System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": s id=\" + id + \" val=\" + val + \" r=\" + r.getVersion());\n              }\n\n              //  sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              IndexSearcher searcher;\n              if (r == lastReader) {\n                // Just re-use lastSearcher, else\n                // newSearcher may create too many thread\n                // pools (ExecutorService):\n                searcher = lastSearcher;\n              } else {\n                searcher = newSearcher(r);\n                lastReader = r;\n                lastSearcher = searcher;\n              }\n              Query q = new TermQuery(new Term(\"id\",Integer.toString(id)));\n              TopDocs results = searcher.search(q, 10);\n\n              if (results.totalHits == 0 && tombstones) {\n                // if we couldn't find the doc, look for its tombstone\n                q = new TermQuery(new Term(\"id\",\"-\"+Integer.toString(id)));\n                results = searcher.search(q, 1);\n                if (results.totalHits == 0) {\n                  if (val == -1L) {\n                    // expected... no doc was added yet\n                    r.decRef();\n                    continue;\n                  }\n                  fail(\"No documents or tombstones found for id \" + id + \", expected at least \" + val + \" reader=\" + r);\n                }\n              }\n\n              if (results.totalHits == 0 && !tombstones) {\n                // nothing to do - we can't tell anything from a deleted doc without tombstones\n              } else {\n                // we should have found the document, or its tombstone\n                if (results.totalHits != 1) {\n                  System.out.println(\"FAIL: hits id:\" + id + \" val=\" + val);\n                  for(ScoreDoc sd : results.scoreDocs) {\n                    final Document doc = r.document(sd.doc);\n                    System.out.println(\"  docID=\" + sd.doc + \" id:\" + doc.get(\"id\") + \" foundVal=\" + doc.get(field));\n                  }\n                  fail(\"id=\" + id + \" reader=\" + r + \" totalHits=\" + results.totalHits);\n                }\n                Document doc = searcher.doc(results.scoreDocs[0].doc);\n                long foundVal = Long.parseLong(doc.get(field));\n                if (foundVal < Math.abs(val)) {\n                  fail(\"foundVal=\" + foundVal + \" val=\" + val + \" id=\" + id + \" reader=\" + r);\n                }\n              }\n\n              r.decRef();\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    writer.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: close reader=\" + reader);\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    // update variables\n    final int commitPercent = random().nextInt(20);\n    final int softCommitPercent = random().nextInt(100); // what percent of the commits are soft\n    final int deletePercent = random().nextInt(50);\n    final int deleteByQueryPercent = random().nextInt(25);\n    final int ndocs = atLeast(50);\n    final int nWriteThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    final int maxConcurrentCommits = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n    \n    final boolean tombstones = random().nextBoolean();\n\n    // query variables\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n\n    final int nReadThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    initModel(ndocs);\n\n    final FieldType storedOnlyType = new FieldType();\n    storedOnlyType.setStored(true);\n\n    if (VERBOSE) {\n      System.out.println(\"\\n\");\n      System.out.println(\"TEST: commitPercent=\" + commitPercent);\n      System.out.println(\"TEST: softCommitPercent=\" + softCommitPercent);\n      System.out.println(\"TEST: deletePercent=\" + deletePercent);\n      System.out.println(\"TEST: deleteByQueryPercent=\" + deleteByQueryPercent);\n      System.out.println(\"TEST: ndocs=\" + ndocs);\n      System.out.println(\"TEST: nWriteThreads=\" + nWriteThreads);\n      System.out.println(\"TEST: nReadThreads=\" + nReadThreads);\n      System.out.println(\"TEST: maxConcurrentCommits=\" + maxConcurrentCommits);\n      System.out.println(\"TEST: tombstones=\" + tombstones);\n      System.out.println(\"TEST: operations=\" + operations);\n      System.out.println(\"\\n\");\n    }\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<>();\n\n    Directory dir = newMaybeVirusCheckingDirectory();\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    writer.setDoRandomForceMergeAssert(false);\n    writer.commit();\n    reader = DirectoryReader.open(dir);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n                  DirectoryReader oldReader;\n\n                  synchronized(TestStressNRT.this) {\n                    newCommittedModel = new HashMap<>(model);  // take a snapshot\n                    version = snapshotCount++;\n                    oldReader = reader;\n                    oldReader.incRef();  // increment the reference since we will use this for reopening\n                  }\n\n                  DirectoryReader newReader;\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    // assertU(h.commit(\"softCommit\",\"true\"));\n                    if (random().nextBoolean()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": call writer.getReader\");\n                      }\n                      newReader = writer.getReader();\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": reopen reader=\" + oldReader + \" version=\" + version);\n                      }\n                      newReader = DirectoryReader.openIfChanged(oldReader, writer.w);\n                    }\n                  } else {\n                    // assertU(commit());\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": commit+reopen reader=\" + oldReader + \" version=\" + version);\n                    }\n                    writer.commit();\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": now reopen after commit\");\n                    }\n                    newReader = DirectoryReader.openIfChanged(oldReader);\n                  }\n\n                  // Code below assumes newReader comes w/\n                  // extra ref:\n                  if (newReader == null) {\n                    oldReader.incRef();\n                    newReader = oldReader;\n                  }\n\n                  oldReader.decRef();\n\n                  synchronized(TestStressNRT.this) {\n                    // install the new reader if it's newest (and check the current version since another reader may have already been installed)\n                    //System.out.println(Thread.currentThread().getName() + \": newVersion=\" + newReader.getVersion());\n                    assert newReader.getRefCount() > 0;\n                    assert reader.getRefCount() > 0;\n                    if (newReader.getVersion() > reader.getVersion()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new reader=\" + newReader);\n                      }\n                      reader.decRef();\n                      reader = newReader;\n\n                      // Silly: forces fieldInfos to be\n                      // loaded so we don't hit IOE on later\n                      // reader.toString\n                      newReader.toString();\n\n                      // install this snapshot only if it's newer than the current one\n                      if (version >= committedModelClock) {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new model version=\" + version);\n                        }\n                        committedModel = newCommittedModel;\n                        committedModelClock = version;\n                      } else {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new model version=\" + version);\n                        }\n                      }\n                    } else {\n                      // if the same reader, don't decRef.\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new reader=\" + newReader);\n                      }\n                      newReader.decRef();\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else {\n\n                int id = rand.nextInt(ndocs);\n                Object sync = syncArr[id];\n\n                // set the lastId before we actually change it sometimes to try and\n                // uncover more race conditions between writing and reading\n                boolean before = random().nextBoolean();\n                if (before) {\n                  lastId = id;\n                }\n\n                // We can't concurrently update the same document and retain our invariants of increasing values\n                // since we can't guarantee what order the updates will be executed.\n                synchronized (sync) {\n                  Long val = model.get(id);\n                  long nextVal = Math.abs(val)+1;\n\n                  if (oper < commitPercent + deletePercent) {\n                    // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": term delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new Term(\"id\",Integer.toString(id)));\n                    model.put(id, -nextVal);\n                  } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                    //assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": query delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new TermQuery(new Term(\"id\", Integer.toString(id))));\n                    model.put(id, -nextVal);\n                  } else {\n                    // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                    Document d = new Document();\n                    d.add(newStringField(\"id\", Integer.toString(id), Field.Store.YES));\n                    d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": u id:\" + id + \" val=\" + nextVal);\n                    }\n                    writer.updateDocument(new Term(\"id\", Integer.toString(id)), d);\n                    if (tombstones) {\n                      // remove tombstone after new addition (this should be optional?)\n                      writer.deleteDocuments(new Term(\"id\",\"-\"+Integer.toString(id)));\n                    }\n                    model.put(id, nextVal);\n                  }\n                }\n\n                if (!before) {\n                  lastId = id;\n                }\n              }\n            }\n          } catch (Throwable e) {\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            IndexReader lastReader = null;\n            IndexSearcher lastSearcher = null;\n\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              long val;\n              DirectoryReader r;\n              synchronized(TestStressNRT.this) {\n                val = committedModel.get(id);\n                r = reader;\n                r.incRef();\n              }\n\n              if (VERBOSE) {\n                System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": s id=\" + id + \" val=\" + val + \" r=\" + r.getVersion());\n              }\n\n              //  sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              IndexSearcher searcher;\n              if (r == lastReader) {\n                // Just re-use lastSearcher, else\n                // newSearcher may create too many thread\n                // pools (ExecutorService):\n                searcher = lastSearcher;\n              } else {\n                searcher = newSearcher(r);\n                lastReader = r;\n                lastSearcher = searcher;\n              }\n              Query q = new TermQuery(new Term(\"id\",Integer.toString(id)));\n              TopDocs results = searcher.search(q, 10);\n\n              if (results.totalHits == 0 && tombstones) {\n                // if we couldn't find the doc, look for its tombstone\n                q = new TermQuery(new Term(\"id\",\"-\"+Integer.toString(id)));\n                results = searcher.search(q, 1);\n                if (results.totalHits == 0) {\n                  if (val == -1L) {\n                    // expected... no doc was added yet\n                    r.decRef();\n                    continue;\n                  }\n                  fail(\"No documents or tombstones found for id \" + id + \", expected at least \" + val + \" reader=\" + r);\n                }\n              }\n\n              if (results.totalHits == 0 && !tombstones) {\n                // nothing to do - we can't tell anything from a deleted doc without tombstones\n              } else {\n                // we should have found the document, or its tombstone\n                if (results.totalHits != 1) {\n                  System.out.println(\"FAIL: hits id:\" + id + \" val=\" + val);\n                  for(ScoreDoc sd : results.scoreDocs) {\n                    final Document doc = r.document(sd.doc);\n                    System.out.println(\"  docID=\" + sd.doc + \" id:\" + doc.get(\"id\") + \" foundVal=\" + doc.get(field));\n                  }\n                  fail(\"id=\" + id + \" reader=\" + r + \" totalHits=\" + results.totalHits);\n                }\n                Document doc = searcher.doc(results.scoreDocs[0].doc);\n                long foundVal = Long.parseLong(doc.get(field));\n                if (foundVal < Math.abs(val)) {\n                  fail(\"foundVal=\" + foundVal + \" val=\" + val + \" id=\" + id + \" reader=\" + r);\n                }\n              }\n\n              r.decRef();\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    writer.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: close reader=\" + reader);\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cb0130363fa13c53e4e78317c35b3b45a3089276","date":1523267438,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestStressNRT#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestStressNRT#test().mjava","sourceNew":"  public void test() throws Exception {\n    // update variables\n    final int commitPercent = random().nextInt(20);\n    final int softCommitPercent = random().nextInt(100); // what percent of the commits are soft\n    final int deletePercent = random().nextInt(50);\n    final int deleteByQueryPercent = random().nextInt(25);\n    final int ndocs = atLeast(50);\n    final int nWriteThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    final int maxConcurrentCommits = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n    final boolean useSoftDeletes = random().nextInt(10) < 3;\n    \n    final boolean tombstones = random().nextBoolean();\n\n    // query variables\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n\n    final int nReadThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    initModel(ndocs);\n\n    final FieldType storedOnlyType = new FieldType();\n    storedOnlyType.setStored(true);\n\n    if (VERBOSE) {\n      System.out.println(\"\\n\");\n      System.out.println(\"TEST: commitPercent=\" + commitPercent);\n      System.out.println(\"TEST: softCommitPercent=\" + softCommitPercent);\n      System.out.println(\"TEST: deletePercent=\" + deletePercent);\n      System.out.println(\"TEST: deleteByQueryPercent=\" + deleteByQueryPercent);\n      System.out.println(\"TEST: ndocs=\" + ndocs);\n      System.out.println(\"TEST: nWriteThreads=\" + nWriteThreads);\n      System.out.println(\"TEST: nReadThreads=\" + nReadThreads);\n      System.out.println(\"TEST: maxConcurrentCommits=\" + maxConcurrentCommits);\n      System.out.println(\"TEST: tombstones=\" + tombstones);\n      System.out.println(\"TEST: operations=\" + operations);\n      System.out.println(\"\\n\");\n    }\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<>();\n\n    Directory dir = newMaybeVirusCheckingDirectory();\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), dir, newIndexWriterConfig(new MockAnalyzer(random())), useSoftDeletes);\n    writer.setDoRandomForceMergeAssert(false);\n    writer.commit();\n    if (useSoftDeletes) {\n      reader = new SoftDeletesDirectoryReaderWrapper(DirectoryReader.open(dir), writer.w.getConfig().getSoftDeletesField());\n    } else {\n      reader = DirectoryReader.open(dir);\n    }\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n                  DirectoryReader oldReader;\n\n                  synchronized(TestStressNRT.this) {\n                    newCommittedModel = new HashMap<>(model);  // take a snapshot\n                    version = snapshotCount++;\n                    oldReader = reader;\n                    oldReader.incRef();  // increment the reference since we will use this for reopening\n                  }\n\n                  DirectoryReader newReader;\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    // assertU(h.commit(\"softCommit\",\"true\"));\n                    if (random().nextBoolean()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": call writer.getReader\");\n                      }\n                      newReader = writer.getReader();\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": reopen reader=\" + oldReader + \" version=\" + version);\n                      }\n                      newReader = DirectoryReader.openIfChanged(oldReader, writer.w);\n                    }\n                  } else {\n                    // assertU(commit());\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": commit+reopen reader=\" + oldReader + \" version=\" + version);\n                    }\n                    writer.commit();\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": now reopen after commit\");\n                    }\n                    newReader = DirectoryReader.openIfChanged(oldReader);\n                  }\n\n                  // Code below assumes newReader comes w/\n                  // extra ref:\n                  if (newReader == null) {\n                    oldReader.incRef();\n                    newReader = oldReader;\n                  }\n\n                  oldReader.decRef();\n\n                  synchronized(TestStressNRT.this) {\n                    // install the new reader if it's newest (and check the current version since another reader may have already been installed)\n                    //System.out.println(Thread.currentThread().getName() + \": newVersion=\" + newReader.getVersion());\n                    assert newReader.getRefCount() > 0;\n                    assert reader.getRefCount() > 0;\n                    if (newReader.getVersion() > reader.getVersion()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new reader=\" + newReader);\n                      }\n                      reader.decRef();\n                      reader = newReader;\n\n                      // Silly: forces fieldInfos to be\n                      // loaded so we don't hit IOE on later\n                      // reader.toString\n                      newReader.toString();\n\n                      // install this snapshot only if it's newer than the current one\n                      if (version >= committedModelClock) {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new model version=\" + version);\n                        }\n                        committedModel = newCommittedModel;\n                        committedModelClock = version;\n                      } else {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new model version=\" + version);\n                        }\n                      }\n                    } else {\n                      // if the same reader, don't decRef.\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new reader=\" + newReader);\n                      }\n                      newReader.decRef();\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else {\n\n                int id = rand.nextInt(ndocs);\n                Object sync = syncArr[id];\n\n                // set the lastId before we actually change it sometimes to try and\n                // uncover more race conditions between writing and reading\n                boolean before = random().nextBoolean();\n                if (before) {\n                  lastId = id;\n                }\n\n                // We can't concurrently update the same document and retain our invariants of increasing values\n                // since we can't guarantee what order the updates will be executed.\n                synchronized (sync) {\n                  Long val = model.get(id);\n                  long nextVal = Math.abs(val)+1;\n\n                  if (oper < commitPercent + deletePercent) {\n                    // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": term delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new Term(\"id\",Integer.toString(id)));\n                    model.put(id, -nextVal);\n                  } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                    //assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": query delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new TermQuery(new Term(\"id\", Integer.toString(id))));\n                    model.put(id, -nextVal);\n                  } else {\n                    // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                    Document d = new Document();\n                    d.add(newStringField(\"id\", Integer.toString(id), Field.Store.YES));\n                    d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": u id:\" + id + \" val=\" + nextVal);\n                    }\n                    writer.updateDocument(new Term(\"id\", Integer.toString(id)), d);\n                    if (tombstones) {\n                      // remove tombstone after new addition (this should be optional?)\n                      writer.deleteDocuments(new Term(\"id\",\"-\"+Integer.toString(id)));\n                    }\n                    model.put(id, nextVal);\n                  }\n                }\n\n                if (!before) {\n                  lastId = id;\n                }\n              }\n            }\n          } catch (Throwable e) {\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            IndexReader lastReader = null;\n            IndexSearcher lastSearcher = null;\n\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              long val;\n              DirectoryReader r;\n              synchronized(TestStressNRT.this) {\n                val = committedModel.get(id);\n                r = reader;\n                r.incRef();\n              }\n\n              if (VERBOSE) {\n                System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": s id=\" + id + \" val=\" + val + \" r=\" + r.getVersion());\n              }\n\n              //  sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              IndexSearcher searcher;\n              if (r == lastReader) {\n                // Just re-use lastSearcher, else\n                // newSearcher may create too many thread\n                // pools (ExecutorService):\n                searcher = lastSearcher;\n              } else {\n                searcher = newSearcher(r);\n                lastReader = r;\n                lastSearcher = searcher;\n              }\n              Query q = new TermQuery(new Term(\"id\",Integer.toString(id)));\n              TopDocs results = searcher.search(q, 10);\n\n              if (results.totalHits == 0 && tombstones) {\n                // if we couldn't find the doc, look for its tombstone\n                q = new TermQuery(new Term(\"id\",\"-\"+Integer.toString(id)));\n                results = searcher.search(q, 1);\n                if (results.totalHits == 0) {\n                  if (val == -1L) {\n                    // expected... no doc was added yet\n                    r.decRef();\n                    continue;\n                  }\n                  fail(\"No documents or tombstones found for id \" + id + \", expected at least \" + val + \" reader=\" + r);\n                }\n              }\n\n              if (results.totalHits == 0 && !tombstones) {\n                // nothing to do - we can't tell anything from a deleted doc without tombstones\n              } else {\n                // we should have found the document, or its tombstone\n                if (results.totalHits != 1) {\n                  System.out.println(\"FAIL: hits id:\" + id + \" val=\" + val);\n                  for(ScoreDoc sd : results.scoreDocs) {\n                    final Document doc = r.document(sd.doc);\n                    System.out.println(\"  docID=\" + sd.doc + \" id:\" + doc.get(\"id\") + \" foundVal=\" + doc.get(field));\n                  }\n                  fail(\"id=\" + id + \" reader=\" + r + \" totalHits=\" + results.totalHits);\n                }\n                Document doc = searcher.doc(results.scoreDocs[0].doc);\n                long foundVal = Long.parseLong(doc.get(field));\n                if (foundVal < Math.abs(val)) {\n                  fail(\"foundVal=\" + foundVal + \" val=\" + val + \" id=\" + id + \" reader=\" + r);\n                }\n              }\n\n              r.decRef();\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    writer.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: close reader=\" + reader);\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    // update variables\n    final int commitPercent = random().nextInt(20);\n    final int softCommitPercent = random().nextInt(100); // what percent of the commits are soft\n    final int deletePercent = random().nextInt(50);\n    final int deleteByQueryPercent = random().nextInt(25);\n    final int ndocs = atLeast(50);\n    final int nWriteThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    final int maxConcurrentCommits = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n    final boolean useSoftDeletes = random().nextInt(10) < 3;\n    \n    final boolean tombstones = random().nextBoolean();\n\n    // query variables\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n\n    final int nReadThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    initModel(ndocs);\n\n    final FieldType storedOnlyType = new FieldType();\n    storedOnlyType.setStored(true);\n\n    if (VERBOSE) {\n      System.out.println(\"\\n\");\n      System.out.println(\"TEST: commitPercent=\" + commitPercent);\n      System.out.println(\"TEST: softCommitPercent=\" + softCommitPercent);\n      System.out.println(\"TEST: deletePercent=\" + deletePercent);\n      System.out.println(\"TEST: deleteByQueryPercent=\" + deleteByQueryPercent);\n      System.out.println(\"TEST: ndocs=\" + ndocs);\n      System.out.println(\"TEST: nWriteThreads=\" + nWriteThreads);\n      System.out.println(\"TEST: nReadThreads=\" + nReadThreads);\n      System.out.println(\"TEST: maxConcurrentCommits=\" + maxConcurrentCommits);\n      System.out.println(\"TEST: tombstones=\" + tombstones);\n      System.out.println(\"TEST: operations=\" + operations);\n      System.out.println(\"\\n\");\n    }\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<>();\n\n    Directory dir = newMaybeVirusCheckingDirectory();\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), dir, newIndexWriterConfig(new MockAnalyzer(random())), useSoftDeletes);\n    writer.setDoRandomForceMergeAssert(false);\n    writer.commit();\n    reader = useSoftDeletes ? writer.getReader() : DirectoryReader.open(dir);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n                  DirectoryReader oldReader;\n\n                  synchronized(TestStressNRT.this) {\n                    newCommittedModel = new HashMap<>(model);  // take a snapshot\n                    version = snapshotCount++;\n                    oldReader = reader;\n                    oldReader.incRef();  // increment the reference since we will use this for reopening\n                  }\n\n                  DirectoryReader newReader;\n                  if (rand.nextInt(100) < softCommitPercent || useSoftDeletes) {\n                    // assertU(h.commit(\"softCommit\",\"true\"));\n                    if (random().nextBoolean()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": call writer.getReader\");\n                      }\n                      newReader = writer.getReader();\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": reopen reader=\" + oldReader + \" version=\" + version);\n                      }\n                      newReader = DirectoryReader.openIfChanged(oldReader, writer.w);\n                    }\n                  } else {\n                    // assertU(commit());\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": commit+reopen reader=\" + oldReader + \" version=\" + version);\n                    }\n                    writer.commit();\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": now reopen after commit\");\n                    }\n                    newReader = DirectoryReader.openIfChanged(oldReader);\n                  }\n\n                  // Code below assumes newReader comes w/\n                  // extra ref:\n                  if (newReader == null) {\n                    oldReader.incRef();\n                    newReader = oldReader;\n                  }\n\n                  oldReader.decRef();\n\n                  synchronized(TestStressNRT.this) {\n                    // install the new reader if it's newest (and check the current version since another reader may have already been installed)\n                    //System.out.println(Thread.currentThread().getName() + \": newVersion=\" + newReader.getVersion());\n                    assert newReader.getRefCount() > 0;\n                    assert reader.getRefCount() > 0;\n                    if (newReader.getVersion() > reader.getVersion()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new reader=\" + newReader);\n                      }\n                      reader.decRef();\n                      reader = newReader;\n\n                      // Silly: forces fieldInfos to be\n                      // loaded so we don't hit IOE on later\n                      // reader.toString\n                      newReader.toString();\n\n                      // install this snapshot only if it's newer than the current one\n                      if (version >= committedModelClock) {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new model version=\" + version);\n                        }\n                        committedModel = newCommittedModel;\n                        committedModelClock = version;\n                      } else {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new model version=\" + version);\n                        }\n                      }\n                    } else {\n                      // if the same reader, don't decRef.\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new reader=\" + newReader);\n                      }\n                      newReader.decRef();\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else {\n\n                int id = rand.nextInt(ndocs);\n                Object sync = syncArr[id];\n\n                // set the lastId before we actually change it sometimes to try and\n                // uncover more race conditions between writing and reading\n                boolean before = random().nextBoolean();\n                if (before) {\n                  lastId = id;\n                }\n\n                // We can't concurrently update the same document and retain our invariants of increasing values\n                // since we can't guarantee what order the updates will be executed.\n                synchronized (sync) {\n                  Long val = model.get(id);\n                  long nextVal = Math.abs(val)+1;\n\n                  if (oper < commitPercent + deletePercent) {\n                    // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": term delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new Term(\"id\",Integer.toString(id)));\n                    model.put(id, -nextVal);\n                  } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                    //assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": query delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new TermQuery(new Term(\"id\", Integer.toString(id))));\n                    model.put(id, -nextVal);\n                  } else {\n                    // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                    Document d = new Document();\n                    d.add(newStringField(\"id\", Integer.toString(id), Field.Store.YES));\n                    d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": u id:\" + id + \" val=\" + nextVal);\n                    }\n                    writer.updateDocument(new Term(\"id\", Integer.toString(id)), d);\n                    if (tombstones) {\n                      // remove tombstone after new addition (this should be optional?)\n                      writer.deleteDocuments(new Term(\"id\",\"-\"+Integer.toString(id)));\n                    }\n                    model.put(id, nextVal);\n                  }\n                }\n\n                if (!before) {\n                  lastId = id;\n                }\n              }\n            }\n          } catch (Throwable e) {\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            IndexReader lastReader = null;\n            IndexSearcher lastSearcher = null;\n\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              long val;\n              DirectoryReader r;\n              synchronized(TestStressNRT.this) {\n                val = committedModel.get(id);\n                r = reader;\n                r.incRef();\n              }\n\n              if (VERBOSE) {\n                System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": s id=\" + id + \" val=\" + val + \" r=\" + r.getVersion());\n              }\n\n              //  sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              IndexSearcher searcher;\n              if (r == lastReader) {\n                // Just re-use lastSearcher, else\n                // newSearcher may create too many thread\n                // pools (ExecutorService):\n                searcher = lastSearcher;\n              } else {\n                searcher = newSearcher(r);\n                lastReader = r;\n                lastSearcher = searcher;\n              }\n              Query q = new TermQuery(new Term(\"id\",Integer.toString(id)));\n              TopDocs results = searcher.search(q, 10);\n\n              if (results.totalHits == 0 && tombstones) {\n                // if we couldn't find the doc, look for its tombstone\n                q = new TermQuery(new Term(\"id\",\"-\"+Integer.toString(id)));\n                results = searcher.search(q, 1);\n                if (results.totalHits == 0) {\n                  if (val == -1L) {\n                    // expected... no doc was added yet\n                    r.decRef();\n                    continue;\n                  }\n                  fail(\"No documents or tombstones found for id \" + id + \", expected at least \" + val + \" reader=\" + r);\n                }\n              }\n\n              if (results.totalHits == 0 && !tombstones) {\n                // nothing to do - we can't tell anything from a deleted doc without tombstones\n              } else {\n                // we should have found the document, or its tombstone\n                if (results.totalHits != 1) {\n                  System.out.println(\"FAIL: hits id:\" + id + \" val=\" + val);\n                  for(ScoreDoc sd : results.scoreDocs) {\n                    final Document doc = r.document(sd.doc);\n                    System.out.println(\"  docID=\" + sd.doc + \" id:\" + doc.get(\"id\") + \" foundVal=\" + doc.get(field));\n                  }\n                  fail(\"id=\" + id + \" reader=\" + r + \" totalHits=\" + results.totalHits);\n                }\n                Document doc = searcher.doc(results.scoreDocs[0].doc);\n                long foundVal = Long.parseLong(doc.get(field));\n                if (foundVal < Math.abs(val)) {\n                  fail(\"foundVal=\" + foundVal + \" val=\" + val + \" id=\" + id + \" reader=\" + r);\n                }\n              }\n\n              r.decRef();\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    writer.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: close reader=\" + reader);\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d58e44159788900f4a2113b84463dc3fbbf80f20","date":1523319203,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestStressNRT#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestStressNRT#test().mjava","sourceNew":"  public void test() throws Exception {\n    // update variables\n    final int commitPercent = random().nextInt(20);\n    final int softCommitPercent = random().nextInt(100); // what percent of the commits are soft\n    final int deletePercent = random().nextInt(50);\n    final int deleteByQueryPercent = random().nextInt(25);\n    final int ndocs = atLeast(50);\n    final int nWriteThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    final int maxConcurrentCommits = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n    final boolean useSoftDeletes = random().nextInt(10) < 3;\n    \n    final boolean tombstones = random().nextBoolean();\n\n    // query variables\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n\n    final int nReadThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    initModel(ndocs);\n\n    final FieldType storedOnlyType = new FieldType();\n    storedOnlyType.setStored(true);\n\n    if (VERBOSE) {\n      System.out.println(\"\\n\");\n      System.out.println(\"TEST: commitPercent=\" + commitPercent);\n      System.out.println(\"TEST: softCommitPercent=\" + softCommitPercent);\n      System.out.println(\"TEST: deletePercent=\" + deletePercent);\n      System.out.println(\"TEST: deleteByQueryPercent=\" + deleteByQueryPercent);\n      System.out.println(\"TEST: ndocs=\" + ndocs);\n      System.out.println(\"TEST: nWriteThreads=\" + nWriteThreads);\n      System.out.println(\"TEST: nReadThreads=\" + nReadThreads);\n      System.out.println(\"TEST: maxConcurrentCommits=\" + maxConcurrentCommits);\n      System.out.println(\"TEST: tombstones=\" + tombstones);\n      System.out.println(\"TEST: operations=\" + operations);\n      System.out.println(\"\\n\");\n    }\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<>();\n\n    Directory dir = newMaybeVirusCheckingDirectory();\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), dir, newIndexWriterConfig(new MockAnalyzer(random())), useSoftDeletes);\n    writer.setDoRandomForceMergeAssert(false);\n    writer.commit();\n    if (useSoftDeletes) {\n      reader = new SoftDeletesDirectoryReaderWrapper(DirectoryReader.open(dir), writer.w.getConfig().getSoftDeletesField());\n    } else {\n      reader = DirectoryReader.open(dir);\n    }\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n                  DirectoryReader oldReader;\n\n                  synchronized(TestStressNRT.this) {\n                    newCommittedModel = new HashMap<>(model);  // take a snapshot\n                    version = snapshotCount++;\n                    oldReader = reader;\n                    oldReader.incRef();  // increment the reference since we will use this for reopening\n                  }\n\n                  DirectoryReader newReader;\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    // assertU(h.commit(\"softCommit\",\"true\"));\n                    if (random().nextBoolean()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": call writer.getReader\");\n                      }\n                      newReader = writer.getReader();\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": reopen reader=\" + oldReader + \" version=\" + version);\n                      }\n                      newReader = DirectoryReader.openIfChanged(oldReader, writer.w);\n                    }\n                  } else {\n                    // assertU(commit());\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": commit+reopen reader=\" + oldReader + \" version=\" + version);\n                    }\n                    writer.commit();\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": now reopen after commit\");\n                    }\n                    newReader = DirectoryReader.openIfChanged(oldReader);\n                  }\n\n                  // Code below assumes newReader comes w/\n                  // extra ref:\n                  if (newReader == null) {\n                    oldReader.incRef();\n                    newReader = oldReader;\n                  }\n\n                  oldReader.decRef();\n\n                  synchronized(TestStressNRT.this) {\n                    // install the new reader if it's newest (and check the current version since another reader may have already been installed)\n                    //System.out.println(Thread.currentThread().getName() + \": newVersion=\" + newReader.getVersion());\n                    assert newReader.getRefCount() > 0;\n                    assert reader.getRefCount() > 0;\n                    if (newReader.getVersion() > reader.getVersion()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new reader=\" + newReader);\n                      }\n                      reader.decRef();\n                      reader = newReader;\n\n                      // Silly: forces fieldInfos to be\n                      // loaded so we don't hit IOE on later\n                      // reader.toString\n                      newReader.toString();\n\n                      // install this snapshot only if it's newer than the current one\n                      if (version >= committedModelClock) {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new model version=\" + version);\n                        }\n                        committedModel = newCommittedModel;\n                        committedModelClock = version;\n                      } else {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new model version=\" + version);\n                        }\n                      }\n                    } else {\n                      // if the same reader, don't decRef.\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new reader=\" + newReader);\n                      }\n                      newReader.decRef();\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else {\n\n                int id = rand.nextInt(ndocs);\n                Object sync = syncArr[id];\n\n                // set the lastId before we actually change it sometimes to try and\n                // uncover more race conditions between writing and reading\n                boolean before = random().nextBoolean();\n                if (before) {\n                  lastId = id;\n                }\n\n                // We can't concurrently update the same document and retain our invariants of increasing values\n                // since we can't guarantee what order the updates will be executed.\n                synchronized (sync) {\n                  Long val = model.get(id);\n                  long nextVal = Math.abs(val)+1;\n\n                  if (oper < commitPercent + deletePercent) {\n                    // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": term delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new Term(\"id\",Integer.toString(id)));\n                    model.put(id, -nextVal);\n                  } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                    //assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": query delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new TermQuery(new Term(\"id\", Integer.toString(id))));\n                    model.put(id, -nextVal);\n                  } else {\n                    // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                    Document d = new Document();\n                    d.add(newStringField(\"id\", Integer.toString(id), Field.Store.YES));\n                    d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": u id:\" + id + \" val=\" + nextVal);\n                    }\n                    writer.updateDocument(new Term(\"id\", Integer.toString(id)), d);\n                    if (tombstones) {\n                      // remove tombstone after new addition (this should be optional?)\n                      writer.deleteDocuments(new Term(\"id\",\"-\"+Integer.toString(id)));\n                    }\n                    model.put(id, nextVal);\n                  }\n                }\n\n                if (!before) {\n                  lastId = id;\n                }\n              }\n            }\n          } catch (Throwable e) {\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            IndexReader lastReader = null;\n            IndexSearcher lastSearcher = null;\n\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              long val;\n              DirectoryReader r;\n              synchronized(TestStressNRT.this) {\n                val = committedModel.get(id);\n                r = reader;\n                r.incRef();\n              }\n\n              if (VERBOSE) {\n                System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": s id=\" + id + \" val=\" + val + \" r=\" + r.getVersion());\n              }\n\n              //  sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              IndexSearcher searcher;\n              if (r == lastReader) {\n                // Just re-use lastSearcher, else\n                // newSearcher may create too many thread\n                // pools (ExecutorService):\n                searcher = lastSearcher;\n              } else {\n                searcher = newSearcher(r);\n                lastReader = r;\n                lastSearcher = searcher;\n              }\n              Query q = new TermQuery(new Term(\"id\",Integer.toString(id)));\n              TopDocs results = searcher.search(q, 10);\n\n              if (results.totalHits == 0 && tombstones) {\n                // if we couldn't find the doc, look for its tombstone\n                q = new TermQuery(new Term(\"id\",\"-\"+Integer.toString(id)));\n                results = searcher.search(q, 1);\n                if (results.totalHits == 0) {\n                  if (val == -1L) {\n                    // expected... no doc was added yet\n                    r.decRef();\n                    continue;\n                  }\n                  fail(\"No documents or tombstones found for id \" + id + \", expected at least \" + val + \" reader=\" + r);\n                }\n              }\n\n              if (results.totalHits == 0 && !tombstones) {\n                // nothing to do - we can't tell anything from a deleted doc without tombstones\n              } else {\n                // we should have found the document, or its tombstone\n                if (results.totalHits != 1) {\n                  System.out.println(\"FAIL: hits id:\" + id + \" val=\" + val);\n                  for(ScoreDoc sd : results.scoreDocs) {\n                    final Document doc = r.document(sd.doc);\n                    System.out.println(\"  docID=\" + sd.doc + \" id:\" + doc.get(\"id\") + \" foundVal=\" + doc.get(field));\n                  }\n                  fail(\"id=\" + id + \" reader=\" + r + \" totalHits=\" + results.totalHits);\n                }\n                Document doc = searcher.doc(results.scoreDocs[0].doc);\n                long foundVal = Long.parseLong(doc.get(field));\n                if (foundVal < Math.abs(val)) {\n                  fail(\"foundVal=\" + foundVal + \" val=\" + val + \" id=\" + id + \" reader=\" + r);\n                }\n              }\n\n              r.decRef();\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    writer.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: close reader=\" + reader);\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    // update variables\n    final int commitPercent = random().nextInt(20);\n    final int softCommitPercent = random().nextInt(100); // what percent of the commits are soft\n    final int deletePercent = random().nextInt(50);\n    final int deleteByQueryPercent = random().nextInt(25);\n    final int ndocs = atLeast(50);\n    final int nWriteThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    final int maxConcurrentCommits = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n    final boolean useSoftDeletes = random().nextInt(10) < 3;\n    \n    final boolean tombstones = random().nextBoolean();\n\n    // query variables\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n\n    final int nReadThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    initModel(ndocs);\n\n    final FieldType storedOnlyType = new FieldType();\n    storedOnlyType.setStored(true);\n\n    if (VERBOSE) {\n      System.out.println(\"\\n\");\n      System.out.println(\"TEST: commitPercent=\" + commitPercent);\n      System.out.println(\"TEST: softCommitPercent=\" + softCommitPercent);\n      System.out.println(\"TEST: deletePercent=\" + deletePercent);\n      System.out.println(\"TEST: deleteByQueryPercent=\" + deleteByQueryPercent);\n      System.out.println(\"TEST: ndocs=\" + ndocs);\n      System.out.println(\"TEST: nWriteThreads=\" + nWriteThreads);\n      System.out.println(\"TEST: nReadThreads=\" + nReadThreads);\n      System.out.println(\"TEST: maxConcurrentCommits=\" + maxConcurrentCommits);\n      System.out.println(\"TEST: tombstones=\" + tombstones);\n      System.out.println(\"TEST: operations=\" + operations);\n      System.out.println(\"\\n\");\n    }\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<>();\n\n    Directory dir = newMaybeVirusCheckingDirectory();\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), dir, newIndexWriterConfig(new MockAnalyzer(random())), useSoftDeletes);\n    writer.setDoRandomForceMergeAssert(false);\n    writer.commit();\n    reader = useSoftDeletes ? writer.getReader() : DirectoryReader.open(dir);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n                  DirectoryReader oldReader;\n\n                  synchronized(TestStressNRT.this) {\n                    newCommittedModel = new HashMap<>(model);  // take a snapshot\n                    version = snapshotCount++;\n                    oldReader = reader;\n                    oldReader.incRef();  // increment the reference since we will use this for reopening\n                  }\n\n                  DirectoryReader newReader;\n                  if (rand.nextInt(100) < softCommitPercent || useSoftDeletes) {\n                    // assertU(h.commit(\"softCommit\",\"true\"));\n                    if (random().nextBoolean()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": call writer.getReader\");\n                      }\n                      newReader = writer.getReader();\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": reopen reader=\" + oldReader + \" version=\" + version);\n                      }\n                      newReader = DirectoryReader.openIfChanged(oldReader, writer.w);\n                    }\n                  } else {\n                    // assertU(commit());\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": commit+reopen reader=\" + oldReader + \" version=\" + version);\n                    }\n                    writer.commit();\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": now reopen after commit\");\n                    }\n                    newReader = DirectoryReader.openIfChanged(oldReader);\n                  }\n\n                  // Code below assumes newReader comes w/\n                  // extra ref:\n                  if (newReader == null) {\n                    oldReader.incRef();\n                    newReader = oldReader;\n                  }\n\n                  oldReader.decRef();\n\n                  synchronized(TestStressNRT.this) {\n                    // install the new reader if it's newest (and check the current version since another reader may have already been installed)\n                    //System.out.println(Thread.currentThread().getName() + \": newVersion=\" + newReader.getVersion());\n                    assert newReader.getRefCount() > 0;\n                    assert reader.getRefCount() > 0;\n                    if (newReader.getVersion() > reader.getVersion()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new reader=\" + newReader);\n                      }\n                      reader.decRef();\n                      reader = newReader;\n\n                      // Silly: forces fieldInfos to be\n                      // loaded so we don't hit IOE on later\n                      // reader.toString\n                      newReader.toString();\n\n                      // install this snapshot only if it's newer than the current one\n                      if (version >= committedModelClock) {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new model version=\" + version);\n                        }\n                        committedModel = newCommittedModel;\n                        committedModelClock = version;\n                      } else {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new model version=\" + version);\n                        }\n                      }\n                    } else {\n                      // if the same reader, don't decRef.\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new reader=\" + newReader);\n                      }\n                      newReader.decRef();\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else {\n\n                int id = rand.nextInt(ndocs);\n                Object sync = syncArr[id];\n\n                // set the lastId before we actually change it sometimes to try and\n                // uncover more race conditions between writing and reading\n                boolean before = random().nextBoolean();\n                if (before) {\n                  lastId = id;\n                }\n\n                // We can't concurrently update the same document and retain our invariants of increasing values\n                // since we can't guarantee what order the updates will be executed.\n                synchronized (sync) {\n                  Long val = model.get(id);\n                  long nextVal = Math.abs(val)+1;\n\n                  if (oper < commitPercent + deletePercent) {\n                    // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": term delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new Term(\"id\",Integer.toString(id)));\n                    model.put(id, -nextVal);\n                  } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                    //assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": query delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new TermQuery(new Term(\"id\", Integer.toString(id))));\n                    model.put(id, -nextVal);\n                  } else {\n                    // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                    Document d = new Document();\n                    d.add(newStringField(\"id\", Integer.toString(id), Field.Store.YES));\n                    d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": u id:\" + id + \" val=\" + nextVal);\n                    }\n                    writer.updateDocument(new Term(\"id\", Integer.toString(id)), d);\n                    if (tombstones) {\n                      // remove tombstone after new addition (this should be optional?)\n                      writer.deleteDocuments(new Term(\"id\",\"-\"+Integer.toString(id)));\n                    }\n                    model.put(id, nextVal);\n                  }\n                }\n\n                if (!before) {\n                  lastId = id;\n                }\n              }\n            }\n          } catch (Throwable e) {\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            IndexReader lastReader = null;\n            IndexSearcher lastSearcher = null;\n\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              long val;\n              DirectoryReader r;\n              synchronized(TestStressNRT.this) {\n                val = committedModel.get(id);\n                r = reader;\n                r.incRef();\n              }\n\n              if (VERBOSE) {\n                System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": s id=\" + id + \" val=\" + val + \" r=\" + r.getVersion());\n              }\n\n              //  sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              IndexSearcher searcher;\n              if (r == lastReader) {\n                // Just re-use lastSearcher, else\n                // newSearcher may create too many thread\n                // pools (ExecutorService):\n                searcher = lastSearcher;\n              } else {\n                searcher = newSearcher(r);\n                lastReader = r;\n                lastSearcher = searcher;\n              }\n              Query q = new TermQuery(new Term(\"id\",Integer.toString(id)));\n              TopDocs results = searcher.search(q, 10);\n\n              if (results.totalHits == 0 && tombstones) {\n                // if we couldn't find the doc, look for its tombstone\n                q = new TermQuery(new Term(\"id\",\"-\"+Integer.toString(id)));\n                results = searcher.search(q, 1);\n                if (results.totalHits == 0) {\n                  if (val == -1L) {\n                    // expected... no doc was added yet\n                    r.decRef();\n                    continue;\n                  }\n                  fail(\"No documents or tombstones found for id \" + id + \", expected at least \" + val + \" reader=\" + r);\n                }\n              }\n\n              if (results.totalHits == 0 && !tombstones) {\n                // nothing to do - we can't tell anything from a deleted doc without tombstones\n              } else {\n                // we should have found the document, or its tombstone\n                if (results.totalHits != 1) {\n                  System.out.println(\"FAIL: hits id:\" + id + \" val=\" + val);\n                  for(ScoreDoc sd : results.scoreDocs) {\n                    final Document doc = r.document(sd.doc);\n                    System.out.println(\"  docID=\" + sd.doc + \" id:\" + doc.get(\"id\") + \" foundVal=\" + doc.get(field));\n                  }\n                  fail(\"id=\" + id + \" reader=\" + r + \" totalHits=\" + results.totalHits);\n                }\n                Document doc = searcher.doc(results.scoreDocs[0].doc);\n                long foundVal = Long.parseLong(doc.get(field));\n                if (foundVal < Math.abs(val)) {\n                  fail(\"foundVal=\" + foundVal + \" val=\" + val + \" id=\" + id + \" reader=\" + r);\n                }\n              }\n\n              r.decRef();\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    writer.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: close reader=\" + reader);\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"83788ad129a5154d5c6562c4e8ce3db48793aada","date":1532961485,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestStressNRT#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestStressNRT#test().mjava","sourceNew":"  public void test() throws Exception {\n    // update variables\n    final int commitPercent = random().nextInt(20);\n    final int softCommitPercent = random().nextInt(100); // what percent of the commits are soft\n    final int deletePercent = random().nextInt(50);\n    final int deleteByQueryPercent = random().nextInt(25);\n    final int ndocs = atLeast(50);\n    final int nWriteThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    final int maxConcurrentCommits = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n    final boolean useSoftDeletes = random().nextInt(10) < 3;\n    \n    final boolean tombstones = random().nextBoolean();\n\n    // query variables\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n\n    final int nReadThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    initModel(ndocs);\n\n    final FieldType storedOnlyType = new FieldType();\n    storedOnlyType.setStored(true);\n\n    if (VERBOSE) {\n      System.out.println(\"\\n\");\n      System.out.println(\"TEST: commitPercent=\" + commitPercent);\n      System.out.println(\"TEST: softCommitPercent=\" + softCommitPercent);\n      System.out.println(\"TEST: deletePercent=\" + deletePercent);\n      System.out.println(\"TEST: deleteByQueryPercent=\" + deleteByQueryPercent);\n      System.out.println(\"TEST: ndocs=\" + ndocs);\n      System.out.println(\"TEST: nWriteThreads=\" + nWriteThreads);\n      System.out.println(\"TEST: nReadThreads=\" + nReadThreads);\n      System.out.println(\"TEST: maxConcurrentCommits=\" + maxConcurrentCommits);\n      System.out.println(\"TEST: tombstones=\" + tombstones);\n      System.out.println(\"TEST: operations=\" + operations);\n      System.out.println(\"\\n\");\n    }\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<>();\n\n    Directory dir = newMaybeVirusCheckingDirectory();\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), dir, newIndexWriterConfig(new MockAnalyzer(random())), useSoftDeletes);\n    writer.setDoRandomForceMergeAssert(false);\n    writer.commit();\n    if (useSoftDeletes) {\n      reader = new SoftDeletesDirectoryReaderWrapper(DirectoryReader.open(dir), writer.w.getConfig().getSoftDeletesField());\n    } else {\n      reader = DirectoryReader.open(dir);\n    }\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n                  DirectoryReader oldReader;\n\n                  synchronized(TestStressNRT.this) {\n                    newCommittedModel = new HashMap<>(model);  // take a snapshot\n                    version = snapshotCount++;\n                    oldReader = reader;\n                    oldReader.incRef();  // increment the reference since we will use this for reopening\n                  }\n\n                  DirectoryReader newReader;\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    // assertU(h.commit(\"softCommit\",\"true\"));\n                    if (random().nextBoolean()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": call writer.getReader\");\n                      }\n                      newReader = writer.getReader();\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": reopen reader=\" + oldReader + \" version=\" + version);\n                      }\n                      newReader = DirectoryReader.openIfChanged(oldReader, writer.w);\n                    }\n                  } else {\n                    // assertU(commit());\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": commit+reopen reader=\" + oldReader + \" version=\" + version);\n                    }\n                    writer.commit();\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": now reopen after commit\");\n                    }\n                    newReader = DirectoryReader.openIfChanged(oldReader);\n                  }\n\n                  // Code below assumes newReader comes w/\n                  // extra ref:\n                  if (newReader == null) {\n                    oldReader.incRef();\n                    newReader = oldReader;\n                  }\n\n                  oldReader.decRef();\n\n                  synchronized(TestStressNRT.this) {\n                    // install the new reader if it's newest (and check the current version since another reader may have already been installed)\n                    //System.out.println(Thread.currentThread().getName() + \": newVersion=\" + newReader.getVersion());\n                    assert newReader.getRefCount() > 0;\n                    assert reader.getRefCount() > 0;\n                    if (newReader.getVersion() > reader.getVersion()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new reader=\" + newReader);\n                      }\n                      reader.decRef();\n                      reader = newReader;\n\n                      // Silly: forces fieldInfos to be\n                      // loaded so we don't hit IOE on later\n                      // reader.toString\n                      newReader.toString();\n\n                      // install this snapshot only if it's newer than the current one\n                      if (version >= committedModelClock) {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new model version=\" + version);\n                        }\n                        committedModel = newCommittedModel;\n                        committedModelClock = version;\n                      } else {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new model version=\" + version);\n                        }\n                      }\n                    } else {\n                      // if the same reader, don't decRef.\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new reader=\" + newReader);\n                      }\n                      newReader.decRef();\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else {\n\n                int id = rand.nextInt(ndocs);\n                Object sync = syncArr[id];\n\n                // set the lastId before we actually change it sometimes to try and\n                // uncover more race conditions between writing and reading\n                boolean before = random().nextBoolean();\n                if (before) {\n                  lastId = id;\n                }\n\n                // We can't concurrently update the same document and retain our invariants of increasing values\n                // since we can't guarantee what order the updates will be executed.\n                synchronized (sync) {\n                  Long val = model.get(id);\n                  long nextVal = Math.abs(val)+1;\n\n                  if (oper < commitPercent + deletePercent) {\n                    // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": term delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new Term(\"id\",Integer.toString(id)));\n                    model.put(id, -nextVal);\n                  } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                    //assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": query delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new TermQuery(new Term(\"id\", Integer.toString(id))));\n                    model.put(id, -nextVal);\n                  } else {\n                    // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                    Document d = new Document();\n                    d.add(newStringField(\"id\", Integer.toString(id), Field.Store.YES));\n                    d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": u id:\" + id + \" val=\" + nextVal);\n                    }\n                    writer.updateDocument(new Term(\"id\", Integer.toString(id)), d);\n                    if (tombstones) {\n                      // remove tombstone after new addition (this should be optional?)\n                      writer.deleteDocuments(new Term(\"id\",\"-\"+Integer.toString(id)));\n                    }\n                    model.put(id, nextVal);\n                  }\n                }\n\n                if (!before) {\n                  lastId = id;\n                }\n              }\n            }\n          } catch (Throwable e) {\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            IndexReader lastReader = null;\n            IndexSearcher lastSearcher = null;\n\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              long val;\n              DirectoryReader r;\n              synchronized(TestStressNRT.this) {\n                val = committedModel.get(id);\n                r = reader;\n                r.incRef();\n              }\n\n              if (VERBOSE) {\n                System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": s id=\" + id + \" val=\" + val + \" r=\" + r.getVersion());\n              }\n\n              //  sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              IndexSearcher searcher;\n              if (r == lastReader) {\n                // Just re-use lastSearcher, else\n                // newSearcher may create too many thread\n                // pools (ExecutorService):\n                searcher = lastSearcher;\n              } else {\n                searcher = newSearcher(r);\n                lastReader = r;\n                lastSearcher = searcher;\n              }\n              Query q = new TermQuery(new Term(\"id\",Integer.toString(id)));\n              TopDocs results = searcher.search(q, 10);\n\n              if (results.totalHits.value == 0 && tombstones) {\n                // if we couldn't find the doc, look for its tombstone\n                q = new TermQuery(new Term(\"id\",\"-\"+Integer.toString(id)));\n                results = searcher.search(q, 1);\n                if (results.totalHits.value == 0) {\n                  if (val == -1L) {\n                    // expected... no doc was added yet\n                    r.decRef();\n                    continue;\n                  }\n                  fail(\"No documents or tombstones found for id \" + id + \", expected at least \" + val + \" reader=\" + r);\n                }\n              }\n\n              if (results.totalHits.value == 0 && !tombstones) {\n                // nothing to do - we can't tell anything from a deleted doc without tombstones\n              } else {\n                // we should have found the document, or its tombstone\n                if (results.totalHits.value != 1) {\n                  System.out.println(\"FAIL: hits id:\" + id + \" val=\" + val);\n                  for(ScoreDoc sd : results.scoreDocs) {\n                    final Document doc = r.document(sd.doc);\n                    System.out.println(\"  docID=\" + sd.doc + \" id:\" + doc.get(\"id\") + \" foundVal=\" + doc.get(field));\n                  }\n                  fail(\"id=\" + id + \" reader=\" + r + \" totalHits=\" + results.totalHits.value);\n                }\n                Document doc = searcher.doc(results.scoreDocs[0].doc);\n                long foundVal = Long.parseLong(doc.get(field));\n                if (foundVal < Math.abs(val)) {\n                  fail(\"foundVal=\" + foundVal + \" val=\" + val + \" id=\" + id + \" reader=\" + r);\n                }\n              }\n\n              r.decRef();\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    writer.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: close reader=\" + reader);\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    // update variables\n    final int commitPercent = random().nextInt(20);\n    final int softCommitPercent = random().nextInt(100); // what percent of the commits are soft\n    final int deletePercent = random().nextInt(50);\n    final int deleteByQueryPercent = random().nextInt(25);\n    final int ndocs = atLeast(50);\n    final int nWriteThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    final int maxConcurrentCommits = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n    final boolean useSoftDeletes = random().nextInt(10) < 3;\n    \n    final boolean tombstones = random().nextBoolean();\n\n    // query variables\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n\n    final int nReadThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);\n    initModel(ndocs);\n\n    final FieldType storedOnlyType = new FieldType();\n    storedOnlyType.setStored(true);\n\n    if (VERBOSE) {\n      System.out.println(\"\\n\");\n      System.out.println(\"TEST: commitPercent=\" + commitPercent);\n      System.out.println(\"TEST: softCommitPercent=\" + softCommitPercent);\n      System.out.println(\"TEST: deletePercent=\" + deletePercent);\n      System.out.println(\"TEST: deleteByQueryPercent=\" + deleteByQueryPercent);\n      System.out.println(\"TEST: ndocs=\" + ndocs);\n      System.out.println(\"TEST: nWriteThreads=\" + nWriteThreads);\n      System.out.println(\"TEST: nReadThreads=\" + nReadThreads);\n      System.out.println(\"TEST: maxConcurrentCommits=\" + maxConcurrentCommits);\n      System.out.println(\"TEST: tombstones=\" + tombstones);\n      System.out.println(\"TEST: operations=\" + operations);\n      System.out.println(\"\\n\");\n    }\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<>();\n\n    Directory dir = newMaybeVirusCheckingDirectory();\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), dir, newIndexWriterConfig(new MockAnalyzer(random())), useSoftDeletes);\n    writer.setDoRandomForceMergeAssert(false);\n    writer.commit();\n    if (useSoftDeletes) {\n      reader = new SoftDeletesDirectoryReaderWrapper(DirectoryReader.open(dir), writer.w.getConfig().getSoftDeletesField());\n    } else {\n      reader = DirectoryReader.open(dir);\n    }\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n                  DirectoryReader oldReader;\n\n                  synchronized(TestStressNRT.this) {\n                    newCommittedModel = new HashMap<>(model);  // take a snapshot\n                    version = snapshotCount++;\n                    oldReader = reader;\n                    oldReader.incRef();  // increment the reference since we will use this for reopening\n                  }\n\n                  DirectoryReader newReader;\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    // assertU(h.commit(\"softCommit\",\"true\"));\n                    if (random().nextBoolean()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": call writer.getReader\");\n                      }\n                      newReader = writer.getReader();\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": reopen reader=\" + oldReader + \" version=\" + version);\n                      }\n                      newReader = DirectoryReader.openIfChanged(oldReader, writer.w);\n                    }\n                  } else {\n                    // assertU(commit());\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": commit+reopen reader=\" + oldReader + \" version=\" + version);\n                    }\n                    writer.commit();\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": now reopen after commit\");\n                    }\n                    newReader = DirectoryReader.openIfChanged(oldReader);\n                  }\n\n                  // Code below assumes newReader comes w/\n                  // extra ref:\n                  if (newReader == null) {\n                    oldReader.incRef();\n                    newReader = oldReader;\n                  }\n\n                  oldReader.decRef();\n\n                  synchronized(TestStressNRT.this) {\n                    // install the new reader if it's newest (and check the current version since another reader may have already been installed)\n                    //System.out.println(Thread.currentThread().getName() + \": newVersion=\" + newReader.getVersion());\n                    assert newReader.getRefCount() > 0;\n                    assert reader.getRefCount() > 0;\n                    if (newReader.getVersion() > reader.getVersion()) {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new reader=\" + newReader);\n                      }\n                      reader.decRef();\n                      reader = newReader;\n\n                      // Silly: forces fieldInfos to be\n                      // loaded so we don't hit IOE on later\n                      // reader.toString\n                      newReader.toString();\n\n                      // install this snapshot only if it's newer than the current one\n                      if (version >= committedModelClock) {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": install new model version=\" + version);\n                        }\n                        committedModel = newCommittedModel;\n                        committedModelClock = version;\n                      } else {\n                        if (VERBOSE) {\n                          System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new model version=\" + version);\n                        }\n                      }\n                    } else {\n                      // if the same reader, don't decRef.\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": skip install new reader=\" + newReader);\n                      }\n                      newReader.decRef();\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else {\n\n                int id = rand.nextInt(ndocs);\n                Object sync = syncArr[id];\n\n                // set the lastId before we actually change it sometimes to try and\n                // uncover more race conditions between writing and reading\n                boolean before = random().nextBoolean();\n                if (before) {\n                  lastId = id;\n                }\n\n                // We can't concurrently update the same document and retain our invariants of increasing values\n                // since we can't guarantee what order the updates will be executed.\n                synchronized (sync) {\n                  Long val = model.get(id);\n                  long nextVal = Math.abs(val)+1;\n\n                  if (oper < commitPercent + deletePercent) {\n                    // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": term delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new Term(\"id\",Integer.toString(id)));\n                    model.put(id, -nextVal);\n                  } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                    //assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n\n                    // add tombstone first\n                    if (tombstones) {\n                      Document d = new Document();\n                      d.add(newStringField(\"id\", \"-\"+Integer.toString(id), Field.Store.YES));\n                      d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                      writer.updateDocument(new Term(\"id\", \"-\"+Integer.toString(id)), d);\n                    }\n\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": query delDocs id:\" + id + \" nextVal=\" + nextVal);\n                    }\n                    writer.deleteDocuments(new TermQuery(new Term(\"id\", Integer.toString(id))));\n                    model.put(id, -nextVal);\n                  } else {\n                    // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                    Document d = new Document();\n                    d.add(newStringField(\"id\", Integer.toString(id), Field.Store.YES));\n                    d.add(newField(field, Long.toString(nextVal), storedOnlyType));\n                    if (VERBOSE) {\n                      System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": u id:\" + id + \" val=\" + nextVal);\n                    }\n                    writer.updateDocument(new Term(\"id\", Integer.toString(id)), d);\n                    if (tombstones) {\n                      // remove tombstone after new addition (this should be optional?)\n                      writer.deleteDocuments(new Term(\"id\",\"-\"+Integer.toString(id)));\n                    }\n                    model.put(id, nextVal);\n                  }\n                }\n\n                if (!before) {\n                  lastId = id;\n                }\n              }\n            }\n          } catch (Throwable e) {\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            IndexReader lastReader = null;\n            IndexSearcher lastSearcher = null;\n\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              long val;\n              DirectoryReader r;\n              synchronized(TestStressNRT.this) {\n                val = committedModel.get(id);\n                r = reader;\n                r.incRef();\n              }\n\n              if (VERBOSE) {\n                System.out.println(\"TEST: \" + Thread.currentThread().getName() + \": s id=\" + id + \" val=\" + val + \" r=\" + r.getVersion());\n              }\n\n              //  sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              IndexSearcher searcher;\n              if (r == lastReader) {\n                // Just re-use lastSearcher, else\n                // newSearcher may create too many thread\n                // pools (ExecutorService):\n                searcher = lastSearcher;\n              } else {\n                searcher = newSearcher(r);\n                lastReader = r;\n                lastSearcher = searcher;\n              }\n              Query q = new TermQuery(new Term(\"id\",Integer.toString(id)));\n              TopDocs results = searcher.search(q, 10);\n\n              if (results.totalHits == 0 && tombstones) {\n                // if we couldn't find the doc, look for its tombstone\n                q = new TermQuery(new Term(\"id\",\"-\"+Integer.toString(id)));\n                results = searcher.search(q, 1);\n                if (results.totalHits == 0) {\n                  if (val == -1L) {\n                    // expected... no doc was added yet\n                    r.decRef();\n                    continue;\n                  }\n                  fail(\"No documents or tombstones found for id \" + id + \", expected at least \" + val + \" reader=\" + r);\n                }\n              }\n\n              if (results.totalHits == 0 && !tombstones) {\n                // nothing to do - we can't tell anything from a deleted doc without tombstones\n              } else {\n                // we should have found the document, or its tombstone\n                if (results.totalHits != 1) {\n                  System.out.println(\"FAIL: hits id:\" + id + \" val=\" + val);\n                  for(ScoreDoc sd : results.scoreDocs) {\n                    final Document doc = r.document(sd.doc);\n                    System.out.println(\"  docID=\" + sd.doc + \" id:\" + doc.get(\"id\") + \" foundVal=\" + doc.get(field));\n                  }\n                  fail(\"id=\" + id + \" reader=\" + r + \" totalHits=\" + results.totalHits);\n                }\n                Document doc = searcher.doc(results.scoreDocs[0].doc);\n                long foundVal = Long.parseLong(doc.get(field));\n                if (foundVal < Math.abs(val)) {\n                  fail(\"foundVal=\" + foundVal + \" val=\" + val + \" id=\" + id + \" reader=\" + r);\n                }\n              }\n\n              r.decRef();\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            System.out.println(Thread.currentThread().getName() + \": FAILED: unexpected exception\");\n            e.printStackTrace(System.out);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    writer.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: close reader=\" + reader);\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"8f0e28f2a7f0f3f0fca1a2ffedaa10c7ac9536c4":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"5a207d19eac354d649c3f0e2cce070017c78125e":["7b516a692d03225c8f0e81a13ceed2dc32bb457d","b470f36a9372c97283360b1304eacbde22df6c0d"],"3b0e8c39ca08b5a02de6edcd33d6f3b90b865173":["1d028314cced5858683a1bb4741423d0f934257b"],"04f07771a2a7dd3a395700665ed839c3dae2def2":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f"],"d58e44159788900f4a2113b84463dc3fbbf80f20":["5ee0394b8176abd7c90a4be8c05465be1879db79","cb0130363fa13c53e4e78317c35b3b45a3089276"],"1d028314cced5858683a1bb4741423d0f934257b":["04f07771a2a7dd3a395700665ed839c3dae2def2","8f0e28f2a7f0f3f0fca1a2ffedaa10c7ac9536c4"],"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"83788ad129a5154d5c6562c4e8ce3db48793aada":["d58e44159788900f4a2113b84463dc3fbbf80f20"],"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["6613659748fe4411a7dcf85266e55db1f95f7315"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"6613659748fe4411a7dcf85266e55db1f95f7315":["8381e40f04c08698784f68f818258dc998398888"],"5ee0394b8176abd7c90a4be8c05465be1879db79":["5a207d19eac354d649c3f0e2cce070017c78125e"],"1e6acbaae7af722f17204ceccf0f7db5753eccf3":["7b516a692d03225c8f0e81a13ceed2dc32bb457d","b470f36a9372c97283360b1304eacbde22df6c0d"],"7b516a692d03225c8f0e81a13ceed2dc32bb457d":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c"],"1e6105d385afcbf42689e171e9bcea48d0c9ff6c":["7b516a692d03225c8f0e81a13ceed2dc32bb457d"],"b470f36a9372c97283360b1304eacbde22df6c0d":["7b516a692d03225c8f0e81a13ceed2dc32bb457d","1e6105d385afcbf42689e171e9bcea48d0c9ff6c"],"cb0130363fa13c53e4e78317c35b3b45a3089276":["5ee0394b8176abd7c90a4be8c05465be1879db79"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"8381e40f04c08698784f68f818258dc998398888":["3b0e8c39ca08b5a02de6edcd33d6f3b90b865173"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["83788ad129a5154d5c6562c4e8ce3db48793aada"]},"commit2Childs":{"8f0e28f2a7f0f3f0fca1a2ffedaa10c7ac9536c4":["1d028314cced5858683a1bb4741423d0f934257b"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"5a207d19eac354d649c3f0e2cce070017c78125e":["5ee0394b8176abd7c90a4be8c05465be1879db79"],"3b0e8c39ca08b5a02de6edcd33d6f3b90b865173":["8381e40f04c08698784f68f818258dc998398888"],"04f07771a2a7dd3a395700665ed839c3dae2def2":["8f0e28f2a7f0f3f0fca1a2ffedaa10c7ac9536c4","1d028314cced5858683a1bb4741423d0f934257b"],"d58e44159788900f4a2113b84463dc3fbbf80f20":["83788ad129a5154d5c6562c4e8ce3db48793aada"],"1d028314cced5858683a1bb4741423d0f934257b":["3b0e8c39ca08b5a02de6edcd33d6f3b90b865173"],"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"83788ad129a5154d5c6562c4e8ce3db48793aada":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c":["7b516a692d03225c8f0e81a13ceed2dc32bb457d"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"6613659748fe4411a7dcf85266e55db1f95f7315":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"5ee0394b8176abd7c90a4be8c05465be1879db79":["d58e44159788900f4a2113b84463dc3fbbf80f20","cb0130363fa13c53e4e78317c35b3b45a3089276"],"1e6acbaae7af722f17204ceccf0f7db5753eccf3":[],"7b516a692d03225c8f0e81a13ceed2dc32bb457d":["5a207d19eac354d649c3f0e2cce070017c78125e","1e6acbaae7af722f17204ceccf0f7db5753eccf3","1e6105d385afcbf42689e171e9bcea48d0c9ff6c","b470f36a9372c97283360b1304eacbde22df6c0d"],"1e6105d385afcbf42689e171e9bcea48d0c9ff6c":["b470f36a9372c97283360b1304eacbde22df6c0d"],"b470f36a9372c97283360b1304eacbde22df6c0d":["5a207d19eac354d649c3f0e2cce070017c78125e","1e6acbaae7af722f17204ceccf0f7db5753eccf3"],"cb0130363fa13c53e4e78317c35b3b45a3089276":["d58e44159788900f4a2113b84463dc3fbbf80f20"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f"],"8381e40f04c08698784f68f818258dc998398888":["6613659748fe4411a7dcf85266e55db1f95f7315"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["1e6acbaae7af722f17204ceccf0f7db5753eccf3","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}