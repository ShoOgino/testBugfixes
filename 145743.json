{"path":"lucene/src/java/org/apache/lucene/index/LogMergePolicy#findMergesForOptimize(SegmentInfos,int,Set[SegmentInfo]).mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/LogMergePolicy#findMergesForOptimize(SegmentInfos,int,Set[SegmentInfo]).mjava","pathOld":"src/java/org/apache/lucene/index/LogMergePolicy#findMergesForOptimize(SegmentInfos,int,Set[SegmentInfo]).mjava","sourceNew":"  /** Returns the merges necessary to optimize the index.\n   *  This merge policy defines \"optimized\" to mean only one\n   *  segment in the index, where that segment has no\n   *  deletions pending nor separate norms, and it is in\n   *  compound file format if the current useCompoundFile\n   *  setting is true.  This method returns multiple merges\n   *  (mergeFactor at a time) so the {@link MergeScheduler}\n   *  in use may make use of concurrency. */\n  @Override\n  public MergeSpecification findMergesForOptimize(SegmentInfos infos,\n      int maxNumSegments, Set<SegmentInfo> segmentsToOptimize) throws IOException {\n    MergeSpecification spec;\n\n    assert maxNumSegments > 0;\n\n    if (!isOptimized(infos, maxNumSegments, segmentsToOptimize)) {\n\n      // Find the newest (rightmost) segment that needs to\n      // be optimized (other segments may have been flushed\n      // since optimize started):\n      int last = infos.size();\n      while(last > 0) {\n        final SegmentInfo info = infos.info(--last);\n        if (segmentsToOptimize.contains(info)) {\n          last++;\n          break;\n        }\n      }\n\n      if (last > 0) {\n\n        spec = new MergeSpecification();\n\n        // First, enroll all \"full\" merges (size\n        // mergeFactor) to potentially be run concurrently:\n        while (last - maxNumSegments + 1 >= mergeFactor) {\n          spec.add(new OneMerge(infos.range(last-mergeFactor, last), useCompoundFile));\n          last -= mergeFactor;\n        }\n\n        // Only if there are no full merges pending do we\n        // add a final partial (< mergeFactor segments) merge:\n        if (0 == spec.merges.size()) {\n          if (maxNumSegments == 1) {\n\n            // Since we must optimize down to 1 segment, the\n            // choice is simple:\n            if (last > 1 || !isOptimized(infos.info(0)))\n              spec.add(new OneMerge(infos.range(0, last), useCompoundFile));\n          } else if (last > maxNumSegments) {\n\n            // Take care to pick a partial merge that is\n            // least cost, but does not make the index too\n            // lopsided.  If we always just picked the\n            // partial tail then we could produce a highly\n            // lopsided index over time:\n\n            // We must merge this many segments to leave\n            // maxNumSegments in the index (from when\n            // optimize was first kicked off):\n            final int finalMergeSize = last - maxNumSegments + 1;\n\n            // Consider all possible starting points:\n            long bestSize = 0;\n            int bestStart = 0;\n\n            for(int i=0;i<last-finalMergeSize+1;i++) {\n              long sumSize = 0;\n              for(int j=0;j<finalMergeSize;j++)\n                sumSize += size(infos.info(j+i));\n              if (i == 0 || (sumSize < 2*size(infos.info(i-1)) && sumSize < bestSize)) {\n                bestStart = i;\n                bestSize = sumSize;\n              }\n            }\n\n            spec.add(new OneMerge(infos.range(bestStart, bestStart+finalMergeSize), useCompoundFile));\n          }\n        }\n        \n      } else\n        spec = null;\n    } else\n      spec = null;\n\n    return spec;\n  }\n\n","sourceOld":"  /** Returns the merges necessary to optimize the index.\n   *  This merge policy defines \"optimized\" to mean only one\n   *  segment in the index, where that segment has no\n   *  deletions pending nor separate norms, and it is in\n   *  compound file format if the current useCompoundFile\n   *  setting is true.  This method returns multiple merges\n   *  (mergeFactor at a time) so the {@link MergeScheduler}\n   *  in use may make use of concurrency. */\n  @Override\n  public MergeSpecification findMergesForOptimize(SegmentInfos infos,\n      int maxNumSegments, Set<SegmentInfo> segmentsToOptimize) throws IOException {\n    MergeSpecification spec;\n\n    assert maxNumSegments > 0;\n\n    if (!isOptimized(infos, maxNumSegments, segmentsToOptimize)) {\n\n      // Find the newest (rightmost) segment that needs to\n      // be optimized (other segments may have been flushed\n      // since optimize started):\n      int last = infos.size();\n      while(last > 0) {\n        final SegmentInfo info = infos.info(--last);\n        if (segmentsToOptimize.contains(info)) {\n          last++;\n          break;\n        }\n      }\n\n      if (last > 0) {\n\n        spec = new MergeSpecification();\n\n        // First, enroll all \"full\" merges (size\n        // mergeFactor) to potentially be run concurrently:\n        while (last - maxNumSegments + 1 >= mergeFactor) {\n          spec.add(new OneMerge(infos.range(last-mergeFactor, last), useCompoundFile));\n          last -= mergeFactor;\n        }\n\n        // Only if there are no full merges pending do we\n        // add a final partial (< mergeFactor segments) merge:\n        if (0 == spec.merges.size()) {\n          if (maxNumSegments == 1) {\n\n            // Since we must optimize down to 1 segment, the\n            // choice is simple:\n            if (last > 1 || !isOptimized(infos.info(0)))\n              spec.add(new OneMerge(infos.range(0, last), useCompoundFile));\n          } else if (last > maxNumSegments) {\n\n            // Take care to pick a partial merge that is\n            // least cost, but does not make the index too\n            // lopsided.  If we always just picked the\n            // partial tail then we could produce a highly\n            // lopsided index over time:\n\n            // We must merge this many segments to leave\n            // maxNumSegments in the index (from when\n            // optimize was first kicked off):\n            final int finalMergeSize = last - maxNumSegments + 1;\n\n            // Consider all possible starting points:\n            long bestSize = 0;\n            int bestStart = 0;\n\n            for(int i=0;i<last-finalMergeSize+1;i++) {\n              long sumSize = 0;\n              for(int j=0;j<finalMergeSize;j++)\n                sumSize += size(infos.info(j+i));\n              if (i == 0 || (sumSize < 2*size(infos.info(i-1)) && sumSize < bestSize)) {\n                bestStart = i;\n                bestSize = sumSize;\n              }\n            }\n\n            spec.add(new OneMerge(infos.range(bestStart, bestStart+finalMergeSize), useCompoundFile));\n          }\n        }\n        \n      } else\n        spec = null;\n    } else\n      spec = null;\n\n    return spec;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8723a3379c08ae0b4ba0cf4f246306f86ad8362d","date":1287582680,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/LogMergePolicy#findMergesForOptimize(SegmentInfos,int,Set[SegmentInfo]).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/LogMergePolicy#findMergesForOptimize(SegmentInfos,int,Set[SegmentInfo]).mjava","sourceNew":"  /** Returns the merges necessary to optimize the index.\n   *  This merge policy defines \"optimized\" to mean only one\n   *  segment in the index, where that segment has no\n   *  deletions pending nor separate norms, and it is in\n   *  compound file format if the current useCompoundFile\n   *  setting is true.  This method returns multiple merges\n   *  (mergeFactor at a time) so the {@link MergeScheduler}\n   *  in use may make use of concurrency. */\n  @Override\n  public MergeSpecification findMergesForOptimize(SegmentInfos infos,\n      int maxNumSegments, Set<SegmentInfo> segmentsToOptimize) throws IOException {\n\n    assert maxNumSegments > 0;\n\n    // If the segments are already optimized (e.g. there's only 1 segment), or\n    // there are <maxNumSegements, all optimized, nothing to do.\n    if (isOptimized(infos, maxNumSegments, segmentsToOptimize)) return null;\n    \n    // Find the newest (rightmost) segment that needs to\n    // be optimized (other segments may have been flushed\n    // since optimize started):\n    int last = infos.size();\n    while (last > 0) {\n      final SegmentInfo info = infos.info(--last);\n      if (segmentsToOptimize.contains(info)) {\n        last++;\n        break;\n      }\n    }\n\n    if (last == 0) return null;\n    \n    // There is only one segment already, and it is optimized\n    if (maxNumSegments == 1 && last == 1 && isOptimized(infos.info(0))) return null;\n\n    // Check if there are any segments above the threshold\n    boolean anyTooLarge = false;\n    for (int i = 0; i < last; i++) {\n      SegmentInfo info = infos.info(i);\n      if (size(info) > maxMergeSize || sizeDocs(info) > maxMergeDocs) {\n        anyTooLarge = true;\n        break;\n      }\n    }\n    \n    if (anyTooLarge) {\n      return findMergesForOptimizeSizeLimit(infos, maxNumSegments, last);\n    } else {\n      return findMergesForOptimizeMaxNumSegments(infos, maxNumSegments, last);\n    }\n  }\n\n","sourceOld":"  /** Returns the merges necessary to optimize the index.\n   *  This merge policy defines \"optimized\" to mean only one\n   *  segment in the index, where that segment has no\n   *  deletions pending nor separate norms, and it is in\n   *  compound file format if the current useCompoundFile\n   *  setting is true.  This method returns multiple merges\n   *  (mergeFactor at a time) so the {@link MergeScheduler}\n   *  in use may make use of concurrency. */\n  @Override\n  public MergeSpecification findMergesForOptimize(SegmentInfos infos,\n      int maxNumSegments, Set<SegmentInfo> segmentsToOptimize) throws IOException {\n    MergeSpecification spec;\n\n    assert maxNumSegments > 0;\n\n    if (!isOptimized(infos, maxNumSegments, segmentsToOptimize)) {\n\n      // Find the newest (rightmost) segment that needs to\n      // be optimized (other segments may have been flushed\n      // since optimize started):\n      int last = infos.size();\n      while(last > 0) {\n        final SegmentInfo info = infos.info(--last);\n        if (segmentsToOptimize.contains(info)) {\n          last++;\n          break;\n        }\n      }\n\n      if (last > 0) {\n\n        spec = new MergeSpecification();\n\n        // First, enroll all \"full\" merges (size\n        // mergeFactor) to potentially be run concurrently:\n        while (last - maxNumSegments + 1 >= mergeFactor) {\n          spec.add(new OneMerge(infos.range(last-mergeFactor, last), useCompoundFile));\n          last -= mergeFactor;\n        }\n\n        // Only if there are no full merges pending do we\n        // add a final partial (< mergeFactor segments) merge:\n        if (0 == spec.merges.size()) {\n          if (maxNumSegments == 1) {\n\n            // Since we must optimize down to 1 segment, the\n            // choice is simple:\n            if (last > 1 || !isOptimized(infos.info(0)))\n              spec.add(new OneMerge(infos.range(0, last), useCompoundFile));\n          } else if (last > maxNumSegments) {\n\n            // Take care to pick a partial merge that is\n            // least cost, but does not make the index too\n            // lopsided.  If we always just picked the\n            // partial tail then we could produce a highly\n            // lopsided index over time:\n\n            // We must merge this many segments to leave\n            // maxNumSegments in the index (from when\n            // optimize was first kicked off):\n            final int finalMergeSize = last - maxNumSegments + 1;\n\n            // Consider all possible starting points:\n            long bestSize = 0;\n            int bestStart = 0;\n\n            for(int i=0;i<last-finalMergeSize+1;i++) {\n              long sumSize = 0;\n              for(int j=0;j<finalMergeSize;j++)\n                sumSize += size(infos.info(j+i));\n              if (i == 0 || (sumSize < 2*size(infos.info(i-1)) && sumSize < bestSize)) {\n                bestStart = i;\n                bestSize = sumSize;\n              }\n            }\n\n            spec.add(new OneMerge(infos.range(bestStart, bestStart+finalMergeSize), useCompoundFile));\n          }\n        }\n        \n      } else\n        spec = null;\n    } else\n      spec = null;\n\n    return spec;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8017ab6544f30f93b106e419e7298173bad77f69","date":1287608126,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/LogMergePolicy#findMergesForOptimize(SegmentInfos,int,Set[SegmentInfo]).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/LogMergePolicy#findMergesForOptimize(SegmentInfos,int,Set[SegmentInfo]).mjava","sourceNew":"  /** Returns the merges necessary to optimize the index.\n   *  This merge policy defines \"optimized\" to mean only one\n   *  segment in the index, where that segment has no\n   *  deletions pending nor separate norms, and it is in\n   *  compound file format if the current useCompoundFile\n   *  setting is true.  This method returns multiple merges\n   *  (mergeFactor at a time) so the {@link MergeScheduler}\n   *  in use may make use of concurrency. */\n  @Override\n  public MergeSpecification findMergesForOptimize(SegmentInfos infos,\n      int maxNumSegments, Set<SegmentInfo> segmentsToOptimize) throws IOException {\n\n    assert maxNumSegments > 0;\n\n    // If the segments are already optimized (e.g. there's only 1 segment), or\n    // there are <maxNumSegements, all optimized, nothing to do.\n    if (isOptimized(infos, maxNumSegments, segmentsToOptimize)) return null;\n    \n    // Find the newest (rightmost) segment that needs to\n    // be optimized (other segments may have been flushed\n    // since optimize started):\n    int last = infos.size();\n    while (last > 0) {\n      final SegmentInfo info = infos.info(--last);\n      if (segmentsToOptimize.contains(info)) {\n        last++;\n        break;\n      }\n    }\n\n    if (last == 0) return null;\n    \n    // There is only one segment already, and it is optimized\n    if (maxNumSegments == 1 && last == 1 && isOptimized(infos.info(0))) return null;\n\n    // Check if there are any segments above the threshold\n    boolean anyTooLarge = false;\n    for (int i = 0; i < last; i++) {\n      SegmentInfo info = infos.info(i);\n      if (size(info) > maxMergeSize || sizeDocs(info) > maxMergeDocs) {\n        anyTooLarge = true;\n        break;\n      }\n    }\n    \n    if (anyTooLarge) {\n      return findMergesForOptimizeSizeLimit(infos, maxNumSegments, last);\n    } else {\n      return findMergesForOptimizeMaxNumSegments(infos, maxNumSegments, last);\n    }\n  }\n\n","sourceOld":"  /** Returns the merges necessary to optimize the index.\n   *  This merge policy defines \"optimized\" to mean only one\n   *  segment in the index, where that segment has no\n   *  deletions pending nor separate norms, and it is in\n   *  compound file format if the current useCompoundFile\n   *  setting is true.  This method returns multiple merges\n   *  (mergeFactor at a time) so the {@link MergeScheduler}\n   *  in use may make use of concurrency. */\n  @Override\n  public MergeSpecification findMergesForOptimize(SegmentInfos infos,\n      int maxNumSegments, Set<SegmentInfo> segmentsToOptimize) throws IOException {\n    MergeSpecification spec;\n\n    assert maxNumSegments > 0;\n\n    if (!isOptimized(infos, maxNumSegments, segmentsToOptimize)) {\n\n      // Find the newest (rightmost) segment that needs to\n      // be optimized (other segments may have been flushed\n      // since optimize started):\n      int last = infos.size();\n      while(last > 0) {\n        final SegmentInfo info = infos.info(--last);\n        if (segmentsToOptimize.contains(info)) {\n          last++;\n          break;\n        }\n      }\n\n      if (last > 0) {\n\n        spec = new MergeSpecification();\n\n        // First, enroll all \"full\" merges (size\n        // mergeFactor) to potentially be run concurrently:\n        while (last - maxNumSegments + 1 >= mergeFactor) {\n          spec.add(new OneMerge(infos.range(last-mergeFactor, last), useCompoundFile));\n          last -= mergeFactor;\n        }\n\n        // Only if there are no full merges pending do we\n        // add a final partial (< mergeFactor segments) merge:\n        if (0 == spec.merges.size()) {\n          if (maxNumSegments == 1) {\n\n            // Since we must optimize down to 1 segment, the\n            // choice is simple:\n            if (last > 1 || !isOptimized(infos.info(0)))\n              spec.add(new OneMerge(infos.range(0, last), useCompoundFile));\n          } else if (last > maxNumSegments) {\n\n            // Take care to pick a partial merge that is\n            // least cost, but does not make the index too\n            // lopsided.  If we always just picked the\n            // partial tail then we could produce a highly\n            // lopsided index over time:\n\n            // We must merge this many segments to leave\n            // maxNumSegments in the index (from when\n            // optimize was first kicked off):\n            final int finalMergeSize = last - maxNumSegments + 1;\n\n            // Consider all possible starting points:\n            long bestSize = 0;\n            int bestStart = 0;\n\n            for(int i=0;i<last-finalMergeSize+1;i++) {\n              long sumSize = 0;\n              for(int j=0;j<finalMergeSize;j++)\n                sumSize += size(infos.info(j+i));\n              if (i == 0 || (sumSize < 2*size(infos.info(i-1)) && sumSize < bestSize)) {\n                bestStart = i;\n                bestSize = sumSize;\n              }\n            }\n\n            spec.add(new OneMerge(infos.range(bestStart, bestStart+finalMergeSize), useCompoundFile));\n          }\n        }\n        \n      } else\n        spec = null;\n    } else\n      spec = null;\n\n    return spec;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/LogMergePolicy#findMergesForOptimize(SegmentInfos,int,Set[SegmentInfo]).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/LogMergePolicy#findMergesForOptimize(SegmentInfos,int,Set[SegmentInfo]).mjava","sourceNew":"  /** Returns the merges necessary to optimize the index.\n   *  This merge policy defines \"optimized\" to mean only one\n   *  segment in the index, where that segment has no\n   *  deletions pending nor separate norms, and it is in\n   *  compound file format if the current useCompoundFile\n   *  setting is true.  This method returns multiple merges\n   *  (mergeFactor at a time) so the {@link MergeScheduler}\n   *  in use may make use of concurrency. */\n  @Override\n  public MergeSpecification findMergesForOptimize(SegmentInfos infos,\n      int maxNumSegments, Set<SegmentInfo> segmentsToOptimize) throws IOException {\n\n    assert maxNumSegments > 0;\n\n    // If the segments are already optimized (e.g. there's only 1 segment), or\n    // there are <maxNumSegements, all optimized, nothing to do.\n    if (isOptimized(infos, maxNumSegments, segmentsToOptimize)) return null;\n\n    // Find the newest (rightmost) segment that needs to\n    // be optimized (other segments may have been flushed\n    // since optimize started):\n    int last = infos.size();\n    while (last > 0) {\n      final SegmentInfo info = infos.info(--last);\n      if (segmentsToOptimize.contains(info)) {\n        last++;\n        break;\n      }\n    }\n\n    if (last == 0) return null;\n\n    // There is only one segment already, and it is optimized\n    if (maxNumSegments == 1 && last == 1 && isOptimized(infos.info(0))) return null;\n\n    // Check if there are any segments above the threshold\n    boolean anyTooLarge = false;\n    for (int i = 0; i < last; i++) {\n      SegmentInfo info = infos.info(i);\n      if (size(info) > maxMergeSize || sizeDocs(info) > maxMergeDocs) {\n        anyTooLarge = true;\n        break;\n      }\n    }\n\n    if (anyTooLarge) {\n      return findMergesForOptimizeSizeLimit(infos, maxNumSegments, last);\n    } else {\n      return findMergesForOptimizeMaxNumSegments(infos, maxNumSegments, last);\n    }\n  }\n\n","sourceOld":"  /** Returns the merges necessary to optimize the index.\n   *  This merge policy defines \"optimized\" to mean only one\n   *  segment in the index, where that segment has no\n   *  deletions pending nor separate norms, and it is in\n   *  compound file format if the current useCompoundFile\n   *  setting is true.  This method returns multiple merges\n   *  (mergeFactor at a time) so the {@link MergeScheduler}\n   *  in use may make use of concurrency. */\n  @Override\n  public MergeSpecification findMergesForOptimize(SegmentInfos infos,\n      int maxNumSegments, Set<SegmentInfo> segmentsToOptimize) throws IOException {\n    MergeSpecification spec;\n\n    assert maxNumSegments > 0;\n\n    if (!isOptimized(infos, maxNumSegments, segmentsToOptimize)) {\n\n      // Find the newest (rightmost) segment that needs to\n      // be optimized (other segments may have been flushed\n      // since optimize started):\n      int last = infos.size();\n      while(last > 0) {\n        final SegmentInfo info = infos.info(--last);\n        if (segmentsToOptimize.contains(info)) {\n          last++;\n          break;\n        }\n      }\n\n      if (last > 0) {\n\n        spec = new MergeSpecification();\n\n        // First, enroll all \"full\" merges (size\n        // mergeFactor) to potentially be run concurrently:\n        while (last - maxNumSegments + 1 >= mergeFactor) {\n          spec.add(new OneMerge(infos.range(last-mergeFactor, last), useCompoundFile));\n          last -= mergeFactor;\n        }\n\n        // Only if there are no full merges pending do we\n        // add a final partial (< mergeFactor segments) merge:\n        if (0 == spec.merges.size()) {\n          if (maxNumSegments == 1) {\n\n            // Since we must optimize down to 1 segment, the\n            // choice is simple:\n            if (last > 1 || !isOptimized(infos.info(0)))\n              spec.add(new OneMerge(infos.range(0, last), useCompoundFile));\n          } else if (last > maxNumSegments) {\n\n            // Take care to pick a partial merge that is\n            // least cost, but does not make the index too\n            // lopsided.  If we always just picked the\n            // partial tail then we could produce a highly\n            // lopsided index over time:\n\n            // We must merge this many segments to leave\n            // maxNumSegments in the index (from when\n            // optimize was first kicked off):\n            final int finalMergeSize = last - maxNumSegments + 1;\n\n            // Consider all possible starting points:\n            long bestSize = 0;\n            int bestStart = 0;\n\n            for(int i=0;i<last-finalMergeSize+1;i++) {\n              long sumSize = 0;\n              for(int j=0;j<finalMergeSize;j++)\n                sumSize += size(infos.info(j+i));\n              if (i == 0 || (sumSize < 2*size(infos.info(i-1)) && sumSize < bestSize)) {\n                bestStart = i;\n                bestSize = sumSize;\n              }\n            }\n\n            spec.add(new OneMerge(infos.range(bestStart, bestStart+finalMergeSize), useCompoundFile));\n          }\n        }\n        \n      } else\n        spec = null;\n    } else\n      spec = null;\n\n    return spec;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8b241ea5e635d896cc0af83cd96ffd0322e0aba7","date":1294226200,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/LogMergePolicy#findMergesForOptimize(SegmentInfos,int,Set[SegmentInfo]).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/LogMergePolicy#findMergesForOptimize(SegmentInfos,int,Set[SegmentInfo]).mjava","sourceNew":"  /** Returns the merges necessary to optimize the index.\n   *  This merge policy defines \"optimized\" to mean only one\n   *  segment in the index, where that segment has no\n   *  deletions pending nor separate norms, and it is in\n   *  compound file format if the current useCompoundFile\n   *  setting is true.  This method returns multiple merges\n   *  (mergeFactor at a time) so the {@link MergeScheduler}\n   *  in use may make use of concurrency. */\n  @Override\n  public MergeSpecification findMergesForOptimize(SegmentInfos infos,\n      int maxNumSegments, Set<SegmentInfo> segmentsToOptimize) throws IOException {\n\n    assert maxNumSegments > 0;\n    if (verbose()) {\n      message(\"findMergesForOptimize: maxNumSegs=\" + maxNumSegments + \" segsToOptimize= \"+ segmentsToOptimize);\n    }\n\n    // If the segments are already optimized (e.g. there's only 1 segment), or\n    // there are <maxNumSegements, all optimized, nothing to do.\n    if (isOptimized(infos, maxNumSegments, segmentsToOptimize)) {\n      if (verbose()) {\n        message(\"already optimized; skip\");\n      }\n      return null;\n    }\n    \n    // Find the newest (rightmost) segment that needs to\n    // be optimized (other segments may have been flushed\n    // since optimize started):\n    int last = infos.size();\n    while (last > 0) {\n      final SegmentInfo info = infos.info(--last);\n      if (segmentsToOptimize.contains(info)) {\n        last++;\n        break;\n      }\n    }\n\n    if (last == 0) {\n      if (verbose()) {\n        message(\"last == 0; skip\");\n      }\n      return null;\n    }\n    \n    // There is only one segment already, and it is optimized\n    if (maxNumSegments == 1 && last == 1 && isOptimized(infos.info(0))) {\n      if (verbose()) {\n        message(\"already 1 seg; skip\");\n      }\n      return null;\n    }\n\n    // Check if there are any segments above the threshold\n    boolean anyTooLarge = false;\n    for (int i = 0; i < last; i++) {\n      SegmentInfo info = infos.info(i);\n      if (size(info) > maxMergeSize || sizeDocs(info) > maxMergeDocs) {\n        anyTooLarge = true;\n        break;\n      }\n    }\n    \n    if (anyTooLarge) {\n      return findMergesForOptimizeSizeLimit(infos, maxNumSegments, last);\n    } else {\n      return findMergesForOptimizeMaxNumSegments(infos, maxNumSegments, last);\n    }\n  }\n\n","sourceOld":"  /** Returns the merges necessary to optimize the index.\n   *  This merge policy defines \"optimized\" to mean only one\n   *  segment in the index, where that segment has no\n   *  deletions pending nor separate norms, and it is in\n   *  compound file format if the current useCompoundFile\n   *  setting is true.  This method returns multiple merges\n   *  (mergeFactor at a time) so the {@link MergeScheduler}\n   *  in use may make use of concurrency. */\n  @Override\n  public MergeSpecification findMergesForOptimize(SegmentInfos infos,\n      int maxNumSegments, Set<SegmentInfo> segmentsToOptimize) throws IOException {\n\n    assert maxNumSegments > 0;\n\n    // If the segments are already optimized (e.g. there's only 1 segment), or\n    // there are <maxNumSegements, all optimized, nothing to do.\n    if (isOptimized(infos, maxNumSegments, segmentsToOptimize)) return null;\n    \n    // Find the newest (rightmost) segment that needs to\n    // be optimized (other segments may have been flushed\n    // since optimize started):\n    int last = infos.size();\n    while (last > 0) {\n      final SegmentInfo info = infos.info(--last);\n      if (segmentsToOptimize.contains(info)) {\n        last++;\n        break;\n      }\n    }\n\n    if (last == 0) return null;\n    \n    // There is only one segment already, and it is optimized\n    if (maxNumSegments == 1 && last == 1 && isOptimized(infos.info(0))) return null;\n\n    // Check if there are any segments above the threshold\n    boolean anyTooLarge = false;\n    for (int i = 0; i < last; i++) {\n      SegmentInfo info = infos.info(i);\n      if (size(info) > maxMergeSize || sizeDocs(info) > maxMergeDocs) {\n        anyTooLarge = true;\n        break;\n      }\n    }\n    \n    if (anyTooLarge) {\n      return findMergesForOptimizeSizeLimit(infos, maxNumSegments, last);\n    } else {\n      return findMergesForOptimizeMaxNumSegments(infos, maxNumSegments, last);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"70ad682703b8585f5d0a637efec044d57ec05efb","date":1294259117,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/LogMergePolicy#findMergesForOptimize(SegmentInfos,int,Set[SegmentInfo]).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/LogMergePolicy#findMergesForOptimize(SegmentInfos,int,Set[SegmentInfo]).mjava","sourceNew":"  /** Returns the merges necessary to optimize the index.\n   *  This merge policy defines \"optimized\" to mean only one\n   *  segment in the index, where that segment has no\n   *  deletions pending nor separate norms, and it is in\n   *  compound file format if the current useCompoundFile\n   *  setting is true.  This method returns multiple merges\n   *  (mergeFactor at a time) so the {@link MergeScheduler}\n   *  in use may make use of concurrency. */\n  @Override\n  public MergeSpecification findMergesForOptimize(SegmentInfos infos,\n      int maxNumSegments, Set<SegmentInfo> segmentsToOptimize) throws IOException {\n\n    assert maxNumSegments > 0;\n    if (verbose()) {\n      message(\"findMergesForOptimize: maxNumSegs=\" + maxNumSegments + \" segsToOptimize= \"+ segmentsToOptimize);\n    }\n\n    // If the segments are already optimized (e.g. there's only 1 segment), or\n    // there are <maxNumSegements, all optimized, nothing to do.\n    if (isOptimized(infos, maxNumSegments, segmentsToOptimize)) {\n      if (verbose()) {\n        message(\"already optimized; skip\");\n      }\n      return null;\n    }\n    \n    // Find the newest (rightmost) segment that needs to\n    // be optimized (other segments may have been flushed\n    // since optimize started):\n    int last = infos.size();\n    while (last > 0) {\n      final SegmentInfo info = infos.info(--last);\n      if (segmentsToOptimize.contains(info)) {\n        last++;\n        break;\n      }\n    }\n\n    if (last == 0) {\n      if (verbose()) {\n        message(\"last == 0; skip\");\n      }\n      return null;\n    }\n    \n    // There is only one segment already, and it is optimized\n    if (maxNumSegments == 1 && last == 1 && isOptimized(infos.info(0))) {\n      if (verbose()) {\n        message(\"already 1 seg; skip\");\n      }\n      return null;\n    }\n\n    // Check if there are any segments above the threshold\n    boolean anyTooLarge = false;\n    for (int i = 0; i < last; i++) {\n      SegmentInfo info = infos.info(i);\n      if (size(info) > maxMergeSize || sizeDocs(info) > maxMergeDocs) {\n        anyTooLarge = true;\n        break;\n      }\n    }\n    \n    if (anyTooLarge) {\n      return findMergesForOptimizeSizeLimit(infos, maxNumSegments, last);\n    } else {\n      return findMergesForOptimizeMaxNumSegments(infos, maxNumSegments, last);\n    }\n  }\n\n","sourceOld":"  /** Returns the merges necessary to optimize the index.\n   *  This merge policy defines \"optimized\" to mean only one\n   *  segment in the index, where that segment has no\n   *  deletions pending nor separate norms, and it is in\n   *  compound file format if the current useCompoundFile\n   *  setting is true.  This method returns multiple merges\n   *  (mergeFactor at a time) so the {@link MergeScheduler}\n   *  in use may make use of concurrency. */\n  @Override\n  public MergeSpecification findMergesForOptimize(SegmentInfos infos,\n      int maxNumSegments, Set<SegmentInfo> segmentsToOptimize) throws IOException {\n\n    assert maxNumSegments > 0;\n\n    // If the segments are already optimized (e.g. there's only 1 segment), or\n    // there are <maxNumSegements, all optimized, nothing to do.\n    if (isOptimized(infos, maxNumSegments, segmentsToOptimize)) return null;\n    \n    // Find the newest (rightmost) segment that needs to\n    // be optimized (other segments may have been flushed\n    // since optimize started):\n    int last = infos.size();\n    while (last > 0) {\n      final SegmentInfo info = infos.info(--last);\n      if (segmentsToOptimize.contains(info)) {\n        last++;\n        break;\n      }\n    }\n\n    if (last == 0) return null;\n    \n    // There is only one segment already, and it is optimized\n    if (maxNumSegments == 1 && last == 1 && isOptimized(infos.info(0))) return null;\n\n    // Check if there are any segments above the threshold\n    boolean anyTooLarge = false;\n    for (int i = 0; i < last; i++) {\n      SegmentInfo info = infos.info(i);\n      if (size(info) > maxMergeSize || sizeDocs(info) > maxMergeDocs) {\n        anyTooLarge = true;\n        break;\n      }\n    }\n    \n    if (anyTooLarge) {\n      return findMergesForOptimizeSizeLimit(infos, maxNumSegments, last);\n    } else {\n      return findMergesForOptimizeMaxNumSegments(infos, maxNumSegments, last);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"868da859b43505d9d2a023bfeae6dd0c795f5295","date":1294948401,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/LogMergePolicy#findMergesForOptimize(SegmentInfos,int,Set[SegmentInfo]).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/LogMergePolicy#findMergesForOptimize(SegmentInfos,int,Set[SegmentInfo]).mjava","sourceNew":"  /** Returns the merges necessary to optimize the index.\n   *  This merge policy defines \"optimized\" to mean only one\n   *  segment in the index, where that segment has no\n   *  deletions pending nor separate norms, and it is in\n   *  compound file format if the current useCompoundFile\n   *  setting is true.  This method returns multiple merges\n   *  (mergeFactor at a time) so the {@link MergeScheduler}\n   *  in use may make use of concurrency. */\n  @Override\n  public MergeSpecification findMergesForOptimize(SegmentInfos infos,\n      int maxNumSegments, Set<SegmentInfo> segmentsToOptimize) throws IOException {\n\n    assert maxNumSegments > 0;\n    if (verbose()) {\n      message(\"findMergesForOptimize: maxNumSegs=\" + maxNumSegments + \" segsToOptimize= \"+ segmentsToOptimize);\n    }\n\n    // If the segments are already optimized (e.g. there's only 1 segment), or\n    // there are <maxNumSegements, all optimized, nothing to do.\n    if (isOptimized(infos, maxNumSegments, segmentsToOptimize)) {\n      if (verbose()) {\n        message(\"already optimized; skip\");\n      }\n      return null;\n    }\n\n    // Find the newest (rightmost) segment that needs to\n    // be optimized (other segments may have been flushed\n    // since optimize started):\n    int last = infos.size();\n    while (last > 0) {\n      final SegmentInfo info = infos.info(--last);\n      if (segmentsToOptimize.contains(info)) {\n        last++;\n        break;\n      }\n    }\n\n    if (last == 0) {\n      if (verbose()) {\n        message(\"last == 0; skip\");\n      }\n      return null;\n    }\n\n    // There is only one segment already, and it is optimized\n    if (maxNumSegments == 1 && last == 1 && isOptimized(infos.info(0))) {\n      if (verbose()) {\n        message(\"already 1 seg; skip\");\n      }\n      return null;\n    }\n\n    // Check if there are any segments above the threshold\n    boolean anyTooLarge = false;\n    for (int i = 0; i < last; i++) {\n      SegmentInfo info = infos.info(i);\n      if (size(info) > maxMergeSize || sizeDocs(info) > maxMergeDocs) {\n        anyTooLarge = true;\n        break;\n      }\n    }\n\n    if (anyTooLarge) {\n      return findMergesForOptimizeSizeLimit(infos, maxNumSegments, last);\n    } else {\n      return findMergesForOptimizeMaxNumSegments(infos, maxNumSegments, last);\n    }\n  }\n\n","sourceOld":"  /** Returns the merges necessary to optimize the index.\n   *  This merge policy defines \"optimized\" to mean only one\n   *  segment in the index, where that segment has no\n   *  deletions pending nor separate norms, and it is in\n   *  compound file format if the current useCompoundFile\n   *  setting is true.  This method returns multiple merges\n   *  (mergeFactor at a time) so the {@link MergeScheduler}\n   *  in use may make use of concurrency. */\n  @Override\n  public MergeSpecification findMergesForOptimize(SegmentInfos infos,\n      int maxNumSegments, Set<SegmentInfo> segmentsToOptimize) throws IOException {\n\n    assert maxNumSegments > 0;\n\n    // If the segments are already optimized (e.g. there's only 1 segment), or\n    // there are <maxNumSegements, all optimized, nothing to do.\n    if (isOptimized(infos, maxNumSegments, segmentsToOptimize)) return null;\n\n    // Find the newest (rightmost) segment that needs to\n    // be optimized (other segments may have been flushed\n    // since optimize started):\n    int last = infos.size();\n    while (last > 0) {\n      final SegmentInfo info = infos.info(--last);\n      if (segmentsToOptimize.contains(info)) {\n        last++;\n        break;\n      }\n    }\n\n    if (last == 0) return null;\n\n    // There is only one segment already, and it is optimized\n    if (maxNumSegments == 1 && last == 1 && isOptimized(infos.info(0))) return null;\n\n    // Check if there are any segments above the threshold\n    boolean anyTooLarge = false;\n    for (int i = 0; i < last; i++) {\n      SegmentInfo info = infos.info(i);\n      if (size(info) > maxMergeSize || sizeDocs(info) > maxMergeDocs) {\n        anyTooLarge = true;\n        break;\n      }\n    }\n\n    if (anyTooLarge) {\n      return findMergesForOptimizeSizeLimit(infos, maxNumSegments, last);\n    } else {\n      return findMergesForOptimizeMaxNumSegments(infos, maxNumSegments, last);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8bcd63cc99c783b21344aeeebc8c04db29770205","date":1295239623,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/LogMergePolicy#findMergesForOptimize(SegmentInfos,int,Set[SegmentInfo]).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/LogMergePolicy#findMergesForOptimize(SegmentInfos,int,Set[SegmentInfo]).mjava","sourceNew":"  /** Returns the merges necessary to optimize the index.\n   *  This merge policy defines \"optimized\" to mean only the\n   *  requested number of segments is left in the index, and\n   *  respects the {@link #maxMergeSizeForOptimize} setting.\n   *  By default, and assuming {@code maxNumSegments=1}, only\n   *  one segment will be left in the index, where that segment\n   *  has no deletions pending nor separate norms, and it is in\n   *  compound file format if the current useCompoundFile\n   *  setting is true.  This method returns multiple merges\n   *  (mergeFactor at a time) so the {@link MergeScheduler}\n   *  in use may make use of concurrency. */\n  @Override\n  public MergeSpecification findMergesForOptimize(SegmentInfos infos,\n      int maxNumSegments, Set<SegmentInfo> segmentsToOptimize) throws IOException {\n\n    assert maxNumSegments > 0;\n    if (verbose()) {\n      message(\"findMergesForOptimize: maxNumSegs=\" + maxNumSegments + \" segsToOptimize= \"+ segmentsToOptimize);\n    }\n\n    // If the segments are already optimized (e.g. there's only 1 segment), or\n    // there are <maxNumSegements, all optimized, nothing to do.\n    if (isOptimized(infos, maxNumSegments, segmentsToOptimize)) {\n      if (verbose()) {\n        message(\"already optimized; skip\");\n      }\n      return null;\n    }\n    \n    // Find the newest (rightmost) segment that needs to\n    // be optimized (other segments may have been flushed\n    // since optimize started):\n    int last = infos.size();\n    while (last > 0) {\n      final SegmentInfo info = infos.info(--last);\n      if (segmentsToOptimize.contains(info)) {\n        last++;\n        break;\n      }\n    }\n\n    if (last == 0) {\n      if (verbose()) {\n        message(\"last == 0; skip\");\n      }\n      return null;\n    }\n    \n    // There is only one segment already, and it is optimized\n    if (maxNumSegments == 1 && last == 1 && isOptimized(infos.info(0))) {\n      if (verbose()) {\n        message(\"already 1 seg; skip\");\n      }\n      return null;\n    }\n\n    // Check if there are any segments above the threshold\n    boolean anyTooLarge = false;\n    for (int i = 0; i < last; i++) {\n      SegmentInfo info = infos.info(i);\n      if (size(info) > maxMergeSizeForOptimize || sizeDocs(info) > maxMergeDocs) {\n        anyTooLarge = true;\n        break;\n      }\n    }\n    \n    if (anyTooLarge) {\n      return findMergesForOptimizeSizeLimit(infos, maxNumSegments, last);\n    } else {\n      return findMergesForOptimizeMaxNumSegments(infos, maxNumSegments, last);\n    }\n  }\n\n","sourceOld":"  /** Returns the merges necessary to optimize the index.\n   *  This merge policy defines \"optimized\" to mean only one\n   *  segment in the index, where that segment has no\n   *  deletions pending nor separate norms, and it is in\n   *  compound file format if the current useCompoundFile\n   *  setting is true.  This method returns multiple merges\n   *  (mergeFactor at a time) so the {@link MergeScheduler}\n   *  in use may make use of concurrency. */\n  @Override\n  public MergeSpecification findMergesForOptimize(SegmentInfos infos,\n      int maxNumSegments, Set<SegmentInfo> segmentsToOptimize) throws IOException {\n\n    assert maxNumSegments > 0;\n    if (verbose()) {\n      message(\"findMergesForOptimize: maxNumSegs=\" + maxNumSegments + \" segsToOptimize= \"+ segmentsToOptimize);\n    }\n\n    // If the segments are already optimized (e.g. there's only 1 segment), or\n    // there are <maxNumSegements, all optimized, nothing to do.\n    if (isOptimized(infos, maxNumSegments, segmentsToOptimize)) {\n      if (verbose()) {\n        message(\"already optimized; skip\");\n      }\n      return null;\n    }\n    \n    // Find the newest (rightmost) segment that needs to\n    // be optimized (other segments may have been flushed\n    // since optimize started):\n    int last = infos.size();\n    while (last > 0) {\n      final SegmentInfo info = infos.info(--last);\n      if (segmentsToOptimize.contains(info)) {\n        last++;\n        break;\n      }\n    }\n\n    if (last == 0) {\n      if (verbose()) {\n        message(\"last == 0; skip\");\n      }\n      return null;\n    }\n    \n    // There is only one segment already, and it is optimized\n    if (maxNumSegments == 1 && last == 1 && isOptimized(infos.info(0))) {\n      if (verbose()) {\n        message(\"already 1 seg; skip\");\n      }\n      return null;\n    }\n\n    // Check if there are any segments above the threshold\n    boolean anyTooLarge = false;\n    for (int i = 0; i < last; i++) {\n      SegmentInfo info = infos.info(i);\n      if (size(info) > maxMergeSize || sizeDocs(info) > maxMergeDocs) {\n        anyTooLarge = true;\n        break;\n      }\n    }\n    \n    if (anyTooLarge) {\n      return findMergesForOptimizeSizeLimit(infos, maxNumSegments, last);\n    } else {\n      return findMergesForOptimizeMaxNumSegments(infos, maxNumSegments, last);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae31c2e5298b269d50b60961fe85afc5fbe873c3","date":1295256360,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/LogMergePolicy#findMergesForOptimize(SegmentInfos,int,Set[SegmentInfo]).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/LogMergePolicy#findMergesForOptimize(SegmentInfos,int,Set[SegmentInfo]).mjava","sourceNew":"  /** Returns the merges necessary to optimize the index.\n   *  This merge policy defines \"optimized\" to mean only the\n   *  requested number of segments is left in the index, and\n   *  respects the {@link #maxMergeSizeForOptimize} setting.\n   *  By default, and assuming {@code maxNumSegments=1}, only\n   *  one segment will be left in the index, where that segment\n   *  has no deletions pending nor separate norms, and it is in\n   *  compound file format if the current useCompoundFile\n   *  setting is true.  This method returns multiple merges\n   *  (mergeFactor at a time) so the {@link MergeScheduler}\n   *  in use may make use of concurrency. */\n  @Override\n  public MergeSpecification findMergesForOptimize(SegmentInfos infos,\n      int maxNumSegments, Set<SegmentInfo> segmentsToOptimize) throws IOException {\n\n    assert maxNumSegments > 0;\n    if (verbose()) {\n      message(\"findMergesForOptimize: maxNumSegs=\" + maxNumSegments + \" segsToOptimize= \"+ segmentsToOptimize);\n    }\n\n    // If the segments are already optimized (e.g. there's only 1 segment), or\n    // there are <maxNumSegements, all optimized, nothing to do.\n    if (isOptimized(infos, maxNumSegments, segmentsToOptimize)) {\n      if (verbose()) {\n        message(\"already optimized; skip\");\n      }\n      return null;\n    }\n\n    // Find the newest (rightmost) segment that needs to\n    // be optimized (other segments may have been flushed\n    // since optimize started):\n    int last = infos.size();\n    while (last > 0) {\n      final SegmentInfo info = infos.info(--last);\n      if (segmentsToOptimize.contains(info)) {\n        last++;\n        break;\n      }\n    }\n\n    if (last == 0) {\n      if (verbose()) {\n        message(\"last == 0; skip\");\n      }\n      return null;\n    }\n\n    // There is only one segment already, and it is optimized\n    if (maxNumSegments == 1 && last == 1 && isOptimized(infos.info(0))) {\n      if (verbose()) {\n        message(\"already 1 seg; skip\");\n      }\n      return null;\n    }\n\n    // Check if there are any segments above the threshold\n    boolean anyTooLarge = false;\n    for (int i = 0; i < last; i++) {\n      SegmentInfo info = infos.info(i);\n      if (size(info) > maxMergeSizeForOptimize || sizeDocs(info) > maxMergeDocs) {\n        anyTooLarge = true;\n        break;\n      }\n    }\n\n    if (anyTooLarge) {\n      return findMergesForOptimizeSizeLimit(infos, maxNumSegments, last);\n    } else {\n      return findMergesForOptimizeMaxNumSegments(infos, maxNumSegments, last);\n    }\n  }\n\n","sourceOld":"  /** Returns the merges necessary to optimize the index.\n   *  This merge policy defines \"optimized\" to mean only one\n   *  segment in the index, where that segment has no\n   *  deletions pending nor separate norms, and it is in\n   *  compound file format if the current useCompoundFile\n   *  setting is true.  This method returns multiple merges\n   *  (mergeFactor at a time) so the {@link MergeScheduler}\n   *  in use may make use of concurrency. */\n  @Override\n  public MergeSpecification findMergesForOptimize(SegmentInfos infos,\n      int maxNumSegments, Set<SegmentInfo> segmentsToOptimize) throws IOException {\n\n    assert maxNumSegments > 0;\n    if (verbose()) {\n      message(\"findMergesForOptimize: maxNumSegs=\" + maxNumSegments + \" segsToOptimize= \"+ segmentsToOptimize);\n    }\n\n    // If the segments are already optimized (e.g. there's only 1 segment), or\n    // there are <maxNumSegements, all optimized, nothing to do.\n    if (isOptimized(infos, maxNumSegments, segmentsToOptimize)) {\n      if (verbose()) {\n        message(\"already optimized; skip\");\n      }\n      return null;\n    }\n\n    // Find the newest (rightmost) segment that needs to\n    // be optimized (other segments may have been flushed\n    // since optimize started):\n    int last = infos.size();\n    while (last > 0) {\n      final SegmentInfo info = infos.info(--last);\n      if (segmentsToOptimize.contains(info)) {\n        last++;\n        break;\n      }\n    }\n\n    if (last == 0) {\n      if (verbose()) {\n        message(\"last == 0; skip\");\n      }\n      return null;\n    }\n\n    // There is only one segment already, and it is optimized\n    if (maxNumSegments == 1 && last == 1 && isOptimized(infos.info(0))) {\n      if (verbose()) {\n        message(\"already 1 seg; skip\");\n      }\n      return null;\n    }\n\n    // Check if there are any segments above the threshold\n    boolean anyTooLarge = false;\n    for (int i = 0; i < last; i++) {\n      SegmentInfo info = infos.info(i);\n      if (size(info) > maxMergeSize || sizeDocs(info) > maxMergeDocs) {\n        anyTooLarge = true;\n        break;\n      }\n    }\n\n    if (anyTooLarge) {\n      return findMergesForOptimizeSizeLimit(infos, maxNumSegments, last);\n    } else {\n      return findMergesForOptimizeMaxNumSegments(infos, maxNumSegments, last);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c19f985e36a65cc969e8e564fe337a0d41512075","date":1296330536,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/LogMergePolicy#findMergesForOptimize(SegmentInfos,int,Set[SegmentInfo]).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/LogMergePolicy#findMergesForOptimize(SegmentInfos,int,Set[SegmentInfo]).mjava","sourceNew":"  /** Returns the merges necessary to optimize the index.\n   *  This merge policy defines \"optimized\" to mean only the\n   *  requested number of segments is left in the index, and\n   *  respects the {@link #maxMergeSizeForOptimize} setting.\n   *  By default, and assuming {@code maxNumSegments=1}, only\n   *  one segment will be left in the index, where that segment\n   *  has no deletions pending nor separate norms, and it is in\n   *  compound file format if the current useCompoundFile\n   *  setting is true.  This method returns multiple merges\n   *  (mergeFactor at a time) so the {@link MergeScheduler}\n   *  in use may make use of concurrency. */\n  @Override\n  public MergeSpecification findMergesForOptimize(SegmentInfos infos,\n      int maxNumSegments, Set<SegmentInfo> segmentsToOptimize) throws IOException {\n\n    assert maxNumSegments > 0;\n    if (verbose()) {\n      message(\"findMergesForOptimize: maxNumSegs=\" + maxNumSegments + \" segsToOptimize= \"+ segmentsToOptimize);\n    }\n\n    // If the segments are already optimized (e.g. there's only 1 segment), or\n    // there are <maxNumSegements, all optimized, nothing to do.\n    if (isOptimized(infos, maxNumSegments, segmentsToOptimize)) {\n      if (verbose()) {\n        message(\"already optimized; skip\");\n      }\n      return null;\n    }\n\n    // TODO: handle non-contiguous merge case differently?\n    \n    // Find the newest (rightmost) segment that needs to\n    // be optimized (other segments may have been flushed\n    // since optimize started):\n    int last = infos.size();\n    while (last > 0) {\n      final SegmentInfo info = infos.info(--last);\n      if (segmentsToOptimize.contains(info)) {\n        last++;\n        break;\n      }\n    }\n\n    if (last == 0) {\n      if (verbose()) {\n        message(\"last == 0; skip\");\n      }\n      return null;\n    }\n    \n    // There is only one segment already, and it is optimized\n    if (maxNumSegments == 1 && last == 1 && isOptimized(infos.info(0))) {\n      if (verbose()) {\n        message(\"already 1 seg; skip\");\n      }\n      return null;\n    }\n\n    // Check if there are any segments above the threshold\n    boolean anyTooLarge = false;\n    for (int i = 0; i < last; i++) {\n      SegmentInfo info = infos.info(i);\n      if (size(info) > maxMergeSizeForOptimize || sizeDocs(info) > maxMergeDocs) {\n        anyTooLarge = true;\n        break;\n      }\n    }\n    \n    if (anyTooLarge) {\n      return findMergesForOptimizeSizeLimit(infos, maxNumSegments, last);\n    } else {\n      return findMergesForOptimizeMaxNumSegments(infos, maxNumSegments, last);\n    }\n  }\n\n","sourceOld":"  /** Returns the merges necessary to optimize the index.\n   *  This merge policy defines \"optimized\" to mean only the\n   *  requested number of segments is left in the index, and\n   *  respects the {@link #maxMergeSizeForOptimize} setting.\n   *  By default, and assuming {@code maxNumSegments=1}, only\n   *  one segment will be left in the index, where that segment\n   *  has no deletions pending nor separate norms, and it is in\n   *  compound file format if the current useCompoundFile\n   *  setting is true.  This method returns multiple merges\n   *  (mergeFactor at a time) so the {@link MergeScheduler}\n   *  in use may make use of concurrency. */\n  @Override\n  public MergeSpecification findMergesForOptimize(SegmentInfos infos,\n      int maxNumSegments, Set<SegmentInfo> segmentsToOptimize) throws IOException {\n\n    assert maxNumSegments > 0;\n    if (verbose()) {\n      message(\"findMergesForOptimize: maxNumSegs=\" + maxNumSegments + \" segsToOptimize= \"+ segmentsToOptimize);\n    }\n\n    // If the segments are already optimized (e.g. there's only 1 segment), or\n    // there are <maxNumSegements, all optimized, nothing to do.\n    if (isOptimized(infos, maxNumSegments, segmentsToOptimize)) {\n      if (verbose()) {\n        message(\"already optimized; skip\");\n      }\n      return null;\n    }\n    \n    // Find the newest (rightmost) segment that needs to\n    // be optimized (other segments may have been flushed\n    // since optimize started):\n    int last = infos.size();\n    while (last > 0) {\n      final SegmentInfo info = infos.info(--last);\n      if (segmentsToOptimize.contains(info)) {\n        last++;\n        break;\n      }\n    }\n\n    if (last == 0) {\n      if (verbose()) {\n        message(\"last == 0; skip\");\n      }\n      return null;\n    }\n    \n    // There is only one segment already, and it is optimized\n    if (maxNumSegments == 1 && last == 1 && isOptimized(infos.info(0))) {\n      if (verbose()) {\n        message(\"already 1 seg; skip\");\n      }\n      return null;\n    }\n\n    // Check if there are any segments above the threshold\n    boolean anyTooLarge = false;\n    for (int i = 0; i < last; i++) {\n      SegmentInfo info = infos.info(i);\n      if (size(info) > maxMergeSizeForOptimize || sizeDocs(info) > maxMergeDocs) {\n        anyTooLarge = true;\n        break;\n      }\n    }\n    \n    if (anyTooLarge) {\n      return findMergesForOptimizeSizeLimit(infos, maxNumSegments, last);\n    } else {\n      return findMergesForOptimizeMaxNumSegments(infos, maxNumSegments, last);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/LogMergePolicy#findMergesForOptimize(SegmentInfos,int,Set[SegmentInfo]).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/LogMergePolicy#findMergesForOptimize(SegmentInfos,int,Set[SegmentInfo]).mjava","sourceNew":"  /** Returns the merges necessary to optimize the index.\n   *  This merge policy defines \"optimized\" to mean only the\n   *  requested number of segments is left in the index, and\n   *  respects the {@link #maxMergeSizeForOptimize} setting.\n   *  By default, and assuming {@code maxNumSegments=1}, only\n   *  one segment will be left in the index, where that segment\n   *  has no deletions pending nor separate norms, and it is in\n   *  compound file format if the current useCompoundFile\n   *  setting is true.  This method returns multiple merges\n   *  (mergeFactor at a time) so the {@link MergeScheduler}\n   *  in use may make use of concurrency. */\n  @Override\n  public MergeSpecification findMergesForOptimize(SegmentInfos infos,\n      int maxNumSegments, Set<SegmentInfo> segmentsToOptimize) throws IOException {\n\n    assert maxNumSegments > 0;\n    if (verbose()) {\n      message(\"findMergesForOptimize: maxNumSegs=\" + maxNumSegments + \" segsToOptimize= \"+ segmentsToOptimize);\n    }\n\n    // If the segments are already optimized (e.g. there's only 1 segment), or\n    // there are <maxNumSegements, all optimized, nothing to do.\n    if (isOptimized(infos, maxNumSegments, segmentsToOptimize)) {\n      if (verbose()) {\n        message(\"already optimized; skip\");\n      }\n      return null;\n    }\n\n    // TODO: handle non-contiguous merge case differently?\n    \n    // Find the newest (rightmost) segment that needs to\n    // be optimized (other segments may have been flushed\n    // since optimize started):\n    int last = infos.size();\n    while (last > 0) {\n      final SegmentInfo info = infos.info(--last);\n      if (segmentsToOptimize.contains(info)) {\n        last++;\n        break;\n      }\n    }\n\n    if (last == 0) {\n      if (verbose()) {\n        message(\"last == 0; skip\");\n      }\n      return null;\n    }\n    \n    // There is only one segment already, and it is optimized\n    if (maxNumSegments == 1 && last == 1 && isOptimized(infos.info(0))) {\n      if (verbose()) {\n        message(\"already 1 seg; skip\");\n      }\n      return null;\n    }\n\n    // Check if there are any segments above the threshold\n    boolean anyTooLarge = false;\n    for (int i = 0; i < last; i++) {\n      SegmentInfo info = infos.info(i);\n      if (size(info) > maxMergeSizeForOptimize || sizeDocs(info) > maxMergeDocs) {\n        anyTooLarge = true;\n        break;\n      }\n    }\n    \n    if (anyTooLarge) {\n      return findMergesForOptimizeSizeLimit(infos, maxNumSegments, last);\n    } else {\n      return findMergesForOptimizeMaxNumSegments(infos, maxNumSegments, last);\n    }\n  }\n\n","sourceOld":"  /** Returns the merges necessary to optimize the index.\n   *  This merge policy defines \"optimized\" to mean only one\n   *  segment in the index, where that segment has no\n   *  deletions pending nor separate norms, and it is in\n   *  compound file format if the current useCompoundFile\n   *  setting is true.  This method returns multiple merges\n   *  (mergeFactor at a time) so the {@link MergeScheduler}\n   *  in use may make use of concurrency. */\n  @Override\n  public MergeSpecification findMergesForOptimize(SegmentInfos infos,\n      int maxNumSegments, Set<SegmentInfo> segmentsToOptimize) throws IOException {\n\n    assert maxNumSegments > 0;\n    if (verbose()) {\n      message(\"findMergesForOptimize: maxNumSegs=\" + maxNumSegments + \" segsToOptimize= \"+ segmentsToOptimize);\n    }\n\n    // If the segments are already optimized (e.g. there's only 1 segment), or\n    // there are <maxNumSegements, all optimized, nothing to do.\n    if (isOptimized(infos, maxNumSegments, segmentsToOptimize)) {\n      if (verbose()) {\n        message(\"already optimized; skip\");\n      }\n      return null;\n    }\n    \n    // Find the newest (rightmost) segment that needs to\n    // be optimized (other segments may have been flushed\n    // since optimize started):\n    int last = infos.size();\n    while (last > 0) {\n      final SegmentInfo info = infos.info(--last);\n      if (segmentsToOptimize.contains(info)) {\n        last++;\n        break;\n      }\n    }\n\n    if (last == 0) {\n      if (verbose()) {\n        message(\"last == 0; skip\");\n      }\n      return null;\n    }\n    \n    // There is only one segment already, and it is optimized\n    if (maxNumSegments == 1 && last == 1 && isOptimized(infos.info(0))) {\n      if (verbose()) {\n        message(\"already 1 seg; skip\");\n      }\n      return null;\n    }\n\n    // Check if there are any segments above the threshold\n    boolean anyTooLarge = false;\n    for (int i = 0; i < last; i++) {\n      SegmentInfo info = infos.info(i);\n      if (size(info) > maxMergeSize || sizeDocs(info) > maxMergeDocs) {\n        anyTooLarge = true;\n        break;\n      }\n    }\n    \n    if (anyTooLarge) {\n      return findMergesForOptimizeSizeLimit(infos, maxNumSegments, last);\n    } else {\n      return findMergesForOptimizeMaxNumSegments(infos, maxNumSegments, last);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bde51b089eb7f86171eb3406e38a274743f9b7ac","date":1298336439,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/LogMergePolicy#findMergesForOptimize(SegmentInfos,int,Set[SegmentInfo]).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/LogMergePolicy#findMergesForOptimize(SegmentInfos,int,Set[SegmentInfo]).mjava","sourceNew":"  /** Returns the merges necessary to optimize the index.\n   *  This merge policy defines \"optimized\" to mean only the\n   *  requested number of segments is left in the index, and\n   *  respects the {@link #maxMergeSizeForOptimize} setting.\n   *  By default, and assuming {@code maxNumSegments=1}, only\n   *  one segment will be left in the index, where that segment\n   *  has no deletions pending nor separate norms, and it is in\n   *  compound file format if the current useCompoundFile\n   *  setting is true.  This method returns multiple merges\n   *  (mergeFactor at a time) so the {@link MergeScheduler}\n   *  in use may make use of concurrency. */\n  @Override\n  public MergeSpecification findMergesForOptimize(SegmentInfos infos,\n      int maxNumSegments, Set<SegmentInfo> segmentsToOptimize) throws IOException {\n\n    assert maxNumSegments > 0;\n    if (verbose()) {\n      message(\"findMergesForOptimize: maxNumSegs=\" + maxNumSegments + \" segsToOptimize= \"+ segmentsToOptimize);\n    }\n\n    // If the segments are already optimized (e.g. there's only 1 segment), or\n    // there are <maxNumSegements, all optimized, nothing to do.\n    if (isOptimized(infos, maxNumSegments, segmentsToOptimize)) {\n      if (verbose()) {\n        message(\"already optimized; skip\");\n      }\n      return null;\n    }\n\n    // TODO: handle non-contiguous merge case differently?\n\n    // Find the newest (rightmost) segment that needs to\n    // be optimized (other segments may have been flushed\n    // since optimize started):\n    int last = infos.size();\n    while (last > 0) {\n      final SegmentInfo info = infos.info(--last);\n      if (segmentsToOptimize.contains(info)) {\n        last++;\n        break;\n      }\n    }\n\n    if (last == 0) {\n      if (verbose()) {\n        message(\"last == 0; skip\");\n      }\n      return null;\n    }\n\n    // There is only one segment already, and it is optimized\n    if (maxNumSegments == 1 && last == 1 && isOptimized(infos.info(0))) {\n      if (verbose()) {\n        message(\"already 1 seg; skip\");\n      }\n      return null;\n    }\n\n    // Check if there are any segments above the threshold\n    boolean anyTooLarge = false;\n    for (int i = 0; i < last; i++) {\n      SegmentInfo info = infos.info(i);\n      if (size(info) > maxMergeSizeForOptimize || sizeDocs(info) > maxMergeDocs) {\n        anyTooLarge = true;\n        break;\n      }\n    }\n\n    if (anyTooLarge) {\n      return findMergesForOptimizeSizeLimit(infos, maxNumSegments, last);\n    } else {\n      return findMergesForOptimizeMaxNumSegments(infos, maxNumSegments, last);\n    }\n  }\n\n","sourceOld":"  /** Returns the merges necessary to optimize the index.\n   *  This merge policy defines \"optimized\" to mean only the\n   *  requested number of segments is left in the index, and\n   *  respects the {@link #maxMergeSizeForOptimize} setting.\n   *  By default, and assuming {@code maxNumSegments=1}, only\n   *  one segment will be left in the index, where that segment\n   *  has no deletions pending nor separate norms, and it is in\n   *  compound file format if the current useCompoundFile\n   *  setting is true.  This method returns multiple merges\n   *  (mergeFactor at a time) so the {@link MergeScheduler}\n   *  in use may make use of concurrency. */\n  @Override\n  public MergeSpecification findMergesForOptimize(SegmentInfos infos,\n      int maxNumSegments, Set<SegmentInfo> segmentsToOptimize) throws IOException {\n\n    assert maxNumSegments > 0;\n    if (verbose()) {\n      message(\"findMergesForOptimize: maxNumSegs=\" + maxNumSegments + \" segsToOptimize= \"+ segmentsToOptimize);\n    }\n\n    // If the segments are already optimized (e.g. there's only 1 segment), or\n    // there are <maxNumSegements, all optimized, nothing to do.\n    if (isOptimized(infos, maxNumSegments, segmentsToOptimize)) {\n      if (verbose()) {\n        message(\"already optimized; skip\");\n      }\n      return null;\n    }\n\n    // Find the newest (rightmost) segment that needs to\n    // be optimized (other segments may have been flushed\n    // since optimize started):\n    int last = infos.size();\n    while (last > 0) {\n      final SegmentInfo info = infos.info(--last);\n      if (segmentsToOptimize.contains(info)) {\n        last++;\n        break;\n      }\n    }\n\n    if (last == 0) {\n      if (verbose()) {\n        message(\"last == 0; skip\");\n      }\n      return null;\n    }\n\n    // There is only one segment already, and it is optimized\n    if (maxNumSegments == 1 && last == 1 && isOptimized(infos.info(0))) {\n      if (verbose()) {\n        message(\"already 1 seg; skip\");\n      }\n      return null;\n    }\n\n    // Check if there are any segments above the threshold\n    boolean anyTooLarge = false;\n    for (int i = 0; i < last; i++) {\n      SegmentInfo info = infos.info(i);\n      if (size(info) > maxMergeSizeForOptimize || sizeDocs(info) > maxMergeDocs) {\n        anyTooLarge = true;\n        break;\n      }\n    }\n\n    if (anyTooLarge) {\n      return findMergesForOptimizeSizeLimit(infos, maxNumSegments, last);\n    } else {\n      return findMergesForOptimizeMaxNumSegments(infos, maxNumSegments, last);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"01e5948db9a07144112d2f08f28ca2e3cd880348","date":1301759232,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/LogMergePolicy#findMergesForOptimize(SegmentInfos,int,Set[SegmentInfo]).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/LogMergePolicy#findMergesForOptimize(SegmentInfos,int,Set[SegmentInfo]).mjava","sourceNew":"  /** Returns the merges necessary to optimize the index.\n   *  This merge policy defines \"optimized\" to mean only the\n   *  requested number of segments is left in the index, and\n   *  respects the {@link #maxMergeSizeForOptimize} setting.\n   *  By default, and assuming {@code maxNumSegments=1}, only\n   *  one segment will be left in the index, where that segment\n   *  has no deletions pending nor separate norms, and it is in\n   *  compound file format if the current useCompoundFile\n   *  setting is true.  This method returns multiple merges\n   *  (mergeFactor at a time) so the {@link MergeScheduler}\n   *  in use may make use of concurrency. */\n  @Override\n  public MergeSpecification findMergesForOptimize(SegmentInfos infos,\n      int maxNumSegments, Set<SegmentInfo> segmentsToOptimize) throws IOException {\n\n    assert maxNumSegments > 0;\n    if (verbose()) {\n      message(\"findMergesForOptimize: maxNumSegs=\" + maxNumSegments + \" segsToOptimize= \"+ segmentsToOptimize);\n    }\n\n    // If the segments are already optimized (e.g. there's only 1 segment), or\n    // there are <maxNumSegements, all optimized, nothing to do.\n    if (isOptimized(infos, maxNumSegments, segmentsToOptimize)) {\n      if (verbose()) {\n        message(\"already optimized; skip\");\n      }\n      return null;\n    }\n\n    // Find the newest (rightmost) segment that needs to\n    // be optimized (other segments may have been flushed\n    // since optimize started):\n    int last = infos.size();\n    while (last > 0) {\n      final SegmentInfo info = infos.info(--last);\n      if (segmentsToOptimize.contains(info)) {\n        last++;\n        break;\n      }\n    }\n\n    if (last == 0) {\n      if (verbose()) {\n        message(\"last == 0; skip\");\n      }\n      return null;\n    }\n    \n    // There is only one segment already, and it is optimized\n    if (maxNumSegments == 1 && last == 1 && isOptimized(infos.info(0))) {\n      if (verbose()) {\n        message(\"already 1 seg; skip\");\n      }\n      return null;\n    }\n\n    // Check if there are any segments above the threshold\n    boolean anyTooLarge = false;\n    for (int i = 0; i < last; i++) {\n      SegmentInfo info = infos.info(i);\n      if (size(info) > maxMergeSizeForOptimize || sizeDocs(info) > maxMergeDocs) {\n        anyTooLarge = true;\n        break;\n      }\n    }\n    \n    if (anyTooLarge) {\n      return findMergesForOptimizeSizeLimit(infos, maxNumSegments, last);\n    } else {\n      return findMergesForOptimizeMaxNumSegments(infos, maxNumSegments, last);\n    }\n  }\n\n","sourceOld":"  /** Returns the merges necessary to optimize the index.\n   *  This merge policy defines \"optimized\" to mean only the\n   *  requested number of segments is left in the index, and\n   *  respects the {@link #maxMergeSizeForOptimize} setting.\n   *  By default, and assuming {@code maxNumSegments=1}, only\n   *  one segment will be left in the index, where that segment\n   *  has no deletions pending nor separate norms, and it is in\n   *  compound file format if the current useCompoundFile\n   *  setting is true.  This method returns multiple merges\n   *  (mergeFactor at a time) so the {@link MergeScheduler}\n   *  in use may make use of concurrency. */\n  @Override\n  public MergeSpecification findMergesForOptimize(SegmentInfos infos,\n      int maxNumSegments, Set<SegmentInfo> segmentsToOptimize) throws IOException {\n\n    assert maxNumSegments > 0;\n    if (verbose()) {\n      message(\"findMergesForOptimize: maxNumSegs=\" + maxNumSegments + \" segsToOptimize= \"+ segmentsToOptimize);\n    }\n\n    // If the segments are already optimized (e.g. there's only 1 segment), or\n    // there are <maxNumSegements, all optimized, nothing to do.\n    if (isOptimized(infos, maxNumSegments, segmentsToOptimize)) {\n      if (verbose()) {\n        message(\"already optimized; skip\");\n      }\n      return null;\n    }\n\n    // TODO: handle non-contiguous merge case differently?\n    \n    // Find the newest (rightmost) segment that needs to\n    // be optimized (other segments may have been flushed\n    // since optimize started):\n    int last = infos.size();\n    while (last > 0) {\n      final SegmentInfo info = infos.info(--last);\n      if (segmentsToOptimize.contains(info)) {\n        last++;\n        break;\n      }\n    }\n\n    if (last == 0) {\n      if (verbose()) {\n        message(\"last == 0; skip\");\n      }\n      return null;\n    }\n    \n    // There is only one segment already, and it is optimized\n    if (maxNumSegments == 1 && last == 1 && isOptimized(infos.info(0))) {\n      if (verbose()) {\n        message(\"already 1 seg; skip\");\n      }\n      return null;\n    }\n\n    // Check if there are any segments above the threshold\n    boolean anyTooLarge = false;\n    for (int i = 0; i < last; i++) {\n      SegmentInfo info = infos.info(i);\n      if (size(info) > maxMergeSizeForOptimize || sizeDocs(info) > maxMergeDocs) {\n        anyTooLarge = true;\n        break;\n      }\n    }\n    \n    if (anyTooLarge) {\n      return findMergesForOptimizeSizeLimit(infos, maxNumSegments, last);\n    } else {\n      return findMergesForOptimizeMaxNumSegments(infos, maxNumSegments, last);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"45669a651c970812a680841b97a77cce06af559f","date":1301922222,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/LogMergePolicy#findMergesForOptimize(SegmentInfos,int,Set[SegmentInfo]).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/LogMergePolicy#findMergesForOptimize(SegmentInfos,int,Set[SegmentInfo]).mjava","sourceNew":"  /** Returns the merges necessary to optimize the index.\n   *  This merge policy defines \"optimized\" to mean only the\n   *  requested number of segments is left in the index, and\n   *  respects the {@link #maxMergeSizeForOptimize} setting.\n   *  By default, and assuming {@code maxNumSegments=1}, only\n   *  one segment will be left in the index, where that segment\n   *  has no deletions pending nor separate norms, and it is in\n   *  compound file format if the current useCompoundFile\n   *  setting is true.  This method returns multiple merges\n   *  (mergeFactor at a time) so the {@link MergeScheduler}\n   *  in use may make use of concurrency. */\n  @Override\n  public MergeSpecification findMergesForOptimize(SegmentInfos infos,\n      int maxNumSegments, Set<SegmentInfo> segmentsToOptimize) throws IOException {\n\n    assert maxNumSegments > 0;\n    if (verbose()) {\n      message(\"findMergesForOptimize: maxNumSegs=\" + maxNumSegments + \" segsToOptimize= \"+ segmentsToOptimize);\n    }\n\n    // If the segments are already optimized (e.g. there's only 1 segment), or\n    // there are <maxNumSegements, all optimized, nothing to do.\n    if (isOptimized(infos, maxNumSegments, segmentsToOptimize)) {\n      if (verbose()) {\n        message(\"already optimized; skip\");\n      }\n      return null;\n    }\n\n    // Find the newest (rightmost) segment that needs to\n    // be optimized (other segments may have been flushed\n    // since optimize started):\n    int last = infos.size();\n    while (last > 0) {\n      final SegmentInfo info = infos.info(--last);\n      if (segmentsToOptimize.contains(info)) {\n        last++;\n        break;\n      }\n    }\n\n    if (last == 0) {\n      if (verbose()) {\n        message(\"last == 0; skip\");\n      }\n      return null;\n    }\n\n    // There is only one segment already, and it is optimized\n    if (maxNumSegments == 1 && last == 1 && isOptimized(infos.info(0))) {\n      if (verbose()) {\n        message(\"already 1 seg; skip\");\n      }\n      return null;\n    }\n\n    // Check if there are any segments above the threshold\n    boolean anyTooLarge = false;\n    for (int i = 0; i < last; i++) {\n      SegmentInfo info = infos.info(i);\n      if (size(info) > maxMergeSizeForOptimize || sizeDocs(info) > maxMergeDocs) {\n        anyTooLarge = true;\n        break;\n      }\n    }\n\n    if (anyTooLarge) {\n      return findMergesForOptimizeSizeLimit(infos, maxNumSegments, last);\n    } else {\n      return findMergesForOptimizeMaxNumSegments(infos, maxNumSegments, last);\n    }\n  }\n\n","sourceOld":"  /** Returns the merges necessary to optimize the index.\n   *  This merge policy defines \"optimized\" to mean only the\n   *  requested number of segments is left in the index, and\n   *  respects the {@link #maxMergeSizeForOptimize} setting.\n   *  By default, and assuming {@code maxNumSegments=1}, only\n   *  one segment will be left in the index, where that segment\n   *  has no deletions pending nor separate norms, and it is in\n   *  compound file format if the current useCompoundFile\n   *  setting is true.  This method returns multiple merges\n   *  (mergeFactor at a time) so the {@link MergeScheduler}\n   *  in use may make use of concurrency. */\n  @Override\n  public MergeSpecification findMergesForOptimize(SegmentInfos infos,\n      int maxNumSegments, Set<SegmentInfo> segmentsToOptimize) throws IOException {\n\n    assert maxNumSegments > 0;\n    if (verbose()) {\n      message(\"findMergesForOptimize: maxNumSegs=\" + maxNumSegments + \" segsToOptimize= \"+ segmentsToOptimize);\n    }\n\n    // If the segments are already optimized (e.g. there's only 1 segment), or\n    // there are <maxNumSegements, all optimized, nothing to do.\n    if (isOptimized(infos, maxNumSegments, segmentsToOptimize)) {\n      if (verbose()) {\n        message(\"already optimized; skip\");\n      }\n      return null;\n    }\n\n    // TODO: handle non-contiguous merge case differently?\n\n    // Find the newest (rightmost) segment that needs to\n    // be optimized (other segments may have been flushed\n    // since optimize started):\n    int last = infos.size();\n    while (last > 0) {\n      final SegmentInfo info = infos.info(--last);\n      if (segmentsToOptimize.contains(info)) {\n        last++;\n        break;\n      }\n    }\n\n    if (last == 0) {\n      if (verbose()) {\n        message(\"last == 0; skip\");\n      }\n      return null;\n    }\n\n    // There is only one segment already, and it is optimized\n    if (maxNumSegments == 1 && last == 1 && isOptimized(infos.info(0))) {\n      if (verbose()) {\n        message(\"already 1 seg; skip\");\n      }\n      return null;\n    }\n\n    // Check if there are any segments above the threshold\n    boolean anyTooLarge = false;\n    for (int i = 0; i < last; i++) {\n      SegmentInfo info = infos.info(i);\n      if (size(info) > maxMergeSizeForOptimize || sizeDocs(info) > maxMergeDocs) {\n        anyTooLarge = true;\n        break;\n      }\n    }\n\n    if (anyTooLarge) {\n      return findMergesForOptimizeSizeLimit(infos, maxNumSegments, last);\n    } else {\n      return findMergesForOptimizeMaxNumSegments(infos, maxNumSegments, last);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/LogMergePolicy#findMergesForOptimize(SegmentInfos,int,Set[SegmentInfo]).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/LogMergePolicy#findMergesForOptimize(SegmentInfos,int,Set[SegmentInfo]).mjava","sourceNew":"  /** Returns the merges necessary to optimize the index.\n   *  This merge policy defines \"optimized\" to mean only the\n   *  requested number of segments is left in the index, and\n   *  respects the {@link #maxMergeSizeForOptimize} setting.\n   *  By default, and assuming {@code maxNumSegments=1}, only\n   *  one segment will be left in the index, where that segment\n   *  has no deletions pending nor separate norms, and it is in\n   *  compound file format if the current useCompoundFile\n   *  setting is true.  This method returns multiple merges\n   *  (mergeFactor at a time) so the {@link MergeScheduler}\n   *  in use may make use of concurrency. */\n  @Override\n  public MergeSpecification findMergesForOptimize(SegmentInfos infos,\n      int maxNumSegments, Set<SegmentInfo> segmentsToOptimize) throws IOException {\n\n    assert maxNumSegments > 0;\n    if (verbose()) {\n      message(\"findMergesForOptimize: maxNumSegs=\" + maxNumSegments + \" segsToOptimize= \"+ segmentsToOptimize);\n    }\n\n    // If the segments are already optimized (e.g. there's only 1 segment), or\n    // there are <maxNumSegements, all optimized, nothing to do.\n    if (isOptimized(infos, maxNumSegments, segmentsToOptimize)) {\n      if (verbose()) {\n        message(\"already optimized; skip\");\n      }\n      return null;\n    }\n\n    // Find the newest (rightmost) segment that needs to\n    // be optimized (other segments may have been flushed\n    // since optimize started):\n    int last = infos.size();\n    while (last > 0) {\n      final SegmentInfo info = infos.info(--last);\n      if (segmentsToOptimize.contains(info)) {\n        last++;\n        break;\n      }\n    }\n\n    if (last == 0) {\n      if (verbose()) {\n        message(\"last == 0; skip\");\n      }\n      return null;\n    }\n    \n    // There is only one segment already, and it is optimized\n    if (maxNumSegments == 1 && last == 1 && isOptimized(infos.info(0))) {\n      if (verbose()) {\n        message(\"already 1 seg; skip\");\n      }\n      return null;\n    }\n\n    // Check if there are any segments above the threshold\n    boolean anyTooLarge = false;\n    for (int i = 0; i < last; i++) {\n      SegmentInfo info = infos.info(i);\n      if (size(info) > maxMergeSizeForOptimize || sizeDocs(info) > maxMergeDocs) {\n        anyTooLarge = true;\n        break;\n      }\n    }\n    \n    if (anyTooLarge) {\n      return findMergesForOptimizeSizeLimit(infos, maxNumSegments, last);\n    } else {\n      return findMergesForOptimizeMaxNumSegments(infos, maxNumSegments, last);\n    }\n  }\n\n","sourceOld":"  /** Returns the merges necessary to optimize the index.\n   *  This merge policy defines \"optimized\" to mean only the\n   *  requested number of segments is left in the index, and\n   *  respects the {@link #maxMergeSizeForOptimize} setting.\n   *  By default, and assuming {@code maxNumSegments=1}, only\n   *  one segment will be left in the index, where that segment\n   *  has no deletions pending nor separate norms, and it is in\n   *  compound file format if the current useCompoundFile\n   *  setting is true.  This method returns multiple merges\n   *  (mergeFactor at a time) so the {@link MergeScheduler}\n   *  in use may make use of concurrency. */\n  @Override\n  public MergeSpecification findMergesForOptimize(SegmentInfos infos,\n      int maxNumSegments, Set<SegmentInfo> segmentsToOptimize) throws IOException {\n\n    assert maxNumSegments > 0;\n    if (verbose()) {\n      message(\"findMergesForOptimize: maxNumSegs=\" + maxNumSegments + \" segsToOptimize= \"+ segmentsToOptimize);\n    }\n\n    // If the segments are already optimized (e.g. there's only 1 segment), or\n    // there are <maxNumSegements, all optimized, nothing to do.\n    if (isOptimized(infos, maxNumSegments, segmentsToOptimize)) {\n      if (verbose()) {\n        message(\"already optimized; skip\");\n      }\n      return null;\n    }\n\n    // TODO: handle non-contiguous merge case differently?\n    \n    // Find the newest (rightmost) segment that needs to\n    // be optimized (other segments may have been flushed\n    // since optimize started):\n    int last = infos.size();\n    while (last > 0) {\n      final SegmentInfo info = infos.info(--last);\n      if (segmentsToOptimize.contains(info)) {\n        last++;\n        break;\n      }\n    }\n\n    if (last == 0) {\n      if (verbose()) {\n        message(\"last == 0; skip\");\n      }\n      return null;\n    }\n    \n    // There is only one segment already, and it is optimized\n    if (maxNumSegments == 1 && last == 1 && isOptimized(infos.info(0))) {\n      if (verbose()) {\n        message(\"already 1 seg; skip\");\n      }\n      return null;\n    }\n\n    // Check if there are any segments above the threshold\n    boolean anyTooLarge = false;\n    for (int i = 0; i < last; i++) {\n      SegmentInfo info = infos.info(i);\n      if (size(info) > maxMergeSizeForOptimize || sizeDocs(info) > maxMergeDocs) {\n        anyTooLarge = true;\n        break;\n      }\n    }\n    \n    if (anyTooLarge) {\n      return findMergesForOptimizeSizeLimit(infos, maxNumSegments, last);\n    } else {\n      return findMergesForOptimizeMaxNumSegments(infos, maxNumSegments, last);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/LogMergePolicy#findMergesForOptimize(SegmentInfos,int,Set[SegmentInfo]).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/LogMergePolicy#findMergesForOptimize(SegmentInfos,int,Set[SegmentInfo]).mjava","sourceNew":"  /** Returns the merges necessary to optimize the index.\n   *  This merge policy defines \"optimized\" to mean only the\n   *  requested number of segments is left in the index, and\n   *  respects the {@link #maxMergeSizeForOptimize} setting.\n   *  By default, and assuming {@code maxNumSegments=1}, only\n   *  one segment will be left in the index, where that segment\n   *  has no deletions pending nor separate norms, and it is in\n   *  compound file format if the current useCompoundFile\n   *  setting is true.  This method returns multiple merges\n   *  (mergeFactor at a time) so the {@link MergeScheduler}\n   *  in use may make use of concurrency. */\n  @Override\n  public MergeSpecification findMergesForOptimize(SegmentInfos infos,\n      int maxNumSegments, Set<SegmentInfo> segmentsToOptimize) throws IOException {\n\n    assert maxNumSegments > 0;\n    if (verbose()) {\n      message(\"findMergesForOptimize: maxNumSegs=\" + maxNumSegments + \" segsToOptimize= \"+ segmentsToOptimize);\n    }\n\n    // If the segments are already optimized (e.g. there's only 1 segment), or\n    // there are <maxNumSegements, all optimized, nothing to do.\n    if (isOptimized(infos, maxNumSegments, segmentsToOptimize)) {\n      if (verbose()) {\n        message(\"already optimized; skip\");\n      }\n      return null;\n    }\n\n    // Find the newest (rightmost) segment that needs to\n    // be optimized (other segments may have been flushed\n    // since optimize started):\n    int last = infos.size();\n    while (last > 0) {\n      final SegmentInfo info = infos.info(--last);\n      if (segmentsToOptimize.contains(info)) {\n        last++;\n        break;\n      }\n    }\n\n    if (last == 0) {\n      if (verbose()) {\n        message(\"last == 0; skip\");\n      }\n      return null;\n    }\n    \n    // There is only one segment already, and it is optimized\n    if (maxNumSegments == 1 && last == 1 && isOptimized(infos.info(0))) {\n      if (verbose()) {\n        message(\"already 1 seg; skip\");\n      }\n      return null;\n    }\n\n    // Check if there are any segments above the threshold\n    boolean anyTooLarge = false;\n    for (int i = 0; i < last; i++) {\n      SegmentInfo info = infos.info(i);\n      if (size(info) > maxMergeSizeForOptimize || sizeDocs(info) > maxMergeDocs) {\n        anyTooLarge = true;\n        break;\n      }\n    }\n    \n    if (anyTooLarge) {\n      return findMergesForOptimizeSizeLimit(infos, maxNumSegments, last);\n    } else {\n      return findMergesForOptimizeMaxNumSegments(infos, maxNumSegments, last);\n    }\n  }\n\n","sourceOld":"  /** Returns the merges necessary to optimize the index.\n   *  This merge policy defines \"optimized\" to mean only the\n   *  requested number of segments is left in the index, and\n   *  respects the {@link #maxMergeSizeForOptimize} setting.\n   *  By default, and assuming {@code maxNumSegments=1}, only\n   *  one segment will be left in the index, where that segment\n   *  has no deletions pending nor separate norms, and it is in\n   *  compound file format if the current useCompoundFile\n   *  setting is true.  This method returns multiple merges\n   *  (mergeFactor at a time) so the {@link MergeScheduler}\n   *  in use may make use of concurrency. */\n  @Override\n  public MergeSpecification findMergesForOptimize(SegmentInfos infos,\n      int maxNumSegments, Set<SegmentInfo> segmentsToOptimize) throws IOException {\n\n    assert maxNumSegments > 0;\n    if (verbose()) {\n      message(\"findMergesForOptimize: maxNumSegs=\" + maxNumSegments + \" segsToOptimize= \"+ segmentsToOptimize);\n    }\n\n    // If the segments are already optimized (e.g. there's only 1 segment), or\n    // there are <maxNumSegements, all optimized, nothing to do.\n    if (isOptimized(infos, maxNumSegments, segmentsToOptimize)) {\n      if (verbose()) {\n        message(\"already optimized; skip\");\n      }\n      return null;\n    }\n\n    // TODO: handle non-contiguous merge case differently?\n    \n    // Find the newest (rightmost) segment that needs to\n    // be optimized (other segments may have been flushed\n    // since optimize started):\n    int last = infos.size();\n    while (last > 0) {\n      final SegmentInfo info = infos.info(--last);\n      if (segmentsToOptimize.contains(info)) {\n        last++;\n        break;\n      }\n    }\n\n    if (last == 0) {\n      if (verbose()) {\n        message(\"last == 0; skip\");\n      }\n      return null;\n    }\n    \n    // There is only one segment already, and it is optimized\n    if (maxNumSegments == 1 && last == 1 && isOptimized(infos.info(0))) {\n      if (verbose()) {\n        message(\"already 1 seg; skip\");\n      }\n      return null;\n    }\n\n    // Check if there are any segments above the threshold\n    boolean anyTooLarge = false;\n    for (int i = 0; i < last; i++) {\n      SegmentInfo info = infos.info(i);\n      if (size(info) > maxMergeSizeForOptimize || sizeDocs(info) > maxMergeDocs) {\n        anyTooLarge = true;\n        break;\n      }\n    }\n    \n    if (anyTooLarge) {\n      return findMergesForOptimizeSizeLimit(infos, maxNumSegments, last);\n    } else {\n      return findMergesForOptimizeMaxNumSegments(infos, maxNumSegments, last);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"09b6beb7329eb1b75a38c94b1c5ab4e840743c59","date":1308413204,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/LogMergePolicy#findMergesForOptimize(SegmentInfos,int,Map[SegmentInfo,Boolean]).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/LogMergePolicy#findMergesForOptimize(SegmentInfos,int,Set[SegmentInfo]).mjava","sourceNew":"  /** Returns the merges necessary to optimize the index.\n   *  This merge policy defines \"optimized\" to mean only the\n   *  requested number of segments is left in the index, and\n   *  respects the {@link #maxMergeSizeForOptimize} setting.\n   *  By default, and assuming {@code maxNumSegments=1}, only\n   *  one segment will be left in the index, where that segment\n   *  has no deletions pending nor separate norms, and it is in\n   *  compound file format if the current useCompoundFile\n   *  setting is true.  This method returns multiple merges\n   *  (mergeFactor at a time) so the {@link MergeScheduler}\n   *  in use may make use of concurrency. */\n  @Override\n  public MergeSpecification findMergesForOptimize(SegmentInfos infos,\n            int maxNumSegments, Map<SegmentInfo,Boolean> segmentsToOptimize) throws IOException {\n\n    assert maxNumSegments > 0;\n    if (verbose()) {\n      message(\"findMergesForOptimize: maxNumSegs=\" + maxNumSegments + \" segsToOptimize= \"+ segmentsToOptimize);\n    }\n\n    // If the segments are already optimized (e.g. there's only 1 segment), or\n    // there are <maxNumSegements, all optimized, nothing to do.\n    if (isOptimized(infos, maxNumSegments, segmentsToOptimize)) {\n      if (verbose()) {\n        message(\"already optimized; skip\");\n      }\n      return null;\n    }\n\n    // Find the newest (rightmost) segment that needs to\n    // be optimized (other segments may have been flushed\n    // since optimize started):\n    int last = infos.size();\n    while (last > 0) {\n      final SegmentInfo info = infos.info(--last);\n      if (segmentsToOptimize.get(info) != null) {\n        last++;\n        break;\n      }\n    }\n\n    if (last == 0) {\n      if (verbose()) {\n        message(\"last == 0; skip\");\n      }\n      return null;\n    }\n    \n    // There is only one segment already, and it is optimized\n    if (maxNumSegments == 1 && last == 1 && isOptimized(infos.info(0))) {\n      if (verbose()) {\n        message(\"already 1 seg; skip\");\n      }\n      return null;\n    }\n\n    // Check if there are any segments above the threshold\n    boolean anyTooLarge = false;\n    for (int i = 0; i < last; i++) {\n      SegmentInfo info = infos.info(i);\n      if (size(info) > maxMergeSizeForOptimize || sizeDocs(info) > maxMergeDocs) {\n        anyTooLarge = true;\n        break;\n      }\n    }\n    \n    if (anyTooLarge) {\n      return findMergesForOptimizeSizeLimit(infos, maxNumSegments, last);\n    } else {\n      return findMergesForOptimizeMaxNumSegments(infos, maxNumSegments, last);\n    }\n  }\n\n","sourceOld":"  /** Returns the merges necessary to optimize the index.\n   *  This merge policy defines \"optimized\" to mean only the\n   *  requested number of segments is left in the index, and\n   *  respects the {@link #maxMergeSizeForOptimize} setting.\n   *  By default, and assuming {@code maxNumSegments=1}, only\n   *  one segment will be left in the index, where that segment\n   *  has no deletions pending nor separate norms, and it is in\n   *  compound file format if the current useCompoundFile\n   *  setting is true.  This method returns multiple merges\n   *  (mergeFactor at a time) so the {@link MergeScheduler}\n   *  in use may make use of concurrency. */\n  @Override\n  public MergeSpecification findMergesForOptimize(SegmentInfos infos,\n      int maxNumSegments, Set<SegmentInfo> segmentsToOptimize) throws IOException {\n\n    assert maxNumSegments > 0;\n    if (verbose()) {\n      message(\"findMergesForOptimize: maxNumSegs=\" + maxNumSegments + \" segsToOptimize= \"+ segmentsToOptimize);\n    }\n\n    // If the segments are already optimized (e.g. there's only 1 segment), or\n    // there are <maxNumSegements, all optimized, nothing to do.\n    if (isOptimized(infos, maxNumSegments, segmentsToOptimize)) {\n      if (verbose()) {\n        message(\"already optimized; skip\");\n      }\n      return null;\n    }\n\n    // Find the newest (rightmost) segment that needs to\n    // be optimized (other segments may have been flushed\n    // since optimize started):\n    int last = infos.size();\n    while (last > 0) {\n      final SegmentInfo info = infos.info(--last);\n      if (segmentsToOptimize.contains(info)) {\n        last++;\n        break;\n      }\n    }\n\n    if (last == 0) {\n      if (verbose()) {\n        message(\"last == 0; skip\");\n      }\n      return null;\n    }\n    \n    // There is only one segment already, and it is optimized\n    if (maxNumSegments == 1 && last == 1 && isOptimized(infos.info(0))) {\n      if (verbose()) {\n        message(\"already 1 seg; skip\");\n      }\n      return null;\n    }\n\n    // Check if there are any segments above the threshold\n    boolean anyTooLarge = false;\n    for (int i = 0; i < last; i++) {\n      SegmentInfo info = infos.info(i);\n      if (size(info) > maxMergeSizeForOptimize || sizeDocs(info) > maxMergeDocs) {\n        anyTooLarge = true;\n        break;\n      }\n    }\n    \n    if (anyTooLarge) {\n      return findMergesForOptimizeSizeLimit(infos, maxNumSegments, last);\n    } else {\n      return findMergesForOptimizeMaxNumSegments(infos, maxNumSegments, last);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d1ded5d4f5b5e3e5f32bff69cd6fe5e64322a886","date":1308439813,"type":5,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/LogMergePolicy#findMergesForOptimize(SegmentInfos,int,Map[SegmentInfo,Boolean]).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/LogMergePolicy#findMergesForOptimize(SegmentInfos,int,Set[SegmentInfo]).mjava","sourceNew":"  /** Returns the merges necessary to optimize the index.\n   *  This merge policy defines \"optimized\" to mean only the\n   *  requested number of segments is left in the index, and\n   *  respects the {@link #maxMergeSizeForOptimize} setting.\n   *  By default, and assuming {@code maxNumSegments=1}, only\n   *  one segment will be left in the index, where that segment\n   *  has no deletions pending nor separate norms, and it is in\n   *  compound file format if the current useCompoundFile\n   *  setting is true.  This method returns multiple merges\n   *  (mergeFactor at a time) so the {@link MergeScheduler}\n   *  in use may make use of concurrency. */\n  @Override\n  public MergeSpecification findMergesForOptimize(SegmentInfos infos,\n            int maxNumSegments, Map<SegmentInfo,Boolean> segmentsToOptimize) throws IOException {\n\n    assert maxNumSegments > 0;\n    if (verbose()) {\n      message(\"findMergesForOptimize: maxNumSegs=\" + maxNumSegments + \" segsToOptimize= \"+ segmentsToOptimize);\n    }\n\n    // If the segments are already optimized (e.g. there's only 1 segment), or\n    // there are <maxNumSegements, all optimized, nothing to do.\n    if (isOptimized(infos, maxNumSegments, segmentsToOptimize)) {\n      if (verbose()) {\n        message(\"already optimized; skip\");\n      }\n      return null;\n    }\n\n    // Find the newest (rightmost) segment that needs to\n    // be optimized (other segments may have been flushed\n    // since optimize started):\n    int last = infos.size();\n    while (last > 0) {\n      final SegmentInfo info = infos.info(--last);\n      if (segmentsToOptimize.get(info) != null) {\n        last++;\n        break;\n      }\n    }\n\n    if (last == 0) {\n      if (verbose()) {\n        message(\"last == 0; skip\");\n      }\n      return null;\n    }\n    \n    // There is only one segment already, and it is optimized\n    if (maxNumSegments == 1 && last == 1 && isOptimized(infos.info(0))) {\n      if (verbose()) {\n        message(\"already 1 seg; skip\");\n      }\n      return null;\n    }\n\n    // Check if there are any segments above the threshold\n    boolean anyTooLarge = false;\n    for (int i = 0; i < last; i++) {\n      SegmentInfo info = infos.info(i);\n      if (size(info) > maxMergeSizeForOptimize || sizeDocs(info) > maxMergeDocs) {\n        anyTooLarge = true;\n        break;\n      }\n    }\n    \n    if (anyTooLarge) {\n      return findMergesForOptimizeSizeLimit(infos, maxNumSegments, last);\n    } else {\n      return findMergesForOptimizeMaxNumSegments(infos, maxNumSegments, last);\n    }\n  }\n\n","sourceOld":"  /** Returns the merges necessary to optimize the index.\n   *  This merge policy defines \"optimized\" to mean only the\n   *  requested number of segments is left in the index, and\n   *  respects the {@link #maxMergeSizeForOptimize} setting.\n   *  By default, and assuming {@code maxNumSegments=1}, only\n   *  one segment will be left in the index, where that segment\n   *  has no deletions pending nor separate norms, and it is in\n   *  compound file format if the current useCompoundFile\n   *  setting is true.  This method returns multiple merges\n   *  (mergeFactor at a time) so the {@link MergeScheduler}\n   *  in use may make use of concurrency. */\n  @Override\n  public MergeSpecification findMergesForOptimize(SegmentInfos infos,\n      int maxNumSegments, Set<SegmentInfo> segmentsToOptimize) throws IOException {\n\n    assert maxNumSegments > 0;\n    if (verbose()) {\n      message(\"findMergesForOptimize: maxNumSegs=\" + maxNumSegments + \" segsToOptimize= \"+ segmentsToOptimize);\n    }\n\n    // If the segments are already optimized (e.g. there's only 1 segment), or\n    // there are <maxNumSegements, all optimized, nothing to do.\n    if (isOptimized(infos, maxNumSegments, segmentsToOptimize)) {\n      if (verbose()) {\n        message(\"already optimized; skip\");\n      }\n      return null;\n    }\n\n    // Find the newest (rightmost) segment that needs to\n    // be optimized (other segments may have been flushed\n    // since optimize started):\n    int last = infos.size();\n    while (last > 0) {\n      final SegmentInfo info = infos.info(--last);\n      if (segmentsToOptimize.contains(info)) {\n        last++;\n        break;\n      }\n    }\n\n    if (last == 0) {\n      if (verbose()) {\n        message(\"last == 0; skip\");\n      }\n      return null;\n    }\n    \n    // There is only one segment already, and it is optimized\n    if (maxNumSegments == 1 && last == 1 && isOptimized(infos.info(0))) {\n      if (verbose()) {\n        message(\"already 1 seg; skip\");\n      }\n      return null;\n    }\n\n    // Check if there are any segments above the threshold\n    boolean anyTooLarge = false;\n    for (int i = 0; i < last; i++) {\n      SegmentInfo info = infos.info(i);\n      if (size(info) > maxMergeSizeForOptimize || sizeDocs(info) > maxMergeDocs) {\n        anyTooLarge = true;\n        break;\n      }\n    }\n    \n    if (anyTooLarge) {\n      return findMergesForOptimizeSizeLimit(infos, maxNumSegments, last);\n    } else {\n      return findMergesForOptimizeMaxNumSegments(infos, maxNumSegments, last);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"70ad682703b8585f5d0a637efec044d57ec05efb":["8017ab6544f30f93b106e419e7298173bad77f69","8b241ea5e635d896cc0af83cd96ffd0322e0aba7"],"8bcd63cc99c783b21344aeeebc8c04db29770205":["8b241ea5e635d896cc0af83cd96ffd0322e0aba7"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["29ef99d61cda9641b6250bf9567329a6e65f901d","01e5948db9a07144112d2f08f28ca2e3cd880348"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["9454a6510e2db155fb01faa5c049b06ece95fab9","8723a3379c08ae0b4ba0cf4f246306f86ad8362d"],"c19f985e36a65cc969e8e564fe337a0d41512075":["8bcd63cc99c783b21344aeeebc8c04db29770205"],"01e5948db9a07144112d2f08f28ca2e3cd880348":["c19f985e36a65cc969e8e564fe337a0d41512075"],"ae31c2e5298b269d50b60961fe85afc5fbe873c3":["868da859b43505d9d2a023bfeae6dd0c795f5295","8bcd63cc99c783b21344aeeebc8c04db29770205"],"d1ded5d4f5b5e3e5f32bff69cd6fe5e64322a886":["a3776dccca01c11e7046323cfad46a3b4a471233","09b6beb7329eb1b75a38c94b1c5ab4e840743c59"],"8b241ea5e635d896cc0af83cd96ffd0322e0aba7":["8723a3379c08ae0b4ba0cf4f246306f86ad8362d"],"a3776dccca01c11e7046323cfad46a3b4a471233":["c19f985e36a65cc969e8e564fe337a0d41512075","01e5948db9a07144112d2f08f28ca2e3cd880348"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["70ad682703b8585f5d0a637efec044d57ec05efb","c19f985e36a65cc969e8e564fe337a0d41512075"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"8017ab6544f30f93b106e419e7298173bad77f69":["9454a6510e2db155fb01faa5c049b06ece95fab9","8723a3379c08ae0b4ba0cf4f246306f86ad8362d"],"8723a3379c08ae0b4ba0cf4f246306f86ad8362d":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","8b241ea5e635d896cc0af83cd96ffd0322e0aba7"],"45669a651c970812a680841b97a77cce06af559f":["bde51b089eb7f86171eb3406e38a274743f9b7ac","01e5948db9a07144112d2f08f28ca2e3cd880348"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["ae31c2e5298b269d50b60961fe85afc5fbe873c3","c19f985e36a65cc969e8e564fe337a0d41512075"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["09b6beb7329eb1b75a38c94b1c5ab4e840743c59"],"09b6beb7329eb1b75a38c94b1c5ab4e840743c59":["01e5948db9a07144112d2f08f28ca2e3cd880348"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"70ad682703b8585f5d0a637efec044d57ec05efb":["29ef99d61cda9641b6250bf9567329a6e65f901d"],"8bcd63cc99c783b21344aeeebc8c04db29770205":["c19f985e36a65cc969e8e564fe337a0d41512075","ae31c2e5298b269d50b60961fe85afc5fbe873c3"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":[],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["868da859b43505d9d2a023bfeae6dd0c795f5295"],"c19f985e36a65cc969e8e564fe337a0d41512075":["01e5948db9a07144112d2f08f28ca2e3cd880348","a3776dccca01c11e7046323cfad46a3b4a471233","29ef99d61cda9641b6250bf9567329a6e65f901d","bde51b089eb7f86171eb3406e38a274743f9b7ac"],"01e5948db9a07144112d2f08f28ca2e3cd880348":["135621f3a0670a9394eb563224a3b76cc4dddc0f","a3776dccca01c11e7046323cfad46a3b4a471233","45669a651c970812a680841b97a77cce06af559f","09b6beb7329eb1b75a38c94b1c5ab4e840743c59"],"ae31c2e5298b269d50b60961fe85afc5fbe873c3":["bde51b089eb7f86171eb3406e38a274743f9b7ac"],"d1ded5d4f5b5e3e5f32bff69cd6fe5e64322a886":[],"8b241ea5e635d896cc0af83cd96ffd0322e0aba7":["70ad682703b8585f5d0a637efec044d57ec05efb","8bcd63cc99c783b21344aeeebc8c04db29770205","868da859b43505d9d2a023bfeae6dd0c795f5295"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["135621f3a0670a9394eb563224a3b76cc4dddc0f"],"a3776dccca01c11e7046323cfad46a3b4a471233":["d1ded5d4f5b5e3e5f32bff69cd6fe5e64322a886"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"8017ab6544f30f93b106e419e7298173bad77f69":["70ad682703b8585f5d0a637efec044d57ec05efb"],"8723a3379c08ae0b4ba0cf4f246306f86ad8362d":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","8b241ea5e635d896cc0af83cd96ffd0322e0aba7","8017ab6544f30f93b106e419e7298173bad77f69"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["ae31c2e5298b269d50b60961fe85afc5fbe873c3"],"45669a651c970812a680841b97a77cce06af559f":[],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["45669a651c970812a680841b97a77cce06af559f"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","8017ab6544f30f93b106e419e7298173bad77f69","8723a3379c08ae0b4ba0cf4f246306f86ad8362d"],"09b6beb7329eb1b75a38c94b1c5ab4e840743c59":["d1ded5d4f5b5e3e5f32bff69cd6fe5e64322a886","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["135621f3a0670a9394eb563224a3b76cc4dddc0f","d1ded5d4f5b5e3e5f32bff69cd6fe5e64322a886","45669a651c970812a680841b97a77cce06af559f","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}