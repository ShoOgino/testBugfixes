{"path":"lucene/core/src/java/org/apache/lucene/codecs/lucene410/Lucene410DocValuesProducer#getSortedSet(FieldInfo).mjava","commits":[{"id":"0ce5e7f280a7b3f0f96f2623d9f0ce70f742b793","date":1408030244,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene410/Lucene410DocValuesProducer#getSortedSet(FieldInfo).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    SortedSetEntry ss = sortedSets.get(field.number);\n    if (ss.format == SORTED_SINGLE_VALUED) {\n      final SortedDocValues values = getSorted(field);\n      return DocValues.singleton(values);\n    } else if (ss.format != SORTED_WITH_ADDRESSES) {\n      throw new AssertionError();\n    }\n\n    final IndexInput data = this.data.clone();\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(data, field, ordIndexes.get(field.number));\n    \n    return new RandomAccessOrds() {\n      long startOffset;\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        startOffset = offset = ordIndex.get(docID);\n        endOffset = ordIndex.get(docID+1L);\n      }\n\n      @Override\n      public BytesRef lookupOrd(long ord) {\n        return binary.get(ord);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n\n      @Override\n      public long ordAt(int index) {\n        return ordinals.get(startOffset + index);\n      }\n\n      @Override\n      public int cardinality() {\n        return (int) (endOffset - startOffset);\n      }\n    };\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["b873e6a2036c1deda886d1fcf6ba42c995dd15a0"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b873e6a2036c1deda886d1fcf6ba42c995dd15a0","date":1408410832,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene410/Lucene410DocValuesProducer#getSortedSet(FieldInfo).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene410/Lucene410DocValuesProducer#getSortedSet(FieldInfo).mjava","sourceNew":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    SortedSetEntry ss = sortedSets.get(field.number);\n    if (ss.format == SORTED_SINGLE_VALUED) {\n      final SortedDocValues values = getSorted(field);\n      return DocValues.singleton(values);\n    } else if (ss.format != SORTED_WITH_ADDRESSES) {\n      throw new AssertionError();\n    }\n\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(field, ordIndexes.get(field.number));\n    \n    return new RandomAccessOrds() {\n      long startOffset;\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        startOffset = offset = ordIndex.get(docID);\n        endOffset = ordIndex.get(docID+1L);\n      }\n\n      @Override\n      public BytesRef lookupOrd(long ord) {\n        return binary.get(ord);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n\n      @Override\n      public long ordAt(int index) {\n        return ordinals.get(startOffset + index);\n      }\n\n      @Override\n      public int cardinality() {\n        return (int) (endOffset - startOffset);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    SortedSetEntry ss = sortedSets.get(field.number);\n    if (ss.format == SORTED_SINGLE_VALUED) {\n      final SortedDocValues values = getSorted(field);\n      return DocValues.singleton(values);\n    } else if (ss.format != SORTED_WITH_ADDRESSES) {\n      throw new AssertionError();\n    }\n\n    final IndexInput data = this.data.clone();\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(data, field, ordIndexes.get(field.number));\n    \n    return new RandomAccessOrds() {\n      long startOffset;\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        startOffset = offset = ordIndex.get(docID);\n        endOffset = ordIndex.get(docID+1L);\n      }\n\n      @Override\n      public BytesRef lookupOrd(long ord) {\n        return binary.get(ord);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n\n      @Override\n      public long ordAt(int index) {\n        return ordinals.get(startOffset + index);\n      }\n\n      @Override\n      public int cardinality() {\n        return (int) (endOffset - startOffset);\n      }\n    };\n  }\n\n","bugFix":["0ce5e7f280a7b3f0f96f2623d9f0ce70f742b793"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0936055c0eed56be3e4ae5c9db5b0e355390736a","date":1410874015,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene410/Lucene410DocValuesProducer#getSortedSet(FieldInfo).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene410/Lucene410DocValuesProducer#getSortedSet(FieldInfo).mjava","sourceNew":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    SortedSetEntry ss = sortedSets.get(field.name);\n    if (ss.format == SORTED_SINGLE_VALUED) {\n      final SortedDocValues values = getSorted(field);\n      return DocValues.singleton(values);\n    } else if (ss.format != SORTED_WITH_ADDRESSES) {\n      throw new AssertionError();\n    }\n\n    final long valueCount = binaries.get(field.name).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongValues ordinals = getNumeric(ords.get(field.name));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(field, ordIndexes.get(field.name));\n    \n    return new RandomAccessOrds() {\n      long startOffset;\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        startOffset = offset = ordIndex.get(docID);\n        endOffset = ordIndex.get(docID+1L);\n      }\n\n      @Override\n      public BytesRef lookupOrd(long ord) {\n        return binary.get(ord);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n\n      @Override\n      public long ordAt(int index) {\n        return ordinals.get(startOffset + index);\n      }\n\n      @Override\n      public int cardinality() {\n        return (int) (endOffset - startOffset);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    SortedSetEntry ss = sortedSets.get(field.number);\n    if (ss.format == SORTED_SINGLE_VALUED) {\n      final SortedDocValues values = getSorted(field);\n      return DocValues.singleton(values);\n    } else if (ss.format != SORTED_WITH_ADDRESSES) {\n      throw new AssertionError();\n    }\n\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(field, ordIndexes.get(field.number));\n    \n    return new RandomAccessOrds() {\n      long startOffset;\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        startOffset = offset = ordIndex.get(docID);\n        endOffset = ordIndex.get(docID+1L);\n      }\n\n      @Override\n      public BytesRef lookupOrd(long ord) {\n        return binary.get(ord);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n\n      @Override\n      public long ordAt(int index) {\n        return ordinals.get(startOffset + index);\n      }\n\n      @Override\n      public int cardinality() {\n        return (int) (endOffset - startOffset);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d6a3823714ed5de938fb4f3fc814824fe0f95e1a","date":1413422458,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene410/Lucene410DocValuesProducer#getSortedSet(FieldInfo).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene410/Lucene410DocValuesProducer#getSortedSet(FieldInfo).mjava","sourceNew":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    SortedSetEntry ss = sortedSets.get(field.name);\n    if (ss.format == SORTED_SINGLE_VALUED) {\n      final SortedDocValues values = getSorted(field);\n      return DocValues.singleton(values);\n    } else if (ss.format != SORTED_WITH_ADDRESSES) {\n      throw new AssertionError();\n    }\n\n    final long valueCount = binaries.get(field.name).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongValues ordinals = getNumeric(ords.get(field.name));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(field, ordIndexes.get(field.name));\n    \n    return new RandomAccessOrds() {\n      long startOffset;\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        startOffset = offset = ordIndex.get(docID);\n        endOffset = ordIndex.get(docID+1L);\n      }\n\n      @Override\n      public BytesRef lookupOrd(long ord) {\n        return binary.get(ord);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n\n      @Override\n      public long ordAt(int index) {\n        return ordinals.get(startOffset + index);\n      }\n\n      @Override\n      public int cardinality() {\n        return (int) (endOffset - startOffset);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    SortedSetEntry ss = sortedSets.get(field.name);\n    if (ss.format == SORTED_SINGLE_VALUED) {\n      final SortedDocValues values = getSorted(field);\n      return DocValues.singleton(values);\n    } else if (ss.format != SORTED_WITH_ADDRESSES) {\n      throw new AssertionError();\n    }\n\n    final long valueCount = binaries.get(field.name).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongValues ordinals = getNumeric(ords.get(field.name));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(field, ordIndexes.get(field.name));\n    \n    return new RandomAccessOrds() {\n      long startOffset;\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        startOffset = offset = ordIndex.get(docID);\n        endOffset = ordIndex.get(docID+1L);\n      }\n\n      @Override\n      public BytesRef lookupOrd(long ord) {\n        return binary.get(ord);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n\n      @Override\n      public long ordAt(int index) {\n        return ordinals.get(startOffset + index);\n      }\n\n      @Override\n      public int cardinality() {\n        return (int) (endOffset - startOffset);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d6a3823714ed5de938fb4f3fc814824fe0f95e1a","date":1413422458,"type":6,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50DocValuesProducer#getSortedSet(FieldInfo).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene410/Lucene410DocValuesProducer#getSortedSet(FieldInfo).mjava","sourceNew":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    SortedSetEntry ss = sortedSets.get(field.name);\n    if (ss.format == SORTED_SINGLE_VALUED) {\n      final SortedDocValues values = getSorted(field);\n      return DocValues.singleton(values);\n    } else if (ss.format != SORTED_WITH_ADDRESSES) {\n      throw new AssertionError();\n    }\n\n    final long valueCount = binaries.get(field.name).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongValues ordinals = getNumeric(ords.get(field.name));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(field, ordIndexes.get(field.name));\n    \n    return new RandomAccessOrds() {\n      long startOffset;\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        startOffset = offset = ordIndex.get(docID);\n        endOffset = ordIndex.get(docID+1L);\n      }\n\n      @Override\n      public BytesRef lookupOrd(long ord) {\n        return binary.get(ord);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n\n      @Override\n      public long ordAt(int index) {\n        return ordinals.get(startOffset + index);\n      }\n\n      @Override\n      public int cardinality() {\n        return (int) (endOffset - startOffset);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    SortedSetEntry ss = sortedSets.get(field.name);\n    if (ss.format == SORTED_SINGLE_VALUED) {\n      final SortedDocValues values = getSorted(field);\n      return DocValues.singleton(values);\n    } else if (ss.format != SORTED_WITH_ADDRESSES) {\n      throw new AssertionError();\n    }\n\n    final long valueCount = binaries.get(field.name).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongValues ordinals = getNumeric(ords.get(field.name));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(field, ordIndexes.get(field.name));\n    \n    return new RandomAccessOrds() {\n      long startOffset;\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        startOffset = offset = ordIndex.get(docID);\n        endOffset = ordIndex.get(docID+1L);\n      }\n\n      @Override\n      public BytesRef lookupOrd(long ord) {\n        return binary.get(ord);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n\n      @Override\n      public long ordAt(int index) {\n        return ordinals.get(startOffset + index);\n      }\n\n      @Override\n      public int cardinality() {\n        return (int) (endOffset - startOffset);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"db68c63cbfaa8698b9c4475f75ed2b9c9696d238","date":1414118621,"type":5,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene410/Lucene410DocValuesProducer#getSortedSet(FieldInfo).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene410/Lucene410DocValuesProducer#getSortedSet(FieldInfo).mjava","sourceNew":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    SortedSetEntry ss = sortedSets.get(field.name);\n    if (ss.format == SORTED_SINGLE_VALUED) {\n      final SortedDocValues values = getSorted(field);\n      return DocValues.singleton(values);\n    } else if (ss.format != SORTED_WITH_ADDRESSES) {\n      throw new AssertionError();\n    }\n\n    final long valueCount = binaries.get(field.name).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongValues ordinals = getNumeric(ords.get(field.name));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(field, ordIndexes.get(field.name));\n    \n    return new RandomAccessOrds() {\n      long startOffset;\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        startOffset = offset = ordIndex.get(docID);\n        endOffset = ordIndex.get(docID+1L);\n      }\n\n      @Override\n      public BytesRef lookupOrd(long ord) {\n        return binary.get(ord);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n\n      @Override\n      public long ordAt(int index) {\n        return ordinals.get(startOffset + index);\n      }\n\n      @Override\n      public int cardinality() {\n        return (int) (endOffset - startOffset);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    SortedSetEntry ss = sortedSets.get(field.name);\n    if (ss.format == SORTED_SINGLE_VALUED) {\n      final SortedDocValues values = getSorted(field);\n      return DocValues.singleton(values);\n    } else if (ss.format != SORTED_WITH_ADDRESSES) {\n      throw new AssertionError();\n    }\n\n    final long valueCount = binaries.get(field.name).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongValues ordinals = getNumeric(ords.get(field.name));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(field, ordIndexes.get(field.name));\n    \n    return new RandomAccessOrds() {\n      long startOffset;\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        startOffset = offset = ordIndex.get(docID);\n        endOffset = ordIndex.get(docID+1L);\n      }\n\n      @Override\n      public BytesRef lookupOrd(long ord) {\n        return binary.get(ord);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n\n      @Override\n      public long ordAt(int index) {\n        return ordinals.get(startOffset + index);\n      }\n\n      @Override\n      public int cardinality() {\n        return (int) (endOffset - startOffset);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"db68c63cbfaa8698b9c4475f75ed2b9c9696d238","date":1414118621,"type":6,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50DocValuesProducer#getSortedSet(FieldInfo).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene410/Lucene410DocValuesProducer#getSortedSet(FieldInfo).mjava","sourceNew":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    SortedSetEntry ss = sortedSets.get(field.name);\n    if (ss.format == SORTED_SINGLE_VALUED) {\n      final SortedDocValues values = getSorted(field);\n      return DocValues.singleton(values);\n    } else if (ss.format != SORTED_WITH_ADDRESSES) {\n      throw new AssertionError();\n    }\n\n    final long valueCount = binaries.get(field.name).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongValues ordinals = getNumeric(ords.get(field.name));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(field, ordIndexes.get(field.name));\n    \n    return new RandomAccessOrds() {\n      long startOffset;\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        startOffset = offset = ordIndex.get(docID);\n        endOffset = ordIndex.get(docID+1L);\n      }\n\n      @Override\n      public BytesRef lookupOrd(long ord) {\n        return binary.get(ord);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n\n      @Override\n      public long ordAt(int index) {\n        return ordinals.get(startOffset + index);\n      }\n\n      @Override\n      public int cardinality() {\n        return (int) (endOffset - startOffset);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    SortedSetEntry ss = sortedSets.get(field.name);\n    if (ss.format == SORTED_SINGLE_VALUED) {\n      final SortedDocValues values = getSorted(field);\n      return DocValues.singleton(values);\n    } else if (ss.format != SORTED_WITH_ADDRESSES) {\n      throw new AssertionError();\n    }\n\n    final long valueCount = binaries.get(field.name).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongValues ordinals = getNumeric(ords.get(field.name));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(field, ordIndexes.get(field.name));\n    \n    return new RandomAccessOrds() {\n      long startOffset;\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        startOffset = offset = ordIndex.get(docID);\n        endOffset = ordIndex.get(docID+1L);\n      }\n\n      @Override\n      public BytesRef lookupOrd(long ord) {\n        return binary.get(ord);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n\n      @Override\n      public long ordAt(int index) {\n        return ordinals.get(startOffset + index);\n      }\n\n      @Override\n      public int cardinality() {\n        return (int) (endOffset - startOffset);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b873e6a2036c1deda886d1fcf6ba42c995dd15a0":["0ce5e7f280a7b3f0f96f2623d9f0ce70f742b793"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"db68c63cbfaa8698b9c4475f75ed2b9c9696d238":["0936055c0eed56be3e4ae5c9db5b0e355390736a","d6a3823714ed5de938fb4f3fc814824fe0f95e1a"],"0936055c0eed56be3e4ae5c9db5b0e355390736a":["b873e6a2036c1deda886d1fcf6ba42c995dd15a0"],"0ce5e7f280a7b3f0f96f2623d9f0ce70f742b793":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"d6a3823714ed5de938fb4f3fc814824fe0f95e1a":["0936055c0eed56be3e4ae5c9db5b0e355390736a"]},"commit2Childs":{"b873e6a2036c1deda886d1fcf6ba42c995dd15a0":["0936055c0eed56be3e4ae5c9db5b0e355390736a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["0ce5e7f280a7b3f0f96f2623d9f0ce70f742b793"],"db68c63cbfaa8698b9c4475f75ed2b9c9696d238":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"0936055c0eed56be3e4ae5c9db5b0e355390736a":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238","d6a3823714ed5de938fb4f3fc814824fe0f95e1a"],"0ce5e7f280a7b3f0f96f2623d9f0ce70f742b793":["b873e6a2036c1deda886d1fcf6ba42c995dd15a0"],"d6a3823714ed5de938fb4f3fc814824fe0f95e1a":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}