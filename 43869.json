{"path":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(TermFreqIterator).mjava","commits":[{"id":"33ba398fa7984fdcb45fd76b87504d5adf7ca5e3","date":1373907993,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(TermFreqIterator).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public void build(TermFreqIterator iter) throws IOException {\n\n    TermFreqPayloadIterator payloads;\n    if (iter instanceof TermFreqPayloadIterator) {\n      payloads = (TermFreqPayloadIterator) iter;\n    } else {\n      payloads = null;\n    }\n    Directory dirTmp = FSDirectory.open(new File(indexPath.toString() + \".tmp\"));\n\n    Analyzer gramAnalyzer = new AnalyzerWrapper() {\n        @Override\n        protected Analyzer getWrappedAnalyzer(String fieldName) {\n          return indexAnalyzer;\n        }\n\n        @Override\n        protected TokenStreamComponents wrapComponents(String fieldName, TokenStreamComponents components) {\n          if (fieldName.equals(\"textgrams\") && minPrefixChars > 0) {\n            return new TokenStreamComponents(components.getTokenizer(),\n                                             new EdgeNGramTokenFilter(matchVersion,\n                                                                      components.getTokenStream(),\n                                                                      1, minPrefixChars));\n          } else {\n            return components;\n          }\n        }\n      };\n\n    IndexWriter w = new IndexWriter(dirTmp,\n                                    getIndexWriterConfig(matchVersion, gramAnalyzer));\n    IndexWriter w2 = null;\n    AtomicReader r = null;\n    boolean success = false;\n    try {\n      \n      BytesRef text;\n      Document doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      ft.setIndexOptions(IndexOptions.DOCS_ONLY);\n      ft.setOmitNorms(true);\n      Field textField = new Field(TEXT_FIELD_NAME, \"\", ft);\n      doc.add(textField);\n\n      Field textGramField = new Field(\"textgrams\", \"\", ft);\n      doc.add(textGramField);\n\n      Field textDVField = new BinaryDocValuesField(TEXT_FIELD_NAME, new BytesRef());\n      doc.add(textDVField);\n\n      // TODO: use threads...?\n      Field weightField = new NumericDocValuesField(\"weight\", 0);\n      doc.add(weightField);\n\n      Field payloadField;\n      if (payloads != null) {\n        payloadField = new BinaryDocValuesField(\"payloads\", new BytesRef());\n        doc.add(payloadField);\n      } else {\n        payloadField = null;\n      }\n\n      //long t0 = System.nanoTime();\n      while ((text = iter.next()) != null) {\n        String textString = text.utf8ToString();\n        textField.setStringValue(textString);\n        textGramField.setStringValue(textString);\n        textDVField.setBytesValue(text);\n        weightField.setLongValue(iter.weight());\n        if (payloads != null) {\n          payloadField.setBytesValue(payloads.payload());\n        }\n        w.addDocument(doc);\n      }\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n\n      r = new SlowCompositeReaderWrapper(DirectoryReader.open(w, false));\n      //long t1 = System.nanoTime();\n      w.rollback();\n\n      final int maxDoc = r.maxDoc();\n\n      final NumericDocValues weights = r.getNumericDocValues(\"weight\");\n\n      final Sorter.DocComparator comparator = new Sorter.DocComparator() {\n          @Override\n          public int compare(int docID1, int docID2) {\n            final long v1 = weights.get(docID1);\n            final long v2 = weights.get(docID2);\n            // Reverse sort (highest weight first);\n            // java7 only:\n            //return Long.compare(v2, v1);\n            if (v1 > v2) {\n              return -1;\n            } else if (v1 < v2) {\n              return 1;\n            } else {\n              return 0;\n            }\n          }\n        };\n\n      r = SortingAtomicReader.wrap(r, new Sorter() {\n          @Override\n          public Sorter.DocMap sort(AtomicReader reader) throws IOException {\n            return Sorter.sort(maxDoc, comparator);\n          }\n\n          @Override\n          public String getID() {\n            return \"Weight\";\n          }\n        });\n      \n      w2 = new IndexWriter(dir,\n                           getIndexWriterConfig(matchVersion, indexAnalyzer));\n      w2.addIndexes(new IndexReader[] {r});\n      r.close();\n\n      //System.out.println(\"sort time: \" + ((System.nanoTime()-t1)/1000000) + \" msec\");\n\n      searcher = new IndexSearcher(DirectoryReader.open(w2, false));\n      w2.close();\n\n      payloadsDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), \"payloads\");\n      weightsDV = MultiDocValues.getNumericValues(searcher.getIndexReader(), \"weight\");\n      textDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), TEXT_FIELD_NAME);\n      assert textDV != null;\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(w, w2, r);\n      } else {\n        IOUtils.closeWhileHandlingException(w, w2, r);\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["4637747f71df783fc2014ef1f1e0418466e3bed6"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b3aad8246db872dc16fbe6109f893457496b0240","date":1373920172,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(TermFreqIterator).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(TermFreqIterator).mjava","sourceNew":"  @Override\n  public void build(TermFreqIterator iter) throws IOException {\n\n    if (searcher != null) {\n      searcher.getIndexReader().close();\n      searcher = null;\n    }\n\n    TermFreqPayloadIterator payloads;\n    if (iter instanceof TermFreqPayloadIterator) {\n      payloads = (TermFreqPayloadIterator) iter;\n    } else {\n      payloads = null;\n    }\n    Directory dirTmp = getDirectory(new File(indexPath.toString() + \".tmp\"));\n\n    IndexWriter w = null;\n    IndexWriter w2 = null;\n    AtomicReader r = null;\n    boolean success = false;\n    try {\n      Analyzer gramAnalyzer = new AnalyzerWrapper() {\n          @Override\n          protected Analyzer getWrappedAnalyzer(String fieldName) {\n            return indexAnalyzer;\n          }\n\n          @Override\n          protected TokenStreamComponents wrapComponents(String fieldName, TokenStreamComponents components) {\n            if (fieldName.equals(\"textgrams\") && minPrefixChars > 0) {\n              return new TokenStreamComponents(components.getTokenizer(),\n                                               new EdgeNGramTokenFilter(matchVersion,\n                                                                        components.getTokenStream(),\n                                                                        1, minPrefixChars));\n            } else {\n              return components;\n            }\n          }\n        };\n\n      w = new IndexWriter(dirTmp,\n                          getIndexWriterConfig(matchVersion, gramAnalyzer));\n      BytesRef text;\n      Document doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      ft.setIndexOptions(IndexOptions.DOCS_ONLY);\n      ft.setOmitNorms(true);\n      Field textField = new Field(TEXT_FIELD_NAME, \"\", ft);\n      doc.add(textField);\n\n      Field textGramField = new Field(\"textgrams\", \"\", ft);\n      doc.add(textGramField);\n\n      Field textDVField = new BinaryDocValuesField(TEXT_FIELD_NAME, new BytesRef());\n      doc.add(textDVField);\n\n      // TODO: use threads...?\n      Field weightField = new NumericDocValuesField(\"weight\", 0);\n      doc.add(weightField);\n\n      Field payloadField;\n      if (payloads != null) {\n        payloadField = new BinaryDocValuesField(\"payloads\", new BytesRef());\n        doc.add(payloadField);\n      } else {\n        payloadField = null;\n      }\n\n      //long t0 = System.nanoTime();\n      while ((text = iter.next()) != null) {\n        String textString = text.utf8ToString();\n        textField.setStringValue(textString);\n        textGramField.setStringValue(textString);\n        textDVField.setBytesValue(text);\n        weightField.setLongValue(iter.weight());\n        if (payloads != null) {\n          payloadField.setBytesValue(payloads.payload());\n        }\n        w.addDocument(doc);\n      }\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n\n      r = new SlowCompositeReaderWrapper(DirectoryReader.open(w, false));\n      //long t1 = System.nanoTime();\n      w.rollback();\n\n      final int maxDoc = r.maxDoc();\n\n      final NumericDocValues weights = r.getNumericDocValues(\"weight\");\n\n      final Sorter.DocComparator comparator = new Sorter.DocComparator() {\n          @Override\n          public int compare(int docID1, int docID2) {\n            final long v1 = weights.get(docID1);\n            final long v2 = weights.get(docID2);\n            // Reverse sort (highest weight first);\n            // java7 only:\n            //return Long.compare(v2, v1);\n            if (v1 > v2) {\n              return -1;\n            } else if (v1 < v2) {\n              return 1;\n            } else {\n              return 0;\n            }\n          }\n        };\n\n      r = SortingAtomicReader.wrap(r, new Sorter() {\n          @Override\n          public Sorter.DocMap sort(AtomicReader reader) throws IOException {\n            return Sorter.sort(maxDoc, comparator);\n          }\n\n          @Override\n          public String getID() {\n            return \"Weight\";\n          }\n        });\n      \n      w2 = new IndexWriter(dir,\n                           getIndexWriterConfig(matchVersion, indexAnalyzer));\n      w2.addIndexes(new IndexReader[] {r});\n      r.close();\n\n      //System.out.println(\"sort time: \" + ((System.nanoTime()-t1)/1000000) + \" msec\");\n\n      searcher = new IndexSearcher(DirectoryReader.open(w2, false));\n      w2.close();\n\n      payloadsDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), \"payloads\");\n      weightsDV = MultiDocValues.getNumericValues(searcher.getIndexReader(), \"weight\");\n      textDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), TEXT_FIELD_NAME);\n      assert textDV != null;\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(w, w2, r, dirTmp);\n      } else {\n        IOUtils.closeWhileHandlingException(w, w2, r, dirTmp);\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void build(TermFreqIterator iter) throws IOException {\n\n    TermFreqPayloadIterator payloads;\n    if (iter instanceof TermFreqPayloadIterator) {\n      payloads = (TermFreqPayloadIterator) iter;\n    } else {\n      payloads = null;\n    }\n    Directory dirTmp = FSDirectory.open(new File(indexPath.toString() + \".tmp\"));\n\n    Analyzer gramAnalyzer = new AnalyzerWrapper() {\n        @Override\n        protected Analyzer getWrappedAnalyzer(String fieldName) {\n          return indexAnalyzer;\n        }\n\n        @Override\n        protected TokenStreamComponents wrapComponents(String fieldName, TokenStreamComponents components) {\n          if (fieldName.equals(\"textgrams\") && minPrefixChars > 0) {\n            return new TokenStreamComponents(components.getTokenizer(),\n                                             new EdgeNGramTokenFilter(matchVersion,\n                                                                      components.getTokenStream(),\n                                                                      1, minPrefixChars));\n          } else {\n            return components;\n          }\n        }\n      };\n\n    IndexWriter w = new IndexWriter(dirTmp,\n                                    getIndexWriterConfig(matchVersion, gramAnalyzer));\n    IndexWriter w2 = null;\n    AtomicReader r = null;\n    boolean success = false;\n    try {\n      \n      BytesRef text;\n      Document doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      ft.setIndexOptions(IndexOptions.DOCS_ONLY);\n      ft.setOmitNorms(true);\n      Field textField = new Field(TEXT_FIELD_NAME, \"\", ft);\n      doc.add(textField);\n\n      Field textGramField = new Field(\"textgrams\", \"\", ft);\n      doc.add(textGramField);\n\n      Field textDVField = new BinaryDocValuesField(TEXT_FIELD_NAME, new BytesRef());\n      doc.add(textDVField);\n\n      // TODO: use threads...?\n      Field weightField = new NumericDocValuesField(\"weight\", 0);\n      doc.add(weightField);\n\n      Field payloadField;\n      if (payloads != null) {\n        payloadField = new BinaryDocValuesField(\"payloads\", new BytesRef());\n        doc.add(payloadField);\n      } else {\n        payloadField = null;\n      }\n\n      //long t0 = System.nanoTime();\n      while ((text = iter.next()) != null) {\n        String textString = text.utf8ToString();\n        textField.setStringValue(textString);\n        textGramField.setStringValue(textString);\n        textDVField.setBytesValue(text);\n        weightField.setLongValue(iter.weight());\n        if (payloads != null) {\n          payloadField.setBytesValue(payloads.payload());\n        }\n        w.addDocument(doc);\n      }\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n\n      r = new SlowCompositeReaderWrapper(DirectoryReader.open(w, false));\n      //long t1 = System.nanoTime();\n      w.rollback();\n\n      final int maxDoc = r.maxDoc();\n\n      final NumericDocValues weights = r.getNumericDocValues(\"weight\");\n\n      final Sorter.DocComparator comparator = new Sorter.DocComparator() {\n          @Override\n          public int compare(int docID1, int docID2) {\n            final long v1 = weights.get(docID1);\n            final long v2 = weights.get(docID2);\n            // Reverse sort (highest weight first);\n            // java7 only:\n            //return Long.compare(v2, v1);\n            if (v1 > v2) {\n              return -1;\n            } else if (v1 < v2) {\n              return 1;\n            } else {\n              return 0;\n            }\n          }\n        };\n\n      r = SortingAtomicReader.wrap(r, new Sorter() {\n          @Override\n          public Sorter.DocMap sort(AtomicReader reader) throws IOException {\n            return Sorter.sort(maxDoc, comparator);\n          }\n\n          @Override\n          public String getID() {\n            return \"Weight\";\n          }\n        });\n      \n      w2 = new IndexWriter(dir,\n                           getIndexWriterConfig(matchVersion, indexAnalyzer));\n      w2.addIndexes(new IndexReader[] {r});\n      r.close();\n\n      //System.out.println(\"sort time: \" + ((System.nanoTime()-t1)/1000000) + \" msec\");\n\n      searcher = new IndexSearcher(DirectoryReader.open(w2, false));\n      w2.close();\n\n      payloadsDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), \"payloads\");\n      weightsDV = MultiDocValues.getNumericValues(searcher.getIndexReader(), \"weight\");\n      textDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), TEXT_FIELD_NAME);\n      assert textDV != null;\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(w, w2, r);\n      } else {\n        IOUtils.closeWhileHandlingException(w, w2, r);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["4637747f71df783fc2014ef1f1e0418466e3bed6"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"37a0f60745e53927c4c876cfe5b5a58170f0646c","date":1373994005,"type":0,"author":"Han Jiang","isMerge":true,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(TermFreqIterator).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public void build(TermFreqIterator iter) throws IOException {\n\n    if (searcher != null) {\n      searcher.getIndexReader().close();\n      searcher = null;\n    }\n\n    TermFreqPayloadIterator payloads;\n    if (iter instanceof TermFreqPayloadIterator) {\n      payloads = (TermFreqPayloadIterator) iter;\n    } else {\n      payloads = null;\n    }\n    Directory dirTmp = getDirectory(new File(indexPath.toString() + \".tmp\"));\n\n    IndexWriter w = null;\n    IndexWriter w2 = null;\n    AtomicReader r = null;\n    boolean success = false;\n    try {\n      Analyzer gramAnalyzer = new AnalyzerWrapper() {\n          @Override\n          protected Analyzer getWrappedAnalyzer(String fieldName) {\n            return indexAnalyzer;\n          }\n\n          @Override\n          protected TokenStreamComponents wrapComponents(String fieldName, TokenStreamComponents components) {\n            if (fieldName.equals(\"textgrams\") && minPrefixChars > 0) {\n              return new TokenStreamComponents(components.getTokenizer(),\n                                               new EdgeNGramTokenFilter(matchVersion,\n                                                                        components.getTokenStream(),\n                                                                        1, minPrefixChars));\n            } else {\n              return components;\n            }\n          }\n        };\n\n      w = new IndexWriter(dirTmp,\n                          getIndexWriterConfig(matchVersion, gramAnalyzer));\n      BytesRef text;\n      Document doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      ft.setIndexOptions(IndexOptions.DOCS_ONLY);\n      ft.setOmitNorms(true);\n      Field textField = new Field(TEXT_FIELD_NAME, \"\", ft);\n      doc.add(textField);\n\n      Field textGramField = new Field(\"textgrams\", \"\", ft);\n      doc.add(textGramField);\n\n      Field textDVField = new BinaryDocValuesField(TEXT_FIELD_NAME, new BytesRef());\n      doc.add(textDVField);\n\n      // TODO: use threads...?\n      Field weightField = new NumericDocValuesField(\"weight\", 0);\n      doc.add(weightField);\n\n      Field payloadField;\n      if (payloads != null) {\n        payloadField = new BinaryDocValuesField(\"payloads\", new BytesRef());\n        doc.add(payloadField);\n      } else {\n        payloadField = null;\n      }\n\n      //long t0 = System.nanoTime();\n      while ((text = iter.next()) != null) {\n        String textString = text.utf8ToString();\n        textField.setStringValue(textString);\n        textGramField.setStringValue(textString);\n        textDVField.setBytesValue(text);\n        weightField.setLongValue(iter.weight());\n        if (payloads != null) {\n          payloadField.setBytesValue(payloads.payload());\n        }\n        w.addDocument(doc);\n      }\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n\n      r = new SlowCompositeReaderWrapper(DirectoryReader.open(w, false));\n      //long t1 = System.nanoTime();\n      w.rollback();\n\n      final int maxDoc = r.maxDoc();\n\n      final NumericDocValues weights = r.getNumericDocValues(\"weight\");\n\n      final Sorter.DocComparator comparator = new Sorter.DocComparator() {\n          @Override\n          public int compare(int docID1, int docID2) {\n            final long v1 = weights.get(docID1);\n            final long v2 = weights.get(docID2);\n            // Reverse sort (highest weight first);\n            // java7 only:\n            //return Long.compare(v2, v1);\n            if (v1 > v2) {\n              return -1;\n            } else if (v1 < v2) {\n              return 1;\n            } else {\n              return 0;\n            }\n          }\n        };\n\n      r = SortingAtomicReader.wrap(r, new Sorter() {\n          @Override\n          public Sorter.DocMap sort(AtomicReader reader) throws IOException {\n            return Sorter.sort(maxDoc, comparator);\n          }\n\n          @Override\n          public String getID() {\n            return \"Weight\";\n          }\n        });\n      \n      w2 = new IndexWriter(dir,\n                           getIndexWriterConfig(matchVersion, indexAnalyzer));\n      w2.addIndexes(new IndexReader[] {r});\n      r.close();\n\n      //System.out.println(\"sort time: \" + ((System.nanoTime()-t1)/1000000) + \" msec\");\n\n      searcher = new IndexSearcher(DirectoryReader.open(w2, false));\n      w2.close();\n\n      payloadsDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), \"payloads\");\n      weightsDV = MultiDocValues.getNumericValues(searcher.getIndexReader(), \"weight\");\n      textDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), TEXT_FIELD_NAME);\n      assert textDV != null;\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(w, w2, r, dirTmp);\n      } else {\n        IOUtils.closeWhileHandlingException(w, w2, r, dirTmp);\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"38061899d760e06a12fe186bc1f09ca9ff0e64a6","date":1376491296,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(TermFreqIterator).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(TermFreqIterator).mjava","sourceNew":"  @Override\n  public void build(TermFreqIterator iter) throws IOException {\n\n    if (searcher != null) {\n      searcher.getIndexReader().close();\n      searcher = null;\n    }\n\n    TermFreqPayloadIterator payloads;\n    if (iter instanceof TermFreqPayloadIterator) {\n      payloads = (TermFreqPayloadIterator) iter;\n    } else {\n      payloads = null;\n    }\n    Directory dirTmp = getDirectory(new File(indexPath.toString() + \".tmp\"));\n\n    IndexWriter w = null;\n    IndexWriter w2 = null;\n    AtomicReader r = null;\n    boolean success = false;\n    try {\n      Analyzer gramAnalyzer = new AnalyzerWrapper(Analyzer.PER_FIELD_REUSE_STRATEGY) {\n          @Override\n          protected Analyzer getWrappedAnalyzer(String fieldName) {\n            return indexAnalyzer;\n          }\n\n          @Override\n          protected TokenStreamComponents wrapComponents(String fieldName, TokenStreamComponents components) {\n            if (fieldName.equals(\"textgrams\") && minPrefixChars > 0) {\n              return new TokenStreamComponents(components.getTokenizer(),\n                                               new EdgeNGramTokenFilter(matchVersion,\n                                                                        components.getTokenStream(),\n                                                                        1, minPrefixChars));\n            } else {\n              return components;\n            }\n          }\n        };\n\n      w = new IndexWriter(dirTmp,\n                          getIndexWriterConfig(matchVersion, gramAnalyzer));\n      BytesRef text;\n      Document doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      ft.setIndexOptions(IndexOptions.DOCS_ONLY);\n      ft.setOmitNorms(true);\n      Field textField = new Field(TEXT_FIELD_NAME, \"\", ft);\n      doc.add(textField);\n\n      Field textGramField = new Field(\"textgrams\", \"\", ft);\n      doc.add(textGramField);\n\n      Field textDVField = new BinaryDocValuesField(TEXT_FIELD_NAME, new BytesRef());\n      doc.add(textDVField);\n\n      // TODO: use threads...?\n      Field weightField = new NumericDocValuesField(\"weight\", 0);\n      doc.add(weightField);\n\n      Field payloadField;\n      if (payloads != null) {\n        payloadField = new BinaryDocValuesField(\"payloads\", new BytesRef());\n        doc.add(payloadField);\n      } else {\n        payloadField = null;\n      }\n\n      //long t0 = System.nanoTime();\n      while ((text = iter.next()) != null) {\n        String textString = text.utf8ToString();\n        textField.setStringValue(textString);\n        textGramField.setStringValue(textString);\n        textDVField.setBytesValue(text);\n        weightField.setLongValue(iter.weight());\n        if (payloads != null) {\n          payloadField.setBytesValue(payloads.payload());\n        }\n        w.addDocument(doc);\n      }\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n\n      r = new SlowCompositeReaderWrapper(DirectoryReader.open(w, false));\n      //long t1 = System.nanoTime();\n      w.rollback();\n\n      final int maxDoc = r.maxDoc();\n\n      final NumericDocValues weights = r.getNumericDocValues(\"weight\");\n\n      final Sorter.DocComparator comparator = new Sorter.DocComparator() {\n          @Override\n          public int compare(int docID1, int docID2) {\n            final long v1 = weights.get(docID1);\n            final long v2 = weights.get(docID2);\n            // Reverse sort (highest weight first);\n            // java7 only:\n            //return Long.compare(v2, v1);\n            if (v1 > v2) {\n              return -1;\n            } else if (v1 < v2) {\n              return 1;\n            } else {\n              return 0;\n            }\n          }\n        };\n\n      r = SortingAtomicReader.wrap(r, new Sorter() {\n          @Override\n          public Sorter.DocMap sort(AtomicReader reader) throws IOException {\n            return Sorter.sort(maxDoc, comparator);\n          }\n\n          @Override\n          public String getID() {\n            return \"Weight\";\n          }\n        });\n      \n      w2 = new IndexWriter(dir,\n                           getIndexWriterConfig(matchVersion, indexAnalyzer));\n      w2.addIndexes(new IndexReader[] {r});\n      r.close();\n\n      //System.out.println(\"sort time: \" + ((System.nanoTime()-t1)/1000000) + \" msec\");\n\n      searcher = new IndexSearcher(DirectoryReader.open(w2, false));\n      w2.close();\n\n      payloadsDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), \"payloads\");\n      weightsDV = MultiDocValues.getNumericValues(searcher.getIndexReader(), \"weight\");\n      textDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), TEXT_FIELD_NAME);\n      assert textDV != null;\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(w, w2, r, dirTmp);\n      } else {\n        IOUtils.closeWhileHandlingException(w, w2, r, dirTmp);\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void build(TermFreqIterator iter) throws IOException {\n\n    if (searcher != null) {\n      searcher.getIndexReader().close();\n      searcher = null;\n    }\n\n    TermFreqPayloadIterator payloads;\n    if (iter instanceof TermFreqPayloadIterator) {\n      payloads = (TermFreqPayloadIterator) iter;\n    } else {\n      payloads = null;\n    }\n    Directory dirTmp = getDirectory(new File(indexPath.toString() + \".tmp\"));\n\n    IndexWriter w = null;\n    IndexWriter w2 = null;\n    AtomicReader r = null;\n    boolean success = false;\n    try {\n      Analyzer gramAnalyzer = new AnalyzerWrapper() {\n          @Override\n          protected Analyzer getWrappedAnalyzer(String fieldName) {\n            return indexAnalyzer;\n          }\n\n          @Override\n          protected TokenStreamComponents wrapComponents(String fieldName, TokenStreamComponents components) {\n            if (fieldName.equals(\"textgrams\") && minPrefixChars > 0) {\n              return new TokenStreamComponents(components.getTokenizer(),\n                                               new EdgeNGramTokenFilter(matchVersion,\n                                                                        components.getTokenStream(),\n                                                                        1, minPrefixChars));\n            } else {\n              return components;\n            }\n          }\n        };\n\n      w = new IndexWriter(dirTmp,\n                          getIndexWriterConfig(matchVersion, gramAnalyzer));\n      BytesRef text;\n      Document doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      ft.setIndexOptions(IndexOptions.DOCS_ONLY);\n      ft.setOmitNorms(true);\n      Field textField = new Field(TEXT_FIELD_NAME, \"\", ft);\n      doc.add(textField);\n\n      Field textGramField = new Field(\"textgrams\", \"\", ft);\n      doc.add(textGramField);\n\n      Field textDVField = new BinaryDocValuesField(TEXT_FIELD_NAME, new BytesRef());\n      doc.add(textDVField);\n\n      // TODO: use threads...?\n      Field weightField = new NumericDocValuesField(\"weight\", 0);\n      doc.add(weightField);\n\n      Field payloadField;\n      if (payloads != null) {\n        payloadField = new BinaryDocValuesField(\"payloads\", new BytesRef());\n        doc.add(payloadField);\n      } else {\n        payloadField = null;\n      }\n\n      //long t0 = System.nanoTime();\n      while ((text = iter.next()) != null) {\n        String textString = text.utf8ToString();\n        textField.setStringValue(textString);\n        textGramField.setStringValue(textString);\n        textDVField.setBytesValue(text);\n        weightField.setLongValue(iter.weight());\n        if (payloads != null) {\n          payloadField.setBytesValue(payloads.payload());\n        }\n        w.addDocument(doc);\n      }\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n\n      r = new SlowCompositeReaderWrapper(DirectoryReader.open(w, false));\n      //long t1 = System.nanoTime();\n      w.rollback();\n\n      final int maxDoc = r.maxDoc();\n\n      final NumericDocValues weights = r.getNumericDocValues(\"weight\");\n\n      final Sorter.DocComparator comparator = new Sorter.DocComparator() {\n          @Override\n          public int compare(int docID1, int docID2) {\n            final long v1 = weights.get(docID1);\n            final long v2 = weights.get(docID2);\n            // Reverse sort (highest weight first);\n            // java7 only:\n            //return Long.compare(v2, v1);\n            if (v1 > v2) {\n              return -1;\n            } else if (v1 < v2) {\n              return 1;\n            } else {\n              return 0;\n            }\n          }\n        };\n\n      r = SortingAtomicReader.wrap(r, new Sorter() {\n          @Override\n          public Sorter.DocMap sort(AtomicReader reader) throws IOException {\n            return Sorter.sort(maxDoc, comparator);\n          }\n\n          @Override\n          public String getID() {\n            return \"Weight\";\n          }\n        });\n      \n      w2 = new IndexWriter(dir,\n                           getIndexWriterConfig(matchVersion, indexAnalyzer));\n      w2.addIndexes(new IndexReader[] {r});\n      r.close();\n\n      //System.out.println(\"sort time: \" + ((System.nanoTime()-t1)/1000000) + \" msec\");\n\n      searcher = new IndexSearcher(DirectoryReader.open(w2, false));\n      w2.close();\n\n      payloadsDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), \"payloads\");\n      weightsDV = MultiDocValues.getNumericValues(searcher.getIndexReader(), \"weight\");\n      textDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), TEXT_FIELD_NAME);\n      assert textDV != null;\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(w, w2, r, dirTmp);\n      } else {\n        IOUtils.closeWhileHandlingException(w, w2, r, dirTmp);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"df9bf66ed405ee5c7d32b47bdb36c2e36d2c1392","date":1377503666,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(TermFreqIterator).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(TermFreqIterator).mjava","sourceNew":"  @Override\n  public void build(TermFreqIterator iter) throws IOException {\n\n    if (searcher != null) {\n      searcher.getIndexReader().close();\n      searcher = null;\n    }\n\n    TermFreqPayloadIterator payloads;\n    if (iter instanceof TermFreqPayloadIterator) {\n      payloads = (TermFreqPayloadIterator) iter;\n    } else {\n      payloads = null;\n    }\n    Directory dirTmp = getDirectory(new File(indexPath.toString() + \".tmp\"));\n\n    IndexWriter w = null;\n    IndexWriter w2 = null;\n    AtomicReader r = null;\n    boolean success = false;\n    try {\n      Analyzer gramAnalyzer = new AnalyzerWrapper(Analyzer.PER_FIELD_REUSE_STRATEGY) {\n          @Override\n          protected Analyzer getWrappedAnalyzer(String fieldName) {\n            return indexAnalyzer;\n          }\n\n          @Override\n          protected TokenStreamComponents wrapComponents(String fieldName, TokenStreamComponents components) {\n            if (fieldName.equals(\"textgrams\") && minPrefixChars > 0) {\n              return new TokenStreamComponents(components.getTokenizer(),\n                                               new EdgeNGramTokenFilter(matchVersion,\n                                                                        components.getTokenStream(),\n                                                                        1, minPrefixChars));\n            } else {\n              return components;\n            }\n          }\n        };\n\n      w = new IndexWriter(dirTmp,\n                          getIndexWriterConfig(matchVersion, gramAnalyzer));\n      BytesRef text;\n      Document doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      ft.setIndexOptions(IndexOptions.DOCS_ONLY);\n      ft.setOmitNorms(true);\n      Field textField = new Field(TEXT_FIELD_NAME, \"\", ft);\n      doc.add(textField);\n\n      Field textGramField = new Field(\"textgrams\", \"\", ft);\n      doc.add(textGramField);\n\n      Field textDVField = new BinaryDocValuesField(TEXT_FIELD_NAME, new BytesRef());\n      doc.add(textDVField);\n\n      // TODO: use threads...?\n      Field weightField = new NumericDocValuesField(\"weight\", 0);\n      doc.add(weightField);\n\n      Field payloadField;\n      if (payloads != null) {\n        payloadField = new BinaryDocValuesField(\"payloads\", new BytesRef());\n        doc.add(payloadField);\n      } else {\n        payloadField = null;\n      }\n\n      //long t0 = System.nanoTime();\n      while ((text = iter.next()) != null) {\n        String textString = text.utf8ToString();\n        textField.setStringValue(textString);\n        textGramField.setStringValue(textString);\n        textDVField.setBytesValue(text);\n        weightField.setLongValue(iter.weight());\n        if (payloads != null) {\n          payloadField.setBytesValue(payloads.payload());\n        }\n        w.addDocument(doc);\n      }\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n\n      r = SlowCompositeReaderWrapper.wrap(DirectoryReader.open(w, false));\n      //long t1 = System.nanoTime();\n      w.rollback();\n\n      final int maxDoc = r.maxDoc();\n\n      final NumericDocValues weights = r.getNumericDocValues(\"weight\");\n\n      final Sorter.DocComparator comparator = new Sorter.DocComparator() {\n          @Override\n          public int compare(int docID1, int docID2) {\n            final long v1 = weights.get(docID1);\n            final long v2 = weights.get(docID2);\n            // Reverse sort (highest weight first);\n            // java7 only:\n            //return Long.compare(v2, v1);\n            if (v1 > v2) {\n              return -1;\n            } else if (v1 < v2) {\n              return 1;\n            } else {\n              return 0;\n            }\n          }\n        };\n\n      r = SortingAtomicReader.wrap(r, new Sorter() {\n          @Override\n          public Sorter.DocMap sort(AtomicReader reader) throws IOException {\n            return Sorter.sort(maxDoc, comparator);\n          }\n\n          @Override\n          public String getID() {\n            return \"Weight\";\n          }\n        });\n      \n      w2 = new IndexWriter(dir,\n                           getIndexWriterConfig(matchVersion, indexAnalyzer));\n      w2.addIndexes(new IndexReader[] {r});\n      r.close();\n\n      //System.out.println(\"sort time: \" + ((System.nanoTime()-t1)/1000000) + \" msec\");\n\n      searcher = new IndexSearcher(DirectoryReader.open(w2, false));\n      w2.close();\n\n      payloadsDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), \"payloads\");\n      weightsDV = MultiDocValues.getNumericValues(searcher.getIndexReader(), \"weight\");\n      textDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), TEXT_FIELD_NAME);\n      assert textDV != null;\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(w, w2, r, dirTmp);\n      } else {\n        IOUtils.closeWhileHandlingException(w, w2, r, dirTmp);\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void build(TermFreqIterator iter) throws IOException {\n\n    if (searcher != null) {\n      searcher.getIndexReader().close();\n      searcher = null;\n    }\n\n    TermFreqPayloadIterator payloads;\n    if (iter instanceof TermFreqPayloadIterator) {\n      payloads = (TermFreqPayloadIterator) iter;\n    } else {\n      payloads = null;\n    }\n    Directory dirTmp = getDirectory(new File(indexPath.toString() + \".tmp\"));\n\n    IndexWriter w = null;\n    IndexWriter w2 = null;\n    AtomicReader r = null;\n    boolean success = false;\n    try {\n      Analyzer gramAnalyzer = new AnalyzerWrapper(Analyzer.PER_FIELD_REUSE_STRATEGY) {\n          @Override\n          protected Analyzer getWrappedAnalyzer(String fieldName) {\n            return indexAnalyzer;\n          }\n\n          @Override\n          protected TokenStreamComponents wrapComponents(String fieldName, TokenStreamComponents components) {\n            if (fieldName.equals(\"textgrams\") && minPrefixChars > 0) {\n              return new TokenStreamComponents(components.getTokenizer(),\n                                               new EdgeNGramTokenFilter(matchVersion,\n                                                                        components.getTokenStream(),\n                                                                        1, minPrefixChars));\n            } else {\n              return components;\n            }\n          }\n        };\n\n      w = new IndexWriter(dirTmp,\n                          getIndexWriterConfig(matchVersion, gramAnalyzer));\n      BytesRef text;\n      Document doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      ft.setIndexOptions(IndexOptions.DOCS_ONLY);\n      ft.setOmitNorms(true);\n      Field textField = new Field(TEXT_FIELD_NAME, \"\", ft);\n      doc.add(textField);\n\n      Field textGramField = new Field(\"textgrams\", \"\", ft);\n      doc.add(textGramField);\n\n      Field textDVField = new BinaryDocValuesField(TEXT_FIELD_NAME, new BytesRef());\n      doc.add(textDVField);\n\n      // TODO: use threads...?\n      Field weightField = new NumericDocValuesField(\"weight\", 0);\n      doc.add(weightField);\n\n      Field payloadField;\n      if (payloads != null) {\n        payloadField = new BinaryDocValuesField(\"payloads\", new BytesRef());\n        doc.add(payloadField);\n      } else {\n        payloadField = null;\n      }\n\n      //long t0 = System.nanoTime();\n      while ((text = iter.next()) != null) {\n        String textString = text.utf8ToString();\n        textField.setStringValue(textString);\n        textGramField.setStringValue(textString);\n        textDVField.setBytesValue(text);\n        weightField.setLongValue(iter.weight());\n        if (payloads != null) {\n          payloadField.setBytesValue(payloads.payload());\n        }\n        w.addDocument(doc);\n      }\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n\n      r = new SlowCompositeReaderWrapper(DirectoryReader.open(w, false));\n      //long t1 = System.nanoTime();\n      w.rollback();\n\n      final int maxDoc = r.maxDoc();\n\n      final NumericDocValues weights = r.getNumericDocValues(\"weight\");\n\n      final Sorter.DocComparator comparator = new Sorter.DocComparator() {\n          @Override\n          public int compare(int docID1, int docID2) {\n            final long v1 = weights.get(docID1);\n            final long v2 = weights.get(docID2);\n            // Reverse sort (highest weight first);\n            // java7 only:\n            //return Long.compare(v2, v1);\n            if (v1 > v2) {\n              return -1;\n            } else if (v1 < v2) {\n              return 1;\n            } else {\n              return 0;\n            }\n          }\n        };\n\n      r = SortingAtomicReader.wrap(r, new Sorter() {\n          @Override\n          public Sorter.DocMap sort(AtomicReader reader) throws IOException {\n            return Sorter.sort(maxDoc, comparator);\n          }\n\n          @Override\n          public String getID() {\n            return \"Weight\";\n          }\n        });\n      \n      w2 = new IndexWriter(dir,\n                           getIndexWriterConfig(matchVersion, indexAnalyzer));\n      w2.addIndexes(new IndexReader[] {r});\n      r.close();\n\n      //System.out.println(\"sort time: \" + ((System.nanoTime()-t1)/1000000) + \" msec\");\n\n      searcher = new IndexSearcher(DirectoryReader.open(w2, false));\n      w2.close();\n\n      payloadsDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), \"payloads\");\n      weightsDV = MultiDocValues.getNumericValues(searcher.getIndexReader(), \"weight\");\n      textDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), TEXT_FIELD_NAME);\n      assert textDV != null;\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(w, w2, r, dirTmp);\n      } else {\n        IOUtils.closeWhileHandlingException(w, w2, r, dirTmp);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["4637747f71df783fc2014ef1f1e0418466e3bed6"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3dffec77fb8f7d0e9ca4869dddd6af94528b4576","date":1377875202,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(TermFreqIterator).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(TermFreqIterator).mjava","sourceNew":"  @Override\n  public void build(TermFreqIterator iter) throws IOException {\n\n    if (searcher != null) {\n      searcher.getIndexReader().close();\n      searcher = null;\n    }\n\n    TermFreqPayloadIterator payloads;\n    if (iter instanceof TermFreqPayloadIterator) {\n      payloads = (TermFreqPayloadIterator) iter;\n    } else {\n      payloads = null;\n    }\n    Directory dirTmp = getDirectory(new File(indexPath.toString() + \".tmp\"));\n\n    IndexWriter w = null;\n    IndexWriter w2 = null;\n    AtomicReader r = null;\n    boolean success = false;\n    try {\n      Analyzer gramAnalyzer = new AnalyzerWrapper(Analyzer.PER_FIELD_REUSE_STRATEGY) {\n          @Override\n          protected Analyzer getWrappedAnalyzer(String fieldName) {\n            return indexAnalyzer;\n          }\n\n          @Override\n          protected TokenStreamComponents wrapComponents(String fieldName, TokenStreamComponents components) {\n            if (fieldName.equals(\"textgrams\") && minPrefixChars > 0) {\n              return new TokenStreamComponents(components.getTokenizer(),\n                                               new EdgeNGramTokenFilter(matchVersion,\n                                                                        components.getTokenStream(),\n                                                                        1, minPrefixChars));\n            } else {\n              return components;\n            }\n          }\n        };\n\n      w = new IndexWriter(dirTmp,\n                          getIndexWriterConfig(matchVersion, gramAnalyzer));\n      BytesRef text;\n      Document doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      ft.setIndexOptions(IndexOptions.DOCS_ONLY);\n      ft.setOmitNorms(true);\n      Field textField = new Field(TEXT_FIELD_NAME, \"\", ft);\n      doc.add(textField);\n\n      Field textGramField = new Field(\"textgrams\", \"\", ft);\n      doc.add(textGramField);\n\n      Field textDVField = new BinaryDocValuesField(TEXT_FIELD_NAME, new BytesRef());\n      doc.add(textDVField);\n\n      // TODO: use threads...?\n      Field weightField = new NumericDocValuesField(\"weight\", 0);\n      doc.add(weightField);\n\n      Field payloadField;\n      if (payloads != null) {\n        payloadField = new BinaryDocValuesField(\"payloads\", new BytesRef());\n        doc.add(payloadField);\n      } else {\n        payloadField = null;\n      }\n\n      //long t0 = System.nanoTime();\n      while ((text = iter.next()) != null) {\n        String textString = text.utf8ToString();\n        textField.setStringValue(textString);\n        textGramField.setStringValue(textString);\n        textDVField.setBytesValue(text);\n        weightField.setLongValue(iter.weight());\n        if (payloads != null) {\n          payloadField.setBytesValue(payloads.payload());\n        }\n        w.addDocument(doc);\n      }\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n\n      r = SlowCompositeReaderWrapper.wrap(DirectoryReader.open(w, false));\n      //long t1 = System.nanoTime();\n      w.rollback();\n\n      final int maxDoc = r.maxDoc();\n\n      final NumericDocValues weights = r.getNumericDocValues(\"weight\");\n\n      final Sorter.DocComparator comparator = new Sorter.DocComparator() {\n          @Override\n          public int compare(int docID1, int docID2) {\n            final long v1 = weights.get(docID1);\n            final long v2 = weights.get(docID2);\n            // Reverse sort (highest weight first);\n            // java7 only:\n            //return Long.compare(v2, v1);\n            if (v1 > v2) {\n              return -1;\n            } else if (v1 < v2) {\n              return 1;\n            } else {\n              return 0;\n            }\n          }\n        };\n\n      r = SortingAtomicReader.wrap(r, new Sorter() {\n          @Override\n          public Sorter.DocMap sort(AtomicReader reader) throws IOException {\n            return Sorter.sort(maxDoc, comparator);\n          }\n\n          @Override\n          public String getID() {\n            return \"Weight\";\n          }\n        });\n      \n      w2 = new IndexWriter(dir,\n                           getIndexWriterConfig(matchVersion, indexAnalyzer));\n      w2.addIndexes(new IndexReader[] {r});\n      r.close();\n\n      //System.out.println(\"sort time: \" + ((System.nanoTime()-t1)/1000000) + \" msec\");\n\n      searcher = new IndexSearcher(DirectoryReader.open(w2, false));\n      w2.close();\n\n      payloadsDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), \"payloads\");\n      weightsDV = MultiDocValues.getNumericValues(searcher.getIndexReader(), \"weight\");\n      textDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), TEXT_FIELD_NAME);\n      assert textDV != null;\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(w, w2, r, dirTmp);\n      } else {\n        IOUtils.closeWhileHandlingException(w, w2, r, dirTmp);\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void build(TermFreqIterator iter) throws IOException {\n\n    if (searcher != null) {\n      searcher.getIndexReader().close();\n      searcher = null;\n    }\n\n    TermFreqPayloadIterator payloads;\n    if (iter instanceof TermFreqPayloadIterator) {\n      payloads = (TermFreqPayloadIterator) iter;\n    } else {\n      payloads = null;\n    }\n    Directory dirTmp = getDirectory(new File(indexPath.toString() + \".tmp\"));\n\n    IndexWriter w = null;\n    IndexWriter w2 = null;\n    AtomicReader r = null;\n    boolean success = false;\n    try {\n      Analyzer gramAnalyzer = new AnalyzerWrapper() {\n          @Override\n          protected Analyzer getWrappedAnalyzer(String fieldName) {\n            return indexAnalyzer;\n          }\n\n          @Override\n          protected TokenStreamComponents wrapComponents(String fieldName, TokenStreamComponents components) {\n            if (fieldName.equals(\"textgrams\") && minPrefixChars > 0) {\n              return new TokenStreamComponents(components.getTokenizer(),\n                                               new EdgeNGramTokenFilter(matchVersion,\n                                                                        components.getTokenStream(),\n                                                                        1, minPrefixChars));\n            } else {\n              return components;\n            }\n          }\n        };\n\n      w = new IndexWriter(dirTmp,\n                          getIndexWriterConfig(matchVersion, gramAnalyzer));\n      BytesRef text;\n      Document doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      ft.setIndexOptions(IndexOptions.DOCS_ONLY);\n      ft.setOmitNorms(true);\n      Field textField = new Field(TEXT_FIELD_NAME, \"\", ft);\n      doc.add(textField);\n\n      Field textGramField = new Field(\"textgrams\", \"\", ft);\n      doc.add(textGramField);\n\n      Field textDVField = new BinaryDocValuesField(TEXT_FIELD_NAME, new BytesRef());\n      doc.add(textDVField);\n\n      // TODO: use threads...?\n      Field weightField = new NumericDocValuesField(\"weight\", 0);\n      doc.add(weightField);\n\n      Field payloadField;\n      if (payloads != null) {\n        payloadField = new BinaryDocValuesField(\"payloads\", new BytesRef());\n        doc.add(payloadField);\n      } else {\n        payloadField = null;\n      }\n\n      //long t0 = System.nanoTime();\n      while ((text = iter.next()) != null) {\n        String textString = text.utf8ToString();\n        textField.setStringValue(textString);\n        textGramField.setStringValue(textString);\n        textDVField.setBytesValue(text);\n        weightField.setLongValue(iter.weight());\n        if (payloads != null) {\n          payloadField.setBytesValue(payloads.payload());\n        }\n        w.addDocument(doc);\n      }\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n\n      r = new SlowCompositeReaderWrapper(DirectoryReader.open(w, false));\n      //long t1 = System.nanoTime();\n      w.rollback();\n\n      final int maxDoc = r.maxDoc();\n\n      final NumericDocValues weights = r.getNumericDocValues(\"weight\");\n\n      final Sorter.DocComparator comparator = new Sorter.DocComparator() {\n          @Override\n          public int compare(int docID1, int docID2) {\n            final long v1 = weights.get(docID1);\n            final long v2 = weights.get(docID2);\n            // Reverse sort (highest weight first);\n            // java7 only:\n            //return Long.compare(v2, v1);\n            if (v1 > v2) {\n              return -1;\n            } else if (v1 < v2) {\n              return 1;\n            } else {\n              return 0;\n            }\n          }\n        };\n\n      r = SortingAtomicReader.wrap(r, new Sorter() {\n          @Override\n          public Sorter.DocMap sort(AtomicReader reader) throws IOException {\n            return Sorter.sort(maxDoc, comparator);\n          }\n\n          @Override\n          public String getID() {\n            return \"Weight\";\n          }\n        });\n      \n      w2 = new IndexWriter(dir,\n                           getIndexWriterConfig(matchVersion, indexAnalyzer));\n      w2.addIndexes(new IndexReader[] {r});\n      r.close();\n\n      //System.out.println(\"sort time: \" + ((System.nanoTime()-t1)/1000000) + \" msec\");\n\n      searcher = new IndexSearcher(DirectoryReader.open(w2, false));\n      w2.close();\n\n      payloadsDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), \"payloads\");\n      weightsDV = MultiDocValues.getNumericValues(searcher.getIndexReader(), \"weight\");\n      textDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), TEXT_FIELD_NAME);\n      assert textDV != null;\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(w, w2, r, dirTmp);\n      } else {\n        IOUtils.closeWhileHandlingException(w, w2, r, dirTmp);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ada2f7352a7f964fe49bccd13227c4ec38563d39","date":1381659982,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(TermFreqPayloadIterator).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(TermFreqIterator).mjava","sourceNew":"  @Override\n  public void build(TermFreqPayloadIterator iter) throws IOException {\n\n    if (searcher != null) {\n      searcher.getIndexReader().close();\n      searcher = null;\n    }\n\n\n    Directory dirTmp = getDirectory(new File(indexPath.toString() + \".tmp\"));\n\n    IndexWriter w = null;\n    IndexWriter w2 = null;\n    AtomicReader r = null;\n    boolean success = false;\n    try {\n      Analyzer gramAnalyzer = new AnalyzerWrapper(Analyzer.PER_FIELD_REUSE_STRATEGY) {\n          @Override\n          protected Analyzer getWrappedAnalyzer(String fieldName) {\n            return indexAnalyzer;\n          }\n\n          @Override\n          protected TokenStreamComponents wrapComponents(String fieldName, TokenStreamComponents components) {\n            if (fieldName.equals(\"textgrams\") && minPrefixChars > 0) {\n              return new TokenStreamComponents(components.getTokenizer(),\n                                               new EdgeNGramTokenFilter(matchVersion,\n                                                                        components.getTokenStream(),\n                                                                        1, minPrefixChars));\n            } else {\n              return components;\n            }\n          }\n        };\n\n      w = new IndexWriter(dirTmp,\n                          getIndexWriterConfig(matchVersion, gramAnalyzer));\n      BytesRef text;\n      Document doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      ft.setIndexOptions(IndexOptions.DOCS_ONLY);\n      ft.setOmitNorms(true);\n      Field textField = new Field(TEXT_FIELD_NAME, \"\", ft);\n      doc.add(textField);\n\n      Field textGramField = new Field(\"textgrams\", \"\", ft);\n      doc.add(textGramField);\n\n      Field textDVField = new BinaryDocValuesField(TEXT_FIELD_NAME, new BytesRef());\n      doc.add(textDVField);\n\n      // TODO: use threads...?\n      Field weightField = new NumericDocValuesField(\"weight\", 0);\n      doc.add(weightField);\n\n      Field payloadField;\n      if (iter.hasPayloads()) {\n        payloadField = new BinaryDocValuesField(\"payloads\", new BytesRef());\n        doc.add(payloadField);\n      } else {\n        payloadField = null;\n      }\n\n      //long t0 = System.nanoTime();\n      while ((text = iter.next()) != null) {\n        String textString = text.utf8ToString();\n        textField.setStringValue(textString);\n        textGramField.setStringValue(textString);\n        textDVField.setBytesValue(text);\n        weightField.setLongValue(iter.weight());\n        if (iter.hasPayloads()) {\n          payloadField.setBytesValue(iter.payload());\n        }\n        w.addDocument(doc);\n      }\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n\n      r = SlowCompositeReaderWrapper.wrap(DirectoryReader.open(w, false));\n      //long t1 = System.nanoTime();\n      w.rollback();\n\n      final int maxDoc = r.maxDoc();\n\n      final NumericDocValues weights = r.getNumericDocValues(\"weight\");\n\n      final Sorter.DocComparator comparator = new Sorter.DocComparator() {\n          @Override\n          public int compare(int docID1, int docID2) {\n            final long v1 = weights.get(docID1);\n            final long v2 = weights.get(docID2);\n            // Reverse sort (highest weight first);\n            // java7 only:\n            //return Long.compare(v2, v1);\n            if (v1 > v2) {\n              return -1;\n            } else if (v1 < v2) {\n              return 1;\n            } else {\n              return 0;\n            }\n          }\n        };\n\n      r = SortingAtomicReader.wrap(r, new Sorter() {\n          @Override\n          public Sorter.DocMap sort(AtomicReader reader) throws IOException {\n            return Sorter.sort(maxDoc, comparator);\n          }\n\n          @Override\n          public String getID() {\n            return \"Weight\";\n          }\n        });\n      \n      w2 = new IndexWriter(dir,\n                           getIndexWriterConfig(matchVersion, indexAnalyzer));\n      w2.addIndexes(new IndexReader[] {r});\n      r.close();\n\n      //System.out.println(\"sort time: \" + ((System.nanoTime()-t1)/1000000) + \" msec\");\n\n      searcher = new IndexSearcher(DirectoryReader.open(w2, false));\n      w2.close();\n\n      payloadsDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), \"payloads\");\n      weightsDV = MultiDocValues.getNumericValues(searcher.getIndexReader(), \"weight\");\n      textDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), TEXT_FIELD_NAME);\n      assert textDV != null;\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(w, w2, r, dirTmp);\n      } else {\n        IOUtils.closeWhileHandlingException(w, w2, r, dirTmp);\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void build(TermFreqIterator iter) throws IOException {\n\n    if (searcher != null) {\n      searcher.getIndexReader().close();\n      searcher = null;\n    }\n\n    TermFreqPayloadIterator payloads;\n    if (iter instanceof TermFreqPayloadIterator) {\n      payloads = (TermFreqPayloadIterator) iter;\n    } else {\n      payloads = null;\n    }\n    Directory dirTmp = getDirectory(new File(indexPath.toString() + \".tmp\"));\n\n    IndexWriter w = null;\n    IndexWriter w2 = null;\n    AtomicReader r = null;\n    boolean success = false;\n    try {\n      Analyzer gramAnalyzer = new AnalyzerWrapper(Analyzer.PER_FIELD_REUSE_STRATEGY) {\n          @Override\n          protected Analyzer getWrappedAnalyzer(String fieldName) {\n            return indexAnalyzer;\n          }\n\n          @Override\n          protected TokenStreamComponents wrapComponents(String fieldName, TokenStreamComponents components) {\n            if (fieldName.equals(\"textgrams\") && minPrefixChars > 0) {\n              return new TokenStreamComponents(components.getTokenizer(),\n                                               new EdgeNGramTokenFilter(matchVersion,\n                                                                        components.getTokenStream(),\n                                                                        1, minPrefixChars));\n            } else {\n              return components;\n            }\n          }\n        };\n\n      w = new IndexWriter(dirTmp,\n                          getIndexWriterConfig(matchVersion, gramAnalyzer));\n      BytesRef text;\n      Document doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      ft.setIndexOptions(IndexOptions.DOCS_ONLY);\n      ft.setOmitNorms(true);\n      Field textField = new Field(TEXT_FIELD_NAME, \"\", ft);\n      doc.add(textField);\n\n      Field textGramField = new Field(\"textgrams\", \"\", ft);\n      doc.add(textGramField);\n\n      Field textDVField = new BinaryDocValuesField(TEXT_FIELD_NAME, new BytesRef());\n      doc.add(textDVField);\n\n      // TODO: use threads...?\n      Field weightField = new NumericDocValuesField(\"weight\", 0);\n      doc.add(weightField);\n\n      Field payloadField;\n      if (payloads != null) {\n        payloadField = new BinaryDocValuesField(\"payloads\", new BytesRef());\n        doc.add(payloadField);\n      } else {\n        payloadField = null;\n      }\n\n      //long t0 = System.nanoTime();\n      while ((text = iter.next()) != null) {\n        String textString = text.utf8ToString();\n        textField.setStringValue(textString);\n        textGramField.setStringValue(textString);\n        textDVField.setBytesValue(text);\n        weightField.setLongValue(iter.weight());\n        if (payloads != null) {\n          payloadField.setBytesValue(payloads.payload());\n        }\n        w.addDocument(doc);\n      }\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n\n      r = SlowCompositeReaderWrapper.wrap(DirectoryReader.open(w, false));\n      //long t1 = System.nanoTime();\n      w.rollback();\n\n      final int maxDoc = r.maxDoc();\n\n      final NumericDocValues weights = r.getNumericDocValues(\"weight\");\n\n      final Sorter.DocComparator comparator = new Sorter.DocComparator() {\n          @Override\n          public int compare(int docID1, int docID2) {\n            final long v1 = weights.get(docID1);\n            final long v2 = weights.get(docID2);\n            // Reverse sort (highest weight first);\n            // java7 only:\n            //return Long.compare(v2, v1);\n            if (v1 > v2) {\n              return -1;\n            } else if (v1 < v2) {\n              return 1;\n            } else {\n              return 0;\n            }\n          }\n        };\n\n      r = SortingAtomicReader.wrap(r, new Sorter() {\n          @Override\n          public Sorter.DocMap sort(AtomicReader reader) throws IOException {\n            return Sorter.sort(maxDoc, comparator);\n          }\n\n          @Override\n          public String getID() {\n            return \"Weight\";\n          }\n        });\n      \n      w2 = new IndexWriter(dir,\n                           getIndexWriterConfig(matchVersion, indexAnalyzer));\n      w2.addIndexes(new IndexReader[] {r});\n      r.close();\n\n      //System.out.println(\"sort time: \" + ((System.nanoTime()-t1)/1000000) + \" msec\");\n\n      searcher = new IndexSearcher(DirectoryReader.open(w2, false));\n      w2.close();\n\n      payloadsDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), \"payloads\");\n      weightsDV = MultiDocValues.getNumericValues(searcher.getIndexReader(), \"weight\");\n      textDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), TEXT_FIELD_NAME);\n      assert textDV != null;\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(w, w2, r, dirTmp);\n      } else {\n        IOUtils.closeWhileHandlingException(w, w2, r, dirTmp);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"38061899d760e06a12fe186bc1f09ca9ff0e64a6":["b3aad8246db872dc16fbe6109f893457496b0240"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","b3aad8246db872dc16fbe6109f893457496b0240"],"b3aad8246db872dc16fbe6109f893457496b0240":["33ba398fa7984fdcb45fd76b87504d5adf7ca5e3"],"3dffec77fb8f7d0e9ca4869dddd6af94528b4576":["37a0f60745e53927c4c876cfe5b5a58170f0646c","df9bf66ed405ee5c7d32b47bdb36c2e36d2c1392"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"df9bf66ed405ee5c7d32b47bdb36c2e36d2c1392":["38061899d760e06a12fe186bc1f09ca9ff0e64a6"],"33ba398fa7984fdcb45fd76b87504d5adf7ca5e3":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["ada2f7352a7f964fe49bccd13227c4ec38563d39"],"ada2f7352a7f964fe49bccd13227c4ec38563d39":["df9bf66ed405ee5c7d32b47bdb36c2e36d2c1392"]},"commit2Childs":{"38061899d760e06a12fe186bc1f09ca9ff0e64a6":["df9bf66ed405ee5c7d32b47bdb36c2e36d2c1392"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":["3dffec77fb8f7d0e9ca4869dddd6af94528b4576"],"b3aad8246db872dc16fbe6109f893457496b0240":["38061899d760e06a12fe186bc1f09ca9ff0e64a6","37a0f60745e53927c4c876cfe5b5a58170f0646c"],"3dffec77fb8f7d0e9ca4869dddd6af94528b4576":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["37a0f60745e53927c4c876cfe5b5a58170f0646c","33ba398fa7984fdcb45fd76b87504d5adf7ca5e3"],"df9bf66ed405ee5c7d32b47bdb36c2e36d2c1392":["3dffec77fb8f7d0e9ca4869dddd6af94528b4576","ada2f7352a7f964fe49bccd13227c4ec38563d39"],"33ba398fa7984fdcb45fd76b87504d5adf7ca5e3":["b3aad8246db872dc16fbe6109f893457496b0240"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"ada2f7352a7f964fe49bccd13227c4ec38563d39":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["3dffec77fb8f7d0e9ca4869dddd6af94528b4576","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}