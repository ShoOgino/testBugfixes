{"path":"modules/analysis/common/src/test/org/apache/lucene/analysis/util/TestCharTokenizers#testMaxWordLengthWithSupplementary().mjava","commits":[{"id":"1d6179f9c4237a7e5d423f4e4b439a94e967efc9","date":1304382587,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"modules/analysis/common/src/test/org/apache/lucene/analysis/util/TestCharTokenizers#testMaxWordLengthWithSupplementary().mjava","pathOld":"lucene/src/test/org/apache/lucene/analysis/TestCharTokenizers#testMaxWordLengthWithSupplementary().mjava","sourceNew":"  /*\n   * tests the max word length of 255 with a surrogate pair at position 255\n   */\n  public void testMaxWordLengthWithSupplementary() throws IOException {\n    StringBuilder builder = new StringBuilder();\n\n    for (int i = 0; i < 254; i++) {\n      builder.append(\"A\");\n    }\n    builder.append(\"\\ud801\\udc1c\");\n    Tokenizer tokenizer = new LowerCaseTokenizer(TEST_VERSION_CURRENT, new StringReader(builder.toString() + builder.toString()));\n    assertTokenStreamContents(tokenizer, new String[] {builder.toString().toLowerCase(), builder.toString().toLowerCase()});\n  }\n\n","sourceOld":"  /*\n   * tests the max word length of 255 with a surrogate pair at position 255\n   */\n  public void testMaxWordLengthWithSupplementary() throws IOException {\n    StringBuilder builder = new StringBuilder();\n\n    for (int i = 0; i < 254; i++) {\n      builder.append(\"A\");\n    }\n    builder.append(\"\\ud801\\udc1c\");\n    MockTokenizer tokenizer = new MockTokenizer(new StringReader(builder.toString() + builder.toString()), MockTokenizer.SIMPLE, true);\n    assertTokenStreamContents(tokenizer, new String[] {builder.toString().toLowerCase(), builder.toString().toLowerCase()});\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c700f8d0842d3e52bb2bdfbfdc046a137e836edb","date":1305285499,"type":1,"author":"Simon Willnauer","isMerge":true,"pathNew":"modules/analysis/common/src/test/org/apache/lucene/analysis/util/TestCharTokenizers#testMaxWordLengthWithSupplementary().mjava","pathOld":"lucene/src/test/org/apache/lucene/analysis/TestCharTokenizers#testMaxWordLengthWithSupplementary().mjava","sourceNew":"  /*\n   * tests the max word length of 255 with a surrogate pair at position 255\n   */\n  public void testMaxWordLengthWithSupplementary() throws IOException {\n    StringBuilder builder = new StringBuilder();\n\n    for (int i = 0; i < 254; i++) {\n      builder.append(\"A\");\n    }\n    builder.append(\"\\ud801\\udc1c\");\n    Tokenizer tokenizer = new LowerCaseTokenizer(TEST_VERSION_CURRENT, new StringReader(builder.toString() + builder.toString()));\n    assertTokenStreamContents(tokenizer, new String[] {builder.toString().toLowerCase(), builder.toString().toLowerCase()});\n  }\n\n","sourceOld":"  /*\n   * tests the max word length of 255 with a surrogate pair at position 255\n   */\n  public void testMaxWordLengthWithSupplementary() throws IOException {\n    StringBuilder builder = new StringBuilder();\n\n    for (int i = 0; i < 254; i++) {\n      builder.append(\"A\");\n    }\n    builder.append(\"\\ud801\\udc1c\");\n    MockTokenizer tokenizer = new MockTokenizer(new StringReader(builder.toString() + builder.toString()), MockTokenizer.SIMPLE, true);\n    assertTokenStreamContents(tokenizer, new String[] {builder.toString().toLowerCase(), builder.toString().toLowerCase()});\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":0,"author":"Steven Rowe","isMerge":true,"pathNew":"modules/analysis/common/src/test/org/apache/lucene/analysis/util/TestCharTokenizers#testMaxWordLengthWithSupplementary().mjava","pathOld":"/dev/null","sourceNew":"  /*\n   * tests the max word length of 255 with a surrogate pair at position 255\n   */\n  public void testMaxWordLengthWithSupplementary() throws IOException {\n    StringBuilder builder = new StringBuilder();\n\n    for (int i = 0; i < 254; i++) {\n      builder.append(\"A\");\n    }\n    builder.append(\"\\ud801\\udc1c\");\n    Tokenizer tokenizer = new LowerCaseTokenizer(TEST_VERSION_CURRENT, new StringReader(builder.toString() + builder.toString()));\n    assertTokenStreamContents(tokenizer, new String[] {builder.toString().toLowerCase(), builder.toString().toLowerCase()});\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/util/TestCharTokenizers#testMaxWordLengthWithSupplementary().mjava","pathOld":"modules/analysis/common/src/test/org/apache/lucene/analysis/util/TestCharTokenizers#testMaxWordLengthWithSupplementary().mjava","sourceNew":"  /*\n   * tests the max word length of 255 with a surrogate pair at position 255\n   */\n  public void testMaxWordLengthWithSupplementary() throws IOException {\n    StringBuilder builder = new StringBuilder();\n\n    for (int i = 0; i < 254; i++) {\n      builder.append(\"A\");\n    }\n    builder.append(\"\\ud801\\udc1c\");\n    Tokenizer tokenizer = new LowerCaseTokenizer(TEST_VERSION_CURRENT, new StringReader(builder.toString() + builder.toString()));\n    assertTokenStreamContents(tokenizer, new String[] {builder.toString().toLowerCase(), builder.toString().toLowerCase()});\n  }\n\n","sourceOld":"  /*\n   * tests the max word length of 255 with a surrogate pair at position 255\n   */\n  public void testMaxWordLengthWithSupplementary() throws IOException {\n    StringBuilder builder = new StringBuilder();\n\n    for (int i = 0; i < 254; i++) {\n      builder.append(\"A\");\n    }\n    builder.append(\"\\ud801\\udc1c\");\n    Tokenizer tokenizer = new LowerCaseTokenizer(TEST_VERSION_CURRENT, new StringReader(builder.toString() + builder.toString()));\n    assertTokenStreamContents(tokenizer, new String[] {builder.toString().toLowerCase(), builder.toString().toLowerCase()});\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["1d6179f9c4237a7e5d423f4e4b439a94e967efc9"],"1d6179f9c4237a7e5d423f4e4b439a94e967efc9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a3776dccca01c11e7046323cfad46a3b4a471233":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","1d6179f9c4237a7e5d423f4e4b439a94e967efc9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"c700f8d0842d3e52bb2bdfbfdc046a137e836edb":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","1d6179f9c4237a7e5d423f4e4b439a94e967efc9"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b89678825b68eccaf09e6ab71675fc0b0af1e099"]},"commit2Childs":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"1d6179f9c4237a7e5d423f4e4b439a94e967efc9":["b89678825b68eccaf09e6ab71675fc0b0af1e099","a3776dccca01c11e7046323cfad46a3b4a471233","c700f8d0842d3e52bb2bdfbfdc046a137e836edb"],"a3776dccca01c11e7046323cfad46a3b4a471233":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["1d6179f9c4237a7e5d423f4e4b439a94e967efc9","a3776dccca01c11e7046323cfad46a3b4a471233","c700f8d0842d3e52bb2bdfbfdc046a137e836edb"],"c700f8d0842d3e52bb2bdfbfdc046a137e836edb":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a3776dccca01c11e7046323cfad46a3b4a471233","c700f8d0842d3e52bb2bdfbfdc046a137e836edb","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}