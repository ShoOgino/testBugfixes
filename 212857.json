{"path":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","commits":[{"id":"66e0b82bd39567aa2bf534e5282d05fb4a4a2c76","date":1471585465,"type":1,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<ReplicaAssigner.Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = ocmh.identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.info(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<ReplicaAssigner.Position, String> e : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up  artifacts for failed create collection for [\" + collectionName + \"]\");\n      } else {\n        log.debug(\"Finished create command on all shards for collection: \"\n            + collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n    \n    validateConfigOrThrowSolrException(configName);\n    \n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n        \n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader);\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.info(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<Position, String> e : positionVsNodes.entrySet()) {\n        Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up  artifacts for failed create collection for [\" + collectionName + \"]\");\n      } else {\n        log.debug(\"Finished create command on all shards for collection: \"\n            + collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"403d05f7f8d69b65659157eff1bc1d2717f04c66","date":1471692961,"type":1,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<ReplicaAssigner.Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = ocmh.identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.info(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<ReplicaAssigner.Position, String> e : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up  artifacts for failed create collection for [\" + collectionName + \"]\");\n      } else {\n        log.debug(\"Finished create command on all shards for collection: \"\n            + collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n    \n    validateConfigOrThrowSolrException(configName);\n    \n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n        \n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader);\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.info(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<Position, String> e : positionVsNodes.entrySet()) {\n        Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up  artifacts for failed create collection for [\" + collectionName + \"]\");\n      } else {\n        log.debug(\"Finished create command on all shards for collection: \"\n            + collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"962cd4f5e313777f35da8f521265323e84184929","date":1474533758,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<ReplicaAssigner.Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = ocmh.identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<ReplicaAssigner.Position, String> e : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<ReplicaAssigner.Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = ocmh.identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.info(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<ReplicaAssigner.Position, String> e : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up  artifacts for failed create collection for [\" + collectionName + \"]\");\n      } else {\n        log.debug(\"Finished create command on all shards for collection: \"\n            + collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"17e5da53e4e5bd659e22add9bba1cfa222e7e30d","date":1475435902,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<ReplicaAssigner.Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = ocmh.identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<ReplicaAssigner.Position, String> e : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<ReplicaAssigner.Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = ocmh.identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.info(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<ReplicaAssigner.Position, String> e : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up  artifacts for failed create collection for [\" + collectionName + \"]\");\n      } else {\n        log.debug(\"Finished create command on all shards for collection: \"\n            + collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d528fd7ae22865015b756e0a03832e2051de2a9c","date":1476721105,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<ReplicaAssigner.Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = ocmh.identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<ReplicaAssigner.Position, String> e : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<ReplicaAssigner.Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = ocmh.identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<ReplicaAssigner.Position, String> e : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<ReplicaAssigner.Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = ocmh.identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<ReplicaAssigner.Position, String> e : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f291d2d430e8149d24fdd06b0bcdab0941ec9144","date":1481216635,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<ReplicaAssigner.Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = ocmh.identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<ReplicaAssigner.Position, String> e : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<ReplicaAssigner.Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = ocmh.identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<ReplicaAssigner.Position, String> e : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":["8c7a6584aa35e033d783e02c6f4eefa6ad21c7fe","115923bc88e5b1dc4bef049b1ded8486723052ed"],"bugIntro":["5ad9c35f926b4bf8da0336d1300efc709c8d5a56","5ad9c35f926b4bf8da0336d1300efc709c8d5a56","5ad9c35f926b4bf8da0336d1300efc709c8d5a56","5ad9c35f926b4bf8da0336d1300efc709c8d5a56"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9856095f7afb5a607bf5e65077615ed91273508c","date":1481837697,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<ReplicaAssigner.Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = ocmh.identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<ReplicaAssigner.Position, String> e : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<ReplicaAssigner.Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = ocmh.identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<ReplicaAssigner.Position, String> e : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"61c45e99cf6676da48f19d7511c73712ad39402b","date":1495508331,"type":3,"author":"Tomas Fernandez Lobbe","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, 1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<ReplicaAssigner.Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = ocmh.identifyNodes(clusterState, nodeList, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<ReplicaAssigner.Position, String> e : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = Assign.buildCoreName(collectionName, position.shard, position.type, position.index + 1);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl, \n              ZkStateReader.REPLICA_TYPE, position.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, position.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<ReplicaAssigner.Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = ocmh.identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<ReplicaAssigner.Position, String> e : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":["45cb1a93c8314086fa3e14744fbc4eec36006057"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"45cb1a93c8314086fa3e14744fbc4eec36006057","date":1496192068,"type":3,"author":"Tomas Fernandez Lobbe","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<ReplicaAssigner.Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = ocmh.identifyNodes(clusterState, nodeList, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<ReplicaAssigner.Position, String> e : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = Assign.buildCoreName(collectionName, position.shard, position.type, position.index + 1);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl, \n              ZkStateReader.REPLICA_TYPE, position.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, position.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, 1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<ReplicaAssigner.Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = ocmh.identifyNodes(clusterState, nodeList, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<ReplicaAssigner.Position, String> e : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = Assign.buildCoreName(collectionName, position.shard, position.type, position.index + 1);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl, \n              ZkStateReader.REPLICA_TYPE, position.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, position.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":["61c45e99cf6676da48f19d7511c73712ad39402b"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d1f5728f32a4a256b36cfabd7a2636452f599bb9","date":1496231774,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<ReplicaAssigner.Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = ocmh.identifyNodes(clusterState, nodeList, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<ReplicaAssigner.Position, String> e : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = Assign.buildCoreName(collectionName, position.shard, position.type, position.index + 1);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl, \n              ZkStateReader.REPLICA_TYPE, position.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, position.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, 1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<ReplicaAssigner.Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = ocmh.identifyNodes(clusterState, nodeList, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<ReplicaAssigner.Position, String> e : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = Assign.buildCoreName(collectionName, position.shard, position.type, position.index + 1);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl, \n              ZkStateReader.REPLICA_TYPE, position.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, position.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"44b289ba5434fa10782118c697fa706d6cf231df","date":1496249545,"type":3,"author":"Chris Hostetter","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<ReplicaAssigner.Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = ocmh.identifyNodes(clusterState, nodeList, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<ReplicaAssigner.Position, String> e : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = Assign.buildCoreName(collectionName, position.shard, position.type, position.index + 1);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl, \n              ZkStateReader.REPLICA_TYPE, position.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, position.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, 1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<ReplicaAssigner.Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = ocmh.identifyNodes(clusterState, nodeList, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<ReplicaAssigner.Position, String> e : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = Assign.buildCoreName(collectionName, position.shard, position.type, position.index + 1);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl, \n              ZkStateReader.REPLICA_TYPE, position.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, position.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"25e4a4cddd699db6cce60282e747c7705897e821","date":1496721158,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, 1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<ReplicaAssigner.Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = ocmh.identifyNodes(clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<ReplicaAssigner.Position, String> e : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = Assign.buildCoreName(collectionName, position.shard, position.type, position.index + 1);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl, \n              ZkStateReader.REPLICA_TYPE, position.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, position.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, 1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<ReplicaAssigner.Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = ocmh.identifyNodes(clusterState, nodeList, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<ReplicaAssigner.Position, String> e : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = Assign.buildCoreName(collectionName, position.shard, position.type, position.index + 1);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl, \n              ZkStateReader.REPLICA_TYPE, position.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, position.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"74aea047dff7f7c38a2d766827bd20d356f98c6a","date":1496721416,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<ReplicaAssigner.Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = ocmh.identifyNodes(clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<ReplicaAssigner.Position, String> e : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = Assign.buildCoreName(collectionName, position.shard, position.type, position.index + 1);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl, \n              ZkStateReader.REPLICA_TYPE, position.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, position.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<ReplicaAssigner.Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = ocmh.identifyNodes(clusterState, nodeList, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<ReplicaAssigner.Position, String> e : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = Assign.buildCoreName(collectionName, position.shard, position.type, position.index + 1);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl, \n              ZkStateReader.REPLICA_TYPE, position.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, position.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e9017cf144952056066919f1ebc7897ff9bd71b1","date":1496757600,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<ReplicaAssigner.Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = ocmh.identifyNodes(clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<ReplicaAssigner.Position, String> e : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = Assign.buildCoreName(collectionName, position.shard, position.type, position.index + 1);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl, \n              ZkStateReader.REPLICA_TYPE, position.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, position.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<ReplicaAssigner.Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = ocmh.identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<ReplicaAssigner.Position, String> e : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"114b665752b215f36836a7c5411f7c433b4d1352","date":1497007372,"type":3,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n      boolean autoAddReplicas = message.getBool(AUTO_ADD_REPLICAS, false);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<ReplicaAssigner.Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = ocmh.identifyNodes(clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<ReplicaAssigner.Position, String> e : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = Assign.buildCoreName(collectionName, position.shard, position.type, position.index + 1);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl, \n              ZkStateReader.REPLICA_TYPE, position.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, position.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        if (autoAddReplicas) {\n          ocmh.forwardToAutoScaling(AutoScaling.AUTO_ADD_REPLICAS_TRIGGER_DSL);\n        }\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<ReplicaAssigner.Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = ocmh.identifyNodes(clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<ReplicaAssigner.Position, String> e : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = Assign.buildCoreName(collectionName, position.shard, position.type, position.index + 1);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl, \n              ZkStateReader.REPLICA_TYPE, position.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, position.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"28288370235ed02234a64753cdbf0c6ec096304a","date":1498726817,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<ReplicaAssigner.Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = ocmh.identifyNodes(clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<ReplicaAssigner.Position, String> e : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = Assign.buildCoreName(collectionName, position.shard, position.type, position.index + 1);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl, \n              ZkStateReader.REPLICA_TYPE, position.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, position.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<ReplicaAssigner.Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = ocmh.identifyNodes(clusterState, nodeList, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<ReplicaAssigner.Position, String> e : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = Assign.buildCoreName(collectionName, position.shard, position.type, position.index + 1);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl, \n              ZkStateReader.REPLICA_TYPE, position.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, position.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"969718c368b28ed1b2335ea2deb275c696cddb4f","date":1498803580,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      List<ReplicaPosition> replicaPositions;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        replicaPositions = new ArrayList<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        replicaPositions = Assign.identifyNodes(() -> ocmh.overseer.getZkController().getCoreContainer(),\n            ocmh.zkStateReader\n            , clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildCoreName(collectionName, replicaPosition.shard, replicaPosition.type, replicaPosition.index + 1);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<ReplicaAssigner.Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = ocmh.identifyNodes(clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<ReplicaAssigner.Position, String> e : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = Assign.buildCoreName(collectionName, position.shard, position.type, position.index + 1);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl, \n              ZkStateReader.REPLICA_TYPE, position.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, position.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0d92226151c91fb4bebcca6d18782d1c84aee2cd","date":1498804792,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n      boolean autoAddReplicas = message.getBool(AUTO_ADD_REPLICAS, false);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      List<ReplicaPosition> replicaPositions;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        replicaPositions = new ArrayList<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        replicaPositions = Assign.identifyNodes(() -> ocmh.overseer.getZkController().getCoreContainer(),\n            ocmh.zkStateReader\n            , clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildCoreName(collectionName, replicaPosition.shard, replicaPosition.type, replicaPosition.index + 1);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        if (autoAddReplicas) {\n          ocmh.forwardToAutoScaling(AutoScaling.AUTO_ADD_REPLICAS_TRIGGER_DSL);\n        }\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n      boolean autoAddReplicas = message.getBool(AUTO_ADD_REPLICAS, false);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<ReplicaAssigner.Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = ocmh.identifyNodes(clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<ReplicaAssigner.Position, String> e : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = Assign.buildCoreName(collectionName, position.shard, position.type, position.index + 1);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl, \n              ZkStateReader.REPLICA_TYPE, position.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, position.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        if (autoAddReplicas) {\n          ocmh.forwardToAutoScaling(AutoScaling.AUTO_ADD_REPLICAS_TRIGGER_DSL);\n        }\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":["5ad9c35f926b4bf8da0336d1300efc709c8d5a56","5ad9c35f926b4bf8da0336d1300efc709c8d5a56","5ad9c35f926b4bf8da0336d1300efc709c8d5a56","5ad9c35f926b4bf8da0336d1300efc709c8d5a56"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"091980700f1c5c53946291e7fa2b9024b586b288","date":1499600138,"type":3,"author":"Ishan Chattopadhyaya","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      List<ReplicaPosition> replicaPositions;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        replicaPositions = new ArrayList<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        replicaPositions = Assign.identifyNodes(() -> ocmh.overseer.getZkController().getCoreContainer(),\n            ocmh.zkStateReader\n            , clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildCoreName(collectionName, replicaPosition.shard, replicaPosition.type, replicaPosition.index + 1);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n\n        // Emit a warning about production use of data driven functionality\n        boolean defaultConfigSetUsed = message.getStr(COLL_CONF) == null ||\n            message.getStr(COLL_CONF).equals(ConfigSetsHandlerApi.DEFAULT_CONFIGSET_NAME);\n        if (defaultConfigSetUsed) {\n          results.add(\"warning\", \"Using _default configset. Data driven schema functionality\"\n              + \" is enabled by default, which is NOT RECOMMENDED for production use. To turn it off:\"\n              + \" curl http://{host:port}/solr/\" + collectionName + \"/config -d '{\\\"set-user-property\\\": {\\\"update.autoCreateFields\\\":\\\"false\\\"}}'\");\n        }\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      List<ReplicaPosition> replicaPositions;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        replicaPositions = new ArrayList<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        replicaPositions = Assign.identifyNodes(() -> ocmh.overseer.getZkController().getCoreContainer(),\n            ocmh.zkStateReader\n            , clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildCoreName(collectionName, replicaPosition.shard, replicaPosition.type, replicaPosition.index + 1);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f9a989a32a073c55e3aef6f807a3474184bbcf49","date":1499930209,"type":3,"author":"Cao Manh Dat","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n      boolean autoAddReplicas = message.getBool(AUTO_ADD_REPLICAS, false);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      List<ReplicaPosition> replicaPositions;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        replicaPositions = new ArrayList<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        replicaPositions = Assign.identifyNodes(() -> ocmh.overseer.getZkController().getCoreContainer(),\n            ocmh.zkStateReader\n            , clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildCoreName(collectionName, replicaPosition.shard, replicaPosition.type, replicaPosition.index + 1);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        if (autoAddReplicas) {\n          ocmh.forwardToAutoScaling(AutoScaling.AUTO_ADD_REPLICAS_TRIGGER_DSL);\n        }\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n\n        // Emit a warning about production use of data driven functionality\n        boolean defaultConfigSetUsed = message.getStr(COLL_CONF) == null ||\n            message.getStr(COLL_CONF).equals(ConfigSetsHandlerApi.DEFAULT_CONFIGSET_NAME);\n        if (defaultConfigSetUsed) {\n          results.add(\"warning\", \"Using _default configset. Data driven schema functionality\"\n              + \" is enabled by default, which is NOT RECOMMENDED for production use. To turn it off:\"\n              + \" curl http://{host:port}/solr/\" + collectionName + \"/config -d '{\\\"set-user-property\\\": {\\\"update.autoCreateFields\\\":\\\"false\\\"}}'\");\n        }\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n      boolean autoAddReplicas = message.getBool(AUTO_ADD_REPLICAS, false);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      List<ReplicaPosition> replicaPositions;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        replicaPositions = new ArrayList<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        replicaPositions = Assign.identifyNodes(() -> ocmh.overseer.getZkController().getCoreContainer(),\n            ocmh.zkStateReader\n            , clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildCoreName(collectionName, replicaPosition.shard, replicaPosition.type, replicaPosition.index + 1);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        if (autoAddReplicas) {\n          ocmh.forwardToAutoScaling(AutoScaling.AUTO_ADD_REPLICAS_TRIGGER_DSL);\n        }\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0806aac02ecbbdc6b5d9705ae15da193219c7af4","date":1499930856,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n      boolean autoAddReplicas = message.getBool(AUTO_ADD_REPLICAS, false);\n      Map autoScalingJson = Utils.getJson(ocmh.zkStateReader.getZkClient(), SOLR_AUTOSCALING_CONF_PATH, true);\n      String policy = message.getStr(Policy.POLICY);\n      boolean usePolicyFramework = autoScalingJson.get(Policy.CLUSTER_POLICY) != null || policy != null;\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, usePolicyFramework? 0: 1);\n      if(maxShardsPerNode == 0) message.getProperties().put(MAX_SHARDS_PER_NODE, \"0\");\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      List<ReplicaPosition> replicaPositions;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        replicaPositions = new ArrayList<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (!usePolicyFramework &&  maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n        if (usePolicyFramework && maxShardsPerNode > 0) {\n          if (policy == null) {\n            //this means we should create a policy for this collection\n            AutoScalingHandler ash = (AutoScalingHandler) ocmh.overseer.getZkController().getCoreContainer().getRequestHandler(AutoScalingHandler.HANDLER_PATH);\n            Map newPolicy = Utils.makeMap(REPLICA, \"<\" + (maxShardsPerNode + 1), SHARD, Policy.EACH, \"node\", Policy.ANY);\n            SolrQueryResponse rsp = new SolrQueryResponse();\n            policy = \"COLL_POLICY_\" + collectionName;\n            ash.handleSetPolicies(null, rsp, new CommandOperation(AutoScalingParams.CMD_SET_POLICY, singletonMap(\n                policy\n                , Collections.singletonList(newPolicy))));\n            if (!\"success\".equals(rsp.getValues().get(\"result\"))) {\n              throw new SolrException(ErrorCode.SERVER_ERROR, \"unable to create new policy\");\n            }\n            message.getProperties().put(Policy.POLICY, policy);\n\n          } else {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection\");\n          }\n        }\n\n        replicaPositions = Assign.identifyNodes(() -> ocmh.overseer.getZkController().getCoreContainer(),\n            ocmh.zkStateReader\n            , clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildCoreName(collectionName, replicaPosition.shard, replicaPosition.type, replicaPosition.index + 1);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        if (autoAddReplicas) {\n          ocmh.forwardToAutoScaling(AutoScaling.AUTO_ADD_REPLICAS_TRIGGER_DSL);\n        }\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n      boolean autoAddReplicas = message.getBool(AUTO_ADD_REPLICAS, false);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      List<ReplicaPosition> replicaPositions;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        replicaPositions = new ArrayList<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        replicaPositions = Assign.identifyNodes(() -> ocmh.overseer.getZkController().getCoreContainer(),\n            ocmh.zkStateReader\n            , clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildCoreName(collectionName, replicaPosition.shard, replicaPosition.type, replicaPosition.index + 1);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        if (autoAddReplicas) {\n          ocmh.forwardToAutoScaling(AutoScaling.AUTO_ADD_REPLICAS_TRIGGER_DSL);\n        }\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fb569fd721c41eafc2a2d788499a7df490c7f1a5","date":1499930871,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n      boolean autoAddReplicas = message.getBool(AUTO_ADD_REPLICAS, false);\n      Map autoScalingJson = Utils.getJson(ocmh.zkStateReader.getZkClient(), SOLR_AUTOSCALING_CONF_PATH, true);\n      String policy = message.getStr(Policy.POLICY);\n      boolean usePolicyFramework = autoScalingJson.get(Policy.CLUSTER_POLICY) != null || policy != null;\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, usePolicyFramework? 0: 1);\n      if(maxShardsPerNode == 0) message.getProperties().put(MAX_SHARDS_PER_NODE, \"0\");\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      List<ReplicaPosition> replicaPositions;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        replicaPositions = new ArrayList<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (!usePolicyFramework &&  maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n        if (usePolicyFramework && maxShardsPerNode > 0) {\n          if (policy == null) {\n            //this means we should create a policy for this collection\n            AutoScalingHandler ash = (AutoScalingHandler) ocmh.overseer.getZkController().getCoreContainer().getRequestHandler(AutoScalingHandler.HANDLER_PATH);\n            Map newPolicy = Utils.makeMap(REPLICA, \"<\" + (maxShardsPerNode + 1), SHARD, Policy.EACH, \"node\", Policy.ANY);\n            SolrQueryResponse rsp = new SolrQueryResponse();\n            policy = \"COLL_POLICY_\" + collectionName;\n            ash.handleSetPolicies(null, rsp, new CommandOperation(AutoScalingParams.CMD_SET_POLICY, singletonMap(\n                policy\n                , Collections.singletonList(newPolicy))));\n            if (!\"success\".equals(rsp.getValues().get(\"result\"))) {\n              throw new SolrException(ErrorCode.SERVER_ERROR, \"unable to create new policy\");\n            }\n            message.getProperties().put(Policy.POLICY, policy);\n\n          } else {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection\");\n          }\n        }\n\n        replicaPositions = Assign.identifyNodes(() -> ocmh.overseer.getZkController().getCoreContainer(),\n            ocmh.zkStateReader\n            , clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildCoreName(collectionName, replicaPosition.shard, replicaPosition.type, replicaPosition.index + 1);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        if (autoAddReplicas) {\n          ocmh.forwardToAutoScaling(AutoScaling.AUTO_ADD_REPLICAS_TRIGGER_DSL);\n        }\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n\n        // Emit a warning about production use of data driven functionality\n        boolean defaultConfigSetUsed = message.getStr(COLL_CONF) == null ||\n            message.getStr(COLL_CONF).equals(ConfigSetsHandlerApi.DEFAULT_CONFIGSET_NAME);\n        if (defaultConfigSetUsed) {\n          results.add(\"warning\", \"Using _default configset. Data driven schema functionality\"\n              + \" is enabled by default, which is NOT RECOMMENDED for production use. To turn it off:\"\n              + \" curl http://{host:port}/solr/\" + collectionName + \"/config -d '{\\\"set-user-property\\\": {\\\"update.autoCreateFields\\\":\\\"false\\\"}}'\");\n        }\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n      boolean autoAddReplicas = message.getBool(AUTO_ADD_REPLICAS, false);\n      Map autoScalingJson = Utils.getJson(ocmh.zkStateReader.getZkClient(), SOLR_AUTOSCALING_CONF_PATH, true);\n      String policy = message.getStr(Policy.POLICY);\n      boolean usePolicyFramework = autoScalingJson.get(Policy.CLUSTER_POLICY) != null || policy != null;\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, usePolicyFramework? 0: 1);\n      if(maxShardsPerNode == 0) message.getProperties().put(MAX_SHARDS_PER_NODE, \"0\");\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      List<ReplicaPosition> replicaPositions;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        replicaPositions = new ArrayList<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (!usePolicyFramework &&  maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n        if (usePolicyFramework && maxShardsPerNode > 0) {\n          if (policy == null) {\n            //this means we should create a policy for this collection\n            AutoScalingHandler ash = (AutoScalingHandler) ocmh.overseer.getZkController().getCoreContainer().getRequestHandler(AutoScalingHandler.HANDLER_PATH);\n            Map newPolicy = Utils.makeMap(REPLICA, \"<\" + (maxShardsPerNode + 1), SHARD, Policy.EACH, \"node\", Policy.ANY);\n            SolrQueryResponse rsp = new SolrQueryResponse();\n            policy = \"COLL_POLICY_\" + collectionName;\n            ash.handleSetPolicies(null, rsp, new CommandOperation(AutoScalingParams.CMD_SET_POLICY, singletonMap(\n                policy\n                , Collections.singletonList(newPolicy))));\n            if (!\"success\".equals(rsp.getValues().get(\"result\"))) {\n              throw new SolrException(ErrorCode.SERVER_ERROR, \"unable to create new policy\");\n            }\n            message.getProperties().put(Policy.POLICY, policy);\n\n          } else {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection\");\n          }\n        }\n\n        replicaPositions = Assign.identifyNodes(() -> ocmh.overseer.getZkController().getCoreContainer(),\n            ocmh.zkStateReader\n            , clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildCoreName(collectionName, replicaPosition.shard, replicaPosition.type, replicaPosition.index + 1);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        if (autoAddReplicas) {\n          ocmh.forwardToAutoScaling(AutoScaling.AUTO_ADD_REPLICAS_TRIGGER_DSL);\n        }\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"219ac4e012cb38bcfcd8f4290dccd4f5b4d7bc25","date":1499961129,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n      boolean autoAddReplicas = message.getBool(AUTO_ADD_REPLICAS, false);\n      Map autoScalingJson = Utils.getJson(ocmh.zkStateReader.getZkClient(), SOLR_AUTOSCALING_CONF_PATH, true);\n      String policy = message.getStr(Policy.POLICY);\n      boolean usePolicyFramework = autoScalingJson.get(Policy.CLUSTER_POLICY) != null || policy != null;\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, usePolicyFramework? 0: 1);\n      if(maxShardsPerNode == 0) message.getProperties().put(MAX_SHARDS_PER_NODE, \"0\");\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      List<ReplicaPosition> replicaPositions;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        replicaPositions = new ArrayList<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (!usePolicyFramework &&  maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n        if (usePolicyFramework && maxShardsPerNode > 0) {\n          if (policy == null) {\n            //this means we should create a policy for this collection\n            AutoScalingHandler ash = (AutoScalingHandler) ocmh.overseer.getZkController().getCoreContainer().getRequestHandler(AutoScalingHandler.HANDLER_PATH);\n            Map newPolicy = Utils.makeMap(REPLICA, \"<\" + (maxShardsPerNode + 1), SHARD, Policy.EACH, \"node\", Policy.ANY);\n            SolrQueryResponse rsp = new SolrQueryResponse();\n            policy = \"COLL_POLICY_\" + collectionName;\n            ash.processOps(null, rsp, Collections.singletonList(new CommandOperation(AutoScalingParams.CMD_SET_POLICY, singletonMap(\n                policy\n                , Collections.singletonList(newPolicy)))));\n            if (!\"success\".equals(rsp.getValues().get(\"result\"))) {\n              throw new SolrException(ErrorCode.SERVER_ERROR, \"unable to create new policy\");\n            }\n            message.getProperties().put(Policy.POLICY, policy);\n\n          } else {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection\");\n          }\n        }\n\n        replicaPositions = Assign.identifyNodes(() -> ocmh.overseer.getZkController().getCoreContainer(),\n            ocmh.zkStateReader\n            , clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildCoreName(collectionName, replicaPosition.shard, replicaPosition.type, replicaPosition.index + 1);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        if (autoAddReplicas) {\n          ocmh.forwardToAutoScaling(AutoScaling.AUTO_ADD_REPLICAS_TRIGGER_DSL);\n        }\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n\n        // Emit a warning about production use of data driven functionality\n        boolean defaultConfigSetUsed = message.getStr(COLL_CONF) == null ||\n            message.getStr(COLL_CONF).equals(ConfigSetsHandlerApi.DEFAULT_CONFIGSET_NAME);\n        if (defaultConfigSetUsed) {\n          results.add(\"warning\", \"Using _default configset. Data driven schema functionality\"\n              + \" is enabled by default, which is NOT RECOMMENDED for production use. To turn it off:\"\n              + \" curl http://{host:port}/solr/\" + collectionName + \"/config -d '{\\\"set-user-property\\\": {\\\"update.autoCreateFields\\\":\\\"false\\\"}}'\");\n        }\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n      boolean autoAddReplicas = message.getBool(AUTO_ADD_REPLICAS, false);\n      Map autoScalingJson = Utils.getJson(ocmh.zkStateReader.getZkClient(), SOLR_AUTOSCALING_CONF_PATH, true);\n      String policy = message.getStr(Policy.POLICY);\n      boolean usePolicyFramework = autoScalingJson.get(Policy.CLUSTER_POLICY) != null || policy != null;\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, usePolicyFramework? 0: 1);\n      if(maxShardsPerNode == 0) message.getProperties().put(MAX_SHARDS_PER_NODE, \"0\");\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      List<ReplicaPosition> replicaPositions;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        replicaPositions = new ArrayList<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (!usePolicyFramework &&  maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n        if (usePolicyFramework && maxShardsPerNode > 0) {\n          if (policy == null) {\n            //this means we should create a policy for this collection\n            AutoScalingHandler ash = (AutoScalingHandler) ocmh.overseer.getZkController().getCoreContainer().getRequestHandler(AutoScalingHandler.HANDLER_PATH);\n            Map newPolicy = Utils.makeMap(REPLICA, \"<\" + (maxShardsPerNode + 1), SHARD, Policy.EACH, \"node\", Policy.ANY);\n            SolrQueryResponse rsp = new SolrQueryResponse();\n            policy = \"COLL_POLICY_\" + collectionName;\n            ash.handleSetPolicies(null, rsp, new CommandOperation(AutoScalingParams.CMD_SET_POLICY, singletonMap(\n                policy\n                , Collections.singletonList(newPolicy))));\n            if (!\"success\".equals(rsp.getValues().get(\"result\"))) {\n              throw new SolrException(ErrorCode.SERVER_ERROR, \"unable to create new policy\");\n            }\n            message.getProperties().put(Policy.POLICY, policy);\n\n          } else {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection\");\n          }\n        }\n\n        replicaPositions = Assign.identifyNodes(() -> ocmh.overseer.getZkController().getCoreContainer(),\n            ocmh.zkStateReader\n            , clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildCoreName(collectionName, replicaPosition.shard, replicaPosition.type, replicaPosition.index + 1);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        if (autoAddReplicas) {\n          ocmh.forwardToAutoScaling(AutoScaling.AUTO_ADD_REPLICAS_TRIGGER_DSL);\n        }\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n\n        // Emit a warning about production use of data driven functionality\n        boolean defaultConfigSetUsed = message.getStr(COLL_CONF) == null ||\n            message.getStr(COLL_CONF).equals(ConfigSetsHandlerApi.DEFAULT_CONFIGSET_NAME);\n        if (defaultConfigSetUsed) {\n          results.add(\"warning\", \"Using _default configset. Data driven schema functionality\"\n              + \" is enabled by default, which is NOT RECOMMENDED for production use. To turn it off:\"\n              + \" curl http://{host:port}/solr/\" + collectionName + \"/config -d '{\\\"set-user-property\\\": {\\\"update.autoCreateFields\\\":\\\"false\\\"}}'\");\n        }\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"651c3ddf5bc1266d9de0a972ec05e59d77099a4c","date":1500969855,"type":3,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      List<ReplicaPosition> replicaPositions;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        replicaPositions = new ArrayList<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        replicaPositions = Assign.identifyNodes(() -> ocmh.overseer.getZkController().getCoreContainer(),\n            ocmh.zkStateReader\n            , clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildCoreName(ocmh.zkStateReader.getZkClient(), zkStateReader.getClusterState().getCollection(collectionName),\n            replicaPosition.shard, replicaPosition.type);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n\n        // Emit a warning about production use of data driven functionality\n        boolean defaultConfigSetUsed = message.getStr(COLL_CONF) == null ||\n            message.getStr(COLL_CONF).equals(ConfigSetsHandlerApi.DEFAULT_CONFIGSET_NAME);\n        if (defaultConfigSetUsed) {\n          results.add(\"warning\", \"Using _default configset. Data driven schema functionality\"\n              + \" is enabled by default, which is NOT RECOMMENDED for production use. To turn it off:\"\n              + \" curl http://{host:port}/solr/\" + collectionName + \"/config -d '{\\\"set-user-property\\\": {\\\"update.autoCreateFields\\\":\\\"false\\\"}}'\");\n        }\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      List<ReplicaPosition> replicaPositions;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        replicaPositions = new ArrayList<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        replicaPositions = Assign.identifyNodes(() -> ocmh.overseer.getZkController().getCoreContainer(),\n            ocmh.zkStateReader\n            , clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildCoreName(collectionName, replicaPosition.shard, replicaPosition.type, replicaPosition.index + 1);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n\n        // Emit a warning about production use of data driven functionality\n        boolean defaultConfigSetUsed = message.getStr(COLL_CONF) == null ||\n            message.getStr(COLL_CONF).equals(ConfigSetsHandlerApi.DEFAULT_CONFIGSET_NAME);\n        if (defaultConfigSetUsed) {\n          results.add(\"warning\", \"Using _default configset. Data driven schema functionality\"\n              + \" is enabled by default, which is NOT RECOMMENDED for production use. To turn it off:\"\n              + \" curl http://{host:port}/solr/\" + collectionName + \"/config -d '{\\\"set-user-property\\\": {\\\"update.autoCreateFields\\\":\\\"false\\\"}}'\");\n        }\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":["44bfd7d2ea76c7c37dd13eadc1889039e172f3c7"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"936cdd5882761db3b844afd6f84ab81cbb011a75","date":1500973524,"type":3,"author":"Cao Manh Dat","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n      boolean autoAddReplicas = message.getBool(AUTO_ADD_REPLICAS, false);\n      Map autoScalingJson = Utils.getJson(ocmh.zkStateReader.getZkClient(), SOLR_AUTOSCALING_CONF_PATH, true);\n      String policy = message.getStr(Policy.POLICY);\n      boolean usePolicyFramework = autoScalingJson.get(Policy.CLUSTER_POLICY) != null || policy != null;\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, usePolicyFramework? 0: 1);\n      if(maxShardsPerNode == 0) message.getProperties().put(MAX_SHARDS_PER_NODE, \"0\");\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      List<ReplicaPosition> replicaPositions;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        replicaPositions = new ArrayList<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (!usePolicyFramework &&  maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n        if (usePolicyFramework && maxShardsPerNode > 0) {\n          if (policy == null) {\n            //this means we should create a policy for this collection\n            AutoScalingHandler ash = (AutoScalingHandler) ocmh.overseer.getZkController().getCoreContainer().getRequestHandler(AutoScalingHandler.HANDLER_PATH);\n            Map newPolicy = Utils.makeMap(REPLICA, \"<\" + (maxShardsPerNode + 1), SHARD, Policy.EACH, \"node\", Policy.ANY);\n            SolrQueryResponse rsp = new SolrQueryResponse();\n            policy = \"COLL_POLICY_\" + collectionName;\n            ash.processOps(null, rsp, Collections.singletonList(new CommandOperation(AutoScalingParams.CMD_SET_POLICY, singletonMap(\n                policy\n                , Collections.singletonList(newPolicy)))));\n            if (!\"success\".equals(rsp.getValues().get(\"result\"))) {\n              throw new SolrException(ErrorCode.SERVER_ERROR, \"unable to create new policy\");\n            }\n            message.getProperties().put(Policy.POLICY, policy);\n\n          } else {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection\");\n          }\n        }\n\n        replicaPositions = Assign.identifyNodes(() -> ocmh.overseer.getZkController().getCoreContainer(),\n            ocmh.zkStateReader\n            , clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildCoreName(ocmh.zkStateReader.getZkClient(), zkStateReader.getClusterState().getCollection(collectionName),\n            replicaPosition.shard, replicaPosition.type);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        if (autoAddReplicas) {\n          ocmh.forwardToAutoScaling(AutoScaling.AUTO_ADD_REPLICAS_TRIGGER_DSL);\n        }\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n\n        // Emit a warning about production use of data driven functionality\n        boolean defaultConfigSetUsed = message.getStr(COLL_CONF) == null ||\n            message.getStr(COLL_CONF).equals(ConfigSetsHandlerApi.DEFAULT_CONFIGSET_NAME);\n        if (defaultConfigSetUsed) {\n          results.add(\"warning\", \"Using _default configset. Data driven schema functionality\"\n              + \" is enabled by default, which is NOT RECOMMENDED for production use. To turn it off:\"\n              + \" curl http://{host:port}/solr/\" + collectionName + \"/config -d '{\\\"set-user-property\\\": {\\\"update.autoCreateFields\\\":\\\"false\\\"}}'\");\n        }\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n      boolean autoAddReplicas = message.getBool(AUTO_ADD_REPLICAS, false);\n      Map autoScalingJson = Utils.getJson(ocmh.zkStateReader.getZkClient(), SOLR_AUTOSCALING_CONF_PATH, true);\n      String policy = message.getStr(Policy.POLICY);\n      boolean usePolicyFramework = autoScalingJson.get(Policy.CLUSTER_POLICY) != null || policy != null;\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, usePolicyFramework? 0: 1);\n      if(maxShardsPerNode == 0) message.getProperties().put(MAX_SHARDS_PER_NODE, \"0\");\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      List<ReplicaPosition> replicaPositions;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        replicaPositions = new ArrayList<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (!usePolicyFramework &&  maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n        if (usePolicyFramework && maxShardsPerNode > 0) {\n          if (policy == null) {\n            //this means we should create a policy for this collection\n            AutoScalingHandler ash = (AutoScalingHandler) ocmh.overseer.getZkController().getCoreContainer().getRequestHandler(AutoScalingHandler.HANDLER_PATH);\n            Map newPolicy = Utils.makeMap(REPLICA, \"<\" + (maxShardsPerNode + 1), SHARD, Policy.EACH, \"node\", Policy.ANY);\n            SolrQueryResponse rsp = new SolrQueryResponse();\n            policy = \"COLL_POLICY_\" + collectionName;\n            ash.processOps(null, rsp, Collections.singletonList(new CommandOperation(AutoScalingParams.CMD_SET_POLICY, singletonMap(\n                policy\n                , Collections.singletonList(newPolicy)))));\n            if (!\"success\".equals(rsp.getValues().get(\"result\"))) {\n              throw new SolrException(ErrorCode.SERVER_ERROR, \"unable to create new policy\");\n            }\n            message.getProperties().put(Policy.POLICY, policy);\n\n          } else {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection\");\n          }\n        }\n\n        replicaPositions = Assign.identifyNodes(() -> ocmh.overseer.getZkController().getCoreContainer(),\n            ocmh.zkStateReader\n            , clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildCoreName(collectionName, replicaPosition.shard, replicaPosition.type, replicaPosition.index + 1);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        if (autoAddReplicas) {\n          ocmh.forwardToAutoScaling(AutoScaling.AUTO_ADD_REPLICAS_TRIGGER_DSL);\n        }\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n\n        // Emit a warning about production use of data driven functionality\n        boolean defaultConfigSetUsed = message.getStr(COLL_CONF) == null ||\n            message.getStr(COLL_CONF).equals(ConfigSetsHandlerApi.DEFAULT_CONFIGSET_NAME);\n        if (defaultConfigSetUsed) {\n          results.add(\"warning\", \"Using _default configset. Data driven schema functionality\"\n              + \" is enabled by default, which is NOT RECOMMENDED for production use. To turn it off:\"\n              + \" curl http://{host:port}/solr/\" + collectionName + \"/config -d '{\\\"set-user-property\\\": {\\\"update.autoCreateFields\\\":\\\"false\\\"}}'\");\n        }\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a52341299179de5479672f7cf518bf4b173f34b3","date":1501079746,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      List<ReplicaPosition> replicaPositions;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        replicaPositions = new ArrayList<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        replicaPositions = Assign.identifyNodes(() -> ocmh.overseer.getZkController().getCoreContainer(),\n            ocmh.zkStateReader\n            , clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildCoreName(ocmh.zkStateReader.getZkClient(), zkStateReader.getClusterState().getCollection(collectionName),\n            replicaPosition.shard, replicaPosition.type);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n\n        // Emit a warning about production use of data driven functionality\n        boolean defaultConfigSetUsed = message.getStr(COLL_CONF) == null ||\n            message.getStr(COLL_CONF).equals(ConfigSetsHandlerApi.DEFAULT_CONFIGSET_NAME);\n        if (defaultConfigSetUsed) {\n          results.add(\"warning\", \"Using _default configset. Data driven schema functionality\"\n              + \" is enabled by default, which is NOT RECOMMENDED for production use. To turn it off:\"\n              + \" curl http://{host:port}/solr/\" + collectionName + \"/config -d '{\\\"set-user-property\\\": {\\\"update.autoCreateFields\\\":\\\"false\\\"}}'\");\n        }\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      List<ReplicaPosition> replicaPositions;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        replicaPositions = new ArrayList<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        replicaPositions = Assign.identifyNodes(() -> ocmh.overseer.getZkController().getCoreContainer(),\n            ocmh.zkStateReader\n            , clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildCoreName(collectionName, replicaPosition.shard, replicaPosition.type, replicaPosition.index + 1);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n\n        // Emit a warning about production use of data driven functionality\n        boolean defaultConfigSetUsed = message.getStr(COLL_CONF) == null ||\n            message.getStr(COLL_CONF).equals(ConfigSetsHandlerApi.DEFAULT_CONFIGSET_NAME);\n        if (defaultConfigSetUsed) {\n          results.add(\"warning\", \"Using _default configset. Data driven schema functionality\"\n              + \" is enabled by default, which is NOT RECOMMENDED for production use. To turn it off:\"\n              + \" curl http://{host:port}/solr/\" + collectionName + \"/config -d '{\\\"set-user-property\\\": {\\\"update.autoCreateFields\\\":\\\"false\\\"}}'\");\n        }\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"717e5ceb2acae36d422ec75e5a4ce9fac40506e1","date":1501239603,"type":3,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n      Map autoScalingJson = Utils.getJson(ocmh.zkStateReader.getZkClient(), SOLR_AUTOSCALING_CONF_PATH, true);\n      String policy = message.getStr(Policy.POLICY);\n      boolean usePolicyFramework = autoScalingJson.get(Policy.CLUSTER_POLICY) != null || policy != null;\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, usePolicyFramework? 0: 1);\n      if(maxShardsPerNode == 0) message.getProperties().put(MAX_SHARDS_PER_NODE, \"0\");\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      List<ReplicaPosition> replicaPositions;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        replicaPositions = new ArrayList<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (!usePolicyFramework &&  maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n        if (usePolicyFramework && maxShardsPerNode > 0) {\n          if (policy == null) {\n            //this means we should create a policy for this collection\n            AutoScalingHandler ash = (AutoScalingHandler) ocmh.overseer.getZkController().getCoreContainer().getRequestHandler(AutoScalingHandler.HANDLER_PATH);\n            Map newPolicy = Utils.makeMap(REPLICA, \"<\" + (maxShardsPerNode + 1), SHARD, Policy.EACH, \"node\", Policy.ANY);\n            SolrQueryResponse rsp = new SolrQueryResponse();\n            policy = \"COLL_POLICY_\" + collectionName;\n            ash.processOps(null, rsp, Collections.singletonList(new CommandOperation(AutoScalingParams.CMD_SET_POLICY, singletonMap(\n                policy\n                , Collections.singletonList(newPolicy)))));\n            if (!\"success\".equals(rsp.getValues().get(\"result\"))) {\n              throw new SolrException(ErrorCode.SERVER_ERROR, \"unable to create new policy\");\n            }\n            message.getProperties().put(Policy.POLICY, policy);\n\n          } else {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection\");\n          }\n        }\n\n        replicaPositions = Assign.identifyNodes(() -> ocmh.overseer.getZkController().getCoreContainer(),\n            ocmh.zkStateReader\n            , clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildCoreName(ocmh.zkStateReader.getZkClient(), zkStateReader.getClusterState().getCollection(collectionName),\n            replicaPosition.shard, replicaPosition.type);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n\n        // Emit a warning about production use of data driven functionality\n        boolean defaultConfigSetUsed = message.getStr(COLL_CONF) == null ||\n            message.getStr(COLL_CONF).equals(ConfigSetsHandlerApi.DEFAULT_CONFIGSET_NAME);\n        if (defaultConfigSetUsed) {\n          results.add(\"warning\", \"Using _default configset. Data driven schema functionality\"\n              + \" is enabled by default, which is NOT RECOMMENDED for production use. To turn it off:\"\n              + \" curl http://{host:port}/solr/\" + collectionName + \"/config -d '{\\\"set-user-property\\\": {\\\"update.autoCreateFields\\\":\\\"false\\\"}}'\");\n        }\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n      boolean autoAddReplicas = message.getBool(AUTO_ADD_REPLICAS, false);\n      Map autoScalingJson = Utils.getJson(ocmh.zkStateReader.getZkClient(), SOLR_AUTOSCALING_CONF_PATH, true);\n      String policy = message.getStr(Policy.POLICY);\n      boolean usePolicyFramework = autoScalingJson.get(Policy.CLUSTER_POLICY) != null || policy != null;\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, usePolicyFramework? 0: 1);\n      if(maxShardsPerNode == 0) message.getProperties().put(MAX_SHARDS_PER_NODE, \"0\");\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      List<ReplicaPosition> replicaPositions;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        replicaPositions = new ArrayList<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (!usePolicyFramework &&  maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n        if (usePolicyFramework && maxShardsPerNode > 0) {\n          if (policy == null) {\n            //this means we should create a policy for this collection\n            AutoScalingHandler ash = (AutoScalingHandler) ocmh.overseer.getZkController().getCoreContainer().getRequestHandler(AutoScalingHandler.HANDLER_PATH);\n            Map newPolicy = Utils.makeMap(REPLICA, \"<\" + (maxShardsPerNode + 1), SHARD, Policy.EACH, \"node\", Policy.ANY);\n            SolrQueryResponse rsp = new SolrQueryResponse();\n            policy = \"COLL_POLICY_\" + collectionName;\n            ash.processOps(null, rsp, Collections.singletonList(new CommandOperation(AutoScalingParams.CMD_SET_POLICY, singletonMap(\n                policy\n                , Collections.singletonList(newPolicy)))));\n            if (!\"success\".equals(rsp.getValues().get(\"result\"))) {\n              throw new SolrException(ErrorCode.SERVER_ERROR, \"unable to create new policy\");\n            }\n            message.getProperties().put(Policy.POLICY, policy);\n\n          } else {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection\");\n          }\n        }\n\n        replicaPositions = Assign.identifyNodes(() -> ocmh.overseer.getZkController().getCoreContainer(),\n            ocmh.zkStateReader\n            , clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildCoreName(ocmh.zkStateReader.getZkClient(), zkStateReader.getClusterState().getCollection(collectionName),\n            replicaPosition.shard, replicaPosition.type);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        if (autoAddReplicas) {\n          ocmh.forwardToAutoScaling(AutoScaling.AUTO_ADD_REPLICAS_TRIGGER_DSL);\n        }\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n\n        // Emit a warning about production use of data driven functionality\n        boolean defaultConfigSetUsed = message.getStr(COLL_CONF) == null ||\n            message.getStr(COLL_CONF).equals(ConfigSetsHandlerApi.DEFAULT_CONFIGSET_NAME);\n        if (defaultConfigSetUsed) {\n          results.add(\"warning\", \"Using _default configset. Data driven schema functionality\"\n              + \" is enabled by default, which is NOT RECOMMENDED for production use. To turn it off:\"\n              + \" curl http://{host:port}/solr/\" + collectionName + \"/config -d '{\\\"set-user-property\\\": {\\\"update.autoCreateFields\\\":\\\"false\\\"}}'\");\n        }\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"44bfd7d2ea76c7c37dd13eadc1889039e172f3c7","date":1501726570,"type":3,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      List<ReplicaPosition> replicaPositions;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        replicaPositions = new ArrayList<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        replicaPositions = Assign.identifyNodes(() -> ocmh.overseer.getZkController().getCoreContainer(),\n            ocmh.zkStateReader\n            , clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildCoreName(ocmh.zkStateReader.getZkClient(), zkStateReader.getClusterState().getCollection(collectionName),\n            replicaPosition.shard, replicaPosition.type, true);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n\n        // Emit a warning about production use of data driven functionality\n        boolean defaultConfigSetUsed = message.getStr(COLL_CONF) == null ||\n            message.getStr(COLL_CONF).equals(ConfigSetsHandlerApi.DEFAULT_CONFIGSET_NAME);\n        if (defaultConfigSetUsed) {\n          results.add(\"warning\", \"Using _default configset. Data driven schema functionality\"\n              + \" is enabled by default, which is NOT RECOMMENDED for production use. To turn it off:\"\n              + \" curl http://{host:port}/solr/\" + collectionName + \"/config -d '{\\\"set-user-property\\\": {\\\"update.autoCreateFields\\\":\\\"false\\\"}}'\");\n        }\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      List<ReplicaPosition> replicaPositions;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        replicaPositions = new ArrayList<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        replicaPositions = Assign.identifyNodes(() -> ocmh.overseer.getZkController().getCoreContainer(),\n            ocmh.zkStateReader\n            , clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildCoreName(ocmh.zkStateReader.getZkClient(), zkStateReader.getClusterState().getCollection(collectionName),\n            replicaPosition.shard, replicaPosition.type);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n\n        // Emit a warning about production use of data driven functionality\n        boolean defaultConfigSetUsed = message.getStr(COLL_CONF) == null ||\n            message.getStr(COLL_CONF).equals(ConfigSetsHandlerApi.DEFAULT_CONFIGSET_NAME);\n        if (defaultConfigSetUsed) {\n          results.add(\"warning\", \"Using _default configset. Data driven schema functionality\"\n              + \" is enabled by default, which is NOT RECOMMENDED for production use. To turn it off:\"\n              + \" curl http://{host:port}/solr/\" + collectionName + \"/config -d '{\\\"set-user-property\\\": {\\\"update.autoCreateFields\\\":\\\"false\\\"}}'\");\n        }\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":["651c3ddf5bc1266d9de0a972ec05e59d77099a4c"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","date":1502192746,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n      Map autoScalingJson = Utils.getJson(ocmh.zkStateReader.getZkClient(), SOLR_AUTOSCALING_CONF_PATH, true);\n      String policy = message.getStr(Policy.POLICY);\n      boolean usePolicyFramework = autoScalingJson.get(Policy.CLUSTER_POLICY) != null || policy != null;\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, usePolicyFramework? 0: 1);\n      if(maxShardsPerNode == 0) message.getProperties().put(MAX_SHARDS_PER_NODE, \"0\");\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      List<ReplicaPosition> replicaPositions;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        replicaPositions = new ArrayList<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (!usePolicyFramework &&  maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n        if (usePolicyFramework && maxShardsPerNode > 0) {\n          if (policy == null) {\n            //this means we should create a policy for this collection\n            AutoScalingHandler ash = (AutoScalingHandler) ocmh.overseer.getZkController().getCoreContainer().getRequestHandler(AutoScalingHandler.HANDLER_PATH);\n            Map newPolicy = Utils.makeMap(REPLICA, \"<\" + (maxShardsPerNode + 1), SHARD, Policy.EACH, \"node\", Policy.ANY);\n            SolrQueryResponse rsp = new SolrQueryResponse();\n            policy = \"COLL_POLICY_\" + collectionName;\n            ash.processOps(null, rsp, Collections.singletonList(new CommandOperation(AutoScalingParams.CMD_SET_POLICY, singletonMap(\n                policy\n                , Collections.singletonList(newPolicy)))));\n            if (!\"success\".equals(rsp.getValues().get(\"result\"))) {\n              throw new SolrException(ErrorCode.SERVER_ERROR, \"unable to create new policy\");\n            }\n            message.getProperties().put(Policy.POLICY, policy);\n\n          } else {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection\");\n          }\n        }\n\n        replicaPositions = Assign.identifyNodes(() -> ocmh.overseer.getZkController().getCoreContainer(),\n            ocmh.zkStateReader\n            , clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildCoreName(ocmh.zkStateReader.getZkClient(), zkStateReader.getClusterState().getCollection(collectionName),\n            replicaPosition.shard, replicaPosition.type, true);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n\n        // Emit a warning about production use of data driven functionality\n        boolean defaultConfigSetUsed = message.getStr(COLL_CONF) == null ||\n            message.getStr(COLL_CONF).equals(ConfigSetsHandlerApi.DEFAULT_CONFIGSET_NAME);\n        if (defaultConfigSetUsed) {\n          results.add(\"warning\", \"Using _default configset. Data driven schema functionality\"\n              + \" is enabled by default, which is NOT RECOMMENDED for production use. To turn it off:\"\n              + \" curl http://{host:port}/solr/\" + collectionName + \"/config -d '{\\\"set-user-property\\\": {\\\"update.autoCreateFields\\\":\\\"false\\\"}}'\");\n        }\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n      Map autoScalingJson = Utils.getJson(ocmh.zkStateReader.getZkClient(), SOLR_AUTOSCALING_CONF_PATH, true);\n      String policy = message.getStr(Policy.POLICY);\n      boolean usePolicyFramework = autoScalingJson.get(Policy.CLUSTER_POLICY) != null || policy != null;\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, usePolicyFramework? 0: 1);\n      if(maxShardsPerNode == 0) message.getProperties().put(MAX_SHARDS_PER_NODE, \"0\");\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      List<ReplicaPosition> replicaPositions;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        replicaPositions = new ArrayList<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (!usePolicyFramework &&  maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n        if (usePolicyFramework && maxShardsPerNode > 0) {\n          if (policy == null) {\n            //this means we should create a policy for this collection\n            AutoScalingHandler ash = (AutoScalingHandler) ocmh.overseer.getZkController().getCoreContainer().getRequestHandler(AutoScalingHandler.HANDLER_PATH);\n            Map newPolicy = Utils.makeMap(REPLICA, \"<\" + (maxShardsPerNode + 1), SHARD, Policy.EACH, \"node\", Policy.ANY);\n            SolrQueryResponse rsp = new SolrQueryResponse();\n            policy = \"COLL_POLICY_\" + collectionName;\n            ash.processOps(null, rsp, Collections.singletonList(new CommandOperation(AutoScalingParams.CMD_SET_POLICY, singletonMap(\n                policy\n                , Collections.singletonList(newPolicy)))));\n            if (!\"success\".equals(rsp.getValues().get(\"result\"))) {\n              throw new SolrException(ErrorCode.SERVER_ERROR, \"unable to create new policy\");\n            }\n            message.getProperties().put(Policy.POLICY, policy);\n\n          } else {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection\");\n          }\n        }\n\n        replicaPositions = Assign.identifyNodes(() -> ocmh.overseer.getZkController().getCoreContainer(),\n            ocmh.zkStateReader\n            , clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildCoreName(ocmh.zkStateReader.getZkClient(), zkStateReader.getClusterState().getCollection(collectionName),\n            replicaPosition.shard, replicaPosition.type);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n\n        // Emit a warning about production use of data driven functionality\n        boolean defaultConfigSetUsed = message.getStr(COLL_CONF) == null ||\n            message.getStr(COLL_CONF).equals(ConfigSetsHandlerApi.DEFAULT_CONFIGSET_NAME);\n        if (defaultConfigSetUsed) {\n          results.add(\"warning\", \"Using _default configset. Data driven schema functionality\"\n              + \" is enabled by default, which is NOT RECOMMENDED for production use. To turn it off:\"\n              + \" curl http://{host:port}/solr/\" + collectionName + \"/config -d '{\\\"set-user-property\\\": {\\\"update.autoCreateFields\\\":\\\"false\\\"}}'\");\n        }\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bccf7971a36bd151490117582a0a1a695081ead3","date":1502778995,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n      Map autoScalingJson = Utils.getJson(ocmh.zkStateReader.getZkClient(), SOLR_AUTOSCALING_CONF_PATH, true);\n      String policy = message.getStr(Policy.POLICY);\n      boolean usePolicyFramework = autoScalingJson.get(Policy.CLUSTER_POLICY) != null || policy != null;\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, usePolicyFramework? 0: 1);\n      if(maxShardsPerNode == 0) message.getProperties().put(MAX_SHARDS_PER_NODE, \"0\");\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      List<ReplicaPosition> replicaPositions;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        replicaPositions = new ArrayList<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (!usePolicyFramework &&  maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n        if (usePolicyFramework && maxShardsPerNode > 0) {\n          if (policy == null) {\n            //this means we should create a policy for this collection\n            AutoScalingHandler ash = (AutoScalingHandler) ocmh.overseer.getZkController().getCoreContainer().getRequestHandler(AutoScalingHandler.HANDLER_PATH);\n            Map newPolicy = Utils.makeMap(REPLICA, \"<\" + (maxShardsPerNode + 1), SHARD, Policy.EACH, \"node\", Policy.ANY);\n            SolrQueryResponse rsp = new SolrQueryResponse();\n            policy = \"COLL_POLICY_\" + collectionName;\n            ash.processOps(null, rsp, Collections.singletonList(new CommandOperation(AutoScalingParams.CMD_SET_POLICY, singletonMap(\n                policy\n                , Collections.singletonList(newPolicy)))));\n            if (!\"success\".equals(rsp.getValues().get(\"result\"))) {\n              throw new SolrException(ErrorCode.SERVER_ERROR, \"unable to create new policy\");\n            }\n            message.getProperties().put(Policy.POLICY, policy);\n\n          } else {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection\");\n          }\n        }\n\n        replicaPositions = Assign.identifyNodes(ocmh\n            , clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildCoreName(ocmh.zkStateReader.getZkClient(), zkStateReader.getClusterState().getCollection(collectionName),\n            replicaPosition.shard, replicaPosition.type, true);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n\n        // Emit a warning about production use of data driven functionality\n        boolean defaultConfigSetUsed = message.getStr(COLL_CONF) == null ||\n            message.getStr(COLL_CONF).equals(ConfigSetsHandlerApi.DEFAULT_CONFIGSET_NAME);\n        if (defaultConfigSetUsed) {\n          results.add(\"warning\", \"Using _default configset. Data driven schema functionality\"\n              + \" is enabled by default, which is NOT RECOMMENDED for production use. To turn it off:\"\n              + \" curl http://{host:port}/solr/\" + collectionName + \"/config -d '{\\\"set-user-property\\\": {\\\"update.autoCreateFields\\\":\\\"false\\\"}}'\");\n        }\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    } finally {\n      PolicyHelper.clearFlagAndDecref(ocmh.policySessionRef);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n      Map autoScalingJson = Utils.getJson(ocmh.zkStateReader.getZkClient(), SOLR_AUTOSCALING_CONF_PATH, true);\n      String policy = message.getStr(Policy.POLICY);\n      boolean usePolicyFramework = autoScalingJson.get(Policy.CLUSTER_POLICY) != null || policy != null;\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, usePolicyFramework? 0: 1);\n      if(maxShardsPerNode == 0) message.getProperties().put(MAX_SHARDS_PER_NODE, \"0\");\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      List<ReplicaPosition> replicaPositions;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        replicaPositions = new ArrayList<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (!usePolicyFramework &&  maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n        if (usePolicyFramework && maxShardsPerNode > 0) {\n          if (policy == null) {\n            //this means we should create a policy for this collection\n            AutoScalingHandler ash = (AutoScalingHandler) ocmh.overseer.getZkController().getCoreContainer().getRequestHandler(AutoScalingHandler.HANDLER_PATH);\n            Map newPolicy = Utils.makeMap(REPLICA, \"<\" + (maxShardsPerNode + 1), SHARD, Policy.EACH, \"node\", Policy.ANY);\n            SolrQueryResponse rsp = new SolrQueryResponse();\n            policy = \"COLL_POLICY_\" + collectionName;\n            ash.processOps(null, rsp, Collections.singletonList(new CommandOperation(AutoScalingParams.CMD_SET_POLICY, singletonMap(\n                policy\n                , Collections.singletonList(newPolicy)))));\n            if (!\"success\".equals(rsp.getValues().get(\"result\"))) {\n              throw new SolrException(ErrorCode.SERVER_ERROR, \"unable to create new policy\");\n            }\n            message.getProperties().put(Policy.POLICY, policy);\n\n          } else {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection\");\n          }\n        }\n\n        replicaPositions = Assign.identifyNodes(() -> ocmh.overseer.getZkController().getCoreContainer(),\n            ocmh.zkStateReader\n            , clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildCoreName(ocmh.zkStateReader.getZkClient(), zkStateReader.getClusterState().getCollection(collectionName),\n            replicaPosition.shard, replicaPosition.type, true);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n\n        // Emit a warning about production use of data driven functionality\n        boolean defaultConfigSetUsed = message.getStr(COLL_CONF) == null ||\n            message.getStr(COLL_CONF).equals(ConfigSetsHandlerApi.DEFAULT_CONFIGSET_NAME);\n        if (defaultConfigSetUsed) {\n          results.add(\"warning\", \"Using _default configset. Data driven schema functionality\"\n              + \" is enabled by default, which is NOT RECOMMENDED for production use. To turn it off:\"\n              + \" curl http://{host:port}/solr/\" + collectionName + \"/config -d '{\\\"set-user-property\\\": {\\\"update.autoCreateFields\\\":\\\"false\\\"}}'\");\n        }\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c0ee0c7f6bcf49646748d46aee9383b68eb55c80","date":1502884592,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    boolean usePolicyFramework = usePolicyFramework(ocmh.zkStateReader, message);\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      if (usePolicyFramework && message.getStr(MAX_SHARDS_PER_NODE) != null && maxShardsPerNode > 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"'maxShardsPerNode>0' is not supported when autoScaling policies are used\");\n      }\n      if (maxShardsPerNode == -1 || usePolicyFramework) maxShardsPerNode = Integer.MAX_VALUE;\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      List<ReplicaPosition> replicaPositions;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        replicaPositions = new ArrayList<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode == Integer.MAX_VALUE ?\n            Integer.MAX_VALUE :\n            maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        replicaPositions = Assign.identifyNodes(() -> ocmh.overseer.getZkController().getCoreContainer(),\n            ocmh.zkStateReader\n            , clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildCoreName(ocmh.zkStateReader.getZkClient(), zkStateReader.getClusterState().getCollection(collectionName),\n            replicaPosition.shard, replicaPosition.type, true);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n\n        // Emit a warning about production use of data driven functionality\n        boolean defaultConfigSetUsed = message.getStr(COLL_CONF) == null ||\n            message.getStr(COLL_CONF).equals(ConfigSetsHandlerApi.DEFAULT_CONFIGSET_NAME);\n        if (defaultConfigSetUsed) {\n          results.add(\"warning\", \"Using _default configset. Data driven schema functionality\"\n              + \" is enabled by default, which is NOT RECOMMENDED for production use. To turn it off:\"\n              + \" curl http://{host:port}/solr/\" + collectionName + \"/config -d '{\\\"set-user-property\\\": {\\\"update.autoCreateFields\\\":\\\"false\\\"}}'\");\n        }\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      List<ReplicaPosition> replicaPositions;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        replicaPositions = new ArrayList<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        replicaPositions = Assign.identifyNodes(() -> ocmh.overseer.getZkController().getCoreContainer(),\n            ocmh.zkStateReader\n            , clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildCoreName(ocmh.zkStateReader.getZkClient(), zkStateReader.getClusterState().getCollection(collectionName),\n            replicaPosition.shard, replicaPosition.type, true);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n\n        // Emit a warning about production use of data driven functionality\n        boolean defaultConfigSetUsed = message.getStr(COLL_CONF) == null ||\n            message.getStr(COLL_CONF).equals(ConfigSetsHandlerApi.DEFAULT_CONFIGSET_NAME);\n        if (defaultConfigSetUsed) {\n          results.add(\"warning\", \"Using _default configset. Data driven schema functionality\"\n              + \" is enabled by default, which is NOT RECOMMENDED for production use. To turn it off:\"\n              + \" curl http://{host:port}/solr/\" + collectionName + \"/config -d '{\\\"set-user-property\\\": {\\\"update.autoCreateFields\\\":\\\"false\\\"}}'\");\n        }\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":["8c7a6584aa35e033d783e02c6f4eefa6ad21c7fe","2c0d0643efdcc41b0c814bf27a381e4dc2ff472b"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4328dbef1afa8336d38a4301a545999d1e21f8fa","date":1502941879,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n      Map autoScalingJson = Utils.getJson(ocmh.zkStateReader.getZkClient(), SOLR_AUTOSCALING_CONF_PATH, true);\n      String policy = message.getStr(Policy.POLICY);\n      boolean usePolicyFramework = autoScalingJson.get(Policy.CLUSTER_POLICY) != null || policy != null;\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, usePolicyFramework? 0: 1);\n      if(maxShardsPerNode == 0) message.getProperties().put(MAX_SHARDS_PER_NODE, \"0\");\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      List<ReplicaPosition> replicaPositions;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        replicaPositions = new ArrayList<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (!usePolicyFramework &&  maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n        replicaPositions = Assign.identifyNodes(ocmh\n            , clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildCoreName(ocmh.zkStateReader.getZkClient(), zkStateReader.getClusterState().getCollection(collectionName),\n            replicaPosition.shard, replicaPosition.type, true);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n\n        // Emit a warning about production use of data driven functionality\n        boolean defaultConfigSetUsed = message.getStr(COLL_CONF) == null ||\n            message.getStr(COLL_CONF).equals(ConfigSetsHandlerApi.DEFAULT_CONFIGSET_NAME);\n        if (defaultConfigSetUsed) {\n          results.add(\"warning\", \"Using _default configset. Data driven schema functionality\"\n              + \" is enabled by default, which is NOT RECOMMENDED for production use. To turn it off:\"\n              + \" curl http://{host:port}/solr/\" + collectionName + \"/config -d '{\\\"set-user-property\\\": {\\\"update.autoCreateFields\\\":\\\"false\\\"}}'\");\n        }\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    } finally {\n      PolicyHelper.clearFlagAndDecref(ocmh.policySessionRef);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n      Map autoScalingJson = Utils.getJson(ocmh.zkStateReader.getZkClient(), SOLR_AUTOSCALING_CONF_PATH, true);\n      String policy = message.getStr(Policy.POLICY);\n      boolean usePolicyFramework = autoScalingJson.get(Policy.CLUSTER_POLICY) != null || policy != null;\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, usePolicyFramework? 0: 1);\n      if(maxShardsPerNode == 0) message.getProperties().put(MAX_SHARDS_PER_NODE, \"0\");\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      List<ReplicaPosition> replicaPositions;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        replicaPositions = new ArrayList<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (!usePolicyFramework &&  maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n        if (usePolicyFramework && maxShardsPerNode > 0) {\n          if (policy == null) {\n            //this means we should create a policy for this collection\n            AutoScalingHandler ash = (AutoScalingHandler) ocmh.overseer.getZkController().getCoreContainer().getRequestHandler(AutoScalingHandler.HANDLER_PATH);\n            Map newPolicy = Utils.makeMap(REPLICA, \"<\" + (maxShardsPerNode + 1), SHARD, Policy.EACH, \"node\", Policy.ANY);\n            SolrQueryResponse rsp = new SolrQueryResponse();\n            policy = \"COLL_POLICY_\" + collectionName;\n            ash.processOps(null, rsp, Collections.singletonList(new CommandOperation(AutoScalingParams.CMD_SET_POLICY, singletonMap(\n                policy\n                , Collections.singletonList(newPolicy)))));\n            if (!\"success\".equals(rsp.getValues().get(\"result\"))) {\n              throw new SolrException(ErrorCode.SERVER_ERROR, \"unable to create new policy\");\n            }\n            message.getProperties().put(Policy.POLICY, policy);\n\n          } else {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection\");\n          }\n        }\n\n        replicaPositions = Assign.identifyNodes(ocmh\n            , clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildCoreName(ocmh.zkStateReader.getZkClient(), zkStateReader.getClusterState().getCollection(collectionName),\n            replicaPosition.shard, replicaPosition.type, true);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n\n        // Emit a warning about production use of data driven functionality\n        boolean defaultConfigSetUsed = message.getStr(COLL_CONF) == null ||\n            message.getStr(COLL_CONF).equals(ConfigSetsHandlerApi.DEFAULT_CONFIGSET_NAME);\n        if (defaultConfigSetUsed) {\n          results.add(\"warning\", \"Using _default configset. Data driven schema functionality\"\n              + \" is enabled by default, which is NOT RECOMMENDED for production use. To turn it off:\"\n              + \" curl http://{host:port}/solr/\" + collectionName + \"/config -d '{\\\"set-user-property\\\": {\\\"update.autoCreateFields\\\":\\\"false\\\"}}'\");\n        }\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    } finally {\n      PolicyHelper.clearFlagAndDecref(ocmh.policySessionRef);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c00aac053fdd75193eb8b6d45b64c26c3b586d5b","date":1503143818,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n      Map autoScalingJson = Utils.getJson(ocmh.zkStateReader.getZkClient(), SOLR_AUTOSCALING_CONF_PATH, true);\n      String policy = message.getStr(Policy.POLICY);\n      boolean usePolicyFramework = autoScalingJson.get(Policy.CLUSTER_POLICY) != null || policy != null;\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      if (usePolicyFramework && message.getStr(MAX_SHARDS_PER_NODE) != null && maxShardsPerNode > 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"'maxShardsPerNode>0' is not supported when autoScaling policies are used\");\n      }\n      if (maxShardsPerNode == -1 || usePolicyFramework) maxShardsPerNode = Integer.MAX_VALUE;\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      List<ReplicaPosition> replicaPositions;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        replicaPositions = new ArrayList<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode == Integer.MAX_VALUE ?\n            Integer.MAX_VALUE :\n            maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n        replicaPositions = Assign.identifyNodes(ocmh\n            , clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildCoreName(ocmh.zkStateReader.getZkClient(), zkStateReader.getClusterState().getCollection(collectionName),\n            replicaPosition.shard, replicaPosition.type, true);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n\n        // Emit a warning about production use of data driven functionality\n        boolean defaultConfigSetUsed = message.getStr(COLL_CONF) == null ||\n            message.getStr(COLL_CONF).equals(ConfigSetsHandlerApi.DEFAULT_CONFIGSET_NAME);\n        if (defaultConfigSetUsed) {\n          results.add(\"warning\", \"Using _default configset. Data driven schema functionality\"\n              + \" is enabled by default, which is NOT RECOMMENDED for production use. To turn it off:\"\n              + \" curl http://{host:port}/solr/\" + collectionName + \"/config -d '{\\\"set-user-property\\\": {\\\"update.autoCreateFields\\\":\\\"false\\\"}}'\");\n        }\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    } finally {\n      PolicyHelper.clearFlagAndDecref(ocmh.policySessionRef);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n      Map autoScalingJson = Utils.getJson(ocmh.zkStateReader.getZkClient(), SOLR_AUTOSCALING_CONF_PATH, true);\n      String policy = message.getStr(Policy.POLICY);\n      boolean usePolicyFramework = autoScalingJson.get(Policy.CLUSTER_POLICY) != null || policy != null;\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, usePolicyFramework? 0: 1);\n      if(maxShardsPerNode == 0) message.getProperties().put(MAX_SHARDS_PER_NODE, \"0\");\n\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      List<ReplicaPosition> replicaPositions;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        replicaPositions = new ArrayList<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (!usePolicyFramework &&  maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n        replicaPositions = Assign.identifyNodes(ocmh\n            , clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildCoreName(ocmh.zkStateReader.getZkClient(), zkStateReader.getClusterState().getCollection(collectionName),\n            replicaPosition.shard, replicaPosition.type, true);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n\n        // Emit a warning about production use of data driven functionality\n        boolean defaultConfigSetUsed = message.getStr(COLL_CONF) == null ||\n            message.getStr(COLL_CONF).equals(ConfigSetsHandlerApi.DEFAULT_CONFIGSET_NAME);\n        if (defaultConfigSetUsed) {\n          results.add(\"warning\", \"Using _default configset. Data driven schema functionality\"\n              + \" is enabled by default, which is NOT RECOMMENDED for production use. To turn it off:\"\n              + \" curl http://{host:port}/solr/\" + collectionName + \"/config -d '{\\\"set-user-property\\\": {\\\"update.autoCreateFields\\\":\\\"false\\\"}}'\");\n        }\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    } finally {\n      PolicyHelper.clearFlagAndDecref(ocmh.policySessionRef);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c304e97e7c1d472bc70e801b35ee78583916c6cd","date":1507105431,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n      Map autoScalingJson = Utils.getJson(ocmh.zkStateReader.getZkClient(), SOLR_AUTOSCALING_CONF_PATH, true);\n      String policy = message.getStr(Policy.POLICY);\n      boolean usePolicyFramework = autoScalingJson.get(Policy.CLUSTER_POLICY) != null || policy != null;\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      if (usePolicyFramework && message.getStr(MAX_SHARDS_PER_NODE) != null && maxShardsPerNode > 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"'maxShardsPerNode>0' is not supported when autoScaling policies are used\");\n      }\n      if (maxShardsPerNode == -1 || usePolicyFramework) maxShardsPerNode = Integer.MAX_VALUE;\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      List<ReplicaPosition> replicaPositions;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        replicaPositions = new ArrayList<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode == Integer.MAX_VALUE ?\n            Integer.MAX_VALUE :\n            maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n        replicaPositions = Assign.identifyNodes(ocmh\n            , clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildCoreName(ocmh.zkStateReader.getZkClient(), zkStateReader.getClusterState().getCollection(collectionName),\n            replicaPosition.shard, replicaPosition.type, true);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n\n        // Emit a warning about production use of data driven functionality\n        boolean defaultConfigSetUsed = message.getStr(COLL_CONF) == null ||\n            message.getStr(COLL_CONF).equals(ConfigSetsHandlerApi.DEFAULT_CONFIGSET_NAME);\n        if (defaultConfigSetUsed) {\n          results.add(\"warning\", \"Using _default configset. Data driven schema functionality\"\n              + \" is enabled by default, which is NOT RECOMMENDED for production use. To turn it off:\"\n              + \" curl http://{host:port}/solr/\" + collectionName + \"/config -d '{\\\"set-user-property\\\": {\\\"update.autoCreateFields\\\":\\\"false\\\"}}'\");\n        }\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    } finally {\n      PolicyHelper.clearFlagAndDecref(ocmh.policySessionRef);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    boolean usePolicyFramework = usePolicyFramework(ocmh.zkStateReader, message);\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      if (usePolicyFramework && message.getStr(MAX_SHARDS_PER_NODE) != null && maxShardsPerNode > 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"'maxShardsPerNode>0' is not supported when autoScaling policies are used\");\n      }\n      if (maxShardsPerNode == -1 || usePolicyFramework) maxShardsPerNode = Integer.MAX_VALUE;\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      List<ReplicaPosition> replicaPositions;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        replicaPositions = new ArrayList<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode == Integer.MAX_VALUE ?\n            Integer.MAX_VALUE :\n            maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        replicaPositions = Assign.identifyNodes(() -> ocmh.overseer.getZkController().getCoreContainer(),\n            ocmh.zkStateReader\n            , clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildCoreName(ocmh.zkStateReader.getZkClient(), zkStateReader.getClusterState().getCollection(collectionName),\n            replicaPosition.shard, replicaPosition.type, true);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n\n        // Emit a warning about production use of data driven functionality\n        boolean defaultConfigSetUsed = message.getStr(COLL_CONF) == null ||\n            message.getStr(COLL_CONF).equals(ConfigSetsHandlerApi.DEFAULT_CONFIGSET_NAME);\n        if (defaultConfigSetUsed) {\n          results.add(\"warning\", \"Using _default configset. Data driven schema functionality\"\n              + \" is enabled by default, which is NOT RECOMMENDED for production use. To turn it off:\"\n              + \" curl http://{host:port}/solr/\" + collectionName + \"/config -d '{\\\"set-user-property\\\": {\\\"update.autoCreateFields\\\":\\\"false\\\"}}'\");\n        }\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"560c18d71dad43d675158783c3840f8c80d6d39c","date":1507105532,"type":3,"author":"Cao Manh Dat","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n      Map autoScalingJson = Utils.getJson(ocmh.zkStateReader.getZkClient(), SOLR_AUTOSCALING_CONF_PATH, true);\n      String policy = message.getStr(Policy.POLICY);\n      boolean usePolicyFramework = autoScalingJson.get(Policy.CLUSTER_POLICY) != null || policy != null;\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      if (usePolicyFramework && message.getStr(MAX_SHARDS_PER_NODE) != null && maxShardsPerNode > 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"'maxShardsPerNode>0' is not supported when autoScaling policies are used\");\n      }\n      if (maxShardsPerNode == -1 || usePolicyFramework) maxShardsPerNode = Integer.MAX_VALUE;\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      List<ReplicaPosition> replicaPositions;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        replicaPositions = new ArrayList<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode == Integer.MAX_VALUE ?\n            Integer.MAX_VALUE :\n            maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n        replicaPositions = Assign.identifyNodes(ocmh\n            , clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildCoreName(ocmh.zkStateReader.getZkClient(), zkStateReader.getClusterState().getCollection(collectionName),\n            replicaPosition.shard, replicaPosition.type, true);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n\n        // Emit a warning about production use of data driven functionality\n        boolean defaultConfigSetUsed = message.getStr(COLL_CONF) == null ||\n            message.getStr(COLL_CONF).equals(ConfigSetsHandlerApi.DEFAULT_CONFIGSET_NAME);\n        if (defaultConfigSetUsed) {\n          results.add(\"warning\", \"Using _default configset. Data driven schema functionality\"\n              + \" is enabled by default, which is NOT RECOMMENDED for production use. To turn it off:\"\n              + \" curl http://{host:port}/solr/\" + collectionName + \"/config -d '{\\\"set-user-property\\\": {\\\"update.autoCreateFields\\\":\\\"false\\\"}}'\");\n        }\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    } finally {\n      PolicyHelper.clearFlagAndDecref(ocmh.policySessionRef);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    boolean usePolicyFramework = usePolicyFramework(ocmh.zkStateReader, message);\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      if (usePolicyFramework && message.getStr(MAX_SHARDS_PER_NODE) != null && maxShardsPerNode > 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"'maxShardsPerNode>0' is not supported when autoScaling policies are used\");\n      }\n      if (maxShardsPerNode == -1 || usePolicyFramework) maxShardsPerNode = Integer.MAX_VALUE;\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      List<ReplicaPosition> replicaPositions;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        replicaPositions = new ArrayList<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode == Integer.MAX_VALUE ?\n            Integer.MAX_VALUE :\n            maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        replicaPositions = Assign.identifyNodes(() -> ocmh.overseer.getZkController().getCoreContainer(),\n            ocmh.zkStateReader\n            , clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildCoreName(ocmh.zkStateReader.getZkClient(), zkStateReader.getClusterState().getCollection(collectionName),\n            replicaPosition.shard, replicaPosition.type, true);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n\n        // Emit a warning about production use of data driven functionality\n        boolean defaultConfigSetUsed = message.getStr(COLL_CONF) == null ||\n            message.getStr(COLL_CONF).equals(ConfigSetsHandlerApi.DEFAULT_CONFIGSET_NAME);\n        if (defaultConfigSetUsed) {\n          results.add(\"warning\", \"Using _default configset. Data driven schema functionality\"\n              + \" is enabled by default, which is NOT RECOMMENDED for production use. To turn it off:\"\n              + \" curl http://{host:port}/solr/\" + collectionName + \"/config -d '{\\\"set-user-property\\\": {\\\"update.autoCreateFields\\\":\\\"false\\\"}}'\");\n        }\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"85212dad4ed576c7f7e6c165ee19e597b7b4efc8","date":1507997740,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n      Map autoScalingJson = Utils.getJson(ocmh.zkStateReader.getZkClient(), SOLR_AUTOSCALING_CONF_PATH, true);\n      String policy = message.getStr(Policy.POLICY);\n      boolean usePolicyFramework = autoScalingJson.get(Policy.CLUSTER_POLICY) != null || policy != null;\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      if (usePolicyFramework && message.getStr(MAX_SHARDS_PER_NODE) != null && maxShardsPerNode > 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"'maxShardsPerNode>0' is not supported when autoScaling policies are used\");\n      }\n      if (maxShardsPerNode == -1 || usePolicyFramework) maxShardsPerNode = Integer.MAX_VALUE;\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      List<ReplicaPosition> replicaPositions;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        replicaPositions = new ArrayList<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode == Integer.MAX_VALUE ?\n            Integer.MAX_VALUE :\n            maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n        replicaPositions = Assign.identifyNodes(ocmh\n            , clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildCoreName(ocmh.overseer.getSolrCloudManager().getDistribStateManager(), zkStateReader.getClusterState().getCollection(collectionName),\n            replicaPosition.shard, replicaPosition.type, true);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n\n        // Emit a warning about production use of data driven functionality\n        boolean defaultConfigSetUsed = message.getStr(COLL_CONF) == null ||\n            message.getStr(COLL_CONF).equals(ConfigSetsHandlerApi.DEFAULT_CONFIGSET_NAME);\n        if (defaultConfigSetUsed) {\n          results.add(\"warning\", \"Using _default configset. Data driven schema functionality\"\n              + \" is enabled by default, which is NOT RECOMMENDED for production use. To turn it off:\"\n              + \" curl http://{host:port}/solr/\" + collectionName + \"/config -d '{\\\"set-user-property\\\": {\\\"update.autoCreateFields\\\":\\\"false\\\"}}'\");\n        }\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    } finally {\n      PolicyHelper.clearFlagAndDecref(ocmh.policySessionRef);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n      Map autoScalingJson = Utils.getJson(ocmh.zkStateReader.getZkClient(), SOLR_AUTOSCALING_CONF_PATH, true);\n      String policy = message.getStr(Policy.POLICY);\n      boolean usePolicyFramework = autoScalingJson.get(Policy.CLUSTER_POLICY) != null || policy != null;\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      if (usePolicyFramework && message.getStr(MAX_SHARDS_PER_NODE) != null && maxShardsPerNode > 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"'maxShardsPerNode>0' is not supported when autoScaling policies are used\");\n      }\n      if (maxShardsPerNode == -1 || usePolicyFramework) maxShardsPerNode = Integer.MAX_VALUE;\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      List<ReplicaPosition> replicaPositions;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        replicaPositions = new ArrayList<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode == Integer.MAX_VALUE ?\n            Integer.MAX_VALUE :\n            maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n        replicaPositions = Assign.identifyNodes(ocmh\n            , clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildCoreName(ocmh.zkStateReader.getZkClient(), zkStateReader.getClusterState().getCollection(collectionName),\n            replicaPosition.shard, replicaPosition.type, true);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n\n        // Emit a warning about production use of data driven functionality\n        boolean defaultConfigSetUsed = message.getStr(COLL_CONF) == null ||\n            message.getStr(COLL_CONF).equals(ConfigSetsHandlerApi.DEFAULT_CONFIGSET_NAME);\n        if (defaultConfigSetUsed) {\n          results.add(\"warning\", \"Using _default configset. Data driven schema functionality\"\n              + \" is enabled by default, which is NOT RECOMMENDED for production use. To turn it off:\"\n              + \" curl http://{host:port}/solr/\" + collectionName + \"/config -d '{\\\"set-user-property\\\": {\\\"update.autoCreateFields\\\":\\\"false\\\"}}'\");\n        }\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    } finally {\n      PolicyHelper.clearFlagAndDecref(ocmh.policySessionRef);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2bcfee499548996a6e5448bbf93b8f276d010270","date":1508336936,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    final boolean waitForFinalState = message.getBool(WAIT_FOR_FINAL_STATE, false);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n      Map autoScalingJson = Utils.getJson(ocmh.zkStateReader.getZkClient(), SOLR_AUTOSCALING_CONF_PATH, true);\n      String policy = message.getStr(Policy.POLICY);\n      boolean usePolicyFramework = autoScalingJson.get(Policy.CLUSTER_POLICY) != null || policy != null;\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      if (usePolicyFramework && message.getStr(MAX_SHARDS_PER_NODE) != null && maxShardsPerNode > 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"'maxShardsPerNode>0' is not supported when autoScaling policies are used\");\n      }\n      if (maxShardsPerNode == -1 || usePolicyFramework) maxShardsPerNode = Integer.MAX_VALUE;\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      List<ReplicaPosition> replicaPositions;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        replicaPositions = new ArrayList<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode == Integer.MAX_VALUE ?\n            Integer.MAX_VALUE :\n            maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n        replicaPositions = Assign.identifyNodes(ocmh\n            , clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildCoreName(ocmh.overseer.getSolrCloudManager().getDistribStateManager(), zkStateReader.getClusterState().getCollection(collectionName),\n            replicaPosition.shard, replicaPosition.type, true);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name(),\n              CommonAdminParams.WAIT_FOR_FINAL_STATE, Boolean.toString(waitForFinalState));\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n\n        // Emit a warning about production use of data driven functionality\n        boolean defaultConfigSetUsed = message.getStr(COLL_CONF) == null ||\n            message.getStr(COLL_CONF).equals(ConfigSetsHandlerApi.DEFAULT_CONFIGSET_NAME);\n        if (defaultConfigSetUsed) {\n          results.add(\"warning\", \"Using _default configset. Data driven schema functionality\"\n              + \" is enabled by default, which is NOT RECOMMENDED for production use. To turn it off:\"\n              + \" curl http://{host:port}/solr/\" + collectionName + \"/config -d '{\\\"set-user-property\\\": {\\\"update.autoCreateFields\\\":\\\"false\\\"}}'\");\n        }\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    } finally {\n      PolicyHelper.clearFlagAndDecref(ocmh.policySessionRef);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n      Map autoScalingJson = Utils.getJson(ocmh.zkStateReader.getZkClient(), SOLR_AUTOSCALING_CONF_PATH, true);\n      String policy = message.getStr(Policy.POLICY);\n      boolean usePolicyFramework = autoScalingJson.get(Policy.CLUSTER_POLICY) != null || policy != null;\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      if (usePolicyFramework && message.getStr(MAX_SHARDS_PER_NODE) != null && maxShardsPerNode > 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"'maxShardsPerNode>0' is not supported when autoScaling policies are used\");\n      }\n      if (maxShardsPerNode == -1 || usePolicyFramework) maxShardsPerNode = Integer.MAX_VALUE;\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      List<ReplicaPosition> replicaPositions;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        replicaPositions = new ArrayList<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode == Integer.MAX_VALUE ?\n            Integer.MAX_VALUE :\n            maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n        replicaPositions = Assign.identifyNodes(ocmh\n            , clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildCoreName(ocmh.overseer.getSolrCloudManager().getDistribStateManager(), zkStateReader.getClusterState().getCollection(collectionName),\n            replicaPosition.shard, replicaPosition.type, true);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name());\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n\n        // Emit a warning about production use of data driven functionality\n        boolean defaultConfigSetUsed = message.getStr(COLL_CONF) == null ||\n            message.getStr(COLL_CONF).equals(ConfigSetsHandlerApi.DEFAULT_CONFIGSET_NAME);\n        if (defaultConfigSetUsed) {\n          results.add(\"warning\", \"Using _default configset. Data driven schema functionality\"\n              + \" is enabled by default, which is NOT RECOMMENDED for production use. To turn it off:\"\n              + \" curl http://{host:port}/solr/\" + collectionName + \"/config -d '{\\\"set-user-property\\\": {\\\"update.autoCreateFields\\\":\\\"false\\\"}}'\");\n        }\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    } finally {\n      PolicyHelper.clearFlagAndDecref(ocmh.policySessionRef);\n    }\n  }\n\n","bugFix":null,"bugIntro":["5ad9c35f926b4bf8da0336d1300efc709c8d5a56","5ad9c35f926b4bf8da0336d1300efc709c8d5a56","5ad9c35f926b4bf8da0336d1300efc709c8d5a56","5ad9c35f926b4bf8da0336d1300efc709c8d5a56"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"427295870ac138112ed6ab0973a2dbe42e0a1a2d","date":1510742913,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    final boolean waitForFinalState = message.getBool(WAIT_FOR_FINAL_STATE, false);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n      Map autoScalingJson = Utils.getJson(ocmh.zkStateReader.getZkClient(), SOLR_AUTOSCALING_CONF_PATH, true);\n      String policy = message.getStr(Policy.POLICY);\n      boolean usePolicyFramework = autoScalingJson.get(Policy.CLUSTER_POLICY) != null || policy != null;\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      if (usePolicyFramework && message.getStr(MAX_SHARDS_PER_NODE) != null && maxShardsPerNode > 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"'maxShardsPerNode>0' is not supported when autoScaling policies are used\");\n      }\n      if (maxShardsPerNode == -1 || usePolicyFramework) maxShardsPerNode = Integer.MAX_VALUE;\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      List<ReplicaPosition> replicaPositions;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        replicaPositions = new ArrayList<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode == Integer.MAX_VALUE ?\n            Integer.MAX_VALUE :\n            maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n        replicaPositions = Assign.identifyNodes(ocmh\n            , clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildCoreName(ocmh.overseer.getSolrCloudManager().getDistribStateManager(), zkStateReader.getClusterState().getCollection(collectionName),\n            replicaPosition.shard, replicaPosition.type, true);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name(),\n              CommonAdminParams.WAIT_FOR_FINAL_STATE, Boolean.toString(waitForFinalState));\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n\n        // Emit a warning about production use of data driven functionality\n        boolean defaultConfigSetUsed = message.getStr(COLL_CONF) == null ||\n            message.getStr(COLL_CONF).equals(ConfigSetsHandlerApi.DEFAULT_CONFIGSET_NAME);\n        if (defaultConfigSetUsed) {\n          results.add(\"warning\", \"Using _default configset. Data driven schema functionality\"\n              + \" is enabled by default, which is NOT RECOMMENDED for production use. To turn it off:\"\n              + \" curl http://{host:port}/solr/\" + collectionName + \"/config -d '{\\\"set-user-property\\\": {\\\"update.autoCreateFields\\\":\\\"false\\\"}}'\");\n        }\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    } finally {\n      PolicyHelper.clearFlagAndDecref(PolicyHelper.getPolicySessionRef(ocmh.overseer.getSolrCloudManager()));\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    final boolean waitForFinalState = message.getBool(WAIT_FOR_FINAL_STATE, false);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n      Map autoScalingJson = Utils.getJson(ocmh.zkStateReader.getZkClient(), SOLR_AUTOSCALING_CONF_PATH, true);\n      String policy = message.getStr(Policy.POLICY);\n      boolean usePolicyFramework = autoScalingJson.get(Policy.CLUSTER_POLICY) != null || policy != null;\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      if (usePolicyFramework && message.getStr(MAX_SHARDS_PER_NODE) != null && maxShardsPerNode > 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"'maxShardsPerNode>0' is not supported when autoScaling policies are used\");\n      }\n      if (maxShardsPerNode == -1 || usePolicyFramework) maxShardsPerNode = Integer.MAX_VALUE;\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      List<ReplicaPosition> replicaPositions;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        replicaPositions = new ArrayList<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode == Integer.MAX_VALUE ?\n            Integer.MAX_VALUE :\n            maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n        replicaPositions = Assign.identifyNodes(ocmh\n            , clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildCoreName(ocmh.overseer.getSolrCloudManager().getDistribStateManager(), zkStateReader.getClusterState().getCollection(collectionName),\n            replicaPosition.shard, replicaPosition.type, true);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name(),\n              CommonAdminParams.WAIT_FOR_FINAL_STATE, Boolean.toString(waitForFinalState));\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n\n        // Emit a warning about production use of data driven functionality\n        boolean defaultConfigSetUsed = message.getStr(COLL_CONF) == null ||\n            message.getStr(COLL_CONF).equals(ConfigSetsHandlerApi.DEFAULT_CONFIGSET_NAME);\n        if (defaultConfigSetUsed) {\n          results.add(\"warning\", \"Using _default configset. Data driven schema functionality\"\n              + \" is enabled by default, which is NOT RECOMMENDED for production use. To turn it off:\"\n              + \" curl http://{host:port}/solr/\" + collectionName + \"/config -d '{\\\"set-user-property\\\": {\\\"update.autoCreateFields\\\":\\\"false\\\"}}'\");\n        }\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    } finally {\n      PolicyHelper.clearFlagAndDecref(ocmh.policySessionRef);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d907c28c7fe6305eaec1756d51365f5149e1e41d","date":1512533044,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    final boolean waitForFinalState = message.getBool(WAIT_FOR_FINAL_STATE, false);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n      Map autoScalingJson = Utils.getJson(ocmh.zkStateReader.getZkClient(), SOLR_AUTOSCALING_CONF_PATH, true);\n      String policy = message.getStr(Policy.POLICY);\n      boolean usePolicyFramework = autoScalingJson.get(Policy.CLUSTER_POLICY) != null || policy != null;\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      if (usePolicyFramework && message.getStr(MAX_SHARDS_PER_NODE) != null && maxShardsPerNode > 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"'maxShardsPerNode>0' is not supported when autoScaling policies are used\");\n      }\n      if (maxShardsPerNode == -1 || usePolicyFramework) maxShardsPerNode = Integer.MAX_VALUE;\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      List<ReplicaPosition> replicaPositions;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        replicaPositions = new ArrayList<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode == Integer.MAX_VALUE ?\n            Integer.MAX_VALUE :\n            maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n        replicaPositions = Assign.identifyNodes(ocmh\n            , clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n        sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildCoreName(ocmh.overseer.getSolrCloudManager().getDistribStateManager(), zkStateReader.getClusterState().getCollection(collectionName),\n            replicaPosition.shard, replicaPosition.type, true);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name(),\n              CommonAdminParams.WAIT_FOR_FINAL_STATE, Boolean.toString(waitForFinalState));\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n\n        // Emit a warning about production use of data driven functionality\n        boolean defaultConfigSetUsed = message.getStr(COLL_CONF) == null ||\n            message.getStr(COLL_CONF).equals(ConfigSetsHandlerApi.DEFAULT_CONFIGSET_NAME);\n        if (defaultConfigSetUsed) {\n          results.add(\"warning\", \"Using _default configset. Data driven schema functionality\"\n              + \" is enabled by default, which is NOT RECOMMENDED for production use. To turn it off:\"\n              + \" curl http://{host:port}/solr/\" + collectionName + \"/config -d '{\\\"set-user-property\\\": {\\\"update.autoCreateFields\\\":\\\"false\\\"}}'\");\n        }\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    } finally {\n      if(sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    final boolean waitForFinalState = message.getBool(WAIT_FOR_FINAL_STATE, false);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n      Map autoScalingJson = Utils.getJson(ocmh.zkStateReader.getZkClient(), SOLR_AUTOSCALING_CONF_PATH, true);\n      String policy = message.getStr(Policy.POLICY);\n      boolean usePolicyFramework = autoScalingJson.get(Policy.CLUSTER_POLICY) != null || policy != null;\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      if (usePolicyFramework && message.getStr(MAX_SHARDS_PER_NODE) != null && maxShardsPerNode > 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"'maxShardsPerNode>0' is not supported when autoScaling policies are used\");\n      }\n      if (maxShardsPerNode == -1 || usePolicyFramework) maxShardsPerNode = Integer.MAX_VALUE;\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      List<ReplicaPosition> replicaPositions;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        replicaPositions = new ArrayList<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode == Integer.MAX_VALUE ?\n            Integer.MAX_VALUE :\n            maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n        replicaPositions = Assign.identifyNodes(ocmh\n            , clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildCoreName(ocmh.overseer.getSolrCloudManager().getDistribStateManager(), zkStateReader.getClusterState().getCollection(collectionName),\n            replicaPosition.shard, replicaPosition.type, true);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name(),\n              CommonAdminParams.WAIT_FOR_FINAL_STATE, Boolean.toString(waitForFinalState));\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n\n        // Emit a warning about production use of data driven functionality\n        boolean defaultConfigSetUsed = message.getStr(COLL_CONF) == null ||\n            message.getStr(COLL_CONF).equals(ConfigSetsHandlerApi.DEFAULT_CONFIGSET_NAME);\n        if (defaultConfigSetUsed) {\n          results.add(\"warning\", \"Using _default configset. Data driven schema functionality\"\n              + \" is enabled by default, which is NOT RECOMMENDED for production use. To turn it off:\"\n              + \" curl http://{host:port}/solr/\" + collectionName + \"/config -d '{\\\"set-user-property\\\": {\\\"update.autoCreateFields\\\":\\\"false\\\"}}'\");\n        }\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    } finally {\n      PolicyHelper.clearFlagAndDecref(PolicyHelper.getPolicySessionRef(ocmh.overseer.getSolrCloudManager()));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1","date":1513252583,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    final boolean waitForFinalState = message.getBool(WAIT_FOR_FINAL_STATE, false);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n    AtomicReference<PolicyHelper.SessionWrapper> sessionWrapper = new AtomicReference<>();\n\n    try {\n\n      final String async = message.getStr(ASYNC);\n\n      List<String> nodeList = new ArrayList<>();\n      List<String> shardNames = new ArrayList<>();\n      List<ReplicaPosition> replicaPositions = buildReplicaPositions(ocmh.cloudManager, clusterState, message,\n          nodeList, shardNames, sessionWrapper);\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(stateManager, configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(stateManager, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS, timeSource);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        waitUntil.sleep(100);\n        created = ocmh.cloudManager.getClusterStateProvider().getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , message : {2}\",\n          collectionName, shardNames, message));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildSolrCoreName(ocmh.cloudManager.getDistribStateManager(),\n            ocmh.cloudManager.getClusterStateProvider().getClusterState().getCollection(collectionName),\n            replicaPosition.shard, replicaPosition.type, true);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name(),\n              CommonAdminParams.WAIT_FOR_FINAL_STATE, Boolean.toString(waitForFinalState));\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, shardNames.size());\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n\n        // Emit a warning about production use of data driven functionality\n        boolean defaultConfigSetUsed = message.getStr(COLL_CONF) == null ||\n            message.getStr(COLL_CONF).equals(ConfigSetsHandlerApi.DEFAULT_CONFIGSET_NAME);\n        if (defaultConfigSetUsed) {\n          results.add(\"warning\", \"Using _default configset. Data driven schema functionality\"\n              + \" is enabled by default, which is NOT RECOMMENDED for production use. To turn it off:\"\n              + \" curl http://{host:port}/solr/\" + collectionName + \"/config -d '{\\\"set-user-property\\\": {\\\"update.autoCreateFields\\\":\\\"false\\\"}}'\");\n        }\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    } finally {\n      if (sessionWrapper.get() != null) sessionWrapper.get().release();\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    final boolean waitForFinalState = message.getBool(WAIT_FOR_FINAL_STATE, false);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n      int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n      int numPullReplicas = message.getInt(PULL_REPLICAS, 0);\n      Map autoScalingJson = Utils.getJson(ocmh.zkStateReader.getZkClient(), SOLR_AUTOSCALING_CONF_PATH, true);\n      String policy = message.getStr(Policy.POLICY);\n      boolean usePolicyFramework = autoScalingJson.get(Policy.CLUSTER_POLICY) != null || policy != null;\n\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      if (usePolicyFramework && message.getStr(MAX_SHARDS_PER_NODE) != null && maxShardsPerNode > 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"'maxShardsPerNode>0' is not supported when autoScaling policies are used\");\n      }\n      if (maxShardsPerNode == -1 || usePolicyFramework) maxShardsPerNode = Integer.MAX_VALUE;\n      if (numNrtReplicas + numTlogReplicas <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      List<ReplicaPosition> replicaPositions;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        replicaPositions = new ArrayList<>();\n      } else {\n        int totalNumReplicas = numNrtReplicas + numTlogReplicas + numPullReplicas;\n        if (totalNumReplicas > nodeList.size()) {\n          log.warn(\"Specified number of replicas of \"\n              + totalNumReplicas\n              + \" on collection \"\n              + collectionName\n              + \" is higher than the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n\n        int maxShardsAllowedToCreate = maxShardsPerNode == Integer.MAX_VALUE ?\n            Integer.MAX_VALUE :\n            maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * totalNumReplicas;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \", value of \" + NRT_REPLICAS + \" is \" + numNrtReplicas\n              + \", value of \" + TLOG_REPLICAS + \" is \" + numTlogReplicas\n              + \" and value of \" + PULL_REPLICAS + \" is \" + numPullReplicas\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n        replicaPositions = Assign.identifyNodes(ocmh\n            , clusterState, nodeList, collectionName, message, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n        sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n      }\n\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(zkClient, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , nrtReplicas : {2}, tlogReplicas: {3}, pullReplicas: {4}\",\n          collectionName, shardNames, numNrtReplicas, numTlogReplicas, numPullReplicas));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildCoreName(ocmh.overseer.getSolrCloudManager().getDistribStateManager(), zkStateReader.getClusterState().getCollection(collectionName),\n            replicaPosition.shard, replicaPosition.type, true);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name(),\n              CommonAdminParams.WAIT_FOR_FINAL_STATE, Boolean.toString(waitForFinalState));\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n\n        // Emit a warning about production use of data driven functionality\n        boolean defaultConfigSetUsed = message.getStr(COLL_CONF) == null ||\n            message.getStr(COLL_CONF).equals(ConfigSetsHandlerApi.DEFAULT_CONFIGSET_NAME);\n        if (defaultConfigSetUsed) {\n          results.add(\"warning\", \"Using _default configset. Data driven schema functionality\"\n              + \" is enabled by default, which is NOT RECOMMENDED for production use. To turn it off:\"\n              + \" curl http://{host:port}/solr/\" + collectionName + \"/config -d '{\\\"set-user-property\\\": {\\\"update.autoCreateFields\\\":\\\"false\\\"}}'\");\n        }\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    } finally {\n      if(sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f","bb222a3f9d9421d5c95afce73013fbd8de07ea1f","bb222a3f9d9421d5c95afce73013fbd8de07ea1f","bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6146c07c0dee1ae1e42926167acd127fed5ef59d","date":1516129420,"type":5,"author":"Varun Thacker","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/api/collections/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    final boolean waitForFinalState = message.getBool(WAIT_FOR_FINAL_STATE, false);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n    AtomicReference<PolicyHelper.SessionWrapper> sessionWrapper = new AtomicReference<>();\n\n    try {\n\n      final String async = message.getStr(ASYNC);\n\n      List<String> nodeList = new ArrayList<>();\n      List<String> shardNames = new ArrayList<>();\n      List<ReplicaPosition> replicaPositions = buildReplicaPositions(ocmh.cloudManager, clusterState, message,\n          nodeList, shardNames, sessionWrapper);\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(stateManager, configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(stateManager, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS, timeSource);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        waitUntil.sleep(100);\n        created = ocmh.cloudManager.getClusterStateProvider().getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , message : {2}\",\n          collectionName, shardNames, message));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildSolrCoreName(ocmh.cloudManager.getDistribStateManager(),\n            ocmh.cloudManager.getClusterStateProvider().getClusterState().getCollection(collectionName),\n            replicaPosition.shard, replicaPosition.type, true);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name(),\n              CommonAdminParams.WAIT_FOR_FINAL_STATE, Boolean.toString(waitForFinalState));\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, shardNames.size());\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n\n        // Emit a warning about production use of data driven functionality\n        boolean defaultConfigSetUsed = message.getStr(COLL_CONF) == null ||\n            message.getStr(COLL_CONF).equals(ConfigSetsHandlerApi.DEFAULT_CONFIGSET_NAME);\n        if (defaultConfigSetUsed) {\n          results.add(\"warning\", \"Using _default configset. Data driven schema functionality\"\n              + \" is enabled by default, which is NOT RECOMMENDED for production use. To turn it off:\"\n              + \" curl http://{host:port}/solr/\" + collectionName + \"/config -d '{\\\"set-user-property\\\": {\\\"update.autoCreateFields\\\":\\\"false\\\"}}'\");\n        }\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    } finally {\n      if (sessionWrapper.get() != null) sessionWrapper.get().release();\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    final boolean waitForFinalState = message.getBool(WAIT_FOR_FINAL_STATE, false);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n    AtomicReference<PolicyHelper.SessionWrapper> sessionWrapper = new AtomicReference<>();\n\n    try {\n\n      final String async = message.getStr(ASYNC);\n\n      List<String> nodeList = new ArrayList<>();\n      List<String> shardNames = new ArrayList<>();\n      List<ReplicaPosition> replicaPositions = buildReplicaPositions(ocmh.cloudManager, clusterState, message,\n          nodeList, shardNames, sessionWrapper);\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(stateManager, configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(stateManager, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS, timeSource);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        waitUntil.sleep(100);\n        created = ocmh.cloudManager.getClusterStateProvider().getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , message : {2}\",\n          collectionName, shardNames, message));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildSolrCoreName(ocmh.cloudManager.getDistribStateManager(),\n            ocmh.cloudManager.getClusterStateProvider().getClusterState().getCollection(collectionName),\n            replicaPosition.shard, replicaPosition.type, true);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name(),\n              CommonAdminParams.WAIT_FOR_FINAL_STATE, Boolean.toString(waitForFinalState));\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, shardNames.size());\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n\n        // Emit a warning about production use of data driven functionality\n        boolean defaultConfigSetUsed = message.getStr(COLL_CONF) == null ||\n            message.getStr(COLL_CONF).equals(ConfigSetsHandlerApi.DEFAULT_CONFIGSET_NAME);\n        if (defaultConfigSetUsed) {\n          results.add(\"warning\", \"Using _default configset. Data driven schema functionality\"\n              + \" is enabled by default, which is NOT RECOMMENDED for production use. To turn it off:\"\n              + \" curl http://{host:port}/solr/\" + collectionName + \"/config -d '{\\\"set-user-property\\\": {\\\"update.autoCreateFields\\\":\\\"false\\\"}}'\");\n        }\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    } finally {\n      if (sessionWrapper.get() != null) sessionWrapper.get().release();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b94236357aaa22b76c10629851fe4e376e0cea82","date":1516710914,"type":5,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/api/collections/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/CreateCollectionCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    final boolean waitForFinalState = message.getBool(WAIT_FOR_FINAL_STATE, false);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n    AtomicReference<PolicyHelper.SessionWrapper> sessionWrapper = new AtomicReference<>();\n\n    try {\n\n      final String async = message.getStr(ASYNC);\n\n      List<String> nodeList = new ArrayList<>();\n      List<String> shardNames = new ArrayList<>();\n      List<ReplicaPosition> replicaPositions = buildReplicaPositions(ocmh.cloudManager, clusterState, message,\n          nodeList, shardNames, sessionWrapper);\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(stateManager, configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(stateManager, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS, timeSource);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        waitUntil.sleep(100);\n        created = ocmh.cloudManager.getClusterStateProvider().getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , message : {2}\",\n          collectionName, shardNames, message));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildSolrCoreName(ocmh.cloudManager.getDistribStateManager(),\n            ocmh.cloudManager.getClusterStateProvider().getClusterState().getCollection(collectionName),\n            replicaPosition.shard, replicaPosition.type, true);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name(),\n              CommonAdminParams.WAIT_FOR_FINAL_STATE, Boolean.toString(waitForFinalState));\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, shardNames.size());\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n\n        // Emit a warning about production use of data driven functionality\n        boolean defaultConfigSetUsed = message.getStr(COLL_CONF) == null ||\n            message.getStr(COLL_CONF).equals(ConfigSetsHandlerApi.DEFAULT_CONFIGSET_NAME);\n        if (defaultConfigSetUsed) {\n          results.add(\"warning\", \"Using _default configset. Data driven schema functionality\"\n              + \" is enabled by default, which is NOT RECOMMENDED for production use. To turn it off:\"\n              + \" curl http://{host:port}/solr/\" + collectionName + \"/config -d '{\\\"set-user-property\\\": {\\\"update.autoCreateFields\\\":\\\"false\\\"}}'\");\n        }\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    } finally {\n      if (sessionWrapper.get() != null) sessionWrapper.get().release();\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    final String collectionName = message.getStr(NAME);\n    final boolean waitForFinalState = message.getBool(WAIT_FOR_FINAL_STATE, false);\n    log.info(\"Create collection {}\", collectionName);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    }\n\n    ocmh.validateConfigOrThrowSolrException(configName);\n    AtomicReference<PolicyHelper.SessionWrapper> sessionWrapper = new AtomicReference<>();\n\n    try {\n\n      final String async = message.getStr(ASYNC);\n\n      List<String> nodeList = new ArrayList<>();\n      List<String> shardNames = new ArrayList<>();\n      List<ReplicaPosition> replicaPositions = buildReplicaPositions(ocmh.cloudManager, clusterState, message,\n          nodeList, shardNames, sessionWrapper);\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n\n      ocmh.createConfNode(stateManager, configName, collectionName, isLegacyCloud);\n\n      Map<String,String> collectionParams = new HashMap<>();\n      Map<String,Object> collectionProps = message.getProperties();\n      for (String propName : collectionProps.keySet()) {\n        if (propName.startsWith(ZkController.COLLECTION_PARAM_PREFIX)) {\n          collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n        }\n      }\n      \n      createCollectionZkNode(stateManager, collectionName, collectionParams);\n      \n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS, timeSource);\n      boolean created = false;\n      while (! waitUntil.hasTimedOut()) {\n        waitUntil.sleep(100);\n        created = ocmh.cloudManager.getClusterStateProvider().getClusterState().hasCollection(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.debug(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      Map<String, String> requestMap = new HashMap<>();\n\n\n      log.debug(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , message : {2}\",\n          collectionName, shardNames, message));\n      Map<String,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        String nodeName = replicaPosition.node;\n        String coreName = Assign.buildSolrCoreName(ocmh.cloudManager.getDistribStateManager(),\n            ocmh.cloudManager.getClusterStateProvider().getClusterState().getCollection(collectionName),\n            replicaPosition.shard, replicaPosition.type, true);\n        log.debug(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, replicaPosition.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, replicaPosition.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl,\n              ZkStateReader.REPLICA_TYPE, replicaPosition.type.name(),\n              CommonAdminParams.WAIT_FOR_FINAL_STATE, Boolean.toString(waitForFinalState));\n          Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, replicaPosition.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, shardNames.size());\n        params.set(CoreAdminParams.NEW_COLLECTION, \"true\");\n        params.set(CoreAdminParams.REPLICA_TYPE, replicaPosition.type.name());\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        ocmh.addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        sreq.nodeName = nodeName;\n        params.set(\"qt\", ocmh.adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = ocmh.waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ocmh.processResponses(results, shardHandler, false, null, async, requestMap, Collections.emptySet());\n      if(results.get(\"failure\") != null && ((SimpleOrderedMap)results.get(\"failure\")).size() > 0) {\n        // Let's cleanup as we hit an exception\n        // We shouldn't be passing 'results' here for the cleanup as the response would then contain 'success'\n        // element, which may be interpreted by the user as a positive ack\n        ocmh.cleanupCollection(collectionName, new NamedList());\n        log.info(\"Cleaned up artifacts for failed create collection for [{}]\", collectionName);\n      } else {\n        log.debug(\"Finished create command on all shards for collection: {}\", collectionName);\n\n        // Emit a warning about production use of data driven functionality\n        boolean defaultConfigSetUsed = message.getStr(COLL_CONF) == null ||\n            message.getStr(COLL_CONF).equals(ConfigSetsHandlerApi.DEFAULT_CONFIGSET_NAME);\n        if (defaultConfigSetUsed) {\n          results.add(\"warning\", \"Using _default configset. Data driven schema functionality\"\n              + \" is enabled by default, which is NOT RECOMMENDED for production use. To turn it off:\"\n              + \" curl http://{host:port}/solr/\" + collectionName + \"/config -d '{\\\"set-user-property\\\": {\\\"update.autoCreateFields\\\":\\\"false\\\"}}'\");\n        }\n      }\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, ex);\n    } finally {\n      if (sessionWrapper.get() != null) sessionWrapper.get().release();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"c00aac053fdd75193eb8b6d45b64c26c3b586d5b":["4328dbef1afa8336d38a4301a545999d1e21f8fa","c0ee0c7f6bcf49646748d46aee9383b68eb55c80"],"b94236357aaa22b76c10629851fe4e376e0cea82":["1d4bf9d5308dfef350829c28f2b3b2648df1e9b1","6146c07c0dee1ae1e42926167acd127fed5ef59d"],"2bcfee499548996a6e5448bbf93b8f276d010270":["85212dad4ed576c7f7e6c165ee19e597b7b4efc8"],"25e4a4cddd699db6cce60282e747c7705897e821":["61c45e99cf6676da48f19d7511c73712ad39402b"],"c304e97e7c1d472bc70e801b35ee78583916c6cd":["c0ee0c7f6bcf49646748d46aee9383b68eb55c80","c00aac053fdd75193eb8b6d45b64c26c3b586d5b"],"717e5ceb2acae36d422ec75e5a4ce9fac40506e1":["936cdd5882761db3b844afd6f84ab81cbb011a75"],"114b665752b215f36836a7c5411f7c433b4d1352":["e9017cf144952056066919f1ebc7897ff9bd71b1"],"219ac4e012cb38bcfcd8f4290dccd4f5b4d7bc25":["fb569fd721c41eafc2a2d788499a7df490c7f1a5"],"0806aac02ecbbdc6b5d9705ae15da193219c7af4":["0d92226151c91fb4bebcca6d18782d1c84aee2cd"],"f9a989a32a073c55e3aef6f807a3474184bbcf49":["0d92226151c91fb4bebcca6d18782d1c84aee2cd","091980700f1c5c53946291e7fa2b9024b586b288"],"091980700f1c5c53946291e7fa2b9024b586b288":["969718c368b28ed1b2335ea2deb275c696cddb4f"],"e9017cf144952056066919f1ebc7897ff9bd71b1":["f291d2d430e8149d24fdd06b0bcdab0941ec9144","74aea047dff7f7c38a2d766827bd20d356f98c6a"],"44bfd7d2ea76c7c37dd13eadc1889039e172f3c7":["a52341299179de5479672f7cf518bf4b173f34b3"],"f291d2d430e8149d24fdd06b0bcdab0941ec9144":["d528fd7ae22865015b756e0a03832e2051de2a9c"],"74aea047dff7f7c38a2d766827bd20d356f98c6a":["45cb1a93c8314086fa3e14744fbc4eec36006057","25e4a4cddd699db6cce60282e747c7705897e821"],"969718c368b28ed1b2335ea2deb275c696cddb4f":["28288370235ed02234a64753cdbf0c6ec096304a"],"0d92226151c91fb4bebcca6d18782d1c84aee2cd":["114b665752b215f36836a7c5411f7c433b4d1352"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["403d05f7f8d69b65659157eff1bc1d2717f04c66","962cd4f5e313777f35da8f521265323e84184929"],"45cb1a93c8314086fa3e14744fbc4eec36006057":["61c45e99cf6676da48f19d7511c73712ad39402b"],"66e0b82bd39567aa2bf534e5282d05fb4a4a2c76":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"9856095f7afb5a607bf5e65077615ed91273508c":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","f291d2d430e8149d24fdd06b0bcdab0941ec9144"],"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1":["d907c28c7fe6305eaec1756d51365f5149e1e41d"],"560c18d71dad43d675158783c3840f8c80d6d39c":["c0ee0c7f6bcf49646748d46aee9383b68eb55c80","c304e97e7c1d472bc70e801b35ee78583916c6cd"],"4328dbef1afa8336d38a4301a545999d1e21f8fa":["bccf7971a36bd151490117582a0a1a695081ead3"],"d1f5728f32a4a256b36cfabd7a2636452f599bb9":["61c45e99cf6676da48f19d7511c73712ad39402b","45cb1a93c8314086fa3e14744fbc4eec36006057"],"962cd4f5e313777f35da8f521265323e84184929":["403d05f7f8d69b65659157eff1bc1d2717f04c66"],"651c3ddf5bc1266d9de0a972ec05e59d77099a4c":["091980700f1c5c53946291e7fa2b9024b586b288"],"403d05f7f8d69b65659157eff1bc1d2717f04c66":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","66e0b82bd39567aa2bf534e5282d05fb4a4a2c76"],"61c45e99cf6676da48f19d7511c73712ad39402b":["f291d2d430e8149d24fdd06b0bcdab0941ec9144"],"bccf7971a36bd151490117582a0a1a695081ead3":["7a23cf16c8fa265dc0a564adcabb55e3f054e0ac"],"fb569fd721c41eafc2a2d788499a7df490c7f1a5":["0806aac02ecbbdc6b5d9705ae15da193219c7af4","f9a989a32a073c55e3aef6f807a3474184bbcf49"],"85212dad4ed576c7f7e6c165ee19e597b7b4efc8":["560c18d71dad43d675158783c3840f8c80d6d39c"],"936cdd5882761db3b844afd6f84ab81cbb011a75":["219ac4e012cb38bcfcd8f4290dccd4f5b4d7bc25","651c3ddf5bc1266d9de0a972ec05e59d77099a4c"],"6146c07c0dee1ae1e42926167acd127fed5ef59d":["1d4bf9d5308dfef350829c28f2b3b2648df1e9b1"],"d528fd7ae22865015b756e0a03832e2051de2a9c":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"28288370235ed02234a64753cdbf0c6ec096304a":["d1f5728f32a4a256b36cfabd7a2636452f599bb9","74aea047dff7f7c38a2d766827bd20d356f98c6a"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","d528fd7ae22865015b756e0a03832e2051de2a9c"],"a52341299179de5479672f7cf518bf4b173f34b3":["091980700f1c5c53946291e7fa2b9024b586b288","651c3ddf5bc1266d9de0a972ec05e59d77099a4c"],"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac":["717e5ceb2acae36d422ec75e5a4ce9fac40506e1","44bfd7d2ea76c7c37dd13eadc1889039e172f3c7"],"427295870ac138112ed6ab0973a2dbe42e0a1a2d":["2bcfee499548996a6e5448bbf93b8f276d010270"],"44b289ba5434fa10782118c697fa706d6cf231df":["61c45e99cf6676da48f19d7511c73712ad39402b","d1f5728f32a4a256b36cfabd7a2636452f599bb9"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b94236357aaa22b76c10629851fe4e376e0cea82"],"d907c28c7fe6305eaec1756d51365f5149e1e41d":["427295870ac138112ed6ab0973a2dbe42e0a1a2d"],"c0ee0c7f6bcf49646748d46aee9383b68eb55c80":["44bfd7d2ea76c7c37dd13eadc1889039e172f3c7"]},"commit2Childs":{"c00aac053fdd75193eb8b6d45b64c26c3b586d5b":["c304e97e7c1d472bc70e801b35ee78583916c6cd"],"b94236357aaa22b76c10629851fe4e376e0cea82":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"2bcfee499548996a6e5448bbf93b8f276d010270":["427295870ac138112ed6ab0973a2dbe42e0a1a2d"],"25e4a4cddd699db6cce60282e747c7705897e821":["74aea047dff7f7c38a2d766827bd20d356f98c6a"],"c304e97e7c1d472bc70e801b35ee78583916c6cd":["560c18d71dad43d675158783c3840f8c80d6d39c"],"717e5ceb2acae36d422ec75e5a4ce9fac40506e1":["7a23cf16c8fa265dc0a564adcabb55e3f054e0ac"],"114b665752b215f36836a7c5411f7c433b4d1352":["0d92226151c91fb4bebcca6d18782d1c84aee2cd"],"219ac4e012cb38bcfcd8f4290dccd4f5b4d7bc25":["936cdd5882761db3b844afd6f84ab81cbb011a75"],"0806aac02ecbbdc6b5d9705ae15da193219c7af4":["fb569fd721c41eafc2a2d788499a7df490c7f1a5"],"f9a989a32a073c55e3aef6f807a3474184bbcf49":["fb569fd721c41eafc2a2d788499a7df490c7f1a5"],"091980700f1c5c53946291e7fa2b9024b586b288":["f9a989a32a073c55e3aef6f807a3474184bbcf49","651c3ddf5bc1266d9de0a972ec05e59d77099a4c","a52341299179de5479672f7cf518bf4b173f34b3"],"e9017cf144952056066919f1ebc7897ff9bd71b1":["114b665752b215f36836a7c5411f7c433b4d1352"],"f291d2d430e8149d24fdd06b0bcdab0941ec9144":["e9017cf144952056066919f1ebc7897ff9bd71b1","9856095f7afb5a607bf5e65077615ed91273508c","61c45e99cf6676da48f19d7511c73712ad39402b"],"44bfd7d2ea76c7c37dd13eadc1889039e172f3c7":["7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","c0ee0c7f6bcf49646748d46aee9383b68eb55c80"],"74aea047dff7f7c38a2d766827bd20d356f98c6a":["e9017cf144952056066919f1ebc7897ff9bd71b1","28288370235ed02234a64753cdbf0c6ec096304a"],"0d92226151c91fb4bebcca6d18782d1c84aee2cd":["0806aac02ecbbdc6b5d9705ae15da193219c7af4","f9a989a32a073c55e3aef6f807a3474184bbcf49"],"969718c368b28ed1b2335ea2deb275c696cddb4f":["091980700f1c5c53946291e7fa2b9024b586b288"],"45cb1a93c8314086fa3e14744fbc4eec36006057":["74aea047dff7f7c38a2d766827bd20d356f98c6a","d1f5728f32a4a256b36cfabd7a2636452f599bb9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["66e0b82bd39567aa2bf534e5282d05fb4a4a2c76","403d05f7f8d69b65659157eff1bc1d2717f04c66","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["d528fd7ae22865015b756e0a03832e2051de2a9c"],"66e0b82bd39567aa2bf534e5282d05fb4a4a2c76":["403d05f7f8d69b65659157eff1bc1d2717f04c66"],"9856095f7afb5a607bf5e65077615ed91273508c":[],"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1":["b94236357aaa22b76c10629851fe4e376e0cea82","6146c07c0dee1ae1e42926167acd127fed5ef59d"],"4328dbef1afa8336d38a4301a545999d1e21f8fa":["c00aac053fdd75193eb8b6d45b64c26c3b586d5b"],"560c18d71dad43d675158783c3840f8c80d6d39c":["85212dad4ed576c7f7e6c165ee19e597b7b4efc8"],"d1f5728f32a4a256b36cfabd7a2636452f599bb9":["28288370235ed02234a64753cdbf0c6ec096304a","44b289ba5434fa10782118c697fa706d6cf231df"],"962cd4f5e313777f35da8f521265323e84184929":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"651c3ddf5bc1266d9de0a972ec05e59d77099a4c":["936cdd5882761db3b844afd6f84ab81cbb011a75","a52341299179de5479672f7cf518bf4b173f34b3"],"403d05f7f8d69b65659157eff1bc1d2717f04c66":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d","962cd4f5e313777f35da8f521265323e84184929"],"61c45e99cf6676da48f19d7511c73712ad39402b":["25e4a4cddd699db6cce60282e747c7705897e821","45cb1a93c8314086fa3e14744fbc4eec36006057","d1f5728f32a4a256b36cfabd7a2636452f599bb9","44b289ba5434fa10782118c697fa706d6cf231df"],"fb569fd721c41eafc2a2d788499a7df490c7f1a5":["219ac4e012cb38bcfcd8f4290dccd4f5b4d7bc25"],"bccf7971a36bd151490117582a0a1a695081ead3":["4328dbef1afa8336d38a4301a545999d1e21f8fa"],"85212dad4ed576c7f7e6c165ee19e597b7b4efc8":["2bcfee499548996a6e5448bbf93b8f276d010270"],"936cdd5882761db3b844afd6f84ab81cbb011a75":["717e5ceb2acae36d422ec75e5a4ce9fac40506e1"],"6146c07c0dee1ae1e42926167acd127fed5ef59d":["b94236357aaa22b76c10629851fe4e376e0cea82"],"d528fd7ae22865015b756e0a03832e2051de2a9c":["f291d2d430e8149d24fdd06b0bcdab0941ec9144","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"28288370235ed02234a64753cdbf0c6ec096304a":["969718c368b28ed1b2335ea2deb275c696cddb4f"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["9856095f7afb5a607bf5e65077615ed91273508c"],"a52341299179de5479672f7cf518bf4b173f34b3":["44bfd7d2ea76c7c37dd13eadc1889039e172f3c7"],"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac":["bccf7971a36bd151490117582a0a1a695081ead3"],"427295870ac138112ed6ab0973a2dbe42e0a1a2d":["d907c28c7fe6305eaec1756d51365f5149e1e41d"],"44b289ba5434fa10782118c697fa706d6cf231df":[],"c0ee0c7f6bcf49646748d46aee9383b68eb55c80":["c00aac053fdd75193eb8b6d45b64c26c3b586d5b","c304e97e7c1d472bc70e801b35ee78583916c6cd","560c18d71dad43d675158783c3840f8c80d6d39c"],"d907c28c7fe6305eaec1756d51365f5149e1e41d":["1d4bf9d5308dfef350829c28f2b3b2648df1e9b1"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["9856095f7afb5a607bf5e65077615ed91273508c","44b289ba5434fa10782118c697fa706d6cf231df","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}