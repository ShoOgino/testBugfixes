{"path":"lucene/contrib/wikipedia/src/test/org/apache/lucene/wikipedia/analysis/WikipediaTokenizerTest#testHandwritten().mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/wikipedia/src/test/org/apache/lucene/wikipedia/analysis/WikipediaTokenizerTest#testHandwritten().mjava","pathOld":"contrib/wikipedia/src/test/org/apache/lucene/wikipedia/analysis/WikipediaTokenizerTest#testHandwritten().mjava","sourceNew":"  public void testHandwritten() throws Exception {\n    //make sure all tokens are in only one type\n    String test = \"[[link]] This is a [[Category:foo]] Category  This is a linked [[:Category:bar none withstanding]] \" +\n            \"Category This is (parens) This is a [[link]]  This is an external URL [http://lucene.apache.org] \" +\n            \"Here is ''italics'' and ''more italics'', '''bold''' and '''''five quotes''''' \" +\n            \" This is a [[link|display info]]  This is a period.  Here is $3.25 and here is 3.50.  Here's Johnny.  \" +\n            \"==heading== ===sub head=== followed by some text  [[Category:blah| ]] \" +\n            \"''[[Category:ital_cat]]''  here is some that is ''italics [[Category:foo]] but is never closed.\" +\n            \"'''same [[Category:foo]] goes for this '''''and2 [[Category:foo]] and this\" +\n            \" [http://foo.boo.com/test/test/ Test Test] [http://foo.boo.com/test/test/test.html Test Test]\" +\n            \" [http://foo.boo.com/test/test/test.html?g=b&c=d Test Test] <ref>Citation</ref> <sup>martian</sup> <span class=\\\"glue\\\">code</span>\";\n    Map<String,String> tcm = new HashMap<String,String>();//map tokens to types\n    tcm.put(\"link\", WikipediaTokenizer.INTERNAL_LINK);\n    tcm.put(\"display\", WikipediaTokenizer.INTERNAL_LINK);\n    tcm.put(\"info\", WikipediaTokenizer.INTERNAL_LINK);\n\n    tcm.put(\"http://lucene.apache.org\", WikipediaTokenizer.EXTERNAL_LINK_URL);\n    tcm.put(\"http://foo.boo.com/test/test/\", WikipediaTokenizer.EXTERNAL_LINK_URL);\n    tcm.put(\"http://foo.boo.com/test/test/test.html\", WikipediaTokenizer.EXTERNAL_LINK_URL);\n    tcm.put(\"http://foo.boo.com/test/test/test.html?g=b&c=d\", WikipediaTokenizer.EXTERNAL_LINK_URL);\n    tcm.put(\"Test\", WikipediaTokenizer.EXTERNAL_LINK);\n    \n    //alphanums\n    tcm.put(\"This\", \"<ALPHANUM>\");\n    tcm.put(\"is\", \"<ALPHANUM>\");\n    tcm.put(\"a\", \"<ALPHANUM>\");\n    tcm.put(\"Category\", \"<ALPHANUM>\");\n    tcm.put(\"linked\", \"<ALPHANUM>\");\n    tcm.put(\"parens\", \"<ALPHANUM>\");\n    tcm.put(\"external\", \"<ALPHANUM>\");\n    tcm.put(\"URL\", \"<ALPHANUM>\");\n    tcm.put(\"and\", \"<ALPHANUM>\");\n    tcm.put(\"period\", \"<ALPHANUM>\");\n    tcm.put(\"Here\", \"<ALPHANUM>\");\n    tcm.put(\"Here's\", \"<APOSTROPHE>\");\n    tcm.put(\"here\", \"<ALPHANUM>\");\n    tcm.put(\"Johnny\", \"<ALPHANUM>\");\n    tcm.put(\"followed\", \"<ALPHANUM>\");\n    tcm.put(\"by\", \"<ALPHANUM>\");\n    tcm.put(\"text\", \"<ALPHANUM>\");\n    tcm.put(\"that\", \"<ALPHANUM>\");\n    tcm.put(\"but\", \"<ALPHANUM>\");\n    tcm.put(\"never\", \"<ALPHANUM>\");\n    tcm.put(\"closed\", \"<ALPHANUM>\");\n    tcm.put(\"goes\", \"<ALPHANUM>\");\n    tcm.put(\"for\", \"<ALPHANUM>\");\n    tcm.put(\"this\", \"<ALPHANUM>\");\n    tcm.put(\"an\", \"<ALPHANUM>\");\n    tcm.put(\"some\", \"<ALPHANUM>\");\n    tcm.put(\"martian\", \"<ALPHANUM>\");\n    tcm.put(\"code\", \"<ALPHANUM>\");\n\n    tcm.put(\"foo\", WikipediaTokenizer.CATEGORY);\n    tcm.put(\"bar\", WikipediaTokenizer.CATEGORY);\n    tcm.put(\"none\", WikipediaTokenizer.CATEGORY);\n    tcm.put(\"withstanding\", WikipediaTokenizer.CATEGORY);\n    tcm.put(\"blah\", WikipediaTokenizer.CATEGORY);\n    tcm.put(\"ital\", WikipediaTokenizer.CATEGORY);\n    tcm.put(\"cat\", WikipediaTokenizer.CATEGORY);\n\n    tcm.put(\"italics\", WikipediaTokenizer.ITALICS);\n    tcm.put(\"more\", WikipediaTokenizer.ITALICS);\n    tcm.put(\"bold\", WikipediaTokenizer.BOLD);\n    tcm.put(\"same\", WikipediaTokenizer.BOLD);\n    tcm.put(\"five\", WikipediaTokenizer.BOLD_ITALICS);\n    tcm.put(\"and2\", WikipediaTokenizer.BOLD_ITALICS);\n    tcm.put(\"quotes\", WikipediaTokenizer.BOLD_ITALICS);\n\n    tcm.put(\"heading\", WikipediaTokenizer.HEADING);\n    tcm.put(\"sub\", WikipediaTokenizer.SUB_HEADING);\n    tcm.put(\"head\", WikipediaTokenizer.SUB_HEADING);\n    \n    tcm.put(\"Citation\", WikipediaTokenizer.CITATION);\n\n    tcm.put(\"3.25\", \"<NUM>\");\n    tcm.put(\"3.50\", \"<NUM>\");\n    WikipediaTokenizer tf = new WikipediaTokenizer(new StringReader(test));\n    int count = 0;\n    int numItalics = 0;\n    int numBoldItalics = 0;\n    int numCategory = 0;\n    int numCitation = 0;\n    TermAttribute termAtt = tf.addAttribute(TermAttribute.class);\n    TypeAttribute typeAtt = tf.addAttribute(TypeAttribute.class);\n    \n    while (tf.incrementToken()) {\n      String tokText = termAtt.term();\n      //System.out.println(\"Text: \" + tokText + \" Type: \" + token.type());\n      String expectedType = tcm.get(tokText);\n      assertTrue(\"expectedType is null and it shouldn't be for: \" + tf.toString(), expectedType != null);\n      assertTrue(typeAtt.type() + \" is not equal to \" + expectedType + \" for \" + tf.toString(), typeAtt.type().equals(expectedType) == true);\n      count++;\n      if (typeAtt.type().equals(WikipediaTokenizer.ITALICS)  == true){\n        numItalics++;\n      } else if (typeAtt.type().equals(WikipediaTokenizer.BOLD_ITALICS)  == true){\n        numBoldItalics++;\n      } else if (typeAtt.type().equals(WikipediaTokenizer.CATEGORY)  == true){\n        numCategory++;\n      }\n      else if (typeAtt.type().equals(WikipediaTokenizer.CITATION)  == true){\n        numCitation++;\n      }\n    }\n    assertTrue(\"We have not seen enough tokens: \" + count + \" is not >= \" + tcm.size(), count >= tcm.size());\n    assertTrue(numItalics + \" does not equal: \" + 4 + \" for numItalics\", numItalics == 4);\n    assertTrue(numBoldItalics + \" does not equal: \" + 3 + \" for numBoldItalics\", numBoldItalics == 3);\n    assertTrue(numCategory + \" does not equal: \" + 10 + \" for numCategory\", numCategory == 10);\n    assertTrue(numCitation + \" does not equal: \" + 1 + \" for numCitation\", numCitation == 1);\n  }\n\n","sourceOld":"  public void testHandwritten() throws Exception {\n    //make sure all tokens are in only one type\n    String test = \"[[link]] This is a [[Category:foo]] Category  This is a linked [[:Category:bar none withstanding]] \" +\n            \"Category This is (parens) This is a [[link]]  This is an external URL [http://lucene.apache.org] \" +\n            \"Here is ''italics'' and ''more italics'', '''bold''' and '''''five quotes''''' \" +\n            \" This is a [[link|display info]]  This is a period.  Here is $3.25 and here is 3.50.  Here's Johnny.  \" +\n            \"==heading== ===sub head=== followed by some text  [[Category:blah| ]] \" +\n            \"''[[Category:ital_cat]]''  here is some that is ''italics [[Category:foo]] but is never closed.\" +\n            \"'''same [[Category:foo]] goes for this '''''and2 [[Category:foo]] and this\" +\n            \" [http://foo.boo.com/test/test/ Test Test] [http://foo.boo.com/test/test/test.html Test Test]\" +\n            \" [http://foo.boo.com/test/test/test.html?g=b&c=d Test Test] <ref>Citation</ref> <sup>martian</sup> <span class=\\\"glue\\\">code</span>\";\n    Map<String,String> tcm = new HashMap<String,String>();//map tokens to types\n    tcm.put(\"link\", WikipediaTokenizer.INTERNAL_LINK);\n    tcm.put(\"display\", WikipediaTokenizer.INTERNAL_LINK);\n    tcm.put(\"info\", WikipediaTokenizer.INTERNAL_LINK);\n\n    tcm.put(\"http://lucene.apache.org\", WikipediaTokenizer.EXTERNAL_LINK_URL);\n    tcm.put(\"http://foo.boo.com/test/test/\", WikipediaTokenizer.EXTERNAL_LINK_URL);\n    tcm.put(\"http://foo.boo.com/test/test/test.html\", WikipediaTokenizer.EXTERNAL_LINK_URL);\n    tcm.put(\"http://foo.boo.com/test/test/test.html?g=b&c=d\", WikipediaTokenizer.EXTERNAL_LINK_URL);\n    tcm.put(\"Test\", WikipediaTokenizer.EXTERNAL_LINK);\n    \n    //alphanums\n    tcm.put(\"This\", \"<ALPHANUM>\");\n    tcm.put(\"is\", \"<ALPHANUM>\");\n    tcm.put(\"a\", \"<ALPHANUM>\");\n    tcm.put(\"Category\", \"<ALPHANUM>\");\n    tcm.put(\"linked\", \"<ALPHANUM>\");\n    tcm.put(\"parens\", \"<ALPHANUM>\");\n    tcm.put(\"external\", \"<ALPHANUM>\");\n    tcm.put(\"URL\", \"<ALPHANUM>\");\n    tcm.put(\"and\", \"<ALPHANUM>\");\n    tcm.put(\"period\", \"<ALPHANUM>\");\n    tcm.put(\"Here\", \"<ALPHANUM>\");\n    tcm.put(\"Here's\", \"<APOSTROPHE>\");\n    tcm.put(\"here\", \"<ALPHANUM>\");\n    tcm.put(\"Johnny\", \"<ALPHANUM>\");\n    tcm.put(\"followed\", \"<ALPHANUM>\");\n    tcm.put(\"by\", \"<ALPHANUM>\");\n    tcm.put(\"text\", \"<ALPHANUM>\");\n    tcm.put(\"that\", \"<ALPHANUM>\");\n    tcm.put(\"but\", \"<ALPHANUM>\");\n    tcm.put(\"never\", \"<ALPHANUM>\");\n    tcm.put(\"closed\", \"<ALPHANUM>\");\n    tcm.put(\"goes\", \"<ALPHANUM>\");\n    tcm.put(\"for\", \"<ALPHANUM>\");\n    tcm.put(\"this\", \"<ALPHANUM>\");\n    tcm.put(\"an\", \"<ALPHANUM>\");\n    tcm.put(\"some\", \"<ALPHANUM>\");\n    tcm.put(\"martian\", \"<ALPHANUM>\");\n    tcm.put(\"code\", \"<ALPHANUM>\");\n\n    tcm.put(\"foo\", WikipediaTokenizer.CATEGORY);\n    tcm.put(\"bar\", WikipediaTokenizer.CATEGORY);\n    tcm.put(\"none\", WikipediaTokenizer.CATEGORY);\n    tcm.put(\"withstanding\", WikipediaTokenizer.CATEGORY);\n    tcm.put(\"blah\", WikipediaTokenizer.CATEGORY);\n    tcm.put(\"ital\", WikipediaTokenizer.CATEGORY);\n    tcm.put(\"cat\", WikipediaTokenizer.CATEGORY);\n\n    tcm.put(\"italics\", WikipediaTokenizer.ITALICS);\n    tcm.put(\"more\", WikipediaTokenizer.ITALICS);\n    tcm.put(\"bold\", WikipediaTokenizer.BOLD);\n    tcm.put(\"same\", WikipediaTokenizer.BOLD);\n    tcm.put(\"five\", WikipediaTokenizer.BOLD_ITALICS);\n    tcm.put(\"and2\", WikipediaTokenizer.BOLD_ITALICS);\n    tcm.put(\"quotes\", WikipediaTokenizer.BOLD_ITALICS);\n\n    tcm.put(\"heading\", WikipediaTokenizer.HEADING);\n    tcm.put(\"sub\", WikipediaTokenizer.SUB_HEADING);\n    tcm.put(\"head\", WikipediaTokenizer.SUB_HEADING);\n    \n    tcm.put(\"Citation\", WikipediaTokenizer.CITATION);\n\n    tcm.put(\"3.25\", \"<NUM>\");\n    tcm.put(\"3.50\", \"<NUM>\");\n    WikipediaTokenizer tf = new WikipediaTokenizer(new StringReader(test));\n    int count = 0;\n    int numItalics = 0;\n    int numBoldItalics = 0;\n    int numCategory = 0;\n    int numCitation = 0;\n    TermAttribute termAtt = tf.addAttribute(TermAttribute.class);\n    TypeAttribute typeAtt = tf.addAttribute(TypeAttribute.class);\n    \n    while (tf.incrementToken()) {\n      String tokText = termAtt.term();\n      //System.out.println(\"Text: \" + tokText + \" Type: \" + token.type());\n      String expectedType = tcm.get(tokText);\n      assertTrue(\"expectedType is null and it shouldn't be for: \" + tf.toString(), expectedType != null);\n      assertTrue(typeAtt.type() + \" is not equal to \" + expectedType + \" for \" + tf.toString(), typeAtt.type().equals(expectedType) == true);\n      count++;\n      if (typeAtt.type().equals(WikipediaTokenizer.ITALICS)  == true){\n        numItalics++;\n      } else if (typeAtt.type().equals(WikipediaTokenizer.BOLD_ITALICS)  == true){\n        numBoldItalics++;\n      } else if (typeAtt.type().equals(WikipediaTokenizer.CATEGORY)  == true){\n        numCategory++;\n      }\n      else if (typeAtt.type().equals(WikipediaTokenizer.CITATION)  == true){\n        numCitation++;\n      }\n    }\n    assertTrue(\"We have not seen enough tokens: \" + count + \" is not >= \" + tcm.size(), count >= tcm.size());\n    assertTrue(numItalics + \" does not equal: \" + 4 + \" for numItalics\", numItalics == 4);\n    assertTrue(numBoldItalics + \" does not equal: \" + 3 + \" for numBoldItalics\", numBoldItalics == 3);\n    assertTrue(numCategory + \" does not equal: \" + 10 + \" for numCategory\", numCategory == 10);\n    assertTrue(numCitation + \" does not equal: \" + 1 + \" for numCitation\", numCitation == 1);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"344d7fb38511184be27e3eba27408ad5f634b91c","date":1270838455,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/wikipedia/WikipediaTokenizerTest#testHandwritten().mjava","pathOld":"lucene/contrib/wikipedia/src/test/org/apache/lucene/wikipedia/analysis/WikipediaTokenizerTest#testHandwritten().mjava","sourceNew":"  public void testHandwritten() throws Exception {\n    //make sure all tokens are in only one type\n    String test = \"[[link]] This is a [[Category:foo]] Category  This is a linked [[:Category:bar none withstanding]] \" +\n            \"Category This is (parens) This is a [[link]]  This is an external URL [http://lucene.apache.org] \" +\n            \"Here is ''italics'' and ''more italics'', '''bold''' and '''''five quotes''''' \" +\n            \" This is a [[link|display info]]  This is a period.  Here is $3.25 and here is 3.50.  Here's Johnny.  \" +\n            \"==heading== ===sub head=== followed by some text  [[Category:blah| ]] \" +\n            \"''[[Category:ital_cat]]''  here is some that is ''italics [[Category:foo]] but is never closed.\" +\n            \"'''same [[Category:foo]] goes for this '''''and2 [[Category:foo]] and this\" +\n            \" [http://foo.boo.com/test/test/ Test Test] [http://foo.boo.com/test/test/test.html Test Test]\" +\n            \" [http://foo.boo.com/test/test/test.html?g=b&c=d Test Test] <ref>Citation</ref> <sup>martian</sup> <span class=\\\"glue\\\">code</span>\";\n    Map<String,String> tcm = new HashMap<String,String>();//map tokens to types\n    tcm.put(\"link\", WikipediaTokenizer.INTERNAL_LINK);\n    tcm.put(\"display\", WikipediaTokenizer.INTERNAL_LINK);\n    tcm.put(\"info\", WikipediaTokenizer.INTERNAL_LINK);\n\n    tcm.put(\"http://lucene.apache.org\", WikipediaTokenizer.EXTERNAL_LINK_URL);\n    tcm.put(\"http://foo.boo.com/test/test/\", WikipediaTokenizer.EXTERNAL_LINK_URL);\n    tcm.put(\"http://foo.boo.com/test/test/test.html\", WikipediaTokenizer.EXTERNAL_LINK_URL);\n    tcm.put(\"http://foo.boo.com/test/test/test.html?g=b&c=d\", WikipediaTokenizer.EXTERNAL_LINK_URL);\n    tcm.put(\"Test\", WikipediaTokenizer.EXTERNAL_LINK);\n    \n    //alphanums\n    tcm.put(\"This\", \"<ALPHANUM>\");\n    tcm.put(\"is\", \"<ALPHANUM>\");\n    tcm.put(\"a\", \"<ALPHANUM>\");\n    tcm.put(\"Category\", \"<ALPHANUM>\");\n    tcm.put(\"linked\", \"<ALPHANUM>\");\n    tcm.put(\"parens\", \"<ALPHANUM>\");\n    tcm.put(\"external\", \"<ALPHANUM>\");\n    tcm.put(\"URL\", \"<ALPHANUM>\");\n    tcm.put(\"and\", \"<ALPHANUM>\");\n    tcm.put(\"period\", \"<ALPHANUM>\");\n    tcm.put(\"Here\", \"<ALPHANUM>\");\n    tcm.put(\"Here's\", \"<APOSTROPHE>\");\n    tcm.put(\"here\", \"<ALPHANUM>\");\n    tcm.put(\"Johnny\", \"<ALPHANUM>\");\n    tcm.put(\"followed\", \"<ALPHANUM>\");\n    tcm.put(\"by\", \"<ALPHANUM>\");\n    tcm.put(\"text\", \"<ALPHANUM>\");\n    tcm.put(\"that\", \"<ALPHANUM>\");\n    tcm.put(\"but\", \"<ALPHANUM>\");\n    tcm.put(\"never\", \"<ALPHANUM>\");\n    tcm.put(\"closed\", \"<ALPHANUM>\");\n    tcm.put(\"goes\", \"<ALPHANUM>\");\n    tcm.put(\"for\", \"<ALPHANUM>\");\n    tcm.put(\"this\", \"<ALPHANUM>\");\n    tcm.put(\"an\", \"<ALPHANUM>\");\n    tcm.put(\"some\", \"<ALPHANUM>\");\n    tcm.put(\"martian\", \"<ALPHANUM>\");\n    tcm.put(\"code\", \"<ALPHANUM>\");\n\n    tcm.put(\"foo\", WikipediaTokenizer.CATEGORY);\n    tcm.put(\"bar\", WikipediaTokenizer.CATEGORY);\n    tcm.put(\"none\", WikipediaTokenizer.CATEGORY);\n    tcm.put(\"withstanding\", WikipediaTokenizer.CATEGORY);\n    tcm.put(\"blah\", WikipediaTokenizer.CATEGORY);\n    tcm.put(\"ital\", WikipediaTokenizer.CATEGORY);\n    tcm.put(\"cat\", WikipediaTokenizer.CATEGORY);\n\n    tcm.put(\"italics\", WikipediaTokenizer.ITALICS);\n    tcm.put(\"more\", WikipediaTokenizer.ITALICS);\n    tcm.put(\"bold\", WikipediaTokenizer.BOLD);\n    tcm.put(\"same\", WikipediaTokenizer.BOLD);\n    tcm.put(\"five\", WikipediaTokenizer.BOLD_ITALICS);\n    tcm.put(\"and2\", WikipediaTokenizer.BOLD_ITALICS);\n    tcm.put(\"quotes\", WikipediaTokenizer.BOLD_ITALICS);\n\n    tcm.put(\"heading\", WikipediaTokenizer.HEADING);\n    tcm.put(\"sub\", WikipediaTokenizer.SUB_HEADING);\n    tcm.put(\"head\", WikipediaTokenizer.SUB_HEADING);\n    \n    tcm.put(\"Citation\", WikipediaTokenizer.CITATION);\n\n    tcm.put(\"3.25\", \"<NUM>\");\n    tcm.put(\"3.50\", \"<NUM>\");\n    WikipediaTokenizer tf = new WikipediaTokenizer(new StringReader(test));\n    int count = 0;\n    int numItalics = 0;\n    int numBoldItalics = 0;\n    int numCategory = 0;\n    int numCitation = 0;\n    TermAttribute termAtt = tf.addAttribute(TermAttribute.class);\n    TypeAttribute typeAtt = tf.addAttribute(TypeAttribute.class);\n    \n    while (tf.incrementToken()) {\n      String tokText = termAtt.term();\n      //System.out.println(\"Text: \" + tokText + \" Type: \" + token.type());\n      String expectedType = tcm.get(tokText);\n      assertTrue(\"expectedType is null and it shouldn't be for: \" + tf.toString(), expectedType != null);\n      assertTrue(typeAtt.type() + \" is not equal to \" + expectedType + \" for \" + tf.toString(), typeAtt.type().equals(expectedType) == true);\n      count++;\n      if (typeAtt.type().equals(WikipediaTokenizer.ITALICS)  == true){\n        numItalics++;\n      } else if (typeAtt.type().equals(WikipediaTokenizer.BOLD_ITALICS)  == true){\n        numBoldItalics++;\n      } else if (typeAtt.type().equals(WikipediaTokenizer.CATEGORY)  == true){\n        numCategory++;\n      }\n      else if (typeAtt.type().equals(WikipediaTokenizer.CITATION)  == true){\n        numCitation++;\n      }\n    }\n    assertTrue(\"We have not seen enough tokens: \" + count + \" is not >= \" + tcm.size(), count >= tcm.size());\n    assertTrue(numItalics + \" does not equal: \" + 4 + \" for numItalics\", numItalics == 4);\n    assertTrue(numBoldItalics + \" does not equal: \" + 3 + \" for numBoldItalics\", numBoldItalics == 3);\n    assertTrue(numCategory + \" does not equal: \" + 10 + \" for numCategory\", numCategory == 10);\n    assertTrue(numCitation + \" does not equal: \" + 1 + \" for numCitation\", numCitation == 1);\n  }\n\n","sourceOld":"  public void testHandwritten() throws Exception {\n    //make sure all tokens are in only one type\n    String test = \"[[link]] This is a [[Category:foo]] Category  This is a linked [[:Category:bar none withstanding]] \" +\n            \"Category This is (parens) This is a [[link]]  This is an external URL [http://lucene.apache.org] \" +\n            \"Here is ''italics'' and ''more italics'', '''bold''' and '''''five quotes''''' \" +\n            \" This is a [[link|display info]]  This is a period.  Here is $3.25 and here is 3.50.  Here's Johnny.  \" +\n            \"==heading== ===sub head=== followed by some text  [[Category:blah| ]] \" +\n            \"''[[Category:ital_cat]]''  here is some that is ''italics [[Category:foo]] but is never closed.\" +\n            \"'''same [[Category:foo]] goes for this '''''and2 [[Category:foo]] and this\" +\n            \" [http://foo.boo.com/test/test/ Test Test] [http://foo.boo.com/test/test/test.html Test Test]\" +\n            \" [http://foo.boo.com/test/test/test.html?g=b&c=d Test Test] <ref>Citation</ref> <sup>martian</sup> <span class=\\\"glue\\\">code</span>\";\n    Map<String,String> tcm = new HashMap<String,String>();//map tokens to types\n    tcm.put(\"link\", WikipediaTokenizer.INTERNAL_LINK);\n    tcm.put(\"display\", WikipediaTokenizer.INTERNAL_LINK);\n    tcm.put(\"info\", WikipediaTokenizer.INTERNAL_LINK);\n\n    tcm.put(\"http://lucene.apache.org\", WikipediaTokenizer.EXTERNAL_LINK_URL);\n    tcm.put(\"http://foo.boo.com/test/test/\", WikipediaTokenizer.EXTERNAL_LINK_URL);\n    tcm.put(\"http://foo.boo.com/test/test/test.html\", WikipediaTokenizer.EXTERNAL_LINK_URL);\n    tcm.put(\"http://foo.boo.com/test/test/test.html?g=b&c=d\", WikipediaTokenizer.EXTERNAL_LINK_URL);\n    tcm.put(\"Test\", WikipediaTokenizer.EXTERNAL_LINK);\n    \n    //alphanums\n    tcm.put(\"This\", \"<ALPHANUM>\");\n    tcm.put(\"is\", \"<ALPHANUM>\");\n    tcm.put(\"a\", \"<ALPHANUM>\");\n    tcm.put(\"Category\", \"<ALPHANUM>\");\n    tcm.put(\"linked\", \"<ALPHANUM>\");\n    tcm.put(\"parens\", \"<ALPHANUM>\");\n    tcm.put(\"external\", \"<ALPHANUM>\");\n    tcm.put(\"URL\", \"<ALPHANUM>\");\n    tcm.put(\"and\", \"<ALPHANUM>\");\n    tcm.put(\"period\", \"<ALPHANUM>\");\n    tcm.put(\"Here\", \"<ALPHANUM>\");\n    tcm.put(\"Here's\", \"<APOSTROPHE>\");\n    tcm.put(\"here\", \"<ALPHANUM>\");\n    tcm.put(\"Johnny\", \"<ALPHANUM>\");\n    tcm.put(\"followed\", \"<ALPHANUM>\");\n    tcm.put(\"by\", \"<ALPHANUM>\");\n    tcm.put(\"text\", \"<ALPHANUM>\");\n    tcm.put(\"that\", \"<ALPHANUM>\");\n    tcm.put(\"but\", \"<ALPHANUM>\");\n    tcm.put(\"never\", \"<ALPHANUM>\");\n    tcm.put(\"closed\", \"<ALPHANUM>\");\n    tcm.put(\"goes\", \"<ALPHANUM>\");\n    tcm.put(\"for\", \"<ALPHANUM>\");\n    tcm.put(\"this\", \"<ALPHANUM>\");\n    tcm.put(\"an\", \"<ALPHANUM>\");\n    tcm.put(\"some\", \"<ALPHANUM>\");\n    tcm.put(\"martian\", \"<ALPHANUM>\");\n    tcm.put(\"code\", \"<ALPHANUM>\");\n\n    tcm.put(\"foo\", WikipediaTokenizer.CATEGORY);\n    tcm.put(\"bar\", WikipediaTokenizer.CATEGORY);\n    tcm.put(\"none\", WikipediaTokenizer.CATEGORY);\n    tcm.put(\"withstanding\", WikipediaTokenizer.CATEGORY);\n    tcm.put(\"blah\", WikipediaTokenizer.CATEGORY);\n    tcm.put(\"ital\", WikipediaTokenizer.CATEGORY);\n    tcm.put(\"cat\", WikipediaTokenizer.CATEGORY);\n\n    tcm.put(\"italics\", WikipediaTokenizer.ITALICS);\n    tcm.put(\"more\", WikipediaTokenizer.ITALICS);\n    tcm.put(\"bold\", WikipediaTokenizer.BOLD);\n    tcm.put(\"same\", WikipediaTokenizer.BOLD);\n    tcm.put(\"five\", WikipediaTokenizer.BOLD_ITALICS);\n    tcm.put(\"and2\", WikipediaTokenizer.BOLD_ITALICS);\n    tcm.put(\"quotes\", WikipediaTokenizer.BOLD_ITALICS);\n\n    tcm.put(\"heading\", WikipediaTokenizer.HEADING);\n    tcm.put(\"sub\", WikipediaTokenizer.SUB_HEADING);\n    tcm.put(\"head\", WikipediaTokenizer.SUB_HEADING);\n    \n    tcm.put(\"Citation\", WikipediaTokenizer.CITATION);\n\n    tcm.put(\"3.25\", \"<NUM>\");\n    tcm.put(\"3.50\", \"<NUM>\");\n    WikipediaTokenizer tf = new WikipediaTokenizer(new StringReader(test));\n    int count = 0;\n    int numItalics = 0;\n    int numBoldItalics = 0;\n    int numCategory = 0;\n    int numCitation = 0;\n    TermAttribute termAtt = tf.addAttribute(TermAttribute.class);\n    TypeAttribute typeAtt = tf.addAttribute(TypeAttribute.class);\n    \n    while (tf.incrementToken()) {\n      String tokText = termAtt.term();\n      //System.out.println(\"Text: \" + tokText + \" Type: \" + token.type());\n      String expectedType = tcm.get(tokText);\n      assertTrue(\"expectedType is null and it shouldn't be for: \" + tf.toString(), expectedType != null);\n      assertTrue(typeAtt.type() + \" is not equal to \" + expectedType + \" for \" + tf.toString(), typeAtt.type().equals(expectedType) == true);\n      count++;\n      if (typeAtt.type().equals(WikipediaTokenizer.ITALICS)  == true){\n        numItalics++;\n      } else if (typeAtt.type().equals(WikipediaTokenizer.BOLD_ITALICS)  == true){\n        numBoldItalics++;\n      } else if (typeAtt.type().equals(WikipediaTokenizer.CATEGORY)  == true){\n        numCategory++;\n      }\n      else if (typeAtt.type().equals(WikipediaTokenizer.CITATION)  == true){\n        numCitation++;\n      }\n    }\n    assertTrue(\"We have not seen enough tokens: \" + count + \" is not >= \" + tcm.size(), count >= tcm.size());\n    assertTrue(numItalics + \" does not equal: \" + 4 + \" for numItalics\", numItalics == 4);\n    assertTrue(numBoldItalics + \" does not equal: \" + 3 + \" for numBoldItalics\", numBoldItalics == 3);\n    assertTrue(numCategory + \" does not equal: \" + 10 + \" for numCategory\", numCategory == 10);\n    assertTrue(numCitation + \" does not equal: \" + 1 + \" for numCitation\", numCitation == 1);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"344d7fb38511184be27e3eba27408ad5f634b91c":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["344d7fb38511184be27e3eba27408ad5f634b91c"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"344d7fb38511184be27e3eba27408ad5f634b91c":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["344d7fb38511184be27e3eba27408ad5f634b91c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}