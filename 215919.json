{"path":"lucene/core/src/java/org/apache/lucene/search/MultiPhraseQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","commits":[{"id":"9fc47cb7b4346802411bb432f501ed0673d7119e","date":1512640179,"type":0,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/MultiPhraseQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    return new MultiPhraseWeight(searcher, scoreMode.needsScores(), boost);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"417142ff08fda9cf0b72d5133e63097a166c6458","date":1512729693,"type":0,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/search/MultiPhraseQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    return new MultiPhraseWeight(searcher, scoreMode.needsScores(), boost);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"33eef98c565ee21b199f04b92acd6e00b842bd1e","date":1514538360,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/MultiPhraseQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/MultiPhraseQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    return new MultiPhraseWeight(searcher, scoreMode, boost);\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    return new MultiPhraseWeight(searcher, scoreMode.needsScores(), boost);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3b11b9d5eaf9707760ca5151530830a825197023","date":1525941319,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/MultiPhraseQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/MultiPhraseQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    final Map<Term,TermStates> termStates = new HashMap<>();\n    return new PhraseWeight(this, field, searcher, scoreMode) {\n\n      @Override\n      protected Similarity.SimScorer getStats(IndexSearcher searcher) throws IOException {\n        final IndexReaderContext context = searcher.getTopReaderContext();\n\n        // compute idf\n        ArrayList<TermStatistics> allTermStats = new ArrayList<>();\n        for(final Term[] terms: termArrays) {\n          for (Term term: terms) {\n            TermStates ts = termStates.get(term);\n            if (ts == null) {\n              ts = TermStates.build(context, term, scoreMode.needsScores());\n              termStates.put(term, ts);\n            }\n            if (scoreMode.needsScores()) {\n              TermStatistics termStatistics = searcher.termStatistics(term, ts);\n              if (termStatistics != null) {\n                allTermStats.add(termStatistics);\n              }\n            }\n          }\n        }\n        if (allTermStats.isEmpty()) {\n          return null; // none of the terms were found, we won't use sim at all\n        } else {\n          return similarity.scorer(\n              boost,\n              searcher.collectionStatistics(field),\n              allTermStats.toArray(new TermStatistics[allTermStats.size()]));\n        }\n      }\n\n      @Override\n      protected PhraseMatcher getPhraseMatcher(LeafReaderContext context, boolean exposeOffsets) throws IOException {\n        assert termArrays.length != 0;\n        final LeafReader reader = context.reader();\n\n        PhraseQuery.PostingsAndFreq[] postingsFreqs = new PhraseQuery.PostingsAndFreq[termArrays.length];\n\n        final Terms fieldTerms = reader.terms(field);\n        if (fieldTerms == null) {\n          return null;\n        }\n\n        // TODO: move this check to createWeight to happen earlier to the user?\n        if (fieldTerms.hasPositions() == false) {\n          throw new IllegalStateException(\"field \\\"\" + field + \"\\\" was indexed without position data;\" +\n              \" cannot run MultiPhraseQuery (phrase=\" + getQuery() + \")\");\n        }\n\n        // Reuse single TermsEnum below:\n        final TermsEnum termsEnum = fieldTerms.iterator();\n        float totalMatchCost = 0;\n\n        for (int pos=0; pos<postingsFreqs.length; pos++) {\n          Term[] terms = termArrays[pos];\n          List<PostingsEnum> postings = new ArrayList<>();\n\n          for (Term term : terms) {\n            TermState termState = termStates.get(term).get(context);\n            if (termState != null) {\n              termsEnum.seekExact(term.bytes(), termState);\n              postings.add(termsEnum.postings(null, exposeOffsets ? PostingsEnum.OFFSETS : PostingsEnum.POSITIONS));\n              totalMatchCost += PhraseQuery.termPositionsCost(termsEnum);\n            }\n          }\n\n          if (postings.isEmpty()) {\n            return null;\n          }\n\n          final PostingsEnum postingsEnum;\n          if (postings.size() == 1) {\n            postingsEnum = postings.get(0);\n          } else {\n            postingsEnum = exposeOffsets ? new UnionFullPostingsEnum(postings) : new UnionPostingsEnum(postings);\n          }\n\n          postingsFreqs[pos] = new PhraseQuery.PostingsAndFreq(postingsEnum, positions[pos], terms);\n        }\n\n        // sort by increasing docFreq order\n        if (slop == 0) {\n          ArrayUtil.timSort(postingsFreqs);\n          return new ExactPhraseMatcher(postingsFreqs, totalMatchCost);\n        }\n        else {\n          return new SloppyPhraseMatcher(postingsFreqs, slop, totalMatchCost);\n        }\n\n      }\n\n      @Override\n      public void extractTerms(Set<Term> terms) {\n        for (final Term[] arr : termArrays) {\n          Collections.addAll(terms, arr);\n        }\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    return new MultiPhraseWeight(searcher, scoreMode, boost);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"165c3432cb3c4fcfc8e859af24323bbbd12084af","date":1532292166,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/MultiPhraseQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/MultiPhraseQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    final Map<Term,TermStates> termStates = new HashMap<>();\n    return new PhraseWeight(this, field, searcher, scoreMode) {\n\n      @Override\n      protected Similarity.SimScorer getStats(IndexSearcher searcher) throws IOException {\n        final IndexReaderContext context = searcher.getTopReaderContext();\n\n        // compute idf\n        ArrayList<TermStatistics> allTermStats = new ArrayList<>();\n        for(final Term[] terms: termArrays) {\n          for (Term term: terms) {\n            TermStates ts = termStates.get(term);\n            if (ts == null) {\n              ts = TermStates.build(context, term, scoreMode.needsScores());\n              termStates.put(term, ts);\n            }\n            if (scoreMode.needsScores()) {\n              TermStatistics termStatistics = searcher.termStatistics(term, ts);\n              if (termStatistics != null) {\n                allTermStats.add(termStatistics);\n              }\n            }\n          }\n        }\n        if (allTermStats.isEmpty()) {\n          return null; // none of the terms were found, we won't use sim at all\n        } else {\n          return similarity.scorer(\n              boost,\n              searcher.collectionStatistics(field),\n              allTermStats.toArray(new TermStatistics[allTermStats.size()]));\n        }\n      }\n\n      @Override\n      protected PhraseMatcher getPhraseMatcher(LeafReaderContext context, boolean exposeOffsets) throws IOException {\n        assert termArrays.length != 0;\n        final LeafReader reader = context.reader();\n\n        PhraseQuery.PostingsAndFreq[] postingsFreqs = new PhraseQuery.PostingsAndFreq[termArrays.length];\n\n        final Terms fieldTerms = reader.terms(field);\n        if (fieldTerms == null) {\n          return null;\n        }\n\n        // TODO: move this check to createWeight to happen earlier to the user?\n        if (fieldTerms.hasPositions() == false) {\n          throw new IllegalStateException(\"field \\\"\" + field + \"\\\" was indexed without position data;\" +\n              \" cannot run MultiPhraseQuery (phrase=\" + getQuery() + \")\");\n        }\n\n        // Reuse single TermsEnum below:\n        final TermsEnum termsEnum = fieldTerms.iterator();\n        float totalMatchCost = 0;\n\n        for (int pos=0; pos<postingsFreqs.length; pos++) {\n          Term[] terms = termArrays[pos];\n          List<PostingsEnum> postings = new ArrayList<>();\n\n          for (Term term : terms) {\n            TermState termState = termStates.get(term).get(context);\n            if (termState != null) {\n              termsEnum.seekExact(term.bytes(), termState);\n              postings.add(termsEnum.postings(null, exposeOffsets ? PostingsEnum.ALL : PostingsEnum.POSITIONS));\n              totalMatchCost += PhraseQuery.termPositionsCost(termsEnum);\n            }\n          }\n\n          if (postings.isEmpty()) {\n            return null;\n          }\n\n          final PostingsEnum postingsEnum;\n          if (postings.size() == 1) {\n            postingsEnum = postings.get(0);\n          } else {\n            postingsEnum = exposeOffsets ? new UnionFullPostingsEnum(postings) : new UnionPostingsEnum(postings);\n          }\n\n          postingsFreqs[pos] = new PhraseQuery.PostingsAndFreq(postingsEnum, positions[pos], terms);\n        }\n\n        // sort by increasing docFreq order\n        if (slop == 0) {\n          ArrayUtil.timSort(postingsFreqs);\n          return new ExactPhraseMatcher(postingsFreqs, totalMatchCost);\n        }\n        else {\n          return new SloppyPhraseMatcher(postingsFreqs, slop, totalMatchCost, exposeOffsets);\n        }\n\n      }\n\n      @Override\n      public void extractTerms(Set<Term> terms) {\n        for (final Term[] arr : termArrays) {\n          Collections.addAll(terms, arr);\n        }\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    final Map<Term,TermStates> termStates = new HashMap<>();\n    return new PhraseWeight(this, field, searcher, scoreMode) {\n\n      @Override\n      protected Similarity.SimScorer getStats(IndexSearcher searcher) throws IOException {\n        final IndexReaderContext context = searcher.getTopReaderContext();\n\n        // compute idf\n        ArrayList<TermStatistics> allTermStats = new ArrayList<>();\n        for(final Term[] terms: termArrays) {\n          for (Term term: terms) {\n            TermStates ts = termStates.get(term);\n            if (ts == null) {\n              ts = TermStates.build(context, term, scoreMode.needsScores());\n              termStates.put(term, ts);\n            }\n            if (scoreMode.needsScores()) {\n              TermStatistics termStatistics = searcher.termStatistics(term, ts);\n              if (termStatistics != null) {\n                allTermStats.add(termStatistics);\n              }\n            }\n          }\n        }\n        if (allTermStats.isEmpty()) {\n          return null; // none of the terms were found, we won't use sim at all\n        } else {\n          return similarity.scorer(\n              boost,\n              searcher.collectionStatistics(field),\n              allTermStats.toArray(new TermStatistics[allTermStats.size()]));\n        }\n      }\n\n      @Override\n      protected PhraseMatcher getPhraseMatcher(LeafReaderContext context, boolean exposeOffsets) throws IOException {\n        assert termArrays.length != 0;\n        final LeafReader reader = context.reader();\n\n        PhraseQuery.PostingsAndFreq[] postingsFreqs = new PhraseQuery.PostingsAndFreq[termArrays.length];\n\n        final Terms fieldTerms = reader.terms(field);\n        if (fieldTerms == null) {\n          return null;\n        }\n\n        // TODO: move this check to createWeight to happen earlier to the user?\n        if (fieldTerms.hasPositions() == false) {\n          throw new IllegalStateException(\"field \\\"\" + field + \"\\\" was indexed without position data;\" +\n              \" cannot run MultiPhraseQuery (phrase=\" + getQuery() + \")\");\n        }\n\n        // Reuse single TermsEnum below:\n        final TermsEnum termsEnum = fieldTerms.iterator();\n        float totalMatchCost = 0;\n\n        for (int pos=0; pos<postingsFreqs.length; pos++) {\n          Term[] terms = termArrays[pos];\n          List<PostingsEnum> postings = new ArrayList<>();\n\n          for (Term term : terms) {\n            TermState termState = termStates.get(term).get(context);\n            if (termState != null) {\n              termsEnum.seekExact(term.bytes(), termState);\n              postings.add(termsEnum.postings(null, exposeOffsets ? PostingsEnum.OFFSETS : PostingsEnum.POSITIONS));\n              totalMatchCost += PhraseQuery.termPositionsCost(termsEnum);\n            }\n          }\n\n          if (postings.isEmpty()) {\n            return null;\n          }\n\n          final PostingsEnum postingsEnum;\n          if (postings.size() == 1) {\n            postingsEnum = postings.get(0);\n          } else {\n            postingsEnum = exposeOffsets ? new UnionFullPostingsEnum(postings) : new UnionPostingsEnum(postings);\n          }\n\n          postingsFreqs[pos] = new PhraseQuery.PostingsAndFreq(postingsEnum, positions[pos], terms);\n        }\n\n        // sort by increasing docFreq order\n        if (slop == 0) {\n          ArrayUtil.timSort(postingsFreqs);\n          return new ExactPhraseMatcher(postingsFreqs, totalMatchCost);\n        }\n        else {\n          return new SloppyPhraseMatcher(postingsFreqs, slop, totalMatchCost);\n        }\n\n      }\n\n      @Override\n      public void extractTerms(Set<Term> terms) {\n        for (final Term[] arr : termArrays) {\n          Collections.addAll(terms, arr);\n        }\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"62ba8124694976baa3b03705351de238ec5d4352","date":1532295406,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/MultiPhraseQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/MultiPhraseQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    final Map<Term,TermStates> termStates = new HashMap<>();\n    return new PhraseWeight(this, field, searcher, scoreMode) {\n\n      @Override\n      protected Similarity.SimScorer getStats(IndexSearcher searcher) throws IOException {\n        final IndexReaderContext context = searcher.getTopReaderContext();\n\n        // compute idf\n        ArrayList<TermStatistics> allTermStats = new ArrayList<>();\n        for(final Term[] terms: termArrays) {\n          for (Term term: terms) {\n            TermStates ts = termStates.get(term);\n            if (ts == null) {\n              ts = TermStates.build(context, term, scoreMode.needsScores());\n              termStates.put(term, ts);\n            }\n            if (scoreMode.needsScores()) {\n              TermStatistics termStatistics = searcher.termStatistics(term, ts);\n              if (termStatistics != null) {\n                allTermStats.add(termStatistics);\n              }\n            }\n          }\n        }\n        if (allTermStats.isEmpty()) {\n          return null; // none of the terms were found, we won't use sim at all\n        } else {\n          return similarity.scorer(\n              boost,\n              searcher.collectionStatistics(field),\n              allTermStats.toArray(new TermStatistics[allTermStats.size()]));\n        }\n      }\n\n      @Override\n      protected PhraseMatcher getPhraseMatcher(LeafReaderContext context, boolean exposeOffsets) throws IOException {\n        assert termArrays.length != 0;\n        final LeafReader reader = context.reader();\n\n        PhraseQuery.PostingsAndFreq[] postingsFreqs = new PhraseQuery.PostingsAndFreq[termArrays.length];\n\n        final Terms fieldTerms = reader.terms(field);\n        if (fieldTerms == null) {\n          return null;\n        }\n\n        // TODO: move this check to createWeight to happen earlier to the user?\n        if (fieldTerms.hasPositions() == false) {\n          throw new IllegalStateException(\"field \\\"\" + field + \"\\\" was indexed without position data;\" +\n              \" cannot run MultiPhraseQuery (phrase=\" + getQuery() + \")\");\n        }\n\n        // Reuse single TermsEnum below:\n        final TermsEnum termsEnum = fieldTerms.iterator();\n        float totalMatchCost = 0;\n\n        for (int pos=0; pos<postingsFreqs.length; pos++) {\n          Term[] terms = termArrays[pos];\n          List<PostingsEnum> postings = new ArrayList<>();\n\n          for (Term term : terms) {\n            TermState termState = termStates.get(term).get(context);\n            if (termState != null) {\n              termsEnum.seekExact(term.bytes(), termState);\n              postings.add(termsEnum.postings(null, exposeOffsets ? PostingsEnum.OFFSETS : PostingsEnum.POSITIONS));\n              totalMatchCost += PhraseQuery.termPositionsCost(termsEnum);\n            }\n          }\n\n          if (postings.isEmpty()) {\n            return null;\n          }\n\n          final PostingsEnum postingsEnum;\n          if (postings.size() == 1) {\n            postingsEnum = postings.get(0);\n          } else {\n            postingsEnum = exposeOffsets ? new UnionFullPostingsEnum(postings) : new UnionPostingsEnum(postings);\n          }\n\n          postingsFreqs[pos] = new PhraseQuery.PostingsAndFreq(postingsEnum, positions[pos], terms);\n        }\n\n        // sort by increasing docFreq order\n        if (slop == 0) {\n          ArrayUtil.timSort(postingsFreqs);\n          return new ExactPhraseMatcher(postingsFreqs, totalMatchCost);\n        }\n        else {\n          return new SloppyPhraseMatcher(postingsFreqs, slop, totalMatchCost);\n        }\n\n      }\n\n      @Override\n      public void extractTerms(Set<Term> terms) {\n        for (final Term[] arr : termArrays) {\n          Collections.addAll(terms, arr);\n        }\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    final Map<Term,TermStates> termStates = new HashMap<>();\n    return new PhraseWeight(this, field, searcher, scoreMode) {\n\n      @Override\n      protected Similarity.SimScorer getStats(IndexSearcher searcher) throws IOException {\n        final IndexReaderContext context = searcher.getTopReaderContext();\n\n        // compute idf\n        ArrayList<TermStatistics> allTermStats = new ArrayList<>();\n        for(final Term[] terms: termArrays) {\n          for (Term term: terms) {\n            TermStates ts = termStates.get(term);\n            if (ts == null) {\n              ts = TermStates.build(context, term, scoreMode.needsScores());\n              termStates.put(term, ts);\n            }\n            if (scoreMode.needsScores()) {\n              TermStatistics termStatistics = searcher.termStatistics(term, ts);\n              if (termStatistics != null) {\n                allTermStats.add(termStatistics);\n              }\n            }\n          }\n        }\n        if (allTermStats.isEmpty()) {\n          return null; // none of the terms were found, we won't use sim at all\n        } else {\n          return similarity.scorer(\n              boost,\n              searcher.collectionStatistics(field),\n              allTermStats.toArray(new TermStatistics[allTermStats.size()]));\n        }\n      }\n\n      @Override\n      protected PhraseMatcher getPhraseMatcher(LeafReaderContext context, boolean exposeOffsets) throws IOException {\n        assert termArrays.length != 0;\n        final LeafReader reader = context.reader();\n\n        PhraseQuery.PostingsAndFreq[] postingsFreqs = new PhraseQuery.PostingsAndFreq[termArrays.length];\n\n        final Terms fieldTerms = reader.terms(field);\n        if (fieldTerms == null) {\n          return null;\n        }\n\n        // TODO: move this check to createWeight to happen earlier to the user?\n        if (fieldTerms.hasPositions() == false) {\n          throw new IllegalStateException(\"field \\\"\" + field + \"\\\" was indexed without position data;\" +\n              \" cannot run MultiPhraseQuery (phrase=\" + getQuery() + \")\");\n        }\n\n        // Reuse single TermsEnum below:\n        final TermsEnum termsEnum = fieldTerms.iterator();\n        float totalMatchCost = 0;\n\n        for (int pos=0; pos<postingsFreqs.length; pos++) {\n          Term[] terms = termArrays[pos];\n          List<PostingsEnum> postings = new ArrayList<>();\n\n          for (Term term : terms) {\n            TermState termState = termStates.get(term).get(context);\n            if (termState != null) {\n              termsEnum.seekExact(term.bytes(), termState);\n              postings.add(termsEnum.postings(null, exposeOffsets ? PostingsEnum.ALL : PostingsEnum.POSITIONS));\n              totalMatchCost += PhraseQuery.termPositionsCost(termsEnum);\n            }\n          }\n\n          if (postings.isEmpty()) {\n            return null;\n          }\n\n          final PostingsEnum postingsEnum;\n          if (postings.size() == 1) {\n            postingsEnum = postings.get(0);\n          } else {\n            postingsEnum = exposeOffsets ? new UnionFullPostingsEnum(postings) : new UnionPostingsEnum(postings);\n          }\n\n          postingsFreqs[pos] = new PhraseQuery.PostingsAndFreq(postingsEnum, positions[pos], terms);\n        }\n\n        // sort by increasing docFreq order\n        if (slop == 0) {\n          ArrayUtil.timSort(postingsFreqs);\n          return new ExactPhraseMatcher(postingsFreqs, totalMatchCost);\n        }\n        else {\n          return new SloppyPhraseMatcher(postingsFreqs, slop, totalMatchCost, exposeOffsets);\n        }\n\n      }\n\n      @Override\n      public void extractTerms(Set<Term> terms) {\n        for (final Term[] arr : termArrays) {\n          Collections.addAll(terms, arr);\n        }\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"41ebc07bccf12a902ca6a0077910d18ee38b695f","date":1532336521,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/MultiPhraseQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/MultiPhraseQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    final Map<Term,TermStates> termStates = new HashMap<>();\n    return new PhraseWeight(this, field, searcher, scoreMode) {\n\n      @Override\n      protected Similarity.SimScorer getStats(IndexSearcher searcher) throws IOException {\n        final IndexReaderContext context = searcher.getTopReaderContext();\n\n        // compute idf\n        ArrayList<TermStatistics> allTermStats = new ArrayList<>();\n        for(final Term[] terms: termArrays) {\n          for (Term term: terms) {\n            TermStates ts = termStates.get(term);\n            if (ts == null) {\n              ts = TermStates.build(context, term, scoreMode.needsScores());\n              termStates.put(term, ts);\n            }\n            if (scoreMode.needsScores()) {\n              TermStatistics termStatistics = searcher.termStatistics(term, ts);\n              if (termStatistics != null) {\n                allTermStats.add(termStatistics);\n              }\n            }\n          }\n        }\n        if (allTermStats.isEmpty()) {\n          return null; // none of the terms were found, we won't use sim at all\n        } else {\n          return similarity.scorer(\n              boost,\n              searcher.collectionStatistics(field),\n              allTermStats.toArray(new TermStatistics[allTermStats.size()]));\n        }\n      }\n\n      @Override\n      protected PhraseMatcher getPhraseMatcher(LeafReaderContext context, boolean exposeOffsets) throws IOException {\n        assert termArrays.length != 0;\n        final LeafReader reader = context.reader();\n\n        PhraseQuery.PostingsAndFreq[] postingsFreqs = new PhraseQuery.PostingsAndFreq[termArrays.length];\n\n        final Terms fieldTerms = reader.terms(field);\n        if (fieldTerms == null) {\n          return null;\n        }\n\n        // TODO: move this check to createWeight to happen earlier to the user?\n        if (fieldTerms.hasPositions() == false) {\n          throw new IllegalStateException(\"field \\\"\" + field + \"\\\" was indexed without position data;\" +\n              \" cannot run MultiPhraseQuery (phrase=\" + getQuery() + \")\");\n        }\n\n        // Reuse single TermsEnum below:\n        final TermsEnum termsEnum = fieldTerms.iterator();\n        float totalMatchCost = 0;\n\n        for (int pos=0; pos<postingsFreqs.length; pos++) {\n          Term[] terms = termArrays[pos];\n          List<PostingsEnum> postings = new ArrayList<>();\n\n          for (Term term : terms) {\n            TermState termState = termStates.get(term).get(context);\n            if (termState != null) {\n              termsEnum.seekExact(term.bytes(), termState);\n              postings.add(termsEnum.postings(null, exposeOffsets ? PostingsEnum.ALL : PostingsEnum.POSITIONS));\n              totalMatchCost += PhraseQuery.termPositionsCost(termsEnum);\n            }\n          }\n\n          if (postings.isEmpty()) {\n            return null;\n          }\n\n          final PostingsEnum postingsEnum;\n          if (postings.size() == 1) {\n            postingsEnum = postings.get(0);\n          } else {\n            postingsEnum = exposeOffsets ? new UnionFullPostingsEnum(postings) : new UnionPostingsEnum(postings);\n          }\n\n          postingsFreqs[pos] = new PhraseQuery.PostingsAndFreq(postingsEnum, positions[pos], terms);\n        }\n\n        // sort by increasing docFreq order\n        if (slop == 0) {\n          ArrayUtil.timSort(postingsFreqs);\n          return new ExactPhraseMatcher(postingsFreqs, totalMatchCost);\n        }\n        else {\n          return new SloppyPhraseMatcher(postingsFreqs, slop, totalMatchCost, exposeOffsets);\n        }\n\n      }\n\n      @Override\n      public void extractTerms(Set<Term> terms) {\n        for (final Term[] arr : termArrays) {\n          Collections.addAll(terms, arr);\n        }\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    final Map<Term,TermStates> termStates = new HashMap<>();\n    return new PhraseWeight(this, field, searcher, scoreMode) {\n\n      @Override\n      protected Similarity.SimScorer getStats(IndexSearcher searcher) throws IOException {\n        final IndexReaderContext context = searcher.getTopReaderContext();\n\n        // compute idf\n        ArrayList<TermStatistics> allTermStats = new ArrayList<>();\n        for(final Term[] terms: termArrays) {\n          for (Term term: terms) {\n            TermStates ts = termStates.get(term);\n            if (ts == null) {\n              ts = TermStates.build(context, term, scoreMode.needsScores());\n              termStates.put(term, ts);\n            }\n            if (scoreMode.needsScores()) {\n              TermStatistics termStatistics = searcher.termStatistics(term, ts);\n              if (termStatistics != null) {\n                allTermStats.add(termStatistics);\n              }\n            }\n          }\n        }\n        if (allTermStats.isEmpty()) {\n          return null; // none of the terms were found, we won't use sim at all\n        } else {\n          return similarity.scorer(\n              boost,\n              searcher.collectionStatistics(field),\n              allTermStats.toArray(new TermStatistics[allTermStats.size()]));\n        }\n      }\n\n      @Override\n      protected PhraseMatcher getPhraseMatcher(LeafReaderContext context, boolean exposeOffsets) throws IOException {\n        assert termArrays.length != 0;\n        final LeafReader reader = context.reader();\n\n        PhraseQuery.PostingsAndFreq[] postingsFreqs = new PhraseQuery.PostingsAndFreq[termArrays.length];\n\n        final Terms fieldTerms = reader.terms(field);\n        if (fieldTerms == null) {\n          return null;\n        }\n\n        // TODO: move this check to createWeight to happen earlier to the user?\n        if (fieldTerms.hasPositions() == false) {\n          throw new IllegalStateException(\"field \\\"\" + field + \"\\\" was indexed without position data;\" +\n              \" cannot run MultiPhraseQuery (phrase=\" + getQuery() + \")\");\n        }\n\n        // Reuse single TermsEnum below:\n        final TermsEnum termsEnum = fieldTerms.iterator();\n        float totalMatchCost = 0;\n\n        for (int pos=0; pos<postingsFreqs.length; pos++) {\n          Term[] terms = termArrays[pos];\n          List<PostingsEnum> postings = new ArrayList<>();\n\n          for (Term term : terms) {\n            TermState termState = termStates.get(term).get(context);\n            if (termState != null) {\n              termsEnum.seekExact(term.bytes(), termState);\n              postings.add(termsEnum.postings(null, exposeOffsets ? PostingsEnum.OFFSETS : PostingsEnum.POSITIONS));\n              totalMatchCost += PhraseQuery.termPositionsCost(termsEnum);\n            }\n          }\n\n          if (postings.isEmpty()) {\n            return null;\n          }\n\n          final PostingsEnum postingsEnum;\n          if (postings.size() == 1) {\n            postingsEnum = postings.get(0);\n          } else {\n            postingsEnum = exposeOffsets ? new UnionFullPostingsEnum(postings) : new UnionPostingsEnum(postings);\n          }\n\n          postingsFreqs[pos] = new PhraseQuery.PostingsAndFreq(postingsEnum, positions[pos], terms);\n        }\n\n        // sort by increasing docFreq order\n        if (slop == 0) {\n          ArrayUtil.timSort(postingsFreqs);\n          return new ExactPhraseMatcher(postingsFreqs, totalMatchCost);\n        }\n        else {\n          return new SloppyPhraseMatcher(postingsFreqs, slop, totalMatchCost);\n        }\n\n      }\n\n      @Override\n      public void extractTerms(Set<Term> terms) {\n        for (final Term[] arr : termArrays) {\n          Collections.addAll(terms, arr);\n        }\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5b9ffb60dc4bdc972b1403ad2ab2f5b4d9ce4cf7","date":1552575873,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/MultiPhraseQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/MultiPhraseQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    final Map<Term,TermStates> termStates = new HashMap<>();\n    return new PhraseWeight(this, field, searcher, scoreMode) {\n\n      @Override\n      protected Similarity.SimScorer getStats(IndexSearcher searcher) throws IOException {\n        final IndexReaderContext context = searcher.getTopReaderContext();\n\n        // compute idf\n        ArrayList<TermStatistics> allTermStats = new ArrayList<>();\n        for(final Term[] terms: termArrays) {\n          for (Term term: terms) {\n            TermStates ts = termStates.get(term);\n            if (ts == null) {\n              ts = TermStates.build(context, term, scoreMode.needsScores());\n              termStates.put(term, ts);\n            }\n            if (scoreMode.needsScores()) {\n              TermStatistics termStatistics = searcher.termStatistics(term, ts);\n              if (termStatistics != null) {\n                allTermStats.add(termStatistics);\n              }\n            }\n          }\n        }\n        if (allTermStats.isEmpty()) {\n          return null; // none of the terms were found, we won't use sim at all\n        } else {\n          return similarity.scorer(\n              boost,\n              searcher.collectionStatistics(field),\n              allTermStats.toArray(new TermStatistics[allTermStats.size()]));\n        }\n      }\n\n      @Override\n      protected PhraseMatcher getPhraseMatcher(LeafReaderContext context, boolean exposeOffsets) throws IOException {\n        assert termArrays.length != 0;\n        final LeafReader reader = context.reader();\n\n        PhraseQuery.PostingsAndFreq[] postingsFreqs = new PhraseQuery.PostingsAndFreq[termArrays.length];\n\n        final Terms fieldTerms = reader.terms(field);\n        if (fieldTerms == null) {\n          return null;\n        }\n\n        // TODO: move this check to createWeight to happen earlier to the user?\n        if (fieldTerms.hasPositions() == false) {\n          throw new IllegalStateException(\"field \\\"\" + field + \"\\\" was indexed without position data;\" +\n              \" cannot run MultiPhraseQuery (phrase=\" + getQuery() + \")\");\n        }\n\n        // Reuse single TermsEnum below:\n        final TermsEnum termsEnum = fieldTerms.iterator();\n        float totalMatchCost = 0;\n\n        for (int pos=0; pos<postingsFreqs.length; pos++) {\n          Term[] terms = termArrays[pos];\n          List<PostingsEnum> postings = new ArrayList<>();\n\n          for (Term term : terms) {\n            TermState termState = termStates.get(term).get(context);\n            if (termState != null) {\n              termsEnum.seekExact(term.bytes(), termState);\n              postings.add(termsEnum.postings(null, exposeOffsets ? PostingsEnum.ALL : PostingsEnum.POSITIONS));\n              totalMatchCost += PhraseQuery.termPositionsCost(termsEnum);\n            }\n          }\n\n          if (postings.isEmpty()) {\n            return null;\n          }\n\n          final PostingsEnum postingsEnum;\n          if (postings.size() == 1) {\n            postingsEnum = postings.get(0);\n          } else {\n            postingsEnum = exposeOffsets ? new UnionFullPostingsEnum(postings) : new UnionPostingsEnum(postings);\n          }\n\n          postingsFreqs[pos] = new PhraseQuery.PostingsAndFreq(postingsEnum, positions[pos], terms);\n        }\n\n        // sort by increasing docFreq order\n        if (slop == 0) {\n          ArrayUtil.timSort(postingsFreqs);\n          return new ExactPhraseMatcher(postingsFreqs, totalMatchCost);\n        }\n        else {\n          return new SloppyPhraseMatcher(postingsFreqs, slop, totalMatchCost, exposeOffsets);\n        }\n\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    final Map<Term,TermStates> termStates = new HashMap<>();\n    return new PhraseWeight(this, field, searcher, scoreMode) {\n\n      @Override\n      protected Similarity.SimScorer getStats(IndexSearcher searcher) throws IOException {\n        final IndexReaderContext context = searcher.getTopReaderContext();\n\n        // compute idf\n        ArrayList<TermStatistics> allTermStats = new ArrayList<>();\n        for(final Term[] terms: termArrays) {\n          for (Term term: terms) {\n            TermStates ts = termStates.get(term);\n            if (ts == null) {\n              ts = TermStates.build(context, term, scoreMode.needsScores());\n              termStates.put(term, ts);\n            }\n            if (scoreMode.needsScores()) {\n              TermStatistics termStatistics = searcher.termStatistics(term, ts);\n              if (termStatistics != null) {\n                allTermStats.add(termStatistics);\n              }\n            }\n          }\n        }\n        if (allTermStats.isEmpty()) {\n          return null; // none of the terms were found, we won't use sim at all\n        } else {\n          return similarity.scorer(\n              boost,\n              searcher.collectionStatistics(field),\n              allTermStats.toArray(new TermStatistics[allTermStats.size()]));\n        }\n      }\n\n      @Override\n      protected PhraseMatcher getPhraseMatcher(LeafReaderContext context, boolean exposeOffsets) throws IOException {\n        assert termArrays.length != 0;\n        final LeafReader reader = context.reader();\n\n        PhraseQuery.PostingsAndFreq[] postingsFreqs = new PhraseQuery.PostingsAndFreq[termArrays.length];\n\n        final Terms fieldTerms = reader.terms(field);\n        if (fieldTerms == null) {\n          return null;\n        }\n\n        // TODO: move this check to createWeight to happen earlier to the user?\n        if (fieldTerms.hasPositions() == false) {\n          throw new IllegalStateException(\"field \\\"\" + field + \"\\\" was indexed without position data;\" +\n              \" cannot run MultiPhraseQuery (phrase=\" + getQuery() + \")\");\n        }\n\n        // Reuse single TermsEnum below:\n        final TermsEnum termsEnum = fieldTerms.iterator();\n        float totalMatchCost = 0;\n\n        for (int pos=0; pos<postingsFreqs.length; pos++) {\n          Term[] terms = termArrays[pos];\n          List<PostingsEnum> postings = new ArrayList<>();\n\n          for (Term term : terms) {\n            TermState termState = termStates.get(term).get(context);\n            if (termState != null) {\n              termsEnum.seekExact(term.bytes(), termState);\n              postings.add(termsEnum.postings(null, exposeOffsets ? PostingsEnum.ALL : PostingsEnum.POSITIONS));\n              totalMatchCost += PhraseQuery.termPositionsCost(termsEnum);\n            }\n          }\n\n          if (postings.isEmpty()) {\n            return null;\n          }\n\n          final PostingsEnum postingsEnum;\n          if (postings.size() == 1) {\n            postingsEnum = postings.get(0);\n          } else {\n            postingsEnum = exposeOffsets ? new UnionFullPostingsEnum(postings) : new UnionPostingsEnum(postings);\n          }\n\n          postingsFreqs[pos] = new PhraseQuery.PostingsAndFreq(postingsEnum, positions[pos], terms);\n        }\n\n        // sort by increasing docFreq order\n        if (slop == 0) {\n          ArrayUtil.timSort(postingsFreqs);\n          return new ExactPhraseMatcher(postingsFreqs, totalMatchCost);\n        }\n        else {\n          return new SloppyPhraseMatcher(postingsFreqs, slop, totalMatchCost, exposeOffsets);\n        }\n\n      }\n\n      @Override\n      public void extractTerms(Set<Term> terms) {\n        for (final Term[] arr : termArrays) {\n          Collections.addAll(terms, arr);\n        }\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f8dd25829321d66cd54ea7d40a4130e0d2a29bec","date":1562680889,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/MultiPhraseQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/MultiPhraseQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    final Map<Term,TermStates> termStates = new HashMap<>();\n    return new PhraseWeight(this, field, searcher, scoreMode) {\n\n      @Override\n      protected Similarity.SimScorer getStats(IndexSearcher searcher) throws IOException {\n        final IndexReaderContext context = searcher.getTopReaderContext();\n\n        // compute idf\n        ArrayList<TermStatistics> allTermStats = new ArrayList<>();\n        for(final Term[] terms: termArrays) {\n          for (Term term: terms) {\n            TermStates ts = termStates.get(term);\n            if (ts == null) {\n              ts = TermStates.build(context, term, scoreMode.needsScores());\n              termStates.put(term, ts);\n            }\n            if (scoreMode.needsScores()) {\n              TermStatistics termStatistics = searcher.termStatistics(term, ts);\n              if (termStatistics != null) {\n                allTermStats.add(termStatistics);\n              }\n            }\n          }\n        }\n        if (allTermStats.isEmpty()) {\n          return null; // none of the terms were found, we won't use sim at all\n        } else {\n          return similarity.scorer(\n              boost,\n              searcher.collectionStatistics(field),\n              allTermStats.toArray(new TermStatistics[allTermStats.size()]));\n        }\n      }\n\n      @Override\n      protected PhraseMatcher getPhraseMatcher(LeafReaderContext context, SimScorer scorer, boolean exposeOffsets) throws IOException {\n        assert termArrays.length != 0;\n        final LeafReader reader = context.reader();\n\n        PhraseQuery.PostingsAndFreq[] postingsFreqs = new PhraseQuery.PostingsAndFreq[termArrays.length];\n\n        final Terms fieldTerms = reader.terms(field);\n        if (fieldTerms == null) {\n          return null;\n        }\n\n        // TODO: move this check to createWeight to happen earlier to the user?\n        if (fieldTerms.hasPositions() == false) {\n          throw new IllegalStateException(\"field \\\"\" + field + \"\\\" was indexed without position data;\" +\n              \" cannot run MultiPhraseQuery (phrase=\" + getQuery() + \")\");\n        }\n\n        // Reuse single TermsEnum below:\n        final TermsEnum termsEnum = fieldTerms.iterator();\n        float totalMatchCost = 0;\n\n        for (int pos=0; pos<postingsFreqs.length; pos++) {\n          Term[] terms = termArrays[pos];\n          List<PostingsEnum> postings = new ArrayList<>();\n\n          for (Term term : terms) {\n            TermState termState = termStates.get(term).get(context);\n            if (termState != null) {\n              termsEnum.seekExact(term.bytes(), termState);\n              postings.add(termsEnum.postings(null, exposeOffsets ? PostingsEnum.ALL : PostingsEnum.POSITIONS));\n              totalMatchCost += PhraseQuery.termPositionsCost(termsEnum);\n            }\n          }\n\n          if (postings.isEmpty()) {\n            return null;\n          }\n\n          final PostingsEnum postingsEnum;\n          if (postings.size() == 1) {\n            postingsEnum = postings.get(0);\n          } else {\n            postingsEnum = exposeOffsets ? new UnionFullPostingsEnum(postings) : new UnionPostingsEnum(postings);\n          }\n\n          postingsFreqs[pos] = new PhraseQuery.PostingsAndFreq(postingsEnum, new SlowImpactsEnum(postingsEnum), positions[pos], terms);\n        }\n\n        // sort by increasing docFreq order\n        if (slop == 0) {\n          ArrayUtil.timSort(postingsFreqs);\n          return new ExactPhraseMatcher(postingsFreqs, scoreMode, scorer, totalMatchCost);\n        }\n        else {\n          return new SloppyPhraseMatcher(postingsFreqs, slop, scoreMode, scorer, totalMatchCost, exposeOffsets);\n        }\n\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    final Map<Term,TermStates> termStates = new HashMap<>();\n    return new PhraseWeight(this, field, searcher, scoreMode) {\n\n      @Override\n      protected Similarity.SimScorer getStats(IndexSearcher searcher) throws IOException {\n        final IndexReaderContext context = searcher.getTopReaderContext();\n\n        // compute idf\n        ArrayList<TermStatistics> allTermStats = new ArrayList<>();\n        for(final Term[] terms: termArrays) {\n          for (Term term: terms) {\n            TermStates ts = termStates.get(term);\n            if (ts == null) {\n              ts = TermStates.build(context, term, scoreMode.needsScores());\n              termStates.put(term, ts);\n            }\n            if (scoreMode.needsScores()) {\n              TermStatistics termStatistics = searcher.termStatistics(term, ts);\n              if (termStatistics != null) {\n                allTermStats.add(termStatistics);\n              }\n            }\n          }\n        }\n        if (allTermStats.isEmpty()) {\n          return null; // none of the terms were found, we won't use sim at all\n        } else {\n          return similarity.scorer(\n              boost,\n              searcher.collectionStatistics(field),\n              allTermStats.toArray(new TermStatistics[allTermStats.size()]));\n        }\n      }\n\n      @Override\n      protected PhraseMatcher getPhraseMatcher(LeafReaderContext context, boolean exposeOffsets) throws IOException {\n        assert termArrays.length != 0;\n        final LeafReader reader = context.reader();\n\n        PhraseQuery.PostingsAndFreq[] postingsFreqs = new PhraseQuery.PostingsAndFreq[termArrays.length];\n\n        final Terms fieldTerms = reader.terms(field);\n        if (fieldTerms == null) {\n          return null;\n        }\n\n        // TODO: move this check to createWeight to happen earlier to the user?\n        if (fieldTerms.hasPositions() == false) {\n          throw new IllegalStateException(\"field \\\"\" + field + \"\\\" was indexed without position data;\" +\n              \" cannot run MultiPhraseQuery (phrase=\" + getQuery() + \")\");\n        }\n\n        // Reuse single TermsEnum below:\n        final TermsEnum termsEnum = fieldTerms.iterator();\n        float totalMatchCost = 0;\n\n        for (int pos=0; pos<postingsFreqs.length; pos++) {\n          Term[] terms = termArrays[pos];\n          List<PostingsEnum> postings = new ArrayList<>();\n\n          for (Term term : terms) {\n            TermState termState = termStates.get(term).get(context);\n            if (termState != null) {\n              termsEnum.seekExact(term.bytes(), termState);\n              postings.add(termsEnum.postings(null, exposeOffsets ? PostingsEnum.ALL : PostingsEnum.POSITIONS));\n              totalMatchCost += PhraseQuery.termPositionsCost(termsEnum);\n            }\n          }\n\n          if (postings.isEmpty()) {\n            return null;\n          }\n\n          final PostingsEnum postingsEnum;\n          if (postings.size() == 1) {\n            postingsEnum = postings.get(0);\n          } else {\n            postingsEnum = exposeOffsets ? new UnionFullPostingsEnum(postings) : new UnionPostingsEnum(postings);\n          }\n\n          postingsFreqs[pos] = new PhraseQuery.PostingsAndFreq(postingsEnum, positions[pos], terms);\n        }\n\n        // sort by increasing docFreq order\n        if (slop == 0) {\n          ArrayUtil.timSort(postingsFreqs);\n          return new ExactPhraseMatcher(postingsFreqs, totalMatchCost);\n        }\n        else {\n          return new SloppyPhraseMatcher(postingsFreqs, slop, totalMatchCost, exposeOffsets);\n        }\n\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"19238c4860c45945f1b1e39032e056ce9e266152","date":1568753304,"type":3,"author":"Bruno Roustant","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/MultiPhraseQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/MultiPhraseQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    final Map<Term,TermStates> termStates = new HashMap<>();\n    return new PhraseWeight(this, field, searcher, scoreMode) {\n\n      @Override\n      protected Similarity.SimScorer getStats(IndexSearcher searcher) throws IOException {\n        final IndexReaderContext context = searcher.getTopReaderContext();\n\n        // compute idf\n        ArrayList<TermStatistics> allTermStats = new ArrayList<>();\n        for(final Term[] terms: termArrays) {\n          for (Term term: terms) {\n            TermStates ts = termStates.get(term);\n            if (ts == null) {\n              ts = TermStates.build(context, term, scoreMode.needsScores());\n              termStates.put(term, ts);\n            }\n            if (scoreMode.needsScores() && ts.docFreq() > 0) {\n              allTermStats.add(searcher.termStatistics(term, ts.docFreq(), ts.totalTermFreq()));\n            }\n          }\n        }\n        if (allTermStats.isEmpty()) {\n          return null; // none of the terms were found, we won't use sim at all\n        } else {\n          return similarity.scorer(\n              boost,\n              searcher.collectionStatistics(field),\n              allTermStats.toArray(new TermStatistics[allTermStats.size()]));\n        }\n      }\n\n      @Override\n      protected PhraseMatcher getPhraseMatcher(LeafReaderContext context, SimScorer scorer, boolean exposeOffsets) throws IOException {\n        assert termArrays.length != 0;\n        final LeafReader reader = context.reader();\n\n        PhraseQuery.PostingsAndFreq[] postingsFreqs = new PhraseQuery.PostingsAndFreq[termArrays.length];\n\n        final Terms fieldTerms = reader.terms(field);\n        if (fieldTerms == null) {\n          return null;\n        }\n\n        // TODO: move this check to createWeight to happen earlier to the user?\n        if (fieldTerms.hasPositions() == false) {\n          throw new IllegalStateException(\"field \\\"\" + field + \"\\\" was indexed without position data;\" +\n              \" cannot run MultiPhraseQuery (phrase=\" + getQuery() + \")\");\n        }\n\n        // Reuse single TermsEnum below:\n        final TermsEnum termsEnum = fieldTerms.iterator();\n        float totalMatchCost = 0;\n\n        for (int pos=0; pos<postingsFreqs.length; pos++) {\n          Term[] terms = termArrays[pos];\n          List<PostingsEnum> postings = new ArrayList<>();\n\n          for (Term term : terms) {\n            TermState termState = termStates.get(term).get(context);\n            if (termState != null) {\n              termsEnum.seekExact(term.bytes(), termState);\n              postings.add(termsEnum.postings(null, exposeOffsets ? PostingsEnum.ALL : PostingsEnum.POSITIONS));\n              totalMatchCost += PhraseQuery.termPositionsCost(termsEnum);\n            }\n          }\n\n          if (postings.isEmpty()) {\n            return null;\n          }\n\n          final PostingsEnum postingsEnum;\n          if (postings.size() == 1) {\n            postingsEnum = postings.get(0);\n          } else {\n            postingsEnum = exposeOffsets ? new UnionFullPostingsEnum(postings) : new UnionPostingsEnum(postings);\n          }\n\n          postingsFreqs[pos] = new PhraseQuery.PostingsAndFreq(postingsEnum, new SlowImpactsEnum(postingsEnum), positions[pos], terms);\n        }\n\n        // sort by increasing docFreq order\n        if (slop == 0) {\n          ArrayUtil.timSort(postingsFreqs);\n          return new ExactPhraseMatcher(postingsFreqs, scoreMode, scorer, totalMatchCost);\n        }\n        else {\n          return new SloppyPhraseMatcher(postingsFreqs, slop, scoreMode, scorer, totalMatchCost, exposeOffsets);\n        }\n\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    final Map<Term,TermStates> termStates = new HashMap<>();\n    return new PhraseWeight(this, field, searcher, scoreMode) {\n\n      @Override\n      protected Similarity.SimScorer getStats(IndexSearcher searcher) throws IOException {\n        final IndexReaderContext context = searcher.getTopReaderContext();\n\n        // compute idf\n        ArrayList<TermStatistics> allTermStats = new ArrayList<>();\n        for(final Term[] terms: termArrays) {\n          for (Term term: terms) {\n            TermStates ts = termStates.get(term);\n            if (ts == null) {\n              ts = TermStates.build(context, term, scoreMode.needsScores());\n              termStates.put(term, ts);\n            }\n            if (scoreMode.needsScores()) {\n              TermStatistics termStatistics = searcher.termStatistics(term, ts);\n              if (termStatistics != null) {\n                allTermStats.add(termStatistics);\n              }\n            }\n          }\n        }\n        if (allTermStats.isEmpty()) {\n          return null; // none of the terms were found, we won't use sim at all\n        } else {\n          return similarity.scorer(\n              boost,\n              searcher.collectionStatistics(field),\n              allTermStats.toArray(new TermStatistics[allTermStats.size()]));\n        }\n      }\n\n      @Override\n      protected PhraseMatcher getPhraseMatcher(LeafReaderContext context, SimScorer scorer, boolean exposeOffsets) throws IOException {\n        assert termArrays.length != 0;\n        final LeafReader reader = context.reader();\n\n        PhraseQuery.PostingsAndFreq[] postingsFreqs = new PhraseQuery.PostingsAndFreq[termArrays.length];\n\n        final Terms fieldTerms = reader.terms(field);\n        if (fieldTerms == null) {\n          return null;\n        }\n\n        // TODO: move this check to createWeight to happen earlier to the user?\n        if (fieldTerms.hasPositions() == false) {\n          throw new IllegalStateException(\"field \\\"\" + field + \"\\\" was indexed without position data;\" +\n              \" cannot run MultiPhraseQuery (phrase=\" + getQuery() + \")\");\n        }\n\n        // Reuse single TermsEnum below:\n        final TermsEnum termsEnum = fieldTerms.iterator();\n        float totalMatchCost = 0;\n\n        for (int pos=0; pos<postingsFreqs.length; pos++) {\n          Term[] terms = termArrays[pos];\n          List<PostingsEnum> postings = new ArrayList<>();\n\n          for (Term term : terms) {\n            TermState termState = termStates.get(term).get(context);\n            if (termState != null) {\n              termsEnum.seekExact(term.bytes(), termState);\n              postings.add(termsEnum.postings(null, exposeOffsets ? PostingsEnum.ALL : PostingsEnum.POSITIONS));\n              totalMatchCost += PhraseQuery.termPositionsCost(termsEnum);\n            }\n          }\n\n          if (postings.isEmpty()) {\n            return null;\n          }\n\n          final PostingsEnum postingsEnum;\n          if (postings.size() == 1) {\n            postingsEnum = postings.get(0);\n          } else {\n            postingsEnum = exposeOffsets ? new UnionFullPostingsEnum(postings) : new UnionPostingsEnum(postings);\n          }\n\n          postingsFreqs[pos] = new PhraseQuery.PostingsAndFreq(postingsEnum, new SlowImpactsEnum(postingsEnum), positions[pos], terms);\n        }\n\n        // sort by increasing docFreq order\n        if (slop == 0) {\n          ArrayUtil.timSort(postingsFreqs);\n          return new ExactPhraseMatcher(postingsFreqs, scoreMode, scorer, totalMatchCost);\n        }\n        else {\n          return new SloppyPhraseMatcher(postingsFreqs, slop, scoreMode, scorer, totalMatchCost, exposeOffsets);\n        }\n\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"33eef98c565ee21b199f04b92acd6e00b842bd1e":["417142ff08fda9cf0b72d5133e63097a166c6458"],"3b11b9d5eaf9707760ca5151530830a825197023":["33eef98c565ee21b199f04b92acd6e00b842bd1e"],"f8dd25829321d66cd54ea7d40a4130e0d2a29bec":["5b9ffb60dc4bdc972b1403ad2ab2f5b4d9ce4cf7"],"165c3432cb3c4fcfc8e859af24323bbbd12084af":["3b11b9d5eaf9707760ca5151530830a825197023"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"19238c4860c45945f1b1e39032e056ce9e266152":["f8dd25829321d66cd54ea7d40a4130e0d2a29bec"],"9fc47cb7b4346802411bb432f501ed0673d7119e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"62ba8124694976baa3b03705351de238ec5d4352":["165c3432cb3c4fcfc8e859af24323bbbd12084af"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["19238c4860c45945f1b1e39032e056ce9e266152"],"5b9ffb60dc4bdc972b1403ad2ab2f5b4d9ce4cf7":["41ebc07bccf12a902ca6a0077910d18ee38b695f"],"41ebc07bccf12a902ca6a0077910d18ee38b695f":["62ba8124694976baa3b03705351de238ec5d4352"],"417142ff08fda9cf0b72d5133e63097a166c6458":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","9fc47cb7b4346802411bb432f501ed0673d7119e"]},"commit2Childs":{"33eef98c565ee21b199f04b92acd6e00b842bd1e":["3b11b9d5eaf9707760ca5151530830a825197023"],"3b11b9d5eaf9707760ca5151530830a825197023":["165c3432cb3c4fcfc8e859af24323bbbd12084af"],"f8dd25829321d66cd54ea7d40a4130e0d2a29bec":["19238c4860c45945f1b1e39032e056ce9e266152"],"165c3432cb3c4fcfc8e859af24323bbbd12084af":["62ba8124694976baa3b03705351de238ec5d4352"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9fc47cb7b4346802411bb432f501ed0673d7119e","417142ff08fda9cf0b72d5133e63097a166c6458"],"19238c4860c45945f1b1e39032e056ce9e266152":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"9fc47cb7b4346802411bb432f501ed0673d7119e":["417142ff08fda9cf0b72d5133e63097a166c6458"],"62ba8124694976baa3b03705351de238ec5d4352":["41ebc07bccf12a902ca6a0077910d18ee38b695f"],"417142ff08fda9cf0b72d5133e63097a166c6458":["33eef98c565ee21b199f04b92acd6e00b842bd1e"],"5b9ffb60dc4bdc972b1403ad2ab2f5b4d9ce4cf7":["f8dd25829321d66cd54ea7d40a4130e0d2a29bec"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"41ebc07bccf12a902ca6a0077910d18ee38b695f":["5b9ffb60dc4bdc972b1403ad2ab2f5b4d9ce4cf7"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}