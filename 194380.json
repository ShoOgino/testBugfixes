{"path":"src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","commits":[{"id":"91109046a59c58ee0ee5d0d2767b08d1f30d6702","date":1000830588,"type":0,"author":"Jason van Zyl","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","pathOld":"/dev/null","sourceNew":"  /** Merges all segments together into a single segment, optimizing an index\n      for search. */\n  public final synchronized void optimize() throws IOException {\n    flushRamSegments();\n    while (segmentInfos.size() > 1 ||\n\t   (segmentInfos.size() == 1 &&\n\t    SegmentReader.hasDeletions(segmentInfos.info(0)))){\n      int minSegment = segmentInfos.size() - mergeFactor;\n      mergeSegments(minSegment < 0 ? 0 : minSegment);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"97ff927ed26c6ab8f288a4dbf5a20ac8ecf4abe1","date":1003545179,"type":3,"author":"Doug Cutting","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","sourceNew":"  /** Merges all segments together into a single segment, optimizing an index\n      for search. */\n  public final synchronized void optimize() throws IOException {\n    flushRamSegments();\n    while (segmentInfos.size() > 1 ||\n\t   (segmentInfos.size() == 1 &&\n\t    (SegmentReader.hasDeletions(segmentInfos.info(0)) ||\n             segmentInfos.info(0).dir != directory))) {\n      int minSegment = segmentInfos.size() - mergeFactor;\n      mergeSegments(minSegment < 0 ? 0 : minSegment);\n    }\n  }\n\n","sourceOld":"  /** Merges all segments together into a single segment, optimizing an index\n      for search. */\n  public final synchronized void optimize() throws IOException {\n    flushRamSegments();\n    while (segmentInfos.size() > 1 ||\n\t   (segmentInfos.size() == 1 &&\n\t    SegmentReader.hasDeletions(segmentInfos.info(0)))){\n      int minSegment = segmentInfos.size() - mergeFactor;\n      mergeSegments(minSegment < 0 ? 0 : minSegment);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9c7454619ea6a0710272c1dd947345cee64489f6","date":1026927484,"type":3,"author":"Doug Cutting","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","sourceNew":"  /** Merges all segments together into a single segment, optimizing an index\n      for search. */\n  public synchronized void optimize() throws IOException {\n    flushRamSegments();\n    while (segmentInfos.size() > 1 ||\n\t   (segmentInfos.size() == 1 &&\n\t    (SegmentReader.hasDeletions(segmentInfos.info(0)) ||\n             segmentInfos.info(0).dir != directory))) {\n      int minSegment = segmentInfos.size() - mergeFactor;\n      mergeSegments(minSegment < 0 ? 0 : minSegment);\n    }\n  }\n\n","sourceOld":"  /** Merges all segments together into a single segment, optimizing an index\n      for search. */\n  public final synchronized void optimize() throws IOException {\n    flushRamSegments();\n    while (segmentInfos.size() > 1 ||\n\t   (segmentInfos.size() == 1 &&\n\t    (SegmentReader.hasDeletions(segmentInfos.info(0)) ||\n             segmentInfos.info(0).dir != directory))) {\n      int minSegment = segmentInfos.size() - mergeFactor;\n      mergeSegments(minSegment < 0 ? 0 : minSegment);\n    }\n  }\n\n","bugFix":null,"bugIntro":["1b54a9bc667895a2095a886184bf69a3179e63df"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8fb95844e4ba5160067c64c5eb1cd8a09f7a94f1","date":1064527311,"type":3,"author":"Dmitry Serebrennikov","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","sourceNew":"  /** Merges all segments together into a single segment, optimizing an index\n      for search. */\n  public synchronized void optimize() throws IOException {\n    flushRamSegments();\n    while (segmentInfos.size() > 1 ||\n           (segmentInfos.size() == 1 &&\n            (SegmentReader.hasDeletions(segmentInfos.info(0)) ||\n             (useCompoundFile && \n              !SegmentReader.usesCompoundFile(segmentInfos.info(0))) ||\n              segmentInfos.info(0).dir != directory))) {\n      int minSegment = segmentInfos.size() - mergeFactor;\n      mergeSegments(minSegment < 0 ? 0 : minSegment);\n    }    \n  }\n\n","sourceOld":"  /** Merges all segments together into a single segment, optimizing an index\n      for search. */\n  public synchronized void optimize() throws IOException {\n    flushRamSegments();\n    while (segmentInfos.size() > 1 ||\n\t   (segmentInfos.size() == 1 &&\n\t    (SegmentReader.hasDeletions(segmentInfos.info(0)) ||\n             segmentInfos.info(0).dir != directory))) {\n      int minSegment = segmentInfos.size() - mergeFactor;\n      mergeSegments(minSegment < 0 ? 0 : minSegment);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f7961006605708cac1ca5185ead37902442ceff6","date":1078410713,"type":3,"author":"Otis Gospodnetic","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","sourceNew":"  /** Merges all segments together into a single segment, optimizing an index\n      for search. */\n  public synchronized void optimize() throws IOException {\n    flushRamSegments();\n    while (segmentInfos.size() > 1 ||\n           (segmentInfos.size() == 1 &&\n            (SegmentReader.hasDeletions(segmentInfos.info(0)) ||\n             (useCompoundFile &&\n              !SegmentReader.usesCompoundFile(segmentInfos.info(0))) ||\n              segmentInfos.info(0).dir != directory))) {\n      int minSegment = segmentInfos.size() - mergeFactor;\n      mergeSegments(minSegment < 0 ? 0 : minSegment);\n    }\n  }\n\n","sourceOld":"  /** Merges all segments together into a single segment, optimizing an index\n      for search. */\n  public synchronized void optimize() throws IOException {\n    flushRamSegments();\n    while (segmentInfos.size() > 1 ||\n           (segmentInfos.size() == 1 &&\n            (SegmentReader.hasDeletions(segmentInfos.info(0)) ||\n             (useCompoundFile && \n              !SegmentReader.usesCompoundFile(segmentInfos.info(0))) ||\n              segmentInfos.info(0).dir != directory))) {\n      int minSegment = segmentInfos.size() - mergeFactor;\n      mergeSegments(minSegment < 0 ? 0 : minSegment);\n    }    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8e38f34b073ce1e76079bad953c869de3067ec43","date":1082119483,"type":3,"author":"Christoph Goller","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","sourceNew":"  /** Merges all segments together into a single segment, optimizing an index\n      for search. */\n  public synchronized void optimize() throws IOException {\n    flushRamSegments();\n    while (segmentInfos.size() > 1 ||\n           (segmentInfos.size() == 1 &&\n            (SegmentReader.hasDeletions(segmentInfos.info(0)) ||\n             segmentInfos.info(0).dir != directory ||\n             (useCompoundFile &&\n              (!SegmentReader.usesCompoundFile(segmentInfos.info(0)) ||\n                SegmentReader.hasSeparateNorms(segmentInfos.info(0))))))) {\n      int minSegment = segmentInfos.size() - mergeFactor;\n      mergeSegments(minSegment < 0 ? 0 : minSegment);\n    }\n  }\n\n","sourceOld":"  /** Merges all segments together into a single segment, optimizing an index\n      for search. */\n  public synchronized void optimize() throws IOException {\n    flushRamSegments();\n    while (segmentInfos.size() > 1 ||\n           (segmentInfos.size() == 1 &&\n            (SegmentReader.hasDeletions(segmentInfos.info(0)) ||\n             (useCompoundFile &&\n              !SegmentReader.usesCompoundFile(segmentInfos.info(0))) ||\n              segmentInfos.info(0).dir != directory))) {\n      int minSegment = segmentInfos.size() - mergeFactor;\n      mergeSegments(minSegment < 0 ? 0 : minSegment);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1507a324c1f939ed71e01297733a49b9c36e5688","date":1155783141,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","sourceNew":"  /** Merges all segments together into a single segment, optimizing an index\n      for search. */\n  public synchronized void optimize() throws IOException {\n    flushRamSegments();\n    while (segmentInfos.size() > 1 ||\n           (segmentInfos.size() == 1 &&\n            (SegmentReader.hasDeletions(segmentInfos.info(0)) ||\n             segmentInfos.info(0).dir != directory ||\n             (useCompoundFile &&\n              (!SegmentReader.usesCompoundFile(segmentInfos.info(0)) ||\n                SegmentReader.hasSeparateNorms(segmentInfos.info(0))))))) {\n      int minSegment = segmentInfos.size() - mergeFactor;\n      mergeSegments(minSegment < 0 ? 0 : minSegment);\n    }\n    // testInvariants();\n  }\n\n","sourceOld":"  /** Merges all segments together into a single segment, optimizing an index\n      for search. */\n  public synchronized void optimize() throws IOException {\n    flushRamSegments();\n    while (segmentInfos.size() > 1 ||\n           (segmentInfos.size() == 1 &&\n            (SegmentReader.hasDeletions(segmentInfos.info(0)) ||\n             segmentInfos.info(0).dir != directory ||\n             (useCompoundFile &&\n              (!SegmentReader.usesCompoundFile(segmentInfos.info(0)) ||\n                SegmentReader.hasSeparateNorms(segmentInfos.info(0))))))) {\n      int minSegment = segmentInfos.size() - mergeFactor;\n      mergeSegments(minSegment < 0 ? 0 : minSegment);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d7052f725a053aa55424f966831826f61b798bf1","date":1158258681,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","sourceNew":"  /** Merges all segments together into a single segment, optimizing an index\n      for search. */\n  public synchronized void optimize() throws IOException {\n    flushRamSegments();\n    while (segmentInfos.size() > 1 ||\n           (segmentInfos.size() == 1 &&\n            (SegmentReader.hasDeletions(segmentInfos.info(0)) ||\n             segmentInfos.info(0).dir != directory ||\n             (useCompoundFile &&\n              (!SegmentReader.usesCompoundFile(segmentInfos.info(0)) ||\n                SegmentReader.hasSeparateNorms(segmentInfos.info(0))))))) {\n      int minSegment = segmentInfos.size() - mergeFactor;\n      mergeSegments(segmentInfos, minSegment < 0 ? 0 : minSegment, segmentInfos.size());\n    }\n  }\n\n","sourceOld":"  /** Merges all segments together into a single segment, optimizing an index\n      for search. */\n  public synchronized void optimize() throws IOException {\n    flushRamSegments();\n    while (segmentInfos.size() > 1 ||\n           (segmentInfos.size() == 1 &&\n            (SegmentReader.hasDeletions(segmentInfos.info(0)) ||\n             segmentInfos.info(0).dir != directory ||\n             (useCompoundFile &&\n              (!SegmentReader.usesCompoundFile(segmentInfos.info(0)) ||\n                SegmentReader.hasSeparateNorms(segmentInfos.info(0))))))) {\n      int minSegment = segmentInfos.size() - mergeFactor;\n      mergeSegments(minSegment < 0 ? 0 : minSegment);\n    }\n    // testInvariants();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"eeefd99c477417e5c7c574228461ebafe92469d4","date":1166460329,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","sourceNew":"  /** Merges all segments together into a single segment,\n   * optimizing an index for search..\n   * \n   * <p>Note that this requires temporary free space in the\n   * Directory up to the size of the starting index (exact\n   * usage could be less but will depend on many\n   * factors).</p>\n\n   * <p>If an Exception is hit during optimize() (eg, due to\n   * disk full), the index will not be corrupted.  However\n   * it's possible that one of the segments in the index\n   * will be in non-CFS format even when using compound file\n   * format.  This will occur when the Exception is hit\n   * during conversion of the segment into compound\n   * format.</p>\n  */\n  public synchronized void optimize() throws IOException {\n    flushRamSegments();\n    while (segmentInfos.size() > 1 ||\n           (segmentInfos.size() == 1 &&\n            (SegmentReader.hasDeletions(segmentInfos.info(0)) ||\n             segmentInfos.info(0).dir != directory ||\n             (useCompoundFile &&\n              (!SegmentReader.usesCompoundFile(segmentInfos.info(0)) ||\n                SegmentReader.hasSeparateNorms(segmentInfos.info(0))))))) {\n      int minSegment = segmentInfos.size() - mergeFactor;\n      mergeSegments(segmentInfos, minSegment < 0 ? 0 : minSegment, segmentInfos.size());\n    }\n  }\n\n","sourceOld":"  /** Merges all segments together into a single segment, optimizing an index\n      for search. */\n  public synchronized void optimize() throws IOException {\n    flushRamSegments();\n    while (segmentInfos.size() > 1 ||\n           (segmentInfos.size() == 1 &&\n            (SegmentReader.hasDeletions(segmentInfos.info(0)) ||\n             segmentInfos.info(0).dir != directory ||\n             (useCompoundFile &&\n              (!SegmentReader.usesCompoundFile(segmentInfos.info(0)) ||\n                SegmentReader.hasSeparateNorms(segmentInfos.info(0))))))) {\n      int minSegment = segmentInfos.size() - mergeFactor;\n      mergeSegments(segmentInfos, minSegment < 0 ? 0 : minSegment, segmentInfos.size());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8f7478f1d67a81bf80f28067595be0383022d65b","date":1167857941,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","sourceNew":"  /** Merges all segments together into a single segment,\n   * optimizing an index for search.\n   * \n   * <p>Note that this requires substantial temporary free\n   * space in the Directory (see <a target=\"_top\"\n   * href=\"http://issues.apache.org/jira/browse/LUCENE-764\">LUCENE-764</a>\n   * for details):</p>\n   *\n   * <ul>\n   * <li>\n   * \n   * <p>If no readers/searchers are open against the index,\n   * then free space required is up to 1X the total size of\n   * the starting index.  For example, if the starting\n   * index is 10 GB, then you must have up to 10 GB of free\n   * space before calling optimize.</p>\n   *\n   * <li>\n   * \n   * <p>If readers/searchers are using the index, then free\n   * space required is up to 2X the size of the starting\n   * index.  This is because in addition to the 1X used by\n   * optimize, the original 1X of the starting index is\n   * still consuming space in the Directory as the readers\n   * are holding the segments files open.  Even on Unix,\n   * where it will appear as if the files are gone (\"ls\"\n   * won't list them), they still consume storage due to\n   * \"delete on last close\" semantics.</p>\n   * \n   * <p>Furthermore, if some but not all readers re-open\n   * while the optimize is underway, this will cause > 2X\n   * temporary space to be consumed as those new readers\n   * will then hold open the partially optimized segments at\n   * that time.  It is best not to re-open readers while\n   * optimize is running.</p>\n   *\n   * </ul>\n   *\n   * <p>The actual temporary usage could be much less than\n   * these figures (it depends on many factors).</p>\n   *\n   * <p>Once the optimize completes, the total size of the\n   * index will be less than the size of the starting index.\n   * It could be quite a bit smaller (if there were many\n   * pending deletes) or just slightly smaller.</p>\n   *\n   * <p>If an Exception is hit during optimize(), for example\n   * due to disk full, the index will not be corrupt and no\n   * documents will have been lost.  However, it may have\n   * been partially optimized (some segments were merged but\n   * not all), and it's possible that one of the segments in\n   * the index will be in non-compound format even when\n   * using compound file format.  This will occur when the\n   * Exception is hit during conversion of the segment into\n   * compound format.</p>\n  */\n  public synchronized void optimize() throws IOException {\n    flushRamSegments();\n    while (segmentInfos.size() > 1 ||\n           (segmentInfos.size() == 1 &&\n            (SegmentReader.hasDeletions(segmentInfos.info(0)) ||\n             segmentInfos.info(0).dir != directory ||\n             (useCompoundFile &&\n              (!SegmentReader.usesCompoundFile(segmentInfos.info(0)) ||\n                SegmentReader.hasSeparateNorms(segmentInfos.info(0))))))) {\n      int minSegment = segmentInfos.size() - mergeFactor;\n      mergeSegments(segmentInfos, minSegment < 0 ? 0 : minSegment, segmentInfos.size());\n    }\n  }\n\n","sourceOld":"  /** Merges all segments together into a single segment,\n   * optimizing an index for search..\n   * \n   * <p>Note that this requires temporary free space in the\n   * Directory up to the size of the starting index (exact\n   * usage could be less but will depend on many\n   * factors).</p>\n\n   * <p>If an Exception is hit during optimize() (eg, due to\n   * disk full), the index will not be corrupted.  However\n   * it's possible that one of the segments in the index\n   * will be in non-CFS format even when using compound file\n   * format.  This will occur when the Exception is hit\n   * during conversion of the segment into compound\n   * format.</p>\n  */\n  public synchronized void optimize() throws IOException {\n    flushRamSegments();\n    while (segmentInfos.size() > 1 ||\n           (segmentInfos.size() == 1 &&\n            (SegmentReader.hasDeletions(segmentInfos.info(0)) ||\n             segmentInfos.info(0).dir != directory ||\n             (useCompoundFile &&\n              (!SegmentReader.usesCompoundFile(segmentInfos.info(0)) ||\n                SegmentReader.hasSeparateNorms(segmentInfos.info(0))))))) {\n      int minSegment = segmentInfos.size() - mergeFactor;\n      mergeSegments(segmentInfos, minSegment < 0 ? 0 : minSegment, segmentInfos.size());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8969a184df55d25d61e85be785987fbf830d4028","date":1168143561,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","sourceNew":"  /** Merges all segments together into a single segment,\n   * optimizing an index for search.\n   * \n   * <p>Note that this requires substantial temporary free\n   * space in the Directory (see <a target=\"_top\"\n   * href=\"http://issues.apache.org/jira/browse/LUCENE-764\">LUCENE-764</a>\n   * for details):</p>\n   *\n   * <ul>\n   * <li>\n   * \n   * <p>If no readers/searchers are open against the index,\n   * then free space required is up to 1X the total size of\n   * the starting index.  For example, if the starting\n   * index is 10 GB, then you must have up to 10 GB of free\n   * space before calling optimize.</p>\n   *\n   * <li>\n   * \n   * <p>If readers/searchers are using the index, then free\n   * space required is up to 2X the size of the starting\n   * index.  This is because in addition to the 1X used by\n   * optimize, the original 1X of the starting index is\n   * still consuming space in the Directory as the readers\n   * are holding the segments files open.  Even on Unix,\n   * where it will appear as if the files are gone (\"ls\"\n   * won't list them), they still consume storage due to\n   * \"delete on last close\" semantics.</p>\n   * \n   * <p>Furthermore, if some but not all readers re-open\n   * while the optimize is underway, this will cause > 2X\n   * temporary space to be consumed as those new readers\n   * will then hold open the partially optimized segments at\n   * that time.  It is best not to re-open readers while\n   * optimize is running.</p>\n   *\n   * </ul>\n   *\n   * <p>The actual temporary usage could be much less than\n   * these figures (it depends on many factors).</p>\n   *\n   * <p>Once the optimize completes, the total size of the\n   * index will be less than the size of the starting index.\n   * It could be quite a bit smaller (if there were many\n   * pending deletes) or just slightly smaller.</p>\n   *\n   * <p>If an Exception is hit during optimize(), for example\n   * due to disk full, the index will not be corrupt and no\n   * documents will have been lost.  However, it may have\n   * been partially optimized (some segments were merged but\n   * not all), and it's possible that one of the segments in\n   * the index will be in non-compound format even when\n   * using compound file format.  This will occur when the\n   * Exception is hit during conversion of the segment into\n   * compound format.</p>\n  */\n  public synchronized void optimize() throws IOException {\n    flushRamSegments();\n    while (segmentInfos.size() > 1 ||\n           (segmentInfos.size() == 1 &&\n            (SegmentReader.hasDeletions(segmentInfos.info(0)) ||\n             SegmentReader.hasSeparateNorms(segmentInfos.info(0)) ||\n             segmentInfos.info(0).dir != directory ||\n             (useCompoundFile &&\n              (!SegmentReader.usesCompoundFile(segmentInfos.info(0))))))) {\n      int minSegment = segmentInfos.size() - mergeFactor;\n      mergeSegments(segmentInfos, minSegment < 0 ? 0 : minSegment, segmentInfos.size());\n    }\n  }\n\n","sourceOld":"  /** Merges all segments together into a single segment,\n   * optimizing an index for search.\n   * \n   * <p>Note that this requires substantial temporary free\n   * space in the Directory (see <a target=\"_top\"\n   * href=\"http://issues.apache.org/jira/browse/LUCENE-764\">LUCENE-764</a>\n   * for details):</p>\n   *\n   * <ul>\n   * <li>\n   * \n   * <p>If no readers/searchers are open against the index,\n   * then free space required is up to 1X the total size of\n   * the starting index.  For example, if the starting\n   * index is 10 GB, then you must have up to 10 GB of free\n   * space before calling optimize.</p>\n   *\n   * <li>\n   * \n   * <p>If readers/searchers are using the index, then free\n   * space required is up to 2X the size of the starting\n   * index.  This is because in addition to the 1X used by\n   * optimize, the original 1X of the starting index is\n   * still consuming space in the Directory as the readers\n   * are holding the segments files open.  Even on Unix,\n   * where it will appear as if the files are gone (\"ls\"\n   * won't list them), they still consume storage due to\n   * \"delete on last close\" semantics.</p>\n   * \n   * <p>Furthermore, if some but not all readers re-open\n   * while the optimize is underway, this will cause > 2X\n   * temporary space to be consumed as those new readers\n   * will then hold open the partially optimized segments at\n   * that time.  It is best not to re-open readers while\n   * optimize is running.</p>\n   *\n   * </ul>\n   *\n   * <p>The actual temporary usage could be much less than\n   * these figures (it depends on many factors).</p>\n   *\n   * <p>Once the optimize completes, the total size of the\n   * index will be less than the size of the starting index.\n   * It could be quite a bit smaller (if there were many\n   * pending deletes) or just slightly smaller.</p>\n   *\n   * <p>If an Exception is hit during optimize(), for example\n   * due to disk full, the index will not be corrupt and no\n   * documents will have been lost.  However, it may have\n   * been partially optimized (some segments were merged but\n   * not all), and it's possible that one of the segments in\n   * the index will be in non-compound format even when\n   * using compound file format.  This will occur when the\n   * Exception is hit during conversion of the segment into\n   * compound format.</p>\n  */\n  public synchronized void optimize() throws IOException {\n    flushRamSegments();\n    while (segmentInfos.size() > 1 ||\n           (segmentInfos.size() == 1 &&\n            (SegmentReader.hasDeletions(segmentInfos.info(0)) ||\n             segmentInfos.info(0).dir != directory ||\n             (useCompoundFile &&\n              (!SegmentReader.usesCompoundFile(segmentInfos.info(0)) ||\n                SegmentReader.hasSeparateNorms(segmentInfos.info(0))))))) {\n      int minSegment = segmentInfos.size() - mergeFactor;\n      mergeSegments(segmentInfos, minSegment < 0 ? 0 : minSegment, segmentInfos.size());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1b54a9bc667895a2095a886184bf69a3179e63df","date":1172088096,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","sourceNew":"  /** Merges all segments together into a single segment,\n   * optimizing an index for search.\n   * \n   * <p>Note that this requires substantial temporary free\n   * space in the Directory (see <a target=\"_top\"\n   * href=\"http://issues.apache.org/jira/browse/LUCENE-764\">LUCENE-764</a>\n   * for details):</p>\n   *\n   * <ul>\n   * <li>\n   * \n   * <p>If no readers/searchers are open against the index,\n   * then free space required is up to 1X the total size of\n   * the starting index.  For example, if the starting\n   * index is 10 GB, then you must have up to 10 GB of free\n   * space before calling optimize.</p>\n   *\n   * <li>\n   * \n   * <p>If readers/searchers are using the index, then free\n   * space required is up to 2X the size of the starting\n   * index.  This is because in addition to the 1X used by\n   * optimize, the original 1X of the starting index is\n   * still consuming space in the Directory as the readers\n   * are holding the segments files open.  Even on Unix,\n   * where it will appear as if the files are gone (\"ls\"\n   * won't list them), they still consume storage due to\n   * \"delete on last close\" semantics.</p>\n   * \n   * <p>Furthermore, if some but not all readers re-open\n   * while the optimize is underway, this will cause > 2X\n   * temporary space to be consumed as those new readers\n   * will then hold open the partially optimized segments at\n   * that time.  It is best not to re-open readers while\n   * optimize is running.</p>\n   *\n   * </ul>\n   *\n   * <p>The actual temporary usage could be much less than\n   * these figures (it depends on many factors).</p>\n   *\n   * <p>Once the optimize completes, the total size of the\n   * index will be less than the size of the starting index.\n   * It could be quite a bit smaller (if there were many\n   * pending deletes) or just slightly smaller.</p>\n   *\n   * <p>If an Exception is hit during optimize(), for example\n   * due to disk full, the index will not be corrupt and no\n   * documents will have been lost.  However, it may have\n   * been partially optimized (some segments were merged but\n   * not all), and it's possible that one of the segments in\n   * the index will be in non-compound format even when\n   * using compound file format.  This will occur when the\n   * Exception is hit during conversion of the segment into\n   * compound format.</p>\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n  */\n  public synchronized void optimize() throws CorruptIndexException, IOException {\n    flushRamSegments();\n    while (segmentInfos.size() > 1 ||\n           (segmentInfos.size() == 1 &&\n            (SegmentReader.hasDeletions(segmentInfos.info(0)) ||\n             SegmentReader.hasSeparateNorms(segmentInfos.info(0)) ||\n             segmentInfos.info(0).dir != directory ||\n             (useCompoundFile &&\n              (!SegmentReader.usesCompoundFile(segmentInfos.info(0))))))) {\n      int minSegment = segmentInfos.size() - mergeFactor;\n      mergeSegments(segmentInfos, minSegment < 0 ? 0 : minSegment, segmentInfos.size());\n    }\n  }\n\n","sourceOld":"  /** Merges all segments together into a single segment,\n   * optimizing an index for search.\n   * \n   * <p>Note that this requires substantial temporary free\n   * space in the Directory (see <a target=\"_top\"\n   * href=\"http://issues.apache.org/jira/browse/LUCENE-764\">LUCENE-764</a>\n   * for details):</p>\n   *\n   * <ul>\n   * <li>\n   * \n   * <p>If no readers/searchers are open against the index,\n   * then free space required is up to 1X the total size of\n   * the starting index.  For example, if the starting\n   * index is 10 GB, then you must have up to 10 GB of free\n   * space before calling optimize.</p>\n   *\n   * <li>\n   * \n   * <p>If readers/searchers are using the index, then free\n   * space required is up to 2X the size of the starting\n   * index.  This is because in addition to the 1X used by\n   * optimize, the original 1X of the starting index is\n   * still consuming space in the Directory as the readers\n   * are holding the segments files open.  Even on Unix,\n   * where it will appear as if the files are gone (\"ls\"\n   * won't list them), they still consume storage due to\n   * \"delete on last close\" semantics.</p>\n   * \n   * <p>Furthermore, if some but not all readers re-open\n   * while the optimize is underway, this will cause > 2X\n   * temporary space to be consumed as those new readers\n   * will then hold open the partially optimized segments at\n   * that time.  It is best not to re-open readers while\n   * optimize is running.</p>\n   *\n   * </ul>\n   *\n   * <p>The actual temporary usage could be much less than\n   * these figures (it depends on many factors).</p>\n   *\n   * <p>Once the optimize completes, the total size of the\n   * index will be less than the size of the starting index.\n   * It could be quite a bit smaller (if there were many\n   * pending deletes) or just slightly smaller.</p>\n   *\n   * <p>If an Exception is hit during optimize(), for example\n   * due to disk full, the index will not be corrupt and no\n   * documents will have been lost.  However, it may have\n   * been partially optimized (some segments were merged but\n   * not all), and it's possible that one of the segments in\n   * the index will be in non-compound format even when\n   * using compound file format.  This will occur when the\n   * Exception is hit during conversion of the segment into\n   * compound format.</p>\n  */\n  public synchronized void optimize() throws IOException {\n    flushRamSegments();\n    while (segmentInfos.size() > 1 ||\n           (segmentInfos.size() == 1 &&\n            (SegmentReader.hasDeletions(segmentInfos.info(0)) ||\n             SegmentReader.hasSeparateNorms(segmentInfos.info(0)) ||\n             segmentInfos.info(0).dir != directory ||\n             (useCompoundFile &&\n              (!SegmentReader.usesCompoundFile(segmentInfos.info(0))))))) {\n      int minSegment = segmentInfos.size() - mergeFactor;\n      mergeSegments(segmentInfos, minSegment < 0 ? 0 : minSegment, segmentInfos.size());\n    }\n  }\n\n","bugFix":["9c7454619ea6a0710272c1dd947345cee64489f6"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"328c1568e471f0c6eaa49ec00334ca59e573710f","date":1173897963,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","sourceNew":"  /** Merges all segments together into a single segment,\n   * optimizing an index for search.\n   * \n   * <p>Note that this requires substantial temporary free\n   * space in the Directory (see <a target=\"_top\"\n   * href=\"http://issues.apache.org/jira/browse/LUCENE-764\">LUCENE-764</a>\n   * for details):</p>\n   *\n   * <ul>\n   * <li>\n   * \n   * <p>If no readers/searchers are open against the index,\n   * then free space required is up to 1X the total size of\n   * the starting index.  For example, if the starting\n   * index is 10 GB, then you must have up to 10 GB of free\n   * space before calling optimize.</p>\n   *\n   * <li>\n   * \n   * <p>If readers/searchers are using the index, then free\n   * space required is up to 2X the size of the starting\n   * index.  This is because in addition to the 1X used by\n   * optimize, the original 1X of the starting index is\n   * still consuming space in the Directory as the readers\n   * are holding the segments files open.  Even on Unix,\n   * where it will appear as if the files are gone (\"ls\"\n   * won't list them), they still consume storage due to\n   * \"delete on last close\" semantics.</p>\n   * \n   * <p>Furthermore, if some but not all readers re-open\n   * while the optimize is underway, this will cause > 2X\n   * temporary space to be consumed as those new readers\n   * will then hold open the partially optimized segments at\n   * that time.  It is best not to re-open readers while\n   * optimize is running.</p>\n   *\n   * </ul>\n   *\n   * <p>The actual temporary usage could be much less than\n   * these figures (it depends on many factors).</p>\n   *\n   * <p>Once the optimize completes, the total size of the\n   * index will be less than the size of the starting index.\n   * It could be quite a bit smaller (if there were many\n   * pending deletes) or just slightly smaller.</p>\n   *\n   * <p>If an Exception is hit during optimize(), for example\n   * due to disk full, the index will not be corrupt and no\n   * documents will have been lost.  However, it may have\n   * been partially optimized (some segments were merged but\n   * not all), and it's possible that one of the segments in\n   * the index will be in non-compound format even when\n   * using compound file format.  This will occur when the\n   * Exception is hit during conversion of the segment into\n   * compound format.</p>\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n  */\n  public synchronized void optimize() throws CorruptIndexException, IOException {\n    ensureOpen();\n    flushRamSegments();\n    while (segmentInfos.size() > 1 ||\n           (segmentInfos.size() == 1 &&\n            (SegmentReader.hasDeletions(segmentInfos.info(0)) ||\n             SegmentReader.hasSeparateNorms(segmentInfos.info(0)) ||\n             segmentInfos.info(0).dir != directory ||\n             (useCompoundFile &&\n              (!SegmentReader.usesCompoundFile(segmentInfos.info(0))))))) {\n      int minSegment = segmentInfos.size() - mergeFactor;\n      mergeSegments(segmentInfos, minSegment < 0 ? 0 : minSegment, segmentInfos.size());\n    }\n  }\n\n","sourceOld":"  /** Merges all segments together into a single segment,\n   * optimizing an index for search.\n   * \n   * <p>Note that this requires substantial temporary free\n   * space in the Directory (see <a target=\"_top\"\n   * href=\"http://issues.apache.org/jira/browse/LUCENE-764\">LUCENE-764</a>\n   * for details):</p>\n   *\n   * <ul>\n   * <li>\n   * \n   * <p>If no readers/searchers are open against the index,\n   * then free space required is up to 1X the total size of\n   * the starting index.  For example, if the starting\n   * index is 10 GB, then you must have up to 10 GB of free\n   * space before calling optimize.</p>\n   *\n   * <li>\n   * \n   * <p>If readers/searchers are using the index, then free\n   * space required is up to 2X the size of the starting\n   * index.  This is because in addition to the 1X used by\n   * optimize, the original 1X of the starting index is\n   * still consuming space in the Directory as the readers\n   * are holding the segments files open.  Even on Unix,\n   * where it will appear as if the files are gone (\"ls\"\n   * won't list them), they still consume storage due to\n   * \"delete on last close\" semantics.</p>\n   * \n   * <p>Furthermore, if some but not all readers re-open\n   * while the optimize is underway, this will cause > 2X\n   * temporary space to be consumed as those new readers\n   * will then hold open the partially optimized segments at\n   * that time.  It is best not to re-open readers while\n   * optimize is running.</p>\n   *\n   * </ul>\n   *\n   * <p>The actual temporary usage could be much less than\n   * these figures (it depends on many factors).</p>\n   *\n   * <p>Once the optimize completes, the total size of the\n   * index will be less than the size of the starting index.\n   * It could be quite a bit smaller (if there were many\n   * pending deletes) or just slightly smaller.</p>\n   *\n   * <p>If an Exception is hit during optimize(), for example\n   * due to disk full, the index will not be corrupt and no\n   * documents will have been lost.  However, it may have\n   * been partially optimized (some segments were merged but\n   * not all), and it's possible that one of the segments in\n   * the index will be in non-compound format even when\n   * using compound file format.  This will occur when the\n   * Exception is hit during conversion of the segment into\n   * compound format.</p>\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n  */\n  public synchronized void optimize() throws CorruptIndexException, IOException {\n    flushRamSegments();\n    while (segmentInfos.size() > 1 ||\n           (segmentInfos.size() == 1 &&\n            (SegmentReader.hasDeletions(segmentInfos.info(0)) ||\n             SegmentReader.hasSeparateNorms(segmentInfos.info(0)) ||\n             segmentInfos.info(0).dir != directory ||\n             (useCompoundFile &&\n              (!SegmentReader.usesCompoundFile(segmentInfos.info(0))))))) {\n      int minSegment = segmentInfos.size() - mergeFactor;\n      mergeSegments(segmentInfos, minSegment < 0 ? 0 : minSegment, segmentInfos.size());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f928a980971a857c3691519cf634d09b2304937c","date":1176386529,"type":3,"author":"Grant Ingersoll","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","sourceNew":"  /** Merges all segments together into a single segment,\n   * optimizing an index for search.\n   *\n   * <p>It is recommended that this method be called upon completion of indexing.  In\n   * environments with frequent updates, optimize is best done during low volume times, if at all. \n   * \n   * </p>\n   * <p>See http://www.gossamer-threads.com/lists/lucene/java-dev/47895 for more discussion. </p>\n   *\n   * <p>Note that this requires substantial temporary free\n   * space in the Directory (see <a target=\"_top\"\n   * href=\"http://issues.apache.org/jira/browse/LUCENE-764\">LUCENE-764</a>\n   * for details):</p>\n   *\n   * <ul>\n   * <li>\n   * \n   * <p>If no readers/searchers are open against the index,\n   * then free space required is up to 1X the total size of\n   * the starting index.  For example, if the starting\n   * index is 10 GB, then you must have up to 10 GB of free\n   * space before calling optimize.</p>\n   *\n   * <li>\n   * \n   * <p>If readers/searchers are using the index, then free\n   * space required is up to 2X the size of the starting\n   * index.  This is because in addition to the 1X used by\n   * optimize, the original 1X of the starting index is\n   * still consuming space in the Directory as the readers\n   * are holding the segments files open.  Even on Unix,\n   * where it will appear as if the files are gone (\"ls\"\n   * won't list them), they still consume storage due to\n   * \"delete on last close\" semantics.</p>\n   * \n   * <p>Furthermore, if some but not all readers re-open\n   * while the optimize is underway, this will cause > 2X\n   * temporary space to be consumed as those new readers\n   * will then hold open the partially optimized segments at\n   * that time.  It is best not to re-open readers while\n   * optimize is running.</p>\n   *\n   * </ul>\n   *\n   * <p>The actual temporary usage could be much less than\n   * these figures (it depends on many factors).</p>\n   *\n   * <p>Once the optimize completes, the total size of the\n   * index will be less than the size of the starting index.\n   * It could be quite a bit smaller (if there were many\n   * pending deletes) or just slightly smaller.</p>\n   *\n   * <p>If an Exception is hit during optimize(), for example\n   * due to disk full, the index will not be corrupt and no\n   * documents will have been lost.  However, it may have\n   * been partially optimized (some segments were merged but\n   * not all), and it's possible that one of the segments in\n   * the index will be in non-compound format even when\n   * using compound file format.  This will occur when the\n   * Exception is hit during conversion of the segment into\n   * compound format.</p>\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n  */\n  public synchronized void optimize() throws CorruptIndexException, IOException {\n    ensureOpen();\n    flushRamSegments();\n    while (segmentInfos.size() > 1 ||\n           (segmentInfos.size() == 1 &&\n            (SegmentReader.hasDeletions(segmentInfos.info(0)) ||\n             SegmentReader.hasSeparateNorms(segmentInfos.info(0)) ||\n             segmentInfos.info(0).dir != directory ||\n             (useCompoundFile &&\n              (!SegmentReader.usesCompoundFile(segmentInfos.info(0))))))) {\n      int minSegment = segmentInfos.size() - mergeFactor;\n      mergeSegments(segmentInfos, minSegment < 0 ? 0 : minSegment, segmentInfos.size());\n    }\n  }\n\n","sourceOld":"  /** Merges all segments together into a single segment,\n   * optimizing an index for search.\n   * \n   * <p>Note that this requires substantial temporary free\n   * space in the Directory (see <a target=\"_top\"\n   * href=\"http://issues.apache.org/jira/browse/LUCENE-764\">LUCENE-764</a>\n   * for details):</p>\n   *\n   * <ul>\n   * <li>\n   * \n   * <p>If no readers/searchers are open against the index,\n   * then free space required is up to 1X the total size of\n   * the starting index.  For example, if the starting\n   * index is 10 GB, then you must have up to 10 GB of free\n   * space before calling optimize.</p>\n   *\n   * <li>\n   * \n   * <p>If readers/searchers are using the index, then free\n   * space required is up to 2X the size of the starting\n   * index.  This is because in addition to the 1X used by\n   * optimize, the original 1X of the starting index is\n   * still consuming space in the Directory as the readers\n   * are holding the segments files open.  Even on Unix,\n   * where it will appear as if the files are gone (\"ls\"\n   * won't list them), they still consume storage due to\n   * \"delete on last close\" semantics.</p>\n   * \n   * <p>Furthermore, if some but not all readers re-open\n   * while the optimize is underway, this will cause > 2X\n   * temporary space to be consumed as those new readers\n   * will then hold open the partially optimized segments at\n   * that time.  It is best not to re-open readers while\n   * optimize is running.</p>\n   *\n   * </ul>\n   *\n   * <p>The actual temporary usage could be much less than\n   * these figures (it depends on many factors).</p>\n   *\n   * <p>Once the optimize completes, the total size of the\n   * index will be less than the size of the starting index.\n   * It could be quite a bit smaller (if there were many\n   * pending deletes) or just slightly smaller.</p>\n   *\n   * <p>If an Exception is hit during optimize(), for example\n   * due to disk full, the index will not be corrupt and no\n   * documents will have been lost.  However, it may have\n   * been partially optimized (some segments were merged but\n   * not all), and it's possible that one of the segments in\n   * the index will be in non-compound format even when\n   * using compound file format.  This will occur when the\n   * Exception is hit during conversion of the segment into\n   * compound format.</p>\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n  */\n  public synchronized void optimize() throws CorruptIndexException, IOException {\n    ensureOpen();\n    flushRamSegments();\n    while (segmentInfos.size() > 1 ||\n           (segmentInfos.size() == 1 &&\n            (SegmentReader.hasDeletions(segmentInfos.info(0)) ||\n             SegmentReader.hasSeparateNorms(segmentInfos.info(0)) ||\n             segmentInfos.info(0).dir != directory ||\n             (useCompoundFile &&\n              (!SegmentReader.usesCompoundFile(segmentInfos.info(0))))))) {\n      int minSegment = segmentInfos.size() - mergeFactor;\n      mergeSegments(segmentInfos, minSegment < 0 ? 0 : minSegment, segmentInfos.size());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4350b17bd363cd13a95171b8df1ca62ea4c3e71c","date":1183562198,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","sourceNew":"  /** Merges all segments together into a single segment,\n   * optimizing an index for search.\n   *\n   * <p>It is recommended that this method be called upon completion of indexing.  In\n   * environments with frequent updates, optimize is best done during low volume times, if at all. \n   * \n   * </p>\n   * <p>See http://www.gossamer-threads.com/lists/lucene/java-dev/47895 for more discussion. </p>\n   *\n   * <p>Note that this requires substantial temporary free\n   * space in the Directory (see <a target=\"_top\"\n   * href=\"http://issues.apache.org/jira/browse/LUCENE-764\">LUCENE-764</a>\n   * for details):</p>\n   *\n   * <ul>\n   * <li>\n   * \n   * <p>If no readers/searchers are open against the index,\n   * then free space required is up to 1X the total size of\n   * the starting index.  For example, if the starting\n   * index is 10 GB, then you must have up to 10 GB of free\n   * space before calling optimize.</p>\n   *\n   * <li>\n   * \n   * <p>If readers/searchers are using the index, then free\n   * space required is up to 2X the size of the starting\n   * index.  This is because in addition to the 1X used by\n   * optimize, the original 1X of the starting index is\n   * still consuming space in the Directory as the readers\n   * are holding the segments files open.  Even on Unix,\n   * where it will appear as if the files are gone (\"ls\"\n   * won't list them), they still consume storage due to\n   * \"delete on last close\" semantics.</p>\n   * \n   * <p>Furthermore, if some but not all readers re-open\n   * while the optimize is underway, this will cause > 2X\n   * temporary space to be consumed as those new readers\n   * will then hold open the partially optimized segments at\n   * that time.  It is best not to re-open readers while\n   * optimize is running.</p>\n   *\n   * </ul>\n   *\n   * <p>The actual temporary usage could be much less than\n   * these figures (it depends on many factors).</p>\n   *\n   * <p>Once the optimize completes, the total size of the\n   * index will be less than the size of the starting index.\n   * It could be quite a bit smaller (if there were many\n   * pending deletes) or just slightly smaller.</p>\n   *\n   * <p>If an Exception is hit during optimize(), for example\n   * due to disk full, the index will not be corrupt and no\n   * documents will have been lost.  However, it may have\n   * been partially optimized (some segments were merged but\n   * not all), and it's possible that one of the segments in\n   * the index will be in non-compound format even when\n   * using compound file format.  This will occur when the\n   * Exception is hit during conversion of the segment into\n   * compound format.</p>\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n  */\n  public synchronized void optimize() throws CorruptIndexException, IOException {\n    ensureOpen();\n    flush();\n    while (segmentInfos.size() > 1 ||\n           (segmentInfos.size() == 1 &&\n            (SegmentReader.hasDeletions(segmentInfos.info(0)) ||\n             SegmentReader.hasSeparateNorms(segmentInfos.info(0)) ||\n             segmentInfos.info(0).dir != directory ||\n             (useCompoundFile &&\n              !segmentInfos.info(0).getUseCompoundFile())))) {\n      int minSegment = segmentInfos.size() - mergeFactor;\n      mergeSegments(minSegment < 0 ? 0 : minSegment, segmentInfos.size());\n    }\n  }\n\n","sourceOld":"  /** Merges all segments together into a single segment,\n   * optimizing an index for search.\n   *\n   * <p>It is recommended that this method be called upon completion of indexing.  In\n   * environments with frequent updates, optimize is best done during low volume times, if at all. \n   * \n   * </p>\n   * <p>See http://www.gossamer-threads.com/lists/lucene/java-dev/47895 for more discussion. </p>\n   *\n   * <p>Note that this requires substantial temporary free\n   * space in the Directory (see <a target=\"_top\"\n   * href=\"http://issues.apache.org/jira/browse/LUCENE-764\">LUCENE-764</a>\n   * for details):</p>\n   *\n   * <ul>\n   * <li>\n   * \n   * <p>If no readers/searchers are open against the index,\n   * then free space required is up to 1X the total size of\n   * the starting index.  For example, if the starting\n   * index is 10 GB, then you must have up to 10 GB of free\n   * space before calling optimize.</p>\n   *\n   * <li>\n   * \n   * <p>If readers/searchers are using the index, then free\n   * space required is up to 2X the size of the starting\n   * index.  This is because in addition to the 1X used by\n   * optimize, the original 1X of the starting index is\n   * still consuming space in the Directory as the readers\n   * are holding the segments files open.  Even on Unix,\n   * where it will appear as if the files are gone (\"ls\"\n   * won't list them), they still consume storage due to\n   * \"delete on last close\" semantics.</p>\n   * \n   * <p>Furthermore, if some but not all readers re-open\n   * while the optimize is underway, this will cause > 2X\n   * temporary space to be consumed as those new readers\n   * will then hold open the partially optimized segments at\n   * that time.  It is best not to re-open readers while\n   * optimize is running.</p>\n   *\n   * </ul>\n   *\n   * <p>The actual temporary usage could be much less than\n   * these figures (it depends on many factors).</p>\n   *\n   * <p>Once the optimize completes, the total size of the\n   * index will be less than the size of the starting index.\n   * It could be quite a bit smaller (if there were many\n   * pending deletes) or just slightly smaller.</p>\n   *\n   * <p>If an Exception is hit during optimize(), for example\n   * due to disk full, the index will not be corrupt and no\n   * documents will have been lost.  However, it may have\n   * been partially optimized (some segments were merged but\n   * not all), and it's possible that one of the segments in\n   * the index will be in non-compound format even when\n   * using compound file format.  This will occur when the\n   * Exception is hit during conversion of the segment into\n   * compound format.</p>\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n  */\n  public synchronized void optimize() throws CorruptIndexException, IOException {\n    ensureOpen();\n    flushRamSegments();\n    while (segmentInfos.size() > 1 ||\n           (segmentInfos.size() == 1 &&\n            (SegmentReader.hasDeletions(segmentInfos.info(0)) ||\n             SegmentReader.hasSeparateNorms(segmentInfos.info(0)) ||\n             segmentInfos.info(0).dir != directory ||\n             (useCompoundFile &&\n              (!SegmentReader.usesCompoundFile(segmentInfos.info(0))))))) {\n      int minSegment = segmentInfos.size() - mergeFactor;\n      mergeSegments(segmentInfos, minSegment < 0 ? 0 : minSegment, segmentInfos.size());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b1405362241b561f5590ff4a87d5d6e173bcd9cf","date":1190107634,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","sourceNew":"  /**\n   * Requests an \"optimize\" operation on an index, priming the index\n   * for the fastest available search. Traditionally this has meant\n   * merging all segments into a single segment as is done in the\n   * default merge policy, but individaul merge policies may implement\n   * optimize in different ways.\n   *\n   * @see LogMergePolicy#findMergesForOptimize\n   *\n   * <p>It is recommended that this method be called upon completion of indexing.  In\n   * environments with frequent updates, optimize is best done during low volume times, if at all. \n   * \n   * </p>\n   * <p>See http://www.gossamer-threads.com/lists/lucene/java-dev/47895 for more discussion. </p>\n   *\n   * <p>Note that this can require substantial temporary free\n   * space in the Directory (see <a target=\"_top\"\n   * href=\"http://issues.apache.org/jira/browse/LUCENE-764\">LUCENE-764</a>\n   * for details):</p>\n   *\n   * <ul>\n   * <li>\n   * \n   * <p>If no readers/searchers are open against the index,\n   * then free space required is up to 1X the total size of\n   * the starting index.  For example, if the starting\n   * index is 10 GB, then you must have up to 10 GB of free\n   * space before calling optimize.</p>\n   *\n   * <li>\n   * \n   * <p>If readers/searchers are using the index, then free\n   * space required is up to 2X the size of the starting\n   * index.  This is because in addition to the 1X used by\n   * optimize, the original 1X of the starting index is\n   * still consuming space in the Directory as the readers\n   * are holding the segments files open.  Even on Unix,\n   * where it will appear as if the files are gone (\"ls\"\n   * won't list them), they still consume storage due to\n   * \"delete on last close\" semantics.</p>\n   * \n   * <p>Furthermore, if some but not all readers re-open\n   * while the optimize is underway, this will cause > 2X\n   * temporary space to be consumed as those new readers\n   * will then hold open the partially optimized segments at\n   * that time.  It is best not to re-open readers while\n   * optimize is running.</p>\n   *\n   * </ul>\n   *\n   * <p>The actual temporary usage could be much less than\n   * these figures (it depends on many factors).</p>\n   *\n   * <p>In general, once the optimize completes, the total size of the\n   * index will be less than the size of the starting index.\n   * It could be quite a bit smaller (if there were many\n   * pending deletes) or just slightly smaller.</p>\n   *\n   * <p>If an Exception is hit during optimize(), for example\n   * due to disk full, the index will not be corrupt and no\n   * documents will have been lost.  However, it may have\n   * been partially optimized (some segments were merged but\n   * not all), and it's possible that one of the segments in\n   * the index will be in non-compound format even when\n   * using compound file format.  This will occur when the\n   * Exception is hit during conversion of the segment into\n   * compound format.</p>\n   *\n   * <p>This call will optimize those segments present in\n   * the index when the call started.  If other threads are\n   * still adding documents and flushing segments, those\n   * newly created segments will not be optimized unless you\n   * call optimize again.</p>\n   *\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n  */\n  public void optimize() throws CorruptIndexException, IOException {\n    optimize(true);\n  }\n\n","sourceOld":"  /** Merges all segments together into a single segment,\n   * optimizing an index for search.\n   *\n   * <p>It is recommended that this method be called upon completion of indexing.  In\n   * environments with frequent updates, optimize is best done during low volume times, if at all. \n   * \n   * </p>\n   * <p>See http://www.gossamer-threads.com/lists/lucene/java-dev/47895 for more discussion. </p>\n   *\n   * <p>Note that this requires substantial temporary free\n   * space in the Directory (see <a target=\"_top\"\n   * href=\"http://issues.apache.org/jira/browse/LUCENE-764\">LUCENE-764</a>\n   * for details):</p>\n   *\n   * <ul>\n   * <li>\n   * \n   * <p>If no readers/searchers are open against the index,\n   * then free space required is up to 1X the total size of\n   * the starting index.  For example, if the starting\n   * index is 10 GB, then you must have up to 10 GB of free\n   * space before calling optimize.</p>\n   *\n   * <li>\n   * \n   * <p>If readers/searchers are using the index, then free\n   * space required is up to 2X the size of the starting\n   * index.  This is because in addition to the 1X used by\n   * optimize, the original 1X of the starting index is\n   * still consuming space in the Directory as the readers\n   * are holding the segments files open.  Even on Unix,\n   * where it will appear as if the files are gone (\"ls\"\n   * won't list them), they still consume storage due to\n   * \"delete on last close\" semantics.</p>\n   * \n   * <p>Furthermore, if some but not all readers re-open\n   * while the optimize is underway, this will cause > 2X\n   * temporary space to be consumed as those new readers\n   * will then hold open the partially optimized segments at\n   * that time.  It is best not to re-open readers while\n   * optimize is running.</p>\n   *\n   * </ul>\n   *\n   * <p>The actual temporary usage could be much less than\n   * these figures (it depends on many factors).</p>\n   *\n   * <p>Once the optimize completes, the total size of the\n   * index will be less than the size of the starting index.\n   * It could be quite a bit smaller (if there were many\n   * pending deletes) or just slightly smaller.</p>\n   *\n   * <p>If an Exception is hit during optimize(), for example\n   * due to disk full, the index will not be corrupt and no\n   * documents will have been lost.  However, it may have\n   * been partially optimized (some segments were merged but\n   * not all), and it's possible that one of the segments in\n   * the index will be in non-compound format even when\n   * using compound file format.  This will occur when the\n   * Exception is hit during conversion of the segment into\n   * compound format.</p>\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n  */\n  public synchronized void optimize() throws CorruptIndexException, IOException {\n    ensureOpen();\n    flush();\n    while (segmentInfos.size() > 1 ||\n           (segmentInfos.size() == 1 &&\n            (SegmentReader.hasDeletions(segmentInfos.info(0)) ||\n             SegmentReader.hasSeparateNorms(segmentInfos.info(0)) ||\n             segmentInfos.info(0).dir != directory ||\n             (useCompoundFile &&\n              !segmentInfos.info(0).getUseCompoundFile())))) {\n      int minSegment = segmentInfos.size() - mergeFactor;\n      mergeSegments(minSegment < 0 ? 0 : minSegment, segmentInfos.size());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e9665d17707cc21b1db995118ff36129723139ab","date":1225384420,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","sourceNew":"  /**\n   * Requests an \"optimize\" operation on an index, priming the index\n   * for the fastest available search. Traditionally this has meant\n   * merging all segments into a single segment as is done in the\n   * default merge policy, but individaul merge policies may implement\n   * optimize in different ways.\n   *\n   * <p>It is recommended that this method be called upon completion of indexing.  In\n   * environments with frequent updates, optimize is best done during low volume times, if at all. \n   * \n   * </p>\n   * <p>See http://www.gossamer-threads.com/lists/lucene/java-dev/47895 for more discussion. </p>\n   *\n   * <p>Note that this can require substantial temporary free\n   * space in the Directory (see <a target=\"_top\"\n   * href=\"http://issues.apache.org/jira/browse/LUCENE-764\">LUCENE-764</a>\n   * for details):</p>\n   *\n   * <ul>\n   * <li>\n   * \n   * <p>If no readers/searchers are open against the index,\n   * then free space required is up to 1X the total size of\n   * the starting index.  For example, if the starting\n   * index is 10 GB, then you must have up to 10 GB of free\n   * space before calling optimize.</p>\n   *\n   * <li>\n   * \n   * <p>If readers/searchers are using the index, then free\n   * space required is up to 2X the size of the starting\n   * index.  This is because in addition to the 1X used by\n   * optimize, the original 1X of the starting index is\n   * still consuming space in the Directory as the readers\n   * are holding the segments files open.  Even on Unix,\n   * where it will appear as if the files are gone (\"ls\"\n   * won't list them), they still consume storage due to\n   * \"delete on last close\" semantics.</p>\n   * \n   * <p>Furthermore, if some but not all readers re-open\n   * while the optimize is underway, this will cause > 2X\n   * temporary space to be consumed as those new readers\n   * will then hold open the partially optimized segments at\n   * that time.  It is best not to re-open readers while\n   * optimize is running.</p>\n   *\n   * </ul>\n   *\n   * <p>The actual temporary usage could be much less than\n   * these figures (it depends on many factors).</p>\n   *\n   * <p>In general, once the optimize completes, the total size of the\n   * index will be less than the size of the starting index.\n   * It could be quite a bit smaller (if there were many\n   * pending deletes) or just slightly smaller.</p>\n   *\n   * <p>If an Exception is hit during optimize(), for example\n   * due to disk full, the index will not be corrupt and no\n   * documents will have been lost.  However, it may have\n   * been partially optimized (some segments were merged but\n   * not all), and it's possible that one of the segments in\n   * the index will be in non-compound format even when\n   * using compound file format.  This will occur when the\n   * Exception is hit during conversion of the segment into\n   * compound format.</p>\n   *\n   * <p>This call will optimize those segments present in\n   * the index when the call started.  If other threads are\n   * still adding documents and flushing segments, those\n   * newly created segments will not be optimized unless you\n   * call optimize again.</p>\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   * @see LogMergePolicy#findMergesForOptimize\n  */\n  public void optimize() throws CorruptIndexException, IOException {\n    optimize(true);\n  }\n\n","sourceOld":"  /**\n   * Requests an \"optimize\" operation on an index, priming the index\n   * for the fastest available search. Traditionally this has meant\n   * merging all segments into a single segment as is done in the\n   * default merge policy, but individaul merge policies may implement\n   * optimize in different ways.\n   *\n   * @see LogMergePolicy#findMergesForOptimize\n   *\n   * <p>It is recommended that this method be called upon completion of indexing.  In\n   * environments with frequent updates, optimize is best done during low volume times, if at all. \n   * \n   * </p>\n   * <p>See http://www.gossamer-threads.com/lists/lucene/java-dev/47895 for more discussion. </p>\n   *\n   * <p>Note that this can require substantial temporary free\n   * space in the Directory (see <a target=\"_top\"\n   * href=\"http://issues.apache.org/jira/browse/LUCENE-764\">LUCENE-764</a>\n   * for details):</p>\n   *\n   * <ul>\n   * <li>\n   * \n   * <p>If no readers/searchers are open against the index,\n   * then free space required is up to 1X the total size of\n   * the starting index.  For example, if the starting\n   * index is 10 GB, then you must have up to 10 GB of free\n   * space before calling optimize.</p>\n   *\n   * <li>\n   * \n   * <p>If readers/searchers are using the index, then free\n   * space required is up to 2X the size of the starting\n   * index.  This is because in addition to the 1X used by\n   * optimize, the original 1X of the starting index is\n   * still consuming space in the Directory as the readers\n   * are holding the segments files open.  Even on Unix,\n   * where it will appear as if the files are gone (\"ls\"\n   * won't list them), they still consume storage due to\n   * \"delete on last close\" semantics.</p>\n   * \n   * <p>Furthermore, if some but not all readers re-open\n   * while the optimize is underway, this will cause > 2X\n   * temporary space to be consumed as those new readers\n   * will then hold open the partially optimized segments at\n   * that time.  It is best not to re-open readers while\n   * optimize is running.</p>\n   *\n   * </ul>\n   *\n   * <p>The actual temporary usage could be much less than\n   * these figures (it depends on many factors).</p>\n   *\n   * <p>In general, once the optimize completes, the total size of the\n   * index will be less than the size of the starting index.\n   * It could be quite a bit smaller (if there were many\n   * pending deletes) or just slightly smaller.</p>\n   *\n   * <p>If an Exception is hit during optimize(), for example\n   * due to disk full, the index will not be corrupt and no\n   * documents will have been lost.  However, it may have\n   * been partially optimized (some segments were merged but\n   * not all), and it's possible that one of the segments in\n   * the index will be in non-compound format even when\n   * using compound file format.  This will occur when the\n   * Exception is hit during conversion of the segment into\n   * compound format.</p>\n   *\n   * <p>This call will optimize those segments present in\n   * the index when the call started.  If other threads are\n   * still adding documents and flushing segments, those\n   * newly created segments will not be optimized unless you\n   * call optimize again.</p>\n   *\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n  */\n  public void optimize() throws CorruptIndexException, IOException {\n    optimize(true);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"80681cc9c3774bc4805a346bee03516e133f9bdd","date":1238448661,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","sourceNew":"  /**\n   * Requests an \"optimize\" operation on an index, priming the index\n   * for the fastest available search. Traditionally this has meant\n   * merging all segments into a single segment as is done in the\n   * default merge policy, but individaul merge policies may implement\n   * optimize in different ways.\n   *\n   * <p>It is recommended that this method be called upon completion of indexing.  In\n   * environments with frequent updates, optimize is best done during low volume times, if at all. \n   * \n   * </p>\n   * <p>See http://www.gossamer-threads.com/lists/lucene/java-dev/47895 for more discussion. </p>\n   *\n   * <p>Note that optimize requires 2X the index size free\n   * space in your Directory.  For example, if your index\n   * size is 10 MB then you need 20 MB free for optimize to\n   * complete.</p>\n   *\n   * <p>If some but not all readers re-open while an\n   * optimize is underway, this will cause > 2X temporary\n   * space to be consumed as those new readers will then\n   * hold open the partially optimized segments at that\n   * time.  It is best not to re-open readers while optimize\n   * is running.</p>\n   *\n   * <p>The actual temporary usage could be much less than\n   * these figures (it depends on many factors).</p>\n   *\n   * <p>In general, once the optimize completes, the total size of the\n   * index will be less than the size of the starting index.\n   * It could be quite a bit smaller (if there were many\n   * pending deletes) or just slightly smaller.</p>\n   *\n   * <p>If an Exception is hit during optimize(), for example\n   * due to disk full, the index will not be corrupt and no\n   * documents will have been lost.  However, it may have\n   * been partially optimized (some segments were merged but\n   * not all), and it's possible that one of the segments in\n   * the index will be in non-compound format even when\n   * using compound file format.  This will occur when the\n   * Exception is hit during conversion of the segment into\n   * compound format.</p>\n   *\n   * <p>This call will optimize those segments present in\n   * the index when the call started.  If other threads are\n   * still adding documents and flushing segments, those\n   * newly created segments will not be optimized unless you\n   * call optimize again.</p>\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   * @see LogMergePolicy#findMergesForOptimize\n  */\n  public void optimize() throws CorruptIndexException, IOException {\n    optimize(true);\n  }\n\n","sourceOld":"  /**\n   * Requests an \"optimize\" operation on an index, priming the index\n   * for the fastest available search. Traditionally this has meant\n   * merging all segments into a single segment as is done in the\n   * default merge policy, but individaul merge policies may implement\n   * optimize in different ways.\n   *\n   * <p>It is recommended that this method be called upon completion of indexing.  In\n   * environments with frequent updates, optimize is best done during low volume times, if at all. \n   * \n   * </p>\n   * <p>See http://www.gossamer-threads.com/lists/lucene/java-dev/47895 for more discussion. </p>\n   *\n   * <p>Note that this can require substantial temporary free\n   * space in the Directory (see <a target=\"_top\"\n   * href=\"http://issues.apache.org/jira/browse/LUCENE-764\">LUCENE-764</a>\n   * for details):</p>\n   *\n   * <ul>\n   * <li>\n   * \n   * <p>If no readers/searchers are open against the index,\n   * then free space required is up to 1X the total size of\n   * the starting index.  For example, if the starting\n   * index is 10 GB, then you must have up to 10 GB of free\n   * space before calling optimize.</p>\n   *\n   * <li>\n   * \n   * <p>If readers/searchers are using the index, then free\n   * space required is up to 2X the size of the starting\n   * index.  This is because in addition to the 1X used by\n   * optimize, the original 1X of the starting index is\n   * still consuming space in the Directory as the readers\n   * are holding the segments files open.  Even on Unix,\n   * where it will appear as if the files are gone (\"ls\"\n   * won't list them), they still consume storage due to\n   * \"delete on last close\" semantics.</p>\n   * \n   * <p>Furthermore, if some but not all readers re-open\n   * while the optimize is underway, this will cause > 2X\n   * temporary space to be consumed as those new readers\n   * will then hold open the partially optimized segments at\n   * that time.  It is best not to re-open readers while\n   * optimize is running.</p>\n   *\n   * </ul>\n   *\n   * <p>The actual temporary usage could be much less than\n   * these figures (it depends on many factors).</p>\n   *\n   * <p>In general, once the optimize completes, the total size of the\n   * index will be less than the size of the starting index.\n   * It could be quite a bit smaller (if there were many\n   * pending deletes) or just slightly smaller.</p>\n   *\n   * <p>If an Exception is hit during optimize(), for example\n   * due to disk full, the index will not be corrupt and no\n   * documents will have been lost.  However, it may have\n   * been partially optimized (some segments were merged but\n   * not all), and it's possible that one of the segments in\n   * the index will be in non-compound format even when\n   * using compound file format.  This will occur when the\n   * Exception is hit during conversion of the segment into\n   * compound format.</p>\n   *\n   * <p>This call will optimize those segments present in\n   * the index when the call started.  If other threads are\n   * still adding documents and flushing segments, those\n   * newly created segments will not be optimized unless you\n   * call optimize again.</p>\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   * @see LogMergePolicy#findMergesForOptimize\n  */\n  public void optimize() throws CorruptIndexException, IOException {\n    optimize(true);\n  }\n\n","bugFix":null,"bugIntro":["8cac9bbcf5acbef2d0d83f6e9e32a22d71301db5"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"27d1573cbb0b66d39f76e4eaf9116c6cc058a663","date":1253291397,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","sourceNew":"  /**\n   * Requests an \"optimize\" operation on an index, priming the index\n   * for the fastest available search. Traditionally this has meant\n   * merging all segments into a single segment as is done in the\n   * default merge policy, but individual merge policies may implement\n   * optimize in different ways.\n   *\n   * <p>It is recommended that this method be called upon completion of indexing.  In\n   * environments with frequent updates, optimize is best done during low volume times, if at all. \n   * \n   * </p>\n   * <p>See http://www.gossamer-threads.com/lists/lucene/java-dev/47895 for more discussion. </p>\n   *\n   * <p>Note that optimize requires 2X the index size free\n   * space in your Directory.  For example, if your index\n   * size is 10 MB then you need 20 MB free for optimize to\n   * complete.</p>\n   *\n   * <p>If some but not all readers re-open while an\n   * optimize is underway, this will cause > 2X temporary\n   * space to be consumed as those new readers will then\n   * hold open the partially optimized segments at that\n   * time.  It is best not to re-open readers while optimize\n   * is running.</p>\n   *\n   * <p>The actual temporary usage could be much less than\n   * these figures (it depends on many factors).</p>\n   *\n   * <p>In general, once the optimize completes, the total size of the\n   * index will be less than the size of the starting index.\n   * It could be quite a bit smaller (if there were many\n   * pending deletes) or just slightly smaller.</p>\n   *\n   * <p>If an Exception is hit during optimize(), for example\n   * due to disk full, the index will not be corrupt and no\n   * documents will have been lost.  However, it may have\n   * been partially optimized (some segments were merged but\n   * not all), and it's possible that one of the segments in\n   * the index will be in non-compound format even when\n   * using compound file format.  This will occur when the\n   * Exception is hit during conversion of the segment into\n   * compound format.</p>\n   *\n   * <p>This call will optimize those segments present in\n   * the index when the call started.  If other threads are\n   * still adding documents and flushing segments, those\n   * newly created segments will not be optimized unless you\n   * call optimize again.</p>\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   * @see LogMergePolicy#findMergesForOptimize\n  */\n  public void optimize() throws CorruptIndexException, IOException {\n    optimize(true);\n  }\n\n","sourceOld":"  /**\n   * Requests an \"optimize\" operation on an index, priming the index\n   * for the fastest available search. Traditionally this has meant\n   * merging all segments into a single segment as is done in the\n   * default merge policy, but individaul merge policies may implement\n   * optimize in different ways.\n   *\n   * <p>It is recommended that this method be called upon completion of indexing.  In\n   * environments with frequent updates, optimize is best done during low volume times, if at all. \n   * \n   * </p>\n   * <p>See http://www.gossamer-threads.com/lists/lucene/java-dev/47895 for more discussion. </p>\n   *\n   * <p>Note that optimize requires 2X the index size free\n   * space in your Directory.  For example, if your index\n   * size is 10 MB then you need 20 MB free for optimize to\n   * complete.</p>\n   *\n   * <p>If some but not all readers re-open while an\n   * optimize is underway, this will cause > 2X temporary\n   * space to be consumed as those new readers will then\n   * hold open the partially optimized segments at that\n   * time.  It is best not to re-open readers while optimize\n   * is running.</p>\n   *\n   * <p>The actual temporary usage could be much less than\n   * these figures (it depends on many factors).</p>\n   *\n   * <p>In general, once the optimize completes, the total size of the\n   * index will be less than the size of the starting index.\n   * It could be quite a bit smaller (if there were many\n   * pending deletes) or just slightly smaller.</p>\n   *\n   * <p>If an Exception is hit during optimize(), for example\n   * due to disk full, the index will not be corrupt and no\n   * documents will have been lost.  However, it may have\n   * been partially optimized (some segments were merged but\n   * not all), and it's possible that one of the segments in\n   * the index will be in non-compound format even when\n   * using compound file format.  This will occur when the\n   * Exception is hit during conversion of the segment into\n   * compound format.</p>\n   *\n   * <p>This call will optimize those segments present in\n   * the index when the call started.  If other threads are\n   * still adding documents and flushing segments, those\n   * newly created segments will not be optimized unless you\n   * call optimize again.</p>\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   * @see LogMergePolicy#findMergesForOptimize\n  */\n  public void optimize() throws CorruptIndexException, IOException {\n    optimize(true);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b1910b847659c345749ba264675088e32b5ab9a2","date":1259095520,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","sourceNew":"  /**\n   * Requests an \"optimize\" operation on an index, priming the index\n   * for the fastest available search. Traditionally this has meant\n   * merging all segments into a single segment as is done in the\n   * default merge policy, but individual merge policies may implement\n   * optimize in different ways.\n   *\n   * <p> Optimize is a fairly costly operation, so you\n   * should only do it if your search performance really\n   * requires it.  Many search applications do fine never\n   * calling optimize. </p>\n   *\n   * <p>Note that optimize requires 2X the index size free\n   * space in your Directory.  For example, if your index\n   * size is 10 MB then you need 20 MB free for optimize to\n   * complete.  Also, it's best to call {@link #commit()}\n   * after the optimize completes to allow IndexWriter to\n   * free up disk space.</p>\n   *\n   * <p>If some but not all readers re-open while an\n   * optimize is underway, this will cause > 2X temporary\n   * space to be consumed as those new readers will then\n   * hold open the partially optimized segments at that\n   * time.  It is best not to re-open readers while optimize\n   * is running.</p>\n   *\n   * <p>The actual temporary usage could be much less than\n   * these figures (it depends on many factors).</p>\n   *\n   * <p>In general, once the optimize completes, the total size of the\n   * index will be less than the size of the starting index.\n   * It could be quite a bit smaller (if there were many\n   * pending deletes) or just slightly smaller.</p>\n   *\n   * <p>If an Exception is hit during optimize(), for example\n   * due to disk full, the index will not be corrupt and no\n   * documents will have been lost.  However, it may have\n   * been partially optimized (some segments were merged but\n   * not all), and it's possible that one of the segments in\n   * the index will be in non-compound format even when\n   * using compound file format.  This will occur when the\n   * Exception is hit during conversion of the segment into\n   * compound format.</p>\n   *\n   * <p>This call will optimize those segments present in\n   * the index when the call started.  If other threads are\n   * still adding documents and flushing segments, those\n   * newly created segments will not be optimized unless you\n   * call optimize again.</p>\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   * @see LogMergePolicy#findMergesForOptimize\n  */\n  public void optimize() throws CorruptIndexException, IOException {\n    optimize(true);\n  }\n\n","sourceOld":"  /**\n   * Requests an \"optimize\" operation on an index, priming the index\n   * for the fastest available search. Traditionally this has meant\n   * merging all segments into a single segment as is done in the\n   * default merge policy, but individual merge policies may implement\n   * optimize in different ways.\n   *\n   * <p>It is recommended that this method be called upon completion of indexing.  In\n   * environments with frequent updates, optimize is best done during low volume times, if at all. \n   * \n   * </p>\n   * <p>See http://www.gossamer-threads.com/lists/lucene/java-dev/47895 for more discussion. </p>\n   *\n   * <p>Note that optimize requires 2X the index size free\n   * space in your Directory.  For example, if your index\n   * size is 10 MB then you need 20 MB free for optimize to\n   * complete.</p>\n   *\n   * <p>If some but not all readers re-open while an\n   * optimize is underway, this will cause > 2X temporary\n   * space to be consumed as those new readers will then\n   * hold open the partially optimized segments at that\n   * time.  It is best not to re-open readers while optimize\n   * is running.</p>\n   *\n   * <p>The actual temporary usage could be much less than\n   * these figures (it depends on many factors).</p>\n   *\n   * <p>In general, once the optimize completes, the total size of the\n   * index will be less than the size of the starting index.\n   * It could be quite a bit smaller (if there were many\n   * pending deletes) or just slightly smaller.</p>\n   *\n   * <p>If an Exception is hit during optimize(), for example\n   * due to disk full, the index will not be corrupt and no\n   * documents will have been lost.  However, it may have\n   * been partially optimized (some segments were merged but\n   * not all), and it's possible that one of the segments in\n   * the index will be in non-compound format even when\n   * using compound file format.  This will occur when the\n   * Exception is hit during conversion of the segment into\n   * compound format.</p>\n   *\n   * <p>This call will optimize those segments present in\n   * the index when the call started.  If other threads are\n   * still adding documents and flushing segments, those\n   * newly created segments will not be optimized unless you\n   * call optimize again.</p>\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   * @see LogMergePolicy#findMergesForOptimize\n  */\n  public void optimize() throws CorruptIndexException, IOException {\n    optimize(true);\n  }\n\n","bugFix":null,"bugIntro":["8cac9bbcf5acbef2d0d83f6e9e32a22d71301db5"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","sourceNew":"  /**\n   * Requests an \"optimize\" operation on an index, priming the index\n   * for the fastest available search. Traditionally this has meant\n   * merging all segments into a single segment as is done in the\n   * default merge policy, but individual merge policies may implement\n   * optimize in different ways.\n   *\n   * <p> Optimize is a fairly costly operation, so you\n   * should only do it if your search performance really\n   * requires it.  Many search applications do fine never\n   * calling optimize. </p>\n   *\n   * <p>Note that optimize requires 2X the index size free\n   * space in your Directory.  For example, if your index\n   * size is 10 MB then you need 20 MB free for optimize to\n   * complete.  Also, it's best to call {@link #commit()}\n   * after the optimize completes to allow IndexWriter to\n   * free up disk space.</p>\n   *\n   * <p>If some but not all readers re-open while an\n   * optimize is underway, this will cause > 2X temporary\n   * space to be consumed as those new readers will then\n   * hold open the partially optimized segments at that\n   * time.  It is best not to re-open readers while optimize\n   * is running.</p>\n   *\n   * <p>The actual temporary usage could be much less than\n   * these figures (it depends on many factors).</p>\n   *\n   * <p>In general, once the optimize completes, the total size of the\n   * index will be less than the size of the starting index.\n   * It could be quite a bit smaller (if there were many\n   * pending deletes) or just slightly smaller.</p>\n   *\n   * <p>If an Exception is hit during optimize(), for example\n   * due to disk full, the index will not be corrupt and no\n   * documents will have been lost.  However, it may have\n   * been partially optimized (some segments were merged but\n   * not all), and it's possible that one of the segments in\n   * the index will be in non-compound format even when\n   * using compound file format.  This will occur when the\n   * Exception is hit during conversion of the segment into\n   * compound format.</p>\n   *\n   * <p>This call will optimize those segments present in\n   * the index when the call started.  If other threads are\n   * still adding documents and flushing segments, those\n   * newly created segments will not be optimized unless you\n   * call optimize again.</p>\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   * @see LogMergePolicy#findMergesForOptimize\n  */\n  public void optimize() throws CorruptIndexException, IOException {\n    optimize(true);\n  }\n\n","sourceOld":"  /**\n   * Requests an \"optimize\" operation on an index, priming the index\n   * for the fastest available search. Traditionally this has meant\n   * merging all segments into a single segment as is done in the\n   * default merge policy, but individual merge policies may implement\n   * optimize in different ways.\n   *\n   * <p> Optimize is a fairly costly operation, so you\n   * should only do it if your search performance really\n   * requires it.  Many search applications do fine never\n   * calling optimize. </p>\n   *\n   * <p>Note that optimize requires 2X the index size free\n   * space in your Directory.  For example, if your index\n   * size is 10 MB then you need 20 MB free for optimize to\n   * complete.  Also, it's best to call {@link #commit()}\n   * after the optimize completes to allow IndexWriter to\n   * free up disk space.</p>\n   *\n   * <p>If some but not all readers re-open while an\n   * optimize is underway, this will cause > 2X temporary\n   * space to be consumed as those new readers will then\n   * hold open the partially optimized segments at that\n   * time.  It is best not to re-open readers while optimize\n   * is running.</p>\n   *\n   * <p>The actual temporary usage could be much less than\n   * these figures (it depends on many factors).</p>\n   *\n   * <p>In general, once the optimize completes, the total size of the\n   * index will be less than the size of the starting index.\n   * It could be quite a bit smaller (if there were many\n   * pending deletes) or just slightly smaller.</p>\n   *\n   * <p>If an Exception is hit during optimize(), for example\n   * due to disk full, the index will not be corrupt and no\n   * documents will have been lost.  However, it may have\n   * been partially optimized (some segments were merged but\n   * not all), and it's possible that one of the segments in\n   * the index will be in non-compound format even when\n   * using compound file format.  This will occur when the\n   * Exception is hit during conversion of the segment into\n   * compound format.</p>\n   *\n   * <p>This call will optimize those segments present in\n   * the index when the call started.  If other threads are\n   * still adding documents and flushing segments, those\n   * newly created segments will not be optimized unless you\n   * call optimize again.</p>\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   * @see LogMergePolicy#findMergesForOptimize\n  */\n  public void optimize() throws CorruptIndexException, IOException {\n    optimize(true);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"d7052f725a053aa55424f966831826f61b798bf1":["1507a324c1f939ed71e01297733a49b9c36e5688"],"27d1573cbb0b66d39f76e4eaf9116c6cc058a663":["80681cc9c3774bc4805a346bee03516e133f9bdd"],"b1405362241b561f5590ff4a87d5d6e173bcd9cf":["4350b17bd363cd13a95171b8df1ca62ea4c3e71c"],"328c1568e471f0c6eaa49ec00334ca59e573710f":["1b54a9bc667895a2095a886184bf69a3179e63df"],"91109046a59c58ee0ee5d0d2767b08d1f30d6702":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"1b54a9bc667895a2095a886184bf69a3179e63df":["8969a184df55d25d61e85be785987fbf830d4028"],"8e38f34b073ce1e76079bad953c869de3067ec43":["f7961006605708cac1ca5185ead37902442ceff6"],"8fb95844e4ba5160067c64c5eb1cd8a09f7a94f1":["9c7454619ea6a0710272c1dd947345cee64489f6"],"4350b17bd363cd13a95171b8df1ca62ea4c3e71c":["f928a980971a857c3691519cf634d09b2304937c"],"80681cc9c3774bc4805a346bee03516e133f9bdd":["e9665d17707cc21b1db995118ff36129723139ab"],"e9665d17707cc21b1db995118ff36129723139ab":["b1405362241b561f5590ff4a87d5d6e173bcd9cf"],"f7961006605708cac1ca5185ead37902442ceff6":["8fb95844e4ba5160067c64c5eb1cd8a09f7a94f1"],"eeefd99c477417e5c7c574228461ebafe92469d4":["d7052f725a053aa55424f966831826f61b798bf1"],"b1910b847659c345749ba264675088e32b5ab9a2":["27d1573cbb0b66d39f76e4eaf9116c6cc058a663"],"1507a324c1f939ed71e01297733a49b9c36e5688":["8e38f34b073ce1e76079bad953c869de3067ec43"],"8f7478f1d67a81bf80f28067595be0383022d65b":["eeefd99c477417e5c7c574228461ebafe92469d4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"97ff927ed26c6ab8f288a4dbf5a20ac8ecf4abe1":["91109046a59c58ee0ee5d0d2767b08d1f30d6702"],"f928a980971a857c3691519cf634d09b2304937c":["328c1568e471f0c6eaa49ec00334ca59e573710f"],"9c7454619ea6a0710272c1dd947345cee64489f6":["97ff927ed26c6ab8f288a4dbf5a20ac8ecf4abe1"],"8969a184df55d25d61e85be785987fbf830d4028":["8f7478f1d67a81bf80f28067595be0383022d65b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["b1910b847659c345749ba264675088e32b5ab9a2"]},"commit2Childs":{"d7052f725a053aa55424f966831826f61b798bf1":["eeefd99c477417e5c7c574228461ebafe92469d4"],"27d1573cbb0b66d39f76e4eaf9116c6cc058a663":["b1910b847659c345749ba264675088e32b5ab9a2"],"b1405362241b561f5590ff4a87d5d6e173bcd9cf":["e9665d17707cc21b1db995118ff36129723139ab"],"328c1568e471f0c6eaa49ec00334ca59e573710f":["f928a980971a857c3691519cf634d09b2304937c"],"91109046a59c58ee0ee5d0d2767b08d1f30d6702":["97ff927ed26c6ab8f288a4dbf5a20ac8ecf4abe1"],"1b54a9bc667895a2095a886184bf69a3179e63df":["328c1568e471f0c6eaa49ec00334ca59e573710f"],"8e38f34b073ce1e76079bad953c869de3067ec43":["1507a324c1f939ed71e01297733a49b9c36e5688"],"8fb95844e4ba5160067c64c5eb1cd8a09f7a94f1":["f7961006605708cac1ca5185ead37902442ceff6"],"4350b17bd363cd13a95171b8df1ca62ea4c3e71c":["b1405362241b561f5590ff4a87d5d6e173bcd9cf"],"80681cc9c3774bc4805a346bee03516e133f9bdd":["27d1573cbb0b66d39f76e4eaf9116c6cc058a663"],"e9665d17707cc21b1db995118ff36129723139ab":["80681cc9c3774bc4805a346bee03516e133f9bdd"],"f7961006605708cac1ca5185ead37902442ceff6":["8e38f34b073ce1e76079bad953c869de3067ec43"],"eeefd99c477417e5c7c574228461ebafe92469d4":["8f7478f1d67a81bf80f28067595be0383022d65b"],"1507a324c1f939ed71e01297733a49b9c36e5688":["d7052f725a053aa55424f966831826f61b798bf1"],"b1910b847659c345749ba264675088e32b5ab9a2":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"8f7478f1d67a81bf80f28067595be0383022d65b":["8969a184df55d25d61e85be785987fbf830d4028"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["91109046a59c58ee0ee5d0d2767b08d1f30d6702"],"97ff927ed26c6ab8f288a4dbf5a20ac8ecf4abe1":["9c7454619ea6a0710272c1dd947345cee64489f6"],"9c7454619ea6a0710272c1dd947345cee64489f6":["8fb95844e4ba5160067c64c5eb1cd8a09f7a94f1"],"f928a980971a857c3691519cf634d09b2304937c":["4350b17bd363cd13a95171b8df1ca62ea4c3e71c"],"8969a184df55d25d61e85be785987fbf830d4028":["1b54a9bc667895a2095a886184bf69a3179e63df"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}