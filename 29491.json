{"path":"solr/core/src/java/org/apache/solr/search/GraphTermsQParserPlugin.GraphTermsQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","commits":[{"id":"9fc47cb7b4346802411bb432f501ed0673d7119e","date":1512640179,"type":1,"author":"Adrien Grand","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/GraphTermsQParserPlugin.GraphTermsQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/GraphTermsQParserPlugin.GraphTermsQuery#createWeight(IndexSearcher,boolean,float).mjava","sourceNew":"    @Override\n    public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n\n      List<TermContext> finalContexts = new ArrayList();\n      List<Term> finalTerms = new ArrayList();\n      List<LeafReaderContext> contexts = searcher.getTopReaderContext().leaves();\n      TermContext[] termContexts = new TermContext[this.queryTerms.length];\n      collectTermContext(searcher.getIndexReader(), contexts, termContexts, this.queryTerms);\n      for(int i=0; i<termContexts.length; i++) {\n        TermContext termContext = termContexts[i];\n        if(termContext != null && termContext.docFreq() <= this.maxDocFreq) {\n          finalContexts.add(termContext);\n          finalTerms.add(queryTerms[i]);\n        }\n      }\n\n      return new ConstantScoreWeight(this, boost) {\n\n        @Override\n        public void extractTerms(Set<Term> terms) {\n          // no-op\n          // This query is for abuse cases when the number of terms is too high to\n          // run efficiently as a BooleanQuery. So likewise we hide its terms in\n          // order to protect highlighters\n        }\n\n        private WeightOrDocIdSet rewrite(LeafReaderContext context) throws IOException {\n          final LeafReader reader = context.reader();\n          Terms terms = reader.terms(field);\n          if(terms == null) {\n            return new WeightOrDocIdSet(new BitDocIdSet(new FixedBitSet(reader.maxDoc()), 0));\n          }\n          TermsEnum  termsEnum = terms.iterator();\n          PostingsEnum docs = null;\n          DocIdSetBuilder builder = new DocIdSetBuilder(reader.maxDoc(), terms);\n          for (int i=0; i<finalContexts.size(); i++) {\n            TermContext termContext = finalContexts.get(i);\n            TermState termState = termContext.get(context.ord);\n            if(termState != null) {\n              Term term = finalTerms.get(i);\n              termsEnum.seekExact(term.bytes(), termContext.get(context.ord));\n              docs = termsEnum.postings(docs, PostingsEnum.NONE);\n              builder.add(docs);\n            }\n          }\n          return new WeightOrDocIdSet(builder.build());\n        }\n\n        private Scorer scorer(DocIdSet set) throws IOException {\n          if (set == null) {\n            return null;\n          }\n          final DocIdSetIterator disi = set.iterator();\n          if (disi == null) {\n            return null;\n          }\n          return new ConstantScoreScorer(this, score(), disi);\n        }\n\n        @Override\n        public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.bulkScorer(context);\n          } else {\n            final Scorer scorer = scorer(weightOrBitSet.set);\n            if (scorer == null) {\n              return null;\n            }\n            return new DefaultBulkScorer(scorer);\n          }\n        }\n\n        @Override\n        public Scorer scorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.scorer(context);\n          } else {\n            return scorer(weightOrBitSet.set);\n          }\n        }\n\n        @Override\n        public boolean isCacheable(LeafReaderContext ctx) {\n          return true;\n        }\n\n      };\n    }\n\n","sourceOld":"    @Override\n    public Weight createWeight(IndexSearcher searcher, boolean needsScores, float boost) throws IOException {\n\n      List<TermContext> finalContexts = new ArrayList();\n      List<Term> finalTerms = new ArrayList();\n      List<LeafReaderContext> contexts = searcher.getTopReaderContext().leaves();\n      TermContext[] termContexts = new TermContext[this.queryTerms.length];\n      collectTermContext(searcher.getIndexReader(), contexts, termContexts, this.queryTerms);\n      for(int i=0; i<termContexts.length; i++) {\n        TermContext termContext = termContexts[i];\n        if(termContext != null && termContext.docFreq() <= this.maxDocFreq) {\n          finalContexts.add(termContext);\n          finalTerms.add(queryTerms[i]);\n        }\n      }\n\n      return new ConstantScoreWeight(this, boost) {\n\n        @Override\n        public void extractTerms(Set<Term> terms) {\n          // no-op\n          // This query is for abuse cases when the number of terms is too high to\n          // run efficiently as a BooleanQuery. So likewise we hide its terms in\n          // order to protect highlighters\n        }\n\n        private WeightOrDocIdSet rewrite(LeafReaderContext context) throws IOException {\n          final LeafReader reader = context.reader();\n          Terms terms = reader.terms(field);\n          if(terms == null) {\n            return new WeightOrDocIdSet(new BitDocIdSet(new FixedBitSet(reader.maxDoc()), 0));\n          }\n          TermsEnum  termsEnum = terms.iterator();\n          PostingsEnum docs = null;\n          DocIdSetBuilder builder = new DocIdSetBuilder(reader.maxDoc(), terms);\n          for (int i=0; i<finalContexts.size(); i++) {\n            TermContext termContext = finalContexts.get(i);\n            TermState termState = termContext.get(context.ord);\n            if(termState != null) {\n              Term term = finalTerms.get(i);\n              termsEnum.seekExact(term.bytes(), termContext.get(context.ord));\n              docs = termsEnum.postings(docs, PostingsEnum.NONE);\n              builder.add(docs);\n            }\n          }\n          return new WeightOrDocIdSet(builder.build());\n        }\n\n        private Scorer scorer(DocIdSet set) throws IOException {\n          if (set == null) {\n            return null;\n          }\n          final DocIdSetIterator disi = set.iterator();\n          if (disi == null) {\n            return null;\n          }\n          return new ConstantScoreScorer(this, score(), disi);\n        }\n\n        @Override\n        public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.bulkScorer(context);\n          } else {\n            final Scorer scorer = scorer(weightOrBitSet.set);\n            if (scorer == null) {\n              return null;\n            }\n            return new DefaultBulkScorer(scorer);\n          }\n        }\n\n        @Override\n        public Scorer scorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.scorer(context);\n          } else {\n            return scorer(weightOrBitSet.set);\n          }\n        }\n\n        @Override\n        public boolean isCacheable(LeafReaderContext ctx) {\n          return true;\n        }\n\n      };\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"417142ff08fda9cf0b72d5133e63097a166c6458","date":1512729693,"type":1,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/GraphTermsQParserPlugin.GraphTermsQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/GraphTermsQParserPlugin.GraphTermsQuery#createWeight(IndexSearcher,boolean,float).mjava","sourceNew":"    @Override\n    public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n\n      List<TermContext> finalContexts = new ArrayList();\n      List<Term> finalTerms = new ArrayList();\n      List<LeafReaderContext> contexts = searcher.getTopReaderContext().leaves();\n      TermContext[] termContexts = new TermContext[this.queryTerms.length];\n      collectTermContext(searcher.getIndexReader(), contexts, termContexts, this.queryTerms);\n      for(int i=0; i<termContexts.length; i++) {\n        TermContext termContext = termContexts[i];\n        if(termContext != null && termContext.docFreq() <= this.maxDocFreq) {\n          finalContexts.add(termContext);\n          finalTerms.add(queryTerms[i]);\n        }\n      }\n\n      return new ConstantScoreWeight(this, boost) {\n\n        @Override\n        public void extractTerms(Set<Term> terms) {\n          // no-op\n          // This query is for abuse cases when the number of terms is too high to\n          // run efficiently as a BooleanQuery. So likewise we hide its terms in\n          // order to protect highlighters\n        }\n\n        private WeightOrDocIdSet rewrite(LeafReaderContext context) throws IOException {\n          final LeafReader reader = context.reader();\n          Terms terms = reader.terms(field);\n          if(terms == null) {\n            return new WeightOrDocIdSet(new BitDocIdSet(new FixedBitSet(reader.maxDoc()), 0));\n          }\n          TermsEnum  termsEnum = terms.iterator();\n          PostingsEnum docs = null;\n          DocIdSetBuilder builder = new DocIdSetBuilder(reader.maxDoc(), terms);\n          for (int i=0; i<finalContexts.size(); i++) {\n            TermContext termContext = finalContexts.get(i);\n            TermState termState = termContext.get(context.ord);\n            if(termState != null) {\n              Term term = finalTerms.get(i);\n              termsEnum.seekExact(term.bytes(), termContext.get(context.ord));\n              docs = termsEnum.postings(docs, PostingsEnum.NONE);\n              builder.add(docs);\n            }\n          }\n          return new WeightOrDocIdSet(builder.build());\n        }\n\n        private Scorer scorer(DocIdSet set) throws IOException {\n          if (set == null) {\n            return null;\n          }\n          final DocIdSetIterator disi = set.iterator();\n          if (disi == null) {\n            return null;\n          }\n          return new ConstantScoreScorer(this, score(), disi);\n        }\n\n        @Override\n        public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.bulkScorer(context);\n          } else {\n            final Scorer scorer = scorer(weightOrBitSet.set);\n            if (scorer == null) {\n              return null;\n            }\n            return new DefaultBulkScorer(scorer);\n          }\n        }\n\n        @Override\n        public Scorer scorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.scorer(context);\n          } else {\n            return scorer(weightOrBitSet.set);\n          }\n        }\n\n        @Override\n        public boolean isCacheable(LeafReaderContext ctx) {\n          return true;\n        }\n\n      };\n    }\n\n","sourceOld":"    @Override\n    public Weight createWeight(IndexSearcher searcher, boolean needsScores, float boost) throws IOException {\n\n      List<TermContext> finalContexts = new ArrayList();\n      List<Term> finalTerms = new ArrayList();\n      List<LeafReaderContext> contexts = searcher.getTopReaderContext().leaves();\n      TermContext[] termContexts = new TermContext[this.queryTerms.length];\n      collectTermContext(searcher.getIndexReader(), contexts, termContexts, this.queryTerms);\n      for(int i=0; i<termContexts.length; i++) {\n        TermContext termContext = termContexts[i];\n        if(termContext != null && termContext.docFreq() <= this.maxDocFreq) {\n          finalContexts.add(termContext);\n          finalTerms.add(queryTerms[i]);\n        }\n      }\n\n      return new ConstantScoreWeight(this, boost) {\n\n        @Override\n        public void extractTerms(Set<Term> terms) {\n          // no-op\n          // This query is for abuse cases when the number of terms is too high to\n          // run efficiently as a BooleanQuery. So likewise we hide its terms in\n          // order to protect highlighters\n        }\n\n        private WeightOrDocIdSet rewrite(LeafReaderContext context) throws IOException {\n          final LeafReader reader = context.reader();\n          Terms terms = reader.terms(field);\n          if(terms == null) {\n            return new WeightOrDocIdSet(new BitDocIdSet(new FixedBitSet(reader.maxDoc()), 0));\n          }\n          TermsEnum  termsEnum = terms.iterator();\n          PostingsEnum docs = null;\n          DocIdSetBuilder builder = new DocIdSetBuilder(reader.maxDoc(), terms);\n          for (int i=0; i<finalContexts.size(); i++) {\n            TermContext termContext = finalContexts.get(i);\n            TermState termState = termContext.get(context.ord);\n            if(termState != null) {\n              Term term = finalTerms.get(i);\n              termsEnum.seekExact(term.bytes(), termContext.get(context.ord));\n              docs = termsEnum.postings(docs, PostingsEnum.NONE);\n              builder.add(docs);\n            }\n          }\n          return new WeightOrDocIdSet(builder.build());\n        }\n\n        private Scorer scorer(DocIdSet set) throws IOException {\n          if (set == null) {\n            return null;\n          }\n          final DocIdSetIterator disi = set.iterator();\n          if (disi == null) {\n            return null;\n          }\n          return new ConstantScoreScorer(this, score(), disi);\n        }\n\n        @Override\n        public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.bulkScorer(context);\n          } else {\n            final Scorer scorer = scorer(weightOrBitSet.set);\n            if (scorer == null) {\n              return null;\n            }\n            return new DefaultBulkScorer(scorer);\n          }\n        }\n\n        @Override\n        public Scorer scorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.scorer(context);\n          } else {\n            return scorer(weightOrBitSet.set);\n          }\n        }\n\n        @Override\n        public boolean isCacheable(LeafReaderContext ctx) {\n          return true;\n        }\n\n      };\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a6e9f769521480a623f897c0d59089b919fa4239","date":1515161835,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/GraphTermsQParserPlugin.GraphTermsQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/GraphTermsQParserPlugin.GraphTermsQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","sourceNew":"    @Override\n    public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n\n      List<TermStates> finalContexts = new ArrayList();\n      List<Term> finalTerms = new ArrayList();\n      List<LeafReaderContext> contexts = searcher.getTopReaderContext().leaves();\n      TermStates[] termStates = new TermStates[this.queryTerms.length];\n      collectTermStates(searcher.getIndexReader(), contexts, termStates, this.queryTerms);\n      for(int i=0; i<termStates.length; i++) {\n        TermStates ts = termStates[i];\n        if(ts != null && ts.docFreq() <= this.maxDocFreq) {\n          finalContexts.add(ts);\n          finalTerms.add(queryTerms[i]);\n        }\n      }\n\n      return new ConstantScoreWeight(this, boost) {\n\n        @Override\n        public void extractTerms(Set<Term> terms) {\n          // no-op\n          // This query is for abuse cases when the number of terms is too high to\n          // run efficiently as a BooleanQuery. So likewise we hide its terms in\n          // order to protect highlighters\n        }\n\n        private WeightOrDocIdSet rewrite(LeafReaderContext context) throws IOException {\n          final LeafReader reader = context.reader();\n          Terms terms = reader.terms(field);\n          if(terms == null) {\n            return new WeightOrDocIdSet(new BitDocIdSet(new FixedBitSet(reader.maxDoc()), 0));\n          }\n          TermsEnum  termsEnum = terms.iterator();\n          PostingsEnum docs = null;\n          DocIdSetBuilder builder = new DocIdSetBuilder(reader.maxDoc(), terms);\n          for (int i=0; i<finalContexts.size(); i++) {\n            TermStates ts = finalContexts.get(i);\n            TermState termState = ts.get(context);\n            if(termState != null) {\n              Term term = finalTerms.get(i);\n              termsEnum.seekExact(term.bytes(), ts.get(context));\n              docs = termsEnum.postings(docs, PostingsEnum.NONE);\n              builder.add(docs);\n            }\n          }\n          return new WeightOrDocIdSet(builder.build());\n        }\n\n        private Scorer scorer(DocIdSet set) throws IOException {\n          if (set == null) {\n            return null;\n          }\n          final DocIdSetIterator disi = set.iterator();\n          if (disi == null) {\n            return null;\n          }\n          return new ConstantScoreScorer(this, score(), disi);\n        }\n\n        @Override\n        public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.bulkScorer(context);\n          } else {\n            final Scorer scorer = scorer(weightOrBitSet.set);\n            if (scorer == null) {\n              return null;\n            }\n            return new DefaultBulkScorer(scorer);\n          }\n        }\n\n        @Override\n        public Scorer scorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.scorer(context);\n          } else {\n            return scorer(weightOrBitSet.set);\n          }\n        }\n\n        @Override\n        public boolean isCacheable(LeafReaderContext ctx) {\n          return true;\n        }\n\n      };\n    }\n\n","sourceOld":"    @Override\n    public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n\n      List<TermContext> finalContexts = new ArrayList();\n      List<Term> finalTerms = new ArrayList();\n      List<LeafReaderContext> contexts = searcher.getTopReaderContext().leaves();\n      TermContext[] termContexts = new TermContext[this.queryTerms.length];\n      collectTermContext(searcher.getIndexReader(), contexts, termContexts, this.queryTerms);\n      for(int i=0; i<termContexts.length; i++) {\n        TermContext termContext = termContexts[i];\n        if(termContext != null && termContext.docFreq() <= this.maxDocFreq) {\n          finalContexts.add(termContext);\n          finalTerms.add(queryTerms[i]);\n        }\n      }\n\n      return new ConstantScoreWeight(this, boost) {\n\n        @Override\n        public void extractTerms(Set<Term> terms) {\n          // no-op\n          // This query is for abuse cases when the number of terms is too high to\n          // run efficiently as a BooleanQuery. So likewise we hide its terms in\n          // order to protect highlighters\n        }\n\n        private WeightOrDocIdSet rewrite(LeafReaderContext context) throws IOException {\n          final LeafReader reader = context.reader();\n          Terms terms = reader.terms(field);\n          if(terms == null) {\n            return new WeightOrDocIdSet(new BitDocIdSet(new FixedBitSet(reader.maxDoc()), 0));\n          }\n          TermsEnum  termsEnum = terms.iterator();\n          PostingsEnum docs = null;\n          DocIdSetBuilder builder = new DocIdSetBuilder(reader.maxDoc(), terms);\n          for (int i=0; i<finalContexts.size(); i++) {\n            TermContext termContext = finalContexts.get(i);\n            TermState termState = termContext.get(context.ord);\n            if(termState != null) {\n              Term term = finalTerms.get(i);\n              termsEnum.seekExact(term.bytes(), termContext.get(context.ord));\n              docs = termsEnum.postings(docs, PostingsEnum.NONE);\n              builder.add(docs);\n            }\n          }\n          return new WeightOrDocIdSet(builder.build());\n        }\n\n        private Scorer scorer(DocIdSet set) throws IOException {\n          if (set == null) {\n            return null;\n          }\n          final DocIdSetIterator disi = set.iterator();\n          if (disi == null) {\n            return null;\n          }\n          return new ConstantScoreScorer(this, score(), disi);\n        }\n\n        @Override\n        public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.bulkScorer(context);\n          } else {\n            final Scorer scorer = scorer(weightOrBitSet.set);\n            if (scorer == null) {\n              return null;\n            }\n            return new DefaultBulkScorer(scorer);\n          }\n        }\n\n        @Override\n        public Scorer scorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.scorer(context);\n          } else {\n            return scorer(weightOrBitSet.set);\n          }\n        }\n\n        @Override\n        public boolean isCacheable(LeafReaderContext ctx) {\n          return true;\n        }\n\n      };\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b94236357aaa22b76c10629851fe4e376e0cea82","date":1516710914,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/GraphTermsQParserPlugin.GraphTermsQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/GraphTermsQParserPlugin.GraphTermsQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","sourceNew":"    @Override\n    public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n\n      List<TermStates> finalContexts = new ArrayList();\n      List<Term> finalTerms = new ArrayList();\n      List<LeafReaderContext> contexts = searcher.getTopReaderContext().leaves();\n      TermStates[] termStates = new TermStates[this.queryTerms.length];\n      collectTermStates(searcher.getIndexReader(), contexts, termStates, this.queryTerms);\n      for(int i=0; i<termStates.length; i++) {\n        TermStates ts = termStates[i];\n        if(ts != null && ts.docFreq() <= this.maxDocFreq) {\n          finalContexts.add(ts);\n          finalTerms.add(queryTerms[i]);\n        }\n      }\n\n      return new ConstantScoreWeight(this, boost) {\n\n        @Override\n        public void extractTerms(Set<Term> terms) {\n          // no-op\n          // This query is for abuse cases when the number of terms is too high to\n          // run efficiently as a BooleanQuery. So likewise we hide its terms in\n          // order to protect highlighters\n        }\n\n        private WeightOrDocIdSet rewrite(LeafReaderContext context) throws IOException {\n          final LeafReader reader = context.reader();\n          Terms terms = reader.terms(field);\n          if(terms == null) {\n            return new WeightOrDocIdSet(new BitDocIdSet(new FixedBitSet(reader.maxDoc()), 0));\n          }\n          TermsEnum  termsEnum = terms.iterator();\n          PostingsEnum docs = null;\n          DocIdSetBuilder builder = new DocIdSetBuilder(reader.maxDoc(), terms);\n          for (int i=0; i<finalContexts.size(); i++) {\n            TermStates ts = finalContexts.get(i);\n            TermState termState = ts.get(context);\n            if(termState != null) {\n              Term term = finalTerms.get(i);\n              termsEnum.seekExact(term.bytes(), ts.get(context));\n              docs = termsEnum.postings(docs, PostingsEnum.NONE);\n              builder.add(docs);\n            }\n          }\n          return new WeightOrDocIdSet(builder.build());\n        }\n\n        private Scorer scorer(DocIdSet set) throws IOException {\n          if (set == null) {\n            return null;\n          }\n          final DocIdSetIterator disi = set.iterator();\n          if (disi == null) {\n            return null;\n          }\n          return new ConstantScoreScorer(this, score(), disi);\n        }\n\n        @Override\n        public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.bulkScorer(context);\n          } else {\n            final Scorer scorer = scorer(weightOrBitSet.set);\n            if (scorer == null) {\n              return null;\n            }\n            return new DefaultBulkScorer(scorer);\n          }\n        }\n\n        @Override\n        public Scorer scorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.scorer(context);\n          } else {\n            return scorer(weightOrBitSet.set);\n          }\n        }\n\n        @Override\n        public boolean isCacheable(LeafReaderContext ctx) {\n          return true;\n        }\n\n      };\n    }\n\n","sourceOld":"    @Override\n    public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n\n      List<TermContext> finalContexts = new ArrayList();\n      List<Term> finalTerms = new ArrayList();\n      List<LeafReaderContext> contexts = searcher.getTopReaderContext().leaves();\n      TermContext[] termContexts = new TermContext[this.queryTerms.length];\n      collectTermContext(searcher.getIndexReader(), contexts, termContexts, this.queryTerms);\n      for(int i=0; i<termContexts.length; i++) {\n        TermContext termContext = termContexts[i];\n        if(termContext != null && termContext.docFreq() <= this.maxDocFreq) {\n          finalContexts.add(termContext);\n          finalTerms.add(queryTerms[i]);\n        }\n      }\n\n      return new ConstantScoreWeight(this, boost) {\n\n        @Override\n        public void extractTerms(Set<Term> terms) {\n          // no-op\n          // This query is for abuse cases when the number of terms is too high to\n          // run efficiently as a BooleanQuery. So likewise we hide its terms in\n          // order to protect highlighters\n        }\n\n        private WeightOrDocIdSet rewrite(LeafReaderContext context) throws IOException {\n          final LeafReader reader = context.reader();\n          Terms terms = reader.terms(field);\n          if(terms == null) {\n            return new WeightOrDocIdSet(new BitDocIdSet(new FixedBitSet(reader.maxDoc()), 0));\n          }\n          TermsEnum  termsEnum = terms.iterator();\n          PostingsEnum docs = null;\n          DocIdSetBuilder builder = new DocIdSetBuilder(reader.maxDoc(), terms);\n          for (int i=0; i<finalContexts.size(); i++) {\n            TermContext termContext = finalContexts.get(i);\n            TermState termState = termContext.get(context.ord);\n            if(termState != null) {\n              Term term = finalTerms.get(i);\n              termsEnum.seekExact(term.bytes(), termContext.get(context.ord));\n              docs = termsEnum.postings(docs, PostingsEnum.NONE);\n              builder.add(docs);\n            }\n          }\n          return new WeightOrDocIdSet(builder.build());\n        }\n\n        private Scorer scorer(DocIdSet set) throws IOException {\n          if (set == null) {\n            return null;\n          }\n          final DocIdSetIterator disi = set.iterator();\n          if (disi == null) {\n            return null;\n          }\n          return new ConstantScoreScorer(this, score(), disi);\n        }\n\n        @Override\n        public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.bulkScorer(context);\n          } else {\n            final Scorer scorer = scorer(weightOrBitSet.set);\n            if (scorer == null) {\n              return null;\n            }\n            return new DefaultBulkScorer(scorer);\n          }\n        }\n\n        @Override\n        public Scorer scorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.scorer(context);\n          } else {\n            return scorer(weightOrBitSet.set);\n          }\n        }\n\n        @Override\n        public boolean isCacheable(LeafReaderContext ctx) {\n          return true;\n        }\n\n      };\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9c226b0eeb8b028f572020f459851a663a2c064e","date":1542377651,"type":3,"author":"Christophe Bismuth","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/GraphTermsQParserPlugin.GraphTermsQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/GraphTermsQParserPlugin.GraphTermsQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","sourceNew":"    @Override\n    public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n\n      List<TermStates> finalContexts = new ArrayList();\n      List<Term> finalTerms = new ArrayList();\n      List<LeafReaderContext> contexts = searcher.getTopReaderContext().leaves();\n      TermStates[] termStates = new TermStates[this.queryTerms.length];\n      collectTermStates(searcher.getIndexReader(), contexts, termStates, this.queryTerms);\n      for(int i=0; i<termStates.length; i++) {\n        TermStates ts = termStates[i];\n        if(ts != null && ts.docFreq() <= this.maxDocFreq) {\n          finalContexts.add(ts);\n          finalTerms.add(queryTerms[i]);\n        }\n      }\n\n      return new ConstantScoreWeight(this, boost) {\n\n        @Override\n        public void extractTerms(Set<Term> terms) {\n          // no-op\n          // This query is for abuse cases when the number of terms is too high to\n          // run efficiently as a BooleanQuery. So likewise we hide its terms in\n          // order to protect highlighters\n        }\n\n        private WeightOrDocIdSet rewrite(LeafReaderContext context) throws IOException {\n          final LeafReader reader = context.reader();\n          Terms terms = reader.terms(field);\n          if(terms == null) {\n            return new WeightOrDocIdSet(new BitDocIdSet(new FixedBitSet(reader.maxDoc()), 0));\n          }\n          TermsEnum  termsEnum = terms.iterator();\n          PostingsEnum docs = null;\n          DocIdSetBuilder builder = new DocIdSetBuilder(reader.maxDoc(), terms);\n          for (int i=0; i<finalContexts.size(); i++) {\n            TermStates ts = finalContexts.get(i);\n            TermState termState = ts.get(context);\n            if(termState != null) {\n              Term term = finalTerms.get(i);\n              termsEnum.seekExact(term.bytes(), ts.get(context));\n              docs = termsEnum.postings(docs, PostingsEnum.NONE);\n              builder.add(docs);\n            }\n          }\n          return new WeightOrDocIdSet(builder.build());\n        }\n\n        private Scorer scorer(DocIdSet set) throws IOException {\n          if (set == null) {\n            return null;\n          }\n          final DocIdSetIterator disi = set.iterator();\n          if (disi == null) {\n            return null;\n          }\n          return new ConstantScoreScorer(this, score(), scoreMode, disi);\n        }\n\n        @Override\n        public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.bulkScorer(context);\n          } else {\n            final Scorer scorer = scorer(weightOrBitSet.set);\n            if (scorer == null) {\n              return null;\n            }\n            return new DefaultBulkScorer(scorer);\n          }\n        }\n\n        @Override\n        public Scorer scorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.scorer(context);\n          } else {\n            return scorer(weightOrBitSet.set);\n          }\n        }\n\n        @Override\n        public boolean isCacheable(LeafReaderContext ctx) {\n          return true;\n        }\n\n      };\n    }\n\n","sourceOld":"    @Override\n    public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n\n      List<TermStates> finalContexts = new ArrayList();\n      List<Term> finalTerms = new ArrayList();\n      List<LeafReaderContext> contexts = searcher.getTopReaderContext().leaves();\n      TermStates[] termStates = new TermStates[this.queryTerms.length];\n      collectTermStates(searcher.getIndexReader(), contexts, termStates, this.queryTerms);\n      for(int i=0; i<termStates.length; i++) {\n        TermStates ts = termStates[i];\n        if(ts != null && ts.docFreq() <= this.maxDocFreq) {\n          finalContexts.add(ts);\n          finalTerms.add(queryTerms[i]);\n        }\n      }\n\n      return new ConstantScoreWeight(this, boost) {\n\n        @Override\n        public void extractTerms(Set<Term> terms) {\n          // no-op\n          // This query is for abuse cases when the number of terms is too high to\n          // run efficiently as a BooleanQuery. So likewise we hide its terms in\n          // order to protect highlighters\n        }\n\n        private WeightOrDocIdSet rewrite(LeafReaderContext context) throws IOException {\n          final LeafReader reader = context.reader();\n          Terms terms = reader.terms(field);\n          if(terms == null) {\n            return new WeightOrDocIdSet(new BitDocIdSet(new FixedBitSet(reader.maxDoc()), 0));\n          }\n          TermsEnum  termsEnum = terms.iterator();\n          PostingsEnum docs = null;\n          DocIdSetBuilder builder = new DocIdSetBuilder(reader.maxDoc(), terms);\n          for (int i=0; i<finalContexts.size(); i++) {\n            TermStates ts = finalContexts.get(i);\n            TermState termState = ts.get(context);\n            if(termState != null) {\n              Term term = finalTerms.get(i);\n              termsEnum.seekExact(term.bytes(), ts.get(context));\n              docs = termsEnum.postings(docs, PostingsEnum.NONE);\n              builder.add(docs);\n            }\n          }\n          return new WeightOrDocIdSet(builder.build());\n        }\n\n        private Scorer scorer(DocIdSet set) throws IOException {\n          if (set == null) {\n            return null;\n          }\n          final DocIdSetIterator disi = set.iterator();\n          if (disi == null) {\n            return null;\n          }\n          return new ConstantScoreScorer(this, score(), disi);\n        }\n\n        @Override\n        public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.bulkScorer(context);\n          } else {\n            final Scorer scorer = scorer(weightOrBitSet.set);\n            if (scorer == null) {\n              return null;\n            }\n            return new DefaultBulkScorer(scorer);\n          }\n        }\n\n        @Override\n        public Scorer scorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.scorer(context);\n          } else {\n            return scorer(weightOrBitSet.set);\n          }\n        }\n\n        @Override\n        public boolean isCacheable(LeafReaderContext ctx) {\n          return true;\n        }\n\n      };\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5b9ffb60dc4bdc972b1403ad2ab2f5b4d9ce4cf7","date":1552575873,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/GraphTermsQParserPlugin.GraphTermsQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/GraphTermsQParserPlugin.GraphTermsQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","sourceNew":"    @Override\n    public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n\n      List<TermStates> finalContexts = new ArrayList();\n      List<Term> finalTerms = new ArrayList();\n      List<LeafReaderContext> contexts = searcher.getTopReaderContext().leaves();\n      TermStates[] termStates = new TermStates[this.queryTerms.length];\n      collectTermStates(searcher.getIndexReader(), contexts, termStates, this.queryTerms);\n      for(int i=0; i<termStates.length; i++) {\n        TermStates ts = termStates[i];\n        if(ts != null && ts.docFreq() <= this.maxDocFreq) {\n          finalContexts.add(ts);\n          finalTerms.add(queryTerms[i]);\n        }\n      }\n\n      return new ConstantScoreWeight(this, boost) {\n\n        private WeightOrDocIdSet rewrite(LeafReaderContext context) throws IOException {\n          final LeafReader reader = context.reader();\n          Terms terms = reader.terms(field);\n          if(terms == null) {\n            return new WeightOrDocIdSet(new BitDocIdSet(new FixedBitSet(reader.maxDoc()), 0));\n          }\n          TermsEnum  termsEnum = terms.iterator();\n          PostingsEnum docs = null;\n          DocIdSetBuilder builder = new DocIdSetBuilder(reader.maxDoc(), terms);\n          for (int i=0; i<finalContexts.size(); i++) {\n            TermStates ts = finalContexts.get(i);\n            TermState termState = ts.get(context);\n            if(termState != null) {\n              Term term = finalTerms.get(i);\n              termsEnum.seekExact(term.bytes(), ts.get(context));\n              docs = termsEnum.postings(docs, PostingsEnum.NONE);\n              builder.add(docs);\n            }\n          }\n          return new WeightOrDocIdSet(builder.build());\n        }\n\n        private Scorer scorer(DocIdSet set) throws IOException {\n          if (set == null) {\n            return null;\n          }\n          final DocIdSetIterator disi = set.iterator();\n          if (disi == null) {\n            return null;\n          }\n          return new ConstantScoreScorer(this, score(), scoreMode, disi);\n        }\n\n        @Override\n        public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.bulkScorer(context);\n          } else {\n            final Scorer scorer = scorer(weightOrBitSet.set);\n            if (scorer == null) {\n              return null;\n            }\n            return new DefaultBulkScorer(scorer);\n          }\n        }\n\n        @Override\n        public Scorer scorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.scorer(context);\n          } else {\n            return scorer(weightOrBitSet.set);\n          }\n        }\n\n        @Override\n        public boolean isCacheable(LeafReaderContext ctx) {\n          return true;\n        }\n\n      };\n    }\n\n","sourceOld":"    @Override\n    public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n\n      List<TermStates> finalContexts = new ArrayList();\n      List<Term> finalTerms = new ArrayList();\n      List<LeafReaderContext> contexts = searcher.getTopReaderContext().leaves();\n      TermStates[] termStates = new TermStates[this.queryTerms.length];\n      collectTermStates(searcher.getIndexReader(), contexts, termStates, this.queryTerms);\n      for(int i=0; i<termStates.length; i++) {\n        TermStates ts = termStates[i];\n        if(ts != null && ts.docFreq() <= this.maxDocFreq) {\n          finalContexts.add(ts);\n          finalTerms.add(queryTerms[i]);\n        }\n      }\n\n      return new ConstantScoreWeight(this, boost) {\n\n        @Override\n        public void extractTerms(Set<Term> terms) {\n          // no-op\n          // This query is for abuse cases when the number of terms is too high to\n          // run efficiently as a BooleanQuery. So likewise we hide its terms in\n          // order to protect highlighters\n        }\n\n        private WeightOrDocIdSet rewrite(LeafReaderContext context) throws IOException {\n          final LeafReader reader = context.reader();\n          Terms terms = reader.terms(field);\n          if(terms == null) {\n            return new WeightOrDocIdSet(new BitDocIdSet(new FixedBitSet(reader.maxDoc()), 0));\n          }\n          TermsEnum  termsEnum = terms.iterator();\n          PostingsEnum docs = null;\n          DocIdSetBuilder builder = new DocIdSetBuilder(reader.maxDoc(), terms);\n          for (int i=0; i<finalContexts.size(); i++) {\n            TermStates ts = finalContexts.get(i);\n            TermState termState = ts.get(context);\n            if(termState != null) {\n              Term term = finalTerms.get(i);\n              termsEnum.seekExact(term.bytes(), ts.get(context));\n              docs = termsEnum.postings(docs, PostingsEnum.NONE);\n              builder.add(docs);\n            }\n          }\n          return new WeightOrDocIdSet(builder.build());\n        }\n\n        private Scorer scorer(DocIdSet set) throws IOException {\n          if (set == null) {\n            return null;\n          }\n          final DocIdSetIterator disi = set.iterator();\n          if (disi == null) {\n            return null;\n          }\n          return new ConstantScoreScorer(this, score(), scoreMode, disi);\n        }\n\n        @Override\n        public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.bulkScorer(context);\n          } else {\n            final Scorer scorer = scorer(weightOrBitSet.set);\n            if (scorer == null) {\n              return null;\n            }\n            return new DefaultBulkScorer(scorer);\n          }\n        }\n\n        @Override\n        public Scorer scorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.scorer(context);\n          } else {\n            return scorer(weightOrBitSet.set);\n          }\n        }\n\n        @Override\n        public boolean isCacheable(LeafReaderContext ctx) {\n          return true;\n        }\n\n      };\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c85073c7bb192ffda1ad397ced31d287279a2678","date":1588109547,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/GraphTermsQParserPlugin.GraphTermsQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/GraphTermsQParserPlugin.GraphTermsQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","sourceNew":"    @Override\n    public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n\n      List<TermStates> finalContexts = new ArrayList<>();\n      List<Term> finalTerms = new ArrayList<>();\n      {\n        List<LeafReaderContext> contexts = searcher.getTopReaderContext().leaves();\n        TermStates[] termStates = new TermStates[this.queryTerms.length];\n        collectTermStates(searcher.getIndexReader(), contexts, termStates, this.queryTerms);\n        for(int i=0; i<termStates.length; i++) {\n          TermStates ts = termStates[i];\n          if(ts != null && ts.docFreq() <= this.maxDocFreq) {\n            finalContexts.add(ts);\n            finalTerms.add(queryTerms[i]);\n          }\n        }\n      }\n\n      return new ConstantScoreWeight(this, boost) {\n\n        @Override\n        public Scorer scorer(LeafReaderContext context) throws IOException {\n          final LeafReader reader = context.reader();\n          Terms terms = reader.terms(field);\n          if (terms == null) {\n            return null;\n          }\n          TermsEnum  termsEnum = terms.iterator();\n          PostingsEnum docs = null;\n          DocIdSetBuilder builder = new DocIdSetBuilder(reader.maxDoc(), terms);\n          for (int i=0; i<finalContexts.size(); i++) {\n            TermStates ts = finalContexts.get(i);\n            TermState termState = ts.get(context);\n            if(termState != null) {\n              Term term = finalTerms.get(i);\n              termsEnum.seekExact(term.bytes(), ts.get(context));\n              docs = termsEnum.postings(docs, PostingsEnum.NONE);\n              builder.add(docs);\n            }\n          }\n          DocIdSet docIdSet = builder.build();\n          DocIdSetIterator disi = docIdSet.iterator();\n          return disi == null ? null : new ConstantScoreScorer(this, score(), scoreMode, disi);\n        }\n\n        @Override\n        public boolean isCacheable(LeafReaderContext ctx) {\n          return true;\n        }\n\n      };\n    }\n\n","sourceOld":"    @Override\n    public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n\n      List<TermStates> finalContexts = new ArrayList();\n      List<Term> finalTerms = new ArrayList();\n      List<LeafReaderContext> contexts = searcher.getTopReaderContext().leaves();\n      TermStates[] termStates = new TermStates[this.queryTerms.length];\n      collectTermStates(searcher.getIndexReader(), contexts, termStates, this.queryTerms);\n      for(int i=0; i<termStates.length; i++) {\n        TermStates ts = termStates[i];\n        if(ts != null && ts.docFreq() <= this.maxDocFreq) {\n          finalContexts.add(ts);\n          finalTerms.add(queryTerms[i]);\n        }\n      }\n\n      return new ConstantScoreWeight(this, boost) {\n\n        private WeightOrDocIdSet rewrite(LeafReaderContext context) throws IOException {\n          final LeafReader reader = context.reader();\n          Terms terms = reader.terms(field);\n          if(terms == null) {\n            return new WeightOrDocIdSet(new BitDocIdSet(new FixedBitSet(reader.maxDoc()), 0));\n          }\n          TermsEnum  termsEnum = terms.iterator();\n          PostingsEnum docs = null;\n          DocIdSetBuilder builder = new DocIdSetBuilder(reader.maxDoc(), terms);\n          for (int i=0; i<finalContexts.size(); i++) {\n            TermStates ts = finalContexts.get(i);\n            TermState termState = ts.get(context);\n            if(termState != null) {\n              Term term = finalTerms.get(i);\n              termsEnum.seekExact(term.bytes(), ts.get(context));\n              docs = termsEnum.postings(docs, PostingsEnum.NONE);\n              builder.add(docs);\n            }\n          }\n          return new WeightOrDocIdSet(builder.build());\n        }\n\n        private Scorer scorer(DocIdSet set) throws IOException {\n          if (set == null) {\n            return null;\n          }\n          final DocIdSetIterator disi = set.iterator();\n          if (disi == null) {\n            return null;\n          }\n          return new ConstantScoreScorer(this, score(), scoreMode, disi);\n        }\n\n        @Override\n        public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.bulkScorer(context);\n          } else {\n            final Scorer scorer = scorer(weightOrBitSet.set);\n            if (scorer == null) {\n              return null;\n            }\n            return new DefaultBulkScorer(scorer);\n          }\n        }\n\n        @Override\n        public Scorer scorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.scorer(context);\n          } else {\n            return scorer(weightOrBitSet.set);\n          }\n        }\n\n        @Override\n        public boolean isCacheable(LeafReaderContext ctx) {\n          return true;\n        }\n\n      };\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b94236357aaa22b76c10629851fe4e376e0cea82":["417142ff08fda9cf0b72d5133e63097a166c6458","a6e9f769521480a623f897c0d59089b919fa4239"],"a6e9f769521480a623f897c0d59089b919fa4239":["417142ff08fda9cf0b72d5133e63097a166c6458"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"9fc47cb7b4346802411bb432f501ed0673d7119e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"c85073c7bb192ffda1ad397ced31d287279a2678":["5b9ffb60dc4bdc972b1403ad2ab2f5b4d9ce4cf7"],"9c226b0eeb8b028f572020f459851a663a2c064e":["b94236357aaa22b76c10629851fe4e376e0cea82"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c85073c7bb192ffda1ad397ced31d287279a2678"],"5b9ffb60dc4bdc972b1403ad2ab2f5b4d9ce4cf7":["9c226b0eeb8b028f572020f459851a663a2c064e"],"417142ff08fda9cf0b72d5133e63097a166c6458":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","9fc47cb7b4346802411bb432f501ed0673d7119e"]},"commit2Childs":{"b94236357aaa22b76c10629851fe4e376e0cea82":["9c226b0eeb8b028f572020f459851a663a2c064e"],"a6e9f769521480a623f897c0d59089b919fa4239":["b94236357aaa22b76c10629851fe4e376e0cea82"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9fc47cb7b4346802411bb432f501ed0673d7119e","417142ff08fda9cf0b72d5133e63097a166c6458"],"9fc47cb7b4346802411bb432f501ed0673d7119e":["417142ff08fda9cf0b72d5133e63097a166c6458"],"c85073c7bb192ffda1ad397ced31d287279a2678":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"9c226b0eeb8b028f572020f459851a663a2c064e":["5b9ffb60dc4bdc972b1403ad2ab2f5b4d9ce4cf7"],"417142ff08fda9cf0b72d5133e63097a166c6458":["b94236357aaa22b76c10629851fe4e376e0cea82","a6e9f769521480a623f897c0d59089b919fa4239"],"5b9ffb60dc4bdc972b1403ad2ab2f5b4d9ce4cf7":["c85073c7bb192ffda1ad397ced31d287279a2678"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}