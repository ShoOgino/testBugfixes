{"path":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#processDeleteByQuery(DeleteUpdateCommand).mjava","commits":[{"id":"2c007e7c4cf8c55bc2a5884e315123afaaeec87f","date":1327520966,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#processDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"/dev/null","sourceNew":"  private void processDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n        }\n      }\n\n      doLocalDelete(cmd);\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    // TODO: we should consider this? Send delete query to everyone in the current collection\n\n    if (zkEnabled) {\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      if (!params.getBool(DELQUERY_END_POINT, false)) {\n        params.set(DELQUERY_END_POINT, true);\n\n        String nodeName = req.getCore().getCoreDescriptor().getCoreContainer()\n            .getZkController().getNodeName();\n        String shardZkNodeName = nodeName + \"_\" + req.getCore().getName();\n        List<Node> nodes = getCollectionUrls(req, req.getCore().getCoreDescriptor()\n            .getCloudDescriptor().getCollectionName(), shardZkNodeName);\n\n        if (nodes != null) {\n          cmdDistrib.distribDelete(cmd, nodes, params);\n          finish();\n        }\n      }\n    }\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d","date":1327523564,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#processDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"/dev/null","sourceNew":"  private void processDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n        }\n      }\n\n      doLocalDelete(cmd);\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    // TODO: we should consider this? Send delete query to everyone in the current collection\n\n    if (zkEnabled) {\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      if (!params.getBool(DELQUERY_END_POINT, false)) {\n        params.set(DELQUERY_END_POINT, true);\n\n        String nodeName = req.getCore().getCoreDescriptor().getCoreContainer()\n            .getZkController().getNodeName();\n        String shardZkNodeName = nodeName + \"_\" + req.getCore().getName();\n        List<Node> nodes = getCollectionUrls(req, req.getCore().getCoreDescriptor()\n            .getCloudDescriptor().getCollectionName(), shardZkNodeName);\n\n        if (nodes != null) {\n          cmdDistrib.distribDelete(cmd, nodes, params);\n          finish();\n        }\n      }\n    }\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0d22ac6a4146774c1bc8400160fc0b6150294e92","date":1327528604,"type":0,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#processDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"/dev/null","sourceNew":"  private void processDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n        }\n      }\n\n      doLocalDelete(cmd);\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    // TODO: we should consider this? Send delete query to everyone in the current collection\n\n    if (zkEnabled) {\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      if (!params.getBool(DELQUERY_END_POINT, false)) {\n        params.set(DELQUERY_END_POINT, true);\n\n        String nodeName = req.getCore().getCoreDescriptor().getCoreContainer()\n            .getZkController().getNodeName();\n        String shardZkNodeName = nodeName + \"_\" + req.getCore().getName();\n        List<Node> nodes = getCollectionUrls(req, req.getCore().getCoreDescriptor()\n            .getCloudDescriptor().getCollectionName(), shardZkNodeName);\n\n        if (nodes != null) {\n          cmdDistrib.distribDelete(cmd, nodes, params);\n          finish();\n        }\n      }\n    }\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"df5e4eb47076636341c2cfdc58472477477d7e96","date":1329187541,"type":5,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#processDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = !req.getParams().getBool(SEEN_LEADER, false);\n    } else {\n      zkCheck();\n    }\n\n    // Lev1: we are the first to receive this deleteByQuery, it must be forwarded to the leader of every shard\n    // Lev2: we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // Lev3: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n\n    int dbqlevel = req.getParams().getInt(DELETE_BY_QUERY_LEVEL, 1);\n\n    if (zkEnabled && dbqlevel == 1) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getCloudState().getSlices(collection);\n\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(\"dbqlevel\", 2);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the level to 2 so we look up and forward to our own replicas (if any)\n      dbqlevel = 2;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && dbqlevel == 2) {\n      // This core should be a leader\n      replicas = setupRequest();\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          // TODO: flush any adds to these replicas so they do not get reordered w.r.t. this DBQ\n\n          doLocalDelete(cmd);\n\n          // forward to all replicas\n          if (replicas != null) {\n            ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n            params.set(\"dbqlevel\", 3);\n            params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n            params.set(SEEN_LEADER, \"true\");\n            cmdDistrib.distribDelete(cmd, replicas, params);\n\n            // wait for DBQ responses before releasing the update block to eliminate the possibility\n            // of an add being reordered.\n            // TODO: this isn't strictly necessary - we could do the same thing we do for PeerSync\n            // in DUH2 and add a clause that prevents deleting older docs.\n            cmdDistrib.finish();\n          }\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  private void processDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n        }\n      }\n\n      doLocalDelete(cmd);\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    // TODO: we should consider this? Send delete query to everyone in the current collection\n\n    if (zkEnabled) {\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      if (!params.getBool(DELQUERY_END_POINT, false)) {\n        params.set(DELQUERY_END_POINT, true);\n\n        String nodeName = req.getCore().getCoreDescriptor().getCoreContainer()\n            .getZkController().getNodeName();\n        String shardZkNodeName = nodeName + \"_\" + req.getCore().getName();\n        List<Node> nodes = getCollectionUrls(req, req.getCore().getCoreDescriptor()\n            .getCloudDescriptor().getCollectionName(), shardZkNodeName);\n\n        if (nodes != null) {\n          cmdDistrib.distribDelete(cmd, nodes, params);\n          finish();\n        }\n      }\n    }\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n\n  }\n\n","bugFix":null,"bugIntro":["a6378064655e76cd7b908b1cab4ce425b384b508","3d7c0c8a97beb56d2e168604f9928de17981eabe","2806236d9dfa336ac413d3724a4123e7cf4d1e93"],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"0d22ac6a4146774c1bc8400160fc0b6150294e92":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"2c007e7c4cf8c55bc2a5884e315123afaaeec87f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"df5e4eb47076636341c2cfdc58472477477d7e96":["2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["df5e4eb47076636341c2cfdc58472477477d7e96"]},"commit2Childs":{"0d22ac6a4146774c1bc8400160fc0b6150294e92":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["0d22ac6a4146774c1bc8400160fc0b6150294e92","a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d","2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d":[],"2c007e7c4cf8c55bc2a5884e315123afaaeec87f":["0d22ac6a4146774c1bc8400160fc0b6150294e92","a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d","df5e4eb47076636341c2cfdc58472477477d7e96"],"df5e4eb47076636341c2cfdc58472477477d7e96":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["0d22ac6a4146774c1bc8400160fc0b6150294e92","a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}