{"path":"solr/core/src/java/org/apache/solr/handler/SQLHandler#doSelectDistinct(SQLVisitor,int,String,String).mjava","commits":[{"id":"36479872320bb00635cb97ca6757614c88562e1b","date":1444426483,"type":0,"author":"Joel Bernstein","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/SQLHandler#doSelectDistinct(SQLVisitor,int,String,String).mjava","pathOld":"/dev/null","sourceNew":"  private static TupleStream doSelectDistinct(SQLVisitor sqlVisitor,\n                                              int numWorkers,\n                                              String workerCollection,\n                                              String workerZkHost) throws IOException {\n\n    Set<String> fieldSet = new HashSet();\n    Bucket[] buckets = getBuckets(sqlVisitor.fields, fieldSet);\n    Metric[] metrics = getMetrics(sqlVisitor.fields, fieldSet);\n\n    if(metrics.length > 0) {\n      throw new IOException(\"Select Distinct queries cannot include aggregate functions.\");\n    }\n\n    String fl = fields(fieldSet);\n\n    String sort = null;\n    StreamEqualitor ecomp = null;\n    StreamComparator comp = null;\n\n    if(sqlVisitor.sorts != null && sqlVisitor.sorts.size() > 0) {\n      StreamComparator[] adjustedSorts = adjustSorts(sqlVisitor.sorts, buckets);\n      FieldEqualitor[] fieldEqualitors = new FieldEqualitor[adjustedSorts.length];\n      StringBuilder buf = new StringBuilder();\n      for(int i=0; i<adjustedSorts.length; i++) {\n        FieldComparator fieldComparator = (FieldComparator)adjustedSorts[i];\n        fieldEqualitors[i] = new FieldEqualitor(fieldComparator.getFieldName());\n        if(i>0) {\n          buf.append(\",\");\n        }\n        buf.append(fieldComparator.getFieldName()).append(\" \").append(fieldComparator.getOrder().toString());\n      }\n\n      sort = buf.toString();\n\n      if(adjustedSorts.length == 1) {\n        ecomp = fieldEqualitors[0];\n        comp = adjustedSorts[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(fieldEqualitors);\n        comp = new MultipleFieldComparator(adjustedSorts);\n      }\n    } else {\n      StringBuilder sortBuf = new StringBuilder();\n      FieldEqualitor[] equalitors = new FieldEqualitor[buckets.length];\n      StreamComparator[] streamComparators = new StreamComparator[buckets.length];\n      for(int i=0; i<buckets.length; i++) {\n        equalitors[i] = new FieldEqualitor(buckets[i].toString());\n        streamComparators[i] = new FieldComparator(buckets[i].toString(), ComparatorOrder.ASCENDING);\n        if(i>0) {\n          sortBuf.append(',');\n        }\n        sortBuf.append(buckets[i].toString()).append(\" asc\");\n      }\n\n      sort = sortBuf.toString();\n\n      if(equalitors.length == 1) {\n        ecomp = equalitors[0];\n        comp = streamComparators[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(equalitors);\n        comp = new MultipleFieldComparator(streamComparators);\n      }\n    }\n\n    TableSpec tableSpec = new TableSpec(sqlVisitor.table, defaultZkhost);\n\n    String zkHost = tableSpec.zkHost;\n    String collection = tableSpec.collection;\n    Map<String, String> params = new HashMap();\n\n    params.put(CommonParams.FL, fl);\n    params.put(CommonParams.Q, sqlVisitor.query);\n    //Always use the /export handler for Distinct Queries because it requires exporting full result sets.\n    params.put(CommonParams.QT, \"/export\");\n\n    if(numWorkers > 1) {\n      params.put(\"partitionKeys\", getPartitionKeys(buckets));\n    }\n\n    params.put(\"sort\", sort);\n\n    TupleStream tupleStream = null;\n\n    CloudSolrStream cstream = new CloudSolrStream(zkHost, collection, params);\n    tupleStream = new UniqueStream(cstream, ecomp);\n\n    if(numWorkers > 1) {\n      // Do the unique in parallel\n      // Maintain the sort of the Tuples coming from the workers.\n      ParallelStream parallelStream = new ParallelStream(workerZkHost, workerCollection, tupleStream, numWorkers, comp);\n\n      StreamFactory factory = new StreamFactory()\n          .withFunctionName(\"search\", CloudSolrStream.class)\n          .withFunctionName(\"parallel\", ParallelStream.class)\n          .withFunctionName(\"unique\", UniqueStream.class);\n\n      parallelStream.setStreamFactory(factory);\n      parallelStream.setObjectSerialize(false);\n      tupleStream = parallelStream;\n    }\n\n    if(sqlVisitor.limit > 0) {\n      tupleStream = new LimitStream(tupleStream, sqlVisitor.limit);\n    }\n\n    return tupleStream;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"333d804f5abfaf34c57493306a4cb2e01e55662d","date":1447206304,"type":3,"author":"Dennis Gove","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/SQLHandler#doSelectDistinct(SQLVisitor,int,String,String).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/SQLHandler#doSelectDistinct(SQLVisitor,int,String,String).mjava","sourceNew":"  private static TupleStream doSelectDistinct(SQLVisitor sqlVisitor,\n                                              int numWorkers,\n                                              String workerCollection,\n                                              String workerZkHost) throws IOException {\n\n    Set<String> fieldSet = new HashSet();\n    Bucket[] buckets = getBuckets(sqlVisitor.fields, fieldSet);\n    Metric[] metrics = getMetrics(sqlVisitor.fields, fieldSet);\n\n    if(metrics.length > 0) {\n      throw new IOException(\"Select Distinct queries cannot include aggregate functions.\");\n    }\n\n    String fl = fields(fieldSet);\n\n    String sort = null;\n    StreamEqualitor ecomp = null;\n    StreamComparator comp = null;\n\n    if(sqlVisitor.sorts != null && sqlVisitor.sorts.size() > 0) {\n      StreamComparator[] adjustedSorts = adjustSorts(sqlVisitor.sorts, buckets);\n        // Because of the way adjustSorts works we know that each FieldComparator has a single\n        // field name. For this reason we can just look at the leftFieldName\n      FieldEqualitor[] fieldEqualitors = new FieldEqualitor[adjustedSorts.length];\n      StringBuilder buf = new StringBuilder();\n      for(int i=0; i<adjustedSorts.length; i++) {\n        FieldComparator fieldComparator = (FieldComparator)adjustedSorts[i];\n        fieldEqualitors[i] = new FieldEqualitor(fieldComparator.getLeftFieldName());\n        if(i>0) {\n          buf.append(\",\");\n        }\n        buf.append(fieldComparator.getLeftFieldName()).append(\" \").append(fieldComparator.getOrder().toString());\n      }\n\n      sort = buf.toString();\n\n      if(adjustedSorts.length == 1) {\n        ecomp = fieldEqualitors[0];\n        comp = adjustedSorts[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(fieldEqualitors);\n        comp = new MultipleFieldComparator(adjustedSorts);\n      }\n    } else {\n      StringBuilder sortBuf = new StringBuilder();\n      FieldEqualitor[] equalitors = new FieldEqualitor[buckets.length];\n      StreamComparator[] streamComparators = new StreamComparator[buckets.length];\n      for(int i=0; i<buckets.length; i++) {\n        equalitors[i] = new FieldEqualitor(buckets[i].toString());\n        streamComparators[i] = new FieldComparator(buckets[i].toString(), ComparatorOrder.ASCENDING);\n        if(i>0) {\n          sortBuf.append(',');\n        }\n        sortBuf.append(buckets[i].toString()).append(\" asc\");\n      }\n\n      sort = sortBuf.toString();\n\n      if(equalitors.length == 1) {\n        ecomp = equalitors[0];\n        comp = streamComparators[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(equalitors);\n        comp = new MultipleFieldComparator(streamComparators);\n      }\n    }\n\n    TableSpec tableSpec = new TableSpec(sqlVisitor.table, defaultZkhost);\n\n    String zkHost = tableSpec.zkHost;\n    String collection = tableSpec.collection;\n    Map<String, String> params = new HashMap();\n\n    params.put(CommonParams.FL, fl);\n    params.put(CommonParams.Q, sqlVisitor.query);\n    //Always use the /export handler for Distinct Queries because it requires exporting full result sets.\n    params.put(CommonParams.QT, \"/export\");\n\n    if(numWorkers > 1) {\n      params.put(\"partitionKeys\", getPartitionKeys(buckets));\n    }\n\n    params.put(\"sort\", sort);\n\n    TupleStream tupleStream = null;\n\n    CloudSolrStream cstream = new CloudSolrStream(zkHost, collection, params);\n    tupleStream = new UniqueStream(cstream, ecomp);\n\n    if(numWorkers > 1) {\n      // Do the unique in parallel\n      // Maintain the sort of the Tuples coming from the workers.\n      ParallelStream parallelStream = new ParallelStream(workerZkHost, workerCollection, tupleStream, numWorkers, comp);\n\n      StreamFactory factory = new StreamFactory()\n          .withFunctionName(\"search\", CloudSolrStream.class)\n          .withFunctionName(\"parallel\", ParallelStream.class)\n          .withFunctionName(\"unique\", UniqueStream.class);\n\n      parallelStream.setStreamFactory(factory);\n      parallelStream.setObjectSerialize(false);\n      tupleStream = parallelStream;\n    }\n\n    if(sqlVisitor.limit > 0) {\n      tupleStream = new LimitStream(tupleStream, sqlVisitor.limit);\n    }\n\n    return tupleStream;\n  }\n\n","sourceOld":"  private static TupleStream doSelectDistinct(SQLVisitor sqlVisitor,\n                                              int numWorkers,\n                                              String workerCollection,\n                                              String workerZkHost) throws IOException {\n\n    Set<String> fieldSet = new HashSet();\n    Bucket[] buckets = getBuckets(sqlVisitor.fields, fieldSet);\n    Metric[] metrics = getMetrics(sqlVisitor.fields, fieldSet);\n\n    if(metrics.length > 0) {\n      throw new IOException(\"Select Distinct queries cannot include aggregate functions.\");\n    }\n\n    String fl = fields(fieldSet);\n\n    String sort = null;\n    StreamEqualitor ecomp = null;\n    StreamComparator comp = null;\n\n    if(sqlVisitor.sorts != null && sqlVisitor.sorts.size() > 0) {\n      StreamComparator[] adjustedSorts = adjustSorts(sqlVisitor.sorts, buckets);\n      FieldEqualitor[] fieldEqualitors = new FieldEqualitor[adjustedSorts.length];\n      StringBuilder buf = new StringBuilder();\n      for(int i=0; i<adjustedSorts.length; i++) {\n        FieldComparator fieldComparator = (FieldComparator)adjustedSorts[i];\n        fieldEqualitors[i] = new FieldEqualitor(fieldComparator.getFieldName());\n        if(i>0) {\n          buf.append(\",\");\n        }\n        buf.append(fieldComparator.getFieldName()).append(\" \").append(fieldComparator.getOrder().toString());\n      }\n\n      sort = buf.toString();\n\n      if(adjustedSorts.length == 1) {\n        ecomp = fieldEqualitors[0];\n        comp = adjustedSorts[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(fieldEqualitors);\n        comp = new MultipleFieldComparator(adjustedSorts);\n      }\n    } else {\n      StringBuilder sortBuf = new StringBuilder();\n      FieldEqualitor[] equalitors = new FieldEqualitor[buckets.length];\n      StreamComparator[] streamComparators = new StreamComparator[buckets.length];\n      for(int i=0; i<buckets.length; i++) {\n        equalitors[i] = new FieldEqualitor(buckets[i].toString());\n        streamComparators[i] = new FieldComparator(buckets[i].toString(), ComparatorOrder.ASCENDING);\n        if(i>0) {\n          sortBuf.append(',');\n        }\n        sortBuf.append(buckets[i].toString()).append(\" asc\");\n      }\n\n      sort = sortBuf.toString();\n\n      if(equalitors.length == 1) {\n        ecomp = equalitors[0];\n        comp = streamComparators[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(equalitors);\n        comp = new MultipleFieldComparator(streamComparators);\n      }\n    }\n\n    TableSpec tableSpec = new TableSpec(sqlVisitor.table, defaultZkhost);\n\n    String zkHost = tableSpec.zkHost;\n    String collection = tableSpec.collection;\n    Map<String, String> params = new HashMap();\n\n    params.put(CommonParams.FL, fl);\n    params.put(CommonParams.Q, sqlVisitor.query);\n    //Always use the /export handler for Distinct Queries because it requires exporting full result sets.\n    params.put(CommonParams.QT, \"/export\");\n\n    if(numWorkers > 1) {\n      params.put(\"partitionKeys\", getPartitionKeys(buckets));\n    }\n\n    params.put(\"sort\", sort);\n\n    TupleStream tupleStream = null;\n\n    CloudSolrStream cstream = new CloudSolrStream(zkHost, collection, params);\n    tupleStream = new UniqueStream(cstream, ecomp);\n\n    if(numWorkers > 1) {\n      // Do the unique in parallel\n      // Maintain the sort of the Tuples coming from the workers.\n      ParallelStream parallelStream = new ParallelStream(workerZkHost, workerCollection, tupleStream, numWorkers, comp);\n\n      StreamFactory factory = new StreamFactory()\n          .withFunctionName(\"search\", CloudSolrStream.class)\n          .withFunctionName(\"parallel\", ParallelStream.class)\n          .withFunctionName(\"unique\", UniqueStream.class);\n\n      parallelStream.setStreamFactory(factory);\n      parallelStream.setObjectSerialize(false);\n      tupleStream = parallelStream;\n    }\n\n    if(sqlVisitor.limit > 0) {\n      tupleStream = new LimitStream(tupleStream, sqlVisitor.limit);\n    }\n\n    return tupleStream;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c3cf1396610fbacfdf69deb27bc5d3f36b5fbd43","date":1449690748,"type":3,"author":"Joel Bernstein","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/SQLHandler#doSelectDistinct(SQLVisitor,int,String,String).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/SQLHandler#doSelectDistinct(SQLVisitor,int,String,String).mjava","sourceNew":"  private static TupleStream doSelectDistinct(SQLVisitor sqlVisitor,\n                                              int numWorkers,\n                                              String workerCollection,\n                                              String workerZkHost) throws IOException {\n\n    Set<String> fieldSet = new HashSet();\n    Bucket[] buckets = getBuckets(sqlVisitor.fields, fieldSet);\n    Metric[] metrics = getMetrics(sqlVisitor.fields, fieldSet);\n\n    if(metrics.length > 0) {\n      throw new IOException(\"Select Distinct queries cannot include aggregate functions.\");\n    }\n\n    String fl = fields(fieldSet);\n\n    String sort = null;\n    StreamEqualitor ecomp = null;\n    StreamComparator comp = null;\n\n    if(sqlVisitor.sorts != null && sqlVisitor.sorts.size() > 0) {\n      StreamComparator[] adjustedSorts = adjustSorts(sqlVisitor.sorts, buckets);\n        // Because of the way adjustSorts works we know that each FieldComparator has a single\n        // field name. For this reason we can just look at the leftFieldName\n      FieldEqualitor[] fieldEqualitors = new FieldEqualitor[adjustedSorts.length];\n      StringBuilder buf = new StringBuilder();\n      for(int i=0; i<adjustedSorts.length; i++) {\n        FieldComparator fieldComparator = (FieldComparator)adjustedSorts[i];\n        fieldEqualitors[i] = new FieldEqualitor(fieldComparator.getLeftFieldName());\n        if(i>0) {\n          buf.append(\",\");\n        }\n        buf.append(fieldComparator.getLeftFieldName()).append(\" \").append(fieldComparator.getOrder().toString());\n      }\n\n      sort = buf.toString();\n\n      if(adjustedSorts.length == 1) {\n        ecomp = fieldEqualitors[0];\n        comp = adjustedSorts[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(fieldEqualitors);\n        comp = new MultipleFieldComparator(adjustedSorts);\n      }\n    } else {\n      StringBuilder sortBuf = new StringBuilder();\n      FieldEqualitor[] equalitors = new FieldEqualitor[buckets.length];\n      StreamComparator[] streamComparators = new StreamComparator[buckets.length];\n      for(int i=0; i<buckets.length; i++) {\n        equalitors[i] = new FieldEqualitor(buckets[i].toString());\n        streamComparators[i] = new FieldComparator(buckets[i].toString(), ComparatorOrder.ASCENDING);\n        if(i>0) {\n          sortBuf.append(',');\n        }\n        sortBuf.append(buckets[i].toString()).append(\" asc\");\n      }\n\n      sort = sortBuf.toString();\n\n      if(equalitors.length == 1) {\n        ecomp = equalitors[0];\n        comp = streamComparators[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(equalitors);\n        comp = new MultipleFieldComparator(streamComparators);\n      }\n    }\n\n    TableSpec tableSpec = new TableSpec(sqlVisitor.table, defaultZkhost);\n\n    String zkHost = tableSpec.zkHost;\n    String collection = tableSpec.collection;\n    Map<String, String> params = new HashMap();\n\n    params.put(CommonParams.FL, fl);\n    params.put(CommonParams.Q, sqlVisitor.query);\n    //Always use the /export handler for Distinct Queries because it requires exporting full result sets.\n    params.put(CommonParams.QT, \"/export\");\n\n    if(numWorkers > 1) {\n      params.put(\"partitionKeys\", getPartitionKeys(buckets));\n    }\n\n    params.put(\"sort\", sort);\n\n    TupleStream tupleStream = null;\n\n    CloudSolrStream cstream = new CloudSolrStream(zkHost, collection, params);\n    tupleStream = new UniqueStream(cstream, ecomp);\n\n    if(numWorkers > 1) {\n      // Do the unique in parallel\n      // Maintain the sort of the Tuples coming from the workers.\n      ParallelStream parallelStream = new ParallelStream(workerZkHost, workerCollection, tupleStream, numWorkers, comp);\n\n      StreamFactory factory = new StreamFactory()\n          .withFunctionName(\"search\", CloudSolrStream.class)\n          .withFunctionName(\"parallel\", ParallelStream.class)\n          .withFunctionName(\"unique\", UniqueStream.class);\n\n      parallelStream.setStreamFactory(factory);\n      tupleStream = parallelStream;\n    }\n\n    if(sqlVisitor.limit > 0) {\n      tupleStream = new LimitStream(tupleStream, sqlVisitor.limit);\n    }\n\n    return tupleStream;\n  }\n\n","sourceOld":"  private static TupleStream doSelectDistinct(SQLVisitor sqlVisitor,\n                                              int numWorkers,\n                                              String workerCollection,\n                                              String workerZkHost) throws IOException {\n\n    Set<String> fieldSet = new HashSet();\n    Bucket[] buckets = getBuckets(sqlVisitor.fields, fieldSet);\n    Metric[] metrics = getMetrics(sqlVisitor.fields, fieldSet);\n\n    if(metrics.length > 0) {\n      throw new IOException(\"Select Distinct queries cannot include aggregate functions.\");\n    }\n\n    String fl = fields(fieldSet);\n\n    String sort = null;\n    StreamEqualitor ecomp = null;\n    StreamComparator comp = null;\n\n    if(sqlVisitor.sorts != null && sqlVisitor.sorts.size() > 0) {\n      StreamComparator[] adjustedSorts = adjustSorts(sqlVisitor.sorts, buckets);\n        // Because of the way adjustSorts works we know that each FieldComparator has a single\n        // field name. For this reason we can just look at the leftFieldName\n      FieldEqualitor[] fieldEqualitors = new FieldEqualitor[adjustedSorts.length];\n      StringBuilder buf = new StringBuilder();\n      for(int i=0; i<adjustedSorts.length; i++) {\n        FieldComparator fieldComparator = (FieldComparator)adjustedSorts[i];\n        fieldEqualitors[i] = new FieldEqualitor(fieldComparator.getLeftFieldName());\n        if(i>0) {\n          buf.append(\",\");\n        }\n        buf.append(fieldComparator.getLeftFieldName()).append(\" \").append(fieldComparator.getOrder().toString());\n      }\n\n      sort = buf.toString();\n\n      if(adjustedSorts.length == 1) {\n        ecomp = fieldEqualitors[0];\n        comp = adjustedSorts[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(fieldEqualitors);\n        comp = new MultipleFieldComparator(adjustedSorts);\n      }\n    } else {\n      StringBuilder sortBuf = new StringBuilder();\n      FieldEqualitor[] equalitors = new FieldEqualitor[buckets.length];\n      StreamComparator[] streamComparators = new StreamComparator[buckets.length];\n      for(int i=0; i<buckets.length; i++) {\n        equalitors[i] = new FieldEqualitor(buckets[i].toString());\n        streamComparators[i] = new FieldComparator(buckets[i].toString(), ComparatorOrder.ASCENDING);\n        if(i>0) {\n          sortBuf.append(',');\n        }\n        sortBuf.append(buckets[i].toString()).append(\" asc\");\n      }\n\n      sort = sortBuf.toString();\n\n      if(equalitors.length == 1) {\n        ecomp = equalitors[0];\n        comp = streamComparators[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(equalitors);\n        comp = new MultipleFieldComparator(streamComparators);\n      }\n    }\n\n    TableSpec tableSpec = new TableSpec(sqlVisitor.table, defaultZkhost);\n\n    String zkHost = tableSpec.zkHost;\n    String collection = tableSpec.collection;\n    Map<String, String> params = new HashMap();\n\n    params.put(CommonParams.FL, fl);\n    params.put(CommonParams.Q, sqlVisitor.query);\n    //Always use the /export handler for Distinct Queries because it requires exporting full result sets.\n    params.put(CommonParams.QT, \"/export\");\n\n    if(numWorkers > 1) {\n      params.put(\"partitionKeys\", getPartitionKeys(buckets));\n    }\n\n    params.put(\"sort\", sort);\n\n    TupleStream tupleStream = null;\n\n    CloudSolrStream cstream = new CloudSolrStream(zkHost, collection, params);\n    tupleStream = new UniqueStream(cstream, ecomp);\n\n    if(numWorkers > 1) {\n      // Do the unique in parallel\n      // Maintain the sort of the Tuples coming from the workers.\n      ParallelStream parallelStream = new ParallelStream(workerZkHost, workerCollection, tupleStream, numWorkers, comp);\n\n      StreamFactory factory = new StreamFactory()\n          .withFunctionName(\"search\", CloudSolrStream.class)\n          .withFunctionName(\"parallel\", ParallelStream.class)\n          .withFunctionName(\"unique\", UniqueStream.class);\n\n      parallelStream.setStreamFactory(factory);\n      parallelStream.setObjectSerialize(false);\n      tupleStream = parallelStream;\n    }\n\n    if(sqlVisitor.limit > 0) {\n      tupleStream = new LimitStream(tupleStream, sqlVisitor.limit);\n    }\n\n    return tupleStream;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5f90f992f4e4fdedb0fe0cc2fe3925df71a5b9f7","date":1452631653,"type":3,"author":"Joel Bernstein","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/SQLHandler#doSelectDistinct(SQLVisitor,int,String,String).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/SQLHandler#doSelectDistinct(SQLVisitor,int,String,String).mjava","sourceNew":"  private static TupleStream doSelectDistinct(SQLVisitor sqlVisitor,\n                                              int numWorkers,\n                                              String workerCollection,\n                                              String workerZkHost) throws IOException {\n\n    Set<String> fieldSet = new HashSet();\n    Bucket[] buckets = getBuckets(sqlVisitor.fields, fieldSet);\n    Metric[] metrics = getMetrics(sqlVisitor.fields, fieldSet);\n\n    if(metrics.length > 0) {\n      throw new IOException(\"Select Distinct queries cannot include aggregate functions.\");\n    }\n\n    String fl = fields(fieldSet);\n\n    String sort = null;\n    StreamEqualitor ecomp = null;\n    StreamComparator comp = null;\n\n    if(sqlVisitor.sorts != null && sqlVisitor.sorts.size() > 0) {\n      StreamComparator[] adjustedSorts = adjustSorts(sqlVisitor.sorts, buckets, sqlVisitor.reverseColumnAliases);\n        // Because of the way adjustSorts works we know that each FieldComparator has a single\n        // field name. For this reason we can just look at the leftFieldName\n      FieldEqualitor[] fieldEqualitors = new FieldEqualitor[adjustedSorts.length];\n      StringBuilder buf = new StringBuilder();\n      for(int i=0; i<adjustedSorts.length; i++) {\n        FieldComparator fieldComparator = (FieldComparator)adjustedSorts[i];\n        fieldEqualitors[i] = new FieldEqualitor(fieldComparator.getLeftFieldName());\n        if(i>0) {\n          buf.append(\",\");\n        }\n        buf.append(fieldComparator.getLeftFieldName()).append(\" \").append(fieldComparator.getOrder().toString());\n      }\n\n      sort = buf.toString();\n\n      if(adjustedSorts.length == 1) {\n        ecomp = fieldEqualitors[0];\n        comp = adjustedSorts[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(fieldEqualitors);\n        comp = new MultipleFieldComparator(adjustedSorts);\n      }\n    } else {\n      StringBuilder sortBuf = new StringBuilder();\n      FieldEqualitor[] equalitors = new FieldEqualitor[buckets.length];\n      StreamComparator[] streamComparators = new StreamComparator[buckets.length];\n      for(int i=0; i<buckets.length; i++) {\n        equalitors[i] = new FieldEqualitor(buckets[i].toString());\n        streamComparators[i] = new FieldComparator(buckets[i].toString(), ComparatorOrder.ASCENDING);\n        if(i>0) {\n          sortBuf.append(',');\n        }\n        sortBuf.append(buckets[i].toString()).append(\" asc\");\n      }\n\n      sort = sortBuf.toString();\n\n      if(equalitors.length == 1) {\n        ecomp = equalitors[0];\n        comp = streamComparators[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(equalitors);\n        comp = new MultipleFieldComparator(streamComparators);\n      }\n    }\n\n    TableSpec tableSpec = new TableSpec(sqlVisitor.table, defaultZkhost);\n\n    String zkHost = tableSpec.zkHost;\n    String collection = tableSpec.collection;\n    Map<String, String> params = new HashMap();\n\n    params.put(CommonParams.FL, fl);\n    params.put(CommonParams.Q, sqlVisitor.query);\n    //Always use the /export handler for Distinct Queries because it requires exporting full result sets.\n    params.put(CommonParams.QT, \"/export\");\n\n    if(numWorkers > 1) {\n      params.put(\"partitionKeys\", getPartitionKeys(buckets));\n    }\n\n    params.put(\"sort\", sort);\n\n    TupleStream tupleStream = null;\n\n    CloudSolrStream cstream = new CloudSolrStream(zkHost, collection, params);\n    tupleStream = new UniqueStream(cstream, ecomp);\n\n    if(numWorkers > 1) {\n      // Do the unique in parallel\n      // Maintain the sort of the Tuples coming from the workers.\n      ParallelStream parallelStream = new ParallelStream(workerZkHost, workerCollection, tupleStream, numWorkers, comp);\n\n      StreamFactory factory = new StreamFactory()\n          .withFunctionName(\"search\", CloudSolrStream.class)\n          .withFunctionName(\"parallel\", ParallelStream.class)\n          .withFunctionName(\"unique\", UniqueStream.class);\n\n      parallelStream.setStreamFactory(factory);\n      tupleStream = parallelStream;\n    }\n\n    if(sqlVisitor.limit > 0) {\n      tupleStream = new LimitStream(tupleStream, sqlVisitor.limit);\n    }\n\n    if(sqlVisitor.hasColumnAliases) {\n      tupleStream = new SelectStream(tupleStream, sqlVisitor.columnAliases);\n    }\n\n    return tupleStream;\n  }\n\n","sourceOld":"  private static TupleStream doSelectDistinct(SQLVisitor sqlVisitor,\n                                              int numWorkers,\n                                              String workerCollection,\n                                              String workerZkHost) throws IOException {\n\n    Set<String> fieldSet = new HashSet();\n    Bucket[] buckets = getBuckets(sqlVisitor.fields, fieldSet);\n    Metric[] metrics = getMetrics(sqlVisitor.fields, fieldSet);\n\n    if(metrics.length > 0) {\n      throw new IOException(\"Select Distinct queries cannot include aggregate functions.\");\n    }\n\n    String fl = fields(fieldSet);\n\n    String sort = null;\n    StreamEqualitor ecomp = null;\n    StreamComparator comp = null;\n\n    if(sqlVisitor.sorts != null && sqlVisitor.sorts.size() > 0) {\n      StreamComparator[] adjustedSorts = adjustSorts(sqlVisitor.sorts, buckets);\n        // Because of the way adjustSorts works we know that each FieldComparator has a single\n        // field name. For this reason we can just look at the leftFieldName\n      FieldEqualitor[] fieldEqualitors = new FieldEqualitor[adjustedSorts.length];\n      StringBuilder buf = new StringBuilder();\n      for(int i=0; i<adjustedSorts.length; i++) {\n        FieldComparator fieldComparator = (FieldComparator)adjustedSorts[i];\n        fieldEqualitors[i] = new FieldEqualitor(fieldComparator.getLeftFieldName());\n        if(i>0) {\n          buf.append(\",\");\n        }\n        buf.append(fieldComparator.getLeftFieldName()).append(\" \").append(fieldComparator.getOrder().toString());\n      }\n\n      sort = buf.toString();\n\n      if(adjustedSorts.length == 1) {\n        ecomp = fieldEqualitors[0];\n        comp = adjustedSorts[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(fieldEqualitors);\n        comp = new MultipleFieldComparator(adjustedSorts);\n      }\n    } else {\n      StringBuilder sortBuf = new StringBuilder();\n      FieldEqualitor[] equalitors = new FieldEqualitor[buckets.length];\n      StreamComparator[] streamComparators = new StreamComparator[buckets.length];\n      for(int i=0; i<buckets.length; i++) {\n        equalitors[i] = new FieldEqualitor(buckets[i].toString());\n        streamComparators[i] = new FieldComparator(buckets[i].toString(), ComparatorOrder.ASCENDING);\n        if(i>0) {\n          sortBuf.append(',');\n        }\n        sortBuf.append(buckets[i].toString()).append(\" asc\");\n      }\n\n      sort = sortBuf.toString();\n\n      if(equalitors.length == 1) {\n        ecomp = equalitors[0];\n        comp = streamComparators[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(equalitors);\n        comp = new MultipleFieldComparator(streamComparators);\n      }\n    }\n\n    TableSpec tableSpec = new TableSpec(sqlVisitor.table, defaultZkhost);\n\n    String zkHost = tableSpec.zkHost;\n    String collection = tableSpec.collection;\n    Map<String, String> params = new HashMap();\n\n    params.put(CommonParams.FL, fl);\n    params.put(CommonParams.Q, sqlVisitor.query);\n    //Always use the /export handler for Distinct Queries because it requires exporting full result sets.\n    params.put(CommonParams.QT, \"/export\");\n\n    if(numWorkers > 1) {\n      params.put(\"partitionKeys\", getPartitionKeys(buckets));\n    }\n\n    params.put(\"sort\", sort);\n\n    TupleStream tupleStream = null;\n\n    CloudSolrStream cstream = new CloudSolrStream(zkHost, collection, params);\n    tupleStream = new UniqueStream(cstream, ecomp);\n\n    if(numWorkers > 1) {\n      // Do the unique in parallel\n      // Maintain the sort of the Tuples coming from the workers.\n      ParallelStream parallelStream = new ParallelStream(workerZkHost, workerCollection, tupleStream, numWorkers, comp);\n\n      StreamFactory factory = new StreamFactory()\n          .withFunctionName(\"search\", CloudSolrStream.class)\n          .withFunctionName(\"parallel\", ParallelStream.class)\n          .withFunctionName(\"unique\", UniqueStream.class);\n\n      parallelStream.setStreamFactory(factory);\n      tupleStream = parallelStream;\n    }\n\n    if(sqlVisitor.limit > 0) {\n      tupleStream = new LimitStream(tupleStream, sqlVisitor.limit);\n    }\n\n    return tupleStream;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d984627825732e682759c22df7a3b171a80f3812","date":1461857653,"type":4,"author":"Kevin Risden","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/core/src/java/org/apache/solr/handler/SQLHandler#doSelectDistinct(SQLVisitor,int,String,String).mjava","sourceNew":null,"sourceOld":"  private static TupleStream doSelectDistinct(SQLVisitor sqlVisitor,\n                                              int numWorkers,\n                                              String workerCollection,\n                                              String workerZkHost) throws IOException {\n\n    Set<String> fieldSet = new HashSet();\n    Bucket[] buckets = getBuckets(sqlVisitor.fields, fieldSet);\n    Metric[] metrics = getMetrics(sqlVisitor.fields, fieldSet);\n\n    if(metrics.length > 0) {\n      throw new IOException(\"Select Distinct queries cannot include aggregate functions.\");\n    }\n\n    String fl = fields(fieldSet);\n\n    String sort = null;\n    StreamEqualitor ecomp = null;\n    StreamComparator comp = null;\n\n    if(sqlVisitor.sorts != null && sqlVisitor.sorts.size() > 0) {\n      StreamComparator[] adjustedSorts = adjustSorts(sqlVisitor.sorts, buckets, sqlVisitor.reverseColumnAliases);\n        // Because of the way adjustSorts works we know that each FieldComparator has a single\n        // field name. For this reason we can just look at the leftFieldName\n      FieldEqualitor[] fieldEqualitors = new FieldEqualitor[adjustedSorts.length];\n      StringBuilder buf = new StringBuilder();\n      for(int i=0; i<adjustedSorts.length; i++) {\n        FieldComparator fieldComparator = (FieldComparator)adjustedSorts[i];\n        fieldEqualitors[i] = new FieldEqualitor(fieldComparator.getLeftFieldName());\n        if(i>0) {\n          buf.append(\",\");\n        }\n        buf.append(fieldComparator.getLeftFieldName()).append(\" \").append(fieldComparator.getOrder().toString());\n      }\n\n      sort = buf.toString();\n\n      if(adjustedSorts.length == 1) {\n        ecomp = fieldEqualitors[0];\n        comp = adjustedSorts[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(fieldEqualitors);\n        comp = new MultipleFieldComparator(adjustedSorts);\n      }\n    } else {\n      StringBuilder sortBuf = new StringBuilder();\n      FieldEqualitor[] equalitors = new FieldEqualitor[buckets.length];\n      StreamComparator[] streamComparators = new StreamComparator[buckets.length];\n      for(int i=0; i<buckets.length; i++) {\n        equalitors[i] = new FieldEqualitor(buckets[i].toString());\n        streamComparators[i] = new FieldComparator(buckets[i].toString(), ComparatorOrder.ASCENDING);\n        if(i>0) {\n          sortBuf.append(',');\n        }\n        sortBuf.append(buckets[i].toString()).append(\" asc\");\n      }\n\n      sort = sortBuf.toString();\n\n      if(equalitors.length == 1) {\n        ecomp = equalitors[0];\n        comp = streamComparators[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(equalitors);\n        comp = new MultipleFieldComparator(streamComparators);\n      }\n    }\n\n    TableSpec tableSpec = new TableSpec(sqlVisitor.table, defaultZkhost);\n\n    String zkHost = tableSpec.zkHost;\n    String collection = tableSpec.collection;\n    Map<String, String> params = new HashMap();\n\n    params.put(CommonParams.FL, fl);\n    params.put(CommonParams.Q, sqlVisitor.query);\n    //Always use the /export handler for Distinct Queries because it requires exporting full result sets.\n    params.put(CommonParams.QT, \"/export\");\n\n    if(numWorkers > 1) {\n      params.put(\"partitionKeys\", getPartitionKeys(buckets));\n    }\n\n    params.put(\"sort\", sort);\n\n    TupleStream tupleStream = null;\n\n    CloudSolrStream cstream = new CloudSolrStream(zkHost, collection, params);\n    tupleStream = new UniqueStream(cstream, ecomp);\n\n    if(numWorkers > 1) {\n      // Do the unique in parallel\n      // Maintain the sort of the Tuples coming from the workers.\n      ParallelStream parallelStream = new ParallelStream(workerZkHost, workerCollection, tupleStream, numWorkers, comp);\n\n      StreamFactory factory = new StreamFactory()\n          .withFunctionName(\"search\", CloudSolrStream.class)\n          .withFunctionName(\"parallel\", ParallelStream.class)\n          .withFunctionName(\"unique\", UniqueStream.class);\n\n      parallelStream.setStreamFactory(factory);\n      tupleStream = parallelStream;\n    }\n\n    if(sqlVisitor.limit > 0) {\n      tupleStream = new LimitStream(tupleStream, sqlVisitor.limit);\n    }\n\n    if(sqlVisitor.hasColumnAliases) {\n      tupleStream = new SelectStream(tupleStream, sqlVisitor.columnAliases);\n    }\n\n    return tupleStream;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"826d15444ddf61716dc768c229cd54b2c2ccce1c","date":1462822652,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/SQLHandler#doSelectDistinct(SQLVisitor,int,String,String).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/SQLHandler#doSelectDistinct(SQLVisitor,int,String,String).mjava","sourceNew":"  private static TupleStream doSelectDistinct(SQLVisitor sqlVisitor,\n                                              int numWorkers,\n                                              String workerCollection,\n                                              String workerZkHost) throws IOException {\n\n    Set<String> fieldSet = new HashSet();\n    Bucket[] buckets = getBuckets(sqlVisitor.fields, fieldSet);\n    Metric[] metrics = getMetrics(sqlVisitor.fields, fieldSet);\n\n    if(metrics.length > 0) {\n      throw new IOException(\"Select Distinct queries cannot include aggregate functions.\");\n    }\n\n    String fl = fields(fieldSet);\n\n    String sort = null;\n    StreamEqualitor ecomp = null;\n    StreamComparator comp = null;\n\n    if(sqlVisitor.sorts != null && sqlVisitor.sorts.size() > 0) {\n      StreamComparator[] adjustedSorts = adjustSorts(sqlVisitor.sorts, buckets, sqlVisitor.reverseColumnAliases);\n        // Because of the way adjustSorts works we know that each FieldComparator has a single\n        // field name. For this reason we can just look at the leftFieldName\n      FieldEqualitor[] fieldEqualitors = new FieldEqualitor[adjustedSorts.length];\n      StringBuilder buf = new StringBuilder();\n      for(int i=0; i<adjustedSorts.length; i++) {\n        FieldComparator fieldComparator = (FieldComparator)adjustedSorts[i];\n        fieldEqualitors[i] = new FieldEqualitor(fieldComparator.getLeftFieldName());\n        if(i>0) {\n          buf.append(\",\");\n        }\n        buf.append(fieldComparator.getLeftFieldName()).append(\" \").append(fieldComparator.getOrder().toString());\n      }\n\n      sort = buf.toString();\n\n      if(adjustedSorts.length == 1) {\n        ecomp = fieldEqualitors[0];\n        comp = adjustedSorts[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(fieldEqualitors);\n        comp = new MultipleFieldComparator(adjustedSorts);\n      }\n    } else {\n      StringBuilder sortBuf = new StringBuilder();\n      FieldEqualitor[] equalitors = new FieldEqualitor[buckets.length];\n      StreamComparator[] streamComparators = new StreamComparator[buckets.length];\n      for(int i=0; i<buckets.length; i++) {\n        equalitors[i] = new FieldEqualitor(buckets[i].toString());\n        streamComparators[i] = new FieldComparator(buckets[i].toString(), ComparatorOrder.ASCENDING);\n        if(i>0) {\n          sortBuf.append(',');\n        }\n        sortBuf.append(buckets[i].toString()).append(\" asc\");\n      }\n\n      sort = sortBuf.toString();\n\n      if(equalitors.length == 1) {\n        ecomp = equalitors[0];\n        comp = streamComparators[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(equalitors);\n        comp = new MultipleFieldComparator(streamComparators);\n      }\n    }\n\n    TableSpec tableSpec = new TableSpec(sqlVisitor.table, defaultZkhost);\n\n    String zkHost = tableSpec.zkHost;\n    String collection = tableSpec.collection;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n\n    params.set(CommonParams.FL, fl);\n    params.set(CommonParams.Q, sqlVisitor.query);\n    //Always use the /export handler for Distinct Queries because it requires exporting full result sets.\n    params.set(CommonParams.QT, \"/export\");\n\n    if(numWorkers > 1) {\n      params.set(\"partitionKeys\", getPartitionKeys(buckets));\n    }\n\n    params.set(\"sort\", sort);\n\n    TupleStream tupleStream = null;\n\n    CloudSolrStream cstream = new CloudSolrStream(zkHost, collection, params);\n    tupleStream = new UniqueStream(cstream, ecomp);\n\n    if(numWorkers > 1) {\n      // Do the unique in parallel\n      // Maintain the sort of the Tuples coming from the workers.\n      ParallelStream parallelStream = new ParallelStream(workerZkHost, workerCollection, tupleStream, numWorkers, comp);\n\n      StreamFactory factory = new StreamFactory()\n          .withFunctionName(\"search\", CloudSolrStream.class)\n          .withFunctionName(\"parallel\", ParallelStream.class)\n          .withFunctionName(\"unique\", UniqueStream.class);\n\n      parallelStream.setStreamFactory(factory);\n      tupleStream = parallelStream;\n    }\n\n    if(sqlVisitor.limit > 0) {\n      tupleStream = new LimitStream(tupleStream, sqlVisitor.limit);\n    }\n\n    if(sqlVisitor.hasColumnAliases) {\n      tupleStream = new SelectStream(tupleStream, sqlVisitor.columnAliases);\n    }\n\n    return tupleStream;\n  }\n\n","sourceOld":"  private static TupleStream doSelectDistinct(SQLVisitor sqlVisitor,\n                                              int numWorkers,\n                                              String workerCollection,\n                                              String workerZkHost) throws IOException {\n\n    Set<String> fieldSet = new HashSet();\n    Bucket[] buckets = getBuckets(sqlVisitor.fields, fieldSet);\n    Metric[] metrics = getMetrics(sqlVisitor.fields, fieldSet);\n\n    if(metrics.length > 0) {\n      throw new IOException(\"Select Distinct queries cannot include aggregate functions.\");\n    }\n\n    String fl = fields(fieldSet);\n\n    String sort = null;\n    StreamEqualitor ecomp = null;\n    StreamComparator comp = null;\n\n    if(sqlVisitor.sorts != null && sqlVisitor.sorts.size() > 0) {\n      StreamComparator[] adjustedSorts = adjustSorts(sqlVisitor.sorts, buckets, sqlVisitor.reverseColumnAliases);\n        // Because of the way adjustSorts works we know that each FieldComparator has a single\n        // field name. For this reason we can just look at the leftFieldName\n      FieldEqualitor[] fieldEqualitors = new FieldEqualitor[adjustedSorts.length];\n      StringBuilder buf = new StringBuilder();\n      for(int i=0; i<adjustedSorts.length; i++) {\n        FieldComparator fieldComparator = (FieldComparator)adjustedSorts[i];\n        fieldEqualitors[i] = new FieldEqualitor(fieldComparator.getLeftFieldName());\n        if(i>0) {\n          buf.append(\",\");\n        }\n        buf.append(fieldComparator.getLeftFieldName()).append(\" \").append(fieldComparator.getOrder().toString());\n      }\n\n      sort = buf.toString();\n\n      if(adjustedSorts.length == 1) {\n        ecomp = fieldEqualitors[0];\n        comp = adjustedSorts[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(fieldEqualitors);\n        comp = new MultipleFieldComparator(adjustedSorts);\n      }\n    } else {\n      StringBuilder sortBuf = new StringBuilder();\n      FieldEqualitor[] equalitors = new FieldEqualitor[buckets.length];\n      StreamComparator[] streamComparators = new StreamComparator[buckets.length];\n      for(int i=0; i<buckets.length; i++) {\n        equalitors[i] = new FieldEqualitor(buckets[i].toString());\n        streamComparators[i] = new FieldComparator(buckets[i].toString(), ComparatorOrder.ASCENDING);\n        if(i>0) {\n          sortBuf.append(',');\n        }\n        sortBuf.append(buckets[i].toString()).append(\" asc\");\n      }\n\n      sort = sortBuf.toString();\n\n      if(equalitors.length == 1) {\n        ecomp = equalitors[0];\n        comp = streamComparators[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(equalitors);\n        comp = new MultipleFieldComparator(streamComparators);\n      }\n    }\n\n    TableSpec tableSpec = new TableSpec(sqlVisitor.table, defaultZkhost);\n\n    String zkHost = tableSpec.zkHost;\n    String collection = tableSpec.collection;\n    Map<String, String> params = new HashMap();\n\n    params.put(CommonParams.FL, fl);\n    params.put(CommonParams.Q, sqlVisitor.query);\n    //Always use the /export handler for Distinct Queries because it requires exporting full result sets.\n    params.put(CommonParams.QT, \"/export\");\n\n    if(numWorkers > 1) {\n      params.put(\"partitionKeys\", getPartitionKeys(buckets));\n    }\n\n    params.put(\"sort\", sort);\n\n    TupleStream tupleStream = null;\n\n    CloudSolrStream cstream = new CloudSolrStream(zkHost, collection, params);\n    tupleStream = new UniqueStream(cstream, ecomp);\n\n    if(numWorkers > 1) {\n      // Do the unique in parallel\n      // Maintain the sort of the Tuples coming from the workers.\n      ParallelStream parallelStream = new ParallelStream(workerZkHost, workerCollection, tupleStream, numWorkers, comp);\n\n      StreamFactory factory = new StreamFactory()\n          .withFunctionName(\"search\", CloudSolrStream.class)\n          .withFunctionName(\"parallel\", ParallelStream.class)\n          .withFunctionName(\"unique\", UniqueStream.class);\n\n      parallelStream.setStreamFactory(factory);\n      tupleStream = parallelStream;\n    }\n\n    if(sqlVisitor.limit > 0) {\n      tupleStream = new LimitStream(tupleStream, sqlVisitor.limit);\n    }\n\n    if(sqlVisitor.hasColumnAliases) {\n      tupleStream = new SelectStream(tupleStream, sqlVisitor.columnAliases);\n    }\n\n    return tupleStream;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e66a459d38c1c4a2f97128433dab546f683a9fed","date":1462873476,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/SQLHandler#doSelectDistinct(SQLVisitor,int,String,String).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/SQLHandler#doSelectDistinct(SQLVisitor,int,String,String).mjava","sourceNew":"  private static TupleStream doSelectDistinct(SQLVisitor sqlVisitor,\n                                              int numWorkers,\n                                              String workerCollection,\n                                              String workerZkHost) throws IOException {\n\n    Set<String> fieldSet = new HashSet();\n    Bucket[] buckets = getBuckets(sqlVisitor.fields, fieldSet);\n    Metric[] metrics = getMetrics(sqlVisitor.fields, fieldSet);\n\n    if(metrics.length > 0) {\n      throw new IOException(\"Select Distinct queries cannot include aggregate functions.\");\n    }\n\n    String fl = fields(fieldSet);\n\n    String sort = null;\n    StreamEqualitor ecomp = null;\n    StreamComparator comp = null;\n\n    if(sqlVisitor.sorts != null && sqlVisitor.sorts.size() > 0) {\n      StreamComparator[] adjustedSorts = adjustSorts(sqlVisitor.sorts, buckets, sqlVisitor.reverseColumnAliases);\n        // Because of the way adjustSorts works we know that each FieldComparator has a single\n        // field name. For this reason we can just look at the leftFieldName\n      FieldEqualitor[] fieldEqualitors = new FieldEqualitor[adjustedSorts.length];\n      StringBuilder buf = new StringBuilder();\n      for(int i=0; i<adjustedSorts.length; i++) {\n        FieldComparator fieldComparator = (FieldComparator)adjustedSorts[i];\n        fieldEqualitors[i] = new FieldEqualitor(fieldComparator.getLeftFieldName());\n        if(i>0) {\n          buf.append(\",\");\n        }\n        buf.append(fieldComparator.getLeftFieldName()).append(\" \").append(fieldComparator.getOrder().toString());\n      }\n\n      sort = buf.toString();\n\n      if(adjustedSorts.length == 1) {\n        ecomp = fieldEqualitors[0];\n        comp = adjustedSorts[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(fieldEqualitors);\n        comp = new MultipleFieldComparator(adjustedSorts);\n      }\n    } else {\n      StringBuilder sortBuf = new StringBuilder();\n      FieldEqualitor[] equalitors = new FieldEqualitor[buckets.length];\n      StreamComparator[] streamComparators = new StreamComparator[buckets.length];\n      for(int i=0; i<buckets.length; i++) {\n        equalitors[i] = new FieldEqualitor(buckets[i].toString());\n        streamComparators[i] = new FieldComparator(buckets[i].toString(), ComparatorOrder.ASCENDING);\n        if(i>0) {\n          sortBuf.append(',');\n        }\n        sortBuf.append(buckets[i].toString()).append(\" asc\");\n      }\n\n      sort = sortBuf.toString();\n\n      if(equalitors.length == 1) {\n        ecomp = equalitors[0];\n        comp = streamComparators[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(equalitors);\n        comp = new MultipleFieldComparator(streamComparators);\n      }\n    }\n\n    TableSpec tableSpec = new TableSpec(sqlVisitor.table, defaultZkhost);\n\n    String zkHost = tableSpec.zkHost;\n    String collection = tableSpec.collection;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n\n    params.set(CommonParams.FL, fl);\n    params.set(CommonParams.Q, sqlVisitor.query);\n    //Always use the /export handler for Distinct Queries because it requires exporting full result sets.\n    params.set(CommonParams.QT, \"/export\");\n\n    if(numWorkers > 1) {\n      params.set(\"partitionKeys\", getPartitionKeys(buckets));\n    }\n\n    params.set(\"sort\", sort);\n\n    TupleStream tupleStream = null;\n\n    CloudSolrStream cstream = new CloudSolrStream(zkHost, collection, params);\n    tupleStream = new UniqueStream(cstream, ecomp);\n\n    if(numWorkers > 1) {\n      // Do the unique in parallel\n      // Maintain the sort of the Tuples coming from the workers.\n      ParallelStream parallelStream = new ParallelStream(workerZkHost, workerCollection, tupleStream, numWorkers, comp);\n\n      StreamFactory factory = new StreamFactory()\n          .withFunctionName(\"search\", CloudSolrStream.class)\n          .withFunctionName(\"parallel\", ParallelStream.class)\n          .withFunctionName(\"unique\", UniqueStream.class);\n\n      parallelStream.setStreamFactory(factory);\n      tupleStream = parallelStream;\n    }\n\n    if(sqlVisitor.limit > 0) {\n      tupleStream = new LimitStream(tupleStream, sqlVisitor.limit);\n    }\n\n    if(sqlVisitor.hasColumnAliases) {\n      tupleStream = new SelectStream(tupleStream, sqlVisitor.columnAliases);\n    }\n\n    return tupleStream;\n  }\n\n","sourceOld":"  private static TupleStream doSelectDistinct(SQLVisitor sqlVisitor,\n                                              int numWorkers,\n                                              String workerCollection,\n                                              String workerZkHost) throws IOException {\n\n    Set<String> fieldSet = new HashSet();\n    Bucket[] buckets = getBuckets(sqlVisitor.fields, fieldSet);\n    Metric[] metrics = getMetrics(sqlVisitor.fields, fieldSet);\n\n    if(metrics.length > 0) {\n      throw new IOException(\"Select Distinct queries cannot include aggregate functions.\");\n    }\n\n    String fl = fields(fieldSet);\n\n    String sort = null;\n    StreamEqualitor ecomp = null;\n    StreamComparator comp = null;\n\n    if(sqlVisitor.sorts != null && sqlVisitor.sorts.size() > 0) {\n      StreamComparator[] adjustedSorts = adjustSorts(sqlVisitor.sorts, buckets, sqlVisitor.reverseColumnAliases);\n        // Because of the way adjustSorts works we know that each FieldComparator has a single\n        // field name. For this reason we can just look at the leftFieldName\n      FieldEqualitor[] fieldEqualitors = new FieldEqualitor[adjustedSorts.length];\n      StringBuilder buf = new StringBuilder();\n      for(int i=0; i<adjustedSorts.length; i++) {\n        FieldComparator fieldComparator = (FieldComparator)adjustedSorts[i];\n        fieldEqualitors[i] = new FieldEqualitor(fieldComparator.getLeftFieldName());\n        if(i>0) {\n          buf.append(\",\");\n        }\n        buf.append(fieldComparator.getLeftFieldName()).append(\" \").append(fieldComparator.getOrder().toString());\n      }\n\n      sort = buf.toString();\n\n      if(adjustedSorts.length == 1) {\n        ecomp = fieldEqualitors[0];\n        comp = adjustedSorts[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(fieldEqualitors);\n        comp = new MultipleFieldComparator(adjustedSorts);\n      }\n    } else {\n      StringBuilder sortBuf = new StringBuilder();\n      FieldEqualitor[] equalitors = new FieldEqualitor[buckets.length];\n      StreamComparator[] streamComparators = new StreamComparator[buckets.length];\n      for(int i=0; i<buckets.length; i++) {\n        equalitors[i] = new FieldEqualitor(buckets[i].toString());\n        streamComparators[i] = new FieldComparator(buckets[i].toString(), ComparatorOrder.ASCENDING);\n        if(i>0) {\n          sortBuf.append(',');\n        }\n        sortBuf.append(buckets[i].toString()).append(\" asc\");\n      }\n\n      sort = sortBuf.toString();\n\n      if(equalitors.length == 1) {\n        ecomp = equalitors[0];\n        comp = streamComparators[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(equalitors);\n        comp = new MultipleFieldComparator(streamComparators);\n      }\n    }\n\n    TableSpec tableSpec = new TableSpec(sqlVisitor.table, defaultZkhost);\n\n    String zkHost = tableSpec.zkHost;\n    String collection = tableSpec.collection;\n    Map<String, String> params = new HashMap();\n\n    params.put(CommonParams.FL, fl);\n    params.put(CommonParams.Q, sqlVisitor.query);\n    //Always use the /export handler for Distinct Queries because it requires exporting full result sets.\n    params.put(CommonParams.QT, \"/export\");\n\n    if(numWorkers > 1) {\n      params.put(\"partitionKeys\", getPartitionKeys(buckets));\n    }\n\n    params.put(\"sort\", sort);\n\n    TupleStream tupleStream = null;\n\n    CloudSolrStream cstream = new CloudSolrStream(zkHost, collection, params);\n    tupleStream = new UniqueStream(cstream, ecomp);\n\n    if(numWorkers > 1) {\n      // Do the unique in parallel\n      // Maintain the sort of the Tuples coming from the workers.\n      ParallelStream parallelStream = new ParallelStream(workerZkHost, workerCollection, tupleStream, numWorkers, comp);\n\n      StreamFactory factory = new StreamFactory()\n          .withFunctionName(\"search\", CloudSolrStream.class)\n          .withFunctionName(\"parallel\", ParallelStream.class)\n          .withFunctionName(\"unique\", UniqueStream.class);\n\n      parallelStream.setStreamFactory(factory);\n      tupleStream = parallelStream;\n    }\n\n    if(sqlVisitor.limit > 0) {\n      tupleStream = new LimitStream(tupleStream, sqlVisitor.limit);\n    }\n\n    if(sqlVisitor.hasColumnAliases) {\n      tupleStream = new SelectStream(tupleStream, sqlVisitor.columnAliases);\n    }\n\n    return tupleStream;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d470c8182e92b264680e34081b75e70a9f2b3c89","date":1463985353,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/SQLHandler#doSelectDistinct(SQLVisitor,int,String,String).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/SQLHandler#doSelectDistinct(SQLVisitor,int,String,String).mjava","sourceNew":"  private static TupleStream doSelectDistinct(SQLVisitor sqlVisitor,\n                                              int numWorkers,\n                                              String workerCollection,\n                                              String workerZkHost) throws IOException {\n\n    Set<String> fieldSet = new HashSet();\n    Bucket[] buckets = getBuckets(sqlVisitor.fields, fieldSet);\n    Metric[] metrics = getMetrics(sqlVisitor.fields, fieldSet);\n\n    if(metrics.length > 0) {\n      throw new IOException(\"Select Distinct queries cannot include aggregate functions.\");\n    }\n\n    String fl = fields(fieldSet);\n\n    String sort = null;\n    StreamEqualitor ecomp = null;\n    StreamComparator comp = null;\n\n    if(sqlVisitor.sorts != null && sqlVisitor.sorts.size() > 0) {\n      StreamComparator[] adjustedSorts = adjustSorts(sqlVisitor.sorts, buckets, sqlVisitor.reverseColumnAliases);\n        // Because of the way adjustSorts works we know that each FieldComparator has a single\n        // field name. For this reason we can just look at the leftFieldName\n      FieldEqualitor[] fieldEqualitors = new FieldEqualitor[adjustedSorts.length];\n      StringBuilder buf = new StringBuilder();\n      for(int i=0; i<adjustedSorts.length; i++) {\n        FieldComparator fieldComparator = (FieldComparator)adjustedSorts[i];\n        fieldEqualitors[i] = new FieldEqualitor(fieldComparator.getLeftFieldName());\n        if(i>0) {\n          buf.append(\",\");\n        }\n        buf.append(fieldComparator.getLeftFieldName()).append(\" \").append(fieldComparator.getOrder().toString());\n      }\n\n      sort = buf.toString();\n\n      if(adjustedSorts.length == 1) {\n        ecomp = fieldEqualitors[0];\n        comp = adjustedSorts[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(fieldEqualitors);\n        comp = new MultipleFieldComparator(adjustedSorts);\n      }\n    } else {\n      StringBuilder sortBuf = new StringBuilder();\n      FieldEqualitor[] equalitors = new FieldEqualitor[buckets.length];\n      StreamComparator[] streamComparators = new StreamComparator[buckets.length];\n      for(int i=0; i<buckets.length; i++) {\n        equalitors[i] = new FieldEqualitor(buckets[i].toString());\n        streamComparators[i] = new FieldComparator(buckets[i].toString(), ComparatorOrder.ASCENDING);\n        if(i>0) {\n          sortBuf.append(',');\n        }\n        sortBuf.append(buckets[i].toString()).append(\" asc\");\n      }\n\n      sort = sortBuf.toString();\n\n      if(equalitors.length == 1) {\n        ecomp = equalitors[0];\n        comp = streamComparators[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(equalitors);\n        comp = new MultipleFieldComparator(streamComparators);\n      }\n    }\n\n    TableSpec tableSpec = new TableSpec(sqlVisitor.table, defaultZkhost);\n\n    String zkHost = tableSpec.zkHost;\n    String collection = tableSpec.collection;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n\n    params.set(CommonParams.FL, fl);\n    params.set(CommonParams.Q, sqlVisitor.query);\n    //Always use the /export handler for Distinct Queries because it requires exporting full result sets.\n    params.set(CommonParams.QT, \"/export\");\n\n    if(numWorkers > 1) {\n      params.set(\"partitionKeys\", getPartitionKeys(buckets));\n    }\n\n    params.set(\"sort\", sort);\n\n    TupleStream tupleStream = null;\n\n    CloudSolrStream cstream = new CloudSolrStream(zkHost, collection, params);\n    tupleStream = new UniqueStream(cstream, ecomp);\n\n    if(numWorkers > 1) {\n      // Do the unique in parallel\n      // Maintain the sort of the Tuples coming from the workers.\n      ParallelStream parallelStream = new ParallelStream(workerZkHost, workerCollection, tupleStream, numWorkers, comp);\n\n      StreamFactory factory = new StreamFactory()\n          .withFunctionName(\"search\", CloudSolrStream.class)\n          .withFunctionName(\"parallel\", ParallelStream.class)\n          .withFunctionName(\"unique\", UniqueStream.class);\n\n      parallelStream.setStreamFactory(factory);\n      tupleStream = parallelStream;\n    }\n\n    if(sqlVisitor.limit > 0) {\n      tupleStream = new LimitStream(tupleStream, sqlVisitor.limit);\n    }\n\n    if(sqlVisitor.hasColumnAliases) {\n      tupleStream = new SelectStream(tupleStream, sqlVisitor.columnAliases);\n    }\n\n    return tupleStream;\n  }\n\n","sourceOld":"  private static TupleStream doSelectDistinct(SQLVisitor sqlVisitor,\n                                              int numWorkers,\n                                              String workerCollection,\n                                              String workerZkHost) throws IOException {\n\n    Set<String> fieldSet = new HashSet();\n    Bucket[] buckets = getBuckets(sqlVisitor.fields, fieldSet);\n    Metric[] metrics = getMetrics(sqlVisitor.fields, fieldSet);\n\n    if(metrics.length > 0) {\n      throw new IOException(\"Select Distinct queries cannot include aggregate functions.\");\n    }\n\n    String fl = fields(fieldSet);\n\n    String sort = null;\n    StreamEqualitor ecomp = null;\n    StreamComparator comp = null;\n\n    if(sqlVisitor.sorts != null && sqlVisitor.sorts.size() > 0) {\n      StreamComparator[] adjustedSorts = adjustSorts(sqlVisitor.sorts, buckets, sqlVisitor.reverseColumnAliases);\n        // Because of the way adjustSorts works we know that each FieldComparator has a single\n        // field name. For this reason we can just look at the leftFieldName\n      FieldEqualitor[] fieldEqualitors = new FieldEqualitor[adjustedSorts.length];\n      StringBuilder buf = new StringBuilder();\n      for(int i=0; i<adjustedSorts.length; i++) {\n        FieldComparator fieldComparator = (FieldComparator)adjustedSorts[i];\n        fieldEqualitors[i] = new FieldEqualitor(fieldComparator.getLeftFieldName());\n        if(i>0) {\n          buf.append(\",\");\n        }\n        buf.append(fieldComparator.getLeftFieldName()).append(\" \").append(fieldComparator.getOrder().toString());\n      }\n\n      sort = buf.toString();\n\n      if(adjustedSorts.length == 1) {\n        ecomp = fieldEqualitors[0];\n        comp = adjustedSorts[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(fieldEqualitors);\n        comp = new MultipleFieldComparator(adjustedSorts);\n      }\n    } else {\n      StringBuilder sortBuf = new StringBuilder();\n      FieldEqualitor[] equalitors = new FieldEqualitor[buckets.length];\n      StreamComparator[] streamComparators = new StreamComparator[buckets.length];\n      for(int i=0; i<buckets.length; i++) {\n        equalitors[i] = new FieldEqualitor(buckets[i].toString());\n        streamComparators[i] = new FieldComparator(buckets[i].toString(), ComparatorOrder.ASCENDING);\n        if(i>0) {\n          sortBuf.append(',');\n        }\n        sortBuf.append(buckets[i].toString()).append(\" asc\");\n      }\n\n      sort = sortBuf.toString();\n\n      if(equalitors.length == 1) {\n        ecomp = equalitors[0];\n        comp = streamComparators[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(equalitors);\n        comp = new MultipleFieldComparator(streamComparators);\n      }\n    }\n\n    TableSpec tableSpec = new TableSpec(sqlVisitor.table, defaultZkhost);\n\n    String zkHost = tableSpec.zkHost;\n    String collection = tableSpec.collection;\n    Map<String, String> params = new HashMap();\n\n    params.put(CommonParams.FL, fl);\n    params.put(CommonParams.Q, sqlVisitor.query);\n    //Always use the /export handler for Distinct Queries because it requires exporting full result sets.\n    params.put(CommonParams.QT, \"/export\");\n\n    if(numWorkers > 1) {\n      params.put(\"partitionKeys\", getPartitionKeys(buckets));\n    }\n\n    params.put(\"sort\", sort);\n\n    TupleStream tupleStream = null;\n\n    CloudSolrStream cstream = new CloudSolrStream(zkHost, collection, params);\n    tupleStream = new UniqueStream(cstream, ecomp);\n\n    if(numWorkers > 1) {\n      // Do the unique in parallel\n      // Maintain the sort of the Tuples coming from the workers.\n      ParallelStream parallelStream = new ParallelStream(workerZkHost, workerCollection, tupleStream, numWorkers, comp);\n\n      StreamFactory factory = new StreamFactory()\n          .withFunctionName(\"search\", CloudSolrStream.class)\n          .withFunctionName(\"parallel\", ParallelStream.class)\n          .withFunctionName(\"unique\", UniqueStream.class);\n\n      parallelStream.setStreamFactory(factory);\n      tupleStream = parallelStream;\n    }\n\n    if(sqlVisitor.limit > 0) {\n      tupleStream = new LimitStream(tupleStream, sqlVisitor.limit);\n    }\n\n    if(sqlVisitor.hasColumnAliases) {\n      tupleStream = new SelectStream(tupleStream, sqlVisitor.columnAliases);\n    }\n\n    return tupleStream;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"116fdd6b9e04e18a6547a5650bc0afd3fda020aa","date":1487184909,"type":5,"author":"Joel Bernstein","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/sql/SolrTable#handleSelectDistinctMapReduce(String,String,Properties,List[Map.Entry[String,Class]],String,List[Pair[String,String]],Bucket[],String).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/SQLHandler#doSelectDistinct(SQLVisitor,int,String,String).mjava","sourceNew":"  private TupleStream handleSelectDistinctMapReduce(final String zkHost,\n                                                    final String collection,\n                                                    final Properties properties,\n                                                    final List<Map.Entry<String, Class>> fields,\n                                                    final String query,\n                                                    final List<Pair<String, String>> orders,\n                                                    final Bucket[] buckets,\n                                                    final String limit) throws IOException{\n\n    int numWorkers = Integer.parseInt(properties.getProperty(\"numWorkers\", \"1\"));\n\n    String fl = getFields(fields);\n\n    String sort = null;\n    StreamEqualitor ecomp = null;\n    StreamComparator comp = null;\n\n    if(orders != null && orders.size() > 0) {\n      StreamComparator[] adjustedSorts = adjustSorts(orders, buckets);\n      // Because of the way adjustSorts works we know that each FieldComparator has a single\n      // field name. For this reason we can just look at the leftFieldName\n      FieldEqualitor[] fieldEqualitors = new FieldEqualitor[adjustedSorts.length];\n      StringBuilder buf = new StringBuilder();\n      for(int i=0; i<adjustedSorts.length; i++) {\n        FieldComparator fieldComparator = (FieldComparator)adjustedSorts[i];\n        fieldEqualitors[i] = new FieldEqualitor(fieldComparator.getLeftFieldName());\n        if(i>0) {\n          buf.append(\",\");\n        }\n        buf.append(fieldComparator.getLeftFieldName()).append(\" \").append(fieldComparator.getOrder().toString());\n      }\n\n      sort = buf.toString();\n\n      if(adjustedSorts.length == 1) {\n        ecomp = fieldEqualitors[0];\n        comp = adjustedSorts[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(fieldEqualitors);\n        comp = new MultipleFieldComparator(adjustedSorts);\n      }\n    } else {\n      StringBuilder sortBuf = new StringBuilder();\n      FieldEqualitor[] equalitors = new FieldEqualitor[buckets.length];\n      StreamComparator[] streamComparators = new StreamComparator[buckets.length];\n      for(int i=0; i<buckets.length; i++) {\n        equalitors[i] = new FieldEqualitor(buckets[i].toString());\n        streamComparators[i] = new FieldComparator(buckets[i].toString(), ComparatorOrder.ASCENDING);\n        if(i>0) {\n          sortBuf.append(',');\n        }\n        sortBuf.append(buckets[i].toString()).append(\" asc\");\n      }\n\n      sort = sortBuf.toString();\n\n      if(equalitors.length == 1) {\n        ecomp = equalitors[0];\n        comp = streamComparators[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(equalitors);\n        comp = new MultipleFieldComparator(streamComparators);\n      }\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n\n    params.set(CommonParams.FL, fl);\n    params.set(CommonParams.Q, query);\n    //Always use the /export handler for Distinct Queries because it requires exporting full result sets.\n    params.set(CommonParams.QT, \"/export\");\n\n    if(numWorkers > 1) {\n      params.set(\"partitionKeys\", getPartitionKeys(buckets));\n    }\n\n    params.set(\"sort\", sort);\n\n    TupleStream tupleStream = null;\n\n    CloudSolrStream cstream = new CloudSolrStream(zkHost, collection, params);\n    tupleStream = new UniqueStream(cstream, ecomp);\n\n    if(numWorkers > 1) {\n      // Do the unique in parallel\n      // Maintain the sort of the Tuples coming from the workers.\n      ParallelStream parallelStream = new ParallelStream(zkHost, collection, tupleStream, numWorkers, comp);\n\n      StreamFactory factory = new StreamFactory()\n          .withFunctionName(\"search\", CloudSolrStream.class)\n          .withFunctionName(\"parallel\", ParallelStream.class)\n          .withFunctionName(\"unique\", UniqueStream.class);\n\n      parallelStream.setStreamFactory(factory);\n      tupleStream = parallelStream;\n    }\n\n    if(limit != null) {\n      tupleStream = new LimitStream(tupleStream, Integer.parseInt(limit));\n    }\n\n    return tupleStream;\n  }\n\n","sourceOld":"  private static TupleStream doSelectDistinct(SQLVisitor sqlVisitor,\n                                              int numWorkers,\n                                              String workerCollection,\n                                              String workerZkHost) throws IOException {\n\n    Set<String> fieldSet = new HashSet();\n    Bucket[] buckets = getBuckets(sqlVisitor.fields, fieldSet);\n    Metric[] metrics = getMetrics(sqlVisitor.fields, fieldSet);\n\n    if(metrics.length > 0) {\n      throw new IOException(\"Select Distinct queries cannot include aggregate functions.\");\n    }\n\n    String fl = fields(fieldSet);\n\n    String sort = null;\n    StreamEqualitor ecomp = null;\n    StreamComparator comp = null;\n\n    if(sqlVisitor.sorts != null && sqlVisitor.sorts.size() > 0) {\n      StreamComparator[] adjustedSorts = adjustSorts(sqlVisitor.sorts, buckets, sqlVisitor.reverseColumnAliases);\n        // Because of the way adjustSorts works we know that each FieldComparator has a single\n        // field name. For this reason we can just look at the leftFieldName\n      FieldEqualitor[] fieldEqualitors = new FieldEqualitor[adjustedSorts.length];\n      StringBuilder buf = new StringBuilder();\n      for(int i=0; i<adjustedSorts.length; i++) {\n        FieldComparator fieldComparator = (FieldComparator)adjustedSorts[i];\n        fieldEqualitors[i] = new FieldEqualitor(fieldComparator.getLeftFieldName());\n        if(i>0) {\n          buf.append(\",\");\n        }\n        buf.append(fieldComparator.getLeftFieldName()).append(\" \").append(fieldComparator.getOrder().toString());\n      }\n\n      sort = buf.toString();\n\n      if(adjustedSorts.length == 1) {\n        ecomp = fieldEqualitors[0];\n        comp = adjustedSorts[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(fieldEqualitors);\n        comp = new MultipleFieldComparator(adjustedSorts);\n      }\n    } else {\n      StringBuilder sortBuf = new StringBuilder();\n      FieldEqualitor[] equalitors = new FieldEqualitor[buckets.length];\n      StreamComparator[] streamComparators = new StreamComparator[buckets.length];\n      for(int i=0; i<buckets.length; i++) {\n        equalitors[i] = new FieldEqualitor(buckets[i].toString());\n        streamComparators[i] = new FieldComparator(buckets[i].toString(), ComparatorOrder.ASCENDING);\n        if(i>0) {\n          sortBuf.append(',');\n        }\n        sortBuf.append(buckets[i].toString()).append(\" asc\");\n      }\n\n      sort = sortBuf.toString();\n\n      if(equalitors.length == 1) {\n        ecomp = equalitors[0];\n        comp = streamComparators[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(equalitors);\n        comp = new MultipleFieldComparator(streamComparators);\n      }\n    }\n\n    TableSpec tableSpec = new TableSpec(sqlVisitor.table, defaultZkhost);\n\n    String zkHost = tableSpec.zkHost;\n    String collection = tableSpec.collection;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n\n    params.set(CommonParams.FL, fl);\n    params.set(CommonParams.Q, sqlVisitor.query);\n    //Always use the /export handler for Distinct Queries because it requires exporting full result sets.\n    params.set(CommonParams.QT, \"/export\");\n\n    if(numWorkers > 1) {\n      params.set(\"partitionKeys\", getPartitionKeys(buckets));\n    }\n\n    params.set(\"sort\", sort);\n\n    TupleStream tupleStream = null;\n\n    CloudSolrStream cstream = new CloudSolrStream(zkHost, collection, params);\n    tupleStream = new UniqueStream(cstream, ecomp);\n\n    if(numWorkers > 1) {\n      // Do the unique in parallel\n      // Maintain the sort of the Tuples coming from the workers.\n      ParallelStream parallelStream = new ParallelStream(workerZkHost, workerCollection, tupleStream, numWorkers, comp);\n\n      StreamFactory factory = new StreamFactory()\n          .withFunctionName(\"search\", CloudSolrStream.class)\n          .withFunctionName(\"parallel\", ParallelStream.class)\n          .withFunctionName(\"unique\", UniqueStream.class);\n\n      parallelStream.setStreamFactory(factory);\n      tupleStream = parallelStream;\n    }\n\n    if(sqlVisitor.limit > 0) {\n      tupleStream = new LimitStream(tupleStream, sqlVisitor.limit);\n    }\n\n    if(sqlVisitor.hasColumnAliases) {\n      tupleStream = new SelectStream(tupleStream, sqlVisitor.columnAliases);\n    }\n\n    return tupleStream;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"36479872320bb00635cb97ca6757614c88562e1b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"116fdd6b9e04e18a6547a5650bc0afd3fda020aa":["d470c8182e92b264680e34081b75e70a9f2b3c89","d984627825732e682759c22df7a3b171a80f3812"],"d984627825732e682759c22df7a3b171a80f3812":["5f90f992f4e4fdedb0fe0cc2fe3925df71a5b9f7"],"333d804f5abfaf34c57493306a4cb2e01e55662d":["36479872320bb00635cb97ca6757614c88562e1b"],"5f90f992f4e4fdedb0fe0cc2fe3925df71a5b9f7":["c3cf1396610fbacfdf69deb27bc5d3f36b5fbd43"],"c3cf1396610fbacfdf69deb27bc5d3f36b5fbd43":["333d804f5abfaf34c57493306a4cb2e01e55662d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"e66a459d38c1c4a2f97128433dab546f683a9fed":["5f90f992f4e4fdedb0fe0cc2fe3925df71a5b9f7","826d15444ddf61716dc768c229cd54b2c2ccce1c"],"826d15444ddf61716dc768c229cd54b2c2ccce1c":["5f90f992f4e4fdedb0fe0cc2fe3925df71a5b9f7"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["116fdd6b9e04e18a6547a5650bc0afd3fda020aa"],"d470c8182e92b264680e34081b75e70a9f2b3c89":["5f90f992f4e4fdedb0fe0cc2fe3925df71a5b9f7","826d15444ddf61716dc768c229cd54b2c2ccce1c"]},"commit2Childs":{"36479872320bb00635cb97ca6757614c88562e1b":["333d804f5abfaf34c57493306a4cb2e01e55662d"],"116fdd6b9e04e18a6547a5650bc0afd3fda020aa":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"d984627825732e682759c22df7a3b171a80f3812":["116fdd6b9e04e18a6547a5650bc0afd3fda020aa"],"333d804f5abfaf34c57493306a4cb2e01e55662d":["c3cf1396610fbacfdf69deb27bc5d3f36b5fbd43"],"5f90f992f4e4fdedb0fe0cc2fe3925df71a5b9f7":["d984627825732e682759c22df7a3b171a80f3812","e66a459d38c1c4a2f97128433dab546f683a9fed","826d15444ddf61716dc768c229cd54b2c2ccce1c","d470c8182e92b264680e34081b75e70a9f2b3c89"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["36479872320bb00635cb97ca6757614c88562e1b"],"c3cf1396610fbacfdf69deb27bc5d3f36b5fbd43":["5f90f992f4e4fdedb0fe0cc2fe3925df71a5b9f7"],"e66a459d38c1c4a2f97128433dab546f683a9fed":[],"826d15444ddf61716dc768c229cd54b2c2ccce1c":["e66a459d38c1c4a2f97128433dab546f683a9fed","d470c8182e92b264680e34081b75e70a9f2b3c89"],"d470c8182e92b264680e34081b75e70a9f2b3c89":["116fdd6b9e04e18a6547a5650bc0afd3fda020aa"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["e66a459d38c1c4a2f97128433dab546f683a9fed","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}